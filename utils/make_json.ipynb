{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "51b69b1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import os \n",
    "import pandas as pd\n",
    "import cv2\n",
    "import torch\n",
    "import matplotlib.pyplot as plt\n",
    "from ipywidgets import interact\n",
    "import albumentations as A\n",
    "from albumentations.pytorch import ToTensorV2\n",
    "import torchvision\n",
    "from torch import nn\n",
    "import torchsummary\n",
    "from torch.utils.data import DataLoader\n",
    "from collections import defaultdict\n",
    "from torchvision.utils import make_grid\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92a81c29",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2a0a7723",
   "metadata": {},
   "outputs": [],
   "source": [
    "class PET_dataset():\n",
    "    def __init__(self,part,neck_dir,body_dir,phase, transformer=None, aug=None, aug_factor=0):\n",
    "        self.neck_dir=neck_dir\n",
    "        self.body_dir=body_dir\n",
    "        self.part=part\n",
    "        self.phase=phase\n",
    "        self.transformer=transformer\n",
    "        self.aug=aug\n",
    "        self.aug_factor=aug_factor\n",
    "        if(self.part==\"body\"):\n",
    "            self.image_files = sorted([fn for fn in os.listdir(self.body_dir+\"/\"+self.phase+\"/image\") if fn.endswith(\"jpg\")])\n",
    "            self.label_files= sorted([lab for lab in os.listdir(self.body_dir+\"/\"+self.phase+\"/label\") if lab.endswith(\"txt\")])\n",
    "        elif(self.part==\"neck\"):\n",
    "            self.image_files = sorted([fn for fn in os.listdir(self.neck_dir+\"/\"+self.phase+\"/image\") if fn.endswith(\"jpg\")])\n",
    "            self.label_files= sorted([lab for lab in os.listdir(self.neck_dir+\"/\"+self.phase+\"/label\") if lab.endswith(\"txt\")])\n",
    "        \n",
    "        self.auged_img_list, self.auged_label_list=self.make_aug_list(self.image_files, self.label_files)\n",
    "        \n",
    "    def __getitem__(self,index):\n",
    "        if(self.aug==None):\n",
    "            filename, image = self.get_image(self.part, index)\n",
    "            bboxes, class_ids = self.get_label(self.part, index)\n",
    "\n",
    "            if(self.transformer):\n",
    "                transformed_data=self.transformer(image=image, bboxes=bboxes, class_ids=class_ids)\n",
    "                image = transformed_data['image']\n",
    "                bboxes = np.array(transformed_data['bboxes'])\n",
    "                class_ids = np.array(transformed_data['class_ids'])\n",
    "\n",
    "\n",
    "            target = {}\n",
    "    #         print(f'bboxes:{bboxes}\\nclass_ids:{class_ids}\\nlen_bboxes:{len(bboxes)}\\nlen_class_ids:{len(class_ids)}')\n",
    "    #         print(f'filename: {filename}')\n",
    "            target[\"boxes\"] = torch.Tensor(bboxes).float()\n",
    "            target[\"labels\"] = torch.Tensor(class_ids).long()\n",
    "\n",
    "            ###\n",
    "            bboxes=torch.Tensor(bboxes).float()\n",
    "            class_ids=torch.Tensor(class_ids).long()\n",
    "            target = np.concatenate((bboxes, class_ids[:, np.newaxis]), axis=1)\n",
    "            ###\n",
    "        else:\n",
    "            image=self.auged_img_list[index][1]\n",
    "            target=self.auged_label_list[index]\n",
    "            filename=self.auged_img_list[index][0]\n",
    "        return image, target, filename\n",
    "    \n",
    "    def __len__(self, ):\n",
    "        length=0\n",
    "        if(self.aug==None):\n",
    "            length=len(self.image_files)\n",
    "        else:\n",
    "            length=len(self.auged_img_list)\n",
    "        return length\n",
    "    \n",
    "    def make_aug_list(self,ori_image_list,ori_label_files):\n",
    "        aug_image_list=[]\n",
    "        aug_label_list=[]\n",
    "        \n",
    "        print(f\"start making augmented images-- augmented factor:{self.aug_factor}\")\n",
    "        for i in range(len(ori_image_list)):\n",
    "            filename, ori_image = self.get_image(self.part, i)\n",
    "            ori_bboxes, ori_class_ids = self.get_label(self.part, i)\n",
    "            for j in range(self.aug_factor):\n",
    "                auged_data=self.aug(image=ori_image, bboxes=ori_bboxes, class_ids=ori_class_ids)\n",
    "                image = auged_data['image']\n",
    "                bboxes = np.array(auged_data['bboxes'])\n",
    "                class_ids = np.array(auged_data['class_ids'])\n",
    "                \n",
    "                bboxes=torch.Tensor(bboxes).float()\n",
    "                class_ids=torch.Tensor(class_ids).long()\n",
    "                \n",
    "                aug_image_list.append((filename, image))\n",
    "                aug_label_list.append(np.concatenate((bboxes, class_ids[:, np.newaxis]), axis=1))\n",
    "        \n",
    "        print(f\"total length of augmented images: {len(aug_image_list)}\")\n",
    "        \n",
    "        return aug_image_list, aug_label_list\n",
    "        \n",
    "    \n",
    "    def get_image(self, part, index): # 이미지 불러오는 함수\n",
    "        filename = self.image_files[index]\n",
    "        if(part==\"body\"):\n",
    "#             print(f\"body called!-> {self.part}\")\n",
    "            image_path = self.body_dir+\"/\"+self.phase+\"/image/\"+filename\n",
    "        elif(part==\"neck\"):\n",
    "#             print(f\"neck called!-> {self.part}\")\n",
    "            image_path = self.neck_dir+\"/\"+self.phase+\"/image/\"+filename\n",
    "        image = cv2.imread(image_path)\n",
    "        image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "        return filename, image\n",
    "    \n",
    "    def get_label(self, part, index): # label (box좌표, class_id) 불러오는 함수\n",
    "        label_filename=self.label_files[index]\n",
    "        if(part==\"body\"):\n",
    "#             print(f\"body label called!-> {self.part}\")\n",
    "            label_path = self.body_dir+\"/\"+self.phase+\"/label/\"+label_filename\n",
    "        elif(part==\"neck\"):\n",
    "#             print(f\"neck label called!-> {self.part}\")\n",
    "            label_path = self.neck_dir+\"/\"+self.phase+\"/label/\"+label_filename\n",
    "        with open(label_path, 'r') as file:\n",
    "            labels = file.readlines()\n",
    "        \n",
    "        class_ids=[]\n",
    "        bboxes=[]\n",
    "        for label in labels:\n",
    "            label=label.replace(\"\\n\", \"\")\n",
    "            obj=label.split(' ')[0]\n",
    "            coor=label.split(' ')[1:]\n",
    "            obj=int(obj)\n",
    "            coor=list(map(float, coor))\n",
    "            class_ids.append(obj)\n",
    "            bboxes.append(coor)\n",
    "            \n",
    "        return bboxes, class_ids\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7cec32e4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "start making augmented images-- augmented factor:0\n",
      "total length of augmented images: 0\n"
     ]
    }
   ],
   "source": [
    "NECK_PATH = '/home/host_data/PET_data/Neck'\n",
    "BODY_PATH = '/home/host_data/PET_data/Body'\n",
    "IMAGE_SIZE = 448\n",
    "transformer = A.Compose([\n",
    "            A.Resize(height=IMAGE_SIZE, width=IMAGE_SIZE),\n",
    "            A.Normalize(mean=(0.485, 0.456, 0.406),std=(0.229, 0.224, 0.225)),\n",
    "            ToTensorV2(),\n",
    "        ],\n",
    "        bbox_params=A.BboxParams(format='yolo', label_fields=['class_ids']),\n",
    "    )\n",
    "test_dataset=PET_dataset(\"neck\" ,neck_dir=NECK_PATH,body_dir=BODY_PATH,phase='test', transformer=transformer, aug=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "ed9c26b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def XcenYcenWH_to_XminYmin_WH(box):\n",
    "#     Xmin = box[:, 0] - box[:, 2]/2\n",
    "#     Ymin = box[:, 1] - box[:, 3]/2\n",
    "#     W = box[:, 2]\n",
    "#     H = box[:, 3]\n",
    "    Xmin = box[0] - box[2]/2\n",
    "    Ymin = box[1] - box[3]/2\n",
    "    W = box[2]\n",
    "    H = box[3]\n",
    "    return [Xmin,Ymin,W,H]\n",
    "#     return np.stack((Xmin, Ymin, W, H), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "17e0dfd1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([3, 448, 448]) [[0.14337599 0.68225801 0.055735   0.145161   0.        ]] shape1_121.jpg\n",
      "torch.Size([3, 448, 448]) [[0.58001602 0.21947201 0.164094   0.20132001 0.        ]] shape1_148.jpg\n",
      "torch.Size([3, 448, 448]) [[0.21932    0.32191801 0.16169199 0.171233   0.        ]\n",
      " [0.50787699 0.57362998 0.052239   0.14726    0.        ]] shape1_153.jpg\n",
      "torch.Size([3, 448, 448]) [[0.90198499 0.72297299 0.040529   0.128378   0.        ]] shape1_48.jpg\n",
      "torch.Size([3, 448, 448]) [[0.50946498 0.227273   0.13662601 0.22558901 0.        ]\n",
      " [0.35061699 0.59427601 0.046091   0.124579   0.        ]] shape1_65.jpg\n",
      "torch.Size([3, 448, 448]) [[0.109323   0.41396099 0.15924101 0.27597401 0.        ]\n",
      " [0.83745903 0.63960999 0.042904   0.123377   0.        ]] shape1_80.jpg\n",
      "torch.Size([3, 448, 448]) [[0.51067299 0.59515601 0.054187   0.16609    0.        ]] shape1_99.jpg\n",
      "torch.Size([3, 448, 448]) [[0.55207503 0.340996   0.051261   0.19923399 0.        ]] shape2_105.jpg\n",
      "torch.Size([3, 448, 448]) [[0.23926499 0.38813499 0.0642437  0.181031   0.        ]] shape2_127.jpg\n",
      "torch.Size([3, 448, 448]) [[0.66097599 0.43010801 0.030894   0.58781397 1.        ]] shape2_135.jpg\n",
      "torch.Size([3, 448, 448]) [[0.111286   0.33790001 0.0360801  0.57134902 1.        ]\n",
      " [0.77128798 0.368891   0.0506322  0.196611   0.        ]] shape2_14.jpg\n",
      "torch.Size([3, 448, 448]) [[0.343725   0.34905699 0.073684   0.192453   0.        ]] shape2_151.jpg\n",
      "torch.Size([3, 448, 448]) [[0.13187601 0.27845901 0.0446565  0.18458    0.        ]] shape2_53.jpg\n",
      "torch.Size([3, 448, 448]) [[0.373469   0.31872499 0.07102    0.22310799 0.        ]] shape2_55.jpg\n",
      "torch.Size([3, 448, 448]) [[0.11615   0.273662  0.0409005 0.174068  0.       ]] shape2_70.jpg\n",
      "torch.Size([3, 448, 448]) [[0.24308901 0.33794501 0.055285   0.19367599 0.        ]] shape2_75.jpg\n",
      "torch.Size([3, 448, 448]) [[0.363821 0.346899 0.060976 0.236434 0.      ]] shape2_79.jpg\n",
      "torch.Size([3, 448, 448]) [[0.64314699 0.38927299 0.076237   0.19723199 0.        ]] shape2_81.jpg\n",
      "torch.Size([3, 448, 448]) [[0.23838601 0.41774899 0.072535   0.220779   0.        ]] shape3_12.jpg\n",
      "torch.Size([3, 448, 448]) [[0.52074897 0.42060101 0.082994   0.18025801 0.        ]] shape3_14.jpg\n",
      "torch.Size([3, 448, 448]) [[0.190322  0.443174  0.0560288 0.212317  0.       ]] shape3_15.jpg\n",
      "torch.Size([3, 448, 448]) [[0.83401501 0.35281399 0.044154   0.22943699 0.        ]] shape3_44.jpg\n",
      "torch.Size([3, 448, 448]) [[0.161149   0.33522701 0.059396   0.14204501 0.        ]] shape4_24.jpg\n",
      "torch.Size([3, 448, 448]) [[0.68150699 0.50456601 0.078767   0.09589    0.        ]] shape5_34.jpg\n",
      "torch.Size([3, 448, 448]) [[0.271341   0.41538501 0.040941   0.13538501 0.        ]] shape6_34.jpg\n"
     ]
    }
   ],
   "source": [
    "for k in range(len(test_dataset)):\n",
    "    image=test_dataset[k][0]\n",
    "    target=test_dataset[k][1]\n",
    "    filename=test_dataset[k][2]\n",
    "    print(image.shape, target, filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "14521874",
   "metadata": {},
   "outputs": [],
   "source": [
    "part='neck'\n",
    "neck_dir = '/home/host_data/PET_data/Neck'\n",
    "body_dir = '/home/host_data/PET_data/Body'\n",
    "phase='test'\n",
    "\n",
    "ImageToId={\"shape1_121.jpg\": 0,\n",
    "           \"shape1_148.jpg\": 1,\n",
    "           \"shape1_153.jpg\": 2,\n",
    "           \"shape1_48.jpg\": 3,\n",
    "           \"shape1_65.jpg\": 4,\n",
    "           \"shape1_80.jpg\": 5,\n",
    "           \"shape1_99.jpg\": 6,\n",
    "           \"shape2_105.jpg\": 7,\n",
    "           \"shape2_127.jpg\": 8,\n",
    "           \"shape2_135.jpg\": 9,\n",
    "           \"shape2_14.jpg\": 10,\n",
    "           \"shape2_151.jpg\": 11,\n",
    "           \"shape2_53.jpg\": 12,\n",
    "           \"shape2_55.jpg\": 13,\n",
    "           \"shape2_70.jpg\": 14,\n",
    "           \"shape2_75.jpg\": 15,\n",
    "           \"shape2_79.jpg\": 16,\n",
    "           \"shape2_81.jpg\": 17,\n",
    "           \"shape3_12.jpg\": 18,\n",
    "           \"shape3_14.jpg\": 19,\n",
    "           \"shape3_15.jpg\": 20,\n",
    "           \"shape3_44.jpg\": 21,\n",
    "           \"shape4_24.jpg\": 22,\n",
    "           \"shape5_34.jpg\": 23,\n",
    "           \"shape6_34.jpg\": 24,}\n",
    "with open('/home/host_data/PET_data/Neck/test/test.json', 'r') as f:\n",
    "        json_data = json.load(f)\n",
    "        \n",
    "for k in range(len(test_dataset)):\n",
    "    image=test_dataset[k][0]\n",
    "    targets=test_dataset[k][1]\n",
    "    image_filename=test_dataset[k][2]\n",
    "    w=image.shape[2]\n",
    "    h=image.shape[1]\n",
    "    for target in targets:\n",
    "        target[0]=target[0]*w\n",
    "        target[2]=target[2]*w\n",
    "        target[1]=target[1]*h\n",
    "        target[3]=target[3]*h\n",
    "#         class_ids.append(obj)\n",
    "#         bboxes.append(coor)\n",
    "    val={\"id\": 0,\n",
    "   \"image_id\": 0,\n",
    "   \"bbox\": [],\n",
    "   \"area\": 0,\n",
    "   \"iscrowd\": 0,\n",
    "   \"category_id\": 0,\n",
    "   \"segmentation\": []}\n",
    "    for i in range(len(targets)):\n",
    "        val={\"id\": 0,\n",
    "       \"image_id\": 0,\n",
    "       \"bbox\": [],\n",
    "       \"area\": 0,\n",
    "       \"iscrowd\": 0,\n",
    "       \"category_id\": 0,\n",
    "       \"segmentation\": []}\n",
    "        val['image_id']=ImageToId[image_filename]\n",
    "        val['id']=i\n",
    "        val['area']=targets[i][2]*targets[i][3]\n",
    "        val['category_id']=int(targets[i][4])\n",
    "#         val['bbox']=targets[i][0:4].tolist()\n",
    "        val['bbox']=XcenYcenWH_to_XminYmin_WH([targets[i][0],targets[i][1],targets[i][2],targets[i][3]])\n",
    "        json_data['annotations'].append(val)\n",
    "#         print(f\"--{XcenYcenWH_to_XminYmin_WH([targets[i][0],targets[i][1],targets[i][2],targets[i][3]])}\")\n",
    "        with open('/home/host_data/PET_data/Neck/test/test.json', 'w', encoding='utf-8') as make_file:\n",
    "            json.dump(json_data, make_file, indent=\"\\t\")\n",
    "#     print(f\"image shape:{image.shape}, label:{label_filename}, bbox:{targets[i][0:4]}, class_ids:{targets[i][4]}\\n\")\n",
    "\n",
    "    \n",
    "# with open('/home/host_data/PET_data/Body/test/test.json', 'r') as f:\n",
    "#         json_data = json.load(f)\n",
    "# print(json.dumps(json_data['annotations'], indent=\"\\t\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38a9d14a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea7dae72",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
