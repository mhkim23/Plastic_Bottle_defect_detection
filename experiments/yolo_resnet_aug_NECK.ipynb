{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "3c025da0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import os \n",
    "import pandas as pd\n",
    "import cv2\n",
    "import torch\n",
    "import matplotlib.pyplot as plt\n",
    "from ipywidgets import interact\n",
    "import albumentations as A\n",
    "from albumentations.pytorch import ToTensorV2\n",
    "import torchvision\n",
    "from torch import nn\n",
    "import torchsummary\n",
    "from torch.utils.data import DataLoader\n",
    "from collections import defaultdict\n",
    "from torchvision.utils import make_grid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "5d503acd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cuda', index=0)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "device"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ee9eb3c",
   "metadata": {},
   "source": [
    "# Utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "c7fac7d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "CLASS_NAME_TO_ID = {'Unformed': 0, 'Burr': 1}\n",
    "CLASS_ID_TO_NAME = {0: 'Unformed', 1: 'Burr'}\n",
    "BOX_COLOR = {'Unformed':(200, 0, 0), 'Burr':(0, 0, 200)}\n",
    "TEXT_COLOR = (255, 255, 255)\n",
    "\n",
    "def save_model(model_state, model_name, save_dir=\"./trained_model\"):\n",
    "    os.makedirs(save_dir, exist_ok=True)\n",
    "    torch.save(model_state, os.path.join(save_dir, model_name))\n",
    "\n",
    "\n",
    "def visualize_bbox(image, bbox, class_name, color=BOX_COLOR, thickness=2):\n",
    "    x_center, y_center, w, h = bbox\n",
    "    x_min = int(x_center - w/2)\n",
    "    y_min = int(y_center - h/2)\n",
    "    x_max = int(x_center + w/2)\n",
    "    y_max = int(y_center + h/2)\n",
    "    \n",
    "    cv2.rectangle(image, (x_min, y_min), (x_max, y_max), color=color[class_name], thickness=thickness)\n",
    "    \n",
    "    ((text_width, text_height), _) = cv2.getTextSize(class_name, cv2.FONT_HERSHEY_SIMPLEX, 0.35, 1)    \n",
    "    cv2.rectangle(image, (x_min, y_min - int(1.3 * text_height)), (x_min + text_width, y_min), color[class_name], -1)\n",
    "    cv2.putText(\n",
    "        image,\n",
    "        text=class_name,\n",
    "        org=(x_min, y_min - int(0.3 * text_height)),\n",
    "        fontFace=cv2.FONT_HERSHEY_SIMPLEX,\n",
    "        fontScale=0.35, \n",
    "        color=TEXT_COLOR, \n",
    "        lineType=cv2.LINE_AA,\n",
    "    )\n",
    "    return image\n",
    "\n",
    "\n",
    "def visualize(image, bboxes, category_ids):\n",
    "    img = image.copy()\n",
    "    for bbox, category_id in zip(bboxes, category_ids):\n",
    "#         print('category_id: ',category_id)\n",
    "        class_name = CLASS_ID_TO_NAME[category_id.item()]\n",
    "        img = visualize_bbox(img, bbox, class_name)\n",
    "    return img"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62c7da98",
   "metadata": {},
   "source": [
    "# Datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "ea0166e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "class PET_dataset():\n",
    "    def __init__(self,part,neck_dir,body_dir,phase, transformer=None, aug=None, aug_factor=0):\n",
    "        self.neck_dir=neck_dir\n",
    "        self.body_dir=body_dir\n",
    "        self.part=part\n",
    "        self.phase=phase\n",
    "        self.transformer=transformer\n",
    "        self.aug=aug\n",
    "        self.aug_factor=aug_factor\n",
    "        if(self.part==\"body\"):\n",
    "            self.image_files = sorted([fn for fn in os.listdir(self.body_dir+\"/\"+self.phase+\"/image\") if fn.endswith(\"jpg\")])\n",
    "            self.label_files= sorted([lab for lab in os.listdir(self.body_dir+\"/\"+self.phase+\"/label\") if lab.endswith(\"txt\")])\n",
    "        elif(self.part==\"neck\"):\n",
    "            self.image_files = sorted([fn for fn in os.listdir(self.neck_dir+\"/\"+self.phase+\"/image\") if fn.endswith(\"jpg\")])\n",
    "            self.label_files= sorted([lab for lab in os.listdir(self.neck_dir+\"/\"+self.phase+\"/label\") if lab.endswith(\"txt\")])\n",
    "        \n",
    "        self.auged_img_list, self.auged_label_list=self.make_aug_list(self.image_files, self.label_files)\n",
    "        \n",
    "    def __getitem__(self,index):\n",
    "        if(self.aug==None):\n",
    "            filename, image = self.get_image(self.part, index)\n",
    "            bboxes, class_ids = self.get_label(self.part, index)\n",
    "\n",
    "            if(self.transformer):\n",
    "                transformed_data=self.transformer(image=image, bboxes=bboxes, class_ids=class_ids)\n",
    "                image = transformed_data['image']\n",
    "                bboxes = np.array(transformed_data['bboxes'])\n",
    "                class_ids = np.array(transformed_data['class_ids'])\n",
    "\n",
    "\n",
    "            target = {}\n",
    "    #         print(f'bboxes:{bboxes}\\nclass_ids:{class_ids}\\nlen_bboxes:{len(bboxes)}\\nlen_class_ids:{len(class_ids)}')\n",
    "    #         print(f'filename: {filename}')\n",
    "            target[\"boxes\"] = torch.Tensor(bboxes).float()\n",
    "            target[\"labels\"] = torch.Tensor(class_ids).long()\n",
    "\n",
    "            ###\n",
    "            bboxes=torch.Tensor(bboxes).float()\n",
    "            class_ids=torch.Tensor(class_ids).long()\n",
    "            target = np.concatenate((bboxes, class_ids[:, np.newaxis]), axis=1)\n",
    "            ###\n",
    "        else:\n",
    "            image=self.auged_img_list[index][1]\n",
    "            target=self.auged_label_list[index]\n",
    "            filename=self.auged_img_list[index][0]\n",
    "        return image, target, filename\n",
    "    \n",
    "    def __len__(self, ):\n",
    "        length=0\n",
    "        if(self.aug==None):\n",
    "            length=len(self.image_files)\n",
    "        else:\n",
    "            length=len(self.auged_img_list)\n",
    "        return length\n",
    "    \n",
    "    def make_aug_list(self,ori_image_list,ori_label_files):\n",
    "        aug_image_list=[]\n",
    "        aug_label_list=[]\n",
    "        \n",
    "        print(f\"start making augmented images-- augmented factor:{self.aug_factor}\")\n",
    "        for i in range(len(ori_image_list)):\n",
    "            filename, ori_image = self.get_image(self.part, i)\n",
    "            ori_bboxes, ori_class_ids = self.get_label(self.part, i)\n",
    "            for j in range(self.aug_factor):\n",
    "                auged_data=self.aug(image=ori_image, bboxes=ori_bboxes, class_ids=ori_class_ids)\n",
    "                image = auged_data['image']\n",
    "                bboxes = np.array(auged_data['bboxes'])\n",
    "                class_ids = np.array(auged_data['class_ids'])\n",
    "                \n",
    "                bboxes=torch.Tensor(bboxes).float()\n",
    "                class_ids=torch.Tensor(class_ids).long()\n",
    "                \n",
    "                aug_image_list.append((filename, image))\n",
    "                aug_label_list.append(np.concatenate((bboxes, class_ids[:, np.newaxis]), axis=1))\n",
    "        \n",
    "        print(f\"total length of augmented images: {len(aug_image_list)}\")\n",
    "        \n",
    "        return aug_image_list, aug_label_list\n",
    "        \n",
    "    \n",
    "    def get_image(self, part, index): # 이미지 불러오는 함수\n",
    "        filename = self.image_files[index]\n",
    "        if(part==\"body\"):\n",
    "#             print(f\"body called!-> {self.part}\")\n",
    "            image_path = self.body_dir+\"/\"+self.phase+\"/image/\"+filename\n",
    "        elif(part==\"neck\"):\n",
    "#             print(f\"neck called!-> {self.part}\")\n",
    "            image_path = self.neck_dir+\"/\"+self.phase+\"/image/\"+filename\n",
    "        image = cv2.imread(image_path)\n",
    "        image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "        return filename, image\n",
    "    \n",
    "    def get_label(self, part, index): # label (box좌표, class_id) 불러오는 함수\n",
    "        label_filename=self.label_files[index]\n",
    "        if(part==\"body\"):\n",
    "#             print(f\"body label called!-> {self.part}\")\n",
    "            label_path = self.body_dir+\"/\"+self.phase+\"/label/\"+label_filename\n",
    "        elif(part==\"neck\"):\n",
    "#             print(f\"neck label called!-> {self.part}\")\n",
    "            label_path = self.neck_dir+\"/\"+self.phase+\"/label/\"+label_filename\n",
    "        with open(label_path, 'r') as file:\n",
    "            labels = file.readlines()\n",
    "        \n",
    "        class_ids=[]\n",
    "        bboxes=[]\n",
    "        for label in labels:\n",
    "            label=label.replace(\"\\n\", \"\")\n",
    "            obj=label.split(' ')[0]\n",
    "            coor=label.split(' ')[1:]\n",
    "            obj=int(obj)\n",
    "            coor=list(map(float, coor))\n",
    "            class_ids.append(obj)\n",
    "            bboxes.append(coor)\n",
    "            \n",
    "        return bboxes, class_ids\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "235e7cec",
   "metadata": {},
   "outputs": [],
   "source": [
    "IMAGE_SIZE = 448\n",
    "\n",
    "transformer = A.Compose([ \n",
    "        # bounding box의 변환, augmentation에서 albumentations는 Detection 학습을 할 때 굉장히 유용하다. \n",
    "        A.Resize(height=IMAGE_SIZE, width=IMAGE_SIZE),\n",
    "        A.Normalize(mean=(0.485, 0.456, 0.406),std=(0.229, 0.224, 0.225)),\n",
    "        ToTensorV2(),\n",
    "        # albumentations 라이브러리에서는 Normalization을 먼저 진행해 주고 tensor화를 진행해 주어야한다.\n",
    "    ],\n",
    "    # box 위치에 대한 transformation도 함께 진행된다. \n",
    "    bbox_params=A.BboxParams(format='yolo', label_fields=['class_ids']),\n",
    ")\n",
    "\n",
    "augmentator=A.Compose([\n",
    "#     A.Resize(height=IMAGE_SIZE, width=IMAGE_SIZE),\n",
    "    A.HorizontalFlip(p=0.7),\n",
    "#     A.Sharpen(p=0.7),\n",
    "    A.BBoxSafeRandomCrop(p=0.6),\n",
    "    A.VerticalFlip (p=0.5),\n",
    "    A.HueSaturationValue(p=0.5),\n",
    "    A.Resize(height=IMAGE_SIZE, width=IMAGE_SIZE),\n",
    "    A.Normalize(mean=(0.485, 0.456, 0.406),std=(0.229, 0.224, 0.225)),\n",
    "    ToTensorV2(),\n",
    "    ],\n",
    "    bbox_params=A.BboxParams(format='yolo', label_fields=['class_ids']),\n",
    ")\n",
    "\n",
    "def collate_fn(batch):\n",
    "    image_list = []\n",
    "    target_list = []\n",
    "    filename_list = []\n",
    "    \n",
    "    for a,b,c in batch:\n",
    "        image_list.append(a)\n",
    "        target_list.append(b)\n",
    "        filename_list.append(c)\n",
    "\n",
    "    return torch.stack(image_list, dim=0), target_list, filename_list\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "a6d5c32a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "start making augmented images-- augmented factor:5\n",
      "total length of augmented images: 1050\n",
      "start making augmented images-- augmented factor:0\n",
      "total length of augmented images: 0\n"
     ]
    }
   ],
   "source": [
    "NECK_PATH = '/home/host_data/PET_data/Neck'\n",
    "BODY_PATH = '/home/host_data/PET_data/Body'\n",
    "trainset_yes_aug=PET_dataset(part='neck',neck_dir=NECK_PATH,body_dir=BODY_PATH,phase='train', transformer=transformer, aug=augmentator, aug_factor=5)\n",
    "trainset_no_aug=PET_dataset(part='neck',neck_dir=NECK_PATH,body_dir=BODY_PATH,phase='train', transformer=transformer, aug=None)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "c0fbcd25",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1050"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(trainset_yes_aug)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "5db4ebba",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9bf4e17691714a6485e83594dd94be6f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "interactive(children=(IntSlider(value=0, description='index', max=209), Output()), _dom_classes=('widget-inter…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "@interact(index=(0, len(trainset_no_aug)-1))\n",
    "\n",
    "def show_sample(index=0):\n",
    "    image, target, filename = trainset_no_aug[index]\n",
    "    image=image.permute(1,2,0).numpy()\n",
    "    img_H, img_W, _ = image.shape\n",
    "    print(filename)\n",
    "    print(image.shape)\n",
    "#     print(image)\n",
    "\n",
    "#     bboxes = target['boxes']\n",
    "#     class_ids = target[\"labels\"]\n",
    "    \n",
    "    ###\n",
    "    bboxes = target[:, 0:4]\n",
    "    class_ids = target[:, 4]\n",
    "    ###\n",
    "    bboxes[:, [0,2]] *= img_W\n",
    "    bboxes[:, [1,3]] *= img_H\n",
    "\n",
    "    canvas = visualize(image, bboxes, class_ids)\n",
    "    plt.figure(figsize=(6,6))\n",
    "    plt.imshow(canvas)\n",
    "    plt.axis('off')\n",
    "    plt.show()\n",
    "\n",
    "# show_sample()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "5e341d7c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "dc2f0f8545384fc497e75c2df386cf40",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "interactive(children=(IntSlider(value=0, description='index', max=1049), Output()), _dom_classes=('widget-inte…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "@interact(index=(0, len(trainset_yes_aug)-1))\n",
    "\n",
    "def show_sample(index=0):\n",
    "    image, target, filename = trainset_yes_aug[index]\n",
    "    image=image.permute(1,2,0).numpy()\n",
    "    img_H, img_W, _ = image.shape\n",
    "    print(filename)\n",
    "    print(image.shape)\n",
    "#     print(image)\n",
    "\n",
    "#     bboxes = target['boxes']\n",
    "#     class_ids = target[\"labels\"]\n",
    "    ###\n",
    "    bboxes = target[:, 0:4]\n",
    "    class_ids = target[:, 4]\n",
    "    ###\n",
    "    bboxes[:, [0,2]] *= img_W\n",
    "    bboxes[:, [1,3]] *= img_H\n",
    "    print(bboxes)\n",
    "\n",
    "    canvas = visualize(image, bboxes, class_ids)\n",
    "    plt.figure(figsize=(6,6))\n",
    "    plt.imshow(canvas)\n",
    "    plt.axis('off')\n",
    "    plt.show()\n",
    "\n",
    "# show_sample()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f151003",
   "metadata": {},
   "source": [
    "## Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "729f2964",
   "metadata": {},
   "outputs": [],
   "source": [
    "class YOLO_SWIN(nn.Module):\n",
    "    def __init__(self, num_classes):\n",
    "        super().__init__()\n",
    "\n",
    "        self.num_classes = num_classes\n",
    "        self.num_bboxes = 2\n",
    "        self.grid_size = 7\n",
    "\n",
    "#         resnet18 = torchvision.models.resnet18(pretrained = True)\n",
    "        swin=torchvision.models.swin_v2_t(weights='IMAGENET1K_V1')\n",
    "        layers = [m for m in swin.children()] #Resnet에서 Yolo에서 가져올수 있을만한 layer만 선별적으로 가져오기 위해서\n",
    "\n",
    "        # 기존 Resnet18의 layer들중에서 맨 뒤에 두개만 제외하고 다 가져와서 Backbone으로 사용\n",
    "        self.backbone = nn.Sequential(*layers[:-3]) \n",
    "        self.head = nn.Sequential(\n",
    "                nn.Conv2d(in_channels=768, out_channels=1024, kernel_size=1, padding=0,bias=False),\n",
    "                nn.BatchNorm2d(1024),\n",
    "                nn.ReLU(inplace=True),\n",
    "                nn.Conv2d(in_channels=1024, out_channels=1024, kernel_size=3, padding=1,bias=False),\n",
    "                nn.BatchNorm2d(1024),\n",
    "                nn.ReLU(inplace=True),\n",
    "                nn.Conv2d(in_channels=1024, out_channels=1024, kernel_size=3, padding=1,bias=False),\n",
    "                nn.BatchNorm2d(1024),\n",
    "                nn.ReLU(inplace=True),\n",
    "                nn.Conv2d(in_channels=1024, out_channels=1024, kernel_size=3, padding=1,bias=False),\n",
    "                nn.BatchNorm2d(1024),\n",
    "                nn.ReLU(inplace=True),\n",
    "\n",
    "                nn.Conv2d(in_channels=1024, out_channels=(4+1)*self.num_bboxes+num_classes, kernel_size=1, padding=0, bias=False),\n",
    "                nn.AdaptiveAvgPool2d(output_size=(self.grid_size, self.grid_size))\n",
    "            )\n",
    "\n",
    "    def forward(self, x):\n",
    "        out = self.backbone(x)\n",
    "        # out = self.neck(out)\n",
    "        out = self.head(out) # input (batch, 3, 448, 448) -> output feature (batch, 12, 7, 7)\n",
    "        return out\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "b0a6eb83",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "YOLO_SWIN(\n",
       "  (backbone): Sequential(\n",
       "    (0): Sequential(\n",
       "      (0): Sequential(\n",
       "        (0): Conv2d(3, 96, kernel_size=(4, 4), stride=(4, 4))\n",
       "        (1): Permute()\n",
       "        (2): LayerNorm((96,), eps=1e-05, elementwise_affine=True)\n",
       "      )\n",
       "      (1): Sequential(\n",
       "        (0): SwinTransformerBlockV2(\n",
       "          (norm1): LayerNorm((96,), eps=1e-05, elementwise_affine=True)\n",
       "          (attn): ShiftedWindowAttentionV2(\n",
       "            (qkv): Linear(in_features=96, out_features=288, bias=True)\n",
       "            (proj): Linear(in_features=96, out_features=96, bias=True)\n",
       "            (cpb_mlp): Sequential(\n",
       "              (0): Linear(in_features=2, out_features=512, bias=True)\n",
       "              (1): ReLU(inplace=True)\n",
       "              (2): Linear(in_features=512, out_features=3, bias=False)\n",
       "            )\n",
       "          )\n",
       "          (stochastic_depth): StochasticDepth(p=0.0, mode=row)\n",
       "          (norm2): LayerNorm((96,), eps=1e-05, elementwise_affine=True)\n",
       "          (mlp): MLP(\n",
       "            (0): Linear(in_features=96, out_features=384, bias=True)\n",
       "            (1): GELU(approximate='none')\n",
       "            (2): Dropout(p=0.0, inplace=False)\n",
       "            (3): Linear(in_features=384, out_features=96, bias=True)\n",
       "            (4): Dropout(p=0.0, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (1): SwinTransformerBlockV2(\n",
       "          (norm1): LayerNorm((96,), eps=1e-05, elementwise_affine=True)\n",
       "          (attn): ShiftedWindowAttentionV2(\n",
       "            (qkv): Linear(in_features=96, out_features=288, bias=True)\n",
       "            (proj): Linear(in_features=96, out_features=96, bias=True)\n",
       "            (cpb_mlp): Sequential(\n",
       "              (0): Linear(in_features=2, out_features=512, bias=True)\n",
       "              (1): ReLU(inplace=True)\n",
       "              (2): Linear(in_features=512, out_features=3, bias=False)\n",
       "            )\n",
       "          )\n",
       "          (stochastic_depth): StochasticDepth(p=0.018181818181818184, mode=row)\n",
       "          (norm2): LayerNorm((96,), eps=1e-05, elementwise_affine=True)\n",
       "          (mlp): MLP(\n",
       "            (0): Linear(in_features=96, out_features=384, bias=True)\n",
       "            (1): GELU(approximate='none')\n",
       "            (2): Dropout(p=0.0, inplace=False)\n",
       "            (3): Linear(in_features=384, out_features=96, bias=True)\n",
       "            (4): Dropout(p=0.0, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (2): PatchMergingV2(\n",
       "        (reduction): Linear(in_features=384, out_features=192, bias=False)\n",
       "        (norm): LayerNorm((192,), eps=1e-05, elementwise_affine=True)\n",
       "      )\n",
       "      (3): Sequential(\n",
       "        (0): SwinTransformerBlockV2(\n",
       "          (norm1): LayerNorm((192,), eps=1e-05, elementwise_affine=True)\n",
       "          (attn): ShiftedWindowAttentionV2(\n",
       "            (qkv): Linear(in_features=192, out_features=576, bias=True)\n",
       "            (proj): Linear(in_features=192, out_features=192, bias=True)\n",
       "            (cpb_mlp): Sequential(\n",
       "              (0): Linear(in_features=2, out_features=512, bias=True)\n",
       "              (1): ReLU(inplace=True)\n",
       "              (2): Linear(in_features=512, out_features=6, bias=False)\n",
       "            )\n",
       "          )\n",
       "          (stochastic_depth): StochasticDepth(p=0.03636363636363637, mode=row)\n",
       "          (norm2): LayerNorm((192,), eps=1e-05, elementwise_affine=True)\n",
       "          (mlp): MLP(\n",
       "            (0): Linear(in_features=192, out_features=768, bias=True)\n",
       "            (1): GELU(approximate='none')\n",
       "            (2): Dropout(p=0.0, inplace=False)\n",
       "            (3): Linear(in_features=768, out_features=192, bias=True)\n",
       "            (4): Dropout(p=0.0, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (1): SwinTransformerBlockV2(\n",
       "          (norm1): LayerNorm((192,), eps=1e-05, elementwise_affine=True)\n",
       "          (attn): ShiftedWindowAttentionV2(\n",
       "            (qkv): Linear(in_features=192, out_features=576, bias=True)\n",
       "            (proj): Linear(in_features=192, out_features=192, bias=True)\n",
       "            (cpb_mlp): Sequential(\n",
       "              (0): Linear(in_features=2, out_features=512, bias=True)\n",
       "              (1): ReLU(inplace=True)\n",
       "              (2): Linear(in_features=512, out_features=6, bias=False)\n",
       "            )\n",
       "          )\n",
       "          (stochastic_depth): StochasticDepth(p=0.05454545454545456, mode=row)\n",
       "          (norm2): LayerNorm((192,), eps=1e-05, elementwise_affine=True)\n",
       "          (mlp): MLP(\n",
       "            (0): Linear(in_features=192, out_features=768, bias=True)\n",
       "            (1): GELU(approximate='none')\n",
       "            (2): Dropout(p=0.0, inplace=False)\n",
       "            (3): Linear(in_features=768, out_features=192, bias=True)\n",
       "            (4): Dropout(p=0.0, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (4): PatchMergingV2(\n",
       "        (reduction): Linear(in_features=768, out_features=384, bias=False)\n",
       "        (norm): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n",
       "      )\n",
       "      (5): Sequential(\n",
       "        (0): SwinTransformerBlockV2(\n",
       "          (norm1): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n",
       "          (attn): ShiftedWindowAttentionV2(\n",
       "            (qkv): Linear(in_features=384, out_features=1152, bias=True)\n",
       "            (proj): Linear(in_features=384, out_features=384, bias=True)\n",
       "            (cpb_mlp): Sequential(\n",
       "              (0): Linear(in_features=2, out_features=512, bias=True)\n",
       "              (1): ReLU(inplace=True)\n",
       "              (2): Linear(in_features=512, out_features=12, bias=False)\n",
       "            )\n",
       "          )\n",
       "          (stochastic_depth): StochasticDepth(p=0.07272727272727274, mode=row)\n",
       "          (norm2): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n",
       "          (mlp): MLP(\n",
       "            (0): Linear(in_features=384, out_features=1536, bias=True)\n",
       "            (1): GELU(approximate='none')\n",
       "            (2): Dropout(p=0.0, inplace=False)\n",
       "            (3): Linear(in_features=1536, out_features=384, bias=True)\n",
       "            (4): Dropout(p=0.0, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (1): SwinTransformerBlockV2(\n",
       "          (norm1): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n",
       "          (attn): ShiftedWindowAttentionV2(\n",
       "            (qkv): Linear(in_features=384, out_features=1152, bias=True)\n",
       "            (proj): Linear(in_features=384, out_features=384, bias=True)\n",
       "            (cpb_mlp): Sequential(\n",
       "              (0): Linear(in_features=2, out_features=512, bias=True)\n",
       "              (1): ReLU(inplace=True)\n",
       "              (2): Linear(in_features=512, out_features=12, bias=False)\n",
       "            )\n",
       "          )\n",
       "          (stochastic_depth): StochasticDepth(p=0.09090909090909091, mode=row)\n",
       "          (norm2): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n",
       "          (mlp): MLP(\n",
       "            (0): Linear(in_features=384, out_features=1536, bias=True)\n",
       "            (1): GELU(approximate='none')\n",
       "            (2): Dropout(p=0.0, inplace=False)\n",
       "            (3): Linear(in_features=1536, out_features=384, bias=True)\n",
       "            (4): Dropout(p=0.0, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (2): SwinTransformerBlockV2(\n",
       "          (norm1): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n",
       "          (attn): ShiftedWindowAttentionV2(\n",
       "            (qkv): Linear(in_features=384, out_features=1152, bias=True)\n",
       "            (proj): Linear(in_features=384, out_features=384, bias=True)\n",
       "            (cpb_mlp): Sequential(\n",
       "              (0): Linear(in_features=2, out_features=512, bias=True)\n",
       "              (1): ReLU(inplace=True)\n",
       "              (2): Linear(in_features=512, out_features=12, bias=False)\n",
       "            )\n",
       "          )\n",
       "          (stochastic_depth): StochasticDepth(p=0.10909090909090911, mode=row)\n",
       "          (norm2): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n",
       "          (mlp): MLP(\n",
       "            (0): Linear(in_features=384, out_features=1536, bias=True)\n",
       "            (1): GELU(approximate='none')\n",
       "            (2): Dropout(p=0.0, inplace=False)\n",
       "            (3): Linear(in_features=1536, out_features=384, bias=True)\n",
       "            (4): Dropout(p=0.0, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (3): SwinTransformerBlockV2(\n",
       "          (norm1): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n",
       "          (attn): ShiftedWindowAttentionV2(\n",
       "            (qkv): Linear(in_features=384, out_features=1152, bias=True)\n",
       "            (proj): Linear(in_features=384, out_features=384, bias=True)\n",
       "            (cpb_mlp): Sequential(\n",
       "              (0): Linear(in_features=2, out_features=512, bias=True)\n",
       "              (1): ReLU(inplace=True)\n",
       "              (2): Linear(in_features=512, out_features=12, bias=False)\n",
       "            )\n",
       "          )\n",
       "          (stochastic_depth): StochasticDepth(p=0.1272727272727273, mode=row)\n",
       "          (norm2): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n",
       "          (mlp): MLP(\n",
       "            (0): Linear(in_features=384, out_features=1536, bias=True)\n",
       "            (1): GELU(approximate='none')\n",
       "            (2): Dropout(p=0.0, inplace=False)\n",
       "            (3): Linear(in_features=1536, out_features=384, bias=True)\n",
       "            (4): Dropout(p=0.0, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (4): SwinTransformerBlockV2(\n",
       "          (norm1): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n",
       "          (attn): ShiftedWindowAttentionV2(\n",
       "            (qkv): Linear(in_features=384, out_features=1152, bias=True)\n",
       "            (proj): Linear(in_features=384, out_features=384, bias=True)\n",
       "            (cpb_mlp): Sequential(\n",
       "              (0): Linear(in_features=2, out_features=512, bias=True)\n",
       "              (1): ReLU(inplace=True)\n",
       "              (2): Linear(in_features=512, out_features=12, bias=False)\n",
       "            )\n",
       "          )\n",
       "          (stochastic_depth): StochasticDepth(p=0.14545454545454548, mode=row)\n",
       "          (norm2): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n",
       "          (mlp): MLP(\n",
       "            (0): Linear(in_features=384, out_features=1536, bias=True)\n",
       "            (1): GELU(approximate='none')\n",
       "            (2): Dropout(p=0.0, inplace=False)\n",
       "            (3): Linear(in_features=1536, out_features=384, bias=True)\n",
       "            (4): Dropout(p=0.0, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (5): SwinTransformerBlockV2(\n",
       "          (norm1): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n",
       "          (attn): ShiftedWindowAttentionV2(\n",
       "            (qkv): Linear(in_features=384, out_features=1152, bias=True)\n",
       "            (proj): Linear(in_features=384, out_features=384, bias=True)\n",
       "            (cpb_mlp): Sequential(\n",
       "              (0): Linear(in_features=2, out_features=512, bias=True)\n",
       "              (1): ReLU(inplace=True)\n",
       "              (2): Linear(in_features=512, out_features=12, bias=False)\n",
       "            )\n",
       "          )\n",
       "          (stochastic_depth): StochasticDepth(p=0.16363636363636364, mode=row)\n",
       "          (norm2): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n",
       "          (mlp): MLP(\n",
       "            (0): Linear(in_features=384, out_features=1536, bias=True)\n",
       "            (1): GELU(approximate='none')\n",
       "            (2): Dropout(p=0.0, inplace=False)\n",
       "            (3): Linear(in_features=1536, out_features=384, bias=True)\n",
       "            (4): Dropout(p=0.0, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (6): PatchMergingV2(\n",
       "        (reduction): Linear(in_features=1536, out_features=768, bias=False)\n",
       "        (norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "      )\n",
       "      (7): Sequential(\n",
       "        (0): SwinTransformerBlockV2(\n",
       "          (norm1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "          (attn): ShiftedWindowAttentionV2(\n",
       "            (qkv): Linear(in_features=768, out_features=2304, bias=True)\n",
       "            (proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (cpb_mlp): Sequential(\n",
       "              (0): Linear(in_features=2, out_features=512, bias=True)\n",
       "              (1): ReLU(inplace=True)\n",
       "              (2): Linear(in_features=512, out_features=24, bias=False)\n",
       "            )\n",
       "          )\n",
       "          (stochastic_depth): StochasticDepth(p=0.18181818181818182, mode=row)\n",
       "          (norm2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "          (mlp): MLP(\n",
       "            (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (1): GELU(approximate='none')\n",
       "            (2): Dropout(p=0.0, inplace=False)\n",
       "            (3): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (4): Dropout(p=0.0, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (1): SwinTransformerBlockV2(\n",
       "          (norm1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "          (attn): ShiftedWindowAttentionV2(\n",
       "            (qkv): Linear(in_features=768, out_features=2304, bias=True)\n",
       "            (proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (cpb_mlp): Sequential(\n",
       "              (0): Linear(in_features=2, out_features=512, bias=True)\n",
       "              (1): ReLU(inplace=True)\n",
       "              (2): Linear(in_features=512, out_features=24, bias=False)\n",
       "            )\n",
       "          )\n",
       "          (stochastic_depth): StochasticDepth(p=0.2, mode=row)\n",
       "          (norm2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "          (mlp): MLP(\n",
       "            (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (1): GELU(approximate='none')\n",
       "            (2): Dropout(p=0.0, inplace=False)\n",
       "            (3): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (4): Dropout(p=0.0, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "    (2): Permute()\n",
       "  )\n",
       "  (head): Sequential(\n",
       "    (0): Conv2d(768, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "    (1): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU(inplace=True)\n",
       "    (3): Conv2d(1024, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "    (4): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (5): ReLU(inplace=True)\n",
       "    (6): Conv2d(1024, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "    (7): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (8): ReLU(inplace=True)\n",
       "    (9): Conv2d(1024, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "    (10): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (11): ReLU(inplace=True)\n",
       "    (12): Conv2d(1024, 12, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "    (13): AdaptiveAvgPool2d(output_size=(7, 7))\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "NUM_CLASSES = 2\n",
    "model = YOLO_SWIN(num_classes=NUM_CLASSES)\n",
    "model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "361cde55",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------------------------------\n",
      "        Layer (type)               Output Shape         Param #\n",
      "================================================================\n",
      "            Conv2d-1         [-1, 96, 112, 112]           4,704\n",
      "           Permute-2         [-1, 112, 112, 96]               0\n",
      "         LayerNorm-3         [-1, 112, 112, 96]             192\n",
      "            Linear-4          [-1, 15, 15, 512]           1,536\n",
      "              ReLU-5          [-1, 15, 15, 512]               0\n",
      "            Linear-6            [-1, 15, 15, 3]           1,536\n",
      "ShiftedWindowAttentionV2-7         [-1, 112, 112, 96]               0\n",
      "         LayerNorm-8         [-1, 112, 112, 96]             192\n",
      "   StochasticDepth-9         [-1, 112, 112, 96]               0\n",
      "           Linear-10        [-1, 112, 112, 384]          37,248\n",
      "             GELU-11        [-1, 112, 112, 384]               0\n",
      "          Dropout-12        [-1, 112, 112, 384]               0\n",
      "           Linear-13         [-1, 112, 112, 96]          36,960\n",
      "          Dropout-14         [-1, 112, 112, 96]               0\n",
      "        LayerNorm-15         [-1, 112, 112, 96]             192\n",
      "  StochasticDepth-16         [-1, 112, 112, 96]               0\n",
      "SwinTransformerBlockV2-17         [-1, 112, 112, 96]               0\n",
      "           Linear-18          [-1, 15, 15, 512]           1,536\n",
      "             ReLU-19          [-1, 15, 15, 512]               0\n",
      "           Linear-20            [-1, 15, 15, 3]           1,536\n",
      "ShiftedWindowAttentionV2-21         [-1, 112, 112, 96]               0\n",
      "        LayerNorm-22         [-1, 112, 112, 96]             192\n",
      "  StochasticDepth-23         [-1, 112, 112, 96]               0\n",
      "           Linear-24        [-1, 112, 112, 384]          37,248\n",
      "             GELU-25        [-1, 112, 112, 384]               0\n",
      "          Dropout-26        [-1, 112, 112, 384]               0\n",
      "           Linear-27         [-1, 112, 112, 96]          36,960\n",
      "          Dropout-28         [-1, 112, 112, 96]               0\n",
      "        LayerNorm-29         [-1, 112, 112, 96]             192\n",
      "  StochasticDepth-30         [-1, 112, 112, 96]               0\n",
      "SwinTransformerBlockV2-31         [-1, 112, 112, 96]               0\n",
      "           Linear-32          [-1, 56, 56, 192]          73,728\n",
      "        LayerNorm-33          [-1, 56, 56, 192]             384\n",
      "   PatchMergingV2-34          [-1, 56, 56, 192]               0\n",
      "           Linear-35          [-1, 15, 15, 512]           1,536\n",
      "             ReLU-36          [-1, 15, 15, 512]               0\n",
      "           Linear-37            [-1, 15, 15, 6]           3,072\n",
      "ShiftedWindowAttentionV2-38          [-1, 56, 56, 192]               0\n",
      "        LayerNorm-39          [-1, 56, 56, 192]             384\n",
      "  StochasticDepth-40          [-1, 56, 56, 192]               0\n",
      "           Linear-41          [-1, 56, 56, 768]         148,224\n",
      "             GELU-42          [-1, 56, 56, 768]               0\n",
      "          Dropout-43          [-1, 56, 56, 768]               0\n",
      "           Linear-44          [-1, 56, 56, 192]         147,648\n",
      "          Dropout-45          [-1, 56, 56, 192]               0\n",
      "        LayerNorm-46          [-1, 56, 56, 192]             384\n",
      "  StochasticDepth-47          [-1, 56, 56, 192]               0\n",
      "SwinTransformerBlockV2-48          [-1, 56, 56, 192]               0\n",
      "           Linear-49          [-1, 15, 15, 512]           1,536\n",
      "             ReLU-50          [-1, 15, 15, 512]               0\n",
      "           Linear-51            [-1, 15, 15, 6]           3,072\n",
      "ShiftedWindowAttentionV2-52          [-1, 56, 56, 192]               0\n",
      "        LayerNorm-53          [-1, 56, 56, 192]             384\n",
      "  StochasticDepth-54          [-1, 56, 56, 192]               0\n",
      "           Linear-55          [-1, 56, 56, 768]         148,224\n",
      "             GELU-56          [-1, 56, 56, 768]               0\n",
      "          Dropout-57          [-1, 56, 56, 768]               0\n",
      "           Linear-58          [-1, 56, 56, 192]         147,648\n",
      "          Dropout-59          [-1, 56, 56, 192]               0\n",
      "        LayerNorm-60          [-1, 56, 56, 192]             384\n",
      "  StochasticDepth-61          [-1, 56, 56, 192]               0\n",
      "SwinTransformerBlockV2-62          [-1, 56, 56, 192]               0\n",
      "           Linear-63          [-1, 28, 28, 384]         294,912\n",
      "        LayerNorm-64          [-1, 28, 28, 384]             768\n",
      "   PatchMergingV2-65          [-1, 28, 28, 384]               0\n",
      "           Linear-66          [-1, 15, 15, 512]           1,536\n",
      "             ReLU-67          [-1, 15, 15, 512]               0\n",
      "           Linear-68           [-1, 15, 15, 12]           6,144\n",
      "ShiftedWindowAttentionV2-69          [-1, 28, 28, 384]               0\n",
      "        LayerNorm-70          [-1, 28, 28, 384]             768\n",
      "  StochasticDepth-71          [-1, 28, 28, 384]               0\n",
      "           Linear-72         [-1, 28, 28, 1536]         591,360\n",
      "             GELU-73         [-1, 28, 28, 1536]               0\n",
      "          Dropout-74         [-1, 28, 28, 1536]               0\n",
      "           Linear-75          [-1, 28, 28, 384]         590,208\n",
      "          Dropout-76          [-1, 28, 28, 384]               0\n",
      "        LayerNorm-77          [-1, 28, 28, 384]             768\n",
      "  StochasticDepth-78          [-1, 28, 28, 384]               0\n",
      "SwinTransformerBlockV2-79          [-1, 28, 28, 384]               0\n",
      "           Linear-80          [-1, 15, 15, 512]           1,536\n",
      "             ReLU-81          [-1, 15, 15, 512]               0\n",
      "           Linear-82           [-1, 15, 15, 12]           6,144\n",
      "ShiftedWindowAttentionV2-83          [-1, 28, 28, 384]               0\n",
      "        LayerNorm-84          [-1, 28, 28, 384]             768\n",
      "  StochasticDepth-85          [-1, 28, 28, 384]               0\n",
      "           Linear-86         [-1, 28, 28, 1536]         591,360\n",
      "             GELU-87         [-1, 28, 28, 1536]               0\n",
      "          Dropout-88         [-1, 28, 28, 1536]               0\n",
      "           Linear-89          [-1, 28, 28, 384]         590,208\n",
      "          Dropout-90          [-1, 28, 28, 384]               0\n",
      "        LayerNorm-91          [-1, 28, 28, 384]             768\n",
      "  StochasticDepth-92          [-1, 28, 28, 384]               0\n",
      "SwinTransformerBlockV2-93          [-1, 28, 28, 384]               0\n",
      "           Linear-94          [-1, 15, 15, 512]           1,536\n",
      "             ReLU-95          [-1, 15, 15, 512]               0\n",
      "           Linear-96           [-1, 15, 15, 12]           6,144\n",
      "ShiftedWindowAttentionV2-97          [-1, 28, 28, 384]               0\n",
      "        LayerNorm-98          [-1, 28, 28, 384]             768\n",
      "  StochasticDepth-99          [-1, 28, 28, 384]               0\n",
      "          Linear-100         [-1, 28, 28, 1536]         591,360\n",
      "            GELU-101         [-1, 28, 28, 1536]               0\n",
      "         Dropout-102         [-1, 28, 28, 1536]               0\n",
      "          Linear-103          [-1, 28, 28, 384]         590,208\n",
      "         Dropout-104          [-1, 28, 28, 384]               0\n",
      "       LayerNorm-105          [-1, 28, 28, 384]             768\n",
      " StochasticDepth-106          [-1, 28, 28, 384]               0\n",
      "SwinTransformerBlockV2-107          [-1, 28, 28, 384]               0\n",
      "          Linear-108          [-1, 15, 15, 512]           1,536\n",
      "            ReLU-109          [-1, 15, 15, 512]               0\n",
      "          Linear-110           [-1, 15, 15, 12]           6,144\n",
      "ShiftedWindowAttentionV2-111          [-1, 28, 28, 384]               0\n",
      "       LayerNorm-112          [-1, 28, 28, 384]             768\n",
      " StochasticDepth-113          [-1, 28, 28, 384]               0\n",
      "          Linear-114         [-1, 28, 28, 1536]         591,360\n",
      "            GELU-115         [-1, 28, 28, 1536]               0\n",
      "         Dropout-116         [-1, 28, 28, 1536]               0\n",
      "          Linear-117          [-1, 28, 28, 384]         590,208\n",
      "         Dropout-118          [-1, 28, 28, 384]               0\n",
      "       LayerNorm-119          [-1, 28, 28, 384]             768\n",
      " StochasticDepth-120          [-1, 28, 28, 384]               0\n",
      "SwinTransformerBlockV2-121          [-1, 28, 28, 384]               0\n",
      "          Linear-122          [-1, 15, 15, 512]           1,536\n",
      "            ReLU-123          [-1, 15, 15, 512]               0\n",
      "          Linear-124           [-1, 15, 15, 12]           6,144\n",
      "ShiftedWindowAttentionV2-125          [-1, 28, 28, 384]               0\n",
      "       LayerNorm-126          [-1, 28, 28, 384]             768\n",
      " StochasticDepth-127          [-1, 28, 28, 384]               0\n",
      "          Linear-128         [-1, 28, 28, 1536]         591,360\n",
      "            GELU-129         [-1, 28, 28, 1536]               0\n",
      "         Dropout-130         [-1, 28, 28, 1536]               0\n",
      "          Linear-131          [-1, 28, 28, 384]         590,208\n",
      "         Dropout-132          [-1, 28, 28, 384]               0\n",
      "       LayerNorm-133          [-1, 28, 28, 384]             768\n",
      " StochasticDepth-134          [-1, 28, 28, 384]               0\n",
      "SwinTransformerBlockV2-135          [-1, 28, 28, 384]               0\n",
      "          Linear-136          [-1, 15, 15, 512]           1,536\n",
      "            ReLU-137          [-1, 15, 15, 512]               0\n",
      "          Linear-138           [-1, 15, 15, 12]           6,144\n",
      "ShiftedWindowAttentionV2-139          [-1, 28, 28, 384]               0\n",
      "       LayerNorm-140          [-1, 28, 28, 384]             768\n",
      " StochasticDepth-141          [-1, 28, 28, 384]               0\n",
      "          Linear-142         [-1, 28, 28, 1536]         591,360\n",
      "            GELU-143         [-1, 28, 28, 1536]               0\n",
      "         Dropout-144         [-1, 28, 28, 1536]               0\n",
      "          Linear-145          [-1, 28, 28, 384]         590,208\n",
      "         Dropout-146          [-1, 28, 28, 384]               0\n",
      "       LayerNorm-147          [-1, 28, 28, 384]             768\n",
      " StochasticDepth-148          [-1, 28, 28, 384]               0\n",
      "SwinTransformerBlockV2-149          [-1, 28, 28, 384]               0\n",
      "          Linear-150          [-1, 14, 14, 768]       1,179,648\n",
      "       LayerNorm-151          [-1, 14, 14, 768]           1,536\n",
      "  PatchMergingV2-152          [-1, 14, 14, 768]               0\n",
      "          Linear-153          [-1, 15, 15, 512]           1,536\n",
      "            ReLU-154          [-1, 15, 15, 512]               0\n",
      "          Linear-155           [-1, 15, 15, 24]          12,288\n",
      "ShiftedWindowAttentionV2-156          [-1, 14, 14, 768]               0\n",
      "       LayerNorm-157          [-1, 14, 14, 768]           1,536\n",
      " StochasticDepth-158          [-1, 14, 14, 768]               0\n",
      "          Linear-159         [-1, 14, 14, 3072]       2,362,368\n",
      "            GELU-160         [-1, 14, 14, 3072]               0\n",
      "         Dropout-161         [-1, 14, 14, 3072]               0\n",
      "          Linear-162          [-1, 14, 14, 768]       2,360,064\n",
      "         Dropout-163          [-1, 14, 14, 768]               0\n",
      "       LayerNorm-164          [-1, 14, 14, 768]           1,536\n",
      " StochasticDepth-165          [-1, 14, 14, 768]               0\n",
      "SwinTransformerBlockV2-166          [-1, 14, 14, 768]               0\n",
      "          Linear-167          [-1, 15, 15, 512]           1,536\n",
      "            ReLU-168          [-1, 15, 15, 512]               0\n",
      "          Linear-169           [-1, 15, 15, 24]          12,288\n",
      "ShiftedWindowAttentionV2-170          [-1, 14, 14, 768]               0\n",
      "       LayerNorm-171          [-1, 14, 14, 768]           1,536\n",
      " StochasticDepth-172          [-1, 14, 14, 768]               0\n",
      "          Linear-173         [-1, 14, 14, 3072]       2,362,368\n",
      "            GELU-174         [-1, 14, 14, 3072]               0\n",
      "         Dropout-175         [-1, 14, 14, 3072]               0\n",
      "          Linear-176          [-1, 14, 14, 768]       2,360,064\n",
      "         Dropout-177          [-1, 14, 14, 768]               0\n",
      "       LayerNorm-178          [-1, 14, 14, 768]           1,536\n",
      " StochasticDepth-179          [-1, 14, 14, 768]               0\n",
      "SwinTransformerBlockV2-180          [-1, 14, 14, 768]               0\n",
      "       LayerNorm-181          [-1, 14, 14, 768]           1,536\n",
      "         Permute-182          [-1, 768, 14, 14]               0\n",
      "          Conv2d-183         [-1, 1024, 14, 14]         786,432\n",
      "     BatchNorm2d-184         [-1, 1024, 14, 14]           2,048\n",
      "            ReLU-185         [-1, 1024, 14, 14]               0\n",
      "          Conv2d-186         [-1, 1024, 14, 14]       9,437,184\n",
      "     BatchNorm2d-187         [-1, 1024, 14, 14]           2,048\n",
      "            ReLU-188         [-1, 1024, 14, 14]               0\n",
      "          Conv2d-189         [-1, 1024, 14, 14]       9,437,184\n",
      "     BatchNorm2d-190         [-1, 1024, 14, 14]           2,048\n",
      "            ReLU-191         [-1, 1024, 14, 14]               0\n",
      "          Conv2d-192         [-1, 1024, 14, 14]       9,437,184\n",
      "     BatchNorm2d-193         [-1, 1024, 14, 14]           2,048\n",
      "            ReLU-194         [-1, 1024, 14, 14]               0\n",
      "          Conv2d-195           [-1, 12, 14, 14]          12,288\n",
      "AdaptiveAvgPool2d-196             [-1, 12, 7, 7]               0\n",
      "================================================================\n",
      "Total params: 48,057,056\n",
      "Trainable params: 48,057,056\n",
      "Non-trainable params: 0\n",
      "----------------------------------------------------------------\n",
      "Input size (MB): 2.30\n",
      "Forward/backward pass size (MB): 966.52\n",
      "Params size (MB): 183.32\n",
      "Estimated Total Size (MB): 1152.14\n",
      "----------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "torchsummary.summary(model, (3,448,448))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "4cf3af4c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 12, 7, 7])\n"
     ]
    }
   ],
   "source": [
    "x = torch.randn(1, 3, 448, 448).to(device)\n",
    "with torch.no_grad():\n",
    "    y = model(x)\n",
    "print(y.shape)"
   ]
  },
  {
   "cell_type": "raw",
   "id": "f4c05720",
   "metadata": {
    "scrolled": true
   },
   "source": [
    "# data_dir = \"/content/drive/MyDrive/fastCamMedicalProj/DATASET/DATASET/Detection/\"\n",
    "BATCH_SIZE = 1\n",
    "\n",
    "# trainset = Detection_dataset(data_dir=data_dir, phase=\"train\", transformer=transformer)\n",
    "NECK_PATH = '/home/host_data/PET_data/Neck'\n",
    "BODY_PATH = '/home/host_data/PET_data/Body'\n",
    "trainset=PET_dataset(part='body',neck_dir=NECK_PATH,body_dir=BODY_PATH,phase='train', transformer=transformer)\n",
    "trainloader = DataLoader(trainset, batch_size=BATCH_SIZE, shuffle=False, collate_fn=collate_fn)\n",
    "\n",
    "model = YOLO_SWIN(num_classes=NUM_CLASSES)\n",
    "\n",
    "for index, batch in enumerate(trainloader):\n",
    "    images = batch[0]\n",
    "    targets = batch[1]\n",
    "    filenames = batch[2]\n",
    "    \n",
    "    predictions = model(images)\n",
    "    print(f\"filename:{filenames}, target:{targets}\")\n",
    "#     print(f\"{index}--input shape:{images.shape} -> output shape: {predictions.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8da970d7",
   "metadata": {},
   "source": [
    "# Loss func"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "3c66945c",
   "metadata": {},
   "outputs": [],
   "source": [
    "class YOLO_LOSS():\n",
    "    def __init__(self, num_classes, device, lambda_coord=5., lambda_noobj=0.5):\n",
    "        self.num_classes = num_classes\n",
    "        self.device = device\n",
    "        self.grid_size = 7\n",
    "        self.lambda_coord = lambda_coord\n",
    "        self.lambda_noobj = lambda_noobj\n",
    "        self.mse_loss = nn.MSELoss(reduction=\"sum\")\n",
    "\n",
    "    def __call__(self, predictions, targets):\n",
    "        self.batch_size, _, _, _ = predictions.shape\n",
    "        groundtruths = self.build_batch_target_grid(targets)\n",
    "        groundtruths = groundtruths.to(self.device)\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            iou1 = self.get_IoU(predictions[:, 1:5, ...], groundtruths[:, 1:5, ...])\n",
    "            iou2 = self.get_IoU(predictions[:, 6:10, ...], groundtruths[:, 1:5, ...])\n",
    "\n",
    "        ious = torch.stack([iou1, iou2], dim=1)\n",
    "        max_iou, best_box = ious.max(dim=1, keepdim=True)\n",
    "        max_iou = torch.cat([max_iou, max_iou], dim=1)\n",
    "        best_box = torch.cat([best_box.eq(0), best_box.eq(1)], dim=1)\n",
    "\n",
    "        predictions_ = predictions[:, :5*2, ...].reshape(self.batch_size, 2, 5, self.grid_size, self.grid_size)\n",
    "        obj_pred = predictions_[:, :, 0, ...]\n",
    "        xy_pred = predictions_[:, :, 1:3, ...]\n",
    "        wh_pred = predictions_[:, :, 3:5, ...]\n",
    "        cls_pred = predictions[:, 5*2:, ...]\n",
    "\n",
    "        groundtruths_ = groundtruths[:, :5, ...].reshape(self.batch_size, 1, 5, self.grid_size, self.grid_size)\n",
    "        obj_target = groundtruths_[:, :, 0, ...]\n",
    "        xy_target = groundtruths_[:, :, 1:3, ...]\n",
    "        wh_target= groundtruths_[:, :, 3:5, ...]\n",
    "        cls_target = groundtruths[:, 5:, ...]\n",
    "        \n",
    "        positive = obj_target * best_box\n",
    "\n",
    "        obj_loss = self.mse_loss(positive * obj_pred, positive * ious)\n",
    "        noobj_loss = self.mse_loss((1 - positive) * obj_pred, ious*0)\n",
    "        xy_loss = self.mse_loss(positive.unsqueeze(dim=2) * xy_pred, positive.unsqueeze(dim=2) * xy_target)\n",
    "        wh_loss = self.mse_loss(positive.unsqueeze(dim=2) * (wh_pred.sign() * (wh_pred.abs() + 1e-8).sqrt()),\n",
    "                           positive.unsqueeze(dim=2) * (wh_target + 1e-8).sqrt())\n",
    "        cls_loss = self.mse_loss(obj_target * cls_pred, cls_target)\n",
    "        \n",
    "        obj_loss /= self.batch_size\n",
    "        noobj_loss /= self.batch_size\n",
    "        bbox_loss = (xy_loss+wh_loss) / self.batch_size\n",
    "        cls_loss /= self.batch_size\n",
    "        \n",
    "        total_loss = obj_loss + self.lambda_noobj*noobj_loss + self.lambda_coord*bbox_loss + cls_loss\n",
    "        return total_loss, (obj_loss.item(), noobj_loss.item(), bbox_loss.item(), cls_loss.item())\n",
    "    \n",
    "    def build_target_grid(self, target):\n",
    "        target_grid = torch.zeros((1+4+self.num_classes, self.grid_size, self.grid_size), device=self.device)\n",
    "\n",
    "        for gt in target:\n",
    "            xc, yc, w, h, cls_id = gt\n",
    "            xn = (xc % (1/self.grid_size))\n",
    "            yn = (yc % (1/self.grid_size))\n",
    "            cls_id = int(cls_id)\n",
    "\n",
    "            i_grid = int(xc * self.grid_size)\n",
    "            j_grid = int(yc * self.grid_size)\n",
    "            target_grid[0, j_grid, i_grid] = 1\n",
    "            target_grid[1:5, j_grid, i_grid] = torch.Tensor([xn,yn,w,h])\n",
    "#             print(5+cls_id, j_grid, i_grid)\n",
    "            target_grid[5+cls_id, j_grid, i_grid] = 1\n",
    "\n",
    "        return target_grid\n",
    "    \n",
    "    def build_batch_target_grid(self, targets):\n",
    "        target_grid_batch = torch.stack([self.build_target_grid(target) for target in targets], dim=0)\n",
    "        return target_grid_batch\n",
    "    \n",
    "    def get_IoU(self, cbox1, cbox2):\n",
    "        box1 = self.xywh_to_xyxy(cbox1)\n",
    "        box2 = self.xywh_to_xyxy(cbox2)\n",
    "\n",
    "        x1 = torch.max(box1[:, 0, ...], box2[:, 0, ...])\n",
    "        y1 = torch.max(box1[:, 1, ...], box2[:, 1, ...])\n",
    "        x2 = torch.min(box1[:, 2, ...], box2[:, 2, ...])\n",
    "        y2 = torch.min(box1[:, 3, ...], box2[:, 3, ...])\n",
    "\n",
    "        intersection = (x2-x1).clamp(min=0) * (y2-y1).clamp(min=0)\n",
    "        union = abs(cbox1[:, 2, ...]*cbox1[:, 3, ...]) + \\\n",
    "                abs(cbox2[:, 2, ...]*cbox2[:, 3, ...]) - intersection\n",
    "\n",
    "        intersection[intersection.gt(0)] = intersection[intersection.gt(0)] / union[intersection.gt(0)]\n",
    "        return intersection\n",
    "    \n",
    "    def generate_xy_normed_grid(self):\n",
    "        y_offset, x_offset = torch.meshgrid(torch.arange(self.grid_size), torch.arange(self.grid_size))\n",
    "        xy_grid = torch.stack([x_offset, y_offset], dim=0)\n",
    "        xy_normed_grid = xy_grid / self.grid_size\n",
    "        return xy_normed_grid.to(self.device)\n",
    "\n",
    "    def xywh_to_xyxy(self, bboxes):\n",
    "        xy_normed_grid = self.generate_xy_normed_grid()\n",
    "        xcyc = bboxes[:,0:2,...] + xy_normed_grid.tile(self.batch_size, 1,1,1)\n",
    "        wh = bboxes[:,2:4,...]\n",
    "        x1y1 = xcyc - (wh/2)\n",
    "        x2y2 = xcyc + (wh/2)\n",
    "        return torch.cat([x1y1, x2y2], dim=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c46ad931",
   "metadata": {},
   "source": [
    "# Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "b1729df2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_one_epoch(dataloaders, model, criterion, optimizer, device):\n",
    "    train_loss = defaultdict(float)\n",
    "    val_loss = defaultdict(float)\n",
    "    \n",
    "    for phase in [\"train\", \"val\"]:\n",
    "        if phase == \"train\":\n",
    "            model.train()\n",
    "        else:\n",
    "            model.eval()\n",
    "        \n",
    "        running_loss = defaultdict(float)\n",
    "        for index, batch in enumerate(dataloaders[phase]):\n",
    "            images = batch[0].to(device)\n",
    "            targets = batch[1]\n",
    "            filenames = batch[2]\n",
    "            \n",
    "            with torch.set_grad_enabled(phase == \"train\"): # phase가 train 일때만 gradient 추적기능을 킨다.\n",
    "                predictions = model(images) #prediction shape=> B,12,7,7\n",
    "#             print(f\"predictions:{predictions}, \\ntargets: {targets}\\n\")\n",
    "            loss, (obj_loss, noobj_loss, bbox_loss, cls_loss) = criterion(predictions, targets)\n",
    "#             print(f\"loss:{loss}, obj_loss:{obj_loss}, noobj_loss:{noobj_loss}\\nbbox_loss:{bbox_loss}, cls_loss:{cls_loss}\\n--------------\\n\")\n",
    "            if phase == \"train\":\n",
    "                optimizer.zero_grad()\n",
    "                loss.backward()\n",
    "                optimizer.step()\n",
    "                \n",
    "                # 현재 epoch단계에서 loss가 얼마인지 running loss 가출력\n",
    "                running_loss[\"total_loss\"] += loss.item()\n",
    "                running_loss[\"obj_loss\"] += obj_loss\n",
    "                running_loss[\"noobj_loss\"] += noobj_loss\n",
    "                running_loss[\"bbox_loss\"] += bbox_loss\n",
    "                running_loss[\"cls_loss\"] += cls_loss\n",
    "                \n",
    "                train_loss[\"total_loss\"] += loss.item()\n",
    "                train_loss[\"obj_loss\"] += obj_loss\n",
    "                train_loss[\"noobj_loss\"] += noobj_loss\n",
    "                train_loss[\"bbox_loss\"] += bbox_loss\n",
    "                train_loss[\"cls_loss\"] += cls_loss\n",
    "                \n",
    "                if (index > 0) and (index % VERBOSE_FREQ) == 0:\n",
    "                    text = f\"<<<iteration:[{index}/{len(dataloaders[phase])}] - \"\n",
    "                    for k, v in running_loss.items():\n",
    "                        text += f\"{k}: {v/VERBOSE_FREQ:.4f}  \"\n",
    "                        running_loss[k] = 0.\n",
    "                    print(text)\n",
    "            else:\n",
    "                val_loss[\"total_loss\"] += loss.item()\n",
    "                val_loss[\"obj_loss\"] += obj_loss\n",
    "                val_loss[\"noobj_loss\"] += noobj_loss\n",
    "                val_loss[\"bbox_loss\"] += bbox_loss\n",
    "                val_loss[\"cls_loss\"] += cls_loss\n",
    "\n",
    "    for k in train_loss.keys():\n",
    "        train_loss[k] /= len(dataloaders[\"train\"])\n",
    "        val_loss[k] /= len(dataloaders[\"val\"])\n",
    "    return train_loss, val_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "cc20c145",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_dataloader(part, NECK_PATH, BODY_PATH, batch_size=2, aug_factor=0):\n",
    "    IMAGE_SIZE = 448\n",
    "    transformer = A.Compose([\n",
    "            A.Resize(height=IMAGE_SIZE, width=IMAGE_SIZE),\n",
    "            A.Normalize(mean=(0.485, 0.456, 0.406),std=(0.229, 0.224, 0.225)),\n",
    "            ToTensorV2(),\n",
    "        ],\n",
    "        bbox_params=A.BboxParams(format='yolo', label_fields=['class_ids']),\n",
    "    )\n",
    "    augmentator=A.Compose([\n",
    "    #     A.Resize(height=IMAGE_SIZE, width=IMAGE_SIZE),\n",
    "        A.HorizontalFlip(p=0.7),\n",
    "    #     A.Sharpen(p=0.7),\n",
    "        A.BBoxSafeRandomCrop(p=0.6),\n",
    "        A.VerticalFlip (p=0.6),\n",
    "        A.HueSaturationValue(p=0.6),\n",
    "        A.Resize(height=IMAGE_SIZE, width=IMAGE_SIZE),\n",
    "        A.Normalize(mean=(0.485, 0.456, 0.406),std=(0.229, 0.224, 0.225)),\n",
    "        ToTensorV2(),\n",
    "        ],\n",
    "        bbox_params=A.BboxParams(format='yolo', label_fields=['class_ids']),\n",
    "    )\n",
    "    \n",
    "    dataloaders = {}\n",
    "#     train_dataset = Detection_dataset(data_dir=data_dir, phase=\"train\", transformer=transformer)\n",
    "    train_dataset=PET_dataset(part ,neck_dir=NECK_PATH,body_dir=BODY_PATH,phase='train', transformer=transformer, aug=augmentator, aug_factor=aug_factor)\n",
    "    dataloaders[\"train\"] = DataLoader(train_dataset, batch_size=batch_size, shuffle=True, collate_fn=collate_fn)\n",
    "\n",
    "#     val_dataset = Detection_dataset(data_dir=data_dir, phase=\"val\", transformer=transformer)\n",
    "    val_dataset=PET_dataset(part ,neck_dir=NECK_PATH,body_dir=BODY_PATH,phase='valid', transformer=transformer, aug=augmentator, aug_factor=aug_factor)\n",
    "    dataloaders[\"val\"] = DataLoader(val_dataset, batch_size=batch_size, shuffle=False, collate_fn=collate_fn)\n",
    "    return dataloaders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "2771b438",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "start making augmented images-- augmented factor:20\n",
      "total length of augmented images: 4200\n",
      "start making augmented images-- augmented factor:20\n",
      "total length of augmented images: 720\n"
     ]
    }
   ],
   "source": [
    "# data_dir = \"/content/drive/MyDrive/fastCamMedicalProj/DATASET/DATASET/Detection/\"\n",
    "NECK_PATH = '/home/host_data/PET_data/Neck'\n",
    "BODY_PATH = '/home/host_data/PET_data/Body'\n",
    "is_cuda = True\n",
    "\n",
    "NUM_CLASSES = 2\n",
    "IMAGE_SIZE = 448\n",
    "BATCH_SIZE = 8\n",
    "VERBOSE_FREQ = 20\n",
    "LR=0.0001\n",
    "AUG_FACTOR=20\n",
    "BACKBONE=\"YOLO_SWIN_T\"\n",
    "PART=\"neck\"\n",
    "num_epochs = 100\n",
    "# DEVICE = torch.device('cuda' if torch.cuda.is_available and is_cuda else 'cpu')\n",
    "\n",
    "dataloaders = build_dataloader(part=PART,NECK_PATH=NECK_PATH,BODY_PATH=BODY_PATH,batch_size=BATCH_SIZE, aug_factor=AUG_FACTOR)\n",
    "model = YOLO_SWIN(num_classes=NUM_CLASSES)\n",
    "model = model.to(device)\n",
    "criterion = YOLO_LOSS(num_classes=NUM_CLASSES, device=device)\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=LR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "060a24e6",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mgomduribo\u001b[0m (\u001b[33murp\u001b[0m). Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.15.12 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.15.11"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/workspace/Plastic_Bottle_defect_detection/experiments/wandb/run-20231014_160918-uqwmtmk5</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/urp/yolo_swin_neck/runs/uqwmtmk5' target=\"_blank\">young-puddle-1</a></strong> to <a href='https://wandb.ai/urp/yolo_swin_neck' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/urp/yolo_swin_neck' target=\"_blank\">https://wandb.ai/urp/yolo_swin_neck</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/urp/yolo_swin_neck/runs/uqwmtmk5' target=\"_blank\">https://wandb.ai/urp/yolo_swin_neck/runs/uqwmtmk5</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<button onClick=\"this.nextSibling.style.display='block';this.style.display='none';\">Display W&B run</button><iframe src='https://wandb.ai/urp/yolo_swin_neck/runs/uqwmtmk5?jupyter=true' style='border:none;width:100%;height:420px;display:none;'></iframe>"
      ],
      "text/plain": [
       "<wandb.sdk.wandb_run.Run at 0x7fbd8481dfd0>"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import wandb\n",
    "import random\n",
    "\n",
    "# start a new wandb run to track this script\n",
    "wandb.init(\n",
    "    # set the wandb project where this run will be logged\n",
    "    project=\"yolo_swin_neck\",\n",
    "    \n",
    "    # track hyperparameters and run metadata\n",
    "    config={\n",
    "    \"learning_rate\": LR,\n",
    "    \"batch_size\": BATCH_SIZE,\n",
    "    \"architecture\": BACKBONE,\n",
    "    \"dataset\": PART,\n",
    "    \"epochs\": num_epochs,\n",
    "    \"aug factor\":AUG_FACTOR,\n",
    "    }\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "8ebab5dc",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.8/dist-packages/torch/functional.py:504: UserWarning: torch.meshgrid: in an upcoming release, it will be required to pass the indexing argument. (Triggered internally at /opt/pytorch/pytorch/aten/src/ATen/native/TensorShape.cpp:3423.)\n",
      "  return _VF.meshgrid(tensors, **kwargs)  # type: ignore[attr-defined]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<<<iteration:[20/525] - total_loss: 6.9731  obj_loss: 0.0772  noobj_loss: 3.9329  bbox_loss: 0.7826  cls_loss: 1.0162  \n",
      "<<<iteration:[40/525] - total_loss: 3.8196  obj_loss: 0.0522  noobj_loss: 2.6349  bbox_loss: 0.3829  cls_loss: 0.5354  \n",
      "<<<iteration:[60/525] - total_loss: 3.2380  obj_loss: 0.0586  noobj_loss: 2.3305  bbox_loss: 0.3300  cls_loss: 0.3641  \n",
      "<<<iteration:[80/525] - total_loss: 3.2955  obj_loss: 0.0496  noobj_loss: 2.2320  bbox_loss: 0.3516  cls_loss: 0.3718  \n",
      "<<<iteration:[100/525] - total_loss: 4.5594  obj_loss: 0.0439  noobj_loss: 2.1509  bbox_loss: 0.6174  cls_loss: 0.3530  \n",
      "<<<iteration:[120/525] - total_loss: 3.6070  obj_loss: 0.0408  noobj_loss: 2.0752  bbox_loss: 0.4348  cls_loss: 0.3545  \n",
      "<<<iteration:[140/525] - total_loss: 3.2490  obj_loss: 0.0394  noobj_loss: 1.9889  bbox_loss: 0.3683  cls_loss: 0.3735  \n",
      "<<<iteration:[160/525] - total_loss: 3.2121  obj_loss: 0.0278  noobj_loss: 1.8492  bbox_loss: 0.3840  cls_loss: 0.3398  \n",
      "<<<iteration:[180/525] - total_loss: 2.9009  obj_loss: 0.0470  noobj_loss: 1.8052  bbox_loss: 0.3304  cls_loss: 0.2992  \n",
      "<<<iteration:[200/525] - total_loss: 2.5927  obj_loss: 0.0369  noobj_loss: 1.6413  bbox_loss: 0.2871  cls_loss: 0.2998  \n",
      "<<<iteration:[220/525] - total_loss: 2.5539  obj_loss: 0.0375  noobj_loss: 1.5626  bbox_loss: 0.2733  cls_loss: 0.3684  \n",
      "<<<iteration:[240/525] - total_loss: 2.6962  obj_loss: 0.0363  noobj_loss: 1.5090  bbox_loss: 0.3146  cls_loss: 0.3327  \n",
      "<<<iteration:[260/525] - total_loss: 2.3708  obj_loss: 0.0317  noobj_loss: 1.4344  bbox_loss: 0.2575  cls_loss: 0.3342  \n",
      "<<<iteration:[280/525] - total_loss: 2.1931  obj_loss: 0.0364  noobj_loss: 1.3856  bbox_loss: 0.2268  cls_loss: 0.3300  \n",
      "<<<iteration:[300/525] - total_loss: 2.2358  obj_loss: 0.0397  noobj_loss: 1.2663  bbox_loss: 0.2513  cls_loss: 0.3062  \n",
      "<<<iteration:[320/525] - total_loss: 2.1133  obj_loss: 0.0328  noobj_loss: 1.2191  bbox_loss: 0.2237  cls_loss: 0.3524  \n",
      "<<<iteration:[340/525] - total_loss: 2.2733  obj_loss: 0.0311  noobj_loss: 1.2324  bbox_loss: 0.2664  cls_loss: 0.2942  \n",
      "<<<iteration:[360/525] - total_loss: 2.0514  obj_loss: 0.0332  noobj_loss: 1.1961  bbox_loss: 0.2334  cls_loss: 0.2532  \n",
      "<<<iteration:[380/525] - total_loss: 2.0564  obj_loss: 0.0320  noobj_loss: 1.1925  bbox_loss: 0.2264  cls_loss: 0.2959  \n",
      "<<<iteration:[400/525] - total_loss: 1.8591  obj_loss: 0.0347  noobj_loss: 1.2250  bbox_loss: 0.1834  cls_loss: 0.2952  \n",
      "<<<iteration:[420/525] - total_loss: 1.9609  obj_loss: 0.0335  noobj_loss: 1.1353  bbox_loss: 0.2175  cls_loss: 0.2724  \n",
      "<<<iteration:[440/525] - total_loss: 1.9867  obj_loss: 0.0408  noobj_loss: 1.1140  bbox_loss: 0.2178  cls_loss: 0.2999  \n",
      "<<<iteration:[460/525] - total_loss: 1.9120  obj_loss: 0.0332  noobj_loss: 1.0727  bbox_loss: 0.2087  cls_loss: 0.2987  \n",
      "<<<iteration:[480/525] - total_loss: 1.7813  obj_loss: 0.0281  noobj_loss: 1.0079  bbox_loss: 0.1858  cls_loss: 0.3203  \n",
      "<<<iteration:[500/525] - total_loss: 3.1247  obj_loss: 0.0291  noobj_loss: 1.0457  bbox_loss: 0.4529  cls_loss: 0.3082  \n",
      "<<<iteration:[520/525] - total_loss: 2.1657  obj_loss: 0.0275  noobj_loss: 0.9760  bbox_loss: 0.2724  cls_loss: 0.2882  \n",
      "\n",
      "epoch:1/100 - Train Loss: 2.7859, Val Loss: 2.7112\n",
      "\n",
      "<<<iteration:[20/525] - total_loss: 1.8429  obj_loss: 0.0332  noobj_loss: 1.0102  bbox_loss: 0.2048  cls_loss: 0.2809  \n",
      "<<<iteration:[40/525] - total_loss: 1.6988  obj_loss: 0.0383  noobj_loss: 0.9312  bbox_loss: 0.1902  cls_loss: 0.2438  \n",
      "<<<iteration:[60/525] - total_loss: 1.6693  obj_loss: 0.0379  noobj_loss: 0.9098  bbox_loss: 0.1829  cls_loss: 0.2620  \n",
      "<<<iteration:[80/525] - total_loss: 1.7592  obj_loss: 0.0287  noobj_loss: 0.8769  bbox_loss: 0.2135  cls_loss: 0.2245  \n",
      "<<<iteration:[100/525] - total_loss: 1.5670  obj_loss: 0.0282  noobj_loss: 0.8255  bbox_loss: 0.1824  cls_loss: 0.2138  \n",
      "<<<iteration:[120/525] - total_loss: 1.5199  obj_loss: 0.0333  noobj_loss: 0.8138  bbox_loss: 0.1682  cls_loss: 0.2387  \n",
      "<<<iteration:[140/525] - total_loss: 1.5123  obj_loss: 0.0293  noobj_loss: 0.7689  bbox_loss: 0.1669  cls_loss: 0.2640  \n",
      "<<<iteration:[160/525] - total_loss: 1.3913  obj_loss: 0.0339  noobj_loss: 0.7779  bbox_loss: 0.1495  cls_loss: 0.2208  \n",
      "<<<iteration:[180/525] - total_loss: 1.5372  obj_loss: 0.0339  noobj_loss: 0.7141  bbox_loss: 0.1741  cls_loss: 0.2760  \n",
      "<<<iteration:[200/525] - total_loss: 1.6134  obj_loss: 0.0315  noobj_loss: 0.7165  bbox_loss: 0.1918  cls_loss: 0.2647  \n",
      "<<<iteration:[220/525] - total_loss: 1.4537  obj_loss: 0.0330  noobj_loss: 0.6608  bbox_loss: 0.1621  cls_loss: 0.2800  \n",
      "<<<iteration:[240/525] - total_loss: 1.3068  obj_loss: 0.0360  noobj_loss: 0.6287  bbox_loss: 0.1476  cls_loss: 0.2186  \n",
      "<<<iteration:[260/525] - total_loss: 1.3241  obj_loss: 0.0420  noobj_loss: 0.6177  bbox_loss: 0.1578  cls_loss: 0.1840  \n",
      "<<<iteration:[280/525] - total_loss: 1.2568  obj_loss: 0.0360  noobj_loss: 0.6021  bbox_loss: 0.1360  cls_loss: 0.2397  \n",
      "<<<iteration:[300/525] - total_loss: 1.2628  obj_loss: 0.0358  noobj_loss: 0.5965  bbox_loss: 0.1547  cls_loss: 0.1551  \n",
      "<<<iteration:[320/525] - total_loss: 1.1571  obj_loss: 0.0434  noobj_loss: 0.5749  bbox_loss: 0.1271  cls_loss: 0.1910  \n",
      "<<<iteration:[340/525] - total_loss: 1.2184  obj_loss: 0.0281  noobj_loss: 0.5613  bbox_loss: 0.1398  cls_loss: 0.2105  \n",
      "<<<iteration:[360/525] - total_loss: 1.1016  obj_loss: 0.0488  noobj_loss: 0.5491  bbox_loss: 0.1138  cls_loss: 0.2094  \n",
      "<<<iteration:[380/525] - total_loss: 1.7053  obj_loss: 0.0321  noobj_loss: 0.5906  bbox_loss: 0.2387  cls_loss: 0.1844  \n",
      "<<<iteration:[400/525] - total_loss: 1.3296  obj_loss: 0.0438  noobj_loss: 0.5231  bbox_loss: 0.1562  cls_loss: 0.2433  \n",
      "<<<iteration:[420/525] - total_loss: 1.2648  obj_loss: 0.0417  noobj_loss: 0.4799  bbox_loss: 0.1556  cls_loss: 0.2053  \n",
      "<<<iteration:[440/525] - total_loss: 1.1356  obj_loss: 0.0487  noobj_loss: 0.5190  bbox_loss: 0.1152  cls_loss: 0.2514  \n",
      "<<<iteration:[460/525] - total_loss: 1.1431  obj_loss: 0.0419  noobj_loss: 0.5046  bbox_loss: 0.1305  cls_loss: 0.1965  \n",
      "<<<iteration:[480/525] - total_loss: 0.9605  obj_loss: 0.0393  noobj_loss: 0.4719  bbox_loss: 0.1051  cls_loss: 0.1597  \n",
      "<<<iteration:[500/525] - total_loss: 0.9733  obj_loss: 0.0471  noobj_loss: 0.4383  bbox_loss: 0.0953  cls_loss: 0.2304  \n",
      "<<<iteration:[520/525] - total_loss: 0.9843  obj_loss: 0.0409  noobj_loss: 0.4284  bbox_loss: 0.1099  cls_loss: 0.1796  \n",
      "\n",
      "epoch:2/100 - Train Loss: 1.3677, Val Loss: 0.8953\n",
      "\n",
      "<<<iteration:[20/525] - total_loss: 0.9198  obj_loss: 0.0589  noobj_loss: 0.4298  bbox_loss: 0.0925  cls_loss: 0.1836  \n",
      "<<<iteration:[40/525] - total_loss: 0.9582  obj_loss: 0.0509  noobj_loss: 0.3903  bbox_loss: 0.1036  cls_loss: 0.1941  \n",
      "<<<iteration:[60/525] - total_loss: 0.8973  obj_loss: 0.0425  noobj_loss: 0.3644  bbox_loss: 0.0941  cls_loss: 0.2021  \n",
      "<<<iteration:[80/525] - total_loss: 0.7603  obj_loss: 0.0456  noobj_loss: 0.3554  bbox_loss: 0.0762  cls_loss: 0.1559  \n",
      "<<<iteration:[100/525] - total_loss: 0.8907  obj_loss: 0.0448  noobj_loss: 0.3607  bbox_loss: 0.0918  cls_loss: 0.2065  \n",
      "<<<iteration:[120/525] - total_loss: 0.8564  obj_loss: 0.0525  noobj_loss: 0.3490  bbox_loss: 0.0812  cls_loss: 0.2232  \n",
      "<<<iteration:[140/525] - total_loss: 0.7647  obj_loss: 0.0569  noobj_loss: 0.3335  bbox_loss: 0.0710  cls_loss: 0.1860  \n",
      "<<<iteration:[160/525] - total_loss: 0.9091  obj_loss: 0.0517  noobj_loss: 0.3397  bbox_loss: 0.1006  cls_loss: 0.1845  \n",
      "<<<iteration:[180/525] - total_loss: 0.8677  obj_loss: 0.0551  noobj_loss: 0.3368  bbox_loss: 0.0933  cls_loss: 0.1778  \n",
      "<<<iteration:[200/525] - total_loss: 0.8200  obj_loss: 0.0605  noobj_loss: 0.3256  bbox_loss: 0.0812  cls_loss: 0.1907  \n",
      "<<<iteration:[220/525] - total_loss: 0.7595  obj_loss: 0.0691  noobj_loss: 0.2690  bbox_loss: 0.0737  cls_loss: 0.1876  \n",
      "<<<iteration:[240/525] - total_loss: 0.7346  obj_loss: 0.0645  noobj_loss: 0.2854  bbox_loss: 0.0727  cls_loss: 0.1639  \n",
      "<<<iteration:[260/525] - total_loss: 0.7425  obj_loss: 0.0760  noobj_loss: 0.2457  bbox_loss: 0.0739  cls_loss: 0.1739  \n",
      "<<<iteration:[280/525] - total_loss: 0.6568  obj_loss: 0.0564  noobj_loss: 0.2517  bbox_loss: 0.0680  cls_loss: 0.1346  \n",
      "<<<iteration:[300/525] - total_loss: 0.5888  obj_loss: 0.0728  noobj_loss: 0.2283  bbox_loss: 0.0561  cls_loss: 0.1216  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<<<iteration:[320/525] - total_loss: 0.7090  obj_loss: 0.0828  noobj_loss: 0.2428  bbox_loss: 0.0719  cls_loss: 0.1453  \n",
      "<<<iteration:[340/525] - total_loss: 0.6744  obj_loss: 0.0680  noobj_loss: 0.2265  bbox_loss: 0.0690  cls_loss: 0.1484  \n",
      "<<<iteration:[360/525] - total_loss: 0.6969  obj_loss: 0.0610  noobj_loss: 0.2176  bbox_loss: 0.0713  cls_loss: 0.1708  \n",
      "<<<iteration:[380/525] - total_loss: 0.7726  obj_loss: 0.0610  noobj_loss: 0.2268  bbox_loss: 0.0773  cls_loss: 0.2115  \n",
      "<<<iteration:[400/525] - total_loss: 0.7059  obj_loss: 0.0666  noobj_loss: 0.2216  bbox_loss: 0.0706  cls_loss: 0.1755  \n",
      "<<<iteration:[420/525] - total_loss: 0.7525  obj_loss: 0.0632  noobj_loss: 0.2255  bbox_loss: 0.0798  cls_loss: 0.1772  \n",
      "<<<iteration:[440/525] - total_loss: 0.5746  obj_loss: 0.0744  noobj_loss: 0.1839  bbox_loss: 0.0507  cls_loss: 0.1547  \n",
      "<<<iteration:[460/525] - total_loss: 0.5276  obj_loss: 0.0775  noobj_loss: 0.1851  bbox_loss: 0.0488  cls_loss: 0.1137  \n",
      "<<<iteration:[480/525] - total_loss: 0.5939  obj_loss: 0.0791  noobj_loss: 0.1890  bbox_loss: 0.0526  cls_loss: 0.1573  \n",
      "<<<iteration:[500/525] - total_loss: 0.5478  obj_loss: 0.0733  noobj_loss: 0.1896  bbox_loss: 0.0516  cls_loss: 0.1218  \n",
      "<<<iteration:[520/525] - total_loss: 0.5994  obj_loss: 0.0599  noobj_loss: 0.1700  bbox_loss: 0.0685  cls_loss: 0.1122  \n",
      "\n",
      "epoch:3/100 - Train Loss: 0.7395, Val Loss: 0.4951\n",
      "\n",
      "<<<iteration:[20/525] - total_loss: 0.5541  obj_loss: 0.0830  noobj_loss: 0.1921  bbox_loss: 0.0496  cls_loss: 0.1271  \n",
      "<<<iteration:[40/525] - total_loss: 0.6191  obj_loss: 0.0778  noobj_loss: 0.1872  bbox_loss: 0.0594  cls_loss: 0.1508  \n",
      "<<<iteration:[60/525] - total_loss: 0.5855  obj_loss: 0.0896  noobj_loss: 0.1768  bbox_loss: 0.0492  cls_loss: 0.1615  \n",
      "<<<iteration:[80/525] - total_loss: 0.5313  obj_loss: 0.0797  noobj_loss: 0.1682  bbox_loss: 0.0477  cls_loss: 0.1291  \n",
      "<<<iteration:[100/525] - total_loss: 0.5841  obj_loss: 0.0743  noobj_loss: 0.1602  bbox_loss: 0.0565  cls_loss: 0.1472  \n",
      "<<<iteration:[120/525] - total_loss: 0.6124  obj_loss: 0.0815  noobj_loss: 0.1654  bbox_loss: 0.0556  cls_loss: 0.1704  \n",
      "<<<iteration:[140/525] - total_loss: 0.4860  obj_loss: 0.0834  noobj_loss: 0.1543  bbox_loss: 0.0405  cls_loss: 0.1228  \n",
      "<<<iteration:[160/525] - total_loss: 0.5850  obj_loss: 0.0914  noobj_loss: 0.1630  bbox_loss: 0.0535  cls_loss: 0.1448  \n",
      "<<<iteration:[180/525] - total_loss: 0.5223  obj_loss: 0.0851  noobj_loss: 0.1686  bbox_loss: 0.0463  cls_loss: 0.1213  \n",
      "<<<iteration:[200/525] - total_loss: 0.5335  obj_loss: 0.0806  noobj_loss: 0.1486  bbox_loss: 0.0438  cls_loss: 0.1596  \n",
      "<<<iteration:[220/525] - total_loss: 0.5215  obj_loss: 0.0867  noobj_loss: 0.1560  bbox_loss: 0.0493  cls_loss: 0.1104  \n",
      "<<<iteration:[240/525] - total_loss: 0.6412  obj_loss: 0.0800  noobj_loss: 0.1619  bbox_loss: 0.0615  cls_loss: 0.1727  \n",
      "<<<iteration:[260/525] - total_loss: 0.5663  obj_loss: 0.0836  noobj_loss: 0.1573  bbox_loss: 0.0510  cls_loss: 0.1488  \n",
      "<<<iteration:[280/525] - total_loss: 0.5076  obj_loss: 0.0797  noobj_loss: 0.1526  bbox_loss: 0.0445  cls_loss: 0.1291  \n",
      "<<<iteration:[300/525] - total_loss: 0.4818  obj_loss: 0.0907  noobj_loss: 0.1378  bbox_loss: 0.0389  cls_loss: 0.1278  \n",
      "<<<iteration:[320/525] - total_loss: 0.4711  obj_loss: 0.0813  noobj_loss: 0.1444  bbox_loss: 0.0463  cls_loss: 0.0859  \n",
      "<<<iteration:[340/525] - total_loss: 0.5006  obj_loss: 0.0888  noobj_loss: 0.1405  bbox_loss: 0.0422  cls_loss: 0.1307  \n",
      "<<<iteration:[360/525] - total_loss: 0.5362  obj_loss: 0.1002  noobj_loss: 0.1345  bbox_loss: 0.0387  cls_loss: 0.1751  \n",
      "<<<iteration:[380/525] - total_loss: 0.5160  obj_loss: 0.0830  noobj_loss: 0.1383  bbox_loss: 0.0451  cls_loss: 0.1386  \n",
      "<<<iteration:[400/525] - total_loss: 0.5362  obj_loss: 0.0879  noobj_loss: 0.1412  bbox_loss: 0.0440  cls_loss: 0.1574  \n",
      "<<<iteration:[420/525] - total_loss: 0.4663  obj_loss: 0.0802  noobj_loss: 0.1289  bbox_loss: 0.0391  cls_loss: 0.1264  \n",
      "<<<iteration:[440/525] - total_loss: 0.5181  obj_loss: 0.1060  noobj_loss: 0.1294  bbox_loss: 0.0363  cls_loss: 0.1661  \n",
      "<<<iteration:[460/525] - total_loss: 0.5052  obj_loss: 0.0788  noobj_loss: 0.1362  bbox_loss: 0.0452  cls_loss: 0.1324  \n",
      "<<<iteration:[480/525] - total_loss: 0.4865  obj_loss: 0.0909  noobj_loss: 0.1371  bbox_loss: 0.0432  cls_loss: 0.1112  \n",
      "<<<iteration:[500/525] - total_loss: 0.6484  obj_loss: 0.0816  noobj_loss: 0.1285  bbox_loss: 0.0665  cls_loss: 0.1702  \n",
      "<<<iteration:[520/525] - total_loss: 0.5205  obj_loss: 0.1055  noobj_loss: 0.1187  bbox_loss: 0.0487  cls_loss: 0.1123  \n",
      "\n",
      "epoch:4/100 - Train Loss: 0.5395, Val Loss: 0.4725\n",
      "\n",
      "<<<iteration:[20/525] - total_loss: 0.5140  obj_loss: 0.1031  noobj_loss: 0.1225  bbox_loss: 0.0415  cls_loss: 0.1422  \n",
      "<<<iteration:[40/525] - total_loss: 0.4951  obj_loss: 0.0858  noobj_loss: 0.1113  bbox_loss: 0.0408  cls_loss: 0.1496  \n",
      "<<<iteration:[60/525] - total_loss: 0.4802  obj_loss: 0.0996  noobj_loss: 0.1114  bbox_loss: 0.0397  cls_loss: 0.1266  \n",
      "<<<iteration:[80/525] - total_loss: 0.5532  obj_loss: 0.0907  noobj_loss: 0.1202  bbox_loss: 0.0479  cls_loss: 0.1629  \n",
      "<<<iteration:[100/525] - total_loss: 0.4545  obj_loss: 0.0993  noobj_loss: 0.1155  bbox_loss: 0.0358  cls_loss: 0.1183  \n",
      "<<<iteration:[120/525] - total_loss: 0.5130  obj_loss: 0.0957  noobj_loss: 0.1134  bbox_loss: 0.0337  cls_loss: 0.1919  \n",
      "<<<iteration:[140/525] - total_loss: 0.3995  obj_loss: 0.0892  noobj_loss: 0.1166  bbox_loss: 0.0323  cls_loss: 0.0903  \n",
      "<<<iteration:[160/525] - total_loss: 0.4433  obj_loss: 0.0939  noobj_loss: 0.1099  bbox_loss: 0.0378  cls_loss: 0.1053  \n",
      "<<<iteration:[180/525] - total_loss: 0.4667  obj_loss: 0.0981  noobj_loss: 0.1150  bbox_loss: 0.0384  cls_loss: 0.1188  \n",
      "<<<iteration:[200/525] - total_loss: 0.3984  obj_loss: 0.0886  noobj_loss: 0.1057  bbox_loss: 0.0331  cls_loss: 0.0914  \n",
      "<<<iteration:[220/525] - total_loss: 0.4557  obj_loss: 0.1193  noobj_loss: 0.1120  bbox_loss: 0.0338  cls_loss: 0.1115  \n",
      "<<<iteration:[240/525] - total_loss: 0.4811  obj_loss: 0.1367  noobj_loss: 0.1111  bbox_loss: 0.0356  cls_loss: 0.1110  \n",
      "<<<iteration:[260/525] - total_loss: 0.4941  obj_loss: 0.0963  noobj_loss: 0.1151  bbox_loss: 0.0422  cls_loss: 0.1291  \n",
      "<<<iteration:[280/525] - total_loss: 0.4346  obj_loss: 0.0953  noobj_loss: 0.0966  bbox_loss: 0.0345  cls_loss: 0.1183  \n",
      "<<<iteration:[300/525] - total_loss: 0.4278  obj_loss: 0.1019  noobj_loss: 0.1099  bbox_loss: 0.0304  cls_loss: 0.1188  \n",
      "<<<iteration:[320/525] - total_loss: 0.4467  obj_loss: 0.0974  noobj_loss: 0.1012  bbox_loss: 0.0360  cls_loss: 0.1188  \n",
      "<<<iteration:[340/525] - total_loss: 0.5458  obj_loss: 0.0987  noobj_loss: 0.1221  bbox_loss: 0.0489  cls_loss: 0.1415  \n",
      "<<<iteration:[360/525] - total_loss: 0.5014  obj_loss: 0.0935  noobj_loss: 0.1083  bbox_loss: 0.0475  cls_loss: 0.1165  \n",
      "<<<iteration:[380/525] - total_loss: 0.4724  obj_loss: 0.0973  noobj_loss: 0.1046  bbox_loss: 0.0381  cls_loss: 0.1323  \n",
      "<<<iteration:[400/525] - total_loss: 0.4768  obj_loss: 0.0986  noobj_loss: 0.0986  bbox_loss: 0.0460  cls_loss: 0.0990  \n",
      "<<<iteration:[420/525] - total_loss: 0.5184  obj_loss: 0.1083  noobj_loss: 0.1049  bbox_loss: 0.0480  cls_loss: 0.1175  \n",
      "<<<iteration:[440/525] - total_loss: 0.5558  obj_loss: 0.1042  noobj_loss: 0.1175  bbox_loss: 0.0532  cls_loss: 0.1268  \n",
      "<<<iteration:[460/525] - total_loss: 0.4836  obj_loss: 0.0986  noobj_loss: 0.1047  bbox_loss: 0.0438  cls_loss: 0.1134  \n",
      "<<<iteration:[480/525] - total_loss: 0.4666  obj_loss: 0.1078  noobj_loss: 0.0896  bbox_loss: 0.0404  cls_loss: 0.1119  \n",
      "<<<iteration:[500/525] - total_loss: 0.4633  obj_loss: 0.0934  noobj_loss: 0.0996  bbox_loss: 0.0400  cls_loss: 0.1202  \n",
      "<<<iteration:[520/525] - total_loss: 0.4382  obj_loss: 0.0988  noobj_loss: 0.0951  bbox_loss: 0.0347  cls_loss: 0.1183  \n",
      "\n",
      "epoch:5/100 - Train Loss: 0.4759, Val Loss: 0.4059\n",
      "\n",
      "<<<iteration:[20/525] - total_loss: 0.4245  obj_loss: 0.1008  noobj_loss: 0.1066  bbox_loss: 0.0336  cls_loss: 0.1024  \n",
      "<<<iteration:[40/525] - total_loss: 0.4167  obj_loss: 0.0963  noobj_loss: 0.0869  bbox_loss: 0.0321  cls_loss: 0.1166  \n",
      "<<<iteration:[60/525] - total_loss: 0.4313  obj_loss: 0.1076  noobj_loss: 0.0950  bbox_loss: 0.0395  cls_loss: 0.0787  \n",
      "<<<iteration:[80/525] - total_loss: 0.4124  obj_loss: 0.1040  noobj_loss: 0.0890  bbox_loss: 0.0324  cls_loss: 0.1021  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<<<iteration:[100/525] - total_loss: 0.4147  obj_loss: 0.1261  noobj_loss: 0.0907  bbox_loss: 0.0295  cls_loss: 0.0959  \n",
      "<<<iteration:[120/525] - total_loss: 0.4701  obj_loss: 0.0964  noobj_loss: 0.0940  bbox_loss: 0.0350  cls_loss: 0.1520  \n",
      "<<<iteration:[140/525] - total_loss: 0.3942  obj_loss: 0.1149  noobj_loss: 0.0893  bbox_loss: 0.0298  cls_loss: 0.0855  \n",
      "<<<iteration:[160/525] - total_loss: 0.4412  obj_loss: 0.1245  noobj_loss: 0.0901  bbox_loss: 0.0330  cls_loss: 0.1066  \n",
      "<<<iteration:[180/525] - total_loss: 0.4566  obj_loss: 0.1184  noobj_loss: 0.0998  bbox_loss: 0.0361  cls_loss: 0.1080  \n",
      "<<<iteration:[200/525] - total_loss: 0.4597  obj_loss: 0.0978  noobj_loss: 0.0868  bbox_loss: 0.0344  cls_loss: 0.1466  \n",
      "<<<iteration:[220/525] - total_loss: 0.3816  obj_loss: 0.1066  noobj_loss: 0.0904  bbox_loss: 0.0289  cls_loss: 0.0854  \n",
      "<<<iteration:[240/525] - total_loss: 0.4383  obj_loss: 0.1277  noobj_loss: 0.0865  bbox_loss: 0.0347  cls_loss: 0.0941  \n",
      "<<<iteration:[260/525] - total_loss: 0.4300  obj_loss: 0.1053  noobj_loss: 0.0878  bbox_loss: 0.0373  cls_loss: 0.0942  \n",
      "<<<iteration:[280/525] - total_loss: 0.4334  obj_loss: 0.1123  noobj_loss: 0.0952  bbox_loss: 0.0305  cls_loss: 0.1209  \n",
      "<<<iteration:[300/525] - total_loss: 0.4415  obj_loss: 0.1102  noobj_loss: 0.0832  bbox_loss: 0.0312  cls_loss: 0.1337  \n",
      "<<<iteration:[320/525] - total_loss: 0.4106  obj_loss: 0.1180  noobj_loss: 0.0895  bbox_loss: 0.0296  cls_loss: 0.1000  \n",
      "<<<iteration:[340/525] - total_loss: 0.4651  obj_loss: 0.1050  noobj_loss: 0.0874  bbox_loss: 0.0346  cls_loss: 0.1436  \n",
      "<<<iteration:[360/525] - total_loss: 0.4477  obj_loss: 0.1214  noobj_loss: 0.0957  bbox_loss: 0.0339  cls_loss: 0.1090  \n",
      "<<<iteration:[380/525] - total_loss: 0.3747  obj_loss: 0.1168  noobj_loss: 0.0903  bbox_loss: 0.0281  cls_loss: 0.0721  \n",
      "<<<iteration:[400/525] - total_loss: 0.4355  obj_loss: 0.1153  noobj_loss: 0.0835  bbox_loss: 0.0297  cls_loss: 0.1298  \n",
      "<<<iteration:[420/525] - total_loss: 0.4476  obj_loss: 0.1182  noobj_loss: 0.0846  bbox_loss: 0.0300  cls_loss: 0.1373  \n",
      "<<<iteration:[440/525] - total_loss: 0.3996  obj_loss: 0.1032  noobj_loss: 0.0795  bbox_loss: 0.0265  cls_loss: 0.1243  \n",
      "<<<iteration:[460/525] - total_loss: 0.4156  obj_loss: 0.1183  noobj_loss: 0.0793  bbox_loss: 0.0308  cls_loss: 0.1036  \n",
      "<<<iteration:[480/525] - total_loss: 0.4787  obj_loss: 0.1060  noobj_loss: 0.0876  bbox_loss: 0.0403  cls_loss: 0.1273  \n",
      "<<<iteration:[500/525] - total_loss: 0.4181  obj_loss: 0.1127  noobj_loss: 0.0931  bbox_loss: 0.0314  cls_loss: 0.1018  \n",
      "<<<iteration:[520/525] - total_loss: 0.4207  obj_loss: 0.1054  noobj_loss: 0.0866  bbox_loss: 0.0337  cls_loss: 0.1037  \n",
      "\n",
      "epoch:6/100 - Train Loss: 0.4292, Val Loss: 0.4407\n",
      "\n",
      "<<<iteration:[20/525] - total_loss: 0.4842  obj_loss: 0.1322  noobj_loss: 0.0914  bbox_loss: 0.0372  cls_loss: 0.1201  \n",
      "<<<iteration:[40/525] - total_loss: 0.4648  obj_loss: 0.1264  noobj_loss: 0.0813  bbox_loss: 0.0317  cls_loss: 0.1393  \n",
      "<<<iteration:[60/525] - total_loss: 0.3837  obj_loss: 0.0986  noobj_loss: 0.0865  bbox_loss: 0.0307  cls_loss: 0.0883  \n",
      "<<<iteration:[80/525] - total_loss: 0.3934  obj_loss: 0.1156  noobj_loss: 0.0791  bbox_loss: 0.0309  cls_loss: 0.0839  \n",
      "<<<iteration:[100/525] - total_loss: 0.3908  obj_loss: 0.1089  noobj_loss: 0.0790  bbox_loss: 0.0273  cls_loss: 0.1058  \n",
      "<<<iteration:[120/525] - total_loss: 0.3926  obj_loss: 0.1248  noobj_loss: 0.0768  bbox_loss: 0.0279  cls_loss: 0.0897  \n",
      "<<<iteration:[140/525] - total_loss: 0.4275  obj_loss: 0.1224  noobj_loss: 0.0852  bbox_loss: 0.0308  cls_loss: 0.1085  \n",
      "<<<iteration:[160/525] - total_loss: 0.4155  obj_loss: 0.1254  noobj_loss: 0.0770  bbox_loss: 0.0264  cls_loss: 0.1199  \n",
      "<<<iteration:[180/525] - total_loss: 0.4107  obj_loss: 0.1218  noobj_loss: 0.0768  bbox_loss: 0.0274  cls_loss: 0.1134  \n",
      "<<<iteration:[200/525] - total_loss: 0.3811  obj_loss: 0.1104  noobj_loss: 0.0806  bbox_loss: 0.0244  cls_loss: 0.1081  \n",
      "<<<iteration:[220/525] - total_loss: 0.4118  obj_loss: 0.1176  noobj_loss: 0.0818  bbox_loss: 0.0295  cls_loss: 0.1057  \n",
      "<<<iteration:[240/525] - total_loss: 0.4174  obj_loss: 0.1261  noobj_loss: 0.0743  bbox_loss: 0.0269  cls_loss: 0.1194  \n",
      "<<<iteration:[260/525] - total_loss: 0.3653  obj_loss: 0.1135  noobj_loss: 0.0777  bbox_loss: 0.0266  cls_loss: 0.0799  \n",
      "<<<iteration:[280/525] - total_loss: 0.3956  obj_loss: 0.1229  noobj_loss: 0.0800  bbox_loss: 0.0225  cls_loss: 0.1201  \n",
      "<<<iteration:[300/525] - total_loss: 0.4074  obj_loss: 0.1191  noobj_loss: 0.0753  bbox_loss: 0.0271  cls_loss: 0.1151  \n",
      "<<<iteration:[320/525] - total_loss: 0.3919  obj_loss: 0.1115  noobj_loss: 0.0805  bbox_loss: 0.0292  cls_loss: 0.0941  \n",
      "<<<iteration:[340/525] - total_loss: 0.4166  obj_loss: 0.1148  noobj_loss: 0.0780  bbox_loss: 0.0285  cls_loss: 0.1205  \n",
      "<<<iteration:[360/525] - total_loss: 0.3716  obj_loss: 0.1156  noobj_loss: 0.0786  bbox_loss: 0.0274  cls_loss: 0.0795  \n",
      "<<<iteration:[380/525] - total_loss: 0.3622  obj_loss: 0.1101  noobj_loss: 0.0817  bbox_loss: 0.0255  cls_loss: 0.0840  \n",
      "<<<iteration:[400/525] - total_loss: 0.3990  obj_loss: 0.1228  noobj_loss: 0.0771  bbox_loss: 0.0290  cls_loss: 0.0927  \n",
      "<<<iteration:[420/525] - total_loss: 0.4111  obj_loss: 0.1059  noobj_loss: 0.0753  bbox_loss: 0.0278  cls_loss: 0.1289  \n",
      "<<<iteration:[440/525] - total_loss: 0.4000  obj_loss: 0.1185  noobj_loss: 0.0754  bbox_loss: 0.0290  cls_loss: 0.0988  \n",
      "<<<iteration:[460/525] - total_loss: 0.3983  obj_loss: 0.1302  noobj_loss: 0.0777  bbox_loss: 0.0262  cls_loss: 0.0984  \n",
      "<<<iteration:[480/525] - total_loss: 0.3773  obj_loss: 0.1192  noobj_loss: 0.0720  bbox_loss: 0.0229  cls_loss: 0.1074  \n",
      "<<<iteration:[500/525] - total_loss: 0.3894  obj_loss: 0.1287  noobj_loss: 0.0773  bbox_loss: 0.0237  cls_loss: 0.1037  \n",
      "<<<iteration:[520/525] - total_loss: 0.4530  obj_loss: 0.1227  noobj_loss: 0.0831  bbox_loss: 0.0376  cls_loss: 0.1007  \n",
      "\n",
      "epoch:7/100 - Train Loss: 0.4080, Val Loss: 0.9571\n",
      "\n",
      "<<<iteration:[20/525] - total_loss: 0.5641  obj_loss: 0.1188  noobj_loss: 0.0919  bbox_loss: 0.0583  cls_loss: 0.1078  \n",
      "<<<iteration:[40/525] - total_loss: 0.6874  obj_loss: 0.1270  noobj_loss: 0.0810  bbox_loss: 0.0868  cls_loss: 0.0857  \n",
      "<<<iteration:[60/525] - total_loss: 0.5478  obj_loss: 0.1098  noobj_loss: 0.0722  bbox_loss: 0.0595  cls_loss: 0.1041  \n",
      "<<<iteration:[80/525] - total_loss: 0.6666  obj_loss: 0.1077  noobj_loss: 0.0828  bbox_loss: 0.0760  cls_loss: 0.1378  \n",
      "<<<iteration:[100/525] - total_loss: 0.4639  obj_loss: 0.1347  noobj_loss: 0.0780  bbox_loss: 0.0406  cls_loss: 0.0874  \n",
      "<<<iteration:[120/525] - total_loss: 0.4120  obj_loss: 0.1155  noobj_loss: 0.0716  bbox_loss: 0.0338  cls_loss: 0.0917  \n",
      "<<<iteration:[140/525] - total_loss: 0.4061  obj_loss: 0.1248  noobj_loss: 0.0756  bbox_loss: 0.0300  cls_loss: 0.0933  \n",
      "<<<iteration:[160/525] - total_loss: 0.3942  obj_loss: 0.1192  noobj_loss: 0.0814  bbox_loss: 0.0266  cls_loss: 0.1011  \n",
      "<<<iteration:[180/525] - total_loss: 0.4219  obj_loss: 0.1171  noobj_loss: 0.0757  bbox_loss: 0.0327  cls_loss: 0.1033  \n",
      "<<<iteration:[200/525] - total_loss: 0.4625  obj_loss: 0.1106  noobj_loss: 0.0775  bbox_loss: 0.0441  cls_loss: 0.0928  \n",
      "<<<iteration:[220/525] - total_loss: 0.3785  obj_loss: 0.1122  noobj_loss: 0.0773  bbox_loss: 0.0314  cls_loss: 0.0708  \n",
      "<<<iteration:[240/525] - total_loss: 0.4536  obj_loss: 0.1078  noobj_loss: 0.0772  bbox_loss: 0.0352  cls_loss: 0.1314  \n",
      "<<<iteration:[260/525] - total_loss: 0.3812  obj_loss: 0.1203  noobj_loss: 0.0782  bbox_loss: 0.0259  cls_loss: 0.0920  \n",
      "<<<iteration:[280/525] - total_loss: 0.3508  obj_loss: 0.0967  noobj_loss: 0.0713  bbox_loss: 0.0275  cls_loss: 0.0808  \n",
      "<<<iteration:[300/525] - total_loss: 0.4148  obj_loss: 0.1255  noobj_loss: 0.0792  bbox_loss: 0.0311  cls_loss: 0.0942  \n",
      "<<<iteration:[320/525] - total_loss: 0.4255  obj_loss: 0.1129  noobj_loss: 0.0755  bbox_loss: 0.0356  cls_loss: 0.0970  \n",
      "<<<iteration:[340/525] - total_loss: 0.4611  obj_loss: 0.1104  noobj_loss: 0.0772  bbox_loss: 0.0378  cls_loss: 0.1232  \n",
      "<<<iteration:[360/525] - total_loss: 0.4268  obj_loss: 0.1388  noobj_loss: 0.0800  bbox_loss: 0.0294  cls_loss: 0.1011  \n",
      "<<<iteration:[380/525] - total_loss: 0.4074  obj_loss: 0.1244  noobj_loss: 0.0700  bbox_loss: 0.0347  cls_loss: 0.0747  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<<<iteration:[400/525] - total_loss: 0.4021  obj_loss: 0.1262  noobj_loss: 0.0760  bbox_loss: 0.0292  cls_loss: 0.0921  \n",
      "<<<iteration:[420/525] - total_loss: 0.3524  obj_loss: 0.1208  noobj_loss: 0.0718  bbox_loss: 0.0235  cls_loss: 0.0784  \n",
      "<<<iteration:[440/525] - total_loss: 0.3677  obj_loss: 0.1236  noobj_loss: 0.0750  bbox_loss: 0.0247  cls_loss: 0.0831  \n",
      "<<<iteration:[460/525] - total_loss: 0.3856  obj_loss: 0.1198  noobj_loss: 0.0741  bbox_loss: 0.0277  cls_loss: 0.0900  \n",
      "<<<iteration:[480/525] - total_loss: 0.3620  obj_loss: 0.1306  noobj_loss: 0.0754  bbox_loss: 0.0253  cls_loss: 0.0673  \n",
      "<<<iteration:[500/525] - total_loss: 0.3801  obj_loss: 0.1394  noobj_loss: 0.0736  bbox_loss: 0.0258  cls_loss: 0.0747  \n",
      "<<<iteration:[520/525] - total_loss: 0.3992  obj_loss: 0.1302  noobj_loss: 0.0728  bbox_loss: 0.0260  cls_loss: 0.1028  \n",
      "\n",
      "epoch:8/100 - Train Loss: 0.4361, Val Loss: 0.3699\n",
      "\n",
      "<<<iteration:[20/525] - total_loss: 0.4198  obj_loss: 0.1145  noobj_loss: 0.0877  bbox_loss: 0.0331  cls_loss: 0.0961  \n",
      "<<<iteration:[40/525] - total_loss: 0.3751  obj_loss: 0.1119  noobj_loss: 0.0768  bbox_loss: 0.0281  cls_loss: 0.0844  \n",
      "<<<iteration:[60/525] - total_loss: 0.3325  obj_loss: 0.1190  noobj_loss: 0.0728  bbox_loss: 0.0211  cls_loss: 0.0714  \n",
      "<<<iteration:[80/525] - total_loss: 0.3679  obj_loss: 0.1297  noobj_loss: 0.0691  bbox_loss: 0.0248  cls_loss: 0.0798  \n",
      "<<<iteration:[100/525] - total_loss: 0.3585  obj_loss: 0.1272  noobj_loss: 0.0683  bbox_loss: 0.0218  cls_loss: 0.0882  \n",
      "<<<iteration:[120/525] - total_loss: 0.3998  obj_loss: 0.1292  noobj_loss: 0.0715  bbox_loss: 0.0269  cls_loss: 0.1001  \n",
      "<<<iteration:[140/525] - total_loss: 0.3616  obj_loss: 0.1156  noobj_loss: 0.0734  bbox_loss: 0.0259  cls_loss: 0.0798  \n",
      "<<<iteration:[160/525] - total_loss: 0.4016  obj_loss: 0.1317  noobj_loss: 0.0732  bbox_loss: 0.0241  cls_loss: 0.1127  \n",
      "<<<iteration:[180/525] - total_loss: 0.4541  obj_loss: 0.1206  noobj_loss: 0.0804  bbox_loss: 0.0372  cls_loss: 0.1072  \n",
      "<<<iteration:[200/525] - total_loss: 0.3594  obj_loss: 0.1426  noobj_loss: 0.0646  bbox_loss: 0.0201  cls_loss: 0.0841  \n",
      "<<<iteration:[220/525] - total_loss: 0.3568  obj_loss: 0.1280  noobj_loss: 0.0707  bbox_loss: 0.0232  cls_loss: 0.0775  \n",
      "<<<iteration:[240/525] - total_loss: 0.3852  obj_loss: 0.1299  noobj_loss: 0.0704  bbox_loss: 0.0231  cls_loss: 0.1045  \n",
      "<<<iteration:[260/525] - total_loss: 0.3907  obj_loss: 0.1228  noobj_loss: 0.0731  bbox_loss: 0.0253  cls_loss: 0.1050  \n",
      "<<<iteration:[280/525] - total_loss: 0.3736  obj_loss: 0.1280  noobj_loss: 0.0686  bbox_loss: 0.0230  cls_loss: 0.0961  \n",
      "<<<iteration:[300/525] - total_loss: 0.3823  obj_loss: 0.1236  noobj_loss: 0.0728  bbox_loss: 0.0243  cls_loss: 0.1006  \n",
      "<<<iteration:[320/525] - total_loss: 0.3588  obj_loss: 0.1231  noobj_loss: 0.0672  bbox_loss: 0.0244  cls_loss: 0.0800  \n",
      "<<<iteration:[340/525] - total_loss: 0.3898  obj_loss: 0.1409  noobj_loss: 0.0744  bbox_loss: 0.0211  cls_loss: 0.1062  \n",
      "<<<iteration:[360/525] - total_loss: 0.3700  obj_loss: 0.1377  noobj_loss: 0.0700  bbox_loss: 0.0233  cls_loss: 0.0810  \n",
      "<<<iteration:[380/525] - total_loss: 0.3954  obj_loss: 0.1275  noobj_loss: 0.0691  bbox_loss: 0.0245  cls_loss: 0.1108  \n",
      "<<<iteration:[400/525] - total_loss: 0.3250  obj_loss: 0.1063  noobj_loss: 0.0699  bbox_loss: 0.0226  cls_loss: 0.0706  \n",
      "<<<iteration:[420/525] - total_loss: 0.3646  obj_loss: 0.1404  noobj_loss: 0.0703  bbox_loss: 0.0216  cls_loss: 0.0808  \n",
      "<<<iteration:[440/525] - total_loss: 0.3733  obj_loss: 0.1405  noobj_loss: 0.0743  bbox_loss: 0.0237  cls_loss: 0.0773  \n",
      "<<<iteration:[460/525] - total_loss: 0.3378  obj_loss: 0.1488  noobj_loss: 0.0682  bbox_loss: 0.0184  cls_loss: 0.0629  \n",
      "<<<iteration:[480/525] - total_loss: 0.3737  obj_loss: 0.1473  noobj_loss: 0.0702  bbox_loss: 0.0248  cls_loss: 0.0674  \n",
      "<<<iteration:[500/525] - total_loss: 0.3463  obj_loss: 0.1243  noobj_loss: 0.0699  bbox_loss: 0.0214  cls_loss: 0.0800  \n",
      "<<<iteration:[520/525] - total_loss: 0.3667  obj_loss: 0.1340  noobj_loss: 0.0721  bbox_loss: 0.0226  cls_loss: 0.0836  \n",
      "\n",
      "epoch:9/100 - Train Loss: 0.3734, Val Loss: 0.3547\n",
      "\n",
      "<<<iteration:[20/525] - total_loss: 0.3900  obj_loss: 0.1456  noobj_loss: 0.0752  bbox_loss: 0.0225  cls_loss: 0.0941  \n",
      "<<<iteration:[40/525] - total_loss: 0.3096  obj_loss: 0.1235  noobj_loss: 0.0669  bbox_loss: 0.0186  cls_loss: 0.0598  \n",
      "<<<iteration:[60/525] - total_loss: 0.3474  obj_loss: 0.1188  noobj_loss: 0.0704  bbox_loss: 0.0241  cls_loss: 0.0729  \n",
      "<<<iteration:[80/525] - total_loss: 0.3492  obj_loss: 0.1295  noobj_loss: 0.0663  bbox_loss: 0.0226  cls_loss: 0.0735  \n",
      "<<<iteration:[100/525] - total_loss: 0.3504  obj_loss: 0.1315  noobj_loss: 0.0770  bbox_loss: 0.0192  cls_loss: 0.0844  \n",
      "<<<iteration:[120/525] - total_loss: 0.3571  obj_loss: 0.1400  noobj_loss: 0.0683  bbox_loss: 0.0246  cls_loss: 0.0601  \n",
      "<<<iteration:[140/525] - total_loss: 0.3511  obj_loss: 0.1301  noobj_loss: 0.0662  bbox_loss: 0.0241  cls_loss: 0.0674  \n",
      "<<<iteration:[160/525] - total_loss: 0.3522  obj_loss: 0.1150  noobj_loss: 0.0811  bbox_loss: 0.0251  cls_loss: 0.0710  \n",
      "<<<iteration:[180/525] - total_loss: 0.3794  obj_loss: 0.1297  noobj_loss: 0.0676  bbox_loss: 0.0227  cls_loss: 0.1022  \n",
      "<<<iteration:[200/525] - total_loss: 0.3738  obj_loss: 0.1372  noobj_loss: 0.0651  bbox_loss: 0.0195  cls_loss: 0.1065  \n",
      "<<<iteration:[220/525] - total_loss: 0.3249  obj_loss: 0.1266  noobj_loss: 0.0623  bbox_loss: 0.0199  cls_loss: 0.0678  \n",
      "<<<iteration:[240/525] - total_loss: 0.3497  obj_loss: 0.1076  noobj_loss: 0.0677  bbox_loss: 0.0251  cls_loss: 0.0828  \n",
      "<<<iteration:[260/525] - total_loss: 0.3287  obj_loss: 0.1319  noobj_loss: 0.0687  bbox_loss: 0.0205  cls_loss: 0.0597  \n",
      "<<<iteration:[280/525] - total_loss: 0.3477  obj_loss: 0.1347  noobj_loss: 0.0658  bbox_loss: 0.0203  cls_loss: 0.0783  \n",
      "<<<iteration:[300/525] - total_loss: 0.3605  obj_loss: 0.1427  noobj_loss: 0.0745  bbox_loss: 0.0203  cls_loss: 0.0791  \n",
      "<<<iteration:[320/525] - total_loss: 0.3597  obj_loss: 0.1245  noobj_loss: 0.0694  bbox_loss: 0.0249  cls_loss: 0.0761  \n",
      "<<<iteration:[340/525] - total_loss: 0.3341  obj_loss: 0.1325  noobj_loss: 0.0688  bbox_loss: 0.0211  cls_loss: 0.0619  \n",
      "<<<iteration:[360/525] - total_loss: 0.3881  obj_loss: 0.1330  noobj_loss: 0.0738  bbox_loss: 0.0243  cls_loss: 0.0967  \n",
      "<<<iteration:[380/525] - total_loss: 0.3573  obj_loss: 0.1472  noobj_loss: 0.0657  bbox_loss: 0.0216  cls_loss: 0.0691  \n",
      "<<<iteration:[400/525] - total_loss: 0.4222  obj_loss: 0.1289  noobj_loss: 0.0652  bbox_loss: 0.0288  cls_loss: 0.1165  \n",
      "<<<iteration:[420/525] - total_loss: 0.3292  obj_loss: 0.1194  noobj_loss: 0.0652  bbox_loss: 0.0231  cls_loss: 0.0617  \n",
      "<<<iteration:[440/525] - total_loss: 0.3496  obj_loss: 0.1313  noobj_loss: 0.0632  bbox_loss: 0.0218  cls_loss: 0.0775  \n",
      "<<<iteration:[460/525] - total_loss: 0.3448  obj_loss: 0.1299  noobj_loss: 0.0697  bbox_loss: 0.0218  cls_loss: 0.0710  \n",
      "<<<iteration:[480/525] - total_loss: 0.3503  obj_loss: 0.1381  noobj_loss: 0.0651  bbox_loss: 0.0191  cls_loss: 0.0841  \n",
      "<<<iteration:[500/525] - total_loss: 0.3900  obj_loss: 0.1531  noobj_loss: 0.0678  bbox_loss: 0.0206  cls_loss: 0.1002  \n",
      "<<<iteration:[520/525] - total_loss: 0.4006  obj_loss: 0.1324  noobj_loss: 0.0810  bbox_loss: 0.0267  cls_loss: 0.0944  \n",
      "\n",
      "epoch:10/100 - Train Loss: 0.3578, Val Loss: 0.3372\n",
      "\n",
      "<<<iteration:[20/525] - total_loss: 0.3582  obj_loss: 0.1484  noobj_loss: 0.0638  bbox_loss: 0.0211  cls_loss: 0.0722  \n",
      "<<<iteration:[40/525] - total_loss: 0.3677  obj_loss: 0.1449  noobj_loss: 0.0620  bbox_loss: 0.0220  cls_loss: 0.0820  \n",
      "<<<iteration:[60/525] - total_loss: 0.3662  obj_loss: 0.1277  noobj_loss: 0.0683  bbox_loss: 0.0234  cls_loss: 0.0871  \n",
      "<<<iteration:[80/525] - total_loss: 0.3740  obj_loss: 0.1526  noobj_loss: 0.0671  bbox_loss: 0.0208  cls_loss: 0.0839  \n",
      "<<<iteration:[100/525] - total_loss: 0.3504  obj_loss: 0.1241  noobj_loss: 0.0723  bbox_loss: 0.0223  cls_loss: 0.0786  \n",
      "<<<iteration:[120/525] - total_loss: 0.3125  obj_loss: 0.1291  noobj_loss: 0.0655  bbox_loss: 0.0192  cls_loss: 0.0545  \n",
      "<<<iteration:[140/525] - total_loss: 0.3633  obj_loss: 0.1661  noobj_loss: 0.0681  bbox_loss: 0.0178  cls_loss: 0.0740  \n",
      "<<<iteration:[160/525] - total_loss: 0.3649  obj_loss: 0.1390  noobj_loss: 0.0630  bbox_loss: 0.0220  cls_loss: 0.0845  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<<<iteration:[180/525] - total_loss: 0.3638  obj_loss: 0.1405  noobj_loss: 0.0648  bbox_loss: 0.0184  cls_loss: 0.0991  \n",
      "<<<iteration:[200/525] - total_loss: 0.3595  obj_loss: 0.1377  noobj_loss: 0.0668  bbox_loss: 0.0208  cls_loss: 0.0846  \n",
      "<<<iteration:[220/525] - total_loss: 0.3314  obj_loss: 0.1422  noobj_loss: 0.0723  bbox_loss: 0.0201  cls_loss: 0.0524  \n",
      "<<<iteration:[240/525] - total_loss: 0.3743  obj_loss: 0.1403  noobj_loss: 0.0691  bbox_loss: 0.0224  cls_loss: 0.0876  \n",
      "<<<iteration:[260/525] - total_loss: 0.3443  obj_loss: 0.1120  noobj_loss: 0.0675  bbox_loss: 0.0209  cls_loss: 0.0940  \n",
      "<<<iteration:[280/525] - total_loss: 0.3800  obj_loss: 0.1356  noobj_loss: 0.0653  bbox_loss: 0.0237  cls_loss: 0.0932  \n",
      "<<<iteration:[300/525] - total_loss: 0.3552  obj_loss: 0.1217  noobj_loss: 0.0662  bbox_loss: 0.0276  cls_loss: 0.0626  \n",
      "<<<iteration:[320/525] - total_loss: 0.3246  obj_loss: 0.1337  noobj_loss: 0.0664  bbox_loss: 0.0176  cls_loss: 0.0697  \n",
      "<<<iteration:[340/525] - total_loss: 0.3817  obj_loss: 0.1535  noobj_loss: 0.0691  bbox_loss: 0.0210  cls_loss: 0.0887  \n",
      "<<<iteration:[360/525] - total_loss: 0.3525  obj_loss: 0.1419  noobj_loss: 0.0661  bbox_loss: 0.0239  cls_loss: 0.0580  \n",
      "<<<iteration:[380/525] - total_loss: 0.3705  obj_loss: 0.1351  noobj_loss: 0.0680  bbox_loss: 0.0229  cls_loss: 0.0868  \n",
      "<<<iteration:[400/525] - total_loss: 0.3642  obj_loss: 0.1506  noobj_loss: 0.0626  bbox_loss: 0.0181  cls_loss: 0.0918  \n",
      "<<<iteration:[420/525] - total_loss: 0.3442  obj_loss: 0.1268  noobj_loss: 0.0642  bbox_loss: 0.0217  cls_loss: 0.0769  \n",
      "<<<iteration:[440/525] - total_loss: 0.3953  obj_loss: 0.1575  noobj_loss: 0.0665  bbox_loss: 0.0205  cls_loss: 0.1018  \n",
      "<<<iteration:[460/525] - total_loss: 0.3625  obj_loss: 0.1490  noobj_loss: 0.0684  bbox_loss: 0.0169  cls_loss: 0.0948  \n",
      "<<<iteration:[480/525] - total_loss: 0.3517  obj_loss: 0.1514  noobj_loss: 0.0668  bbox_loss: 0.0177  cls_loss: 0.0784  \n",
      "<<<iteration:[500/525] - total_loss: 0.3378  obj_loss: 0.1396  noobj_loss: 0.0645  bbox_loss: 0.0212  cls_loss: 0.0600  \n",
      "<<<iteration:[520/525] - total_loss: 0.3286  obj_loss: 0.1413  noobj_loss: 0.0648  bbox_loss: 0.0178  cls_loss: 0.0661  \n",
      "\n",
      "epoch:11/100 - Train Loss: 0.3565, Val Loss: 0.3384\n",
      "\n",
      "<<<iteration:[20/525] - total_loss: 0.3965  obj_loss: 0.1476  noobj_loss: 0.0705  bbox_loss: 0.0240  cls_loss: 0.0938  \n",
      "<<<iteration:[40/525] - total_loss: 0.3162  obj_loss: 0.1282  noobj_loss: 0.0610  bbox_loss: 0.0191  cls_loss: 0.0619  \n",
      "<<<iteration:[60/525] - total_loss: 0.3449  obj_loss: 0.1364  noobj_loss: 0.0650  bbox_loss: 0.0192  cls_loss: 0.0798  \n",
      "<<<iteration:[80/525] - total_loss: 0.3670  obj_loss: 0.1405  noobj_loss: 0.0624  bbox_loss: 0.0228  cls_loss: 0.0812  \n",
      "<<<iteration:[100/525] - total_loss: 0.3531  obj_loss: 0.1503  noobj_loss: 0.0649  bbox_loss: 0.0204  cls_loss: 0.0685  \n",
      "<<<iteration:[120/525] - total_loss: 0.3479  obj_loss: 0.1610  noobj_loss: 0.0669  bbox_loss: 0.0179  cls_loss: 0.0640  \n",
      "<<<iteration:[140/525] - total_loss: 0.3521  obj_loss: 0.1472  noobj_loss: 0.0692  bbox_loss: 0.0192  cls_loss: 0.0740  \n",
      "<<<iteration:[160/525] - total_loss: 0.3855  obj_loss: 0.1468  noobj_loss: 0.0701  bbox_loss: 0.0219  cls_loss: 0.0943  \n",
      "<<<iteration:[180/525] - total_loss: 0.3197  obj_loss: 0.1280  noobj_loss: 0.0664  bbox_loss: 0.0185  cls_loss: 0.0658  \n",
      "<<<iteration:[200/525] - total_loss: 0.3908  obj_loss: 0.1500  noobj_loss: 0.0763  bbox_loss: 0.0210  cls_loss: 0.0974  \n",
      "<<<iteration:[220/525] - total_loss: 0.3169  obj_loss: 0.1457  noobj_loss: 0.0632  bbox_loss: 0.0181  cls_loss: 0.0492  \n",
      "<<<iteration:[240/525] - total_loss: 0.3153  obj_loss: 0.1439  noobj_loss: 0.0642  bbox_loss: 0.0175  cls_loss: 0.0520  \n",
      "<<<iteration:[260/525] - total_loss: 0.3697  obj_loss: 0.1603  noobj_loss: 0.0700  bbox_loss: 0.0182  cls_loss: 0.0833  \n",
      "<<<iteration:[280/525] - total_loss: 0.3430  obj_loss: 0.1516  noobj_loss: 0.0608  bbox_loss: 0.0171  cls_loss: 0.0753  \n",
      "<<<iteration:[300/525] - total_loss: 0.3482  obj_loss: 0.1386  noobj_loss: 0.0656  bbox_loss: 0.0185  cls_loss: 0.0846  \n",
      "<<<iteration:[320/525] - total_loss: 0.3424  obj_loss: 0.1378  noobj_loss: 0.0699  bbox_loss: 0.0202  cls_loss: 0.0686  \n",
      "<<<iteration:[340/525] - total_loss: 0.3254  obj_loss: 0.1212  noobj_loss: 0.0639  bbox_loss: 0.0213  cls_loss: 0.0657  \n",
      "<<<iteration:[360/525] - total_loss: 0.3534  obj_loss: 0.1304  noobj_loss: 0.0680  bbox_loss: 0.0224  cls_loss: 0.0770  \n",
      "<<<iteration:[380/525] - total_loss: 0.3172  obj_loss: 0.1343  noobj_loss: 0.0643  bbox_loss: 0.0180  cls_loss: 0.0608  \n",
      "<<<iteration:[400/525] - total_loss: 0.3534  obj_loss: 0.1486  noobj_loss: 0.0642  bbox_loss: 0.0158  cls_loss: 0.0937  \n",
      "<<<iteration:[420/525] - total_loss: 0.3208  obj_loss: 0.1399  noobj_loss: 0.0662  bbox_loss: 0.0172  cls_loss: 0.0618  \n",
      "<<<iteration:[440/525] - total_loss: 0.3516  obj_loss: 0.1293  noobj_loss: 0.0694  bbox_loss: 0.0215  cls_loss: 0.0802  \n",
      "<<<iteration:[460/525] - total_loss: 0.3277  obj_loss: 0.1434  noobj_loss: 0.0634  bbox_loss: 0.0212  cls_loss: 0.0466  \n",
      "<<<iteration:[480/525] - total_loss: 0.3339  obj_loss: 0.1425  noobj_loss: 0.0620  bbox_loss: 0.0206  cls_loss: 0.0572  \n",
      "<<<iteration:[500/525] - total_loss: 0.3221  obj_loss: 0.1522  noobj_loss: 0.0642  bbox_loss: 0.0161  cls_loss: 0.0576  \n",
      "<<<iteration:[520/525] - total_loss: 0.3655  obj_loss: 0.1369  noobj_loss: 0.0650  bbox_loss: 0.0217  cls_loss: 0.0874  \n",
      "\n",
      "epoch:12/100 - Train Loss: 0.3449, Val Loss: 0.3207\n",
      "\n",
      "<<<iteration:[20/525] - total_loss: 0.3366  obj_loss: 0.1481  noobj_loss: 0.0726  bbox_loss: 0.0188  cls_loss: 0.0583  \n",
      "<<<iteration:[40/525] - total_loss: 0.3947  obj_loss: 0.1574  noobj_loss: 0.0677  bbox_loss: 0.0229  cls_loss: 0.0887  \n",
      "<<<iteration:[60/525] - total_loss: 0.3790  obj_loss: 0.1399  noobj_loss: 0.0651  bbox_loss: 0.0198  cls_loss: 0.1075  \n",
      "<<<iteration:[80/525] - total_loss: 0.3177  obj_loss: 0.1436  noobj_loss: 0.0611  bbox_loss: 0.0192  cls_loss: 0.0474  \n",
      "<<<iteration:[100/525] - total_loss: 0.3429  obj_loss: 0.1430  noobj_loss: 0.0662  bbox_loss: 0.0177  cls_loss: 0.0782  \n",
      "<<<iteration:[120/525] - total_loss: 0.3559  obj_loss: 0.1548  noobj_loss: 0.0615  bbox_loss: 0.0228  cls_loss: 0.0562  \n",
      "<<<iteration:[140/525] - total_loss: 0.3273  obj_loss: 0.1288  noobj_loss: 0.0680  bbox_loss: 0.0182  cls_loss: 0.0737  \n",
      "<<<iteration:[160/525] - total_loss: 0.3406  obj_loss: 0.1440  noobj_loss: 0.0608  bbox_loss: 0.0170  cls_loss: 0.0813  \n",
      "<<<iteration:[180/525] - total_loss: 0.3743  obj_loss: 0.1660  noobj_loss: 0.0679  bbox_loss: 0.0209  cls_loss: 0.0698  \n",
      "<<<iteration:[200/525] - total_loss: 0.3566  obj_loss: 0.1534  noobj_loss: 0.0669  bbox_loss: 0.0194  cls_loss: 0.0728  \n",
      "<<<iteration:[220/525] - total_loss: 0.3066  obj_loss: 0.1434  noobj_loss: 0.0649  bbox_loss: 0.0161  cls_loss: 0.0504  \n",
      "<<<iteration:[240/525] - total_loss: 0.3340  obj_loss: 0.1349  noobj_loss: 0.0641  bbox_loss: 0.0181  cls_loss: 0.0766  \n",
      "<<<iteration:[260/525] - total_loss: 0.3578  obj_loss: 0.1562  noobj_loss: 0.0648  bbox_loss: 0.0174  cls_loss: 0.0824  \n",
      "<<<iteration:[280/525] - total_loss: 0.3290  obj_loss: 0.1507  noobj_loss: 0.0652  bbox_loss: 0.0169  cls_loss: 0.0613  \n",
      "<<<iteration:[300/525] - total_loss: 0.3411  obj_loss: 0.1590  noobj_loss: 0.0676  bbox_loss: 0.0176  cls_loss: 0.0600  \n",
      "<<<iteration:[320/525] - total_loss: 0.3391  obj_loss: 0.1638  noobj_loss: 0.0648  bbox_loss: 0.0154  cls_loss: 0.0661  \n",
      "<<<iteration:[340/525] - total_loss: 0.3221  obj_loss: 0.1277  noobj_loss: 0.0624  bbox_loss: 0.0213  cls_loss: 0.0567  \n",
      "<<<iteration:[360/525] - total_loss: 0.3258  obj_loss: 0.1417  noobj_loss: 0.0620  bbox_loss: 0.0182  cls_loss: 0.0620  \n",
      "<<<iteration:[380/525] - total_loss: 0.3382  obj_loss: 0.1265  noobj_loss: 0.0642  bbox_loss: 0.0202  cls_loss: 0.0784  \n",
      "<<<iteration:[400/525] - total_loss: 0.3461  obj_loss: 0.1512  noobj_loss: 0.0632  bbox_loss: 0.0178  cls_loss: 0.0744  \n",
      "<<<iteration:[420/525] - total_loss: 0.3549  obj_loss: 0.1400  noobj_loss: 0.0639  bbox_loss: 0.0203  cls_loss: 0.0812  \n",
      "<<<iteration:[440/525] - total_loss: 0.3279  obj_loss: 0.1519  noobj_loss: 0.0619  bbox_loss: 0.0167  cls_loss: 0.0613  \n",
      "<<<iteration:[460/525] - total_loss: 0.3007  obj_loss: 0.1383  noobj_loss: 0.0689  bbox_loss: 0.0158  cls_loss: 0.0488  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<<<iteration:[480/525] - total_loss: 0.3027  obj_loss: 0.1389  noobj_loss: 0.0644  bbox_loss: 0.0150  cls_loss: 0.0564  \n",
      "<<<iteration:[500/525] - total_loss: 0.3608  obj_loss: 0.1575  noobj_loss: 0.0639  bbox_loss: 0.0160  cls_loss: 0.0914  \n",
      "<<<iteration:[520/525] - total_loss: 0.3389  obj_loss: 0.1351  noobj_loss: 0.0626  bbox_loss: 0.0191  cls_loss: 0.0771  \n",
      "\n",
      "epoch:13/100 - Train Loss: 0.3398, Val Loss: 0.3266\n",
      "\n",
      "<<<iteration:[20/525] - total_loss: 0.3324  obj_loss: 0.1347  noobj_loss: 0.0689  bbox_loss: 0.0175  cls_loss: 0.0758  \n",
      "<<<iteration:[40/525] - total_loss: 0.3260  obj_loss: 0.1461  noobj_loss: 0.0666  bbox_loss: 0.0178  cls_loss: 0.0578  \n",
      "<<<iteration:[60/525] - total_loss: 0.3331  obj_loss: 0.1543  noobj_loss: 0.0648  bbox_loss: 0.0180  cls_loss: 0.0565  \n",
      "<<<iteration:[80/525] - total_loss: 0.3357  obj_loss: 0.1428  noobj_loss: 0.0666  bbox_loss: 0.0193  cls_loss: 0.0629  \n",
      "<<<iteration:[100/525] - total_loss: 0.3358  obj_loss: 0.1585  noobj_loss: 0.0634  bbox_loss: 0.0211  cls_loss: 0.0403  \n",
      "<<<iteration:[120/525] - total_loss: 0.3462  obj_loss: 0.1522  noobj_loss: 0.0642  bbox_loss: 0.0162  cls_loss: 0.0809  \n",
      "<<<iteration:[140/525] - total_loss: 0.3352  obj_loss: 0.1559  noobj_loss: 0.0622  bbox_loss: 0.0162  cls_loss: 0.0671  \n",
      "<<<iteration:[160/525] - total_loss: 0.3505  obj_loss: 0.1343  noobj_loss: 0.0659  bbox_loss: 0.0193  cls_loss: 0.0869  \n",
      "<<<iteration:[180/525] - total_loss: 0.3706  obj_loss: 0.1498  noobj_loss: 0.0620  bbox_loss: 0.0214  cls_loss: 0.0825  \n",
      "<<<iteration:[200/525] - total_loss: 0.3569  obj_loss: 0.1560  noobj_loss: 0.0630  bbox_loss: 0.0160  cls_loss: 0.0896  \n",
      "<<<iteration:[220/525] - total_loss: 0.3289  obj_loss: 0.1619  noobj_loss: 0.0676  bbox_loss: 0.0156  cls_loss: 0.0554  \n",
      "<<<iteration:[240/525] - total_loss: 0.3338  obj_loss: 0.1364  noobj_loss: 0.0668  bbox_loss: 0.0204  cls_loss: 0.0622  \n",
      "<<<iteration:[260/525] - total_loss: 0.3348  obj_loss: 0.1527  noobj_loss: 0.0639  bbox_loss: 0.0161  cls_loss: 0.0696  \n",
      "<<<iteration:[280/525] - total_loss: 0.3364  obj_loss: 0.1601  noobj_loss: 0.0637  bbox_loss: 0.0168  cls_loss: 0.0603  \n",
      "<<<iteration:[300/525] - total_loss: 0.3307  obj_loss: 0.1493  noobj_loss: 0.0629  bbox_loss: 0.0163  cls_loss: 0.0687  \n",
      "<<<iteration:[320/525] - total_loss: 0.3106  obj_loss: 0.1460  noobj_loss: 0.0636  bbox_loss: 0.0135  cls_loss: 0.0651  \n",
      "<<<iteration:[340/525] - total_loss: 0.3105  obj_loss: 0.1422  noobj_loss: 0.0710  bbox_loss: 0.0170  cls_loss: 0.0477  \n",
      "<<<iteration:[360/525] - total_loss: 0.3552  obj_loss: 0.1651  noobj_loss: 0.0615  bbox_loss: 0.0168  cls_loss: 0.0755  \n",
      "<<<iteration:[380/525] - total_loss: 0.3251  obj_loss: 0.1410  noobj_loss: 0.0673  bbox_loss: 0.0159  cls_loss: 0.0708  \n",
      "<<<iteration:[400/525] - total_loss: 0.4134  obj_loss: 0.1195  noobj_loss: 0.0653  bbox_loss: 0.0392  cls_loss: 0.0653  \n",
      "<<<iteration:[420/525] - total_loss: 0.3776  obj_loss: 0.1257  noobj_loss: 0.0637  bbox_loss: 0.0286  cls_loss: 0.0772  \n",
      "<<<iteration:[440/525] - total_loss: 0.3504  obj_loss: 0.1246  noobj_loss: 0.0644  bbox_loss: 0.0228  cls_loss: 0.0794  \n",
      "<<<iteration:[460/525] - total_loss: 0.3373  obj_loss: 0.1481  noobj_loss: 0.0652  bbox_loss: 0.0180  cls_loss: 0.0664  \n",
      "<<<iteration:[480/525] - total_loss: 0.3265  obj_loss: 0.1385  noobj_loss: 0.0704  bbox_loss: 0.0207  cls_loss: 0.0492  \n",
      "<<<iteration:[500/525] - total_loss: 0.3101  obj_loss: 0.1352  noobj_loss: 0.0654  bbox_loss: 0.0186  cls_loss: 0.0491  \n",
      "<<<iteration:[520/525] - total_loss: 0.3496  obj_loss: 0.1483  noobj_loss: 0.0677  bbox_loss: 0.0198  cls_loss: 0.0685  \n",
      "\n",
      "epoch:14/100 - Train Loss: 0.3399, Val Loss: 0.3644\n",
      "\n",
      "<<<iteration:[20/525] - total_loss: 0.3630  obj_loss: 0.1368  noobj_loss: 0.0707  bbox_loss: 0.0245  cls_loss: 0.0684  \n",
      "<<<iteration:[40/525] - total_loss: 0.3326  obj_loss: 0.1424  noobj_loss: 0.0684  bbox_loss: 0.0193  cls_loss: 0.0594  \n",
      "<<<iteration:[60/525] - total_loss: 0.3790  obj_loss: 0.1397  noobj_loss: 0.0601  bbox_loss: 0.0277  cls_loss: 0.0705  \n",
      "<<<iteration:[80/525] - total_loss: 0.3366  obj_loss: 0.1393  noobj_loss: 0.0653  bbox_loss: 0.0202  cls_loss: 0.0634  \n",
      "<<<iteration:[100/525] - total_loss: 0.3593  obj_loss: 0.1499  noobj_loss: 0.0662  bbox_loss: 0.0201  cls_loss: 0.0758  \n",
      "<<<iteration:[120/525] - total_loss: 0.3372  obj_loss: 0.1358  noobj_loss: 0.0669  bbox_loss: 0.0187  cls_loss: 0.0744  \n",
      "<<<iteration:[140/525] - total_loss: 0.3449  obj_loss: 0.1310  noobj_loss: 0.0651  bbox_loss: 0.0255  cls_loss: 0.0541  \n",
      "<<<iteration:[160/525] - total_loss: 0.3609  obj_loss: 0.1453  noobj_loss: 0.0680  bbox_loss: 0.0219  cls_loss: 0.0723  \n",
      "<<<iteration:[180/525] - total_loss: 0.3841  obj_loss: 0.1613  noobj_loss: 0.0627  bbox_loss: 0.0197  cls_loss: 0.0930  \n",
      "<<<iteration:[200/525] - total_loss: 0.3430  obj_loss: 0.1459  noobj_loss: 0.0665  bbox_loss: 0.0194  cls_loss: 0.0670  \n",
      "<<<iteration:[220/525] - total_loss: 0.3416  obj_loss: 0.1624  noobj_loss: 0.0665  bbox_loss: 0.0196  cls_loss: 0.0477  \n",
      "<<<iteration:[240/525] - total_loss: 0.3319  obj_loss: 0.1388  noobj_loss: 0.0721  bbox_loss: 0.0187  cls_loss: 0.0638  \n",
      "<<<iteration:[260/525] - total_loss: 0.3431  obj_loss: 0.1616  noobj_loss: 0.0645  bbox_loss: 0.0176  cls_loss: 0.0615  \n",
      "<<<iteration:[280/525] - total_loss: 0.3614  obj_loss: 0.1712  noobj_loss: 0.0617  bbox_loss: 0.0198  cls_loss: 0.0605  \n",
      "<<<iteration:[300/525] - total_loss: 0.3036  obj_loss: 0.1299  noobj_loss: 0.0682  bbox_loss: 0.0171  cls_loss: 0.0540  \n",
      "<<<iteration:[320/525] - total_loss: 0.3081  obj_loss: 0.1209  noobj_loss: 0.0640  bbox_loss: 0.0173  cls_loss: 0.0688  \n",
      "<<<iteration:[340/525] - total_loss: 0.3148  obj_loss: 0.1420  noobj_loss: 0.0624  bbox_loss: 0.0185  cls_loss: 0.0493  \n",
      "<<<iteration:[360/525] - total_loss: 0.3588  obj_loss: 0.1562  noobj_loss: 0.0631  bbox_loss: 0.0196  cls_loss: 0.0730  \n",
      "<<<iteration:[380/525] - total_loss: 0.3279  obj_loss: 0.1378  noobj_loss: 0.0622  bbox_loss: 0.0195  cls_loss: 0.0613  \n",
      "<<<iteration:[400/525] - total_loss: 0.3132  obj_loss: 0.1464  noobj_loss: 0.0608  bbox_loss: 0.0159  cls_loss: 0.0567  \n",
      "<<<iteration:[420/525] - total_loss: 0.3703  obj_loss: 0.1463  noobj_loss: 0.0674  bbox_loss: 0.0210  cls_loss: 0.0851  \n",
      "<<<iteration:[440/525] - total_loss: 0.3627  obj_loss: 0.1650  noobj_loss: 0.0610  bbox_loss: 0.0152  cls_loss: 0.0914  \n",
      "<<<iteration:[460/525] - total_loss: 0.3373  obj_loss: 0.1554  noobj_loss: 0.0628  bbox_loss: 0.0163  cls_loss: 0.0691  \n",
      "<<<iteration:[480/525] - total_loss: 0.3288  obj_loss: 0.1553  noobj_loss: 0.0641  bbox_loss: 0.0191  cls_loss: 0.0459  \n",
      "<<<iteration:[500/525] - total_loss: 0.3458  obj_loss: 0.1404  noobj_loss: 0.0621  bbox_loss: 0.0185  cls_loss: 0.0818  \n",
      "<<<iteration:[520/525] - total_loss: 0.3123  obj_loss: 0.1359  noobj_loss: 0.0639  bbox_loss: 0.0186  cls_loss: 0.0513  \n",
      "\n",
      "epoch:15/100 - Train Loss: 0.3420, Val Loss: 0.3339\n",
      "\n",
      "<<<iteration:[20/525] - total_loss: 0.3283  obj_loss: 0.1458  noobj_loss: 0.0645  bbox_loss: 0.0175  cls_loss: 0.0629  \n",
      "<<<iteration:[40/525] - total_loss: 0.3429  obj_loss: 0.1630  noobj_loss: 0.0681  bbox_loss: 0.0152  cls_loss: 0.0700  \n",
      "<<<iteration:[60/525] - total_loss: 0.3173  obj_loss: 0.1421  noobj_loss: 0.0661  bbox_loss: 0.0175  cls_loss: 0.0548  \n",
      "<<<iteration:[80/525] - total_loss: 0.3535  obj_loss: 0.1557  noobj_loss: 0.0691  bbox_loss: 0.0210  cls_loss: 0.0583  \n",
      "<<<iteration:[100/525] - total_loss: 0.3024  obj_loss: 0.1413  noobj_loss: 0.0649  bbox_loss: 0.0161  cls_loss: 0.0483  \n",
      "<<<iteration:[120/525] - total_loss: 0.3590  obj_loss: 0.1523  noobj_loss: 0.0656  bbox_loss: 0.0190  cls_loss: 0.0789  \n",
      "<<<iteration:[140/525] - total_loss: 0.3013  obj_loss: 0.1298  noobj_loss: 0.0608  bbox_loss: 0.0174  cls_loss: 0.0541  \n",
      "<<<iteration:[160/525] - total_loss: 0.3469  obj_loss: 0.1479  noobj_loss: 0.0675  bbox_loss: 0.0187  cls_loss: 0.0718  \n",
      "<<<iteration:[180/525] - total_loss: 0.3300  obj_loss: 0.1582  noobj_loss: 0.0613  bbox_loss: 0.0183  cls_loss: 0.0498  \n",
      "<<<iteration:[200/525] - total_loss: 0.3167  obj_loss: 0.1602  noobj_loss: 0.0651  bbox_loss: 0.0147  cls_loss: 0.0503  \n",
      "<<<iteration:[220/525] - total_loss: 0.3177  obj_loss: 0.1371  noobj_loss: 0.0616  bbox_loss: 0.0187  cls_loss: 0.0564  \n",
      "<<<iteration:[240/525] - total_loss: 0.3133  obj_loss: 0.1429  noobj_loss: 0.0591  bbox_loss: 0.0149  cls_loss: 0.0662  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<<<iteration:[260/525] - total_loss: 0.3632  obj_loss: 0.1698  noobj_loss: 0.0648  bbox_loss: 0.0184  cls_loss: 0.0689  \n",
      "<<<iteration:[280/525] - total_loss: 0.3302  obj_loss: 0.1365  noobj_loss: 0.0600  bbox_loss: 0.0198  cls_loss: 0.0648  \n",
      "<<<iteration:[300/525] - total_loss: 0.2942  obj_loss: 0.1419  noobj_loss: 0.0622  bbox_loss: 0.0152  cls_loss: 0.0453  \n",
      "<<<iteration:[320/525] - total_loss: 0.3276  obj_loss: 0.1460  noobj_loss: 0.0613  bbox_loss: 0.0167  cls_loss: 0.0676  \n",
      "<<<iteration:[340/525] - total_loss: 0.3289  obj_loss: 0.1446  noobj_loss: 0.0673  bbox_loss: 0.0177  cls_loss: 0.0623  \n",
      "<<<iteration:[360/525] - total_loss: 0.3502  obj_loss: 0.1619  noobj_loss: 0.0690  bbox_loss: 0.0170  cls_loss: 0.0690  \n",
      "<<<iteration:[380/525] - total_loss: 0.3595  obj_loss: 0.1466  noobj_loss: 0.0664  bbox_loss: 0.0216  cls_loss: 0.0718  \n",
      "<<<iteration:[400/525] - total_loss: 0.3324  obj_loss: 0.1812  noobj_loss: 0.0618  bbox_loss: 0.0158  cls_loss: 0.0415  \n",
      "<<<iteration:[420/525] - total_loss: 0.3119  obj_loss: 0.1390  noobj_loss: 0.0696  bbox_loss: 0.0157  cls_loss: 0.0597  \n",
      "<<<iteration:[440/525] - total_loss: 0.3246  obj_loss: 0.1550  noobj_loss: 0.0690  bbox_loss: 0.0169  cls_loss: 0.0507  \n",
      "<<<iteration:[460/525] - total_loss: 0.3295  obj_loss: 0.1451  noobj_loss: 0.0670  bbox_loss: 0.0165  cls_loss: 0.0684  \n",
      "<<<iteration:[480/525] - total_loss: 0.3006  obj_loss: 0.1400  noobj_loss: 0.0677  bbox_loss: 0.0148  cls_loss: 0.0527  \n",
      "<<<iteration:[500/525] - total_loss: 0.3283  obj_loss: 0.1445  noobj_loss: 0.0669  bbox_loss: 0.0172  cls_loss: 0.0644  \n",
      "<<<iteration:[520/525] - total_loss: 0.3115  obj_loss: 0.1610  noobj_loss: 0.0636  bbox_loss: 0.0132  cls_loss: 0.0527  \n",
      "\n",
      "epoch:16/100 - Train Loss: 0.3267, Val Loss: 0.3148\n",
      "\n",
      "<<<iteration:[20/525] - total_loss: 0.3333  obj_loss: 0.1441  noobj_loss: 0.0642  bbox_loss: 0.0193  cls_loss: 0.0604  \n",
      "<<<iteration:[40/525] - total_loss: 0.3356  obj_loss: 0.1597  noobj_loss: 0.0657  bbox_loss: 0.0184  cls_loss: 0.0510  \n",
      "<<<iteration:[60/525] - total_loss: 0.3817  obj_loss: 0.1536  noobj_loss: 0.0655  bbox_loss: 0.0194  cls_loss: 0.0984  \n",
      "<<<iteration:[80/525] - total_loss: 0.3219  obj_loss: 0.1508  noobj_loss: 0.0664  bbox_loss: 0.0160  cls_loss: 0.0579  \n",
      "<<<iteration:[100/525] - total_loss: 0.3480  obj_loss: 0.1476  noobj_loss: 0.0653  bbox_loss: 0.0184  cls_loss: 0.0760  \n",
      "<<<iteration:[120/525] - total_loss: 0.3207  obj_loss: 0.1518  noobj_loss: 0.0630  bbox_loss: 0.0163  cls_loss: 0.0559  \n",
      "<<<iteration:[140/525] - total_loss: 0.3501  obj_loss: 0.1565  noobj_loss: 0.0654  bbox_loss: 0.0158  cls_loss: 0.0822  \n",
      "<<<iteration:[160/525] - total_loss: 0.3022  obj_loss: 0.1428  noobj_loss: 0.0622  bbox_loss: 0.0160  cls_loss: 0.0481  \n",
      "<<<iteration:[180/525] - total_loss: 0.2935  obj_loss: 0.1378  noobj_loss: 0.0640  bbox_loss: 0.0168  cls_loss: 0.0396  \n",
      "<<<iteration:[200/525] - total_loss: 0.2992  obj_loss: 0.1585  noobj_loss: 0.0610  bbox_loss: 0.0133  cls_loss: 0.0434  \n",
      "<<<iteration:[220/525] - total_loss: 0.3165  obj_loss: 0.1304  noobj_loss: 0.0587  bbox_loss: 0.0180  cls_loss: 0.0670  \n",
      "<<<iteration:[240/525] - total_loss: 0.3203  obj_loss: 0.1506  noobj_loss: 0.0716  bbox_loss: 0.0166  cls_loss: 0.0508  \n",
      "<<<iteration:[260/525] - total_loss: 0.2890  obj_loss: 0.1435  noobj_loss: 0.0627  bbox_loss: 0.0136  cls_loss: 0.0461  \n",
      "<<<iteration:[280/525] - total_loss: 0.3136  obj_loss: 0.1631  noobj_loss: 0.0703  bbox_loss: 0.0149  cls_loss: 0.0408  \n",
      "<<<iteration:[300/525] - total_loss: 0.2956  obj_loss: 0.1443  noobj_loss: 0.0670  bbox_loss: 0.0149  cls_loss: 0.0432  \n",
      "<<<iteration:[320/525] - total_loss: 0.3176  obj_loss: 0.1492  noobj_loss: 0.0615  bbox_loss: 0.0175  cls_loss: 0.0501  \n",
      "<<<iteration:[340/525] - total_loss: 0.3422  obj_loss: 0.1691  noobj_loss: 0.0649  bbox_loss: 0.0139  cls_loss: 0.0713  \n",
      "<<<iteration:[360/525] - total_loss: 0.3037  obj_loss: 0.1425  noobj_loss: 0.0646  bbox_loss: 0.0166  cls_loss: 0.0459  \n",
      "<<<iteration:[380/525] - total_loss: 0.3262  obj_loss: 0.1650  noobj_loss: 0.0637  bbox_loss: 0.0165  cls_loss: 0.0468  \n",
      "<<<iteration:[400/525] - total_loss: 0.3388  obj_loss: 0.1708  noobj_loss: 0.0643  bbox_loss: 0.0166  cls_loss: 0.0527  \n",
      "<<<iteration:[420/525] - total_loss: 0.3285  obj_loss: 0.1385  noobj_loss: 0.0657  bbox_loss: 0.0181  cls_loss: 0.0664  \n",
      "<<<iteration:[440/525] - total_loss: 0.3239  obj_loss: 0.1652  noobj_loss: 0.0618  bbox_loss: 0.0138  cls_loss: 0.0590  \n",
      "<<<iteration:[460/525] - total_loss: 0.3291  obj_loss: 0.1354  noobj_loss: 0.0655  bbox_loss: 0.0179  cls_loss: 0.0713  \n",
      "<<<iteration:[480/525] - total_loss: 0.3511  obj_loss: 0.1582  noobj_loss: 0.0681  bbox_loss: 0.0156  cls_loss: 0.0808  \n",
      "<<<iteration:[500/525] - total_loss: 0.3668  obj_loss: 0.1689  noobj_loss: 0.0675  bbox_loss: 0.0155  cls_loss: 0.0868  \n",
      "<<<iteration:[520/525] - total_loss: 0.2945  obj_loss: 0.1545  noobj_loss: 0.0621  bbox_loss: 0.0134  cls_loss: 0.0420  \n",
      "\n",
      "epoch:17/100 - Train Loss: 0.3241, Val Loss: 0.3150\n",
      "\n",
      "<<<iteration:[20/525] - total_loss: 0.3383  obj_loss: 0.1710  noobj_loss: 0.0704  bbox_loss: 0.0155  cls_loss: 0.0548  \n",
      "<<<iteration:[40/525] - total_loss: 0.3017  obj_loss: 0.1578  noobj_loss: 0.0636  bbox_loss: 0.0139  cls_loss: 0.0425  \n",
      "<<<iteration:[60/525] - total_loss: 0.3477  obj_loss: 0.1716  noobj_loss: 0.0640  bbox_loss: 0.0163  cls_loss: 0.0623  \n",
      "<<<iteration:[80/525] - total_loss: 0.3316  obj_loss: 0.1647  noobj_loss: 0.0706  bbox_loss: 0.0148  cls_loss: 0.0576  \n",
      "<<<iteration:[100/525] - total_loss: 0.3161  obj_loss: 0.1490  noobj_loss: 0.0695  bbox_loss: 0.0171  cls_loss: 0.0470  \n",
      "<<<iteration:[120/525] - total_loss: 0.3350  obj_loss: 0.1515  noobj_loss: 0.0660  bbox_loss: 0.0199  cls_loss: 0.0509  \n",
      "<<<iteration:[140/525] - total_loss: 0.3322  obj_loss: 0.1510  noobj_loss: 0.0657  bbox_loss: 0.0173  cls_loss: 0.0618  \n",
      "<<<iteration:[160/525] - total_loss: 0.2885  obj_loss: 0.1538  noobj_loss: 0.0659  bbox_loss: 0.0127  cls_loss: 0.0380  \n",
      "<<<iteration:[180/525] - total_loss: 0.3138  obj_loss: 0.1642  noobj_loss: 0.0659  bbox_loss: 0.0146  cls_loss: 0.0439  \n",
      "<<<iteration:[200/525] - total_loss: 0.3315  obj_loss: 0.1528  noobj_loss: 0.0660  bbox_loss: 0.0162  cls_loss: 0.0649  \n",
      "<<<iteration:[220/525] - total_loss: 0.3451  obj_loss: 0.1547  noobj_loss: 0.0697  bbox_loss: 0.0179  cls_loss: 0.0663  \n",
      "<<<iteration:[240/525] - total_loss: 0.3104  obj_loss: 0.1401  noobj_loss: 0.0634  bbox_loss: 0.0162  cls_loss: 0.0576  \n",
      "<<<iteration:[260/525] - total_loss: 0.3163  obj_loss: 0.1467  noobj_loss: 0.0679  bbox_loss: 0.0168  cls_loss: 0.0516  \n",
      "<<<iteration:[280/525] - total_loss: 0.3175  obj_loss: 0.1425  noobj_loss: 0.0663  bbox_loss: 0.0167  cls_loss: 0.0582  \n",
      "<<<iteration:[300/525] - total_loss: 0.3402  obj_loss: 0.1752  noobj_loss: 0.0688  bbox_loss: 0.0154  cls_loss: 0.0538  \n",
      "<<<iteration:[320/525] - total_loss: 0.3161  obj_loss: 0.1513  noobj_loss: 0.0640  bbox_loss: 0.0177  cls_loss: 0.0443  \n",
      "<<<iteration:[340/525] - total_loss: 0.3158  obj_loss: 0.1565  noobj_loss: 0.0695  bbox_loss: 0.0137  cls_loss: 0.0560  \n",
      "<<<iteration:[360/525] - total_loss: 0.3466  obj_loss: 0.1653  noobj_loss: 0.0687  bbox_loss: 0.0156  cls_loss: 0.0687  \n",
      "<<<iteration:[380/525] - total_loss: 0.3134  obj_loss: 0.1668  noobj_loss: 0.0698  bbox_loss: 0.0126  cls_loss: 0.0490  \n",
      "<<<iteration:[400/525] - total_loss: 0.3243  obj_loss: 0.1695  noobj_loss: 0.0690  bbox_loss: 0.0127  cls_loss: 0.0569  \n",
      "<<<iteration:[420/525] - total_loss: 0.2932  obj_loss: 0.1378  noobj_loss: 0.0646  bbox_loss: 0.0159  cls_loss: 0.0435  \n",
      "<<<iteration:[440/525] - total_loss: 0.3305  obj_loss: 0.1588  noobj_loss: 0.0669  bbox_loss: 0.0156  cls_loss: 0.0604  \n",
      "<<<iteration:[460/525] - total_loss: 0.3138  obj_loss: 0.1595  noobj_loss: 0.0665  bbox_loss: 0.0131  cls_loss: 0.0554  \n",
      "<<<iteration:[480/525] - total_loss: 0.3240  obj_loss: 0.1587  noobj_loss: 0.0691  bbox_loss: 0.0130  cls_loss: 0.0657  \n",
      "<<<iteration:[500/525] - total_loss: 0.3280  obj_loss: 0.1596  noobj_loss: 0.0688  bbox_loss: 0.0135  cls_loss: 0.0665  \n",
      "<<<iteration:[520/525] - total_loss: 0.3262  obj_loss: 0.1631  noobj_loss: 0.0709  bbox_loss: 0.0151  cls_loss: 0.0520  \n",
      "\n",
      "epoch:18/100 - Train Loss: 0.3225, Val Loss: 0.3153\n",
      "\n",
      "<<<iteration:[20/525] - total_loss: 0.3180  obj_loss: 0.1641  noobj_loss: 0.0731  bbox_loss: 0.0122  cls_loss: 0.0561  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<<<iteration:[40/525] - total_loss: 0.3094  obj_loss: 0.1638  noobj_loss: 0.0702  bbox_loss: 0.0121  cls_loss: 0.0500  \n",
      "<<<iteration:[60/525] - total_loss: 0.3063  obj_loss: 0.1632  noobj_loss: 0.0691  bbox_loss: 0.0138  cls_loss: 0.0394  \n",
      "<<<iteration:[80/525] - total_loss: 0.3393  obj_loss: 0.1512  noobj_loss: 0.0684  bbox_loss: 0.0167  cls_loss: 0.0704  \n",
      "<<<iteration:[100/525] - total_loss: 0.3370  obj_loss: 0.1642  noobj_loss: 0.0707  bbox_loss: 0.0163  cls_loss: 0.0560  \n",
      "<<<iteration:[120/525] - total_loss: 0.3282  obj_loss: 0.1553  noobj_loss: 0.0763  bbox_loss: 0.0130  cls_loss: 0.0699  \n",
      "<<<iteration:[140/525] - total_loss: 0.3077  obj_loss: 0.1598  noobj_loss: 0.0675  bbox_loss: 0.0130  cls_loss: 0.0490  \n",
      "<<<iteration:[160/525] - total_loss: 0.3513  obj_loss: 0.1481  noobj_loss: 0.0687  bbox_loss: 0.0171  cls_loss: 0.0835  \n",
      "<<<iteration:[180/525] - total_loss: 0.3065  obj_loss: 0.1579  noobj_loss: 0.0687  bbox_loss: 0.0143  cls_loss: 0.0428  \n",
      "<<<iteration:[200/525] - total_loss: 0.3270  obj_loss: 0.1549  noobj_loss: 0.0817  bbox_loss: 0.0152  cls_loss: 0.0555  \n",
      "<<<iteration:[220/525] - total_loss: 0.2978  obj_loss: 0.1549  noobj_loss: 0.0639  bbox_loss: 0.0142  cls_loss: 0.0398  \n",
      "<<<iteration:[240/525] - total_loss: 0.3552  obj_loss: 0.1729  noobj_loss: 0.0651  bbox_loss: 0.0161  cls_loss: 0.0693  \n",
      "<<<iteration:[260/525] - total_loss: 0.3300  obj_loss: 0.1678  noobj_loss: 0.0684  bbox_loss: 0.0147  cls_loss: 0.0546  \n",
      "<<<iteration:[280/525] - total_loss: 0.3311  obj_loss: 0.1661  noobj_loss: 0.0678  bbox_loss: 0.0157  cls_loss: 0.0528  \n",
      "<<<iteration:[300/525] - total_loss: 0.3174  obj_loss: 0.1433  noobj_loss: 0.0652  bbox_loss: 0.0175  cls_loss: 0.0539  \n",
      "<<<iteration:[320/525] - total_loss: 0.2946  obj_loss: 0.1441  noobj_loss: 0.0635  bbox_loss: 0.0149  cls_loss: 0.0440  \n",
      "<<<iteration:[340/525] - total_loss: 0.3231  obj_loss: 0.1717  noobj_loss: 0.0695  bbox_loss: 0.0140  cls_loss: 0.0466  \n",
      "<<<iteration:[360/525] - total_loss: 0.3583  obj_loss: 0.1485  noobj_loss: 0.0751  bbox_loss: 0.0176  cls_loss: 0.0843  \n",
      "<<<iteration:[380/525] - total_loss: 0.3111  obj_loss: 0.1607  noobj_loss: 0.0661  bbox_loss: 0.0146  cls_loss: 0.0443  \n",
      "<<<iteration:[400/525] - total_loss: 0.2954  obj_loss: 0.1581  noobj_loss: 0.0690  bbox_loss: 0.0123  cls_loss: 0.0414  \n",
      "<<<iteration:[420/525] - total_loss: 0.3358  obj_loss: 0.1565  noobj_loss: 0.0675  bbox_loss: 0.0169  cls_loss: 0.0612  \n",
      "<<<iteration:[440/525] - total_loss: 0.3080  obj_loss: 0.1519  noobj_loss: 0.0650  bbox_loss: 0.0148  cls_loss: 0.0498  \n",
      "<<<iteration:[460/525] - total_loss: 0.3203  obj_loss: 0.1569  noobj_loss: 0.0681  bbox_loss: 0.0162  cls_loss: 0.0481  \n",
      "<<<iteration:[480/525] - total_loss: 0.3289  obj_loss: 0.1535  noobj_loss: 0.0708  bbox_loss: 0.0164  cls_loss: 0.0579  \n",
      "<<<iteration:[500/525] - total_loss: 0.3209  obj_loss: 0.1663  noobj_loss: 0.0723  bbox_loss: 0.0126  cls_loss: 0.0553  \n",
      "<<<iteration:[520/525] - total_loss: 0.3123  obj_loss: 0.1559  noobj_loss: 0.0685  bbox_loss: 0.0168  cls_loss: 0.0379  \n",
      "\n",
      "epoch:19/100 - Train Loss: 0.3216, Val Loss: 0.3129\n",
      "\n",
      "<<<iteration:[20/525] - total_loss: 0.3255  obj_loss: 0.1779  noobj_loss: 0.0710  bbox_loss: 0.0142  cls_loss: 0.0413  \n",
      "<<<iteration:[40/525] - total_loss: 0.3078  obj_loss: 0.1468  noobj_loss: 0.0688  bbox_loss: 0.0158  cls_loss: 0.0478  \n",
      "<<<iteration:[60/525] - total_loss: 0.3058  obj_loss: 0.1582  noobj_loss: 0.0702  bbox_loss: 0.0146  cls_loss: 0.0393  \n",
      "<<<iteration:[80/525] - total_loss: 0.3242  obj_loss: 0.1516  noobj_loss: 0.0686  bbox_loss: 0.0150  cls_loss: 0.0631  \n",
      "<<<iteration:[100/525] - total_loss: 0.3004  obj_loss: 0.1442  noobj_loss: 0.0723  bbox_loss: 0.0154  cls_loss: 0.0430  \n",
      "<<<iteration:[120/525] - total_loss: 0.3124  obj_loss: 0.1536  noobj_loss: 0.0714  bbox_loss: 0.0136  cls_loss: 0.0551  \n",
      "<<<iteration:[140/525] - total_loss: 0.3070  obj_loss: 0.1548  noobj_loss: 0.0628  bbox_loss: 0.0148  cls_loss: 0.0470  \n",
      "<<<iteration:[160/525] - total_loss: 0.3254  obj_loss: 0.1561  noobj_loss: 0.0661  bbox_loss: 0.0133  cls_loss: 0.0696  \n",
      "<<<iteration:[180/525] - total_loss: 0.3121  obj_loss: 0.1536  noobj_loss: 0.0703  bbox_loss: 0.0157  cls_loss: 0.0447  \n",
      "<<<iteration:[200/525] - total_loss: 0.3284  obj_loss: 0.1577  noobj_loss: 0.0709  bbox_loss: 0.0153  cls_loss: 0.0585  \n",
      "<<<iteration:[220/525] - total_loss: 0.3011  obj_loss: 0.1440  noobj_loss: 0.0711  bbox_loss: 0.0136  cls_loss: 0.0534  \n",
      "<<<iteration:[240/525] - total_loss: 0.3522  obj_loss: 0.1844  noobj_loss: 0.0664  bbox_loss: 0.0157  cls_loss: 0.0562  \n",
      "<<<iteration:[260/525] - total_loss: 0.3065  obj_loss: 0.1534  noobj_loss: 0.0628  bbox_loss: 0.0147  cls_loss: 0.0481  \n",
      "<<<iteration:[280/525] - total_loss: 0.3143  obj_loss: 0.1501  noobj_loss: 0.0711  bbox_loss: 0.0147  cls_loss: 0.0550  \n",
      "<<<iteration:[300/525] - total_loss: 0.3099  obj_loss: 0.1546  noobj_loss: 0.0724  bbox_loss: 0.0149  cls_loss: 0.0445  \n",
      "<<<iteration:[320/525] - total_loss: 0.2938  obj_loss: 0.1279  noobj_loss: 0.0693  bbox_loss: 0.0156  cls_loss: 0.0533  \n",
      "<<<iteration:[340/525] - total_loss: 0.3082  obj_loss: 0.1646  noobj_loss: 0.0635  bbox_loss: 0.0140  cls_loss: 0.0416  \n",
      "<<<iteration:[360/525] - total_loss: 0.3031  obj_loss: 0.1465  noobj_loss: 0.0710  bbox_loss: 0.0142  cls_loss: 0.0498  \n",
      "<<<iteration:[380/525] - total_loss: 0.3202  obj_loss: 0.1672  noobj_loss: 0.0678  bbox_loss: 0.0129  cls_loss: 0.0547  \n",
      "<<<iteration:[400/525] - total_loss: 0.3106  obj_loss: 0.1509  noobj_loss: 0.0720  bbox_loss: 0.0140  cls_loss: 0.0540  \n",
      "<<<iteration:[420/525] - total_loss: 0.3106  obj_loss: 0.1497  noobj_loss: 0.0694  bbox_loss: 0.0147  cls_loss: 0.0528  \n",
      "<<<iteration:[440/525] - total_loss: 0.3086  obj_loss: 0.1638  noobj_loss: 0.0684  bbox_loss: 0.0134  cls_loss: 0.0435  \n",
      "<<<iteration:[460/525] - total_loss: 0.2938  obj_loss: 0.1605  noobj_loss: 0.0647  bbox_loss: 0.0140  cls_loss: 0.0307  \n",
      "<<<iteration:[480/525] - total_loss: 0.3265  obj_loss: 0.1751  noobj_loss: 0.0710  bbox_loss: 0.0138  cls_loss: 0.0471  \n",
      "<<<iteration:[500/525] - total_loss: 0.2973  obj_loss: 0.1456  noobj_loss: 0.0706  bbox_loss: 0.0141  cls_loss: 0.0457  \n",
      "<<<iteration:[520/525] - total_loss: 0.3175  obj_loss: 0.1629  noobj_loss: 0.0726  bbox_loss: 0.0138  cls_loss: 0.0494  \n",
      "\n",
      "epoch:20/100 - Train Loss: 0.3119, Val Loss: 0.3214\n",
      "\n",
      "<<<iteration:[20/525] - total_loss: 0.3140  obj_loss: 0.1561  noobj_loss: 0.0703  bbox_loss: 0.0148  cls_loss: 0.0487  \n",
      "<<<iteration:[40/525] - total_loss: 0.3340  obj_loss: 0.1840  noobj_loss: 0.0720  bbox_loss: 0.0139  cls_loss: 0.0446  \n",
      "<<<iteration:[60/525] - total_loss: 0.3418  obj_loss: 0.1665  noobj_loss: 0.0772  bbox_loss: 0.0151  cls_loss: 0.0610  \n",
      "<<<iteration:[80/525] - total_loss: 0.3037  obj_loss: 0.1653  noobj_loss: 0.0712  bbox_loss: 0.0135  cls_loss: 0.0354  \n",
      "<<<iteration:[100/525] - total_loss: 0.2900  obj_loss: 0.1467  noobj_loss: 0.0653  bbox_loss: 0.0149  cls_loss: 0.0360  \n",
      "<<<iteration:[120/525] - total_loss: 0.2826  obj_loss: 0.1514  noobj_loss: 0.0697  bbox_loss: 0.0127  cls_loss: 0.0329  \n",
      "<<<iteration:[140/525] - total_loss: 0.3237  obj_loss: 0.1481  noobj_loss: 0.0737  bbox_loss: 0.0158  cls_loss: 0.0599  \n",
      "<<<iteration:[160/525] - total_loss: 0.2942  obj_loss: 0.1464  noobj_loss: 0.0705  bbox_loss: 0.0140  cls_loss: 0.0427  \n",
      "<<<iteration:[180/525] - total_loss: 0.3131  obj_loss: 0.1630  noobj_loss: 0.0696  bbox_loss: 0.0134  cls_loss: 0.0485  \n",
      "<<<iteration:[200/525] - total_loss: 0.3007  obj_loss: 0.1571  noobj_loss: 0.0688  bbox_loss: 0.0141  cls_loss: 0.0388  \n",
      "<<<iteration:[220/525] - total_loss: 0.3385  obj_loss: 0.1721  noobj_loss: 0.0705  bbox_loss: 0.0139  cls_loss: 0.0614  \n",
      "<<<iteration:[240/525] - total_loss: 0.3231  obj_loss: 0.1720  noobj_loss: 0.0713  bbox_loss: 0.0146  cls_loss: 0.0423  \n",
      "<<<iteration:[260/525] - total_loss: 0.3161  obj_loss: 0.1659  noobj_loss: 0.0701  bbox_loss: 0.0139  cls_loss: 0.0455  \n",
      "<<<iteration:[280/525] - total_loss: 0.3119  obj_loss: 0.1566  noobj_loss: 0.0711  bbox_loss: 0.0146  cls_loss: 0.0469  \n",
      "<<<iteration:[300/525] - total_loss: 0.3151  obj_loss: 0.1561  noobj_loss: 0.0726  bbox_loss: 0.0141  cls_loss: 0.0520  \n",
      "<<<iteration:[320/525] - total_loss: 0.3143  obj_loss: 0.1544  noobj_loss: 0.0646  bbox_loss: 0.0140  cls_loss: 0.0576  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<<<iteration:[340/525] - total_loss: 0.3102  obj_loss: 0.1574  noobj_loss: 0.0669  bbox_loss: 0.0141  cls_loss: 0.0488  \n",
      "<<<iteration:[360/525] - total_loss: 0.3146  obj_loss: 0.1725  noobj_loss: 0.0695  bbox_loss: 0.0140  cls_loss: 0.0371  \n",
      "<<<iteration:[380/525] - total_loss: 0.3319  obj_loss: 0.1695  noobj_loss: 0.0718  bbox_loss: 0.0138  cls_loss: 0.0574  \n",
      "<<<iteration:[400/525] - total_loss: 0.2979  obj_loss: 0.1612  noobj_loss: 0.0692  bbox_loss: 0.0114  cls_loss: 0.0451  \n",
      "<<<iteration:[420/525] - total_loss: 0.3253  obj_loss: 0.1690  noobj_loss: 0.0709  bbox_loss: 0.0122  cls_loss: 0.0601  \n",
      "<<<iteration:[440/525] - total_loss: 0.3306  obj_loss: 0.1545  noobj_loss: 0.0736  bbox_loss: 0.0151  cls_loss: 0.0638  \n",
      "<<<iteration:[460/525] - total_loss: 0.3194  obj_loss: 0.1641  noobj_loss: 0.0696  bbox_loss: 0.0123  cls_loss: 0.0589  \n",
      "<<<iteration:[480/525] - total_loss: 0.3062  obj_loss: 0.1551  noobj_loss: 0.0662  bbox_loss: 0.0131  cls_loss: 0.0525  \n",
      "<<<iteration:[500/525] - total_loss: 0.3329  obj_loss: 0.1583  noobj_loss: 0.0755  bbox_loss: 0.0153  cls_loss: 0.0605  \n",
      "<<<iteration:[520/525] - total_loss: 0.3020  obj_loss: 0.1444  noobj_loss: 0.0756  bbox_loss: 0.0143  cls_loss: 0.0484  \n",
      "\n",
      "epoch:21/100 - Train Loss: 0.3142, Val Loss: 0.3154\n",
      "\n",
      "<<<iteration:[20/525] - total_loss: 0.3247  obj_loss: 0.1783  noobj_loss: 0.0725  bbox_loss: 0.0127  cls_loss: 0.0466  \n",
      "<<<iteration:[40/525] - total_loss: 0.2959  obj_loss: 0.1406  noobj_loss: 0.0700  bbox_loss: 0.0135  cls_loss: 0.0526  \n",
      "<<<iteration:[60/525] - total_loss: 0.3203  obj_loss: 0.1666  noobj_loss: 0.0694  bbox_loss: 0.0131  cls_loss: 0.0536  \n",
      "<<<iteration:[80/525] - total_loss: 0.3085  obj_loss: 0.1725  noobj_loss: 0.0702  bbox_loss: 0.0125  cls_loss: 0.0382  \n",
      "<<<iteration:[100/525] - total_loss: 0.3161  obj_loss: 0.1722  noobj_loss: 0.0705  bbox_loss: 0.0127  cls_loss: 0.0451  \n",
      "<<<iteration:[120/525] - total_loss: 0.3217  obj_loss: 0.1660  noobj_loss: 0.0722  bbox_loss: 0.0133  cls_loss: 0.0531  \n",
      "<<<iteration:[140/525] - total_loss: 0.3190  obj_loss: 0.1640  noobj_loss: 0.0777  bbox_loss: 0.0124  cls_loss: 0.0541  \n",
      "<<<iteration:[160/525] - total_loss: 0.3116  obj_loss: 0.1663  noobj_loss: 0.0728  bbox_loss: 0.0126  cls_loss: 0.0459  \n",
      "<<<iteration:[180/525] - total_loss: 0.3050  obj_loss: 0.1636  noobj_loss: 0.0720  bbox_loss: 0.0125  cls_loss: 0.0430  \n",
      "<<<iteration:[200/525] - total_loss: 0.2819  obj_loss: 0.1406  noobj_loss: 0.0718  bbox_loss: 0.0121  cls_loss: 0.0451  \n",
      "<<<iteration:[220/525] - total_loss: 0.2963  obj_loss: 0.1362  noobj_loss: 0.0725  bbox_loss: 0.0151  cls_loss: 0.0483  \n",
      "<<<iteration:[240/525] - total_loss: 0.3054  obj_loss: 0.1407  noobj_loss: 0.0696  bbox_loss: 0.0143  cls_loss: 0.0586  \n",
      "<<<iteration:[260/525] - total_loss: 0.3220  obj_loss: 0.1564  noobj_loss: 0.0677  bbox_loss: 0.0136  cls_loss: 0.0639  \n",
      "<<<iteration:[280/525] - total_loss: 0.3097  obj_loss: 0.1679  noobj_loss: 0.0713  bbox_loss: 0.0137  cls_loss: 0.0378  \n",
      "<<<iteration:[300/525] - total_loss: 0.3468  obj_loss: 0.1667  noobj_loss: 0.0733  bbox_loss: 0.0149  cls_loss: 0.0688  \n",
      "<<<iteration:[320/525] - total_loss: 0.3234  obj_loss: 0.1491  noobj_loss: 0.0747  bbox_loss: 0.0196  cls_loss: 0.0392  \n",
      "<<<iteration:[340/525] - total_loss: 0.3440  obj_loss: 0.1591  noobj_loss: 0.0679  bbox_loss: 0.0152  cls_loss: 0.0751  \n",
      "<<<iteration:[360/525] - total_loss: 0.3022  obj_loss: 0.1576  noobj_loss: 0.0725  bbox_loss: 0.0148  cls_loss: 0.0344  \n",
      "<<<iteration:[380/525] - total_loss: 0.3152  obj_loss: 0.1549  noobj_loss: 0.0694  bbox_loss: 0.0157  cls_loss: 0.0473  \n",
      "<<<iteration:[400/525] - total_loss: 0.3317  obj_loss: 0.1590  noobj_loss: 0.0735  bbox_loss: 0.0166  cls_loss: 0.0529  \n",
      "<<<iteration:[420/525] - total_loss: 0.2847  obj_loss: 0.1464  noobj_loss: 0.0705  bbox_loss: 0.0141  cls_loss: 0.0327  \n",
      "<<<iteration:[440/525] - total_loss: 0.2919  obj_loss: 0.1611  noobj_loss: 0.0739  bbox_loss: 0.0133  cls_loss: 0.0273  \n",
      "<<<iteration:[460/525] - total_loss: 0.3209  obj_loss: 0.1712  noobj_loss: 0.0725  bbox_loss: 0.0152  cls_loss: 0.0374  \n",
      "<<<iteration:[480/525] - total_loss: 0.2903  obj_loss: 0.1338  noobj_loss: 0.0697  bbox_loss: 0.0145  cls_loss: 0.0489  \n",
      "<<<iteration:[500/525] - total_loss: 0.3150  obj_loss: 0.1546  noobj_loss: 0.0738  bbox_loss: 0.0153  cls_loss: 0.0469  \n",
      "<<<iteration:[520/525] - total_loss: 0.3140  obj_loss: 0.1579  noobj_loss: 0.0737  bbox_loss: 0.0157  cls_loss: 0.0406  \n",
      "\n",
      "epoch:22/100 - Train Loss: 0.3116, Val Loss: 0.3020\n",
      "\n",
      "<<<iteration:[20/525] - total_loss: 0.3579  obj_loss: 0.1902  noobj_loss: 0.0781  bbox_loss: 0.0160  cls_loss: 0.0488  \n",
      "<<<iteration:[40/525] - total_loss: 0.3190  obj_loss: 0.1658  noobj_loss: 0.0716  bbox_loss: 0.0142  cls_loss: 0.0467  \n",
      "<<<iteration:[60/525] - total_loss: 0.3104  obj_loss: 0.1465  noobj_loss: 0.0692  bbox_loss: 0.0137  cls_loss: 0.0607  \n",
      "<<<iteration:[80/525] - total_loss: 0.3430  obj_loss: 0.1674  noobj_loss: 0.0708  bbox_loss: 0.0160  cls_loss: 0.0600  \n",
      "<<<iteration:[100/525] - total_loss: 0.3405  obj_loss: 0.1560  noobj_loss: 0.0733  bbox_loss: 0.0144  cls_loss: 0.0759  \n",
      "<<<iteration:[120/525] - total_loss: 0.3158  obj_loss: 0.1371  noobj_loss: 0.0714  bbox_loss: 0.0166  cls_loss: 0.0603  \n",
      "<<<iteration:[140/525] - total_loss: 0.2895  obj_loss: 0.1420  noobj_loss: 0.0661  bbox_loss: 0.0129  cls_loss: 0.0498  \n",
      "<<<iteration:[160/525] - total_loss: 0.3241  obj_loss: 0.1800  noobj_loss: 0.0733  bbox_loss: 0.0128  cls_loss: 0.0435  \n",
      "<<<iteration:[180/525] - total_loss: 0.3330  obj_loss: 0.1784  noobj_loss: 0.0735  bbox_loss: 0.0162  cls_loss: 0.0371  \n",
      "<<<iteration:[200/525] - total_loss: 0.3214  obj_loss: 0.1622  noobj_loss: 0.0701  bbox_loss: 0.0166  cls_loss: 0.0413  \n",
      "<<<iteration:[220/525] - total_loss: 0.2985  obj_loss: 0.1585  noobj_loss: 0.0789  bbox_loss: 0.0114  cls_loss: 0.0437  \n",
      "<<<iteration:[240/525] - total_loss: 0.2999  obj_loss: 0.1605  noobj_loss: 0.0685  bbox_loss: 0.0119  cls_loss: 0.0457  \n",
      "<<<iteration:[260/525] - total_loss: 0.2774  obj_loss: 0.1411  noobj_loss: 0.0741  bbox_loss: 0.0116  cls_loss: 0.0413  \n",
      "<<<iteration:[280/525] - total_loss: 0.2927  obj_loss: 0.1513  noobj_loss: 0.0697  bbox_loss: 0.0132  cls_loss: 0.0408  \n",
      "<<<iteration:[300/525] - total_loss: 0.3300  obj_loss: 0.1725  noobj_loss: 0.0670  bbox_loss: 0.0156  cls_loss: 0.0459  \n",
      "<<<iteration:[320/525] - total_loss: 0.3370  obj_loss: 0.1834  noobj_loss: 0.0751  bbox_loss: 0.0142  cls_loss: 0.0450  \n",
      "<<<iteration:[340/525] - total_loss: 0.3154  obj_loss: 0.1733  noobj_loss: 0.0693  bbox_loss: 0.0124  cls_loss: 0.0457  \n",
      "<<<iteration:[360/525] - total_loss: 0.3056  obj_loss: 0.1592  noobj_loss: 0.0747  bbox_loss: 0.0124  cls_loss: 0.0471  \n",
      "<<<iteration:[380/525] - total_loss: 0.3165  obj_loss: 0.1571  noobj_loss: 0.0768  bbox_loss: 0.0135  cls_loss: 0.0535  \n",
      "<<<iteration:[400/525] - total_loss: 0.2989  obj_loss: 0.1553  noobj_loss: 0.0710  bbox_loss: 0.0119  cls_loss: 0.0486  \n",
      "<<<iteration:[420/525] - total_loss: 0.3111  obj_loss: 0.1627  noobj_loss: 0.0718  bbox_loss: 0.0128  cls_loss: 0.0482  \n",
      "<<<iteration:[440/525] - total_loss: 0.2976  obj_loss: 0.1591  noobj_loss: 0.0732  bbox_loss: 0.0128  cls_loss: 0.0379  \n",
      "<<<iteration:[460/525] - total_loss: 0.3038  obj_loss: 0.1474  noobj_loss: 0.0757  bbox_loss: 0.0129  cls_loss: 0.0539  \n",
      "<<<iteration:[480/525] - total_loss: 0.2952  obj_loss: 0.1510  noobj_loss: 0.0731  bbox_loss: 0.0127  cls_loss: 0.0443  \n",
      "<<<iteration:[500/525] - total_loss: 0.3262  obj_loss: 0.1520  noobj_loss: 0.0761  bbox_loss: 0.0146  cls_loss: 0.0629  \n",
      "<<<iteration:[520/525] - total_loss: 0.2996  obj_loss: 0.1636  noobj_loss: 0.0747  bbox_loss: 0.0134  cls_loss: 0.0317  \n",
      "\n",
      "epoch:23/100 - Train Loss: 0.3135, Val Loss: 0.3038\n",
      "\n",
      "<<<iteration:[20/525] - total_loss: 0.3120  obj_loss: 0.1546  noobj_loss: 0.0770  bbox_loss: 0.0151  cls_loss: 0.0435  \n",
      "<<<iteration:[40/525] - total_loss: 0.2732  obj_loss: 0.1531  noobj_loss: 0.0659  bbox_loss: 0.0100  cls_loss: 0.0372  \n",
      "<<<iteration:[60/525] - total_loss: 0.3276  obj_loss: 0.1894  noobj_loss: 0.0724  bbox_loss: 0.0127  cls_loss: 0.0383  \n",
      "<<<iteration:[80/525] - total_loss: 0.2971  obj_loss: 0.1610  noobj_loss: 0.0754  bbox_loss: 0.0114  cls_loss: 0.0416  \n",
      "<<<iteration:[100/525] - total_loss: 0.3136  obj_loss: 0.1533  noobj_loss: 0.0748  bbox_loss: 0.0143  cls_loss: 0.0516  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<<<iteration:[120/525] - total_loss: 0.2980  obj_loss: 0.1414  noobj_loss: 0.0777  bbox_loss: 0.0166  cls_loss: 0.0345  \n",
      "<<<iteration:[140/525] - total_loss: 0.2970  obj_loss: 0.1598  noobj_loss: 0.0737  bbox_loss: 0.0128  cls_loss: 0.0362  \n",
      "<<<iteration:[160/525] - total_loss: 0.2928  obj_loss: 0.1624  noobj_loss: 0.0746  bbox_loss: 0.0121  cls_loss: 0.0324  \n",
      "<<<iteration:[180/525] - total_loss: 0.3049  obj_loss: 0.1558  noobj_loss: 0.0720  bbox_loss: 0.0127  cls_loss: 0.0495  \n",
      "<<<iteration:[200/525] - total_loss: 0.3435  obj_loss: 0.1564  noobj_loss: 0.0764  bbox_loss: 0.0152  cls_loss: 0.0728  \n",
      "<<<iteration:[220/525] - total_loss: 0.2994  obj_loss: 0.1591  noobj_loss: 0.0709  bbox_loss: 0.0121  cls_loss: 0.0442  \n",
      "<<<iteration:[240/525] - total_loss: 0.3408  obj_loss: 0.1541  noobj_loss: 0.0856  bbox_loss: 0.0180  cls_loss: 0.0538  \n",
      "<<<iteration:[260/525] - total_loss: 0.3131  obj_loss: 0.1598  noobj_loss: 0.0715  bbox_loss: 0.0138  cls_loss: 0.0488  \n",
      "<<<iteration:[280/525] - total_loss: 0.3201  obj_loss: 0.1742  noobj_loss: 0.0720  bbox_loss: 0.0125  cls_loss: 0.0473  \n",
      "<<<iteration:[300/525] - total_loss: 0.3274  obj_loss: 0.1706  noobj_loss: 0.0741  bbox_loss: 0.0130  cls_loss: 0.0546  \n",
      "<<<iteration:[320/525] - total_loss: 0.3280  obj_loss: 0.1902  noobj_loss: 0.0778  bbox_loss: 0.0111  cls_loss: 0.0432  \n",
      "<<<iteration:[340/525] - total_loss: 0.3135  obj_loss: 0.1699  noobj_loss: 0.0803  bbox_loss: 0.0138  cls_loss: 0.0345  \n",
      "<<<iteration:[360/525] - total_loss: 0.3093  obj_loss: 0.1636  noobj_loss: 0.0771  bbox_loss: 0.0139  cls_loss: 0.0378  \n",
      "<<<iteration:[380/525] - total_loss: 0.2863  obj_loss: 0.1576  noobj_loss: 0.0768  bbox_loss: 0.0118  cls_loss: 0.0314  \n",
      "<<<iteration:[400/525] - total_loss: 0.3089  obj_loss: 0.1690  noobj_loss: 0.0763  bbox_loss: 0.0124  cls_loss: 0.0395  \n",
      "<<<iteration:[420/525] - total_loss: 0.2994  obj_loss: 0.1566  noobj_loss: 0.0781  bbox_loss: 0.0116  cls_loss: 0.0456  \n",
      "<<<iteration:[440/525] - total_loss: 0.3029  obj_loss: 0.1517  noobj_loss: 0.0767  bbox_loss: 0.0126  cls_loss: 0.0499  \n",
      "<<<iteration:[460/525] - total_loss: 0.3253  obj_loss: 0.1341  noobj_loss: 0.0876  bbox_loss: 0.0180  cls_loss: 0.0575  \n",
      "<<<iteration:[480/525] - total_loss: 0.2958  obj_loss: 0.1547  noobj_loss: 0.0742  bbox_loss: 0.0125  cls_loss: 0.0416  \n",
      "<<<iteration:[500/525] - total_loss: 0.2855  obj_loss: 0.1715  noobj_loss: 0.0732  bbox_loss: 0.0099  cls_loss: 0.0278  \n",
      "<<<iteration:[520/525] - total_loss: 0.2924  obj_loss: 0.1534  noobj_loss: 0.0762  bbox_loss: 0.0117  cls_loss: 0.0426  \n",
      "\n",
      "epoch:24/100 - Train Loss: 0.3073, Val Loss: 0.3096\n",
      "\n",
      "<<<iteration:[20/525] - total_loss: 0.3291  obj_loss: 0.1676  noobj_loss: 0.0758  bbox_loss: 0.0149  cls_loss: 0.0494  \n",
      "<<<iteration:[40/525] - total_loss: 0.2903  obj_loss: 0.1695  noobj_loss: 0.0722  bbox_loss: 0.0126  cls_loss: 0.0215  \n",
      "<<<iteration:[60/525] - total_loss: 0.3133  obj_loss: 0.1637  noobj_loss: 0.0723  bbox_loss: 0.0118  cls_loss: 0.0543  \n",
      "<<<iteration:[80/525] - total_loss: 0.2884  obj_loss: 0.1509  noobj_loss: 0.0783  bbox_loss: 0.0128  cls_loss: 0.0344  \n",
      "<<<iteration:[100/525] - total_loss: 0.3130  obj_loss: 0.1726  noobj_loss: 0.0784  bbox_loss: 0.0119  cls_loss: 0.0416  \n",
      "<<<iteration:[120/525] - total_loss: 0.3021  obj_loss: 0.1650  noobj_loss: 0.0769  bbox_loss: 0.0119  cls_loss: 0.0391  \n",
      "<<<iteration:[140/525] - total_loss: 0.2944  obj_loss: 0.1542  noobj_loss: 0.0744  bbox_loss: 0.0118  cls_loss: 0.0443  \n",
      "<<<iteration:[160/525] - total_loss: 0.3030  obj_loss: 0.1563  noobj_loss: 0.0753  bbox_loss: 0.0128  cls_loss: 0.0449  \n",
      "<<<iteration:[180/525] - total_loss: 0.3010  obj_loss: 0.1464  noobj_loss: 0.0753  bbox_loss: 0.0133  cls_loss: 0.0507  \n",
      "<<<iteration:[200/525] - total_loss: 0.2798  obj_loss: 0.1574  noobj_loss: 0.0751  bbox_loss: 0.0116  cls_loss: 0.0270  \n",
      "<<<iteration:[220/525] - total_loss: 0.3066  obj_loss: 0.1508  noobj_loss: 0.0727  bbox_loss: 0.0138  cls_loss: 0.0504  \n",
      "<<<iteration:[240/525] - total_loss: 0.3171  obj_loss: 0.1734  noobj_loss: 0.0804  bbox_loss: 0.0140  cls_loss: 0.0336  \n",
      "<<<iteration:[260/525] - total_loss: 0.2865  obj_loss: 0.1497  noobj_loss: 0.0700  bbox_loss: 0.0143  cls_loss: 0.0303  \n",
      "<<<iteration:[280/525] - total_loss: 0.3325  obj_loss: 0.1839  noobj_loss: 0.0756  bbox_loss: 0.0116  cls_loss: 0.0526  \n",
      "<<<iteration:[300/525] - total_loss: 0.2938  obj_loss: 0.1499  noobj_loss: 0.0824  bbox_loss: 0.0128  cls_loss: 0.0387  \n",
      "<<<iteration:[320/525] - total_loss: 0.3103  obj_loss: 0.1534  noobj_loss: 0.0753  bbox_loss: 0.0144  cls_loss: 0.0472  \n",
      "<<<iteration:[340/525] - total_loss: 0.3031  obj_loss: 0.1613  noobj_loss: 0.0768  bbox_loss: 0.0112  cls_loss: 0.0473  \n",
      "<<<iteration:[360/525] - total_loss: 0.3310  obj_loss: 0.1696  noobj_loss: 0.0772  bbox_loss: 0.0159  cls_loss: 0.0432  \n",
      "<<<iteration:[380/525] - total_loss: 0.3135  obj_loss: 0.1542  noobj_loss: 0.0824  bbox_loss: 0.0148  cls_loss: 0.0439  \n",
      "<<<iteration:[400/525] - total_loss: 0.3083  obj_loss: 0.1473  noobj_loss: 0.0752  bbox_loss: 0.0155  cls_loss: 0.0461  \n",
      "<<<iteration:[420/525] - total_loss: 0.2925  obj_loss: 0.1610  noobj_loss: 0.0709  bbox_loss: 0.0118  cls_loss: 0.0369  \n",
      "<<<iteration:[440/525] - total_loss: 0.3118  obj_loss: 0.1666  noobj_loss: 0.0752  bbox_loss: 0.0136  cls_loss: 0.0393  \n",
      "<<<iteration:[460/525] - total_loss: 0.3289  obj_loss: 0.1832  noobj_loss: 0.0800  bbox_loss: 0.0128  cls_loss: 0.0416  \n",
      "<<<iteration:[480/525] - total_loss: 0.2950  obj_loss: 0.1496  noobj_loss: 0.0743  bbox_loss: 0.0134  cls_loss: 0.0410  \n",
      "<<<iteration:[500/525] - total_loss: 0.2794  obj_loss: 0.1550  noobj_loss: 0.0717  bbox_loss: 0.0125  cls_loss: 0.0260  \n",
      "<<<iteration:[520/525] - total_loss: 0.3075  obj_loss: 0.1833  noobj_loss: 0.0832  bbox_loss: 0.0115  cls_loss: 0.0250  \n",
      "\n",
      "epoch:25/100 - Train Loss: 0.3043, Val Loss: 0.3121\n",
      "\n",
      "<<<iteration:[20/525] - total_loss: 0.3260  obj_loss: 0.1663  noobj_loss: 0.0789  bbox_loss: 0.0142  cls_loss: 0.0493  \n",
      "<<<iteration:[40/525] - total_loss: 0.2823  obj_loss: 0.1417  noobj_loss: 0.0816  bbox_loss: 0.0118  cls_loss: 0.0407  \n",
      "<<<iteration:[60/525] - total_loss: 0.2914  obj_loss: 0.1530  noobj_loss: 0.0785  bbox_loss: 0.0115  cls_loss: 0.0415  \n",
      "<<<iteration:[80/525] - total_loss: 0.3015  obj_loss: 0.1628  noobj_loss: 0.0756  bbox_loss: 0.0101  cls_loss: 0.0505  \n",
      "<<<iteration:[100/525] - total_loss: 0.2983  obj_loss: 0.1554  noobj_loss: 0.0781  bbox_loss: 0.0142  cls_loss: 0.0327  \n",
      "<<<iteration:[120/525] - total_loss: 0.3222  obj_loss: 0.1818  noobj_loss: 0.0754  bbox_loss: 0.0135  cls_loss: 0.0350  \n",
      "<<<iteration:[140/525] - total_loss: 0.3074  obj_loss: 0.1660  noobj_loss: 0.0775  bbox_loss: 0.0115  cls_loss: 0.0453  \n",
      "<<<iteration:[160/525] - total_loss: 0.2959  obj_loss: 0.1689  noobj_loss: 0.0793  bbox_loss: 0.0111  cls_loss: 0.0318  \n",
      "<<<iteration:[180/525] - total_loss: 0.2646  obj_loss: 0.1407  noobj_loss: 0.0744  bbox_loss: 0.0114  cls_loss: 0.0298  \n",
      "<<<iteration:[200/525] - total_loss: 0.3014  obj_loss: 0.1632  noobj_loss: 0.0757  bbox_loss: 0.0132  cls_loss: 0.0343  \n",
      "<<<iteration:[220/525] - total_loss: 0.3092  obj_loss: 0.1667  noobj_loss: 0.0745  bbox_loss: 0.0126  cls_loss: 0.0424  \n",
      "<<<iteration:[240/525] - total_loss: 0.3051  obj_loss: 0.1524  noobj_loss: 0.0758  bbox_loss: 0.0125  cls_loss: 0.0523  \n",
      "<<<iteration:[260/525] - total_loss: 0.2985  obj_loss: 0.1441  noobj_loss: 0.0788  bbox_loss: 0.0130  cls_loss: 0.0502  \n",
      "<<<iteration:[280/525] - total_loss: 0.2965  obj_loss: 0.1411  noobj_loss: 0.0742  bbox_loss: 0.0138  cls_loss: 0.0493  \n",
      "<<<iteration:[300/525] - total_loss: 0.3212  obj_loss: 0.1750  noobj_loss: 0.0771  bbox_loss: 0.0118  cls_loss: 0.0489  \n",
      "<<<iteration:[320/525] - total_loss: 0.2957  obj_loss: 0.1461  noobj_loss: 0.0775  bbox_loss: 0.0151  cls_loss: 0.0353  \n",
      "<<<iteration:[340/525] - total_loss: 0.3031  obj_loss: 0.1826  noobj_loss: 0.0750  bbox_loss: 0.0114  cls_loss: 0.0259  \n",
      "<<<iteration:[360/525] - total_loss: 0.2957  obj_loss: 0.1640  noobj_loss: 0.0767  bbox_loss: 0.0100  cls_loss: 0.0434  \n",
      "<<<iteration:[380/525] - total_loss: 0.2938  obj_loss: 0.1572  noobj_loss: 0.0781  bbox_loss: 0.0113  cls_loss: 0.0409  \n",
      "<<<iteration:[400/525] - total_loss: 0.3090  obj_loss: 0.1679  noobj_loss: 0.0759  bbox_loss: 0.0125  cls_loss: 0.0405  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<<<iteration:[420/525] - total_loss: 0.2920  obj_loss: 0.1524  noobj_loss: 0.0743  bbox_loss: 0.0115  cls_loss: 0.0451  \n",
      "<<<iteration:[440/525] - total_loss: 0.3035  obj_loss: 0.1558  noobj_loss: 0.0768  bbox_loss: 0.0135  cls_loss: 0.0420  \n",
      "<<<iteration:[460/525] - total_loss: 0.2946  obj_loss: 0.1590  noobj_loss: 0.0799  bbox_loss: 0.0106  cls_loss: 0.0428  \n",
      "<<<iteration:[480/525] - total_loss: 0.2928  obj_loss: 0.1591  noobj_loss: 0.0771  bbox_loss: 0.0126  cls_loss: 0.0323  \n",
      "<<<iteration:[500/525] - total_loss: 0.3166  obj_loss: 0.1754  noobj_loss: 0.0808  bbox_loss: 0.0128  cls_loss: 0.0369  \n",
      "<<<iteration:[520/525] - total_loss: 0.3006  obj_loss: 0.1552  noobj_loss: 0.0846  bbox_loss: 0.0124  cls_loss: 0.0413  \n",
      "\n",
      "epoch:26/100 - Train Loss: 0.2999, Val Loss: 0.3090\n",
      "\n",
      "<<<iteration:[20/525] - total_loss: 0.3232  obj_loss: 0.1623  noobj_loss: 0.0788  bbox_loss: 0.0143  cls_loss: 0.0499  \n",
      "<<<iteration:[40/525] - total_loss: 0.2974  obj_loss: 0.1760  noobj_loss: 0.0776  bbox_loss: 0.0108  cls_loss: 0.0287  \n",
      "<<<iteration:[60/525] - total_loss: 0.2969  obj_loss: 0.1761  noobj_loss: 0.0794  bbox_loss: 0.0102  cls_loss: 0.0299  \n",
      "<<<iteration:[80/525] - total_loss: 0.3131  obj_loss: 0.1806  noobj_loss: 0.0834  bbox_loss: 0.0124  cls_loss: 0.0288  \n",
      "<<<iteration:[100/525] - total_loss: 0.3019  obj_loss: 0.1454  noobj_loss: 0.0772  bbox_loss: 0.0126  cls_loss: 0.0548  \n",
      "<<<iteration:[120/525] - total_loss: 0.2914  obj_loss: 0.1583  noobj_loss: 0.0765  bbox_loss: 0.0125  cls_loss: 0.0322  \n",
      "<<<iteration:[140/525] - total_loss: 0.2838  obj_loss: 0.1619  noobj_loss: 0.0819  bbox_loss: 0.0104  cls_loss: 0.0287  \n",
      "<<<iteration:[160/525] - total_loss: 0.3054  obj_loss: 0.1643  noobj_loss: 0.0771  bbox_loss: 0.0124  cls_loss: 0.0406  \n",
      "<<<iteration:[180/525] - total_loss: 0.2782  obj_loss: 0.1600  noobj_loss: 0.0814  bbox_loss: 0.0097  cls_loss: 0.0290  \n",
      "<<<iteration:[200/525] - total_loss: 0.2828  obj_loss: 0.1579  noobj_loss: 0.0780  bbox_loss: 0.0108  cls_loss: 0.0319  \n",
      "<<<iteration:[220/525] - total_loss: 0.2800  obj_loss: 0.1613  noobj_loss: 0.0767  bbox_loss: 0.0103  cls_loss: 0.0289  \n",
      "<<<iteration:[240/525] - total_loss: 0.3017  obj_loss: 0.1646  noobj_loss: 0.0772  bbox_loss: 0.0112  cls_loss: 0.0426  \n",
      "<<<iteration:[260/525] - total_loss: 0.2853  obj_loss: 0.1557  noobj_loss: 0.0757  bbox_loss: 0.0116  cls_loss: 0.0338  \n",
      "<<<iteration:[280/525] - total_loss: 0.3037  obj_loss: 0.1665  noobj_loss: 0.0763  bbox_loss: 0.0097  cls_loss: 0.0505  \n",
      "<<<iteration:[300/525] - total_loss: 0.2801  obj_loss: 0.1603  noobj_loss: 0.0764  bbox_loss: 0.0111  cls_loss: 0.0259  \n",
      "<<<iteration:[320/525] - total_loss: 0.3275  obj_loss: 0.1687  noobj_loss: 0.0793  bbox_loss: 0.0107  cls_loss: 0.0656  \n",
      "<<<iteration:[340/525] - total_loss: 0.3326  obj_loss: 0.1707  noobj_loss: 0.0951  bbox_loss: 0.0133  cls_loss: 0.0480  \n",
      "<<<iteration:[360/525] - total_loss: 0.3053  obj_loss: 0.1588  noobj_loss: 0.0815  bbox_loss: 0.0113  cls_loss: 0.0492  \n",
      "<<<iteration:[380/525] - total_loss: 0.2927  obj_loss: 0.1559  noobj_loss: 0.0818  bbox_loss: 0.0124  cls_loss: 0.0338  \n",
      "<<<iteration:[400/525] - total_loss: 0.3050  obj_loss: 0.1628  noobj_loss: 0.0804  bbox_loss: 0.0114  cls_loss: 0.0451  \n",
      "<<<iteration:[420/525] - total_loss: 0.2897  obj_loss: 0.1557  noobj_loss: 0.0783  bbox_loss: 0.0114  cls_loss: 0.0378  \n",
      "<<<iteration:[440/525] - total_loss: 0.2770  obj_loss: 0.1486  noobj_loss: 0.0803  bbox_loss: 0.0120  cls_loss: 0.0281  \n",
      "<<<iteration:[460/525] - total_loss: 0.3203  obj_loss: 0.1677  noobj_loss: 0.0818  bbox_loss: 0.0111  cls_loss: 0.0560  \n",
      "<<<iteration:[480/525] - total_loss: 0.3217  obj_loss: 0.1567  noobj_loss: 0.0782  bbox_loss: 0.0144  cls_loss: 0.0538  \n",
      "<<<iteration:[500/525] - total_loss: 0.3019  obj_loss: 0.1640  noobj_loss: 0.0777  bbox_loss: 0.0110  cls_loss: 0.0440  \n",
      "<<<iteration:[520/525] - total_loss: 0.2978  obj_loss: 0.1579  noobj_loss: 0.0707  bbox_loss: 0.0128  cls_loss: 0.0407  \n",
      "\n",
      "epoch:27/100 - Train Loss: 0.2992, Val Loss: 0.3064\n",
      "\n",
      "<<<iteration:[20/525] - total_loss: 0.3386  obj_loss: 0.1843  noobj_loss: 0.0866  bbox_loss: 0.0120  cls_loss: 0.0510  \n",
      "<<<iteration:[40/525] - total_loss: 0.2966  obj_loss: 0.1540  noobj_loss: 0.0785  bbox_loss: 0.0115  cls_loss: 0.0458  \n",
      "<<<iteration:[60/525] - total_loss: 0.2877  obj_loss: 0.1482  noobj_loss: 0.0753  bbox_loss: 0.0121  cls_loss: 0.0415  \n",
      "<<<iteration:[80/525] - total_loss: 0.2917  obj_loss: 0.1676  noobj_loss: 0.0821  bbox_loss: 0.0101  cls_loss: 0.0324  \n",
      "<<<iteration:[100/525] - total_loss: 0.3014  obj_loss: 0.1735  noobj_loss: 0.0874  bbox_loss: 0.0119  cls_loss: 0.0248  \n",
      "<<<iteration:[120/525] - total_loss: 0.2974  obj_loss: 0.1730  noobj_loss: 0.0830  bbox_loss: 0.0099  cls_loss: 0.0332  \n",
      "<<<iteration:[140/525] - total_loss: 0.2776  obj_loss: 0.1549  noobj_loss: 0.0732  bbox_loss: 0.0116  cls_loss: 0.0282  \n",
      "<<<iteration:[160/525] - total_loss: 0.2714  obj_loss: 0.1522  noobj_loss: 0.0797  bbox_loss: 0.0104  cls_loss: 0.0274  \n",
      "<<<iteration:[180/525] - total_loss: 0.2821  obj_loss: 0.1520  noobj_loss: 0.0803  bbox_loss: 0.0122  cls_loss: 0.0291  \n",
      "<<<iteration:[200/525] - total_loss: 0.3216  obj_loss: 0.1940  noobj_loss: 0.0748  bbox_loss: 0.0107  cls_loss: 0.0368  \n",
      "<<<iteration:[220/525] - total_loss: 0.3138  obj_loss: 0.1641  noobj_loss: 0.0801  bbox_loss: 0.0113  cls_loss: 0.0529  \n",
      "<<<iteration:[240/525] - total_loss: 0.3312  obj_loss: 0.1603  noobj_loss: 0.0866  bbox_loss: 0.0123  cls_loss: 0.0659  \n",
      "<<<iteration:[260/525] - total_loss: 0.3119  obj_loss: 0.1660  noobj_loss: 0.0784  bbox_loss: 0.0120  cls_loss: 0.0466  \n",
      "<<<iteration:[280/525] - total_loss: 0.3157  obj_loss: 0.1709  noobj_loss: 0.0810  bbox_loss: 0.0137  cls_loss: 0.0358  \n",
      "<<<iteration:[300/525] - total_loss: 0.2762  obj_loss: 0.1446  noobj_loss: 0.0764  bbox_loss: 0.0113  cls_loss: 0.0370  \n",
      "<<<iteration:[320/525] - total_loss: 0.3194  obj_loss: 0.1552  noobj_loss: 0.0807  bbox_loss: 0.0127  cls_loss: 0.0605  \n",
      "<<<iteration:[340/525] - total_loss: 0.3109  obj_loss: 0.1586  noobj_loss: 0.0752  bbox_loss: 0.0147  cls_loss: 0.0412  \n",
      "<<<iteration:[360/525] - total_loss: 0.3006  obj_loss: 0.1516  noobj_loss: 0.0714  bbox_loss: 0.0145  cls_loss: 0.0411  \n",
      "<<<iteration:[380/525] - total_loss: 0.2952  obj_loss: 0.1679  noobj_loss: 0.0797  bbox_loss: 0.0127  cls_loss: 0.0238  \n",
      "<<<iteration:[400/525] - total_loss: 0.2873  obj_loss: 0.1504  noobj_loss: 0.0788  bbox_loss: 0.0129  cls_loss: 0.0330  \n",
      "<<<iteration:[420/525] - total_loss: 0.2729  obj_loss: 0.1496  noobj_loss: 0.0815  bbox_loss: 0.0112  cls_loss: 0.0266  \n",
      "<<<iteration:[440/525] - total_loss: 0.2807  obj_loss: 0.1695  noobj_loss: 0.0754  bbox_loss: 0.0096  cls_loss: 0.0253  \n",
      "<<<iteration:[460/525] - total_loss: 0.2943  obj_loss: 0.1748  noobj_loss: 0.0844  bbox_loss: 0.0098  cls_loss: 0.0285  \n",
      "<<<iteration:[480/525] - total_loss: 0.2862  obj_loss: 0.1629  noobj_loss: 0.0769  bbox_loss: 0.0106  cls_loss: 0.0320  \n",
      "<<<iteration:[500/525] - total_loss: 0.2969  obj_loss: 0.1641  noobj_loss: 0.0752  bbox_loss: 0.0121  cls_loss: 0.0346  \n",
      "<<<iteration:[520/525] - total_loss: 0.2909  obj_loss: 0.1675  noobj_loss: 0.0712  bbox_loss: 0.0109  cls_loss: 0.0331  \n",
      "\n",
      "epoch:28/100 - Train Loss: 0.2975, Val Loss: 0.3048\n",
      "\n",
      "<<<iteration:[20/525] - total_loss: 0.3184  obj_loss: 0.1583  noobj_loss: 0.0819  bbox_loss: 0.0132  cls_loss: 0.0531  \n",
      "<<<iteration:[40/525] - total_loss: 0.3095  obj_loss: 0.1743  noobj_loss: 0.0750  bbox_loss: 0.0113  cls_loss: 0.0410  \n",
      "<<<iteration:[60/525] - total_loss: 0.2810  obj_loss: 0.1457  noobj_loss: 0.0829  bbox_loss: 0.0117  cls_loss: 0.0353  \n",
      "<<<iteration:[80/525] - total_loss: 0.3050  obj_loss: 0.1730  noobj_loss: 0.0843  bbox_loss: 0.0113  cls_loss: 0.0335  \n",
      "<<<iteration:[100/525] - total_loss: 0.3088  obj_loss: 0.1683  noobj_loss: 0.0832  bbox_loss: 0.0119  cls_loss: 0.0395  \n",
      "<<<iteration:[120/525] - total_loss: 0.2921  obj_loss: 0.1610  noobj_loss: 0.0781  bbox_loss: 0.0106  cls_loss: 0.0391  \n",
      "<<<iteration:[140/525] - total_loss: 0.3077  obj_loss: 0.1650  noobj_loss: 0.0769  bbox_loss: 0.0138  cls_loss: 0.0355  \n",
      "<<<iteration:[160/525] - total_loss: 0.3132  obj_loss: 0.1642  noobj_loss: 0.0791  bbox_loss: 0.0131  cls_loss: 0.0438  \n",
      "<<<iteration:[180/525] - total_loss: 0.2836  obj_loss: 0.1602  noobj_loss: 0.0830  bbox_loss: 0.0105  cls_loss: 0.0292  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<<<iteration:[200/525] - total_loss: 0.3074  obj_loss: 0.1684  noobj_loss: 0.0852  bbox_loss: 0.0119  cls_loss: 0.0369  \n",
      "<<<iteration:[220/525] - total_loss: 0.3132  obj_loss: 0.1783  noobj_loss: 0.0842  bbox_loss: 0.0102  cls_loss: 0.0421  \n",
      "<<<iteration:[240/525] - total_loss: 0.3043  obj_loss: 0.1480  noobj_loss: 0.0854  bbox_loss: 0.0146  cls_loss: 0.0408  \n",
      "<<<iteration:[260/525] - total_loss: 0.2970  obj_loss: 0.1655  noobj_loss: 0.0801  bbox_loss: 0.0108  cls_loss: 0.0374  \n",
      "<<<iteration:[280/525] - total_loss: 0.2903  obj_loss: 0.1775  noobj_loss: 0.0802  bbox_loss: 0.0097  cls_loss: 0.0244  \n",
      "<<<iteration:[300/525] - total_loss: 0.3052  obj_loss: 0.1703  noobj_loss: 0.0759  bbox_loss: 0.0134  cls_loss: 0.0301  \n",
      "<<<iteration:[320/525] - total_loss: 0.3266  obj_loss: 0.1665  noobj_loss: 0.0803  bbox_loss: 0.0145  cls_loss: 0.0474  \n",
      "<<<iteration:[340/525] - total_loss: 0.3303  obj_loss: 0.1678  noobj_loss: 0.0811  bbox_loss: 0.0136  cls_loss: 0.0538  \n",
      "<<<iteration:[360/525] - total_loss: 0.2814  obj_loss: 0.1646  noobj_loss: 0.0731  bbox_loss: 0.0105  cls_loss: 0.0276  \n",
      "<<<iteration:[380/525] - total_loss: 0.2755  obj_loss: 0.1470  noobj_loss: 0.0822  bbox_loss: 0.0105  cls_loss: 0.0350  \n",
      "<<<iteration:[400/525] - total_loss: 0.2761  obj_loss: 0.1467  noobj_loss: 0.0807  bbox_loss: 0.0110  cls_loss: 0.0342  \n",
      "<<<iteration:[420/525] - total_loss: 0.2987  obj_loss: 0.1546  noobj_loss: 0.0854  bbox_loss: 0.0121  cls_loss: 0.0407  \n",
      "<<<iteration:[440/525] - total_loss: 0.3112  obj_loss: 0.1683  noobj_loss: 0.0862  bbox_loss: 0.0125  cls_loss: 0.0370  \n",
      "<<<iteration:[460/525] - total_loss: 0.3093  obj_loss: 0.1606  noobj_loss: 0.0801  bbox_loss: 0.0118  cls_loss: 0.0497  \n",
      "<<<iteration:[480/525] - total_loss: 0.2893  obj_loss: 0.1649  noobj_loss: 0.0866  bbox_loss: 0.0120  cls_loss: 0.0213  \n",
      "<<<iteration:[500/525] - total_loss: 0.2809  obj_loss: 0.1566  noobj_loss: 0.0800  bbox_loss: 0.0108  cls_loss: 0.0302  \n",
      "<<<iteration:[520/525] - total_loss: 0.2773  obj_loss: 0.1531  noobj_loss: 0.0832  bbox_loss: 0.0099  cls_loss: 0.0331  \n",
      "\n",
      "epoch:29/100 - Train Loss: 0.2993, Val Loss: 0.3025\n",
      "\n",
      "<<<iteration:[20/525] - total_loss: 0.2968  obj_loss: 0.1615  noobj_loss: 0.0917  bbox_loss: 0.0132  cls_loss: 0.0234  \n",
      "<<<iteration:[40/525] - total_loss: 0.2678  obj_loss: 0.1461  noobj_loss: 0.0774  bbox_loss: 0.0104  cls_loss: 0.0310  \n",
      "<<<iteration:[60/525] - total_loss: 0.2945  obj_loss: 0.1694  noobj_loss: 0.0834  bbox_loss: 0.0088  cls_loss: 0.0391  \n",
      "<<<iteration:[80/525] - total_loss: 0.3079  obj_loss: 0.1545  noobj_loss: 0.0835  bbox_loss: 0.0123  cls_loss: 0.0504  \n",
      "<<<iteration:[100/525] - total_loss: 0.3127  obj_loss: 0.1673  noobj_loss: 0.0839  bbox_loss: 0.0118  cls_loss: 0.0443  \n",
      "<<<iteration:[120/525] - total_loss: 0.3090  obj_loss: 0.1850  noobj_loss: 0.0851  bbox_loss: 0.0096  cls_loss: 0.0334  \n",
      "<<<iteration:[140/525] - total_loss: 0.2969  obj_loss: 0.1631  noobj_loss: 0.0871  bbox_loss: 0.0107  cls_loss: 0.0366  \n",
      "<<<iteration:[160/525] - total_loss: 0.3001  obj_loss: 0.1714  noobj_loss: 0.0818  bbox_loss: 0.0110  cls_loss: 0.0328  \n",
      "<<<iteration:[180/525] - total_loss: 0.2935  obj_loss: 0.1666  noobj_loss: 0.0798  bbox_loss: 0.0111  cls_loss: 0.0316  \n",
      "<<<iteration:[200/525] - total_loss: 0.2875  obj_loss: 0.1660  noobj_loss: 0.0883  bbox_loss: 0.0102  cls_loss: 0.0262  \n",
      "<<<iteration:[220/525] - total_loss: 0.3057  obj_loss: 0.1563  noobj_loss: 0.0823  bbox_loss: 0.0134  cls_loss: 0.0411  \n",
      "<<<iteration:[240/525] - total_loss: 0.2950  obj_loss: 0.1544  noobj_loss: 0.0896  bbox_loss: 0.0115  cls_loss: 0.0384  \n",
      "<<<iteration:[260/525] - total_loss: 0.2883  obj_loss: 0.1628  noobj_loss: 0.0925  bbox_loss: 0.0089  cls_loss: 0.0347  \n",
      "<<<iteration:[280/525] - total_loss: 0.2819  obj_loss: 0.1532  noobj_loss: 0.0814  bbox_loss: 0.0104  cls_loss: 0.0358  \n",
      "<<<iteration:[300/525] - total_loss: 0.2905  obj_loss: 0.1566  noobj_loss: 0.0796  bbox_loss: 0.0108  cls_loss: 0.0401  \n",
      "<<<iteration:[320/525] - total_loss: 0.3017  obj_loss: 0.1723  noobj_loss: 0.0824  bbox_loss: 0.0112  cls_loss: 0.0321  \n",
      "<<<iteration:[340/525] - total_loss: 0.2995  obj_loss: 0.1705  noobj_loss: 0.0897  bbox_loss: 0.0120  cls_loss: 0.0240  \n",
      "<<<iteration:[360/525] - total_loss: 0.2951  obj_loss: 0.1675  noobj_loss: 0.0816  bbox_loss: 0.0117  cls_loss: 0.0285  \n",
      "<<<iteration:[380/525] - total_loss: 0.3075  obj_loss: 0.1690  noobj_loss: 0.0872  bbox_loss: 0.0117  cls_loss: 0.0367  \n",
      "<<<iteration:[400/525] - total_loss: 0.2937  obj_loss: 0.1662  noobj_loss: 0.0873  bbox_loss: 0.0099  cls_loss: 0.0341  \n",
      "<<<iteration:[420/525] - total_loss: 0.2826  obj_loss: 0.1545  noobj_loss: 0.0769  bbox_loss: 0.0112  cls_loss: 0.0338  \n",
      "<<<iteration:[440/525] - total_loss: 0.2786  obj_loss: 0.1564  noobj_loss: 0.0844  bbox_loss: 0.0112  cls_loss: 0.0239  \n",
      "<<<iteration:[460/525] - total_loss: 0.2875  obj_loss: 0.1577  noobj_loss: 0.0804  bbox_loss: 0.0106  cls_loss: 0.0365  \n",
      "<<<iteration:[480/525] - total_loss: 0.2927  obj_loss: 0.1706  noobj_loss: 0.0854  bbox_loss: 0.0101  cls_loss: 0.0290  \n",
      "<<<iteration:[500/525] - total_loss: 0.2702  obj_loss: 0.1540  noobj_loss: 0.0780  bbox_loss: 0.0105  cls_loss: 0.0248  \n",
      "<<<iteration:[520/525] - total_loss: 0.3065  obj_loss: 0.1643  noobj_loss: 0.0804  bbox_loss: 0.0121  cls_loss: 0.0418  \n",
      "\n",
      "epoch:30/100 - Train Loss: 0.2932, Val Loss: 0.2995\n",
      "\n",
      "<<<iteration:[20/525] - total_loss: 0.3093  obj_loss: 0.1704  noobj_loss: 0.0885  bbox_loss: 0.0117  cls_loss: 0.0362  \n",
      "<<<iteration:[40/525] - total_loss: 0.2885  obj_loss: 0.1708  noobj_loss: 0.0850  bbox_loss: 0.0078  cls_loss: 0.0361  \n",
      "<<<iteration:[60/525] - total_loss: 0.2892  obj_loss: 0.1511  noobj_loss: 0.0888  bbox_loss: 0.0113  cls_loss: 0.0370  \n",
      "<<<iteration:[80/525] - total_loss: 0.3037  obj_loss: 0.1841  noobj_loss: 0.0828  bbox_loss: 0.0095  cls_loss: 0.0308  \n",
      "<<<iteration:[100/525] - total_loss: 0.2770  obj_loss: 0.1559  noobj_loss: 0.0787  bbox_loss: 0.0111  cls_loss: 0.0261  \n",
      "<<<iteration:[120/525] - total_loss: 0.2822  obj_loss: 0.1609  noobj_loss: 0.0829  bbox_loss: 0.0101  cls_loss: 0.0293  \n",
      "<<<iteration:[140/525] - total_loss: 0.2898  obj_loss: 0.1545  noobj_loss: 0.0854  bbox_loss: 0.0109  cls_loss: 0.0378  \n",
      "<<<iteration:[160/525] - total_loss: 0.2954  obj_loss: 0.1673  noobj_loss: 0.0849  bbox_loss: 0.0116  cls_loss: 0.0275  \n",
      "<<<iteration:[180/525] - total_loss: 0.3053  obj_loss: 0.1732  noobj_loss: 0.0826  bbox_loss: 0.0112  cls_loss: 0.0348  \n",
      "<<<iteration:[200/525] - total_loss: 0.3166  obj_loss: 0.1668  noobj_loss: 0.0838  bbox_loss: 0.0128  cls_loss: 0.0440  \n",
      "<<<iteration:[220/525] - total_loss: 0.3023  obj_loss: 0.1640  noobj_loss: 0.0866  bbox_loss: 0.0115  cls_loss: 0.0376  \n",
      "<<<iteration:[240/525] - total_loss: 0.2836  obj_loss: 0.1584  noobj_loss: 0.0825  bbox_loss: 0.0102  cls_loss: 0.0330  \n",
      "<<<iteration:[260/525] - total_loss: 0.3014  obj_loss: 0.1565  noobj_loss: 0.0892  bbox_loss: 0.0113  cls_loss: 0.0437  \n",
      "<<<iteration:[280/525] - total_loss: 0.2767  obj_loss: 0.1526  noobj_loss: 0.0799  bbox_loss: 0.0098  cls_loss: 0.0354  \n",
      "<<<iteration:[300/525] - total_loss: 0.2936  obj_loss: 0.1654  noobj_loss: 0.0798  bbox_loss: 0.0110  cls_loss: 0.0335  \n",
      "<<<iteration:[320/525] - total_loss: 0.2796  obj_loss: 0.1564  noobj_loss: 0.0809  bbox_loss: 0.0112  cls_loss: 0.0267  \n",
      "<<<iteration:[340/525] - total_loss: 0.3072  obj_loss: 0.1649  noobj_loss: 0.0840  bbox_loss: 0.0124  cls_loss: 0.0381  \n",
      "<<<iteration:[360/525] - total_loss: 0.2791  obj_loss: 0.1560  noobj_loss: 0.0847  bbox_loss: 0.0091  cls_loss: 0.0353  \n",
      "<<<iteration:[380/525] - total_loss: 0.2836  obj_loss: 0.1512  noobj_loss: 0.0833  bbox_loss: 0.0120  cls_loss: 0.0310  \n",
      "<<<iteration:[400/525] - total_loss: 0.2913  obj_loss: 0.1520  noobj_loss: 0.0813  bbox_loss: 0.0122  cls_loss: 0.0374  \n",
      "<<<iteration:[420/525] - total_loss: 0.2984  obj_loss: 0.1783  noobj_loss: 0.0834  bbox_loss: 0.0109  cls_loss: 0.0236  \n",
      "<<<iteration:[440/525] - total_loss: 0.2987  obj_loss: 0.1669  noobj_loss: 0.0909  bbox_loss: 0.0109  cls_loss: 0.0317  \n",
      "<<<iteration:[460/525] - total_loss: 0.2920  obj_loss: 0.1698  noobj_loss: 0.0917  bbox_loss: 0.0100  cls_loss: 0.0265  \n",
      "<<<iteration:[480/525] - total_loss: 0.2860  obj_loss: 0.1589  noobj_loss: 0.0833  bbox_loss: 0.0107  cls_loss: 0.0321  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<<<iteration:[500/525] - total_loss: 0.2997  obj_loss: 0.1642  noobj_loss: 0.0797  bbox_loss: 0.0116  cls_loss: 0.0376  \n",
      "<<<iteration:[520/525] - total_loss: 0.3001  obj_loss: 0.1738  noobj_loss: 0.0871  bbox_loss: 0.0108  cls_loss: 0.0287  \n",
      "\n",
      "epoch:31/100 - Train Loss: 0.2924, Val Loss: 0.2950\n",
      "\n",
      "<<<iteration:[20/525] - total_loss: 0.3008  obj_loss: 0.1584  noobj_loss: 0.0919  bbox_loss: 0.0121  cls_loss: 0.0357  \n",
      "<<<iteration:[40/525] - total_loss: 0.3006  obj_loss: 0.1702  noobj_loss: 0.0828  bbox_loss: 0.0098  cls_loss: 0.0399  \n",
      "<<<iteration:[60/525] - total_loss: 0.2994  obj_loss: 0.1533  noobj_loss: 0.0881  bbox_loss: 0.0107  cls_loss: 0.0484  \n",
      "<<<iteration:[80/525] - total_loss: 0.2788  obj_loss: 0.1686  noobj_loss: 0.0930  bbox_loss: 0.0090  cls_loss: 0.0190  \n",
      "<<<iteration:[100/525] - total_loss: 0.3014  obj_loss: 0.1801  noobj_loss: 0.0786  bbox_loss: 0.0094  cls_loss: 0.0352  \n",
      "<<<iteration:[120/525] - total_loss: 0.2787  obj_loss: 0.1406  noobj_loss: 0.0847  bbox_loss: 0.0120  cls_loss: 0.0359  \n",
      "<<<iteration:[140/525] - total_loss: 0.2842  obj_loss: 0.1593  noobj_loss: 0.0860  bbox_loss: 0.0110  cls_loss: 0.0268  \n",
      "<<<iteration:[160/525] - total_loss: 0.2620  obj_loss: 0.1438  noobj_loss: 0.0893  bbox_loss: 0.0103  cls_loss: 0.0218  \n",
      "<<<iteration:[180/525] - total_loss: 0.3100  obj_loss: 0.1723  noobj_loss: 0.0884  bbox_loss: 0.0121  cls_loss: 0.0330  \n",
      "<<<iteration:[200/525] - total_loss: 0.2618  obj_loss: 0.1540  noobj_loss: 0.0824  bbox_loss: 0.0086  cls_loss: 0.0235  \n",
      "<<<iteration:[220/525] - total_loss: 0.2911  obj_loss: 0.1656  noobj_loss: 0.0825  bbox_loss: 0.0106  cls_loss: 0.0313  \n",
      "<<<iteration:[240/525] - total_loss: 0.3013  obj_loss: 0.1753  noobj_loss: 0.0807  bbox_loss: 0.0112  cls_loss: 0.0298  \n",
      "<<<iteration:[260/525] - total_loss: 0.3100  obj_loss: 0.1577  noobj_loss: 0.0888  bbox_loss: 0.0121  cls_loss: 0.0476  \n",
      "<<<iteration:[280/525] - total_loss: 0.2842  obj_loss: 0.1587  noobj_loss: 0.0946  bbox_loss: 0.0112  cls_loss: 0.0221  \n",
      "<<<iteration:[300/525] - total_loss: 0.2703  obj_loss: 0.1480  noobj_loss: 0.0860  bbox_loss: 0.0105  cls_loss: 0.0267  \n",
      "<<<iteration:[320/525] - total_loss: 0.2877  obj_loss: 0.1512  noobj_loss: 0.0825  bbox_loss: 0.0108  cls_loss: 0.0411  \n",
      "<<<iteration:[340/525] - total_loss: 0.2930  obj_loss: 0.1575  noobj_loss: 0.0875  bbox_loss: 0.0096  cls_loss: 0.0437  \n",
      "<<<iteration:[360/525] - total_loss: 0.2839  obj_loss: 0.1595  noobj_loss: 0.0833  bbox_loss: 0.0110  cls_loss: 0.0279  \n",
      "<<<iteration:[380/525] - total_loss: 0.3105  obj_loss: 0.1673  noobj_loss: 0.0902  bbox_loss: 0.0110  cls_loss: 0.0429  \n",
      "<<<iteration:[400/525] - total_loss: 0.3061  obj_loss: 0.1622  noobj_loss: 0.0857  bbox_loss: 0.0127  cls_loss: 0.0373  \n",
      "<<<iteration:[420/525] - total_loss: 0.3171  obj_loss: 0.1738  noobj_loss: 0.0819  bbox_loss: 0.0125  cls_loss: 0.0397  \n",
      "<<<iteration:[440/525] - total_loss: 0.2779  obj_loss: 0.1523  noobj_loss: 0.0858  bbox_loss: 0.0102  cls_loss: 0.0316  \n",
      "<<<iteration:[460/525] - total_loss: 0.2893  obj_loss: 0.1608  noobj_loss: 0.0881  bbox_loss: 0.0096  cls_loss: 0.0364  \n",
      "<<<iteration:[480/525] - total_loss: 0.3018  obj_loss: 0.1660  noobj_loss: 0.0816  bbox_loss: 0.0128  cls_loss: 0.0308  \n",
      "<<<iteration:[500/525] - total_loss: 0.2961  obj_loss: 0.1672  noobj_loss: 0.0814  bbox_loss: 0.0102  cls_loss: 0.0375  \n",
      "<<<iteration:[520/525] - total_loss: 0.2863  obj_loss: 0.1623  noobj_loss: 0.0799  bbox_loss: 0.0100  cls_loss: 0.0338  \n",
      "\n",
      "epoch:32/100 - Train Loss: 0.2908, Val Loss: 0.3078\n",
      "\n",
      "<<<iteration:[20/525] - total_loss: 0.2948  obj_loss: 0.1680  noobj_loss: 0.0909  bbox_loss: 0.0105  cls_loss: 0.0287  \n",
      "<<<iteration:[40/525] - total_loss: 0.2991  obj_loss: 0.1705  noobj_loss: 0.0801  bbox_loss: 0.0111  cls_loss: 0.0333  \n",
      "<<<iteration:[60/525] - total_loss: 0.2521  obj_loss: 0.1450  noobj_loss: 0.0775  bbox_loss: 0.0096  cls_loss: 0.0204  \n",
      "<<<iteration:[80/525] - total_loss: 0.3002  obj_loss: 0.1619  noobj_loss: 0.0980  bbox_loss: 0.0122  cls_loss: 0.0283  \n",
      "<<<iteration:[100/525] - total_loss: 0.2983  obj_loss: 0.1689  noobj_loss: 0.0791  bbox_loss: 0.0102  cls_loss: 0.0389  \n",
      "<<<iteration:[120/525] - total_loss: 0.3132  obj_loss: 0.1708  noobj_loss: 0.0873  bbox_loss: 0.0101  cls_loss: 0.0482  \n",
      "<<<iteration:[140/525] - total_loss: 0.2931  obj_loss: 0.1886  noobj_loss: 0.0825  bbox_loss: 0.0089  cls_loss: 0.0189  \n",
      "<<<iteration:[160/525] - total_loss: 0.2855  obj_loss: 0.1664  noobj_loss: 0.0894  bbox_loss: 0.0095  cls_loss: 0.0270  \n",
      "<<<iteration:[180/525] - total_loss: 0.2701  obj_loss: 0.1525  noobj_loss: 0.0864  bbox_loss: 0.0105  cls_loss: 0.0220  \n",
      "<<<iteration:[200/525] - total_loss: 0.3146  obj_loss: 0.1762  noobj_loss: 0.0839  bbox_loss: 0.0110  cls_loss: 0.0415  \n",
      "<<<iteration:[220/525] - total_loss: 0.3098  obj_loss: 0.1709  noobj_loss: 0.0904  bbox_loss: 0.0114  cls_loss: 0.0367  \n",
      "<<<iteration:[240/525] - total_loss: 0.2774  obj_loss: 0.1495  noobj_loss: 0.0855  bbox_loss: 0.0121  cls_loss: 0.0244  \n",
      "<<<iteration:[260/525] - total_loss: 0.2993  obj_loss: 0.1620  noobj_loss: 0.0920  bbox_loss: 0.0118  cls_loss: 0.0325  \n",
      "<<<iteration:[280/525] - total_loss: 0.3004  obj_loss: 0.1601  noobj_loss: 0.0809  bbox_loss: 0.0108  cls_loss: 0.0459  \n",
      "<<<iteration:[300/525] - total_loss: 0.2766  obj_loss: 0.1645  noobj_loss: 0.0797  bbox_loss: 0.0092  cls_loss: 0.0261  \n",
      "<<<iteration:[320/525] - total_loss: 0.2877  obj_loss: 0.1621  noobj_loss: 0.0866  bbox_loss: 0.0100  cls_loss: 0.0324  \n",
      "<<<iteration:[340/525] - total_loss: 0.2913  obj_loss: 0.1622  noobj_loss: 0.0906  bbox_loss: 0.0111  cls_loss: 0.0283  \n",
      "<<<iteration:[360/525] - total_loss: 0.3114  obj_loss: 0.1814  noobj_loss: 0.0817  bbox_loss: 0.0100  cls_loss: 0.0392  \n",
      "<<<iteration:[380/525] - total_loss: 0.2755  obj_loss: 0.1591  noobj_loss: 0.0883  bbox_loss: 0.0093  cls_loss: 0.0256  \n",
      "<<<iteration:[400/525] - total_loss: 0.3094  obj_loss: 0.1766  noobj_loss: 0.0888  bbox_loss: 0.0112  cls_loss: 0.0322  \n",
      "<<<iteration:[420/525] - total_loss: 0.3017  obj_loss: 0.1809  noobj_loss: 0.0936  bbox_loss: 0.0094  cls_loss: 0.0272  \n",
      "<<<iteration:[440/525] - total_loss: 0.3038  obj_loss: 0.1725  noobj_loss: 0.0935  bbox_loss: 0.0106  cls_loss: 0.0316  \n",
      "<<<iteration:[460/525] - total_loss: 0.2861  obj_loss: 0.1698  noobj_loss: 0.0979  bbox_loss: 0.0089  cls_loss: 0.0228  \n",
      "<<<iteration:[480/525] - total_loss: 0.2638  obj_loss: 0.1433  noobj_loss: 0.0816  bbox_loss: 0.0112  cls_loss: 0.0236  \n",
      "<<<iteration:[500/525] - total_loss: 0.2711  obj_loss: 0.1416  noobj_loss: 0.0883  bbox_loss: 0.0111  cls_loss: 0.0299  \n",
      "<<<iteration:[520/525] - total_loss: 0.2809  obj_loss: 0.1380  noobj_loss: 0.0870  bbox_loss: 0.0127  cls_loss: 0.0361  \n",
      "\n",
      "epoch:33/100 - Train Loss: 0.2903, Val Loss: 0.2878\n",
      "\n",
      "<<<iteration:[20/525] - total_loss: 0.3174  obj_loss: 0.1833  noobj_loss: 0.0982  bbox_loss: 0.0110  cls_loss: 0.0299  \n",
      "<<<iteration:[40/525] - total_loss: 0.2771  obj_loss: 0.1547  noobj_loss: 0.0821  bbox_loss: 0.0102  cls_loss: 0.0302  \n",
      "<<<iteration:[60/525] - total_loss: 0.2643  obj_loss: 0.1505  noobj_loss: 0.0836  bbox_loss: 0.0089  cls_loss: 0.0273  \n",
      "<<<iteration:[80/525] - total_loss: 0.2970  obj_loss: 0.1691  noobj_loss: 0.0857  bbox_loss: 0.0105  cls_loss: 0.0327  \n",
      "<<<iteration:[100/525] - total_loss: 0.2912  obj_loss: 0.1672  noobj_loss: 0.0901  bbox_loss: 0.0111  cls_loss: 0.0236  \n",
      "<<<iteration:[120/525] - total_loss: 0.2709  obj_loss: 0.1600  noobj_loss: 0.0921  bbox_loss: 0.0103  cls_loss: 0.0131  \n",
      "<<<iteration:[140/525] - total_loss: 0.2718  obj_loss: 0.1370  noobj_loss: 0.0826  bbox_loss: 0.0114  cls_loss: 0.0367  \n",
      "<<<iteration:[160/525] - total_loss: 0.3133  obj_loss: 0.1588  noobj_loss: 0.0814  bbox_loss: 0.0133  cls_loss: 0.0471  \n",
      "<<<iteration:[180/525] - total_loss: 0.2950  obj_loss: 0.1652  noobj_loss: 0.0891  bbox_loss: 0.0107  cls_loss: 0.0318  \n",
      "<<<iteration:[200/525] - total_loss: 0.2754  obj_loss: 0.1543  noobj_loss: 0.0945  bbox_loss: 0.0092  cls_loss: 0.0280  \n",
      "<<<iteration:[220/525] - total_loss: 0.3639  obj_loss: 0.1477  noobj_loss: 0.1001  bbox_loss: 0.0171  cls_loss: 0.0806  \n",
      "<<<iteration:[240/525] - total_loss: 0.2670  obj_loss: 0.1540  noobj_loss: 0.0879  bbox_loss: 0.0092  cls_loss: 0.0229  \n",
      "<<<iteration:[260/525] - total_loss: 0.2742  obj_loss: 0.1470  noobj_loss: 0.0861  bbox_loss: 0.0107  cls_loss: 0.0307  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<<<iteration:[280/525] - total_loss: 0.3068  obj_loss: 0.1842  noobj_loss: 0.0850  bbox_loss: 0.0108  cls_loss: 0.0262  \n",
      "<<<iteration:[300/525] - total_loss: 0.2874  obj_loss: 0.1698  noobj_loss: 0.0931  bbox_loss: 0.0110  cls_loss: 0.0162  \n",
      "<<<iteration:[320/525] - total_loss: 0.2983  obj_loss: 0.1709  noobj_loss: 0.0885  bbox_loss: 0.0103  cls_loss: 0.0317  \n",
      "<<<iteration:[340/525] - total_loss: 0.2932  obj_loss: 0.1673  noobj_loss: 0.0829  bbox_loss: 0.0111  cls_loss: 0.0289  \n",
      "<<<iteration:[360/525] - total_loss: 0.2974  obj_loss: 0.1853  noobj_loss: 0.0918  bbox_loss: 0.0085  cls_loss: 0.0237  \n",
      "<<<iteration:[380/525] - total_loss: 0.2732  obj_loss: 0.1560  noobj_loss: 0.0931  bbox_loss: 0.0090  cls_loss: 0.0257  \n",
      "<<<iteration:[400/525] - total_loss: 0.2914  obj_loss: 0.1513  noobj_loss: 0.0909  bbox_loss: 0.0108  cls_loss: 0.0404  \n",
      "<<<iteration:[420/525] - total_loss: 0.2652  obj_loss: 0.1419  noobj_loss: 0.0937  bbox_loss: 0.0104  cls_loss: 0.0243  \n",
      "<<<iteration:[440/525] - total_loss: 0.2669  obj_loss: 0.1526  noobj_loss: 0.0876  bbox_loss: 0.0095  cls_loss: 0.0228  \n",
      "<<<iteration:[460/525] - total_loss: 0.2809  obj_loss: 0.1627  noobj_loss: 0.0860  bbox_loss: 0.0091  cls_loss: 0.0298  \n",
      "<<<iteration:[480/525] - total_loss: 0.2845  obj_loss: 0.1595  noobj_loss: 0.0852  bbox_loss: 0.0107  cls_loss: 0.0290  \n",
      "<<<iteration:[500/525] - total_loss: 0.3221  obj_loss: 0.1729  noobj_loss: 0.0805  bbox_loss: 0.0126  cls_loss: 0.0461  \n",
      "<<<iteration:[520/525] - total_loss: 0.2685  obj_loss: 0.1511  noobj_loss: 0.0866  bbox_loss: 0.0101  cls_loss: 0.0234  \n",
      "\n",
      "epoch:34/100 - Train Loss: 0.2885, Val Loss: 0.2869\n",
      "\n",
      "<<<iteration:[20/525] - total_loss: 0.3179  obj_loss: 0.1771  noobj_loss: 0.0929  bbox_loss: 0.0127  cls_loss: 0.0310  \n",
      "<<<iteration:[40/525] - total_loss: 0.2673  obj_loss: 0.1480  noobj_loss: 0.0908  bbox_loss: 0.0098  cls_loss: 0.0248  \n",
      "<<<iteration:[60/525] - total_loss: 0.2611  obj_loss: 0.1550  noobj_loss: 0.0863  bbox_loss: 0.0087  cls_loss: 0.0192  \n",
      "<<<iteration:[80/525] - total_loss: 0.2945  obj_loss: 0.1736  noobj_loss: 0.0884  bbox_loss: 0.0098  cls_loss: 0.0279  \n",
      "<<<iteration:[100/525] - total_loss: 0.2930  obj_loss: 0.1538  noobj_loss: 0.0871  bbox_loss: 0.0127  cls_loss: 0.0323  \n",
      "<<<iteration:[120/525] - total_loss: 0.2794  obj_loss: 0.1533  noobj_loss: 0.0877  bbox_loss: 0.0108  cls_loss: 0.0285  \n",
      "<<<iteration:[140/525] - total_loss: 0.2891  obj_loss: 0.1559  noobj_loss: 0.0821  bbox_loss: 0.0098  cls_loss: 0.0431  \n",
      "<<<iteration:[160/525] - total_loss: 0.3132  obj_loss: 0.1882  noobj_loss: 0.0841  bbox_loss: 0.0124  cls_loss: 0.0208  \n",
      "<<<iteration:[180/525] - total_loss: 0.2942  obj_loss: 0.1663  noobj_loss: 0.0931  bbox_loss: 0.0107  cls_loss: 0.0276  \n",
      "<<<iteration:[200/525] - total_loss: 0.2841  obj_loss: 0.1579  noobj_loss: 0.0841  bbox_loss: 0.0105  cls_loss: 0.0317  \n",
      "<<<iteration:[220/525] - total_loss: 0.3041  obj_loss: 0.1798  noobj_loss: 0.0909  bbox_loss: 0.0109  cls_loss: 0.0245  \n",
      "<<<iteration:[240/525] - total_loss: 0.2756  obj_loss: 0.1559  noobj_loss: 0.0922  bbox_loss: 0.0091  cls_loss: 0.0282  \n",
      "<<<iteration:[260/525] - total_loss: 0.2713  obj_loss: 0.1484  noobj_loss: 0.0862  bbox_loss: 0.0095  cls_loss: 0.0323  \n",
      "<<<iteration:[280/525] - total_loss: 0.2627  obj_loss: 0.1417  noobj_loss: 0.0853  bbox_loss: 0.0098  cls_loss: 0.0296  \n",
      "<<<iteration:[300/525] - total_loss: 0.2902  obj_loss: 0.1636  noobj_loss: 0.0909  bbox_loss: 0.0108  cls_loss: 0.0272  \n",
      "<<<iteration:[320/525] - total_loss: 0.2753  obj_loss: 0.1703  noobj_loss: 0.0830  bbox_loss: 0.0089  cls_loss: 0.0189  \n",
      "<<<iteration:[340/525] - total_loss: 0.2857  obj_loss: 0.1573  noobj_loss: 0.0906  bbox_loss: 0.0095  cls_loss: 0.0354  \n",
      "<<<iteration:[360/525] - total_loss: 0.2833  obj_loss: 0.1609  noobj_loss: 0.0848  bbox_loss: 0.0113  cls_loss: 0.0237  \n",
      "<<<iteration:[380/525] - total_loss: 0.2662  obj_loss: 0.1590  noobj_loss: 0.0882  bbox_loss: 0.0089  cls_loss: 0.0184  \n",
      "<<<iteration:[400/525] - total_loss: 0.2919  obj_loss: 0.1492  noobj_loss: 0.0876  bbox_loss: 0.0128  cls_loss: 0.0348  \n",
      "<<<iteration:[420/525] - total_loss: 0.2873  obj_loss: 0.1741  noobj_loss: 0.0857  bbox_loss: 0.0093  cls_loss: 0.0239  \n",
      "<<<iteration:[440/525] - total_loss: 0.2825  obj_loss: 0.1637  noobj_loss: 0.0847  bbox_loss: 0.0096  cls_loss: 0.0282  \n",
      "<<<iteration:[460/525] - total_loss: 0.2767  obj_loss: 0.1583  noobj_loss: 0.0938  bbox_loss: 0.0088  cls_loss: 0.0275  \n",
      "<<<iteration:[480/525] - total_loss: 0.3128  obj_loss: 0.1926  noobj_loss: 0.0910  bbox_loss: 0.0095  cls_loss: 0.0271  \n",
      "<<<iteration:[500/525] - total_loss: 0.2776  obj_loss: 0.1714  noobj_loss: 0.0916  bbox_loss: 0.0084  cls_loss: 0.0182  \n",
      "<<<iteration:[520/525] - total_loss: 0.2830  obj_loss: 0.1733  noobj_loss: 0.0871  bbox_loss: 0.0088  cls_loss: 0.0222  \n",
      "\n",
      "epoch:35/100 - Train Loss: 0.2853, Val Loss: 0.2946\n",
      "\n",
      "<<<iteration:[20/525] - total_loss: 0.3027  obj_loss: 0.1677  noobj_loss: 0.0934  bbox_loss: 0.0119  cls_loss: 0.0288  \n",
      "<<<iteration:[40/525] - total_loss: 0.2836  obj_loss: 0.1628  noobj_loss: 0.0919  bbox_loss: 0.0098  cls_loss: 0.0258  \n",
      "<<<iteration:[60/525] - total_loss: 0.2914  obj_loss: 0.1641  noobj_loss: 0.0960  bbox_loss: 0.0097  cls_loss: 0.0308  \n",
      "<<<iteration:[80/525] - total_loss: 0.2848  obj_loss: 0.1561  noobj_loss: 0.0805  bbox_loss: 0.0122  cls_loss: 0.0272  \n",
      "<<<iteration:[100/525] - total_loss: 0.2915  obj_loss: 0.1625  noobj_loss: 0.0938  bbox_loss: 0.0112  cls_loss: 0.0263  \n",
      "<<<iteration:[120/525] - total_loss: 0.2852  obj_loss: 0.1571  noobj_loss: 0.0903  bbox_loss: 0.0111  cls_loss: 0.0273  \n",
      "<<<iteration:[140/525] - total_loss: 0.2668  obj_loss: 0.1485  noobj_loss: 0.0978  bbox_loss: 0.0090  cls_loss: 0.0242  \n",
      "<<<iteration:[160/525] - total_loss: 0.2844  obj_loss: 0.1582  noobj_loss: 0.0897  bbox_loss: 0.0102  cls_loss: 0.0305  \n",
      "<<<iteration:[180/525] - total_loss: 0.2643  obj_loss: 0.1556  noobj_loss: 0.0879  bbox_loss: 0.0090  cls_loss: 0.0199  \n",
      "<<<iteration:[200/525] - total_loss: 0.3120  obj_loss: 0.1824  noobj_loss: 0.0942  bbox_loss: 0.0098  cls_loss: 0.0337  \n",
      "<<<iteration:[220/525] - total_loss: 0.2977  obj_loss: 0.1653  noobj_loss: 0.0924  bbox_loss: 0.0098  cls_loss: 0.0370  \n",
      "<<<iteration:[240/525] - total_loss: 0.2764  obj_loss: 0.1663  noobj_loss: 0.0865  bbox_loss: 0.0100  cls_loss: 0.0169  \n",
      "<<<iteration:[260/525] - total_loss: 0.2823  obj_loss: 0.1595  noobj_loss: 0.0942  bbox_loss: 0.0108  cls_loss: 0.0218  \n",
      "<<<iteration:[280/525] - total_loss: 0.3120  obj_loss: 0.1539  noobj_loss: 0.0794  bbox_loss: 0.0130  cls_loss: 0.0534  \n",
      "<<<iteration:[300/525] - total_loss: 0.2934  obj_loss: 0.1769  noobj_loss: 0.0895  bbox_loss: 0.0092  cls_loss: 0.0255  \n",
      "<<<iteration:[320/525] - total_loss: 0.2968  obj_loss: 0.1746  noobj_loss: 0.0870  bbox_loss: 0.0090  cls_loss: 0.0335  \n",
      "<<<iteration:[340/525] - total_loss: 0.2668  obj_loss: 0.1585  noobj_loss: 0.0869  bbox_loss: 0.0080  cls_loss: 0.0248  \n",
      "<<<iteration:[360/525] - total_loss: 0.2699  obj_loss: 0.1530  noobj_loss: 0.0891  bbox_loss: 0.0105  cls_loss: 0.0196  \n",
      "<<<iteration:[380/525] - total_loss: 0.2760  obj_loss: 0.1630  noobj_loss: 0.0901  bbox_loss: 0.0103  cls_loss: 0.0168  \n",
      "<<<iteration:[400/525] - total_loss: 0.2881  obj_loss: 0.1665  noobj_loss: 0.0906  bbox_loss: 0.0096  cls_loss: 0.0284  \n",
      "<<<iteration:[420/525] - total_loss: 0.2727  obj_loss: 0.1539  noobj_loss: 0.0926  bbox_loss: 0.0089  cls_loss: 0.0281  \n",
      "<<<iteration:[440/525] - total_loss: 0.2998  obj_loss: 0.1741  noobj_loss: 0.0925  bbox_loss: 0.0103  cls_loss: 0.0280  \n",
      "<<<iteration:[460/525] - total_loss: 0.2976  obj_loss: 0.1726  noobj_loss: 0.0962  bbox_loss: 0.0096  cls_loss: 0.0290  \n",
      "<<<iteration:[480/525] - total_loss: 0.3034  obj_loss: 0.1773  noobj_loss: 0.0929  bbox_loss: 0.0102  cls_loss: 0.0287  \n",
      "<<<iteration:[500/525] - total_loss: 0.3018  obj_loss: 0.1797  noobj_loss: 0.0879  bbox_loss: 0.0084  cls_loss: 0.0363  \n",
      "<<<iteration:[520/525] - total_loss: 0.3127  obj_loss: 0.1741  noobj_loss: 0.0862  bbox_loss: 0.0122  cls_loss: 0.0344  \n",
      "\n",
      "epoch:36/100 - Train Loss: 0.2882, Val Loss: 0.2946\n",
      "\n",
      "<<<iteration:[20/525] - total_loss: 0.2871  obj_loss: 0.1583  noobj_loss: 0.0969  bbox_loss: 0.0112  cls_loss: 0.0245  \n",
      "<<<iteration:[40/525] - total_loss: 0.2654  obj_loss: 0.1440  noobj_loss: 0.0953  bbox_loss: 0.0108  cls_loss: 0.0199  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<<<iteration:[60/525] - total_loss: 0.2855  obj_loss: 0.1678  noobj_loss: 0.0889  bbox_loss: 0.0089  cls_loss: 0.0286  \n",
      "<<<iteration:[80/525] - total_loss: 0.2913  obj_loss: 0.1459  noobj_loss: 0.0950  bbox_loss: 0.0111  cls_loss: 0.0424  \n",
      "<<<iteration:[100/525] - total_loss: 0.2924  obj_loss: 0.1563  noobj_loss: 0.0841  bbox_loss: 0.0103  cls_loss: 0.0424  \n",
      "<<<iteration:[120/525] - total_loss: 0.2838  obj_loss: 0.1642  noobj_loss: 0.0927  bbox_loss: 0.0102  cls_loss: 0.0223  \n",
      "<<<iteration:[140/525] - total_loss: 0.2704  obj_loss: 0.1563  noobj_loss: 0.0884  bbox_loss: 0.0093  cls_loss: 0.0232  \n",
      "<<<iteration:[160/525] - total_loss: 0.2761  obj_loss: 0.1450  noobj_loss: 0.0855  bbox_loss: 0.0108  cls_loss: 0.0341  \n",
      "<<<iteration:[180/525] - total_loss: 0.2981  obj_loss: 0.1677  noobj_loss: 0.0846  bbox_loss: 0.0106  cls_loss: 0.0353  \n",
      "<<<iteration:[200/525] - total_loss: 0.2802  obj_loss: 0.1496  noobj_loss: 0.0931  bbox_loss: 0.0111  cls_loss: 0.0285  \n",
      "<<<iteration:[220/525] - total_loss: 0.2776  obj_loss: 0.1535  noobj_loss: 0.0875  bbox_loss: 0.0098  cls_loss: 0.0315  \n",
      "<<<iteration:[240/525] - total_loss: 0.2691  obj_loss: 0.1524  noobj_loss: 0.0929  bbox_loss: 0.0094  cls_loss: 0.0233  \n",
      "<<<iteration:[260/525] - total_loss: 0.2917  obj_loss: 0.1568  noobj_loss: 0.0879  bbox_loss: 0.0102  cls_loss: 0.0401  \n",
      "<<<iteration:[280/525] - total_loss: 0.2580  obj_loss: 0.1412  noobj_loss: 0.0900  bbox_loss: 0.0097  cls_loss: 0.0234  \n",
      "<<<iteration:[300/525] - total_loss: 0.2791  obj_loss: 0.1582  noobj_loss: 0.0846  bbox_loss: 0.0110  cls_loss: 0.0237  \n",
      "<<<iteration:[320/525] - total_loss: 0.2799  obj_loss: 0.1543  noobj_loss: 0.0884  bbox_loss: 0.0115  cls_loss: 0.0240  \n",
      "<<<iteration:[340/525] - total_loss: 0.3083  obj_loss: 0.1831  noobj_loss: 0.0889  bbox_loss: 0.0096  cls_loss: 0.0326  \n",
      "<<<iteration:[360/525] - total_loss: 0.3037  obj_loss: 0.1860  noobj_loss: 0.0901  bbox_loss: 0.0097  cls_loss: 0.0242  \n",
      "<<<iteration:[380/525] - total_loss: 0.2903  obj_loss: 0.1671  noobj_loss: 0.1032  bbox_loss: 0.0096  cls_loss: 0.0236  \n",
      "<<<iteration:[400/525] - total_loss: 0.2705  obj_loss: 0.1588  noobj_loss: 0.0882  bbox_loss: 0.0093  cls_loss: 0.0214  \n",
      "<<<iteration:[420/525] - total_loss: 0.3085  obj_loss: 0.1829  noobj_loss: 0.0871  bbox_loss: 0.0100  cls_loss: 0.0323  \n",
      "<<<iteration:[440/525] - total_loss: 0.2825  obj_loss: 0.1556  noobj_loss: 0.0938  bbox_loss: 0.0112  cls_loss: 0.0241  \n",
      "<<<iteration:[460/525] - total_loss: 0.2663  obj_loss: 0.1641  noobj_loss: 0.0865  bbox_loss: 0.0079  cls_loss: 0.0193  \n",
      "<<<iteration:[480/525] - total_loss: 0.2860  obj_loss: 0.1601  noobj_loss: 0.0854  bbox_loss: 0.0097  cls_loss: 0.0349  \n",
      "<<<iteration:[500/525] - total_loss: 0.2935  obj_loss: 0.1688  noobj_loss: 0.0960  bbox_loss: 0.0099  cls_loss: 0.0271  \n",
      "<<<iteration:[520/525] - total_loss: 0.2646  obj_loss: 0.1572  noobj_loss: 0.0941  bbox_loss: 0.0084  cls_loss: 0.0185  \n",
      "\n",
      "epoch:37/100 - Train Loss: 0.2828, Val Loss: 0.2913\n",
      "\n",
      "<<<iteration:[20/525] - total_loss: 0.2888  obj_loss: 0.1683  noobj_loss: 0.0948  bbox_loss: 0.0094  cls_loss: 0.0261  \n",
      "<<<iteration:[40/525] - total_loss: 0.3020  obj_loss: 0.1604  noobj_loss: 0.0888  bbox_loss: 0.0116  cls_loss: 0.0391  \n",
      "<<<iteration:[60/525] - total_loss: 0.2751  obj_loss: 0.1602  noobj_loss: 0.0896  bbox_loss: 0.0094  cls_loss: 0.0231  \n",
      "<<<iteration:[80/525] - total_loss: 0.2600  obj_loss: 0.1446  noobj_loss: 0.0892  bbox_loss: 0.0095  cls_loss: 0.0234  \n",
      "<<<iteration:[100/525] - total_loss: 0.2845  obj_loss: 0.1726  noobj_loss: 0.0899  bbox_loss: 0.0095  cls_loss: 0.0192  \n",
      "<<<iteration:[120/525] - total_loss: 0.2844  obj_loss: 0.1584  noobj_loss: 0.0894  bbox_loss: 0.0096  cls_loss: 0.0334  \n",
      "<<<iteration:[140/525] - total_loss: 0.2733  obj_loss: 0.1699  noobj_loss: 0.0810  bbox_loss: 0.0087  cls_loss: 0.0196  \n",
      "<<<iteration:[160/525] - total_loss: 0.2902  obj_loss: 0.1640  noobj_loss: 0.0934  bbox_loss: 0.0103  cls_loss: 0.0278  \n",
      "<<<iteration:[180/525] - total_loss: 0.2551  obj_loss: 0.1473  noobj_loss: 0.0836  bbox_loss: 0.0100  cls_loss: 0.0160  \n",
      "<<<iteration:[200/525] - total_loss: 0.2666  obj_loss: 0.1598  noobj_loss: 0.0862  bbox_loss: 0.0082  cls_loss: 0.0227  \n",
      "<<<iteration:[220/525] - total_loss: 0.2652  obj_loss: 0.1551  noobj_loss: 0.0929  bbox_loss: 0.0080  cls_loss: 0.0236  \n",
      "<<<iteration:[240/525] - total_loss: 0.2560  obj_loss: 0.1473  noobj_loss: 0.0953  bbox_loss: 0.0083  cls_loss: 0.0194  \n",
      "<<<iteration:[260/525] - total_loss: 0.2934  obj_loss: 0.1595  noobj_loss: 0.0893  bbox_loss: 0.0107  cls_loss: 0.0355  \n",
      "<<<iteration:[280/525] - total_loss: 0.2724  obj_loss: 0.1649  noobj_loss: 0.0864  bbox_loss: 0.0092  cls_loss: 0.0181  \n",
      "<<<iteration:[300/525] - total_loss: 0.2848  obj_loss: 0.1647  noobj_loss: 0.0935  bbox_loss: 0.0109  cls_loss: 0.0188  \n",
      "<<<iteration:[320/525] - total_loss: 0.2778  obj_loss: 0.1616  noobj_loss: 0.0880  bbox_loss: 0.0105  cls_loss: 0.0197  \n",
      "<<<iteration:[340/525] - total_loss: 0.2944  obj_loss: 0.1605  noobj_loss: 0.0970  bbox_loss: 0.0102  cls_loss: 0.0345  \n",
      "<<<iteration:[360/525] - total_loss: 0.2658  obj_loss: 0.1559  noobj_loss: 0.0889  bbox_loss: 0.0096  cls_loss: 0.0174  \n",
      "<<<iteration:[380/525] - total_loss: 0.2606  obj_loss: 0.1517  noobj_loss: 0.0850  bbox_loss: 0.0084  cls_loss: 0.0243  \n",
      "<<<iteration:[400/525] - total_loss: 0.2946  obj_loss: 0.1767  noobj_loss: 0.0916  bbox_loss: 0.0088  cls_loss: 0.0281  \n",
      "<<<iteration:[420/525] - total_loss: 0.2861  obj_loss: 0.1631  noobj_loss: 0.0965  bbox_loss: 0.0101  cls_loss: 0.0240  \n",
      "<<<iteration:[440/525] - total_loss: 0.2841  obj_loss: 0.1515  noobj_loss: 0.0862  bbox_loss: 0.0103  cls_loss: 0.0382  \n",
      "<<<iteration:[460/525] - total_loss: 0.3034  obj_loss: 0.1808  noobj_loss: 0.0892  bbox_loss: 0.0090  cls_loss: 0.0328  \n",
      "<<<iteration:[480/525] - total_loss: 0.2853  obj_loss: 0.1645  noobj_loss: 0.0898  bbox_loss: 0.0087  cls_loss: 0.0323  \n",
      "<<<iteration:[500/525] - total_loss: 0.2782  obj_loss: 0.1667  noobj_loss: 0.0913  bbox_loss: 0.0092  cls_loss: 0.0200  \n",
      "<<<iteration:[520/525] - total_loss: 0.2861  obj_loss: 0.1631  noobj_loss: 0.0975  bbox_loss: 0.0095  cls_loss: 0.0268  \n",
      "\n",
      "epoch:38/100 - Train Loss: 0.2792, Val Loss: 0.2925\n",
      "\n",
      "<<<iteration:[20/525] - total_loss: 0.2797  obj_loss: 0.1636  noobj_loss: 0.0938  bbox_loss: 0.0092  cls_loss: 0.0232  \n",
      "<<<iteration:[40/525] - total_loss: 0.2749  obj_loss: 0.1549  noobj_loss: 0.0993  bbox_loss: 0.0091  cls_loss: 0.0248  \n",
      "<<<iteration:[60/525] - total_loss: 0.2927  obj_loss: 0.1611  noobj_loss: 0.0865  bbox_loss: 0.0106  cls_loss: 0.0355  \n",
      "<<<iteration:[80/525] - total_loss: 0.2833  obj_loss: 0.1719  noobj_loss: 0.0947  bbox_loss: 0.0096  cls_loss: 0.0159  \n",
      "<<<iteration:[100/525] - total_loss: 0.2849  obj_loss: 0.1719  noobj_loss: 0.0917  bbox_loss: 0.0098  cls_loss: 0.0181  \n",
      "<<<iteration:[120/525] - total_loss: 0.2729  obj_loss: 0.1526  noobj_loss: 0.0922  bbox_loss: 0.0104  cls_loss: 0.0221  \n",
      "<<<iteration:[140/525] - total_loss: 0.2846  obj_loss: 0.1670  noobj_loss: 0.0915  bbox_loss: 0.0093  cls_loss: 0.0256  \n",
      "<<<iteration:[160/525] - total_loss: 0.2924  obj_loss: 0.1710  noobj_loss: 0.0931  bbox_loss: 0.0104  cls_loss: 0.0230  \n",
      "<<<iteration:[180/525] - total_loss: 0.2769  obj_loss: 0.1650  noobj_loss: 0.0873  bbox_loss: 0.0092  cls_loss: 0.0223  \n",
      "<<<iteration:[200/525] - total_loss: 0.2779  obj_loss: 0.1645  noobj_loss: 0.0949  bbox_loss: 0.0092  cls_loss: 0.0198  \n",
      "<<<iteration:[220/525] - total_loss: 0.2771  obj_loss: 0.1636  noobj_loss: 0.0924  bbox_loss: 0.0091  cls_loss: 0.0216  \n",
      "<<<iteration:[240/525] - total_loss: 0.2872  obj_loss: 0.1681  noobj_loss: 0.0892  bbox_loss: 0.0084  cls_loss: 0.0323  \n",
      "<<<iteration:[260/525] - total_loss: 0.2738  obj_loss: 0.1568  noobj_loss: 0.0942  bbox_loss: 0.0093  cls_loss: 0.0232  \n",
      "<<<iteration:[280/525] - total_loss: 0.3022  obj_loss: 0.1718  noobj_loss: 0.0955  bbox_loss: 0.0089  cls_loss: 0.0383  \n",
      "<<<iteration:[300/525] - total_loss: 0.2889  obj_loss: 0.1596  noobj_loss: 0.1011  bbox_loss: 0.0105  cls_loss: 0.0262  \n",
      "<<<iteration:[320/525] - total_loss: 0.3150  obj_loss: 0.1687  noobj_loss: 0.0947  bbox_loss: 0.0104  cls_loss: 0.0467  \n",
      "<<<iteration:[340/525] - total_loss: 0.2878  obj_loss: 0.1808  noobj_loss: 0.1002  bbox_loss: 0.0073  cls_loss: 0.0205  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<<<iteration:[360/525] - total_loss: 0.3133  obj_loss: 0.1931  noobj_loss: 0.0930  bbox_loss: 0.0094  cls_loss: 0.0265  \n",
      "<<<iteration:[380/525] - total_loss: 0.3019  obj_loss: 0.1767  noobj_loss: 0.0963  bbox_loss: 0.0096  cls_loss: 0.0288  \n",
      "<<<iteration:[400/525] - total_loss: 0.2833  obj_loss: 0.1543  noobj_loss: 0.0949  bbox_loss: 0.0110  cls_loss: 0.0264  \n",
      "<<<iteration:[420/525] - total_loss: 0.2925  obj_loss: 0.1518  noobj_loss: 0.1031  bbox_loss: 0.0116  cls_loss: 0.0310  \n",
      "<<<iteration:[440/525] - total_loss: 0.2693  obj_loss: 0.1509  noobj_loss: 0.0916  bbox_loss: 0.0100  cls_loss: 0.0224  \n",
      "<<<iteration:[460/525] - total_loss: 0.2760  obj_loss: 0.1595  noobj_loss: 0.0977  bbox_loss: 0.0095  cls_loss: 0.0199  \n",
      "<<<iteration:[480/525] - total_loss: 0.2880  obj_loss: 0.1599  noobj_loss: 0.0905  bbox_loss: 0.0097  cls_loss: 0.0341  \n",
      "<<<iteration:[500/525] - total_loss: 0.2828  obj_loss: 0.1465  noobj_loss: 0.0944  bbox_loss: 0.0105  cls_loss: 0.0366  \n",
      "<<<iteration:[520/525] - total_loss: 0.2593  obj_loss: 0.1549  noobj_loss: 0.0887  bbox_loss: 0.0085  cls_loss: 0.0174  \n",
      "\n",
      "epoch:39/100 - Train Loss: 0.2847, Val Loss: 0.2803\n",
      "\n",
      "<<<iteration:[20/525] - total_loss: 0.2978  obj_loss: 0.1845  noobj_loss: 0.0981  bbox_loss: 0.0092  cls_loss: 0.0179  \n",
      "<<<iteration:[40/525] - total_loss: 0.2723  obj_loss: 0.1558  noobj_loss: 0.0877  bbox_loss: 0.0099  cls_loss: 0.0231  \n",
      "<<<iteration:[60/525] - total_loss: 0.2802  obj_loss: 0.1534  noobj_loss: 0.0959  bbox_loss: 0.0104  cls_loss: 0.0267  \n",
      "<<<iteration:[80/525] - total_loss: 0.2774  obj_loss: 0.1495  noobj_loss: 0.0869  bbox_loss: 0.0097  cls_loss: 0.0359  \n",
      "<<<iteration:[100/525] - total_loss: 0.2736  obj_loss: 0.1731  noobj_loss: 0.0926  bbox_loss: 0.0078  cls_loss: 0.0153  \n",
      "<<<iteration:[120/525] - total_loss: 0.3021  obj_loss: 0.1721  noobj_loss: 0.0933  bbox_loss: 0.0100  cls_loss: 0.0331  \n",
      "<<<iteration:[140/525] - total_loss: 0.2947  obj_loss: 0.1727  noobj_loss: 0.0993  bbox_loss: 0.0097  cls_loss: 0.0236  \n",
      "<<<iteration:[160/525] - total_loss: 0.2585  obj_loss: 0.1441  noobj_loss: 0.0979  bbox_loss: 0.0097  cls_loss: 0.0170  \n",
      "<<<iteration:[180/525] - total_loss: 0.2809  obj_loss: 0.1680  noobj_loss: 0.0940  bbox_loss: 0.0085  cls_loss: 0.0234  \n",
      "<<<iteration:[200/525] - total_loss: 0.3158  obj_loss: 0.1939  noobj_loss: 0.0930  bbox_loss: 0.0082  cls_loss: 0.0344  \n",
      "<<<iteration:[220/525] - total_loss: 0.2816  obj_loss: 0.1650  noobj_loss: 0.0979  bbox_loss: 0.0089  cls_loss: 0.0232  \n",
      "<<<iteration:[240/525] - total_loss: 0.2830  obj_loss: 0.1741  noobj_loss: 0.0869  bbox_loss: 0.0090  cls_loss: 0.0203  \n",
      "<<<iteration:[260/525] - total_loss: 0.2756  obj_loss: 0.1616  noobj_loss: 0.0973  bbox_loss: 0.0084  cls_loss: 0.0232  \n",
      "<<<iteration:[280/525] - total_loss: 0.2826  obj_loss: 0.1679  noobj_loss: 0.0931  bbox_loss: 0.0079  cls_loss: 0.0287  \n",
      "<<<iteration:[300/525] - total_loss: 0.2905  obj_loss: 0.1628  noobj_loss: 0.0914  bbox_loss: 0.0095  cls_loss: 0.0343  \n",
      "<<<iteration:[320/525] - total_loss: 0.2731  obj_loss: 0.1599  noobj_loss: 0.0964  bbox_loss: 0.0091  cls_loss: 0.0195  \n",
      "<<<iteration:[340/525] - total_loss: 0.3008  obj_loss: 0.1704  noobj_loss: 0.0994  bbox_loss: 0.0099  cls_loss: 0.0314  \n",
      "<<<iteration:[360/525] - total_loss: 0.2762  obj_loss: 0.1611  noobj_loss: 0.0923  bbox_loss: 0.0088  cls_loss: 0.0251  \n",
      "<<<iteration:[380/525] - total_loss: 0.3179  obj_loss: 0.1810  noobj_loss: 0.1069  bbox_loss: 0.0100  cls_loss: 0.0337  \n",
      "<<<iteration:[400/525] - total_loss: 0.2849  obj_loss: 0.1632  noobj_loss: 0.0955  bbox_loss: 0.0100  cls_loss: 0.0240  \n",
      "<<<iteration:[420/525] - total_loss: 0.2722  obj_loss: 0.1665  noobj_loss: 0.0932  bbox_loss: 0.0082  cls_loss: 0.0183  \n",
      "<<<iteration:[440/525] - total_loss: 0.3044  obj_loss: 0.1615  noobj_loss: 0.0960  bbox_loss: 0.0116  cls_loss: 0.0369  \n",
      "<<<iteration:[460/525] - total_loss: 0.2919  obj_loss: 0.1696  noobj_loss: 0.0968  bbox_loss: 0.0095  cls_loss: 0.0265  \n",
      "<<<iteration:[480/525] - total_loss: 0.2856  obj_loss: 0.1636  noobj_loss: 0.0977  bbox_loss: 0.0109  cls_loss: 0.0185  \n",
      "<<<iteration:[500/525] - total_loss: 0.2682  obj_loss: 0.1662  noobj_loss: 0.0974  bbox_loss: 0.0080  cls_loss: 0.0131  \n",
      "<<<iteration:[520/525] - total_loss: 0.2635  obj_loss: 0.1527  noobj_loss: 0.0954  bbox_loss: 0.0082  cls_loss: 0.0220  \n",
      "\n",
      "epoch:40/100 - Train Loss: 0.2841, Val Loss: 0.2845\n",
      "\n",
      "<<<iteration:[20/525] - total_loss: 0.2780  obj_loss: 0.1564  noobj_loss: 0.0966  bbox_loss: 0.0091  cls_loss: 0.0280  \n",
      "<<<iteration:[40/525] - total_loss: 0.2847  obj_loss: 0.1703  noobj_loss: 0.0931  bbox_loss: 0.0101  cls_loss: 0.0174  \n",
      "<<<iteration:[60/525] - total_loss: 0.2777  obj_loss: 0.1690  noobj_loss: 0.1000  bbox_loss: 0.0082  cls_loss: 0.0179  \n",
      "<<<iteration:[80/525] - total_loss: 0.2848  obj_loss: 0.1659  noobj_loss: 0.0986  bbox_loss: 0.0094  cls_loss: 0.0228  \n",
      "<<<iteration:[100/525] - total_loss: 0.2823  obj_loss: 0.1649  noobj_loss: 0.0959  bbox_loss: 0.0090  cls_loss: 0.0244  \n",
      "<<<iteration:[120/525] - total_loss: 0.2699  obj_loss: 0.1570  noobj_loss: 0.1037  bbox_loss: 0.0081  cls_loss: 0.0206  \n",
      "<<<iteration:[140/525] - total_loss: 0.2873  obj_loss: 0.1689  noobj_loss: 0.0904  bbox_loss: 0.0087  cls_loss: 0.0299  \n",
      "<<<iteration:[160/525] - total_loss: 0.3185  obj_loss: 0.1979  noobj_loss: 0.0940  bbox_loss: 0.0087  cls_loss: 0.0301  \n",
      "<<<iteration:[180/525] - total_loss: 0.2899  obj_loss: 0.1602  noobj_loss: 0.0939  bbox_loss: 0.0102  cls_loss: 0.0316  \n",
      "<<<iteration:[200/525] - total_loss: 0.2733  obj_loss: 0.1470  noobj_loss: 0.0924  bbox_loss: 0.0105  cls_loss: 0.0277  \n",
      "<<<iteration:[220/525] - total_loss: 0.2905  obj_loss: 0.1762  noobj_loss: 0.0967  bbox_loss: 0.0090  cls_loss: 0.0208  \n",
      "<<<iteration:[240/525] - total_loss: 0.2833  obj_loss: 0.1716  noobj_loss: 0.0978  bbox_loss: 0.0084  cls_loss: 0.0207  \n",
      "<<<iteration:[260/525] - total_loss: 0.2954  obj_loss: 0.1839  noobj_loss: 0.0948  bbox_loss: 0.0087  cls_loss: 0.0207  \n",
      "<<<iteration:[280/525] - total_loss: 0.2934  obj_loss: 0.1622  noobj_loss: 0.1051  bbox_loss: 0.0091  cls_loss: 0.0333  \n",
      "<<<iteration:[300/525] - total_loss: 0.3002  obj_loss: 0.1710  noobj_loss: 0.1010  bbox_loss: 0.0097  cls_loss: 0.0302  \n",
      "<<<iteration:[320/525] - total_loss: 0.2747  obj_loss: 0.1501  noobj_loss: 0.0975  bbox_loss: 0.0095  cls_loss: 0.0285  \n",
      "<<<iteration:[340/525] - total_loss: 0.2920  obj_loss: 0.1765  noobj_loss: 0.1019  bbox_loss: 0.0096  cls_loss: 0.0166  \n",
      "<<<iteration:[360/525] - total_loss: 0.2865  obj_loss: 0.1640  noobj_loss: 0.0979  bbox_loss: 0.0082  cls_loss: 0.0324  \n",
      "<<<iteration:[380/525] - total_loss: 0.2887  obj_loss: 0.1820  noobj_loss: 0.0974  bbox_loss: 0.0077  cls_loss: 0.0195  \n",
      "<<<iteration:[400/525] - total_loss: 0.2704  obj_loss: 0.1580  noobj_loss: 0.0987  bbox_loss: 0.0088  cls_loss: 0.0191  \n",
      "<<<iteration:[420/525] - total_loss: 0.2657  obj_loss: 0.1549  noobj_loss: 0.0976  bbox_loss: 0.0088  cls_loss: 0.0182  \n",
      "<<<iteration:[440/525] - total_loss: 0.2824  obj_loss: 0.1635  noobj_loss: 0.0975  bbox_loss: 0.0100  cls_loss: 0.0203  \n",
      "<<<iteration:[460/525] - total_loss: 0.2754  obj_loss: 0.1728  noobj_loss: 0.0932  bbox_loss: 0.0070  cls_loss: 0.0208  \n",
      "<<<iteration:[480/525] - total_loss: 0.2582  obj_loss: 0.1496  noobj_loss: 0.0983  bbox_loss: 0.0089  cls_loss: 0.0148  \n",
      "<<<iteration:[500/525] - total_loss: 0.2644  obj_loss: 0.1446  noobj_loss: 0.0990  bbox_loss: 0.0102  cls_loss: 0.0191  \n",
      "<<<iteration:[520/525] - total_loss: 0.2720  obj_loss: 0.1471  noobj_loss: 0.0833  bbox_loss: 0.0103  cls_loss: 0.0317  \n",
      "\n",
      "epoch:41/100 - Train Loss: 0.2815, Val Loss: 0.2825\n",
      "\n",
      "<<<iteration:[20/525] - total_loss: 0.2709  obj_loss: 0.1510  noobj_loss: 0.0967  bbox_loss: 0.0103  cls_loss: 0.0202  \n",
      "<<<iteration:[40/525] - total_loss: 0.2800  obj_loss: 0.1482  noobj_loss: 0.0912  bbox_loss: 0.0120  cls_loss: 0.0259  \n",
      "<<<iteration:[60/525] - total_loss: 0.3004  obj_loss: 0.1725  noobj_loss: 0.0894  bbox_loss: 0.0098  cls_loss: 0.0343  \n",
      "<<<iteration:[80/525] - total_loss: 0.2653  obj_loss: 0.1562  noobj_loss: 0.0919  bbox_loss: 0.0087  cls_loss: 0.0194  \n",
      "<<<iteration:[100/525] - total_loss: 0.2638  obj_loss: 0.1613  noobj_loss: 0.0975  bbox_loss: 0.0078  cls_loss: 0.0148  \n",
      "<<<iteration:[120/525] - total_loss: 0.2780  obj_loss: 0.1665  noobj_loss: 0.0923  bbox_loss: 0.0077  cls_loss: 0.0268  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<<<iteration:[140/525] - total_loss: 0.2857  obj_loss: 0.1718  noobj_loss: 0.0926  bbox_loss: 0.0086  cls_loss: 0.0246  \n",
      "<<<iteration:[160/525] - total_loss: 0.2717  obj_loss: 0.1580  noobj_loss: 0.0968  bbox_loss: 0.0102  cls_loss: 0.0146  \n",
      "<<<iteration:[180/525] - total_loss: 0.2882  obj_loss: 0.1770  noobj_loss: 0.0890  bbox_loss: 0.0088  cls_loss: 0.0227  \n",
      "<<<iteration:[200/525] - total_loss: 0.2932  obj_loss: 0.1720  noobj_loss: 0.0931  bbox_loss: 0.0098  cls_loss: 0.0257  \n",
      "<<<iteration:[220/525] - total_loss: 0.2970  obj_loss: 0.1509  noobj_loss: 0.1015  bbox_loss: 0.0107  cls_loss: 0.0417  \n",
      "<<<iteration:[240/525] - total_loss: 0.2884  obj_loss: 0.1593  noobj_loss: 0.1003  bbox_loss: 0.0101  cls_loss: 0.0288  \n",
      "<<<iteration:[260/525] - total_loss: 0.2928  obj_loss: 0.1640  noobj_loss: 0.1004  bbox_loss: 0.0082  cls_loss: 0.0376  \n",
      "<<<iteration:[280/525] - total_loss: 0.3013  obj_loss: 0.1804  noobj_loss: 0.1002  bbox_loss: 0.0095  cls_loss: 0.0235  \n",
      "<<<iteration:[300/525] - total_loss: 0.2793  obj_loss: 0.1566  noobj_loss: 0.1009  bbox_loss: 0.0092  cls_loss: 0.0263  \n",
      "<<<iteration:[320/525] - total_loss: 0.2776  obj_loss: 0.1696  noobj_loss: 0.1038  bbox_loss: 0.0081  cls_loss: 0.0158  \n",
      "<<<iteration:[340/525] - total_loss: 0.2908  obj_loss: 0.1721  noobj_loss: 0.0971  bbox_loss: 0.0095  cls_loss: 0.0228  \n",
      "<<<iteration:[360/525] - total_loss: 0.2895  obj_loss: 0.1610  noobj_loss: 0.1040  bbox_loss: 0.0095  cls_loss: 0.0288  \n",
      "<<<iteration:[380/525] - total_loss: 0.2787  obj_loss: 0.1716  noobj_loss: 0.0935  bbox_loss: 0.0082  cls_loss: 0.0191  \n",
      "<<<iteration:[400/525] - total_loss: 0.2782  obj_loss: 0.1625  noobj_loss: 0.1044  bbox_loss: 0.0082  cls_loss: 0.0226  \n",
      "<<<iteration:[420/525] - total_loss: 0.2743  obj_loss: 0.1530  noobj_loss: 0.0853  bbox_loss: 0.0110  cls_loss: 0.0236  \n",
      "<<<iteration:[440/525] - total_loss: 0.2561  obj_loss: 0.1422  noobj_loss: 0.0875  bbox_loss: 0.0093  cls_loss: 0.0239  \n",
      "<<<iteration:[460/525] - total_loss: 0.2813  obj_loss: 0.1463  noobj_loss: 0.0962  bbox_loss: 0.0134  cls_loss: 0.0201  \n",
      "<<<iteration:[480/525] - total_loss: 0.2979  obj_loss: 0.1606  noobj_loss: 0.0994  bbox_loss: 0.0143  cls_loss: 0.0162  \n",
      "<<<iteration:[500/525] - total_loss: 0.2723  obj_loss: 0.1526  noobj_loss: 0.0938  bbox_loss: 0.0117  cls_loss: 0.0142  \n",
      "<<<iteration:[520/525] - total_loss: 0.2730  obj_loss: 0.1619  noobj_loss: 0.1042  bbox_loss: 0.0088  cls_loss: 0.0150  \n",
      "\n",
      "epoch:42/100 - Train Loss: 0.2810, Val Loss: 0.2820\n",
      "\n",
      "<<<iteration:[20/525] - total_loss: 0.2979  obj_loss: 0.1664  noobj_loss: 0.0924  bbox_loss: 0.0106  cls_loss: 0.0322  \n",
      "<<<iteration:[40/525] - total_loss: 0.2586  obj_loss: 0.1543  noobj_loss: 0.0987  bbox_loss: 0.0082  cls_loss: 0.0138  \n",
      "<<<iteration:[60/525] - total_loss: 0.2682  obj_loss: 0.1497  noobj_loss: 0.0968  bbox_loss: 0.0099  cls_loss: 0.0206  \n",
      "<<<iteration:[80/525] - total_loss: 0.2955  obj_loss: 0.1695  noobj_loss: 0.0915  bbox_loss: 0.0104  cls_loss: 0.0280  \n",
      "<<<iteration:[100/525] - total_loss: 0.2704  obj_loss: 0.1619  noobj_loss: 0.0966  bbox_loss: 0.0081  cls_loss: 0.0195  \n",
      "<<<iteration:[120/525] - total_loss: 0.2925  obj_loss: 0.1662  noobj_loss: 0.0969  bbox_loss: 0.0093  cls_loss: 0.0314  \n",
      "<<<iteration:[140/525] - total_loss: 0.2930  obj_loss: 0.1769  noobj_loss: 0.0912  bbox_loss: 0.0094  cls_loss: 0.0237  \n",
      "<<<iteration:[160/525] - total_loss: 0.2656  obj_loss: 0.1371  noobj_loss: 0.0967  bbox_loss: 0.0101  cls_loss: 0.0299  \n",
      "<<<iteration:[180/525] - total_loss: 0.2611  obj_loss: 0.1667  noobj_loss: 0.0861  bbox_loss: 0.0075  cls_loss: 0.0141  \n",
      "<<<iteration:[200/525] - total_loss: 0.2737  obj_loss: 0.1537  noobj_loss: 0.0945  bbox_loss: 0.0098  cls_loss: 0.0238  \n",
      "<<<iteration:[220/525] - total_loss: 0.2638  obj_loss: 0.1639  noobj_loss: 0.0960  bbox_loss: 0.0078  cls_loss: 0.0128  \n",
      "<<<iteration:[240/525] - total_loss: 0.2790  obj_loss: 0.1605  noobj_loss: 0.0974  bbox_loss: 0.0084  cls_loss: 0.0281  \n",
      "<<<iteration:[260/525] - total_loss: 0.3272  obj_loss: 0.1728  noobj_loss: 0.1141  bbox_loss: 0.0108  cls_loss: 0.0432  \n",
      "<<<iteration:[280/525] - total_loss: 0.2831  obj_loss: 0.1612  noobj_loss: 0.0997  bbox_loss: 0.0093  cls_loss: 0.0253  \n",
      "<<<iteration:[300/525] - total_loss: 0.2811  obj_loss: 0.1681  noobj_loss: 0.0975  bbox_loss: 0.0089  cls_loss: 0.0198  \n",
      "<<<iteration:[320/525] - total_loss: 0.2784  obj_loss: 0.1567  noobj_loss: 0.0944  bbox_loss: 0.0106  cls_loss: 0.0215  \n",
      "<<<iteration:[340/525] - total_loss: 0.2655  obj_loss: 0.1536  noobj_loss: 0.0967  bbox_loss: 0.0084  cls_loss: 0.0214  \n",
      "<<<iteration:[360/525] - total_loss: 0.2883  obj_loss: 0.1656  noobj_loss: 0.0946  bbox_loss: 0.0111  cls_loss: 0.0201  \n",
      "<<<iteration:[380/525] - total_loss: 0.2747  obj_loss: 0.1621  noobj_loss: 0.0924  bbox_loss: 0.0094  cls_loss: 0.0194  \n",
      "<<<iteration:[400/525] - total_loss: 0.2875  obj_loss: 0.1715  noobj_loss: 0.0964  bbox_loss: 0.0088  cls_loss: 0.0236  \n",
      "<<<iteration:[420/525] - total_loss: 0.2777  obj_loss: 0.1623  noobj_loss: 0.0991  bbox_loss: 0.0080  cls_loss: 0.0260  \n",
      "<<<iteration:[440/525] - total_loss: 0.2810  obj_loss: 0.1667  noobj_loss: 0.0944  bbox_loss: 0.0099  cls_loss: 0.0173  \n",
      "<<<iteration:[460/525] - total_loss: 0.2637  obj_loss: 0.1592  noobj_loss: 0.0959  bbox_loss: 0.0077  cls_loss: 0.0181  \n",
      "<<<iteration:[480/525] - total_loss: 0.2872  obj_loss: 0.1606  noobj_loss: 0.0966  bbox_loss: 0.0098  cls_loss: 0.0294  \n",
      "<<<iteration:[500/525] - total_loss: 0.2789  obj_loss: 0.1662  noobj_loss: 0.0961  bbox_loss: 0.0085  cls_loss: 0.0221  \n",
      "<<<iteration:[520/525] - total_loss: 0.2773  obj_loss: 0.1552  noobj_loss: 0.0967  bbox_loss: 0.0103  cls_loss: 0.0220  \n",
      "\n",
      "epoch:43/100 - Train Loss: 0.2788, Val Loss: 0.2823\n",
      "\n",
      "<<<iteration:[20/525] - total_loss: 0.3121  obj_loss: 0.1769  noobj_loss: 0.1032  bbox_loss: 0.0105  cls_loss: 0.0312  \n",
      "<<<iteration:[40/525] - total_loss: 0.2755  obj_loss: 0.1517  noobj_loss: 0.0916  bbox_loss: 0.0104  cls_loss: 0.0259  \n",
      "<<<iteration:[60/525] - total_loss: 0.2644  obj_loss: 0.1597  noobj_loss: 0.0989  bbox_loss: 0.0083  cls_loss: 0.0136  \n",
      "<<<iteration:[80/525] - total_loss: 0.2830  obj_loss: 0.1700  noobj_loss: 0.0950  bbox_loss: 0.0086  cls_loss: 0.0226  \n",
      "<<<iteration:[100/525] - total_loss: 0.2808  obj_loss: 0.1541  noobj_loss: 0.0944  bbox_loss: 0.0107  cls_loss: 0.0258  \n",
      "<<<iteration:[120/525] - total_loss: 0.2812  obj_loss: 0.1696  noobj_loss: 0.0955  bbox_loss: 0.0082  cls_loss: 0.0227  \n",
      "<<<iteration:[140/525] - total_loss: 0.2752  obj_loss: 0.1624  noobj_loss: 0.0945  bbox_loss: 0.0078  cls_loss: 0.0267  \n",
      "<<<iteration:[160/525] - total_loss: 0.2707  obj_loss: 0.1515  noobj_loss: 0.0942  bbox_loss: 0.0090  cls_loss: 0.0271  \n",
      "<<<iteration:[180/525] - total_loss: 0.2842  obj_loss: 0.1685  noobj_loss: 0.0922  bbox_loss: 0.0092  cls_loss: 0.0236  \n",
      "<<<iteration:[200/525] - total_loss: 0.2554  obj_loss: 0.1519  noobj_loss: 0.0961  bbox_loss: 0.0076  cls_loss: 0.0174  \n",
      "<<<iteration:[220/525] - total_loss: 0.2782  obj_loss: 0.1603  noobj_loss: 0.1034  bbox_loss: 0.0086  cls_loss: 0.0234  \n",
      "<<<iteration:[240/525] - total_loss: 0.2869  obj_loss: 0.1660  noobj_loss: 0.0908  bbox_loss: 0.0088  cls_loss: 0.0315  \n",
      "<<<iteration:[260/525] - total_loss: 0.2824  obj_loss: 0.1705  noobj_loss: 0.0928  bbox_loss: 0.0083  cls_loss: 0.0238  \n",
      "<<<iteration:[280/525] - total_loss: 0.2840  obj_loss: 0.1682  noobj_loss: 0.0913  bbox_loss: 0.0102  cls_loss: 0.0194  \n",
      "<<<iteration:[300/525] - total_loss: 0.2691  obj_loss: 0.1613  noobj_loss: 0.0935  bbox_loss: 0.0078  cls_loss: 0.0220  \n",
      "<<<iteration:[320/525] - total_loss: 0.2706  obj_loss: 0.1549  noobj_loss: 0.1014  bbox_loss: 0.0081  cls_loss: 0.0247  \n",
      "<<<iteration:[340/525] - total_loss: 0.2841  obj_loss: 0.1621  noobj_loss: 0.0966  bbox_loss: 0.0094  cls_loss: 0.0268  \n",
      "<<<iteration:[360/525] - total_loss: 0.2918  obj_loss: 0.1665  noobj_loss: 0.0974  bbox_loss: 0.0098  cls_loss: 0.0275  \n",
      "<<<iteration:[380/525] - total_loss: 0.2705  obj_loss: 0.1625  noobj_loss: 0.0945  bbox_loss: 0.0082  cls_loss: 0.0197  \n",
      "<<<iteration:[400/525] - total_loss: 0.2775  obj_loss: 0.1732  noobj_loss: 0.1021  bbox_loss: 0.0076  cls_loss: 0.0151  \n",
      "<<<iteration:[420/525] - total_loss: 0.2622  obj_loss: 0.1546  noobj_loss: 0.1005  bbox_loss: 0.0085  cls_loss: 0.0150  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<<<iteration:[440/525] - total_loss: 0.2637  obj_loss: 0.1532  noobj_loss: 0.1004  bbox_loss: 0.0080  cls_loss: 0.0202  \n",
      "<<<iteration:[460/525] - total_loss: 0.3002  obj_loss: 0.1748  noobj_loss: 0.0999  bbox_loss: 0.0096  cls_loss: 0.0274  \n",
      "<<<iteration:[480/525] - total_loss: 0.2889  obj_loss: 0.1778  noobj_loss: 0.1007  bbox_loss: 0.0078  cls_loss: 0.0219  \n",
      "<<<iteration:[500/525] - total_loss: 0.3061  obj_loss: 0.1835  noobj_loss: 0.1039  bbox_loss: 0.0107  cls_loss: 0.0170  \n",
      "<<<iteration:[520/525] - total_loss: 0.2953  obj_loss: 0.1509  noobj_loss: 0.1007  bbox_loss: 0.0123  cls_loss: 0.0324  \n",
      "\n",
      "epoch:44/100 - Train Loss: 0.2804, Val Loss: 0.2825\n",
      "\n",
      "<<<iteration:[20/525] - total_loss: 0.2966  obj_loss: 0.1855  noobj_loss: 0.0997  bbox_loss: 0.0076  cls_loss: 0.0233  \n",
      "<<<iteration:[40/525] - total_loss: 0.2720  obj_loss: 0.1633  noobj_loss: 0.0988  bbox_loss: 0.0084  cls_loss: 0.0172  \n",
      "<<<iteration:[60/525] - total_loss: 0.2848  obj_loss: 0.1658  noobj_loss: 0.1032  bbox_loss: 0.0094  cls_loss: 0.0206  \n",
      "<<<iteration:[80/525] - total_loss: 0.2790  obj_loss: 0.1608  noobj_loss: 0.1013  bbox_loss: 0.0079  cls_loss: 0.0283  \n",
      "<<<iteration:[100/525] - total_loss: 0.2769  obj_loss: 0.1800  noobj_loss: 0.0995  bbox_loss: 0.0073  cls_loss: 0.0106  \n",
      "<<<iteration:[120/525] - total_loss: 0.2895  obj_loss: 0.1625  noobj_loss: 0.1123  bbox_loss: 0.0094  cls_loss: 0.0238  \n",
      "<<<iteration:[140/525] - total_loss: 0.2605  obj_loss: 0.1410  noobj_loss: 0.0879  bbox_loss: 0.0094  cls_loss: 0.0286  \n",
      "<<<iteration:[160/525] - total_loss: 0.2941  obj_loss: 0.1759  noobj_loss: 0.0934  bbox_loss: 0.0079  cls_loss: 0.0320  \n",
      "<<<iteration:[180/525] - total_loss: 0.2468  obj_loss: 0.1440  noobj_loss: 0.0951  bbox_loss: 0.0079  cls_loss: 0.0158  \n",
      "<<<iteration:[200/525] - total_loss: 0.2599  obj_loss: 0.1545  noobj_loss: 0.0850  bbox_loss: 0.0080  cls_loss: 0.0228  \n",
      "<<<iteration:[220/525] - total_loss: 0.2939  obj_loss: 0.1779  noobj_loss: 0.0981  bbox_loss: 0.0088  cls_loss: 0.0231  \n",
      "<<<iteration:[240/525] - total_loss: 0.2875  obj_loss: 0.1562  noobj_loss: 0.0974  bbox_loss: 0.0112  cls_loss: 0.0264  \n",
      "<<<iteration:[260/525] - total_loss: 0.2549  obj_loss: 0.1494  noobj_loss: 0.1022  bbox_loss: 0.0078  cls_loss: 0.0152  \n",
      "<<<iteration:[280/525] - total_loss: 0.2636  obj_loss: 0.1601  noobj_loss: 0.1071  bbox_loss: 0.0074  cls_loss: 0.0130  \n",
      "<<<iteration:[300/525] - total_loss: 0.2707  obj_loss: 0.1562  noobj_loss: 0.0964  bbox_loss: 0.0093  cls_loss: 0.0197  \n",
      "<<<iteration:[320/525] - total_loss: 0.2705  obj_loss: 0.1588  noobj_loss: 0.0998  bbox_loss: 0.0080  cls_loss: 0.0216  \n",
      "<<<iteration:[340/525] - total_loss: 0.2756  obj_loss: 0.1689  noobj_loss: 0.1021  bbox_loss: 0.0087  cls_loss: 0.0119  \n",
      "<<<iteration:[360/525] - total_loss: 0.2890  obj_loss: 0.1549  noobj_loss: 0.0954  bbox_loss: 0.0112  cls_loss: 0.0304  \n",
      "<<<iteration:[380/525] - total_loss: 0.2762  obj_loss: 0.1573  noobj_loss: 0.0895  bbox_loss: 0.0098  cls_loss: 0.0250  \n",
      "<<<iteration:[400/525] - total_loss: 0.2832  obj_loss: 0.1646  noobj_loss: 0.0995  bbox_loss: 0.0104  cls_loss: 0.0167  \n",
      "<<<iteration:[420/525] - total_loss: 0.2681  obj_loss: 0.1607  noobj_loss: 0.0971  bbox_loss: 0.0080  cls_loss: 0.0188  \n",
      "<<<iteration:[440/525] - total_loss: 0.2655  obj_loss: 0.1514  noobj_loss: 0.0911  bbox_loss: 0.0089  cls_loss: 0.0241  \n",
      "<<<iteration:[460/525] - total_loss: 0.2680  obj_loss: 0.1581  noobj_loss: 0.0984  bbox_loss: 0.0091  cls_loss: 0.0152  \n",
      "<<<iteration:[480/525] - total_loss: 0.2783  obj_loss: 0.1679  noobj_loss: 0.1021  bbox_loss: 0.0086  cls_loss: 0.0165  \n",
      "<<<iteration:[500/525] - total_loss: 0.2722  obj_loss: 0.1615  noobj_loss: 0.0952  bbox_loss: 0.0093  cls_loss: 0.0167  \n",
      "<<<iteration:[520/525] - total_loss: 0.2868  obj_loss: 0.1592  noobj_loss: 0.1037  bbox_loss: 0.0091  cls_loss: 0.0302  \n",
      "\n",
      "epoch:45/100 - Train Loss: 0.2753, Val Loss: 0.2887\n",
      "\n",
      "<<<iteration:[20/525] - total_loss: 0.2886  obj_loss: 0.1697  noobj_loss: 0.1027  bbox_loss: 0.0091  cls_loss: 0.0221  \n",
      "<<<iteration:[40/525] - total_loss: 0.2549  obj_loss: 0.1488  noobj_loss: 0.0920  bbox_loss: 0.0088  cls_loss: 0.0162  \n",
      "<<<iteration:[60/525] - total_loss: 0.2907  obj_loss: 0.1614  noobj_loss: 0.0957  bbox_loss: 0.0104  cls_loss: 0.0293  \n",
      "<<<iteration:[80/525] - total_loss: 0.2720  obj_loss: 0.1564  noobj_loss: 0.0988  bbox_loss: 0.0096  cls_loss: 0.0181  \n",
      "<<<iteration:[100/525] - total_loss: 0.2793  obj_loss: 0.1622  noobj_loss: 0.0967  bbox_loss: 0.0082  cls_loss: 0.0279  \n",
      "<<<iteration:[120/525] - total_loss: 0.2934  obj_loss: 0.1632  noobj_loss: 0.1023  bbox_loss: 0.0095  cls_loss: 0.0315  \n",
      "<<<iteration:[140/525] - total_loss: 0.2854  obj_loss: 0.1766  noobj_loss: 0.0987  bbox_loss: 0.0083  cls_loss: 0.0182  \n",
      "<<<iteration:[160/525] - total_loss: 0.3061  obj_loss: 0.1764  noobj_loss: 0.0968  bbox_loss: 0.0090  cls_loss: 0.0363  \n",
      "<<<iteration:[180/525] - total_loss: 0.2709  obj_loss: 0.1551  noobj_loss: 0.0949  bbox_loss: 0.0101  cls_loss: 0.0180  \n",
      "<<<iteration:[200/525] - total_loss: 0.2839  obj_loss: 0.1673  noobj_loss: 0.1086  bbox_loss: 0.0083  cls_loss: 0.0208  \n",
      "<<<iteration:[220/525] - total_loss: 0.2860  obj_loss: 0.1667  noobj_loss: 0.1032  bbox_loss: 0.0088  cls_loss: 0.0238  \n",
      "<<<iteration:[240/525] - total_loss: 0.2747  obj_loss: 0.1734  noobj_loss: 0.0947  bbox_loss: 0.0075  cls_loss: 0.0164  \n",
      "<<<iteration:[260/525] - total_loss: 0.2877  obj_loss: 0.1717  noobj_loss: 0.1109  bbox_loss: 0.0081  cls_loss: 0.0203  \n",
      "<<<iteration:[280/525] - total_loss: 0.2894  obj_loss: 0.1721  noobj_loss: 0.1069  bbox_loss: 0.0091  cls_loss: 0.0184  \n",
      "<<<iteration:[300/525] - total_loss: 0.2704  obj_loss: 0.1629  noobj_loss: 0.1078  bbox_loss: 0.0074  cls_loss: 0.0164  \n",
      "<<<iteration:[320/525] - total_loss: 0.2921  obj_loss: 0.1776  noobj_loss: 0.1026  bbox_loss: 0.0091  cls_loss: 0.0175  \n",
      "<<<iteration:[340/525] - total_loss: 0.2628  obj_loss: 0.1563  noobj_loss: 0.0961  bbox_loss: 0.0078  cls_loss: 0.0195  \n",
      "<<<iteration:[360/525] - total_loss: 0.2632  obj_loss: 0.1471  noobj_loss: 0.1007  bbox_loss: 0.0085  cls_loss: 0.0233  \n",
      "<<<iteration:[380/525] - total_loss: 0.2654  obj_loss: 0.1590  noobj_loss: 0.1037  bbox_loss: 0.0075  cls_loss: 0.0172  \n",
      "<<<iteration:[400/525] - total_loss: 0.2734  obj_loss: 0.1488  noobj_loss: 0.0936  bbox_loss: 0.0113  cls_loss: 0.0213  \n",
      "<<<iteration:[420/525] - total_loss: 0.2932  obj_loss: 0.1680  noobj_loss: 0.1140  bbox_loss: 0.0078  cls_loss: 0.0289  \n",
      "<<<iteration:[440/525] - total_loss: 0.2667  obj_loss: 0.1628  noobj_loss: 0.0960  bbox_loss: 0.0075  cls_loss: 0.0182  \n",
      "<<<iteration:[460/525] - total_loss: 0.2832  obj_loss: 0.1731  noobj_loss: 0.0916  bbox_loss: 0.0092  cls_loss: 0.0185  \n",
      "<<<iteration:[480/525] - total_loss: 0.2927  obj_loss: 0.1654  noobj_loss: 0.1012  bbox_loss: 0.0102  cls_loss: 0.0257  \n",
      "<<<iteration:[500/525] - total_loss: 0.2595  obj_loss: 0.1511  noobj_loss: 0.0947  bbox_loss: 0.0084  cls_loss: 0.0191  \n",
      "<<<iteration:[520/525] - total_loss: 0.2694  obj_loss: 0.1547  noobj_loss: 0.1012  bbox_loss: 0.0094  cls_loss: 0.0168  \n",
      "\n",
      "epoch:46/100 - Train Loss: 0.2784, Val Loss: 0.2846\n",
      "\n",
      "<<<iteration:[20/525] - total_loss: 0.2707  obj_loss: 0.1602  noobj_loss: 0.1052  bbox_loss: 0.0090  cls_loss: 0.0128  \n",
      "<<<iteration:[40/525] - total_loss: 0.2657  obj_loss: 0.1499  noobj_loss: 0.1015  bbox_loss: 0.0092  cls_loss: 0.0191  \n",
      "<<<iteration:[60/525] - total_loss: 0.2735  obj_loss: 0.1599  noobj_loss: 0.1126  bbox_loss: 0.0079  cls_loss: 0.0177  \n",
      "<<<iteration:[80/525] - total_loss: 0.2868  obj_loss: 0.1672  noobj_loss: 0.1021  bbox_loss: 0.0089  cls_loss: 0.0241  \n",
      "<<<iteration:[100/525] - total_loss: 0.2729  obj_loss: 0.1614  noobj_loss: 0.0930  bbox_loss: 0.0084  cls_loss: 0.0229  \n",
      "<<<iteration:[120/525] - total_loss: 0.2799  obj_loss: 0.1684  noobj_loss: 0.0949  bbox_loss: 0.0084  cls_loss: 0.0223  \n",
      "<<<iteration:[140/525] - total_loss: 0.2775  obj_loss: 0.1609  noobj_loss: 0.0975  bbox_loss: 0.0092  cls_loss: 0.0218  \n",
      "<<<iteration:[160/525] - total_loss: 0.2814  obj_loss: 0.1762  noobj_loss: 0.1010  bbox_loss: 0.0079  cls_loss: 0.0153  \n",
      "<<<iteration:[180/525] - total_loss: 0.3051  obj_loss: 0.1901  noobj_loss: 0.1007  bbox_loss: 0.0090  cls_loss: 0.0199  \n",
      "<<<iteration:[200/525] - total_loss: 0.2686  obj_loss: 0.1570  noobj_loss: 0.1017  bbox_loss: 0.0086  cls_loss: 0.0177  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<<<iteration:[220/525] - total_loss: 0.2834  obj_loss: 0.1735  noobj_loss: 0.1037  bbox_loss: 0.0080  cls_loss: 0.0182  \n",
      "<<<iteration:[240/525] - total_loss: 0.2667  obj_loss: 0.1541  noobj_loss: 0.0961  bbox_loss: 0.0097  cls_loss: 0.0159  \n",
      "<<<iteration:[260/525] - total_loss: 0.2791  obj_loss: 0.1641  noobj_loss: 0.1034  bbox_loss: 0.0082  cls_loss: 0.0224  \n",
      "<<<iteration:[280/525] - total_loss: 0.2664  obj_loss: 0.1504  noobj_loss: 0.0977  bbox_loss: 0.0085  cls_loss: 0.0247  \n",
      "<<<iteration:[300/525] - total_loss: 0.2959  obj_loss: 0.1701  noobj_loss: 0.1010  bbox_loss: 0.0110  cls_loss: 0.0202  \n",
      "<<<iteration:[320/525] - total_loss: 0.2825  obj_loss: 0.1716  noobj_loss: 0.0964  bbox_loss: 0.0086  cls_loss: 0.0199  \n",
      "<<<iteration:[340/525] - total_loss: 0.2629  obj_loss: 0.1548  noobj_loss: 0.0929  bbox_loss: 0.0087  cls_loss: 0.0184  \n",
      "<<<iteration:[360/525] - total_loss: 0.2954  obj_loss: 0.1751  noobj_loss: 0.1082  bbox_loss: 0.0093  cls_loss: 0.0199  \n",
      "<<<iteration:[380/525] - total_loss: 0.2873  obj_loss: 0.1613  noobj_loss: 0.1103  bbox_loss: 0.0083  cls_loss: 0.0295  \n",
      "<<<iteration:[400/525] - total_loss: 0.2871  obj_loss: 0.1777  noobj_loss: 0.1146  bbox_loss: 0.0072  cls_loss: 0.0159  \n",
      "<<<iteration:[420/525] - total_loss: 0.2700  obj_loss: 0.1524  noobj_loss: 0.1073  bbox_loss: 0.0086  cls_loss: 0.0208  \n",
      "<<<iteration:[440/525] - total_loss: 0.2762  obj_loss: 0.1810  noobj_loss: 0.0952  bbox_loss: 0.0065  cls_loss: 0.0152  \n",
      "<<<iteration:[460/525] - total_loss: 0.2846  obj_loss: 0.1610  noobj_loss: 0.1018  bbox_loss: 0.0105  cls_loss: 0.0204  \n",
      "<<<iteration:[480/525] - total_loss: 0.2870  obj_loss: 0.1661  noobj_loss: 0.0995  bbox_loss: 0.0094  cls_loss: 0.0240  \n",
      "<<<iteration:[500/525] - total_loss: 0.3101  obj_loss: 0.1600  noobj_loss: 0.1146  bbox_loss: 0.0115  cls_loss: 0.0354  \n",
      "<<<iteration:[520/525] - total_loss: 0.2870  obj_loss: 0.1624  noobj_loss: 0.1020  bbox_loss: 0.0102  cls_loss: 0.0228  \n",
      "\n",
      "epoch:47/100 - Train Loss: 0.2806, Val Loss: 0.2961\n",
      "\n",
      "<<<iteration:[20/525] - total_loss: 0.2807  obj_loss: 0.1642  noobj_loss: 0.1139  bbox_loss: 0.0090  cls_loss: 0.0146  \n",
      "<<<iteration:[40/525] - total_loss: 0.3015  obj_loss: 0.1640  noobj_loss: 0.0937  bbox_loss: 0.0116  cls_loss: 0.0325  \n",
      "<<<iteration:[60/525] - total_loss: 0.2689  obj_loss: 0.1646  noobj_loss: 0.0930  bbox_loss: 0.0080  cls_loss: 0.0177  \n",
      "<<<iteration:[80/525] - total_loss: 0.2739  obj_loss: 0.1576  noobj_loss: 0.0907  bbox_loss: 0.0107  cls_loss: 0.0175  \n",
      "<<<iteration:[100/525] - total_loss: 0.2684  obj_loss: 0.1562  noobj_loss: 0.0996  bbox_loss: 0.0082  cls_loss: 0.0212  \n",
      "<<<iteration:[120/525] - total_loss: 0.2922  obj_loss: 0.1832  noobj_loss: 0.0965  bbox_loss: 0.0077  cls_loss: 0.0225  \n",
      "<<<iteration:[140/525] - total_loss: 0.2652  obj_loss: 0.1666  noobj_loss: 0.0974  bbox_loss: 0.0071  cls_loss: 0.0142  \n",
      "<<<iteration:[160/525] - total_loss: 0.2715  obj_loss: 0.1589  noobj_loss: 0.1112  bbox_loss: 0.0081  cls_loss: 0.0167  \n",
      "<<<iteration:[180/525] - total_loss: 0.2835  obj_loss: 0.1619  noobj_loss: 0.1042  bbox_loss: 0.0097  cls_loss: 0.0209  \n",
      "<<<iteration:[200/525] - total_loss: 0.2813  obj_loss: 0.1648  noobj_loss: 0.1057  bbox_loss: 0.0088  cls_loss: 0.0194  \n",
      "<<<iteration:[220/525] - total_loss: 0.2603  obj_loss: 0.1587  noobj_loss: 0.0988  bbox_loss: 0.0081  cls_loss: 0.0119  \n",
      "<<<iteration:[240/525] - total_loss: 0.2679  obj_loss: 0.1564  noobj_loss: 0.0971  bbox_loss: 0.0093  cls_loss: 0.0166  \n",
      "<<<iteration:[260/525] - total_loss: 0.2869  obj_loss: 0.1611  noobj_loss: 0.1141  bbox_loss: 0.0076  cls_loss: 0.0310  \n",
      "<<<iteration:[280/525] - total_loss: 0.3487  obj_loss: 0.1516  noobj_loss: 0.1168  bbox_loss: 0.0160  cls_loss: 0.0588  \n",
      "<<<iteration:[300/525] - total_loss: 0.2844  obj_loss: 0.1729  noobj_loss: 0.1043  bbox_loss: 0.0086  cls_loss: 0.0162  \n",
      "<<<iteration:[320/525] - total_loss: 0.2682  obj_loss: 0.1573  noobj_loss: 0.1007  bbox_loss: 0.0078  cls_loss: 0.0217  \n",
      "<<<iteration:[340/525] - total_loss: 0.2595  obj_loss: 0.1444  noobj_loss: 0.0979  bbox_loss: 0.0092  cls_loss: 0.0199  \n",
      "<<<iteration:[360/525] - total_loss: 0.2793  obj_loss: 0.1596  noobj_loss: 0.1010  bbox_loss: 0.0094  cls_loss: 0.0221  \n",
      "<<<iteration:[380/525] - total_loss: 0.2824  obj_loss: 0.1538  noobj_loss: 0.0957  bbox_loss: 0.0093  cls_loss: 0.0339  \n",
      "<<<iteration:[400/525] - total_loss: 0.2758  obj_loss: 0.1694  noobj_loss: 0.1001  bbox_loss: 0.0076  cls_loss: 0.0182  \n",
      "<<<iteration:[420/525] - total_loss: 0.2778  obj_loss: 0.1636  noobj_loss: 0.1066  bbox_loss: 0.0079  cls_loss: 0.0213  \n",
      "<<<iteration:[440/525] - total_loss: 0.2992  obj_loss: 0.1675  noobj_loss: 0.1067  bbox_loss: 0.0095  cls_loss: 0.0308  \n",
      "<<<iteration:[460/525] - total_loss: 0.3089  obj_loss: 0.1805  noobj_loss: 0.1032  bbox_loss: 0.0087  cls_loss: 0.0334  \n",
      "<<<iteration:[480/525] - total_loss: 0.2718  obj_loss: 0.1546  noobj_loss: 0.1041  bbox_loss: 0.0090  cls_loss: 0.0201  \n",
      "<<<iteration:[500/525] - total_loss: 0.2802  obj_loss: 0.1666  noobj_loss: 0.0999  bbox_loss: 0.0094  cls_loss: 0.0164  \n",
      "<<<iteration:[520/525] - total_loss: 0.2690  obj_loss: 0.1589  noobj_loss: 0.1053  bbox_loss: 0.0083  cls_loss: 0.0161  \n",
      "\n",
      "epoch:48/100 - Train Loss: 0.2804, Val Loss: 0.2853\n",
      "\n",
      "<<<iteration:[20/525] - total_loss: 0.2819  obj_loss: 0.1554  noobj_loss: 0.1016  bbox_loss: 0.0092  cls_loss: 0.0298  \n",
      "<<<iteration:[40/525] - total_loss: 0.2675  obj_loss: 0.1548  noobj_loss: 0.1117  bbox_loss: 0.0075  cls_loss: 0.0194  \n",
      "<<<iteration:[60/525] - total_loss: 0.2810  obj_loss: 0.1760  noobj_loss: 0.0992  bbox_loss: 0.0082  cls_loss: 0.0145  \n",
      "<<<iteration:[80/525] - total_loss: 0.2730  obj_loss: 0.1650  noobj_loss: 0.1076  bbox_loss: 0.0075  cls_loss: 0.0167  \n",
      "<<<iteration:[100/525] - total_loss: 0.2688  obj_loss: 0.1740  noobj_loss: 0.0941  bbox_loss: 0.0074  cls_loss: 0.0106  \n",
      "<<<iteration:[120/525] - total_loss: 0.2778  obj_loss: 0.1749  noobj_loss: 0.0997  bbox_loss: 0.0072  cls_loss: 0.0170  \n",
      "<<<iteration:[140/525] - total_loss: 0.2714  obj_loss: 0.1444  noobj_loss: 0.1031  bbox_loss: 0.0103  cls_loss: 0.0241  \n",
      "<<<iteration:[160/525] - total_loss: 0.2749  obj_loss: 0.1673  noobj_loss: 0.1004  bbox_loss: 0.0076  cls_loss: 0.0195  \n",
      "<<<iteration:[180/525] - total_loss: 0.2859  obj_loss: 0.1616  noobj_loss: 0.1024  bbox_loss: 0.0097  cls_loss: 0.0245  \n",
      "<<<iteration:[200/525] - total_loss: 0.2721  obj_loss: 0.1634  noobj_loss: 0.0982  bbox_loss: 0.0086  cls_loss: 0.0168  \n",
      "<<<iteration:[220/525] - total_loss: 0.2836  obj_loss: 0.1699  noobj_loss: 0.1066  bbox_loss: 0.0083  cls_loss: 0.0187  \n",
      "<<<iteration:[240/525] - total_loss: 0.2505  obj_loss: 0.1502  noobj_loss: 0.1056  bbox_loss: 0.0074  cls_loss: 0.0104  \n",
      "<<<iteration:[260/525] - total_loss: 0.2918  obj_loss: 0.1854  noobj_loss: 0.1043  bbox_loss: 0.0074  cls_loss: 0.0171  \n",
      "<<<iteration:[280/525] - total_loss: 0.2794  obj_loss: 0.1653  noobj_loss: 0.1042  bbox_loss: 0.0079  cls_loss: 0.0223  \n",
      "<<<iteration:[300/525] - total_loss: 0.2865  obj_loss: 0.1650  noobj_loss: 0.0979  bbox_loss: 0.0095  cls_loss: 0.0252  \n",
      "<<<iteration:[320/525] - total_loss: 0.2630  obj_loss: 0.1590  noobj_loss: 0.1147  bbox_loss: 0.0068  cls_loss: 0.0128  \n",
      "<<<iteration:[340/525] - total_loss: 0.2779  obj_loss: 0.1698  noobj_loss: 0.1033  bbox_loss: 0.0077  cls_loss: 0.0181  \n",
      "<<<iteration:[360/525] - total_loss: 0.2639  obj_loss: 0.1544  noobj_loss: 0.1056  bbox_loss: 0.0090  cls_loss: 0.0120  \n",
      "<<<iteration:[380/525] - total_loss: 0.2838  obj_loss: 0.1530  noobj_loss: 0.1002  bbox_loss: 0.0097  cls_loss: 0.0324  \n",
      "<<<iteration:[400/525] - total_loss: 0.2751  obj_loss: 0.1585  noobj_loss: 0.1042  bbox_loss: 0.0092  cls_loss: 0.0187  \n",
      "<<<iteration:[420/525] - total_loss: 0.2691  obj_loss: 0.1522  noobj_loss: 0.0938  bbox_loss: 0.0090  cls_loss: 0.0250  \n",
      "<<<iteration:[440/525] - total_loss: 0.2769  obj_loss: 0.1539  noobj_loss: 0.1024  bbox_loss: 0.0092  cls_loss: 0.0259  \n",
      "<<<iteration:[460/525] - total_loss: 0.2832  obj_loss: 0.1813  noobj_loss: 0.1009  bbox_loss: 0.0073  cls_loss: 0.0149  \n",
      "<<<iteration:[480/525] - total_loss: 0.2777  obj_loss: 0.1794  noobj_loss: 0.1047  bbox_loss: 0.0071  cls_loss: 0.0106  \n",
      "<<<iteration:[500/525] - total_loss: 0.2768  obj_loss: 0.1575  noobj_loss: 0.0953  bbox_loss: 0.0092  cls_loss: 0.0255  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<<<iteration:[520/525] - total_loss: 0.3063  obj_loss: 0.1803  noobj_loss: 0.1096  bbox_loss: 0.0077  cls_loss: 0.0324  \n",
      "\n",
      "epoch:49/100 - Train Loss: 0.2765, Val Loss: 0.2882\n",
      "\n",
      "<<<iteration:[20/525] - total_loss: 0.2634  obj_loss: 0.1581  noobj_loss: 0.0998  bbox_loss: 0.0082  cls_loss: 0.0145  \n",
      "<<<iteration:[40/525] - total_loss: 0.2775  obj_loss: 0.1638  noobj_loss: 0.1096  bbox_loss: 0.0092  cls_loss: 0.0127  \n",
      "<<<iteration:[60/525] - total_loss: 0.2747  obj_loss: 0.1685  noobj_loss: 0.0977  bbox_loss: 0.0073  cls_loss: 0.0207  \n",
      "<<<iteration:[80/525] - total_loss: 0.2769  obj_loss: 0.1727  noobj_loss: 0.1016  bbox_loss: 0.0079  cls_loss: 0.0140  \n",
      "<<<iteration:[100/525] - total_loss: 0.2774  obj_loss: 0.1691  noobj_loss: 0.1084  bbox_loss: 0.0075  cls_loss: 0.0166  \n",
      "<<<iteration:[120/525] - total_loss: 0.2714  obj_loss: 0.1637  noobj_loss: 0.1033  bbox_loss: 0.0076  cls_loss: 0.0183  \n",
      "<<<iteration:[140/525] - total_loss: 0.2905  obj_loss: 0.1646  noobj_loss: 0.1006  bbox_loss: 0.0096  cls_loss: 0.0274  \n",
      "<<<iteration:[160/525] - total_loss: 0.2835  obj_loss: 0.1726  noobj_loss: 0.1040  bbox_loss: 0.0090  cls_loss: 0.0138  \n",
      "<<<iteration:[180/525] - total_loss: 0.2759  obj_loss: 0.1609  noobj_loss: 0.0966  bbox_loss: 0.0099  cls_loss: 0.0173  \n",
      "<<<iteration:[200/525] - total_loss: 0.2831  obj_loss: 0.1681  noobj_loss: 0.1025  bbox_loss: 0.0093  cls_loss: 0.0173  \n",
      "<<<iteration:[220/525] - total_loss: 0.2920  obj_loss: 0.1732  noobj_loss: 0.1191  bbox_loss: 0.0081  cls_loss: 0.0186  \n",
      "<<<iteration:[240/525] - total_loss: 0.2784  obj_loss: 0.1737  noobj_loss: 0.1077  bbox_loss: 0.0077  cls_loss: 0.0125  \n",
      "<<<iteration:[260/525] - total_loss: 0.2716  obj_loss: 0.1530  noobj_loss: 0.1063  bbox_loss: 0.0085  cls_loss: 0.0229  \n",
      "<<<iteration:[280/525] - total_loss: 0.2671  obj_loss: 0.1559  noobj_loss: 0.0964  bbox_loss: 0.0087  cls_loss: 0.0196  \n",
      "<<<iteration:[300/525] - total_loss: 0.2857  obj_loss: 0.1565  noobj_loss: 0.1134  bbox_loss: 0.0088  cls_loss: 0.0287  \n",
      "<<<iteration:[320/525] - total_loss: 0.2777  obj_loss: 0.1689  noobj_loss: 0.1051  bbox_loss: 0.0078  cls_loss: 0.0174  \n",
      "<<<iteration:[340/525] - total_loss: 0.2780  obj_loss: 0.1723  noobj_loss: 0.1138  bbox_loss: 0.0075  cls_loss: 0.0111  \n",
      "<<<iteration:[360/525] - total_loss: 0.2913  obj_loss: 0.1719  noobj_loss: 0.1139  bbox_loss: 0.0085  cls_loss: 0.0201  \n",
      "<<<iteration:[380/525] - total_loss: 0.2883  obj_loss: 0.1734  noobj_loss: 0.1018  bbox_loss: 0.0095  cls_loss: 0.0164  \n",
      "<<<iteration:[400/525] - total_loss: 0.2703  obj_loss: 0.1651  noobj_loss: 0.1022  bbox_loss: 0.0084  cls_loss: 0.0120  \n",
      "<<<iteration:[420/525] - total_loss: 0.2599  obj_loss: 0.1481  noobj_loss: 0.1015  bbox_loss: 0.0084  cls_loss: 0.0191  \n",
      "<<<iteration:[440/525] - total_loss: 0.2645  obj_loss: 0.1620  noobj_loss: 0.0974  bbox_loss: 0.0079  cls_loss: 0.0142  \n",
      "<<<iteration:[460/525] - total_loss: 0.2708  obj_loss: 0.1442  noobj_loss: 0.0934  bbox_loss: 0.0090  cls_loss: 0.0351  \n",
      "<<<iteration:[480/525] - total_loss: 0.2535  obj_loss: 0.1493  noobj_loss: 0.0989  bbox_loss: 0.0075  cls_loss: 0.0171  \n",
      "<<<iteration:[500/525] - total_loss: 0.2775  obj_loss: 0.1756  noobj_loss: 0.1069  bbox_loss: 0.0076  cls_loss: 0.0106  \n",
      "<<<iteration:[520/525] - total_loss: 0.2680  obj_loss: 0.1575  noobj_loss: 0.1022  bbox_loss: 0.0090  cls_loss: 0.0147  \n",
      "\n",
      "epoch:50/100 - Train Loss: 0.2750, Val Loss: 0.2761\n",
      "\n",
      "<<<iteration:[20/525] - total_loss: 0.2966  obj_loss: 0.1699  noobj_loss: 0.1109  bbox_loss: 0.0092  cls_loss: 0.0251  \n",
      "<<<iteration:[40/525] - total_loss: 0.2937  obj_loss: 0.1710  noobj_loss: 0.0973  bbox_loss: 0.0111  cls_loss: 0.0188  \n",
      "<<<iteration:[60/525] - total_loss: 0.2837  obj_loss: 0.1587  noobj_loss: 0.1019  bbox_loss: 0.0098  cls_loss: 0.0252  \n",
      "<<<iteration:[80/525] - total_loss: 0.2463  obj_loss: 0.1419  noobj_loss: 0.1026  bbox_loss: 0.0077  cls_loss: 0.0147  \n",
      "<<<iteration:[100/525] - total_loss: 0.2551  obj_loss: 0.1516  noobj_loss: 0.1012  bbox_loss: 0.0072  cls_loss: 0.0170  \n",
      "<<<iteration:[120/525] - total_loss: 0.2727  obj_loss: 0.1609  noobj_loss: 0.0973  bbox_loss: 0.0091  cls_loss: 0.0175  \n",
      "<<<iteration:[140/525] - total_loss: 0.2695  obj_loss: 0.1527  noobj_loss: 0.1041  bbox_loss: 0.0082  cls_loss: 0.0240  \n",
      "<<<iteration:[160/525] - total_loss: 0.2662  obj_loss: 0.1654  noobj_loss: 0.0928  bbox_loss: 0.0083  cls_loss: 0.0128  \n",
      "<<<iteration:[180/525] - total_loss: 0.2453  obj_loss: 0.1527  noobj_loss: 0.0993  bbox_loss: 0.0065  cls_loss: 0.0104  \n",
      "<<<iteration:[200/525] - total_loss: 0.2975  obj_loss: 0.1799  noobj_loss: 0.0976  bbox_loss: 0.0077  cls_loss: 0.0303  \n",
      "<<<iteration:[220/525] - total_loss: 0.2843  obj_loss: 0.1666  noobj_loss: 0.1074  bbox_loss: 0.0096  cls_loss: 0.0163  \n",
      "<<<iteration:[240/525] - total_loss: 0.2762  obj_loss: 0.1782  noobj_loss: 0.1041  bbox_loss: 0.0064  cls_loss: 0.0138  \n",
      "<<<iteration:[260/525] - total_loss: 0.2729  obj_loss: 0.1614  noobj_loss: 0.1034  bbox_loss: 0.0083  cls_loss: 0.0184  \n",
      "<<<iteration:[280/525] - total_loss: 0.2796  obj_loss: 0.1668  noobj_loss: 0.1046  bbox_loss: 0.0082  cls_loss: 0.0195  \n",
      "<<<iteration:[300/525] - total_loss: 0.2674  obj_loss: 0.1619  noobj_loss: 0.1086  bbox_loss: 0.0068  cls_loss: 0.0174  \n",
      "<<<iteration:[320/525] - total_loss: 0.3134  obj_loss: 0.1946  noobj_loss: 0.0966  bbox_loss: 0.0078  cls_loss: 0.0315  \n",
      "<<<iteration:[340/525] - total_loss: 0.2401  obj_loss: 0.1372  noobj_loss: 0.1034  bbox_loss: 0.0073  cls_loss: 0.0148  \n",
      "<<<iteration:[360/525] - total_loss: 0.2792  obj_loss: 0.1761  noobj_loss: 0.1093  bbox_loss: 0.0068  cls_loss: 0.0147  \n",
      "<<<iteration:[380/525] - total_loss: 0.2935  obj_loss: 0.1809  noobj_loss: 0.1024  bbox_loss: 0.0079  cls_loss: 0.0217  \n",
      "<<<iteration:[400/525] - total_loss: 0.2671  obj_loss: 0.1496  noobj_loss: 0.1045  bbox_loss: 0.0083  cls_loss: 0.0237  \n",
      "<<<iteration:[420/525] - total_loss: 0.2882  obj_loss: 0.1766  noobj_loss: 0.1078  bbox_loss: 0.0070  cls_loss: 0.0227  \n",
      "<<<iteration:[440/525] - total_loss: 0.2642  obj_loss: 0.1512  noobj_loss: 0.1145  bbox_loss: 0.0085  cls_loss: 0.0131  \n",
      "<<<iteration:[460/525] - total_loss: 0.2706  obj_loss: 0.1524  noobj_loss: 0.1050  bbox_loss: 0.0085  cls_loss: 0.0230  \n",
      "<<<iteration:[480/525] - total_loss: 0.2862  obj_loss: 0.1729  noobj_loss: 0.1034  bbox_loss: 0.0084  cls_loss: 0.0194  \n",
      "<<<iteration:[500/525] - total_loss: 0.2729  obj_loss: 0.1638  noobj_loss: 0.1002  bbox_loss: 0.0085  cls_loss: 0.0166  \n",
      "<<<iteration:[520/525] - total_loss: 0.2907  obj_loss: 0.1744  noobj_loss: 0.1126  bbox_loss: 0.0070  cls_loss: 0.0248  \n",
      "\n",
      "epoch:51/100 - Train Loss: 0.2755, Val Loss: 0.2757\n",
      "\n",
      "<<<iteration:[20/525] - total_loss: 0.2827  obj_loss: 0.1725  noobj_loss: 0.1122  bbox_loss: 0.0080  cls_loss: 0.0141  \n",
      "<<<iteration:[40/525] - total_loss: 0.2652  obj_loss: 0.1639  noobj_loss: 0.0997  bbox_loss: 0.0075  cls_loss: 0.0137  \n",
      "<<<iteration:[60/525] - total_loss: 0.2772  obj_loss: 0.1738  noobj_loss: 0.0995  bbox_loss: 0.0061  cls_loss: 0.0231  \n",
      "<<<iteration:[80/525] - total_loss: 0.2562  obj_loss: 0.1474  noobj_loss: 0.0971  bbox_loss: 0.0080  cls_loss: 0.0200  \n",
      "<<<iteration:[100/525] - total_loss: 0.3070  obj_loss: 0.1813  noobj_loss: 0.1071  bbox_loss: 0.0084  cls_loss: 0.0300  \n",
      "<<<iteration:[120/525] - total_loss: 0.3007  obj_loss: 0.1748  noobj_loss: 0.1085  bbox_loss: 0.0108  cls_loss: 0.0176  \n",
      "<<<iteration:[140/525] - total_loss: 0.2680  obj_loss: 0.1645  noobj_loss: 0.1029  bbox_loss: 0.0077  cls_loss: 0.0137  \n",
      "<<<iteration:[160/525] - total_loss: 0.2761  obj_loss: 0.1727  noobj_loss: 0.1066  bbox_loss: 0.0077  cls_loss: 0.0115  \n",
      "<<<iteration:[180/525] - total_loss: 0.2508  obj_loss: 0.1379  noobj_loss: 0.0952  bbox_loss: 0.0095  cls_loss: 0.0177  \n",
      "<<<iteration:[200/525] - total_loss: 0.2568  obj_loss: 0.1539  noobj_loss: 0.1061  bbox_loss: 0.0079  cls_loss: 0.0105  \n",
      "<<<iteration:[220/525] - total_loss: 0.2634  obj_loss: 0.1585  noobj_loss: 0.0943  bbox_loss: 0.0080  cls_loss: 0.0175  \n",
      "<<<iteration:[240/525] - total_loss: 0.2701  obj_loss: 0.1512  noobj_loss: 0.1107  bbox_loss: 0.0088  cls_loss: 0.0197  \n",
      "<<<iteration:[260/525] - total_loss: 0.2703  obj_loss: 0.1544  noobj_loss: 0.1069  bbox_loss: 0.0092  cls_loss: 0.0167  \n",
      "<<<iteration:[280/525] - total_loss: 0.2930  obj_loss: 0.1774  noobj_loss: 0.1056  bbox_loss: 0.0088  cls_loss: 0.0189  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<<<iteration:[300/525] - total_loss: 0.2683  obj_loss: 0.1657  noobj_loss: 0.1059  bbox_loss: 0.0074  cls_loss: 0.0129  \n",
      "<<<iteration:[320/525] - total_loss: 0.2829  obj_loss: 0.1696  noobj_loss: 0.1050  bbox_loss: 0.0073  cls_loss: 0.0240  \n",
      "<<<iteration:[340/525] - total_loss: 0.2723  obj_loss: 0.1575  noobj_loss: 0.1042  bbox_loss: 0.0090  cls_loss: 0.0175  \n",
      "<<<iteration:[360/525] - total_loss: 0.2673  obj_loss: 0.1582  noobj_loss: 0.1164  bbox_loss: 0.0067  cls_loss: 0.0172  \n",
      "<<<iteration:[380/525] - total_loss: 0.2412  obj_loss: 0.1457  noobj_loss: 0.1011  bbox_loss: 0.0061  cls_loss: 0.0147  \n",
      "<<<iteration:[400/525] - total_loss: 0.2891  obj_loss: 0.1715  noobj_loss: 0.1070  bbox_loss: 0.0077  cls_loss: 0.0255  \n",
      "<<<iteration:[420/525] - total_loss: 0.3026  obj_loss: 0.1681  noobj_loss: 0.1139  bbox_loss: 0.0085  cls_loss: 0.0352  \n",
      "<<<iteration:[440/525] - total_loss: 0.2747  obj_loss: 0.1654  noobj_loss: 0.1093  bbox_loss: 0.0079  cls_loss: 0.0152  \n",
      "<<<iteration:[460/525] - total_loss: 0.2761  obj_loss: 0.1730  noobj_loss: 0.1125  bbox_loss: 0.0072  cls_loss: 0.0108  \n",
      "<<<iteration:[480/525] - total_loss: 0.2865  obj_loss: 0.1706  noobj_loss: 0.1227  bbox_loss: 0.0078  cls_loss: 0.0159  \n",
      "<<<iteration:[500/525] - total_loss: 0.2870  obj_loss: 0.1623  noobj_loss: 0.1128  bbox_loss: 0.0090  cls_loss: 0.0233  \n",
      "<<<iteration:[520/525] - total_loss: 0.2803  obj_loss: 0.1692  noobj_loss: 0.1050  bbox_loss: 0.0077  cls_loss: 0.0200  \n",
      "\n",
      "epoch:52/100 - Train Loss: 0.2748, Val Loss: 0.2794\n",
      "\n",
      "<<<iteration:[20/525] - total_loss: 0.2769  obj_loss: 0.1684  noobj_loss: 0.1032  bbox_loss: 0.0082  cls_loss: 0.0158  \n",
      "<<<iteration:[40/525] - total_loss: 0.2795  obj_loss: 0.1783  noobj_loss: 0.1163  bbox_loss: 0.0067  cls_loss: 0.0097  \n",
      "<<<iteration:[60/525] - total_loss: 0.2894  obj_loss: 0.1751  noobj_loss: 0.1088  bbox_loss: 0.0079  cls_loss: 0.0204  \n",
      "<<<iteration:[80/525] - total_loss: 0.2781  obj_loss: 0.1571  noobj_loss: 0.1079  bbox_loss: 0.0092  cls_loss: 0.0209  \n",
      "<<<iteration:[100/525] - total_loss: 0.2696  obj_loss: 0.1582  noobj_loss: 0.1061  bbox_loss: 0.0086  cls_loss: 0.0154  \n",
      "<<<iteration:[120/525] - total_loss: 0.2786  obj_loss: 0.1576  noobj_loss: 0.1073  bbox_loss: 0.0080  cls_loss: 0.0272  \n",
      "<<<iteration:[140/525] - total_loss: 0.2404  obj_loss: 0.1421  noobj_loss: 0.1062  bbox_loss: 0.0069  cls_loss: 0.0105  \n",
      "<<<iteration:[160/525] - total_loss: 0.2882  obj_loss: 0.1840  noobj_loss: 0.1075  bbox_loss: 0.0079  cls_loss: 0.0111  \n",
      "<<<iteration:[180/525] - total_loss: 0.2766  obj_loss: 0.1630  noobj_loss: 0.1034  bbox_loss: 0.0083  cls_loss: 0.0206  \n",
      "<<<iteration:[200/525] - total_loss: 0.2599  obj_loss: 0.1565  noobj_loss: 0.1116  bbox_loss: 0.0064  cls_loss: 0.0153  \n",
      "<<<iteration:[220/525] - total_loss: 0.2931  obj_loss: 0.1752  noobj_loss: 0.1042  bbox_loss: 0.0086  cls_loss: 0.0227  \n",
      "<<<iteration:[240/525] - total_loss: 0.2822  obj_loss: 0.1707  noobj_loss: 0.0959  bbox_loss: 0.0082  cls_loss: 0.0224  \n",
      "<<<iteration:[260/525] - total_loss: 0.2649  obj_loss: 0.1587  noobj_loss: 0.1072  bbox_loss: 0.0076  cls_loss: 0.0146  \n",
      "<<<iteration:[280/525] - total_loss: 0.2805  obj_loss: 0.1764  noobj_loss: 0.1038  bbox_loss: 0.0072  cls_loss: 0.0161  \n",
      "<<<iteration:[300/525] - total_loss: 0.2691  obj_loss: 0.1517  noobj_loss: 0.1174  bbox_loss: 0.0083  cls_loss: 0.0171  \n",
      "<<<iteration:[320/525] - total_loss: 0.2849  obj_loss: 0.1795  noobj_loss: 0.1041  bbox_loss: 0.0080  cls_loss: 0.0132  \n",
      "<<<iteration:[340/525] - total_loss: 0.2586  obj_loss: 0.1560  noobj_loss: 0.0981  bbox_loss: 0.0084  cls_loss: 0.0116  \n",
      "<<<iteration:[360/525] - total_loss: 0.2933  obj_loss: 0.1686  noobj_loss: 0.1072  bbox_loss: 0.0078  cls_loss: 0.0318  \n",
      "<<<iteration:[380/525] - total_loss: 0.2743  obj_loss: 0.1604  noobj_loss: 0.1041  bbox_loss: 0.0080  cls_loss: 0.0218  \n",
      "<<<iteration:[400/525] - total_loss: 0.2753  obj_loss: 0.1751  noobj_loss: 0.1037  bbox_loss: 0.0066  cls_loss: 0.0152  \n",
      "<<<iteration:[420/525] - total_loss: 0.2587  obj_loss: 0.1562  noobj_loss: 0.1037  bbox_loss: 0.0072  cls_loss: 0.0147  \n",
      "<<<iteration:[440/525] - total_loss: 0.2658  obj_loss: 0.1642  noobj_loss: 0.1161  bbox_loss: 0.0059  cls_loss: 0.0140  \n",
      "<<<iteration:[460/525] - total_loss: 0.2811  obj_loss: 0.1558  noobj_loss: 0.1085  bbox_loss: 0.0085  cls_loss: 0.0287  \n",
      "<<<iteration:[480/525] - total_loss: 0.3149  obj_loss: 0.1953  noobj_loss: 0.1095  bbox_loss: 0.0074  cls_loss: 0.0277  \n",
      "<<<iteration:[500/525] - total_loss: 0.2576  obj_loss: 0.1523  noobj_loss: 0.1083  bbox_loss: 0.0068  cls_loss: 0.0172  \n",
      "<<<iteration:[520/525] - total_loss: 0.2816  obj_loss: 0.1714  noobj_loss: 0.1113  bbox_loss: 0.0081  cls_loss: 0.0139  \n",
      "\n",
      "epoch:53/100 - Train Loss: 0.2754, Val Loss: 0.2849\n",
      "\n",
      "<<<iteration:[20/525] - total_loss: 0.2905  obj_loss: 0.1799  noobj_loss: 0.1125  bbox_loss: 0.0071  cls_loss: 0.0188  \n",
      "<<<iteration:[40/525] - total_loss: 0.2898  obj_loss: 0.1678  noobj_loss: 0.1079  bbox_loss: 0.0080  cls_loss: 0.0283  \n",
      "<<<iteration:[60/525] - total_loss: 0.2787  obj_loss: 0.1695  noobj_loss: 0.1120  bbox_loss: 0.0077  cls_loss: 0.0146  \n",
      "<<<iteration:[80/525] - total_loss: 0.2774  obj_loss: 0.1647  noobj_loss: 0.1000  bbox_loss: 0.0083  cls_loss: 0.0211  \n",
      "<<<iteration:[100/525] - total_loss: 0.2648  obj_loss: 0.1548  noobj_loss: 0.1166  bbox_loss: 0.0076  cls_loss: 0.0134  \n",
      "<<<iteration:[120/525] - total_loss: 0.2734  obj_loss: 0.1655  noobj_loss: 0.1032  bbox_loss: 0.0071  cls_loss: 0.0209  \n",
      "<<<iteration:[140/525] - total_loss: 0.2786  obj_loss: 0.1675  noobj_loss: 0.1151  bbox_loss: 0.0086  cls_loss: 0.0107  \n",
      "<<<iteration:[160/525] - total_loss: 0.2790  obj_loss: 0.1715  noobj_loss: 0.1157  bbox_loss: 0.0070  cls_loss: 0.0144  \n",
      "<<<iteration:[180/525] - total_loss: 0.2701  obj_loss: 0.1610  noobj_loss: 0.1129  bbox_loss: 0.0065  cls_loss: 0.0203  \n",
      "<<<iteration:[200/525] - total_loss: 0.2817  obj_loss: 0.1703  noobj_loss: 0.1179  bbox_loss: 0.0077  cls_loss: 0.0139  \n",
      "<<<iteration:[220/525] - total_loss: 0.2742  obj_loss: 0.1650  noobj_loss: 0.1107  bbox_loss: 0.0076  cls_loss: 0.0159  \n",
      "<<<iteration:[240/525] - total_loss: 0.2722  obj_loss: 0.1604  noobj_loss: 0.0975  bbox_loss: 0.0078  cls_loss: 0.0239  \n",
      "<<<iteration:[260/525] - total_loss: 0.2859  obj_loss: 0.1786  noobj_loss: 0.1022  bbox_loss: 0.0081  cls_loss: 0.0159  \n",
      "<<<iteration:[280/525] - total_loss: 0.2875  obj_loss: 0.1623  noobj_loss: 0.1110  bbox_loss: 0.0095  cls_loss: 0.0222  \n",
      "<<<iteration:[300/525] - total_loss: 0.2557  obj_loss: 0.1504  noobj_loss: 0.1018  bbox_loss: 0.0090  cls_loss: 0.0093  \n",
      "<<<iteration:[320/525] - total_loss: 0.2788  obj_loss: 0.1707  noobj_loss: 0.1071  bbox_loss: 0.0071  cls_loss: 0.0192  \n",
      "<<<iteration:[340/525] - total_loss: 0.2629  obj_loss: 0.1607  noobj_loss: 0.1061  bbox_loss: 0.0070  cls_loss: 0.0139  \n",
      "<<<iteration:[360/525] - total_loss: 0.2567  obj_loss: 0.1551  noobj_loss: 0.1023  bbox_loss: 0.0071  cls_loss: 0.0148  \n",
      "<<<iteration:[380/525] - total_loss: 0.2964  obj_loss: 0.1660  noobj_loss: 0.1075  bbox_loss: 0.0090  cls_loss: 0.0316  \n",
      "<<<iteration:[400/525] - total_loss: 0.2700  obj_loss: 0.1678  noobj_loss: 0.1180  bbox_loss: 0.0067  cls_loss: 0.0097  \n",
      "<<<iteration:[420/525] - total_loss: 0.2707  obj_loss: 0.1637  noobj_loss: 0.1066  bbox_loss: 0.0078  cls_loss: 0.0146  \n",
      "<<<iteration:[440/525] - total_loss: 0.2583  obj_loss: 0.1547  noobj_loss: 0.1038  bbox_loss: 0.0073  cls_loss: 0.0152  \n",
      "<<<iteration:[460/525] - total_loss: 0.2920  obj_loss: 0.1634  noobj_loss: 0.1137  bbox_loss: 0.0100  cls_loss: 0.0217  \n",
      "<<<iteration:[480/525] - total_loss: 0.2743  obj_loss: 0.1556  noobj_loss: 0.1021  bbox_loss: 0.0079  cls_loss: 0.0282  \n",
      "<<<iteration:[500/525] - total_loss: 0.2662  obj_loss: 0.1626  noobj_loss: 0.1071  bbox_loss: 0.0076  cls_loss: 0.0121  \n",
      "<<<iteration:[520/525] - total_loss: 0.2568  obj_loss: 0.1537  noobj_loss: 0.0995  bbox_loss: 0.0075  cls_loss: 0.0158  \n",
      "\n",
      "epoch:54/100 - Train Loss: 0.2743, Val Loss: 0.2811\n",
      "\n",
      "<<<iteration:[20/525] - total_loss: 0.2940  obj_loss: 0.1820  noobj_loss: 0.1130  bbox_loss: 0.0077  cls_loss: 0.0169  \n",
      "<<<iteration:[40/525] - total_loss: 0.2783  obj_loss: 0.1635  noobj_loss: 0.1151  bbox_loss: 0.0085  cls_loss: 0.0150  \n",
      "<<<iteration:[60/525] - total_loss: 0.3001  obj_loss: 0.1910  noobj_loss: 0.1059  bbox_loss: 0.0077  cls_loss: 0.0179  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<<<iteration:[80/525] - total_loss: 0.2793  obj_loss: 0.1812  noobj_loss: 0.1086  bbox_loss: 0.0066  cls_loss: 0.0110  \n",
      "<<<iteration:[100/525] - total_loss: 0.2716  obj_loss: 0.1611  noobj_loss: 0.1060  bbox_loss: 0.0083  cls_loss: 0.0158  \n",
      "<<<iteration:[120/525] - total_loss: 0.2682  obj_loss: 0.1607  noobj_loss: 0.1046  bbox_loss: 0.0084  cls_loss: 0.0134  \n",
      "<<<iteration:[140/525] - total_loss: 0.2563  obj_loss: 0.1492  noobj_loss: 0.1030  bbox_loss: 0.0069  cls_loss: 0.0209  \n",
      "<<<iteration:[160/525] - total_loss: 0.2816  obj_loss: 0.1727  noobj_loss: 0.1052  bbox_loss: 0.0076  cls_loss: 0.0182  \n",
      "<<<iteration:[180/525] - total_loss: 0.2719  obj_loss: 0.1717  noobj_loss: 0.1138  bbox_loss: 0.0060  cls_loss: 0.0131  \n",
      "<<<iteration:[200/525] - total_loss: 0.2870  obj_loss: 0.1818  noobj_loss: 0.1091  bbox_loss: 0.0066  cls_loss: 0.0174  \n",
      "<<<iteration:[220/525] - total_loss: 0.2872  obj_loss: 0.1675  noobj_loss: 0.1157  bbox_loss: 0.0089  cls_loss: 0.0175  \n",
      "<<<iteration:[240/525] - total_loss: 0.2704  obj_loss: 0.1694  noobj_loss: 0.1015  bbox_loss: 0.0066  cls_loss: 0.0171  \n",
      "<<<iteration:[260/525] - total_loss: 0.2711  obj_loss: 0.1585  noobj_loss: 0.1066  bbox_loss: 0.0083  cls_loss: 0.0178  \n",
      "<<<iteration:[280/525] - total_loss: 0.2726  obj_loss: 0.1647  noobj_loss: 0.1145  bbox_loss: 0.0086  cls_loss: 0.0077  \n",
      "<<<iteration:[300/525] - total_loss: 0.2785  obj_loss: 0.1683  noobj_loss: 0.1027  bbox_loss: 0.0067  cls_loss: 0.0254  \n",
      "<<<iteration:[320/525] - total_loss: 0.2743  obj_loss: 0.1563  noobj_loss: 0.1229  bbox_loss: 0.0079  cls_loss: 0.0170  \n",
      "<<<iteration:[340/525] - total_loss: 0.2883  obj_loss: 0.1510  noobj_loss: 0.1143  bbox_loss: 0.0095  cls_loss: 0.0327  \n",
      "<<<iteration:[360/525] - total_loss: 0.2598  obj_loss: 0.1512  noobj_loss: 0.1123  bbox_loss: 0.0070  cls_loss: 0.0176  \n",
      "<<<iteration:[380/525] - total_loss: 0.2736  obj_loss: 0.1586  noobj_loss: 0.1100  bbox_loss: 0.0079  cls_loss: 0.0206  \n",
      "<<<iteration:[400/525] - total_loss: 0.2855  obj_loss: 0.1525  noobj_loss: 0.1224  bbox_loss: 0.0093  cls_loss: 0.0253  \n",
      "<<<iteration:[420/525] - total_loss: 0.2912  obj_loss: 0.1812  noobj_loss: 0.1129  bbox_loss: 0.0074  cls_loss: 0.0164  \n",
      "<<<iteration:[440/525] - total_loss: 0.2837  obj_loss: 0.1624  noobj_loss: 0.1107  bbox_loss: 0.0081  cls_loss: 0.0254  \n",
      "<<<iteration:[460/525] - total_loss: 0.2435  obj_loss: 0.1382  noobj_loss: 0.1080  bbox_loss: 0.0076  cls_loss: 0.0135  \n",
      "<<<iteration:[480/525] - total_loss: 0.2752  obj_loss: 0.1629  noobj_loss: 0.1046  bbox_loss: 0.0080  cls_loss: 0.0202  \n",
      "<<<iteration:[500/525] - total_loss: 0.2844  obj_loss: 0.1775  noobj_loss: 0.1093  bbox_loss: 0.0079  cls_loss: 0.0126  \n",
      "<<<iteration:[520/525] - total_loss: 0.2902  obj_loss: 0.1754  noobj_loss: 0.1121  bbox_loss: 0.0077  cls_loss: 0.0202  \n",
      "\n",
      "epoch:55/100 - Train Loss: 0.2771, Val Loss: 0.2781\n",
      "\n",
      "<<<iteration:[20/525] - total_loss: 0.3058  obj_loss: 0.1880  noobj_loss: 0.1200  bbox_loss: 0.0089  cls_loss: 0.0135  \n",
      "<<<iteration:[40/525] - total_loss: 0.2854  obj_loss: 0.1596  noobj_loss: 0.1055  bbox_loss: 0.0094  cls_loss: 0.0263  \n",
      "<<<iteration:[60/525] - total_loss: 0.2579  obj_loss: 0.1532  noobj_loss: 0.1113  bbox_loss: 0.0072  cls_loss: 0.0131  \n",
      "<<<iteration:[80/525] - total_loss: 0.2801  obj_loss: 0.1623  noobj_loss: 0.1081  bbox_loss: 0.0082  cls_loss: 0.0227  \n",
      "<<<iteration:[100/525] - total_loss: 0.2738  obj_loss: 0.1771  noobj_loss: 0.1021  bbox_loss: 0.0064  cls_loss: 0.0138  \n",
      "<<<iteration:[120/525] - total_loss: 0.2722  obj_loss: 0.1560  noobj_loss: 0.1147  bbox_loss: 0.0090  cls_loss: 0.0138  \n",
      "<<<iteration:[140/525] - total_loss: 0.2926  obj_loss: 0.1846  noobj_loss: 0.1055  bbox_loss: 0.0080  cls_loss: 0.0151  \n",
      "<<<iteration:[160/525] - total_loss: 0.2753  obj_loss: 0.1512  noobj_loss: 0.1094  bbox_loss: 0.0098  cls_loss: 0.0203  \n",
      "<<<iteration:[180/525] - total_loss: 0.2868  obj_loss: 0.1709  noobj_loss: 0.1061  bbox_loss: 0.0080  cls_loss: 0.0228  \n",
      "<<<iteration:[200/525] - total_loss: 0.2752  obj_loss: 0.1659  noobj_loss: 0.1137  bbox_loss: 0.0082  cls_loss: 0.0117  \n",
      "<<<iteration:[220/525] - total_loss: 0.2786  obj_loss: 0.1643  noobj_loss: 0.1098  bbox_loss: 0.0078  cls_loss: 0.0206  \n",
      "<<<iteration:[240/525] - total_loss: 0.2781  obj_loss: 0.1702  noobj_loss: 0.1116  bbox_loss: 0.0078  cls_loss: 0.0133  \n",
      "<<<iteration:[260/525] - total_loss: 0.2496  obj_loss: 0.1526  noobj_loss: 0.1011  bbox_loss: 0.0070  cls_loss: 0.0113  \n",
      "<<<iteration:[280/525] - total_loss: 0.2835  obj_loss: 0.1793  noobj_loss: 0.1079  bbox_loss: 0.0074  cls_loss: 0.0134  \n",
      "<<<iteration:[300/525] - total_loss: 0.2732  obj_loss: 0.1608  noobj_loss: 0.1090  bbox_loss: 0.0075  cls_loss: 0.0206  \n",
      "<<<iteration:[320/525] - total_loss: 0.2737  obj_loss: 0.1536  noobj_loss: 0.1128  bbox_loss: 0.0080  cls_loss: 0.0237  \n",
      "<<<iteration:[340/525] - total_loss: 0.3238  obj_loss: 0.1560  noobj_loss: 0.1224  bbox_loss: 0.0124  cls_loss: 0.0445  \n",
      "<<<iteration:[360/525] - total_loss: 0.2700  obj_loss: 0.1584  noobj_loss: 0.1055  bbox_loss: 0.0082  cls_loss: 0.0180  \n",
      "<<<iteration:[380/525] - total_loss: 0.2711  obj_loss: 0.1744  noobj_loss: 0.1122  bbox_loss: 0.0060  cls_loss: 0.0109  \n",
      "<<<iteration:[400/525] - total_loss: 0.2851  obj_loss: 0.1774  noobj_loss: 0.1066  bbox_loss: 0.0074  cls_loss: 0.0176  \n",
      "<<<iteration:[420/525] - total_loss: 0.2726  obj_loss: 0.1668  noobj_loss: 0.1097  bbox_loss: 0.0078  cls_loss: 0.0121  \n",
      "<<<iteration:[440/525] - total_loss: 0.2922  obj_loss: 0.1705  noobj_loss: 0.1141  bbox_loss: 0.0082  cls_loss: 0.0239  \n",
      "<<<iteration:[460/525] - total_loss: 0.2631  obj_loss: 0.1560  noobj_loss: 0.1015  bbox_loss: 0.0073  cls_loss: 0.0198  \n",
      "<<<iteration:[480/525] - total_loss: 0.2842  obj_loss: 0.1694  noobj_loss: 0.1207  bbox_loss: 0.0065  cls_loss: 0.0221  \n",
      "<<<iteration:[500/525] - total_loss: 0.2641  obj_loss: 0.1587  noobj_loss: 0.1180  bbox_loss: 0.0067  cls_loss: 0.0129  \n",
      "<<<iteration:[520/525] - total_loss: 0.2780  obj_loss: 0.1639  noobj_loss: 0.1068  bbox_loss: 0.0070  cls_loss: 0.0258  \n",
      "\n",
      "epoch:56/100 - Train Loss: 0.2782, Val Loss: 0.2747\n",
      "\n",
      "<<<iteration:[20/525] - total_loss: 0.2945  obj_loss: 0.1747  noobj_loss: 0.1181  bbox_loss: 0.0077  cls_loss: 0.0225  \n",
      "<<<iteration:[40/525] - total_loss: 0.2828  obj_loss: 0.1656  noobj_loss: 0.1116  bbox_loss: 0.0079  cls_loss: 0.0216  \n",
      "<<<iteration:[60/525] - total_loss: 0.2737  obj_loss: 0.1569  noobj_loss: 0.1194  bbox_loss: 0.0075  cls_loss: 0.0195  \n",
      "<<<iteration:[80/525] - total_loss: 0.2811  obj_loss: 0.1572  noobj_loss: 0.1095  bbox_loss: 0.0084  cls_loss: 0.0270  \n",
      "<<<iteration:[100/525] - total_loss: 0.2623  obj_loss: 0.1620  noobj_loss: 0.0989  bbox_loss: 0.0072  cls_loss: 0.0147  \n",
      "<<<iteration:[120/525] - total_loss: 0.2848  obj_loss: 0.1759  noobj_loss: 0.1117  bbox_loss: 0.0073  cls_loss: 0.0167  \n",
      "<<<iteration:[140/525] - total_loss: 0.2739  obj_loss: 0.1702  noobj_loss: 0.1163  bbox_loss: 0.0070  cls_loss: 0.0108  \n",
      "<<<iteration:[160/525] - total_loss: 0.2627  obj_loss: 0.1473  noobj_loss: 0.1039  bbox_loss: 0.0087  cls_loss: 0.0198  \n",
      "<<<iteration:[180/525] - total_loss: 0.2692  obj_loss: 0.1604  noobj_loss: 0.1160  bbox_loss: 0.0080  cls_loss: 0.0109  \n",
      "<<<iteration:[200/525] - total_loss: 0.2767  obj_loss: 0.1774  noobj_loss: 0.1059  bbox_loss: 0.0071  cls_loss: 0.0109  \n",
      "<<<iteration:[220/525] - total_loss: 0.2628  obj_loss: 0.1477  noobj_loss: 0.1088  bbox_loss: 0.0083  cls_loss: 0.0192  \n",
      "<<<iteration:[240/525] - total_loss: 0.2841  obj_loss: 0.1779  noobj_loss: 0.1090  bbox_loss: 0.0073  cls_loss: 0.0151  \n",
      "<<<iteration:[260/525] - total_loss: 0.2744  obj_loss: 0.1616  noobj_loss: 0.1062  bbox_loss: 0.0073  cls_loss: 0.0232  \n",
      "<<<iteration:[280/525] - total_loss: 0.2786  obj_loss: 0.1734  noobj_loss: 0.1058  bbox_loss: 0.0076  cls_loss: 0.0141  \n",
      "<<<iteration:[300/525] - total_loss: 0.2800  obj_loss: 0.1709  noobj_loss: 0.1215  bbox_loss: 0.0063  cls_loss: 0.0168  \n",
      "<<<iteration:[320/525] - total_loss: 0.2616  obj_loss: 0.1539  noobj_loss: 0.1105  bbox_loss: 0.0077  cls_loss: 0.0138  \n",
      "<<<iteration:[340/525] - total_loss: 0.2691  obj_loss: 0.1572  noobj_loss: 0.1131  bbox_loss: 0.0079  cls_loss: 0.0157  \n",
      "<<<iteration:[360/525] - total_loss: 0.2952  obj_loss: 0.1612  noobj_loss: 0.1069  bbox_loss: 0.0085  cls_loss: 0.0378  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<<<iteration:[380/525] - total_loss: 0.2746  obj_loss: 0.1684  noobj_loss: 0.1029  bbox_loss: 0.0075  cls_loss: 0.0171  \n",
      "<<<iteration:[400/525] - total_loss: 0.2742  obj_loss: 0.1645  noobj_loss: 0.1169  bbox_loss: 0.0067  cls_loss: 0.0179  \n",
      "<<<iteration:[420/525] - total_loss: 0.2701  obj_loss: 0.1558  noobj_loss: 0.1143  bbox_loss: 0.0073  cls_loss: 0.0206  \n",
      "<<<iteration:[440/525] - total_loss: 0.2924  obj_loss: 0.1627  noobj_loss: 0.1132  bbox_loss: 0.0087  cls_loss: 0.0297  \n",
      "<<<iteration:[460/525] - total_loss: 0.2750  obj_loss: 0.1672  noobj_loss: 0.1168  bbox_loss: 0.0074  cls_loss: 0.0124  \n",
      "<<<iteration:[480/525] - total_loss: 0.2747  obj_loss: 0.1682  noobj_loss: 0.1104  bbox_loss: 0.0080  cls_loss: 0.0113  \n",
      "<<<iteration:[500/525] - total_loss: 0.2685  obj_loss: 0.1627  noobj_loss: 0.1162  bbox_loss: 0.0065  cls_loss: 0.0154  \n",
      "<<<iteration:[520/525] - total_loss: 0.2498  obj_loss: 0.1430  noobj_loss: 0.1043  bbox_loss: 0.0072  cls_loss: 0.0186  \n",
      "\n",
      "epoch:57/100 - Train Loss: 0.2743, Val Loss: 0.2831\n",
      "\n",
      "<<<iteration:[20/525] - total_loss: 0.3102  obj_loss: 0.1887  noobj_loss: 0.1159  bbox_loss: 0.0071  cls_loss: 0.0282  \n",
      "<<<iteration:[40/525] - total_loss: 0.2665  obj_loss: 0.1526  noobj_loss: 0.1144  bbox_loss: 0.0073  cls_loss: 0.0202  \n",
      "<<<iteration:[60/525] - total_loss: 0.2738  obj_loss: 0.1541  noobj_loss: 0.1169  bbox_loss: 0.0079  cls_loss: 0.0215  \n",
      "<<<iteration:[80/525] - total_loss: 0.2666  obj_loss: 0.1585  noobj_loss: 0.1099  bbox_loss: 0.0076  cls_loss: 0.0149  \n",
      "<<<iteration:[100/525] - total_loss: 0.2619  obj_loss: 0.1438  noobj_loss: 0.1123  bbox_loss: 0.0077  cls_loss: 0.0233  \n",
      "<<<iteration:[120/525] - total_loss: 0.2843  obj_loss: 0.1298  noobj_loss: 0.0902  bbox_loss: 0.0192  cls_loss: 0.0136  \n",
      "<<<iteration:[140/525] - total_loss: 0.2738  obj_loss: 0.1429  noobj_loss: 0.0902  bbox_loss: 0.0138  cls_loss: 0.0170  \n",
      "<<<iteration:[160/525] - total_loss: 0.3082  obj_loss: 0.1384  noobj_loss: 0.0998  bbox_loss: 0.0205  cls_loss: 0.0175  \n",
      "<<<iteration:[180/525] - total_loss: 0.2614  obj_loss: 0.1441  noobj_loss: 0.0992  bbox_loss: 0.0102  cls_loss: 0.0165  \n",
      "<<<iteration:[200/525] - total_loss: 0.2713  obj_loss: 0.1501  noobj_loss: 0.0947  bbox_loss: 0.0123  cls_loss: 0.0121  \n",
      "<<<iteration:[220/525] - total_loss: 0.2714  obj_loss: 0.1539  noobj_loss: 0.1060  bbox_loss: 0.0096  cls_loss: 0.0165  \n",
      "<<<iteration:[240/525] - total_loss: 0.3225  obj_loss: 0.1395  noobj_loss: 0.1019  bbox_loss: 0.0220  cls_loss: 0.0221  \n",
      "<<<iteration:[260/525] - total_loss: 0.2636  obj_loss: 0.1560  noobj_loss: 0.0968  bbox_loss: 0.0096  cls_loss: 0.0112  \n",
      "<<<iteration:[280/525] - total_loss: 0.2914  obj_loss: 0.1625  noobj_loss: 0.1017  bbox_loss: 0.0121  cls_loss: 0.0174  \n",
      "<<<iteration:[300/525] - total_loss: 0.2903  obj_loss: 0.1632  noobj_loss: 0.1118  bbox_loss: 0.0100  cls_loss: 0.0212  \n",
      "<<<iteration:[320/525] - total_loss: 0.2717  obj_loss: 0.1663  noobj_loss: 0.1039  bbox_loss: 0.0093  cls_loss: 0.0072  \n",
      "<<<iteration:[340/525] - total_loss: 0.2870  obj_loss: 0.1623  noobj_loss: 0.1041  bbox_loss: 0.0108  cls_loss: 0.0186  \n",
      "<<<iteration:[360/525] - total_loss: 0.2491  obj_loss: 0.1428  noobj_loss: 0.1106  bbox_loss: 0.0074  cls_loss: 0.0141  \n",
      "<<<iteration:[380/525] - total_loss: 0.2926  obj_loss: 0.1556  noobj_loss: 0.1021  bbox_loss: 0.0112  cls_loss: 0.0298  \n",
      "<<<iteration:[400/525] - total_loss: 0.2776  obj_loss: 0.1663  noobj_loss: 0.1109  bbox_loss: 0.0078  cls_loss: 0.0170  \n",
      "<<<iteration:[420/525] - total_loss: 0.2767  obj_loss: 0.1598  noobj_loss: 0.1076  bbox_loss: 0.0088  cls_loss: 0.0190  \n",
      "<<<iteration:[440/525] - total_loss: 0.2601  obj_loss: 0.1556  noobj_loss: 0.1028  bbox_loss: 0.0083  cls_loss: 0.0118  \n",
      "<<<iteration:[460/525] - total_loss: 0.2405  obj_loss: 0.1360  noobj_loss: 0.0993  bbox_loss: 0.0083  cls_loss: 0.0132  \n",
      "<<<iteration:[480/525] - total_loss: 0.2805  obj_loss: 0.1557  noobj_loss: 0.1087  bbox_loss: 0.0104  cls_loss: 0.0185  \n",
      "<<<iteration:[500/525] - total_loss: 0.2415  obj_loss: 0.1377  noobj_loss: 0.1056  bbox_loss: 0.0077  cls_loss: 0.0125  \n",
      "<<<iteration:[520/525] - total_loss: 0.2757  obj_loss: 0.1580  noobj_loss: 0.1019  bbox_loss: 0.0099  cls_loss: 0.0174  \n",
      "\n",
      "epoch:58/100 - Train Loss: 0.2750, Val Loss: 0.2781\n",
      "\n",
      "<<<iteration:[20/525] - total_loss: 0.2920  obj_loss: 0.1749  noobj_loss: 0.1104  bbox_loss: 0.0090  cls_loss: 0.0167  \n",
      "<<<iteration:[40/525] - total_loss: 0.2811  obj_loss: 0.1672  noobj_loss: 0.1077  bbox_loss: 0.0094  cls_loss: 0.0132  \n",
      "<<<iteration:[60/525] - total_loss: 0.2706  obj_loss: 0.1574  noobj_loss: 0.1134  bbox_loss: 0.0081  cls_loss: 0.0162  \n",
      "<<<iteration:[80/525] - total_loss: 0.2756  obj_loss: 0.1579  noobj_loss: 0.1106  bbox_loss: 0.0092  cls_loss: 0.0162  \n",
      "<<<iteration:[100/525] - total_loss: 0.2493  obj_loss: 0.1471  noobj_loss: 0.0968  bbox_loss: 0.0080  cls_loss: 0.0138  \n",
      "<<<iteration:[120/525] - total_loss: 0.2659  obj_loss: 0.1595  noobj_loss: 0.1048  bbox_loss: 0.0079  cls_loss: 0.0147  \n",
      "<<<iteration:[140/525] - total_loss: 0.2544  obj_loss: 0.1607  noobj_loss: 0.0983  bbox_loss: 0.0065  cls_loss: 0.0118  \n",
      "<<<iteration:[160/525] - total_loss: 0.2721  obj_loss: 0.1517  noobj_loss: 0.1043  bbox_loss: 0.0085  cls_loss: 0.0257  \n",
      "<<<iteration:[180/525] - total_loss: 0.2824  obj_loss: 0.1752  noobj_loss: 0.1106  bbox_loss: 0.0080  cls_loss: 0.0120  \n",
      "<<<iteration:[200/525] - total_loss: 0.2531  obj_loss: 0.1451  noobj_loss: 0.1069  bbox_loss: 0.0074  cls_loss: 0.0177  \n",
      "<<<iteration:[220/525] - total_loss: 0.2912  obj_loss: 0.1648  noobj_loss: 0.1092  bbox_loss: 0.0093  cls_loss: 0.0251  \n",
      "<<<iteration:[240/525] - total_loss: 0.2616  obj_loss: 0.1495  noobj_loss: 0.1059  bbox_loss: 0.0088  cls_loss: 0.0148  \n",
      "<<<iteration:[260/525] - total_loss: 0.2694  obj_loss: 0.1553  noobj_loss: 0.1045  bbox_loss: 0.0074  cls_loss: 0.0249  \n",
      "<<<iteration:[280/525] - total_loss: 0.2691  obj_loss: 0.1533  noobj_loss: 0.1063  bbox_loss: 0.0085  cls_loss: 0.0203  \n",
      "<<<iteration:[300/525] - total_loss: 0.2584  obj_loss: 0.1507  noobj_loss: 0.0928  bbox_loss: 0.0085  cls_loss: 0.0191  \n",
      "<<<iteration:[320/525] - total_loss: 0.2713  obj_loss: 0.1613  noobj_loss: 0.1144  bbox_loss: 0.0072  cls_loss: 0.0166  \n",
      "<<<iteration:[340/525] - total_loss: 0.2521  obj_loss: 0.1535  noobj_loss: 0.1100  bbox_loss: 0.0062  cls_loss: 0.0124  \n",
      "<<<iteration:[360/525] - total_loss: 0.2540  obj_loss: 0.1520  noobj_loss: 0.1139  bbox_loss: 0.0062  cls_loss: 0.0143  \n",
      "<<<iteration:[380/525] - total_loss: 0.2697  obj_loss: 0.1478  noobj_loss: 0.1105  bbox_loss: 0.0094  cls_loss: 0.0198  \n",
      "<<<iteration:[400/525] - total_loss: 0.2623  obj_loss: 0.1580  noobj_loss: 0.1077  bbox_loss: 0.0081  cls_loss: 0.0099  \n",
      "<<<iteration:[420/525] - total_loss: 0.2493  obj_loss: 0.1437  noobj_loss: 0.1094  bbox_loss: 0.0069  cls_loss: 0.0166  \n",
      "<<<iteration:[440/525] - total_loss: 0.2693  obj_loss: 0.1581  noobj_loss: 0.1113  bbox_loss: 0.0073  cls_loss: 0.0192  \n",
      "<<<iteration:[460/525] - total_loss: 0.2558  obj_loss: 0.1515  noobj_loss: 0.1106  bbox_loss: 0.0073  cls_loss: 0.0127  \n",
      "<<<iteration:[480/525] - total_loss: 0.2631  obj_loss: 0.1514  noobj_loss: 0.1108  bbox_loss: 0.0075  cls_loss: 0.0187  \n",
      "<<<iteration:[500/525] - total_loss: 0.2509  obj_loss: 0.1514  noobj_loss: 0.1129  bbox_loss: 0.0065  cls_loss: 0.0104  \n",
      "<<<iteration:[520/525] - total_loss: 0.2425  obj_loss: 0.1340  noobj_loss: 0.1026  bbox_loss: 0.0082  cls_loss: 0.0161  \n",
      "\n",
      "epoch:59/100 - Train Loss: 0.2643, Val Loss: 0.2716\n",
      "\n",
      "<<<iteration:[20/525] - total_loss: 0.2847  obj_loss: 0.1642  noobj_loss: 0.1209  bbox_loss: 0.0079  cls_loss: 0.0205  \n",
      "<<<iteration:[40/525] - total_loss: 0.2627  obj_loss: 0.1575  noobj_loss: 0.1136  bbox_loss: 0.0074  cls_loss: 0.0115  \n",
      "<<<iteration:[60/525] - total_loss: 0.2413  obj_loss: 0.1383  noobj_loss: 0.1010  bbox_loss: 0.0083  cls_loss: 0.0112  \n",
      "<<<iteration:[80/525] - total_loss: 0.2701  obj_loss: 0.1608  noobj_loss: 0.1084  bbox_loss: 0.0089  cls_loss: 0.0106  \n",
      "<<<iteration:[100/525] - total_loss: 0.2703  obj_loss: 0.1698  noobj_loss: 0.1057  bbox_loss: 0.0072  cls_loss: 0.0118  \n",
      "<<<iteration:[120/525] - total_loss: 0.2684  obj_loss: 0.1693  noobj_loss: 0.1075  bbox_loss: 0.0060  cls_loss: 0.0154  \n",
      "<<<iteration:[140/525] - total_loss: 0.2608  obj_loss: 0.1500  noobj_loss: 0.1125  bbox_loss: 0.0072  cls_loss: 0.0186  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<<<iteration:[160/525] - total_loss: 0.2464  obj_loss: 0.1443  noobj_loss: 0.0998  bbox_loss: 0.0076  cls_loss: 0.0144  \n",
      "<<<iteration:[180/525] - total_loss: 0.2586  obj_loss: 0.1510  noobj_loss: 0.1072  bbox_loss: 0.0073  cls_loss: 0.0175  \n",
      "<<<iteration:[200/525] - total_loss: 0.2485  obj_loss: 0.1498  noobj_loss: 0.1098  bbox_loss: 0.0058  cls_loss: 0.0146  \n",
      "<<<iteration:[220/525] - total_loss: 0.2641  obj_loss: 0.1373  noobj_loss: 0.1067  bbox_loss: 0.0096  cls_loss: 0.0257  \n",
      "<<<iteration:[240/525] - total_loss: 0.2696  obj_loss: 0.1608  noobj_loss: 0.1113  bbox_loss: 0.0080  cls_loss: 0.0133  \n",
      "<<<iteration:[260/525] - total_loss: 0.2461  obj_loss: 0.1429  noobj_loss: 0.1048  bbox_loss: 0.0076  cls_loss: 0.0130  \n",
      "<<<iteration:[280/525] - total_loss: 0.2599  obj_loss: 0.1407  noobj_loss: 0.1114  bbox_loss: 0.0094  cls_loss: 0.0163  \n",
      "<<<iteration:[300/525] - total_loss: 0.2710  obj_loss: 0.1635  noobj_loss: 0.1030  bbox_loss: 0.0074  cls_loss: 0.0192  \n",
      "<<<iteration:[320/525] - total_loss: 0.2741  obj_loss: 0.1564  noobj_loss: 0.1107  bbox_loss: 0.0085  cls_loss: 0.0201  \n",
      "<<<iteration:[340/525] - total_loss: 0.2652  obj_loss: 0.1555  noobj_loss: 0.1061  bbox_loss: 0.0076  cls_loss: 0.0186  \n",
      "<<<iteration:[360/525] - total_loss: 0.2718  obj_loss: 0.1482  noobj_loss: 0.1063  bbox_loss: 0.0088  cls_loss: 0.0263  \n",
      "<<<iteration:[380/525] - total_loss: 0.2893  obj_loss: 0.1641  noobj_loss: 0.1146  bbox_loss: 0.0087  cls_loss: 0.0242  \n",
      "<<<iteration:[400/525] - total_loss: 0.3033  obj_loss: 0.1712  noobj_loss: 0.1033  bbox_loss: 0.0086  cls_loss: 0.0376  \n",
      "<<<iteration:[420/525] - total_loss: 0.2668  obj_loss: 0.1578  noobj_loss: 0.1211  bbox_loss: 0.0074  cls_loss: 0.0115  \n",
      "<<<iteration:[440/525] - total_loss: 0.2720  obj_loss: 0.1697  noobj_loss: 0.1166  bbox_loss: 0.0066  cls_loss: 0.0111  \n",
      "<<<iteration:[460/525] - total_loss: 0.2651  obj_loss: 0.1533  noobj_loss: 0.1142  bbox_loss: 0.0074  cls_loss: 0.0179  \n",
      "<<<iteration:[480/525] - total_loss: 0.2309  obj_loss: 0.1281  noobj_loss: 0.0998  bbox_loss: 0.0081  cls_loss: 0.0124  \n",
      "<<<iteration:[500/525] - total_loss: 0.2411  obj_loss: 0.1361  noobj_loss: 0.1087  bbox_loss: 0.0076  cls_loss: 0.0129  \n",
      "<<<iteration:[520/525] - total_loss: 0.2701  obj_loss: 0.1683  noobj_loss: 0.1063  bbox_loss: 0.0071  cls_loss: 0.0133  \n",
      "\n",
      "epoch:60/100 - Train Loss: 0.2636, Val Loss: 0.2653\n",
      "\n",
      "<<<iteration:[20/525] - total_loss: 0.2933  obj_loss: 0.1717  noobj_loss: 0.1210  bbox_loss: 0.0087  cls_loss: 0.0174  \n",
      "<<<iteration:[40/525] - total_loss: 0.2655  obj_loss: 0.1454  noobj_loss: 0.1062  bbox_loss: 0.0104  cls_loss: 0.0149  \n",
      "<<<iteration:[60/525] - total_loss: 0.2803  obj_loss: 0.1645  noobj_loss: 0.1136  bbox_loss: 0.0086  cls_loss: 0.0161  \n",
      "<<<iteration:[80/525] - total_loss: 0.2773  obj_loss: 0.1593  noobj_loss: 0.1137  bbox_loss: 0.0088  cls_loss: 0.0169  \n",
      "<<<iteration:[100/525] - total_loss: 0.2680  obj_loss: 0.1507  noobj_loss: 0.1096  bbox_loss: 0.0090  cls_loss: 0.0176  \n",
      "<<<iteration:[120/525] - total_loss: 0.2505  obj_loss: 0.1396  noobj_loss: 0.0983  bbox_loss: 0.0084  cls_loss: 0.0195  \n",
      "<<<iteration:[140/525] - total_loss: 0.2542  obj_loss: 0.1626  noobj_loss: 0.1053  bbox_loss: 0.0058  cls_loss: 0.0101  \n",
      "<<<iteration:[160/525] - total_loss: 0.2536  obj_loss: 0.1488  noobj_loss: 0.1153  bbox_loss: 0.0076  cls_loss: 0.0094  \n",
      "<<<iteration:[180/525] - total_loss: 0.2696  obj_loss: 0.1589  noobj_loss: 0.1100  bbox_loss: 0.0083  cls_loss: 0.0144  \n",
      "<<<iteration:[200/525] - total_loss: 0.2596  obj_loss: 0.1545  noobj_loss: 0.1127  bbox_loss: 0.0070  cls_loss: 0.0136  \n",
      "<<<iteration:[220/525] - total_loss: 0.2522  obj_loss: 0.1434  noobj_loss: 0.1083  bbox_loss: 0.0074  cls_loss: 0.0178  \n",
      "<<<iteration:[240/525] - total_loss: 0.2578  obj_loss: 0.1542  noobj_loss: 0.1050  bbox_loss: 0.0073  cls_loss: 0.0145  \n",
      "<<<iteration:[260/525] - total_loss: 0.2579  obj_loss: 0.1518  noobj_loss: 0.1059  bbox_loss: 0.0073  cls_loss: 0.0169  \n",
      "<<<iteration:[280/525] - total_loss: 0.2676  obj_loss: 0.1532  noobj_loss: 0.1048  bbox_loss: 0.0085  cls_loss: 0.0194  \n",
      "<<<iteration:[300/525] - total_loss: 0.2557  obj_loss: 0.1519  noobj_loss: 0.1070  bbox_loss: 0.0074  cls_loss: 0.0133  \n",
      "<<<iteration:[320/525] - total_loss: 0.2647  obj_loss: 0.1475  noobj_loss: 0.1079  bbox_loss: 0.0087  cls_loss: 0.0197  \n",
      "<<<iteration:[340/525] - total_loss: 0.2556  obj_loss: 0.1428  noobj_loss: 0.0992  bbox_loss: 0.0089  cls_loss: 0.0186  \n",
      "<<<iteration:[360/525] - total_loss: 0.2463  obj_loss: 0.1529  noobj_loss: 0.1052  bbox_loss: 0.0064  cls_loss: 0.0090  \n",
      "<<<iteration:[380/525] - total_loss: 0.2618  obj_loss: 0.1609  noobj_loss: 0.1007  bbox_loss: 0.0077  cls_loss: 0.0120  \n",
      "<<<iteration:[400/525] - total_loss: 0.2603  obj_loss: 0.1622  noobj_loss: 0.1050  bbox_loss: 0.0069  cls_loss: 0.0111  \n",
      "<<<iteration:[420/525] - total_loss: 0.2661  obj_loss: 0.1714  noobj_loss: 0.1040  bbox_loss: 0.0056  cls_loss: 0.0147  \n",
      "<<<iteration:[440/525] - total_loss: 0.2454  obj_loss: 0.1474  noobj_loss: 0.0969  bbox_loss: 0.0066  cls_loss: 0.0164  \n",
      "<<<iteration:[460/525] - total_loss: 0.2527  obj_loss: 0.1448  noobj_loss: 0.1075  bbox_loss: 0.0084  cls_loss: 0.0121  \n",
      "<<<iteration:[480/525] - total_loss: 0.2650  obj_loss: 0.1563  noobj_loss: 0.1071  bbox_loss: 0.0076  cls_loss: 0.0171  \n",
      "<<<iteration:[500/525] - total_loss: 0.2672  obj_loss: 0.1661  noobj_loss: 0.1101  bbox_loss: 0.0071  cls_loss: 0.0103  \n",
      "<<<iteration:[520/525] - total_loss: 0.2863  obj_loss: 0.1628  noobj_loss: 0.1089  bbox_loss: 0.0098  cls_loss: 0.0203  \n",
      "\n",
      "epoch:61/100 - Train Loss: 0.2623, Val Loss: 0.2772\n",
      "\n",
      "<<<iteration:[20/525] - total_loss: 0.2765  obj_loss: 0.1668  noobj_loss: 0.1159  bbox_loss: 0.0078  cls_loss: 0.0130  \n",
      "<<<iteration:[40/525] - total_loss: 0.2566  obj_loss: 0.1517  noobj_loss: 0.0980  bbox_loss: 0.0079  cls_loss: 0.0165  \n",
      "<<<iteration:[60/525] - total_loss: 0.2665  obj_loss: 0.1643  noobj_loss: 0.1090  bbox_loss: 0.0074  cls_loss: 0.0105  \n",
      "<<<iteration:[80/525] - total_loss: 0.2463  obj_loss: 0.1459  noobj_loss: 0.1086  bbox_loss: 0.0064  cls_loss: 0.0143  \n",
      "<<<iteration:[100/525] - total_loss: 0.2779  obj_loss: 0.1712  noobj_loss: 0.1108  bbox_loss: 0.0076  cls_loss: 0.0133  \n",
      "<<<iteration:[120/525] - total_loss: 0.2583  obj_loss: 0.1504  noobj_loss: 0.1119  bbox_loss: 0.0073  cls_loss: 0.0153  \n",
      "<<<iteration:[140/525] - total_loss: 0.2461  obj_loss: 0.1466  noobj_loss: 0.1159  bbox_loss: 0.0064  cls_loss: 0.0096  \n",
      "<<<iteration:[160/525] - total_loss: 0.2791  obj_loss: 0.1586  noobj_loss: 0.1180  bbox_loss: 0.0089  cls_loss: 0.0172  \n",
      "<<<iteration:[180/525] - total_loss: 0.2829  obj_loss: 0.1681  noobj_loss: 0.1088  bbox_loss: 0.0069  cls_loss: 0.0257  \n",
      "<<<iteration:[200/525] - total_loss: 0.2700  obj_loss: 0.1705  noobj_loss: 0.1079  bbox_loss: 0.0066  cls_loss: 0.0124  \n",
      "<<<iteration:[220/525] - total_loss: 0.2639  obj_loss: 0.1510  noobj_loss: 0.1176  bbox_loss: 0.0078  cls_loss: 0.0152  \n",
      "<<<iteration:[240/525] - total_loss: 0.2902  obj_loss: 0.1833  noobj_loss: 0.1116  bbox_loss: 0.0069  cls_loss: 0.0166  \n",
      "<<<iteration:[260/525] - total_loss: 0.2510  obj_loss: 0.1405  noobj_loss: 0.1135  bbox_loss: 0.0079  cls_loss: 0.0142  \n",
      "<<<iteration:[280/525] - total_loss: 0.2578  obj_loss: 0.1585  noobj_loss: 0.1021  bbox_loss: 0.0072  cls_loss: 0.0120  \n",
      "<<<iteration:[300/525] - total_loss: 0.2698  obj_loss: 0.1498  noobj_loss: 0.1059  bbox_loss: 0.0079  cls_loss: 0.0278  \n",
      "<<<iteration:[320/525] - total_loss: 0.2934  obj_loss: 0.1669  noobj_loss: 0.1113  bbox_loss: 0.0092  cls_loss: 0.0249  \n",
      "<<<iteration:[340/525] - total_loss: 0.2530  obj_loss: 0.1481  noobj_loss: 0.1140  bbox_loss: 0.0076  cls_loss: 0.0100  \n",
      "<<<iteration:[360/525] - total_loss: 0.2629  obj_loss: 0.1665  noobj_loss: 0.1087  bbox_loss: 0.0064  cls_loss: 0.0101  \n",
      "<<<iteration:[380/525] - total_loss: 0.2700  obj_loss: 0.1686  noobj_loss: 0.1065  bbox_loss: 0.0075  cls_loss: 0.0105  \n",
      "<<<iteration:[400/525] - total_loss: 0.2777  obj_loss: 0.1679  noobj_loss: 0.1160  bbox_loss: 0.0071  cls_loss: 0.0165  \n",
      "<<<iteration:[420/525] - total_loss: 0.2501  obj_loss: 0.1467  noobj_loss: 0.1035  bbox_loss: 0.0078  cls_loss: 0.0128  \n",
      "<<<iteration:[440/525] - total_loss: 0.3153  obj_loss: 0.1572  noobj_loss: 0.1216  bbox_loss: 0.0109  cls_loss: 0.0426  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<<<iteration:[460/525] - total_loss: 0.2728  obj_loss: 0.1612  noobj_loss: 0.1182  bbox_loss: 0.0070  cls_loss: 0.0175  \n",
      "<<<iteration:[480/525] - total_loss: 0.2651  obj_loss: 0.1568  noobj_loss: 0.1046  bbox_loss: 0.0067  cls_loss: 0.0225  \n",
      "<<<iteration:[500/525] - total_loss: 0.2611  obj_loss: 0.1606  noobj_loss: 0.1015  bbox_loss: 0.0076  cls_loss: 0.0120  \n",
      "<<<iteration:[520/525] - total_loss: 0.2671  obj_loss: 0.1489  noobj_loss: 0.1129  bbox_loss: 0.0084  cls_loss: 0.0197  \n",
      "\n",
      "epoch:62/100 - Train Loss: 0.2679, Val Loss: 0.2743\n",
      "\n",
      "<<<iteration:[20/525] - total_loss: 0.2855  obj_loss: 0.1732  noobj_loss: 0.1164  bbox_loss: 0.0075  cls_loss: 0.0163  \n",
      "<<<iteration:[40/525] - total_loss: 0.2875  obj_loss: 0.1685  noobj_loss: 0.1144  bbox_loss: 0.0080  cls_loss: 0.0219  \n",
      "<<<iteration:[60/525] - total_loss: 0.2841  obj_loss: 0.1499  noobj_loss: 0.1125  bbox_loss: 0.0085  cls_loss: 0.0353  \n",
      "<<<iteration:[80/525] - total_loss: 0.2535  obj_loss: 0.1547  noobj_loss: 0.1108  bbox_loss: 0.0069  cls_loss: 0.0090  \n",
      "<<<iteration:[100/525] - total_loss: 0.2528  obj_loss: 0.1479  noobj_loss: 0.1100  bbox_loss: 0.0072  cls_loss: 0.0138  \n",
      "<<<iteration:[120/525] - total_loss: 0.2569  obj_loss: 0.1592  noobj_loss: 0.1045  bbox_loss: 0.0063  cls_loss: 0.0139  \n",
      "<<<iteration:[140/525] - total_loss: 0.2697  obj_loss: 0.1685  noobj_loss: 0.1061  bbox_loss: 0.0075  cls_loss: 0.0106  \n",
      "<<<iteration:[160/525] - total_loss: 0.2621  obj_loss: 0.1527  noobj_loss: 0.1074  bbox_loss: 0.0085  cls_loss: 0.0133  \n",
      "<<<iteration:[180/525] - total_loss: 0.2508  obj_loss: 0.1424  noobj_loss: 0.1123  bbox_loss: 0.0067  cls_loss: 0.0189  \n",
      "<<<iteration:[200/525] - total_loss: 0.2634  obj_loss: 0.1545  noobj_loss: 0.1137  bbox_loss: 0.0075  cls_loss: 0.0144  \n",
      "<<<iteration:[220/525] - total_loss: 0.2839  obj_loss: 0.1571  noobj_loss: 0.1186  bbox_loss: 0.0075  cls_loss: 0.0299  \n",
      "<<<iteration:[240/525] - total_loss: 0.2727  obj_loss: 0.1684  noobj_loss: 0.1064  bbox_loss: 0.0075  cls_loss: 0.0134  \n",
      "<<<iteration:[260/525] - total_loss: 0.2789  obj_loss: 0.1650  noobj_loss: 0.1177  bbox_loss: 0.0077  cls_loss: 0.0166  \n",
      "<<<iteration:[280/525] - total_loss: 0.2646  obj_loss: 0.1480  noobj_loss: 0.1098  bbox_loss: 0.0070  cls_loss: 0.0265  \n",
      "<<<iteration:[300/525] - total_loss: 0.2964  obj_loss: 0.1679  noobj_loss: 0.1102  bbox_loss: 0.0087  cls_loss: 0.0296  \n",
      "<<<iteration:[320/525] - total_loss: 0.2594  obj_loss: 0.1621  noobj_loss: 0.1073  bbox_loss: 0.0067  cls_loss: 0.0101  \n",
      "<<<iteration:[340/525] - total_loss: 0.2550  obj_loss: 0.1505  noobj_loss: 0.1209  bbox_loss: 0.0067  cls_loss: 0.0107  \n",
      "<<<iteration:[360/525] - total_loss: 0.2727  obj_loss: 0.1622  noobj_loss: 0.1068  bbox_loss: 0.0081  cls_loss: 0.0167  \n",
      "<<<iteration:[380/525] - total_loss: 0.2728  obj_loss: 0.1644  noobj_loss: 0.1084  bbox_loss: 0.0074  cls_loss: 0.0173  \n",
      "<<<iteration:[400/525] - total_loss: 0.2789  obj_loss: 0.1754  noobj_loss: 0.1177  bbox_loss: 0.0061  cls_loss: 0.0140  \n",
      "<<<iteration:[420/525] - total_loss: 0.2549  obj_loss: 0.1486  noobj_loss: 0.1119  bbox_loss: 0.0079  cls_loss: 0.0107  \n",
      "<<<iteration:[440/525] - total_loss: 0.2585  obj_loss: 0.1526  noobj_loss: 0.1142  bbox_loss: 0.0078  cls_loss: 0.0100  \n",
      "<<<iteration:[460/525] - total_loss: 0.2484  obj_loss: 0.1412  noobj_loss: 0.1188  bbox_loss: 0.0069  cls_loss: 0.0135  \n",
      "<<<iteration:[480/525] - total_loss: 0.2723  obj_loss: 0.1754  noobj_loss: 0.1109  bbox_loss: 0.0063  cls_loss: 0.0101  \n",
      "<<<iteration:[500/525] - total_loss: 0.2668  obj_loss: 0.1577  noobj_loss: 0.1125  bbox_loss: 0.0071  cls_loss: 0.0175  \n",
      "<<<iteration:[520/525] - total_loss: 0.2489  obj_loss: 0.1486  noobj_loss: 0.1026  bbox_loss: 0.0077  cls_loss: 0.0104  \n",
      "\n",
      "epoch:63/100 - Train Loss: 0.2663, Val Loss: 0.2737\n",
      "\n",
      "<<<iteration:[20/525] - total_loss: 0.2831  obj_loss: 0.1652  noobj_loss: 0.1217  bbox_loss: 0.0083  cls_loss: 0.0157  \n",
      "<<<iteration:[40/525] - total_loss: 0.2659  obj_loss: 0.1605  noobj_loss: 0.1090  bbox_loss: 0.0072  cls_loss: 0.0150  \n",
      "<<<iteration:[60/525] - total_loss: 0.2693  obj_loss: 0.1617  noobj_loss: 0.1142  bbox_loss: 0.0069  cls_loss: 0.0157  \n",
      "<<<iteration:[80/525] - total_loss: 0.2716  obj_loss: 0.1549  noobj_loss: 0.1206  bbox_loss: 0.0075  cls_loss: 0.0191  \n",
      "<<<iteration:[100/525] - total_loss: 0.2849  obj_loss: 0.1537  noobj_loss: 0.1194  bbox_loss: 0.0097  cls_loss: 0.0229  \n",
      "<<<iteration:[120/525] - total_loss: 0.2665  obj_loss: 0.1639  noobj_loss: 0.1143  bbox_loss: 0.0065  cls_loss: 0.0128  \n",
      "<<<iteration:[140/525] - total_loss: 0.3038  obj_loss: 0.1601  noobj_loss: 0.1313  bbox_loss: 0.0090  cls_loss: 0.0328  \n",
      "<<<iteration:[160/525] - total_loss: 0.2674  obj_loss: 0.1613  noobj_loss: 0.1060  bbox_loss: 0.0068  cls_loss: 0.0190  \n",
      "<<<iteration:[180/525] - total_loss: 0.2800  obj_loss: 0.1713  noobj_loss: 0.1207  bbox_loss: 0.0072  cls_loss: 0.0122  \n",
      "<<<iteration:[200/525] - total_loss: 0.2595  obj_loss: 0.1544  noobj_loss: 0.1085  bbox_loss: 0.0068  cls_loss: 0.0168  \n",
      "<<<iteration:[220/525] - total_loss: 0.2672  obj_loss: 0.1593  noobj_loss: 0.1024  bbox_loss: 0.0095  cls_loss: 0.0091  \n",
      "<<<iteration:[240/525] - total_loss: 0.2566  obj_loss: 0.1478  noobj_loss: 0.1112  bbox_loss: 0.0076  cls_loss: 0.0151  \n",
      "<<<iteration:[260/525] - total_loss: 0.2684  obj_loss: 0.1592  noobj_loss: 0.1204  bbox_loss: 0.0063  cls_loss: 0.0178  \n",
      "<<<iteration:[280/525] - total_loss: 0.2535  obj_loss: 0.1420  noobj_loss: 0.1165  bbox_loss: 0.0080  cls_loss: 0.0134  \n",
      "<<<iteration:[300/525] - total_loss: 0.2565  obj_loss: 0.1539  noobj_loss: 0.1051  bbox_loss: 0.0071  cls_loss: 0.0144  \n",
      "<<<iteration:[320/525] - total_loss: 0.2681  obj_loss: 0.1650  noobj_loss: 0.1023  bbox_loss: 0.0074  cls_loss: 0.0151  \n",
      "<<<iteration:[340/525] - total_loss: 0.2975  obj_loss: 0.1934  noobj_loss: 0.1149  bbox_loss: 0.0069  cls_loss: 0.0120  \n",
      "<<<iteration:[360/525] - total_loss: 0.2714  obj_loss: 0.1544  noobj_loss: 0.1145  bbox_loss: 0.0090  cls_loss: 0.0150  \n",
      "<<<iteration:[380/525] - total_loss: 0.2691  obj_loss: 0.1586  noobj_loss: 0.1101  bbox_loss: 0.0084  cls_loss: 0.0132  \n",
      "<<<iteration:[400/525] - total_loss: 0.2592  obj_loss: 0.1550  noobj_loss: 0.1244  bbox_loss: 0.0064  cls_loss: 0.0098  \n",
      "<<<iteration:[420/525] - total_loss: 0.2740  obj_loss: 0.1642  noobj_loss: 0.1166  bbox_loss: 0.0082  cls_loss: 0.0107  \n",
      "<<<iteration:[440/525] - total_loss: 0.2841  obj_loss: 0.1787  noobj_loss: 0.1132  bbox_loss: 0.0073  cls_loss: 0.0122  \n",
      "<<<iteration:[460/525] - total_loss: 0.2792  obj_loss: 0.1631  noobj_loss: 0.1267  bbox_loss: 0.0077  cls_loss: 0.0145  \n",
      "<<<iteration:[480/525] - total_loss: 0.2527  obj_loss: 0.1549  noobj_loss: 0.1028  bbox_loss: 0.0064  cls_loss: 0.0144  \n",
      "<<<iteration:[500/525] - total_loss: 0.2726  obj_loss: 0.1583  noobj_loss: 0.1139  bbox_loss: 0.0071  cls_loss: 0.0218  \n",
      "<<<iteration:[520/525] - total_loss: 0.2790  obj_loss: 0.1657  noobj_loss: 0.1191  bbox_loss: 0.0074  cls_loss: 0.0167  \n",
      "\n",
      "epoch:64/100 - Train Loss: 0.2711, Val Loss: 0.2705\n",
      "\n",
      "<<<iteration:[20/525] - total_loss: 0.2978  obj_loss: 0.1891  noobj_loss: 0.1214  bbox_loss: 0.0069  cls_loss: 0.0134  \n",
      "<<<iteration:[40/525] - total_loss: 0.2548  obj_loss: 0.1566  noobj_loss: 0.1046  bbox_loss: 0.0072  cls_loss: 0.0102  \n",
      "<<<iteration:[60/525] - total_loss: 0.2758  obj_loss: 0.1724  noobj_loss: 0.1211  bbox_loss: 0.0066  cls_loss: 0.0099  \n",
      "<<<iteration:[80/525] - total_loss: 0.2743  obj_loss: 0.1749  noobj_loss: 0.1143  bbox_loss: 0.0068  cls_loss: 0.0083  \n",
      "<<<iteration:[100/525] - total_loss: 0.2693  obj_loss: 0.1725  noobj_loss: 0.1134  bbox_loss: 0.0059  cls_loss: 0.0107  \n",
      "<<<iteration:[120/525] - total_loss: 0.2701  obj_loss: 0.1484  noobj_loss: 0.1172  bbox_loss: 0.0077  cls_loss: 0.0244  \n",
      "<<<iteration:[140/525] - total_loss: 0.2660  obj_loss: 0.1541  noobj_loss: 0.1129  bbox_loss: 0.0077  cls_loss: 0.0172  \n",
      "<<<iteration:[160/525] - total_loss: 0.2856  obj_loss: 0.1811  noobj_loss: 0.1187  bbox_loss: 0.0073  cls_loss: 0.0084  \n",
      "<<<iteration:[180/525] - total_loss: 0.2603  obj_loss: 0.1563  noobj_loss: 0.1155  bbox_loss: 0.0071  cls_loss: 0.0107  \n",
      "<<<iteration:[200/525] - total_loss: 0.3016  obj_loss: 0.1746  noobj_loss: 0.1107  bbox_loss: 0.0082  cls_loss: 0.0304  \n",
      "<<<iteration:[220/525] - total_loss: 0.2765  obj_loss: 0.1638  noobj_loss: 0.1198  bbox_loss: 0.0071  cls_loss: 0.0174  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<<<iteration:[240/525] - total_loss: 0.2912  obj_loss: 0.1712  noobj_loss: 0.1246  bbox_loss: 0.0086  cls_loss: 0.0149  \n",
      "<<<iteration:[260/525] - total_loss: 0.2505  obj_loss: 0.1468  noobj_loss: 0.1123  bbox_loss: 0.0070  cls_loss: 0.0125  \n",
      "<<<iteration:[280/525] - total_loss: 0.2764  obj_loss: 0.1703  noobj_loss: 0.1089  bbox_loss: 0.0080  cls_loss: 0.0117  \n",
      "<<<iteration:[300/525] - total_loss: 0.2792  obj_loss: 0.1735  noobj_loss: 0.1165  bbox_loss: 0.0066  cls_loss: 0.0145  \n",
      "<<<iteration:[320/525] - total_loss: 0.2633  obj_loss: 0.1612  noobj_loss: 0.1141  bbox_loss: 0.0063  cls_loss: 0.0137  \n",
      "<<<iteration:[340/525] - total_loss: 0.2635  obj_loss: 0.1642  noobj_loss: 0.1186  bbox_loss: 0.0058  cls_loss: 0.0109  \n",
      "<<<iteration:[360/525] - total_loss: 0.2725  obj_loss: 0.1671  noobj_loss: 0.1154  bbox_loss: 0.0068  cls_loss: 0.0137  \n",
      "<<<iteration:[380/525] - total_loss: 0.2778  obj_loss: 0.1480  noobj_loss: 0.1270  bbox_loss: 0.0084  cls_loss: 0.0245  \n",
      "<<<iteration:[400/525] - total_loss: 0.2553  obj_loss: 0.1482  noobj_loss: 0.1081  bbox_loss: 0.0074  cls_loss: 0.0161  \n",
      "<<<iteration:[420/525] - total_loss: 0.2696  obj_loss: 0.1647  noobj_loss: 0.1120  bbox_loss: 0.0066  cls_loss: 0.0158  \n",
      "<<<iteration:[440/525] - total_loss: 0.2611  obj_loss: 0.1595  noobj_loss: 0.1192  bbox_loss: 0.0065  cls_loss: 0.0095  \n",
      "<<<iteration:[460/525] - total_loss: 0.2542  obj_loss: 0.1403  noobj_loss: 0.1211  bbox_loss: 0.0079  cls_loss: 0.0141  \n",
      "<<<iteration:[480/525] - total_loss: 0.2798  obj_loss: 0.1723  noobj_loss: 0.1159  bbox_loss: 0.0070  cls_loss: 0.0144  \n",
      "<<<iteration:[500/525] - total_loss: 0.2644  obj_loss: 0.1596  noobj_loss: 0.1142  bbox_loss: 0.0069  cls_loss: 0.0133  \n",
      "<<<iteration:[520/525] - total_loss: 0.2839  obj_loss: 0.1774  noobj_loss: 0.1253  bbox_loss: 0.0069  cls_loss: 0.0095  \n",
      "\n",
      "epoch:65/100 - Train Loss: 0.2712, Val Loss: 0.2700\n",
      "\n",
      "<<<iteration:[20/525] - total_loss: 0.2804  obj_loss: 0.1794  noobj_loss: 0.1143  bbox_loss: 0.0063  cls_loss: 0.0125  \n",
      "<<<iteration:[40/525] - total_loss: 0.2712  obj_loss: 0.1649  noobj_loss: 0.1260  bbox_loss: 0.0064  cls_loss: 0.0113  \n",
      "<<<iteration:[60/525] - total_loss: 0.2737  obj_loss: 0.1669  noobj_loss: 0.1173  bbox_loss: 0.0065  cls_loss: 0.0154  \n",
      "<<<iteration:[80/525] - total_loss: 0.2814  obj_loss: 0.1694  noobj_loss: 0.1204  bbox_loss: 0.0069  cls_loss: 0.0172  \n",
      "<<<iteration:[100/525] - total_loss: 0.2682  obj_loss: 0.1649  noobj_loss: 0.1105  bbox_loss: 0.0072  cls_loss: 0.0118  \n",
      "<<<iteration:[120/525] - total_loss: 0.2719  obj_loss: 0.1682  noobj_loss: 0.1143  bbox_loss: 0.0071  cls_loss: 0.0113  \n",
      "<<<iteration:[140/525] - total_loss: 0.2739  obj_loss: 0.1672  noobj_loss: 0.1243  bbox_loss: 0.0074  cls_loss: 0.0077  \n",
      "<<<iteration:[160/525] - total_loss: 0.2640  obj_loss: 0.1683  noobj_loss: 0.1147  bbox_loss: 0.0058  cls_loss: 0.0094  \n",
      "<<<iteration:[180/525] - total_loss: 0.2908  obj_loss: 0.1813  noobj_loss: 0.1173  bbox_loss: 0.0072  cls_loss: 0.0149  \n",
      "<<<iteration:[200/525] - total_loss: 0.2541  obj_loss: 0.1570  noobj_loss: 0.1193  bbox_loss: 0.0057  cls_loss: 0.0091  \n",
      "<<<iteration:[220/525] - total_loss: 0.2671  obj_loss: 0.1587  noobj_loss: 0.1159  bbox_loss: 0.0071  cls_loss: 0.0149  \n",
      "<<<iteration:[240/525] - total_loss: 0.2835  obj_loss: 0.1803  noobj_loss: 0.1207  bbox_loss: 0.0051  cls_loss: 0.0176  \n",
      "<<<iteration:[260/525] - total_loss: 0.2568  obj_loss: 0.1496  noobj_loss: 0.1143  bbox_loss: 0.0087  cls_loss: 0.0065  \n",
      "<<<iteration:[280/525] - total_loss: 0.2821  obj_loss: 0.1771  noobj_loss: 0.1062  bbox_loss: 0.0069  cls_loss: 0.0174  \n",
      "<<<iteration:[300/525] - total_loss: 0.2771  obj_loss: 0.1637  noobj_loss: 0.1138  bbox_loss: 0.0084  cls_loss: 0.0145  \n",
      "<<<iteration:[320/525] - total_loss: 0.2710  obj_loss: 0.1611  noobj_loss: 0.1183  bbox_loss: 0.0075  cls_loss: 0.0133  \n",
      "<<<iteration:[340/525] - total_loss: 0.2719  obj_loss: 0.1607  noobj_loss: 0.1174  bbox_loss: 0.0079  cls_loss: 0.0129  \n",
      "<<<iteration:[360/525] - total_loss: 0.2697  obj_loss: 0.1563  noobj_loss: 0.1221  bbox_loss: 0.0081  cls_loss: 0.0120  \n",
      "<<<iteration:[380/525] - total_loss: 0.2769  obj_loss: 0.1715  noobj_loss: 0.1180  bbox_loss: 0.0069  cls_loss: 0.0119  \n",
      "<<<iteration:[400/525] - total_loss: 0.2545  obj_loss: 0.1499  noobj_loss: 0.1153  bbox_loss: 0.0077  cls_loss: 0.0083  \n",
      "<<<iteration:[420/525] - total_loss: 0.2858  obj_loss: 0.1507  noobj_loss: 0.1258  bbox_loss: 0.0084  cls_loss: 0.0304  \n",
      "<<<iteration:[440/525] - total_loss: 0.2787  obj_loss: 0.1655  noobj_loss: 0.1163  bbox_loss: 0.0076  cls_loss: 0.0169  \n",
      "<<<iteration:[460/525] - total_loss: 0.2884  obj_loss: 0.1675  noobj_loss: 0.1145  bbox_loss: 0.0080  cls_loss: 0.0238  \n",
      "<<<iteration:[480/525] - total_loss: 0.2707  obj_loss: 0.1628  noobj_loss: 0.1251  bbox_loss: 0.0064  cls_loss: 0.0136  \n",
      "<<<iteration:[500/525] - total_loss: 0.2644  obj_loss: 0.1599  noobj_loss: 0.1301  bbox_loss: 0.0058  cls_loss: 0.0102  \n",
      "<<<iteration:[520/525] - total_loss: 0.2670  obj_loss: 0.1618  noobj_loss: 0.1197  bbox_loss: 0.0064  cls_loss: 0.0132  \n",
      "\n",
      "epoch:66/100 - Train Loss: 0.2723, Val Loss: 0.2618\n",
      "\n",
      "<<<iteration:[20/525] - total_loss: 0.2829  obj_loss: 0.1669  noobj_loss: 0.1273  bbox_loss: 0.0081  cls_loss: 0.0119  \n",
      "<<<iteration:[40/525] - total_loss: 0.2738  obj_loss: 0.1699  noobj_loss: 0.1285  bbox_loss: 0.0067  cls_loss: 0.0063  \n",
      "<<<iteration:[60/525] - total_loss: 0.2554  obj_loss: 0.1469  noobj_loss: 0.1147  bbox_loss: 0.0067  cls_loss: 0.0176  \n",
      "<<<iteration:[80/525] - total_loss: 0.3007  obj_loss: 0.1749  noobj_loss: 0.1233  bbox_loss: 0.0085  cls_loss: 0.0216  \n",
      "<<<iteration:[100/525] - total_loss: 0.2597  obj_loss: 0.1520  noobj_loss: 0.1198  bbox_loss: 0.0071  cls_loss: 0.0125  \n",
      "<<<iteration:[120/525] - total_loss: 0.2696  obj_loss: 0.1593  noobj_loss: 0.1204  bbox_loss: 0.0079  cls_loss: 0.0108  \n",
      "<<<iteration:[140/525] - total_loss: 0.2429  obj_loss: 0.1389  noobj_loss: 0.1204  bbox_loss: 0.0070  cls_loss: 0.0087  \n",
      "<<<iteration:[160/525] - total_loss: 0.2735  obj_loss: 0.1602  noobj_loss: 0.1163  bbox_loss: 0.0077  cls_loss: 0.0164  \n",
      "<<<iteration:[180/525] - total_loss: 0.2621  obj_loss: 0.1595  noobj_loss: 0.1127  bbox_loss: 0.0076  cls_loss: 0.0083  \n",
      "<<<iteration:[200/525] - total_loss: 0.2758  obj_loss: 0.1749  noobj_loss: 0.1170  bbox_loss: 0.0061  cls_loss: 0.0117  \n",
      "<<<iteration:[220/525] - total_loss: 0.2736  obj_loss: 0.1677  noobj_loss: 0.1220  bbox_loss: 0.0069  cls_loss: 0.0102  \n",
      "<<<iteration:[240/525] - total_loss: 0.2579  obj_loss: 0.1531  noobj_loss: 0.1136  bbox_loss: 0.0061  cls_loss: 0.0175  \n",
      "<<<iteration:[260/525] - total_loss: 0.2713  obj_loss: 0.1586  noobj_loss: 0.1179  bbox_loss: 0.0083  cls_loss: 0.0122  \n",
      "<<<iteration:[280/525] - total_loss: 0.2611  obj_loss: 0.1546  noobj_loss: 0.1193  bbox_loss: 0.0060  cls_loss: 0.0168  \n",
      "<<<iteration:[300/525] - total_loss: 0.2735  obj_loss: 0.1718  noobj_loss: 0.1185  bbox_loss: 0.0063  cls_loss: 0.0109  \n",
      "<<<iteration:[320/525] - total_loss: 0.2663  obj_loss: 0.1580  noobj_loss: 0.1166  bbox_loss: 0.0077  cls_loss: 0.0113  \n",
      "<<<iteration:[340/525] - total_loss: 0.2623  obj_loss: 0.1488  noobj_loss: 0.1120  bbox_loss: 0.0069  cls_loss: 0.0231  \n",
      "<<<iteration:[360/525] - total_loss: 0.2924  obj_loss: 0.1710  noobj_loss: 0.1238  bbox_loss: 0.0068  cls_loss: 0.0257  \n",
      "<<<iteration:[380/525] - total_loss: 0.2762  obj_loss: 0.1736  noobj_loss: 0.1147  bbox_loss: 0.0062  cls_loss: 0.0142  \n",
      "<<<iteration:[400/525] - total_loss: 0.2701  obj_loss: 0.1593  noobj_loss: 0.1131  bbox_loss: 0.0080  cls_loss: 0.0140  \n",
      "<<<iteration:[420/525] - total_loss: 0.2513  obj_loss: 0.1442  noobj_loss: 0.1170  bbox_loss: 0.0075  cls_loss: 0.0112  \n",
      "<<<iteration:[440/525] - total_loss: 0.2712  obj_loss: 0.1712  noobj_loss: 0.1169  bbox_loss: 0.0064  cls_loss: 0.0097  \n",
      "<<<iteration:[460/525] - total_loss: 0.2666  obj_loss: 0.1577  noobj_loss: 0.1165  bbox_loss: 0.0074  cls_loss: 0.0135  \n",
      "<<<iteration:[480/525] - total_loss: 0.2874  obj_loss: 0.1713  noobj_loss: 0.1209  bbox_loss: 0.0063  cls_loss: 0.0241  \n",
      "<<<iteration:[500/525] - total_loss: 0.2546  obj_loss: 0.1557  noobj_loss: 0.1184  bbox_loss: 0.0061  cls_loss: 0.0093  \n",
      "<<<iteration:[520/525] - total_loss: 0.2772  obj_loss: 0.1744  noobj_loss: 0.1264  bbox_loss: 0.0059  cls_loss: 0.0100  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "epoch:67/100 - Train Loss: 0.2690, Val Loss: 0.2805\n",
      "\n",
      "<<<iteration:[20/525] - total_loss: 0.2659  obj_loss: 0.1478  noobj_loss: 0.1218  bbox_loss: 0.0079  cls_loss: 0.0176  \n",
      "<<<iteration:[40/525] - total_loss: 0.2667  obj_loss: 0.1530  noobj_loss: 0.1123  bbox_loss: 0.0085  cls_loss: 0.0148  \n",
      "<<<iteration:[60/525] - total_loss: 0.2700  obj_loss: 0.1672  noobj_loss: 0.1159  bbox_loss: 0.0065  cls_loss: 0.0122  \n",
      "<<<iteration:[80/525] - total_loss: 0.2670  obj_loss: 0.1624  noobj_loss: 0.1199  bbox_loss: 0.0068  cls_loss: 0.0108  \n",
      "<<<iteration:[100/525] - total_loss: 0.2577  obj_loss: 0.1617  noobj_loss: 0.1182  bbox_loss: 0.0061  cls_loss: 0.0067  \n",
      "<<<iteration:[120/525] - total_loss: 0.2729  obj_loss: 0.1769  noobj_loss: 0.1152  bbox_loss: 0.0060  cls_loss: 0.0085  \n",
      "<<<iteration:[140/525] - total_loss: 0.2554  obj_loss: 0.1527  noobj_loss: 0.1231  bbox_loss: 0.0062  cls_loss: 0.0100  \n",
      "<<<iteration:[160/525] - total_loss: 0.2597  obj_loss: 0.1540  noobj_loss: 0.1117  bbox_loss: 0.0072  cls_loss: 0.0137  \n",
      "<<<iteration:[180/525] - total_loss: 0.2640  obj_loss: 0.1614  noobj_loss: 0.1183  bbox_loss: 0.0070  cls_loss: 0.0084  \n",
      "<<<iteration:[200/525] - total_loss: 0.2720  obj_loss: 0.1581  noobj_loss: 0.1232  bbox_loss: 0.0074  cls_loss: 0.0153  \n",
      "<<<iteration:[220/525] - total_loss: 0.2894  obj_loss: 0.1830  noobj_loss: 0.1153  bbox_loss: 0.0064  cls_loss: 0.0167  \n",
      "<<<iteration:[240/525] - total_loss: 0.2669  obj_loss: 0.1581  noobj_loss: 0.1273  bbox_loss: 0.0067  cls_loss: 0.0117  \n",
      "<<<iteration:[260/525] - total_loss: 0.2904  obj_loss: 0.1676  noobj_loss: 0.1149  bbox_loss: 0.0076  cls_loss: 0.0275  \n",
      "<<<iteration:[280/525] - total_loss: 0.2587  obj_loss: 0.1656  noobj_loss: 0.1058  bbox_loss: 0.0062  cls_loss: 0.0095  \n",
      "<<<iteration:[300/525] - total_loss: 0.2676  obj_loss: 0.1684  noobj_loss: 0.1145  bbox_loss: 0.0059  cls_loss: 0.0124  \n",
      "<<<iteration:[320/525] - total_loss: 0.2464  obj_loss: 0.1478  noobj_loss: 0.1176  bbox_loss: 0.0060  cls_loss: 0.0096  \n",
      "<<<iteration:[340/525] - total_loss: 0.2727  obj_loss: 0.1591  noobj_loss: 0.1180  bbox_loss: 0.0077  cls_loss: 0.0164  \n",
      "<<<iteration:[360/525] - total_loss: 0.2756  obj_loss: 0.1710  noobj_loss: 0.1118  bbox_loss: 0.0075  cls_loss: 0.0113  \n",
      "<<<iteration:[380/525] - total_loss: 0.2784  obj_loss: 0.1666  noobj_loss: 0.1123  bbox_loss: 0.0083  cls_loss: 0.0141  \n",
      "<<<iteration:[400/525] - total_loss: 0.2432  obj_loss: 0.1400  noobj_loss: 0.1184  bbox_loss: 0.0066  cls_loss: 0.0112  \n",
      "<<<iteration:[420/525] - total_loss: 0.2870  obj_loss: 0.1775  noobj_loss: 0.1128  bbox_loss: 0.0080  cls_loss: 0.0133  \n",
      "<<<iteration:[440/525] - total_loss: 0.2770  obj_loss: 0.1546  noobj_loss: 0.1281  bbox_loss: 0.0084  cls_loss: 0.0165  \n",
      "<<<iteration:[460/525] - total_loss: 0.2815  obj_loss: 0.1757  noobj_loss: 0.1255  bbox_loss: 0.0062  cls_loss: 0.0118  \n",
      "<<<iteration:[480/525] - total_loss: 0.2442  obj_loss: 0.1472  noobj_loss: 0.1180  bbox_loss: 0.0060  cls_loss: 0.0082  \n",
      "<<<iteration:[500/525] - total_loss: 0.2858  obj_loss: 0.1691  noobj_loss: 0.1130  bbox_loss: 0.0072  cls_loss: 0.0242  \n",
      "<<<iteration:[520/525] - total_loss: 0.2687  obj_loss: 0.1582  noobj_loss: 0.1179  bbox_loss: 0.0071  cls_loss: 0.0159  \n",
      "\n",
      "epoch:68/100 - Train Loss: 0.2682, Val Loss: 0.2677\n",
      "\n",
      "<<<iteration:[20/525] - total_loss: 0.2775  obj_loss: 0.1672  noobj_loss: 0.1235  bbox_loss: 0.0079  cls_loss: 0.0088  \n",
      "<<<iteration:[40/525] - total_loss: 0.2764  obj_loss: 0.1675  noobj_loss: 0.1253  bbox_loss: 0.0065  cls_loss: 0.0137  \n",
      "<<<iteration:[60/525] - total_loss: 0.3078  obj_loss: 0.1880  noobj_loss: 0.1238  bbox_loss: 0.0071  cls_loss: 0.0225  \n",
      "<<<iteration:[80/525] - total_loss: 0.2596  obj_loss: 0.1591  noobj_loss: 0.1144  bbox_loss: 0.0066  cls_loss: 0.0105  \n",
      "<<<iteration:[100/525] - total_loss: 0.2597  obj_loss: 0.1513  noobj_loss: 0.1221  bbox_loss: 0.0071  cls_loss: 0.0120  \n",
      "<<<iteration:[120/525] - total_loss: 0.2528  obj_loss: 0.1491  noobj_loss: 0.1195  bbox_loss: 0.0062  cls_loss: 0.0129  \n",
      "<<<iteration:[140/525] - total_loss: 0.2808  obj_loss: 0.1716  noobj_loss: 0.1219  bbox_loss: 0.0074  cls_loss: 0.0113  \n",
      "<<<iteration:[160/525] - total_loss: 0.2751  obj_loss: 0.1621  noobj_loss: 0.1251  bbox_loss: 0.0064  cls_loss: 0.0187  \n",
      "<<<iteration:[180/525] - total_loss: 0.2802  obj_loss: 0.1765  noobj_loss: 0.1219  bbox_loss: 0.0058  cls_loss: 0.0136  \n",
      "<<<iteration:[200/525] - total_loss: 0.2680  obj_loss: 0.1646  noobj_loss: 0.1201  bbox_loss: 0.0065  cls_loss: 0.0109  \n",
      "<<<iteration:[220/525] - total_loss: 0.2724  obj_loss: 0.1667  noobj_loss: 0.1141  bbox_loss: 0.0068  cls_loss: 0.0147  \n",
      "<<<iteration:[240/525] - total_loss: 0.2844  obj_loss: 0.1703  noobj_loss: 0.1231  bbox_loss: 0.0068  cls_loss: 0.0184  \n",
      "<<<iteration:[260/525] - total_loss: 0.2584  obj_loss: 0.1568  noobj_loss: 0.1190  bbox_loss: 0.0064  cls_loss: 0.0103  \n",
      "<<<iteration:[280/525] - total_loss: 0.2681  obj_loss: 0.1601  noobj_loss: 0.1144  bbox_loss: 0.0059  cls_loss: 0.0210  \n",
      "<<<iteration:[300/525] - total_loss: 0.2745  obj_loss: 0.1728  noobj_loss: 0.1216  bbox_loss: 0.0062  cls_loss: 0.0097  \n",
      "<<<iteration:[320/525] - total_loss: 0.2588  obj_loss: 0.1530  noobj_loss: 0.1205  bbox_loss: 0.0079  cls_loss: 0.0063  \n",
      "<<<iteration:[340/525] - total_loss: 0.2555  obj_loss: 0.1564  noobj_loss: 0.1179  bbox_loss: 0.0059  cls_loss: 0.0109  \n",
      "<<<iteration:[360/525] - total_loss: 0.2736  obj_loss: 0.1686  noobj_loss: 0.1141  bbox_loss: 0.0076  cls_loss: 0.0100  \n",
      "<<<iteration:[380/525] - total_loss: 0.2683  obj_loss: 0.1569  noobj_loss: 0.1183  bbox_loss: 0.0071  cls_loss: 0.0166  \n",
      "<<<iteration:[400/525] - total_loss: 0.2531  obj_loss: 0.1563  noobj_loss: 0.1183  bbox_loss: 0.0057  cls_loss: 0.0090  \n",
      "<<<iteration:[420/525] - total_loss: 0.2605  obj_loss: 0.1591  noobj_loss: 0.1128  bbox_loss: 0.0067  cls_loss: 0.0112  \n",
      "<<<iteration:[440/525] - total_loss: 0.2747  obj_loss: 0.1646  noobj_loss: 0.1164  bbox_loss: 0.0080  cls_loss: 0.0117  \n",
      "<<<iteration:[460/525] - total_loss: 0.2671  obj_loss: 0.1601  noobj_loss: 0.1268  bbox_loss: 0.0065  cls_loss: 0.0112  \n",
      "<<<iteration:[480/525] - total_loss: 0.2653  obj_loss: 0.1682  noobj_loss: 0.1119  bbox_loss: 0.0063  cls_loss: 0.0098  \n",
      "<<<iteration:[500/525] - total_loss: 0.2775  obj_loss: 0.1697  noobj_loss: 0.1235  bbox_loss: 0.0072  cls_loss: 0.0100  \n",
      "<<<iteration:[520/525] - total_loss: 0.2708  obj_loss: 0.1575  noobj_loss: 0.1252  bbox_loss: 0.0072  cls_loss: 0.0148  \n",
      "\n",
      "epoch:69/100 - Train Loss: 0.2695, Val Loss: 0.2736\n",
      "\n",
      "<<<iteration:[20/525] - total_loss: 0.2750  obj_loss: 0.1678  noobj_loss: 0.1218  bbox_loss: 0.0070  cls_loss: 0.0116  \n",
      "<<<iteration:[40/525] - total_loss: 0.2803  obj_loss: 0.1628  noobj_loss: 0.1256  bbox_loss: 0.0070  cls_loss: 0.0198  \n",
      "<<<iteration:[60/525] - total_loss: 0.2736  obj_loss: 0.1645  noobj_loss: 0.1254  bbox_loss: 0.0062  cls_loss: 0.0157  \n",
      "<<<iteration:[80/525] - total_loss: 0.2765  obj_loss: 0.1713  noobj_loss: 0.1159  bbox_loss: 0.0068  cls_loss: 0.0134  \n",
      "<<<iteration:[100/525] - total_loss: 0.2683  obj_loss: 0.1623  noobj_loss: 0.1227  bbox_loss: 0.0062  cls_loss: 0.0138  \n",
      "<<<iteration:[120/525] - total_loss: 0.2622  obj_loss: 0.1583  noobj_loss: 0.1187  bbox_loss: 0.0074  cls_loss: 0.0075  \n",
      "<<<iteration:[140/525] - total_loss: 0.2609  obj_loss: 0.1469  noobj_loss: 0.1142  bbox_loss: 0.0096  cls_loss: 0.0091  \n",
      "<<<iteration:[160/525] - total_loss: 0.2689  obj_loss: 0.1650  noobj_loss: 0.1255  bbox_loss: 0.0065  cls_loss: 0.0086  \n",
      "<<<iteration:[180/525] - total_loss: 0.2562  obj_loss: 0.1499  noobj_loss: 0.1016  bbox_loss: 0.0079  cls_loss: 0.0160  \n",
      "<<<iteration:[200/525] - total_loss: 0.2945  obj_loss: 0.1796  noobj_loss: 0.1088  bbox_loss: 0.0085  cls_loss: 0.0178  \n",
      "<<<iteration:[220/525] - total_loss: 0.2821  obj_loss: 0.1711  noobj_loss: 0.1193  bbox_loss: 0.0071  cls_loss: 0.0159  \n",
      "<<<iteration:[240/525] - total_loss: 0.2630  obj_loss: 0.1571  noobj_loss: 0.1207  bbox_loss: 0.0072  cls_loss: 0.0094  \n",
      "<<<iteration:[260/525] - total_loss: 0.2609  obj_loss: 0.1557  noobj_loss: 0.1187  bbox_loss: 0.0063  cls_loss: 0.0143  \n",
      "<<<iteration:[280/525] - total_loss: 0.2877  obj_loss: 0.1668  noobj_loss: 0.1295  bbox_loss: 0.0077  cls_loss: 0.0178  \n",
      "<<<iteration:[300/525] - total_loss: 0.2717  obj_loss: 0.1537  noobj_loss: 0.1275  bbox_loss: 0.0081  cls_loss: 0.0136  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<<<iteration:[320/525] - total_loss: 0.2688  obj_loss: 0.1683  noobj_loss: 0.1284  bbox_loss: 0.0052  cls_loss: 0.0103  \n",
      "<<<iteration:[340/525] - total_loss: 0.2809  obj_loss: 0.1705  noobj_loss: 0.1216  bbox_loss: 0.0081  cls_loss: 0.0091  \n",
      "<<<iteration:[360/525] - total_loss: 0.2698  obj_loss: 0.1581  noobj_loss: 0.1245  bbox_loss: 0.0076  cls_loss: 0.0114  \n",
      "<<<iteration:[380/525] - total_loss: 0.3023  obj_loss: 0.1743  noobj_loss: 0.1255  bbox_loss: 0.0098  cls_loss: 0.0164  \n",
      "<<<iteration:[400/525] - total_loss: 0.2714  obj_loss: 0.1600  noobj_loss: 0.1114  bbox_loss: 0.0082  cls_loss: 0.0146  \n",
      "<<<iteration:[420/525] - total_loss: 0.2621  obj_loss: 0.1606  noobj_loss: 0.1186  bbox_loss: 0.0064  cls_loss: 0.0104  \n",
      "<<<iteration:[440/525] - total_loss: 0.3010  obj_loss: 0.1670  noobj_loss: 0.1299  bbox_loss: 0.0085  cls_loss: 0.0263  \n",
      "<<<iteration:[460/525] - total_loss: 0.2628  obj_loss: 0.1561  noobj_loss: 0.1250  bbox_loss: 0.0072  cls_loss: 0.0083  \n",
      "<<<iteration:[480/525] - total_loss: 0.2579  obj_loss: 0.1596  noobj_loss: 0.1073  bbox_loss: 0.0067  cls_loss: 0.0111  \n",
      "<<<iteration:[500/525] - total_loss: 0.2712  obj_loss: 0.1639  noobj_loss: 0.1172  bbox_loss: 0.0070  cls_loss: 0.0140  \n",
      "<<<iteration:[520/525] - total_loss: 0.2614  obj_loss: 0.1603  noobj_loss: 0.1178  bbox_loss: 0.0067  cls_loss: 0.0090  \n",
      "\n",
      "epoch:70/100 - Train Loss: 0.2721, Val Loss: 0.2745\n",
      "\n",
      "<<<iteration:[20/525] - total_loss: 0.2772  obj_loss: 0.1726  noobj_loss: 0.1235  bbox_loss: 0.0064  cls_loss: 0.0108  \n",
      "<<<iteration:[40/525] - total_loss: 0.2521  obj_loss: 0.1533  noobj_loss: 0.1184  bbox_loss: 0.0063  cls_loss: 0.0083  \n",
      "<<<iteration:[60/525] - total_loss: 0.2468  obj_loss: 0.1428  noobj_loss: 0.1202  bbox_loss: 0.0074  cls_loss: 0.0068  \n",
      "<<<iteration:[80/525] - total_loss: 0.2598  obj_loss: 0.1610  noobj_loss: 0.1187  bbox_loss: 0.0056  cls_loss: 0.0116  \n",
      "<<<iteration:[100/525] - total_loss: 0.2773  obj_loss: 0.1704  noobj_loss: 0.1235  bbox_loss: 0.0069  cls_loss: 0.0108  \n",
      "<<<iteration:[120/525] - total_loss: 0.2738  obj_loss: 0.1714  noobj_loss: 0.1166  bbox_loss: 0.0066  cls_loss: 0.0112  \n",
      "<<<iteration:[140/525] - total_loss: 0.2764  obj_loss: 0.1665  noobj_loss: 0.1266  bbox_loss: 0.0067  cls_loss: 0.0133  \n",
      "<<<iteration:[160/525] - total_loss: 0.2734  obj_loss: 0.1638  noobj_loss: 0.1226  bbox_loss: 0.0072  cls_loss: 0.0126  \n",
      "<<<iteration:[180/525] - total_loss: 0.2680  obj_loss: 0.1669  noobj_loss: 0.1219  bbox_loss: 0.0063  cls_loss: 0.0085  \n",
      "<<<iteration:[200/525] - total_loss: 0.2765  obj_loss: 0.1552  noobj_loss: 0.1224  bbox_loss: 0.0076  cls_loss: 0.0221  \n",
      "<<<iteration:[220/525] - total_loss: 0.2682  obj_loss: 0.1673  noobj_loss: 0.1246  bbox_loss: 0.0057  cls_loss: 0.0100  \n",
      "<<<iteration:[240/525] - total_loss: 0.2767  obj_loss: 0.1677  noobj_loss: 0.1249  bbox_loss: 0.0072  cls_loss: 0.0104  \n",
      "<<<iteration:[260/525] - total_loss: 0.2808  obj_loss: 0.1664  noobj_loss: 0.1251  bbox_loss: 0.0066  cls_loss: 0.0188  \n",
      "<<<iteration:[280/525] - total_loss: 0.2591  obj_loss: 0.1527  noobj_loss: 0.1268  bbox_loss: 0.0063  cls_loss: 0.0116  \n",
      "<<<iteration:[300/525] - total_loss: 0.2683  obj_loss: 0.1568  noobj_loss: 0.1233  bbox_loss: 0.0081  cls_loss: 0.0094  \n",
      "<<<iteration:[320/525] - total_loss: 0.2827  obj_loss: 0.1725  noobj_loss: 0.1195  bbox_loss: 0.0072  cls_loss: 0.0146  \n",
      "<<<iteration:[340/525] - total_loss: 0.2672  obj_loss: 0.1552  noobj_loss: 0.1138  bbox_loss: 0.0083  cls_loss: 0.0136  \n",
      "<<<iteration:[360/525] - total_loss: 0.2700  obj_loss: 0.1684  noobj_loss: 0.1176  bbox_loss: 0.0061  cls_loss: 0.0125  \n",
      "<<<iteration:[380/525] - total_loss: 0.2836  obj_loss: 0.1742  noobj_loss: 0.1122  bbox_loss: 0.0084  cls_loss: 0.0116  \n",
      "<<<iteration:[400/525] - total_loss: 0.2776  obj_loss: 0.1588  noobj_loss: 0.1371  bbox_loss: 0.0074  cls_loss: 0.0134  \n",
      "<<<iteration:[420/525] - total_loss: 0.2758  obj_loss: 0.1678  noobj_loss: 0.1280  bbox_loss: 0.0065  cls_loss: 0.0116  \n",
      "<<<iteration:[440/525] - total_loss: 0.2634  obj_loss: 0.1549  noobj_loss: 0.1181  bbox_loss: 0.0063  cls_loss: 0.0180  \n",
      "<<<iteration:[460/525] - total_loss: 0.2777  obj_loss: 0.1682  noobj_loss: 0.1149  bbox_loss: 0.0071  cls_loss: 0.0167  \n",
      "<<<iteration:[480/525] - total_loss: 0.2676  obj_loss: 0.1569  noobj_loss: 0.1272  bbox_loss: 0.0070  cls_loss: 0.0118  \n",
      "<<<iteration:[500/525] - total_loss: 0.2613  obj_loss: 0.1553  noobj_loss: 0.1199  bbox_loss: 0.0067  cls_loss: 0.0127  \n",
      "<<<iteration:[520/525] - total_loss: 0.2723  obj_loss: 0.1702  noobj_loss: 0.1126  bbox_loss: 0.0068  cls_loss: 0.0120  \n",
      "\n",
      "epoch:71/100 - Train Loss: 0.2700, Val Loss: 0.2744\n",
      "\n",
      "<<<iteration:[20/525] - total_loss: 0.2814  obj_loss: 0.1735  noobj_loss: 0.1223  bbox_loss: 0.0076  cls_loss: 0.0089  \n",
      "<<<iteration:[40/525] - total_loss: 0.2745  obj_loss: 0.1659  noobj_loss: 0.1226  bbox_loss: 0.0069  cls_loss: 0.0126  \n",
      "<<<iteration:[60/525] - total_loss: 0.2791  obj_loss: 0.1624  noobj_loss: 0.1225  bbox_loss: 0.0073  cls_loss: 0.0190  \n",
      "<<<iteration:[80/525] - total_loss: 0.2496  obj_loss: 0.1508  noobj_loss: 0.1195  bbox_loss: 0.0063  cls_loss: 0.0075  \n",
      "<<<iteration:[100/525] - total_loss: 0.2860  obj_loss: 0.1620  noobj_loss: 0.1198  bbox_loss: 0.0085  cls_loss: 0.0218  \n",
      "<<<iteration:[120/525] - total_loss: 0.2731  obj_loss: 0.1646  noobj_loss: 0.1238  bbox_loss: 0.0070  cls_loss: 0.0118  \n",
      "<<<iteration:[140/525] - total_loss: 0.2770  obj_loss: 0.1518  noobj_loss: 0.1196  bbox_loss: 0.0081  cls_loss: 0.0248  \n",
      "<<<iteration:[160/525] - total_loss: 0.2518  obj_loss: 0.1575  noobj_loss: 0.1141  bbox_loss: 0.0058  cls_loss: 0.0081  \n",
      "<<<iteration:[180/525] - total_loss: 0.2572  obj_loss: 0.1517  noobj_loss: 0.1189  bbox_loss: 0.0072  cls_loss: 0.0102  \n",
      "<<<iteration:[200/525] - total_loss: 0.2637  obj_loss: 0.1563  noobj_loss: 0.1138  bbox_loss: 0.0060  cls_loss: 0.0204  \n",
      "<<<iteration:[220/525] - total_loss: 0.2632  obj_loss: 0.1659  noobj_loss: 0.1164  bbox_loss: 0.0062  cls_loss: 0.0083  \n",
      "<<<iteration:[240/525] - total_loss: 0.2583  obj_loss: 0.1570  noobj_loss: 0.1124  bbox_loss: 0.0069  cls_loss: 0.0107  \n",
      "<<<iteration:[260/525] - total_loss: 0.2569  obj_loss: 0.1581  noobj_loss: 0.1196  bbox_loss: 0.0061  cls_loss: 0.0084  \n",
      "<<<iteration:[280/525] - total_loss: 0.2559  obj_loss: 0.1492  noobj_loss: 0.1208  bbox_loss: 0.0065  cls_loss: 0.0140  \n",
      "<<<iteration:[300/525] - total_loss: 0.2660  obj_loss: 0.1499  noobj_loss: 0.1306  bbox_loss: 0.0070  cls_loss: 0.0160  \n",
      "<<<iteration:[320/525] - total_loss: 0.2832  obj_loss: 0.1617  noobj_loss: 0.1262  bbox_loss: 0.0067  cls_loss: 0.0247  \n",
      "<<<iteration:[340/525] - total_loss: 0.2639  obj_loss: 0.1512  noobj_loss: 0.1291  bbox_loss: 0.0076  cls_loss: 0.0104  \n",
      "<<<iteration:[360/525] - total_loss: 0.2544  obj_loss: 0.1569  noobj_loss: 0.1215  bbox_loss: 0.0061  cls_loss: 0.0065  \n",
      "<<<iteration:[380/525] - total_loss: 0.2584  obj_loss: 0.1586  noobj_loss: 0.1189  bbox_loss: 0.0060  cls_loss: 0.0102  \n",
      "<<<iteration:[400/525] - total_loss: 0.2687  obj_loss: 0.1622  noobj_loss: 0.1196  bbox_loss: 0.0074  cls_loss: 0.0099  \n",
      "<<<iteration:[420/525] - total_loss: 0.2761  obj_loss: 0.1648  noobj_loss: 0.1215  bbox_loss: 0.0069  cls_loss: 0.0160  \n",
      "<<<iteration:[440/525] - total_loss: 0.2793  obj_loss: 0.1623  noobj_loss: 0.1304  bbox_loss: 0.0068  cls_loss: 0.0176  \n",
      "<<<iteration:[460/525] - total_loss: 0.2675  obj_loss: 0.1689  noobj_loss: 0.1106  bbox_loss: 0.0061  cls_loss: 0.0126  \n",
      "<<<iteration:[480/525] - total_loss: 0.2739  obj_loss: 0.1627  noobj_loss: 0.1269  bbox_loss: 0.0079  cls_loss: 0.0081  \n",
      "<<<iteration:[500/525] - total_loss: 0.2858  obj_loss: 0.1823  noobj_loss: 0.1123  bbox_loss: 0.0064  cls_loss: 0.0153  \n",
      "<<<iteration:[520/525] - total_loss: 0.2755  obj_loss: 0.1718  noobj_loss: 0.1266  bbox_loss: 0.0063  cls_loss: 0.0089  \n",
      "\n",
      "epoch:72/100 - Train Loss: 0.2682, Val Loss: 0.2687\n",
      "\n",
      "<<<iteration:[20/525] - total_loss: 0.2634  obj_loss: 0.1460  noobj_loss: 0.1211  bbox_loss: 0.0079  cls_loss: 0.0174  \n",
      "<<<iteration:[40/525] - total_loss: 0.2642  obj_loss: 0.1572  noobj_loss: 0.1204  bbox_loss: 0.0074  cls_loss: 0.0097  \n",
      "<<<iteration:[60/525] - total_loss: 0.2793  obj_loss: 0.1787  noobj_loss: 0.1207  bbox_loss: 0.0062  cls_loss: 0.0093  \n",
      "<<<iteration:[80/525] - total_loss: 0.2613  obj_loss: 0.1572  noobj_loss: 0.1287  bbox_loss: 0.0065  cls_loss: 0.0073  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<<<iteration:[100/525] - total_loss: 0.2675  obj_loss: 0.1672  noobj_loss: 0.1270  bbox_loss: 0.0052  cls_loss: 0.0110  \n",
      "<<<iteration:[120/525] - total_loss: 0.2807  obj_loss: 0.1725  noobj_loss: 0.1226  bbox_loss: 0.0071  cls_loss: 0.0113  \n",
      "<<<iteration:[140/525] - total_loss: 0.2826  obj_loss: 0.1756  noobj_loss: 0.1257  bbox_loss: 0.0067  cls_loss: 0.0106  \n",
      "<<<iteration:[160/525] - total_loss: 0.2618  obj_loss: 0.1506  noobj_loss: 0.1241  bbox_loss: 0.0077  cls_loss: 0.0107  \n",
      "<<<iteration:[180/525] - total_loss: 0.2579  obj_loss: 0.1448  noobj_loss: 0.1271  bbox_loss: 0.0084  cls_loss: 0.0074  \n",
      "<<<iteration:[200/525] - total_loss: 0.2711  obj_loss: 0.1726  noobj_loss: 0.1158  bbox_loss: 0.0052  cls_loss: 0.0146  \n",
      "<<<iteration:[220/525] - total_loss: 0.2588  obj_loss: 0.1567  noobj_loss: 0.1224  bbox_loss: 0.0057  cls_loss: 0.0123  \n",
      "<<<iteration:[240/525] - total_loss: 0.2445  obj_loss: 0.1433  noobj_loss: 0.1210  bbox_loss: 0.0061  cls_loss: 0.0101  \n",
      "<<<iteration:[260/525] - total_loss: 0.3050  obj_loss: 0.1776  noobj_loss: 0.1204  bbox_loss: 0.0073  cls_loss: 0.0308  \n",
      "<<<iteration:[280/525] - total_loss: 0.2829  obj_loss: 0.1755  noobj_loss: 0.1213  bbox_loss: 0.0063  cls_loss: 0.0152  \n",
      "<<<iteration:[300/525] - total_loss: 0.2768  obj_loss: 0.1554  noobj_loss: 0.1305  bbox_loss: 0.0084  cls_loss: 0.0143  \n",
      "<<<iteration:[320/525] - total_loss: 0.2746  obj_loss: 0.1790  noobj_loss: 0.1201  bbox_loss: 0.0054  cls_loss: 0.0084  \n",
      "<<<iteration:[340/525] - total_loss: 0.2545  obj_loss: 0.1438  noobj_loss: 0.1149  bbox_loss: 0.0080  cls_loss: 0.0131  \n",
      "<<<iteration:[360/525] - total_loss: 0.2555  obj_loss: 0.1527  noobj_loss: 0.1195  bbox_loss: 0.0070  cls_loss: 0.0083  \n",
      "<<<iteration:[380/525] - total_loss: 0.2728  obj_loss: 0.1620  noobj_loss: 0.1198  bbox_loss: 0.0065  cls_loss: 0.0182  \n",
      "<<<iteration:[400/525] - total_loss: 0.2802  obj_loss: 0.1729  noobj_loss: 0.1266  bbox_loss: 0.0068  cls_loss: 0.0099  \n",
      "<<<iteration:[420/525] - total_loss: 0.2745  obj_loss: 0.1654  noobj_loss: 0.1244  bbox_loss: 0.0071  cls_loss: 0.0113  \n",
      "<<<iteration:[440/525] - total_loss: 0.2664  obj_loss: 0.1734  noobj_loss: 0.1176  bbox_loss: 0.0055  cls_loss: 0.0068  \n",
      "<<<iteration:[460/525] - total_loss: 0.2587  obj_loss: 0.1545  noobj_loss: 0.1150  bbox_loss: 0.0065  cls_loss: 0.0144  \n",
      "<<<iteration:[480/525] - total_loss: 0.2630  obj_loss: 0.1616  noobj_loss: 0.1285  bbox_loss: 0.0061  cls_loss: 0.0068  \n",
      "<<<iteration:[500/525] - total_loss: 0.2750  obj_loss: 0.1598  noobj_loss: 0.1248  bbox_loss: 0.0083  cls_loss: 0.0112  \n",
      "<<<iteration:[520/525] - total_loss: 0.2704  obj_loss: 0.1661  noobj_loss: 0.1264  bbox_loss: 0.0061  cls_loss: 0.0106  \n",
      "\n",
      "epoch:73/100 - Train Loss: 0.2685, Val Loss: 0.2746\n",
      "\n",
      "<<<iteration:[20/525] - total_loss: 0.2726  obj_loss: 0.1515  noobj_loss: 0.1201  bbox_loss: 0.0072  cls_loss: 0.0249  \n",
      "<<<iteration:[40/525] - total_loss: 0.2441  obj_loss: 0.1471  noobj_loss: 0.1166  bbox_loss: 0.0062  cls_loss: 0.0077  \n",
      "<<<iteration:[60/525] - total_loss: 0.2819  obj_loss: 0.1644  noobj_loss: 0.1244  bbox_loss: 0.0064  cls_loss: 0.0231  \n",
      "<<<iteration:[80/525] - total_loss: 0.2711  obj_loss: 0.1679  noobj_loss: 0.1210  bbox_loss: 0.0066  cls_loss: 0.0094  \n",
      "<<<iteration:[100/525] - total_loss: 0.2649  obj_loss: 0.1606  noobj_loss: 0.1180  bbox_loss: 0.0070  cls_loss: 0.0102  \n",
      "<<<iteration:[120/525] - total_loss: 0.2758  obj_loss: 0.1708  noobj_loss: 0.1291  bbox_loss: 0.0061  cls_loss: 0.0102  \n",
      "<<<iteration:[140/525] - total_loss: 0.2854  obj_loss: 0.1752  noobj_loss: 0.1300  bbox_loss: 0.0061  cls_loss: 0.0145  \n",
      "<<<iteration:[160/525] - total_loss: 0.2692  obj_loss: 0.1618  noobj_loss: 0.1285  bbox_loss: 0.0061  cls_loss: 0.0125  \n",
      "<<<iteration:[180/525] - total_loss: 0.2749  obj_loss: 0.1697  noobj_loss: 0.1262  bbox_loss: 0.0061  cls_loss: 0.0114  \n",
      "<<<iteration:[200/525] - total_loss: 0.2656  obj_loss: 0.1539  noobj_loss: 0.1283  bbox_loss: 0.0070  cls_loss: 0.0128  \n",
      "<<<iteration:[220/525] - total_loss: 0.2640  obj_loss: 0.1566  noobj_loss: 0.1187  bbox_loss: 0.0068  cls_loss: 0.0140  \n",
      "<<<iteration:[240/525] - total_loss: 0.2619  obj_loss: 0.1626  noobj_loss: 0.1215  bbox_loss: 0.0055  cls_loss: 0.0108  \n",
      "<<<iteration:[260/525] - total_loss: 0.2785  obj_loss: 0.1561  noobj_loss: 0.1220  bbox_loss: 0.0071  cls_loss: 0.0262  \n",
      "<<<iteration:[280/525] - total_loss: 0.2727  obj_loss: 0.1700  noobj_loss: 0.1170  bbox_loss: 0.0068  cls_loss: 0.0101  \n",
      "<<<iteration:[300/525] - total_loss: 0.2667  obj_loss: 0.1513  noobj_loss: 0.1196  bbox_loss: 0.0077  cls_loss: 0.0172  \n",
      "<<<iteration:[320/525] - total_loss: 0.2757  obj_loss: 0.1742  noobj_loss: 0.1204  bbox_loss: 0.0057  cls_loss: 0.0129  \n",
      "<<<iteration:[340/525] - total_loss: 0.2831  obj_loss: 0.1742  noobj_loss: 0.1316  bbox_loss: 0.0060  cls_loss: 0.0132  \n",
      "<<<iteration:[360/525] - total_loss: 0.2628  obj_loss: 0.1576  noobj_loss: 0.1283  bbox_loss: 0.0062  cls_loss: 0.0101  \n",
      "<<<iteration:[380/525] - total_loss: 0.2772  obj_loss: 0.1637  noobj_loss: 0.1349  bbox_loss: 0.0063  cls_loss: 0.0146  \n",
      "<<<iteration:[400/525] - total_loss: 0.2639  obj_loss: 0.1595  noobj_loss: 0.1320  bbox_loss: 0.0059  cls_loss: 0.0088  \n",
      "<<<iteration:[420/525] - total_loss: 0.2603  obj_loss: 0.1596  noobj_loss: 0.1138  bbox_loss: 0.0064  cls_loss: 0.0120  \n",
      "<<<iteration:[440/525] - total_loss: 0.2628  obj_loss: 0.1571  noobj_loss: 0.1193  bbox_loss: 0.0069  cls_loss: 0.0115  \n",
      "<<<iteration:[460/525] - total_loss: 0.2603  obj_loss: 0.1618  noobj_loss: 0.1284  bbox_loss: 0.0052  cls_loss: 0.0080  \n",
      "<<<iteration:[480/525] - total_loss: 0.2776  obj_loss: 0.1655  noobj_loss: 0.1273  bbox_loss: 0.0075  cls_loss: 0.0112  \n",
      "<<<iteration:[500/525] - total_loss: 0.2617  obj_loss: 0.1594  noobj_loss: 0.1262  bbox_loss: 0.0060  cls_loss: 0.0094  \n",
      "<<<iteration:[520/525] - total_loss: 0.2662  obj_loss: 0.1644  noobj_loss: 0.1301  bbox_loss: 0.0057  cls_loss: 0.0082  \n",
      "\n",
      "epoch:74/100 - Train Loss: 0.2689, Val Loss: 0.2712\n",
      "\n",
      "<<<iteration:[20/525] - total_loss: 0.2848  obj_loss: 0.1665  noobj_loss: 0.1416  bbox_loss: 0.0074  cls_loss: 0.0108  \n",
      "<<<iteration:[40/525] - total_loss: 0.2576  obj_loss: 0.1558  noobj_loss: 0.1166  bbox_loss: 0.0067  cls_loss: 0.0098  \n",
      "<<<iteration:[60/525] - total_loss: 0.2512  obj_loss: 0.1522  noobj_loss: 0.1226  bbox_loss: 0.0060  cls_loss: 0.0078  \n",
      "<<<iteration:[80/525] - total_loss: 0.2832  obj_loss: 0.1756  noobj_loss: 0.1273  bbox_loss: 0.0057  cls_loss: 0.0155  \n",
      "<<<iteration:[100/525] - total_loss: 0.2562  obj_loss: 0.1471  noobj_loss: 0.1240  bbox_loss: 0.0071  cls_loss: 0.0117  \n",
      "<<<iteration:[120/525] - total_loss: 0.3002  obj_loss: 0.1893  noobj_loss: 0.1264  bbox_loss: 0.0065  cls_loss: 0.0150  \n",
      "<<<iteration:[140/525] - total_loss: 0.2807  obj_loss: 0.1653  noobj_loss: 0.1359  bbox_loss: 0.0059  cls_loss: 0.0178  \n",
      "<<<iteration:[160/525] - total_loss: 0.2568  obj_loss: 0.1547  noobj_loss: 0.1236  bbox_loss: 0.0063  cls_loss: 0.0088  \n",
      "<<<iteration:[180/525] - total_loss: 0.2762  obj_loss: 0.1707  noobj_loss: 0.1273  bbox_loss: 0.0062  cls_loss: 0.0109  \n",
      "<<<iteration:[200/525] - total_loss: 0.2833  obj_loss: 0.1676  noobj_loss: 0.1192  bbox_loss: 0.0089  cls_loss: 0.0115  \n",
      "<<<iteration:[220/525] - total_loss: 0.2654  obj_loss: 0.1643  noobj_loss: 0.1261  bbox_loss: 0.0061  cls_loss: 0.0075  \n",
      "<<<iteration:[240/525] - total_loss: 0.2909  obj_loss: 0.1699  noobj_loss: 0.1177  bbox_loss: 0.0076  cls_loss: 0.0240  \n",
      "<<<iteration:[260/525] - total_loss: 0.2677  obj_loss: 0.1636  noobj_loss: 0.1290  bbox_loss: 0.0058  cls_loss: 0.0105  \n",
      "<<<iteration:[280/525] - total_loss: 0.2361  obj_loss: 0.1330  noobj_loss: 0.1301  bbox_loss: 0.0061  cls_loss: 0.0073  \n",
      "<<<iteration:[300/525] - total_loss: 0.2696  obj_loss: 0.1548  noobj_loss: 0.1272  bbox_loss: 0.0082  cls_loss: 0.0100  \n",
      "<<<iteration:[320/525] - total_loss: 0.2735  obj_loss: 0.1507  noobj_loss: 0.1247  bbox_loss: 0.0075  cls_loss: 0.0230  \n",
      "<<<iteration:[340/525] - total_loss: 0.2542  obj_loss: 0.1592  noobj_loss: 0.1185  bbox_loss: 0.0056  cls_loss: 0.0076  \n",
      "<<<iteration:[360/525] - total_loss: 0.2809  obj_loss: 0.1833  noobj_loss: 0.1219  bbox_loss: 0.0061  cls_loss: 0.0061  \n",
      "<<<iteration:[380/525] - total_loss: 0.2559  obj_loss: 0.1563  noobj_loss: 0.1247  bbox_loss: 0.0060  cls_loss: 0.0075  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<<<iteration:[400/525] - total_loss: 0.2642  obj_loss: 0.1655  noobj_loss: 0.1284  bbox_loss: 0.0052  cls_loss: 0.0087  \n",
      "<<<iteration:[420/525] - total_loss: 0.2670  obj_loss: 0.1584  noobj_loss: 0.1268  bbox_loss: 0.0068  cls_loss: 0.0111  \n",
      "<<<iteration:[440/525] - total_loss: 0.2690  obj_loss: 0.1640  noobj_loss: 0.1248  bbox_loss: 0.0067  cls_loss: 0.0092  \n",
      "<<<iteration:[460/525] - total_loss: 0.2550  obj_loss: 0.1476  noobj_loss: 0.1206  bbox_loss: 0.0075  cls_loss: 0.0098  \n",
      "<<<iteration:[480/525] - total_loss: 0.2514  obj_loss: 0.1530  noobj_loss: 0.1185  bbox_loss: 0.0062  cls_loss: 0.0082  \n",
      "<<<iteration:[500/525] - total_loss: 0.2760  obj_loss: 0.1727  noobj_loss: 0.1262  bbox_loss: 0.0060  cls_loss: 0.0102  \n",
      "<<<iteration:[520/525] - total_loss: 0.2720  obj_loss: 0.1724  noobj_loss: 0.1179  bbox_loss: 0.0061  cls_loss: 0.0099  \n",
      "\n",
      "epoch:75/100 - Train Loss: 0.2681, Val Loss: 0.2705\n",
      "\n",
      "<<<iteration:[20/525] - total_loss: 0.2783  obj_loss: 0.1669  noobj_loss: 0.1330  bbox_loss: 0.0071  cls_loss: 0.0093  \n",
      "<<<iteration:[40/525] - total_loss: 0.2506  obj_loss: 0.1566  noobj_loss: 0.1178  bbox_loss: 0.0057  cls_loss: 0.0068  \n",
      "<<<iteration:[60/525] - total_loss: 0.2700  obj_loss: 0.1675  noobj_loss: 0.1253  bbox_loss: 0.0065  cls_loss: 0.0074  \n",
      "<<<iteration:[80/525] - total_loss: 0.2592  obj_loss: 0.1574  noobj_loss: 0.1230  bbox_loss: 0.0060  cls_loss: 0.0104  \n",
      "<<<iteration:[100/525] - total_loss: 0.2862  obj_loss: 0.1751  noobj_loss: 0.1310  bbox_loss: 0.0068  cls_loss: 0.0114  \n",
      "<<<iteration:[120/525] - total_loss: 0.2759  obj_loss: 0.1687  noobj_loss: 0.1244  bbox_loss: 0.0064  cls_loss: 0.0131  \n",
      "<<<iteration:[140/525] - total_loss: 0.2889  obj_loss: 0.1712  noobj_loss: 0.1230  bbox_loss: 0.0064  cls_loss: 0.0240  \n",
      "<<<iteration:[160/525] - total_loss: 0.2533  obj_loss: 0.1540  noobj_loss: 0.1214  bbox_loss: 0.0057  cls_loss: 0.0101  \n",
      "<<<iteration:[180/525] - total_loss: 0.2576  obj_loss: 0.1624  noobj_loss: 0.1225  bbox_loss: 0.0054  cls_loss: 0.0072  \n",
      "<<<iteration:[200/525] - total_loss: 0.2663  obj_loss: 0.1558  noobj_loss: 0.1159  bbox_loss: 0.0068  cls_loss: 0.0188  \n",
      "<<<iteration:[220/525] - total_loss: 0.2587  obj_loss: 0.1481  noobj_loss: 0.1330  bbox_loss: 0.0056  cls_loss: 0.0159  \n",
      "<<<iteration:[240/525] - total_loss: 0.2634  obj_loss: 0.1588  noobj_loss: 0.1219  bbox_loss: 0.0063  cls_loss: 0.0120  \n",
      "<<<iteration:[260/525] - total_loss: 0.2798  obj_loss: 0.1686  noobj_loss: 0.1347  bbox_loss: 0.0059  cls_loss: 0.0146  \n",
      "<<<iteration:[280/525] - total_loss: 0.2500  obj_loss: 0.1467  noobj_loss: 0.1349  bbox_loss: 0.0056  cls_loss: 0.0076  \n",
      "<<<iteration:[300/525] - total_loss: 0.2642  obj_loss: 0.1604  noobj_loss: 0.1216  bbox_loss: 0.0070  cls_loss: 0.0081  \n",
      "<<<iteration:[320/525] - total_loss: 0.2650  obj_loss: 0.1584  noobj_loss: 0.1300  bbox_loss: 0.0067  cls_loss: 0.0083  \n",
      "<<<iteration:[340/525] - total_loss: 0.2710  obj_loss: 0.1728  noobj_loss: 0.1204  bbox_loss: 0.0063  cls_loss: 0.0068  \n",
      "<<<iteration:[360/525] - total_loss: 0.2592  obj_loss: 0.1530  noobj_loss: 0.1243  bbox_loss: 0.0064  cls_loss: 0.0119  \n",
      "<<<iteration:[380/525] - total_loss: 0.2518  obj_loss: 0.1525  noobj_loss: 0.1228  bbox_loss: 0.0060  cls_loss: 0.0076  \n",
      "<<<iteration:[400/525] - total_loss: 0.2917  obj_loss: 0.1708  noobj_loss: 0.1391  bbox_loss: 0.0077  cls_loss: 0.0130  \n",
      "<<<iteration:[420/525] - total_loss: 0.2705  obj_loss: 0.1611  noobj_loss: 0.1279  bbox_loss: 0.0066  cls_loss: 0.0124  \n",
      "<<<iteration:[440/525] - total_loss: 0.2711  obj_loss: 0.1638  noobj_loss: 0.1261  bbox_loss: 0.0067  cls_loss: 0.0108  \n",
      "<<<iteration:[460/525] - total_loss: 0.2670  obj_loss: 0.1600  noobj_loss: 0.1345  bbox_loss: 0.0058  cls_loss: 0.0110  \n",
      "<<<iteration:[480/525] - total_loss: 0.2500  obj_loss: 0.1542  noobj_loss: 0.1213  bbox_loss: 0.0053  cls_loss: 0.0089  \n",
      "<<<iteration:[500/525] - total_loss: 0.2506  obj_loss: 0.1424  noobj_loss: 0.1227  bbox_loss: 0.0066  cls_loss: 0.0140  \n",
      "<<<iteration:[520/525] - total_loss: 0.2789  obj_loss: 0.1637  noobj_loss: 0.1209  bbox_loss: 0.0081  cls_loss: 0.0143  \n",
      "\n",
      "epoch:76/100 - Train Loss: 0.2659, Val Loss: 0.2707\n",
      "\n",
      "<<<iteration:[20/525] - total_loss: 0.2901  obj_loss: 0.1722  noobj_loss: 0.1440  bbox_loss: 0.0071  cls_loss: 0.0106  \n",
      "<<<iteration:[40/525] - total_loss: 0.2692  obj_loss: 0.1684  noobj_loss: 0.1189  bbox_loss: 0.0065  cls_loss: 0.0090  \n",
      "<<<iteration:[60/525] - total_loss: 0.2610  obj_loss: 0.1669  noobj_loss: 0.1251  bbox_loss: 0.0051  cls_loss: 0.0060  \n",
      "<<<iteration:[80/525] - total_loss: 0.2909  obj_loss: 0.1729  noobj_loss: 0.1285  bbox_loss: 0.0083  cls_loss: 0.0123  \n",
      "<<<iteration:[100/525] - total_loss: 0.2673  obj_loss: 0.1631  noobj_loss: 0.1218  bbox_loss: 0.0065  cls_loss: 0.0106  \n",
      "<<<iteration:[120/525] - total_loss: 0.2689  obj_loss: 0.1649  noobj_loss: 0.1251  bbox_loss: 0.0067  cls_loss: 0.0081  \n",
      "<<<iteration:[140/525] - total_loss: 0.2684  obj_loss: 0.1565  noobj_loss: 0.1188  bbox_loss: 0.0083  cls_loss: 0.0108  \n",
      "<<<iteration:[160/525] - total_loss: 0.2558  obj_loss: 0.1555  noobj_loss: 0.1205  bbox_loss: 0.0059  cls_loss: 0.0107  \n",
      "<<<iteration:[180/525] - total_loss: 0.2436  obj_loss: 0.1345  noobj_loss: 0.1372  bbox_loss: 0.0062  cls_loss: 0.0093  \n",
      "<<<iteration:[200/525] - total_loss: 0.2500  obj_loss: 0.1474  noobj_loss: 0.1243  bbox_loss: 0.0066  cls_loss: 0.0075  \n",
      "<<<iteration:[220/525] - total_loss: 0.2780  obj_loss: 0.1767  noobj_loss: 0.1228  bbox_loss: 0.0062  cls_loss: 0.0089  \n",
      "<<<iteration:[240/525] - total_loss: 0.2811  obj_loss: 0.1600  noobj_loss: 0.1266  bbox_loss: 0.0067  cls_loss: 0.0241  \n",
      "<<<iteration:[260/525] - total_loss: 0.2883  obj_loss: 0.1779  noobj_loss: 0.1380  bbox_loss: 0.0057  cls_loss: 0.0129  \n",
      "<<<iteration:[280/525] - total_loss: 0.2550  obj_loss: 0.1585  noobj_loss: 0.1192  bbox_loss: 0.0054  cls_loss: 0.0099  \n",
      "<<<iteration:[300/525] - total_loss: 0.2502  obj_loss: 0.1403  noobj_loss: 0.1309  bbox_loss: 0.0074  cls_loss: 0.0076  \n",
      "<<<iteration:[320/525] - total_loss: 0.2820  obj_loss: 0.1702  noobj_loss: 0.1245  bbox_loss: 0.0069  cls_loss: 0.0152  \n",
      "<<<iteration:[340/525] - total_loss: 0.2573  obj_loss: 0.1530  noobj_loss: 0.1227  bbox_loss: 0.0068  cls_loss: 0.0088  \n",
      "<<<iteration:[360/525] - total_loss: 0.2879  obj_loss: 0.1773  noobj_loss: 0.1190  bbox_loss: 0.0068  cls_loss: 0.0170  \n",
      "<<<iteration:[380/525] - total_loss: 0.2686  obj_loss: 0.1658  noobj_loss: 0.1277  bbox_loss: 0.0064  cls_loss: 0.0069  \n",
      "<<<iteration:[400/525] - total_loss: 0.2515  obj_loss: 0.1457  noobj_loss: 0.1240  bbox_loss: 0.0066  cls_loss: 0.0107  \n",
      "<<<iteration:[420/525] - total_loss: 0.2712  obj_loss: 0.1635  noobj_loss: 0.1328  bbox_loss: 0.0060  cls_loss: 0.0115  \n",
      "<<<iteration:[440/525] - total_loss: 0.2493  obj_loss: 0.1544  noobj_loss: 0.1172  bbox_loss: 0.0060  cls_loss: 0.0063  \n",
      "<<<iteration:[460/525] - total_loss: 0.2979  obj_loss: 0.1478  noobj_loss: 0.1275  bbox_loss: 0.0105  cls_loss: 0.0339  \n",
      "<<<iteration:[480/525] - total_loss: 0.2674  obj_loss: 0.1673  noobj_loss: 0.1197  bbox_loss: 0.0058  cls_loss: 0.0111  \n",
      "<<<iteration:[500/525] - total_loss: 0.2562  obj_loss: 0.1555  noobj_loss: 0.1220  bbox_loss: 0.0061  cls_loss: 0.0093  \n",
      "<<<iteration:[520/525] - total_loss: 0.2651  obj_loss: 0.1547  noobj_loss: 0.1203  bbox_loss: 0.0066  cls_loss: 0.0173  \n",
      "\n",
      "epoch:77/100 - Train Loss: 0.2680, Val Loss: 0.2696\n",
      "\n",
      "<<<iteration:[20/525] - total_loss: 0.2814  obj_loss: 0.1690  noobj_loss: 0.1327  bbox_loss: 0.0066  cls_loss: 0.0132  \n",
      "<<<iteration:[40/525] - total_loss: 0.2724  obj_loss: 0.1651  noobj_loss: 0.1258  bbox_loss: 0.0060  cls_loss: 0.0143  \n",
      "<<<iteration:[60/525] - total_loss: 0.2661  obj_loss: 0.1591  noobj_loss: 0.1301  bbox_loss: 0.0065  cls_loss: 0.0097  \n",
      "<<<iteration:[80/525] - total_loss: 0.2817  obj_loss: 0.1636  noobj_loss: 0.1204  bbox_loss: 0.0067  cls_loss: 0.0243  \n",
      "<<<iteration:[100/525] - total_loss: 0.2616  obj_loss: 0.1654  noobj_loss: 0.1272  bbox_loss: 0.0051  cls_loss: 0.0069  \n",
      "<<<iteration:[120/525] - total_loss: 0.2762  obj_loss: 0.1644  noobj_loss: 0.1288  bbox_loss: 0.0060  cls_loss: 0.0175  \n",
      "<<<iteration:[140/525] - total_loss: 0.2976  obj_loss: 0.1694  noobj_loss: 0.1375  bbox_loss: 0.0075  cls_loss: 0.0219  \n",
      "<<<iteration:[160/525] - total_loss: 0.2486  obj_loss: 0.1502  noobj_loss: 0.1203  bbox_loss: 0.0057  cls_loss: 0.0098  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<<<iteration:[180/525] - total_loss: 0.2718  obj_loss: 0.1660  noobj_loss: 0.1292  bbox_loss: 0.0058  cls_loss: 0.0123  \n",
      "<<<iteration:[200/525] - total_loss: 0.2506  obj_loss: 0.1550  noobj_loss: 0.1110  bbox_loss: 0.0059  cls_loss: 0.0105  \n",
      "<<<iteration:[220/525] - total_loss: 0.2528  obj_loss: 0.1466  noobj_loss: 0.1179  bbox_loss: 0.0065  cls_loss: 0.0146  \n",
      "<<<iteration:[240/525] - total_loss: 0.2698  obj_loss: 0.1683  noobj_loss: 0.1260  bbox_loss: 0.0053  cls_loss: 0.0122  \n",
      "<<<iteration:[260/525] - total_loss: 0.2705  obj_loss: 0.1622  noobj_loss: 0.1283  bbox_loss: 0.0065  cls_loss: 0.0116  \n",
      "<<<iteration:[280/525] - total_loss: 0.4080  obj_loss: 0.1087  noobj_loss: 0.1097  bbox_loss: 0.0452  cls_loss: 0.0187  \n",
      "<<<iteration:[300/525] - total_loss: 0.5235  obj_loss: 0.0941  noobj_loss: 0.1031  bbox_loss: 0.0714  cls_loss: 0.0207  \n",
      "<<<iteration:[320/525] - total_loss: 0.4834  obj_loss: 0.0860  noobj_loss: 0.1172  bbox_loss: 0.0610  cls_loss: 0.0338  \n",
      "<<<iteration:[340/525] - total_loss: 0.4808  obj_loss: 0.0912  noobj_loss: 0.1003  bbox_loss: 0.0621  cls_loss: 0.0289  \n",
      "<<<iteration:[360/525] - total_loss: 0.4483  obj_loss: 0.0781  noobj_loss: 0.1001  bbox_loss: 0.0583  cls_loss: 0.0288  \n",
      "<<<iteration:[380/525] - total_loss: 0.3466  obj_loss: 0.0964  noobj_loss: 0.1035  bbox_loss: 0.0325  cls_loss: 0.0360  \n",
      "<<<iteration:[400/525] - total_loss: 0.2846  obj_loss: 0.1014  noobj_loss: 0.1043  bbox_loss: 0.0207  cls_loss: 0.0274  \n",
      "<<<iteration:[420/525] - total_loss: 0.2903  obj_loss: 0.1064  noobj_loss: 0.1034  bbox_loss: 0.0164  cls_loss: 0.0502  \n",
      "<<<iteration:[440/525] - total_loss: 0.3429  obj_loss: 0.1231  noobj_loss: 0.0982  bbox_loss: 0.0283  cls_loss: 0.0294  \n",
      "<<<iteration:[460/525] - total_loss: 0.2528  obj_loss: 0.0995  noobj_loss: 0.0953  bbox_loss: 0.0166  cls_loss: 0.0229  \n",
      "<<<iteration:[480/525] - total_loss: 0.2726  obj_loss: 0.1004  noobj_loss: 0.0962  bbox_loss: 0.0188  cls_loss: 0.0302  \n",
      "<<<iteration:[500/525] - total_loss: 0.2548  obj_loss: 0.1067  noobj_loss: 0.0963  bbox_loss: 0.0161  cls_loss: 0.0195  \n",
      "<<<iteration:[520/525] - total_loss: 0.2600  obj_loss: 0.1126  noobj_loss: 0.0838  bbox_loss: 0.0173  cls_loss: 0.0191  \n",
      "\n",
      "epoch:78/100 - Train Loss: 0.3139, Val Loss: 0.2484\n",
      "\n",
      "<<<iteration:[20/525] - total_loss: 0.2765  obj_loss: 0.1295  noobj_loss: 0.0999  bbox_loss: 0.0149  cls_loss: 0.0227  \n",
      "<<<iteration:[40/525] - total_loss: 0.2638  obj_loss: 0.1237  noobj_loss: 0.0968  bbox_loss: 0.0125  cls_loss: 0.0294  \n",
      "<<<iteration:[60/525] - total_loss: 0.2588  obj_loss: 0.1092  noobj_loss: 0.0972  bbox_loss: 0.0163  cls_loss: 0.0195  \n",
      "<<<iteration:[80/525] - total_loss: 0.2507  obj_loss: 0.1222  noobj_loss: 0.0916  bbox_loss: 0.0122  cls_loss: 0.0219  \n",
      "<<<iteration:[100/525] - total_loss: 0.2493  obj_loss: 0.1322  noobj_loss: 0.0957  bbox_loss: 0.0098  cls_loss: 0.0200  \n",
      "<<<iteration:[120/525] - total_loss: 0.2451  obj_loss: 0.1208  noobj_loss: 0.0987  bbox_loss: 0.0104  cls_loss: 0.0229  \n",
      "<<<iteration:[140/525] - total_loss: 0.2539  obj_loss: 0.1227  noobj_loss: 0.0956  bbox_loss: 0.0135  cls_loss: 0.0160  \n",
      "<<<iteration:[160/525] - total_loss: 0.2492  obj_loss: 0.1255  noobj_loss: 0.1039  bbox_loss: 0.0108  cls_loss: 0.0178  \n",
      "<<<iteration:[180/525] - total_loss: 0.2745  obj_loss: 0.1090  noobj_loss: 0.1135  bbox_loss: 0.0152  cls_loss: 0.0329  \n",
      "<<<iteration:[200/525] - total_loss: 0.2606  obj_loss: 0.1358  noobj_loss: 0.0990  bbox_loss: 0.0106  cls_loss: 0.0222  \n",
      "<<<iteration:[220/525] - total_loss: 0.2597  obj_loss: 0.1404  noobj_loss: 0.0944  bbox_loss: 0.0111  cls_loss: 0.0168  \n",
      "<<<iteration:[240/525] - total_loss: 0.2305  obj_loss: 0.1094  noobj_loss: 0.1031  bbox_loss: 0.0099  cls_loss: 0.0198  \n",
      "<<<iteration:[260/525] - total_loss: 0.2757  obj_loss: 0.1369  noobj_loss: 0.1147  bbox_loss: 0.0130  cls_loss: 0.0165  \n",
      "<<<iteration:[280/525] - total_loss: 0.2610  obj_loss: 0.1234  noobj_loss: 0.0961  bbox_loss: 0.0140  cls_loss: 0.0193  \n",
      "<<<iteration:[300/525] - total_loss: 0.2399  obj_loss: 0.1300  noobj_loss: 0.0977  bbox_loss: 0.0089  cls_loss: 0.0166  \n",
      "<<<iteration:[320/525] - total_loss: 0.2367  obj_loss: 0.1242  noobj_loss: 0.1025  bbox_loss: 0.0086  cls_loss: 0.0184  \n",
      "<<<iteration:[340/525] - total_loss: 0.2604  obj_loss: 0.1532  noobj_loss: 0.1082  bbox_loss: 0.0075  cls_loss: 0.0155  \n",
      "<<<iteration:[360/525] - total_loss: 0.2639  obj_loss: 0.1353  noobj_loss: 0.0977  bbox_loss: 0.0121  cls_loss: 0.0191  \n",
      "<<<iteration:[380/525] - total_loss: 0.2668  obj_loss: 0.1521  noobj_loss: 0.1016  bbox_loss: 0.0100  cls_loss: 0.0139  \n",
      "<<<iteration:[400/525] - total_loss: 0.2405  obj_loss: 0.1314  noobj_loss: 0.0944  bbox_loss: 0.0089  cls_loss: 0.0176  \n",
      "<<<iteration:[420/525] - total_loss: 0.2451  obj_loss: 0.1450  noobj_loss: 0.0924  bbox_loss: 0.0075  cls_loss: 0.0163  \n",
      "<<<iteration:[440/525] - total_loss: 0.2309  obj_loss: 0.1146  noobj_loss: 0.1055  bbox_loss: 0.0093  cls_loss: 0.0169  \n",
      "<<<iteration:[460/525] - total_loss: 0.2417  obj_loss: 0.1297  noobj_loss: 0.0970  bbox_loss: 0.0104  cls_loss: 0.0117  \n",
      "<<<iteration:[480/525] - total_loss: 0.2219  obj_loss: 0.1211  noobj_loss: 0.0946  bbox_loss: 0.0078  cls_loss: 0.0146  \n",
      "<<<iteration:[500/525] - total_loss: 0.2493  obj_loss: 0.1235  noobj_loss: 0.0962  bbox_loss: 0.0118  cls_loss: 0.0186  \n",
      "<<<iteration:[520/525] - total_loss: 0.2621  obj_loss: 0.1431  noobj_loss: 0.1006  bbox_loss: 0.0100  cls_loss: 0.0186  \n",
      "\n",
      "epoch:79/100 - Train Loss: 0.2522, Val Loss: 0.2533\n",
      "\n",
      "<<<iteration:[20/525] - total_loss: 0.2410  obj_loss: 0.1300  noobj_loss: 0.0987  bbox_loss: 0.0100  cls_loss: 0.0119  \n",
      "<<<iteration:[40/525] - total_loss: 0.2416  obj_loss: 0.1404  noobj_loss: 0.1032  bbox_loss: 0.0070  cls_loss: 0.0148  \n",
      "<<<iteration:[60/525] - total_loss: 0.2397  obj_loss: 0.1334  noobj_loss: 0.1003  bbox_loss: 0.0091  cls_loss: 0.0107  \n",
      "<<<iteration:[80/525] - total_loss: 0.2594  obj_loss: 0.1551  noobj_loss: 0.1100  bbox_loss: 0.0077  cls_loss: 0.0106  \n",
      "<<<iteration:[100/525] - total_loss: 0.2321  obj_loss: 0.1291  noobj_loss: 0.1030  bbox_loss: 0.0082  cls_loss: 0.0104  \n",
      "<<<iteration:[120/525] - total_loss: 0.2418  obj_loss: 0.1302  noobj_loss: 0.1093  bbox_loss: 0.0095  cls_loss: 0.0094  \n",
      "<<<iteration:[140/525] - total_loss: 0.2435  obj_loss: 0.1342  noobj_loss: 0.1000  bbox_loss: 0.0099  cls_loss: 0.0096  \n",
      "<<<iteration:[160/525] - total_loss: 0.2396  obj_loss: 0.1320  noobj_loss: 0.0986  bbox_loss: 0.0090  cls_loss: 0.0133  \n",
      "<<<iteration:[180/525] - total_loss: 0.2643  obj_loss: 0.1466  noobj_loss: 0.1063  bbox_loss: 0.0086  cls_loss: 0.0217  \n",
      "<<<iteration:[200/525] - total_loss: 0.2613  obj_loss: 0.1283  noobj_loss: 0.1090  bbox_loss: 0.0112  cls_loss: 0.0225  \n",
      "<<<iteration:[220/525] - total_loss: 0.2437  obj_loss: 0.1406  noobj_loss: 0.1055  bbox_loss: 0.0082  cls_loss: 0.0093  \n",
      "<<<iteration:[240/525] - total_loss: 0.2481  obj_loss: 0.1423  noobj_loss: 0.1089  bbox_loss: 0.0079  cls_loss: 0.0121  \n",
      "<<<iteration:[260/525] - total_loss: 0.2552  obj_loss: 0.1401  noobj_loss: 0.1046  bbox_loss: 0.0089  cls_loss: 0.0182  \n",
      "<<<iteration:[280/525] - total_loss: 0.2615  obj_loss: 0.1445  noobj_loss: 0.1125  bbox_loss: 0.0082  cls_loss: 0.0195  \n",
      "<<<iteration:[300/525] - total_loss: 0.2438  obj_loss: 0.1455  noobj_loss: 0.1039  bbox_loss: 0.0072  cls_loss: 0.0104  \n",
      "<<<iteration:[320/525] - total_loss: 0.2412  obj_loss: 0.1315  noobj_loss: 0.1087  bbox_loss: 0.0090  cls_loss: 0.0102  \n",
      "<<<iteration:[340/525] - total_loss: 0.2485  obj_loss: 0.1447  noobj_loss: 0.1034  bbox_loss: 0.0076  cls_loss: 0.0141  \n",
      "<<<iteration:[360/525] - total_loss: 0.2439  obj_loss: 0.1253  noobj_loss: 0.0939  bbox_loss: 0.0094  cls_loss: 0.0246  \n",
      "<<<iteration:[380/525] - total_loss: 0.2624  obj_loss: 0.1640  noobj_loss: 0.1110  bbox_loss: 0.0060  cls_loss: 0.0128  \n",
      "<<<iteration:[400/525] - total_loss: 0.2426  obj_loss: 0.1370  noobj_loss: 0.1144  bbox_loss: 0.0070  cls_loss: 0.0135  \n",
      "<<<iteration:[420/525] - total_loss: 0.2641  obj_loss: 0.1555  noobj_loss: 0.1230  bbox_loss: 0.0072  cls_loss: 0.0109  \n",
      "<<<iteration:[440/525] - total_loss: 0.2632  obj_loss: 0.1510  noobj_loss: 0.1117  bbox_loss: 0.0086  cls_loss: 0.0131  \n",
      "<<<iteration:[460/525] - total_loss: 0.2440  obj_loss: 0.1405  noobj_loss: 0.1128  bbox_loss: 0.0074  cls_loss: 0.0100  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<<<iteration:[480/525] - total_loss: 0.2590  obj_loss: 0.1534  noobj_loss: 0.1034  bbox_loss: 0.0081  cls_loss: 0.0135  \n",
      "<<<iteration:[500/525] - total_loss: 0.2545  obj_loss: 0.1405  noobj_loss: 0.1094  bbox_loss: 0.0076  cls_loss: 0.0215  \n",
      "<<<iteration:[520/525] - total_loss: 0.2557  obj_loss: 0.1427  noobj_loss: 0.0988  bbox_loss: 0.0095  cls_loss: 0.0163  \n",
      "\n",
      "epoch:80/100 - Train Loss: 0.2493, Val Loss: 0.2578\n",
      "\n",
      "<<<iteration:[20/525] - total_loss: 0.2733  obj_loss: 0.1552  noobj_loss: 0.1159  bbox_loss: 0.0074  cls_loss: 0.0232  \n",
      "<<<iteration:[40/525] - total_loss: 0.2289  obj_loss: 0.1144  noobj_loss: 0.1034  bbox_loss: 0.0105  cls_loss: 0.0103  \n",
      "<<<iteration:[60/525] - total_loss: 0.2365  obj_loss: 0.1344  noobj_loss: 0.1139  bbox_loss: 0.0068  cls_loss: 0.0111  \n",
      "<<<iteration:[80/525] - total_loss: 0.2740  obj_loss: 0.1688  noobj_loss: 0.1113  bbox_loss: 0.0079  cls_loss: 0.0099  \n",
      "<<<iteration:[100/525] - total_loss: 0.2369  obj_loss: 0.1338  noobj_loss: 0.1048  bbox_loss: 0.0082  cls_loss: 0.0098  \n",
      "<<<iteration:[120/525] - total_loss: 0.2582  obj_loss: 0.1454  noobj_loss: 0.1090  bbox_loss: 0.0079  cls_loss: 0.0187  \n",
      "<<<iteration:[140/525] - total_loss: 0.2547  obj_loss: 0.1411  noobj_loss: 0.1095  bbox_loss: 0.0079  cls_loss: 0.0195  \n",
      "<<<iteration:[160/525] - total_loss: 0.2535  obj_loss: 0.1466  noobj_loss: 0.1067  bbox_loss: 0.0083  cls_loss: 0.0121  \n",
      "<<<iteration:[180/525] - total_loss: 0.2845  obj_loss: 0.1429  noobj_loss: 0.1272  bbox_loss: 0.0101  cls_loss: 0.0276  \n",
      "<<<iteration:[200/525] - total_loss: 0.2550  obj_loss: 0.1474  noobj_loss: 0.1042  bbox_loss: 0.0078  cls_loss: 0.0165  \n",
      "<<<iteration:[220/525] - total_loss: 0.2449  obj_loss: 0.1445  noobj_loss: 0.1049  bbox_loss: 0.0068  cls_loss: 0.0140  \n",
      "<<<iteration:[240/525] - total_loss: 0.2696  obj_loss: 0.1574  noobj_loss: 0.1117  bbox_loss: 0.0074  cls_loss: 0.0193  \n",
      "<<<iteration:[260/525] - total_loss: 0.2420  obj_loss: 0.1401  noobj_loss: 0.1103  bbox_loss: 0.0072  cls_loss: 0.0109  \n",
      "<<<iteration:[280/525] - total_loss: 0.2487  obj_loss: 0.1430  noobj_loss: 0.1137  bbox_loss: 0.0075  cls_loss: 0.0115  \n",
      "<<<iteration:[300/525] - total_loss: 0.2314  obj_loss: 0.1314  noobj_loss: 0.0965  bbox_loss: 0.0083  cls_loss: 0.0104  \n",
      "<<<iteration:[320/525] - total_loss: 0.2769  obj_loss: 0.1551  noobj_loss: 0.1163  bbox_loss: 0.0081  cls_loss: 0.0229  \n",
      "<<<iteration:[340/525] - total_loss: 0.2502  obj_loss: 0.1470  noobj_loss: 0.1128  bbox_loss: 0.0071  cls_loss: 0.0112  \n",
      "<<<iteration:[360/525] - total_loss: 0.2344  obj_loss: 0.1422  noobj_loss: 0.1004  bbox_loss: 0.0065  cls_loss: 0.0097  \n",
      "<<<iteration:[380/525] - total_loss: 0.2471  obj_loss: 0.1455  noobj_loss: 0.1123  bbox_loss: 0.0071  cls_loss: 0.0102  \n",
      "<<<iteration:[400/525] - total_loss: 0.2551  obj_loss: 0.1420  noobj_loss: 0.1095  bbox_loss: 0.0084  cls_loss: 0.0166  \n",
      "<<<iteration:[420/525] - total_loss: 0.2560  obj_loss: 0.1475  noobj_loss: 0.1148  bbox_loss: 0.0068  cls_loss: 0.0170  \n",
      "<<<iteration:[440/525] - total_loss: 0.2496  obj_loss: 0.1481  noobj_loss: 0.1073  bbox_loss: 0.0071  cls_loss: 0.0122  \n",
      "<<<iteration:[460/525] - total_loss: 0.2474  obj_loss: 0.1494  noobj_loss: 0.1128  bbox_loss: 0.0066  cls_loss: 0.0084  \n",
      "<<<iteration:[480/525] - total_loss: 0.2579  obj_loss: 0.1520  noobj_loss: 0.1130  bbox_loss: 0.0076  cls_loss: 0.0114  \n",
      "<<<iteration:[500/525] - total_loss: 0.2600  obj_loss: 0.1547  noobj_loss: 0.1153  bbox_loss: 0.0067  cls_loss: 0.0143  \n",
      "<<<iteration:[520/525] - total_loss: 0.2572  obj_loss: 0.1570  noobj_loss: 0.1041  bbox_loss: 0.0073  cls_loss: 0.0115  \n",
      "\n",
      "epoch:81/100 - Train Loss: 0.2527, Val Loss: 0.2523\n",
      "\n",
      "<<<iteration:[20/525] - total_loss: 0.2511  obj_loss: 0.1531  noobj_loss: 0.1136  bbox_loss: 0.0059  cls_loss: 0.0117  \n",
      "<<<iteration:[40/525] - total_loss: 0.2520  obj_loss: 0.1367  noobj_loss: 0.1094  bbox_loss: 0.0077  cls_loss: 0.0219  \n",
      "<<<iteration:[60/525] - total_loss: 0.2661  obj_loss: 0.1540  noobj_loss: 0.1177  bbox_loss: 0.0073  cls_loss: 0.0168  \n",
      "<<<iteration:[80/525] - total_loss: 0.2586  obj_loss: 0.1651  noobj_loss: 0.1021  bbox_loss: 0.0066  cls_loss: 0.0092  \n",
      "<<<iteration:[100/525] - total_loss: 0.2417  obj_loss: 0.1418  noobj_loss: 0.1077  bbox_loss: 0.0070  cls_loss: 0.0111  \n",
      "<<<iteration:[120/525] - total_loss: 0.2535  obj_loss: 0.1603  noobj_loss: 0.1069  bbox_loss: 0.0063  cls_loss: 0.0082  \n",
      "<<<iteration:[140/525] - total_loss: 0.2517  obj_loss: 0.1450  noobj_loss: 0.1125  bbox_loss: 0.0074  cls_loss: 0.0134  \n",
      "<<<iteration:[160/525] - total_loss: 0.2457  obj_loss: 0.1449  noobj_loss: 0.1105  bbox_loss: 0.0063  cls_loss: 0.0143  \n",
      "<<<iteration:[180/525] - total_loss: 0.2593  obj_loss: 0.1429  noobj_loss: 0.1061  bbox_loss: 0.0089  cls_loss: 0.0190  \n",
      "<<<iteration:[200/525] - total_loss: 0.2389  obj_loss: 0.1358  noobj_loss: 0.1104  bbox_loss: 0.0078  cls_loss: 0.0088  \n",
      "<<<iteration:[220/525] - total_loss: 0.2548  obj_loss: 0.1668  noobj_loss: 0.1074  bbox_loss: 0.0053  cls_loss: 0.0078  \n",
      "<<<iteration:[240/525] - total_loss: 0.2329  obj_loss: 0.1329  noobj_loss: 0.1112  bbox_loss: 0.0061  cls_loss: 0.0138  \n",
      "<<<iteration:[260/525] - total_loss: 0.2364  obj_loss: 0.1283  noobj_loss: 0.1053  bbox_loss: 0.0081  cls_loss: 0.0149  \n",
      "<<<iteration:[280/525] - total_loss: 0.2539  obj_loss: 0.1548  noobj_loss: 0.1190  bbox_loss: 0.0054  cls_loss: 0.0128  \n",
      "<<<iteration:[300/525] - total_loss: 0.2539  obj_loss: 0.1595  noobj_loss: 0.1101  bbox_loss: 0.0057  cls_loss: 0.0110  \n",
      "<<<iteration:[320/525] - total_loss: 0.2455  obj_loss: 0.1377  noobj_loss: 0.1122  bbox_loss: 0.0065  cls_loss: 0.0191  \n",
      "<<<iteration:[340/525] - total_loss: 0.2561  obj_loss: 0.1529  noobj_loss: 0.1165  bbox_loss: 0.0069  cls_loss: 0.0103  \n",
      "<<<iteration:[360/525] - total_loss: 0.2510  obj_loss: 0.1465  noobj_loss: 0.1181  bbox_loss: 0.0067  cls_loss: 0.0116  \n",
      "<<<iteration:[380/525] - total_loss: 0.2717  obj_loss: 0.1618  noobj_loss: 0.1217  bbox_loss: 0.0074  cls_loss: 0.0119  \n",
      "<<<iteration:[400/525] - total_loss: 0.2437  obj_loss: 0.1394  noobj_loss: 0.1078  bbox_loss: 0.0075  cls_loss: 0.0129  \n",
      "<<<iteration:[420/525] - total_loss: 0.2548  obj_loss: 0.1532  noobj_loss: 0.1135  bbox_loss: 0.0069  cls_loss: 0.0105  \n",
      "<<<iteration:[440/525] - total_loss: 0.2403  obj_loss: 0.1397  noobj_loss: 0.1147  bbox_loss: 0.0067  cls_loss: 0.0098  \n",
      "<<<iteration:[460/525] - total_loss: 0.2510  obj_loss: 0.1525  noobj_loss: 0.1124  bbox_loss: 0.0065  cls_loss: 0.0097  \n",
      "<<<iteration:[480/525] - total_loss: 0.2512  obj_loss: 0.1510  noobj_loss: 0.1189  bbox_loss: 0.0063  cls_loss: 0.0095  \n",
      "<<<iteration:[500/525] - total_loss: 0.2585  obj_loss: 0.1526  noobj_loss: 0.1247  bbox_loss: 0.0068  cls_loss: 0.0094  \n",
      "<<<iteration:[520/525] - total_loss: 0.2518  obj_loss: 0.1527  noobj_loss: 0.1179  bbox_loss: 0.0059  cls_loss: 0.0107  \n",
      "\n",
      "epoch:82/100 - Train Loss: 0.2507, Val Loss: 0.2565\n",
      "\n",
      "<<<iteration:[20/525] - total_loss: 0.2422  obj_loss: 0.1403  noobj_loss: 0.1168  bbox_loss: 0.0068  cls_loss: 0.0097  \n",
      "<<<iteration:[40/525] - total_loss: 0.2606  obj_loss: 0.1648  noobj_loss: 0.1117  bbox_loss: 0.0062  cls_loss: 0.0089  \n",
      "<<<iteration:[60/525] - total_loss: 0.2419  obj_loss: 0.1494  noobj_loss: 0.1113  bbox_loss: 0.0058  cls_loss: 0.0077  \n",
      "<<<iteration:[80/525] - total_loss: 0.2597  obj_loss: 0.1462  noobj_loss: 0.1161  bbox_loss: 0.0071  cls_loss: 0.0197  \n",
      "<<<iteration:[100/525] - total_loss: 0.2554  obj_loss: 0.1595  noobj_loss: 0.1142  bbox_loss: 0.0064  cls_loss: 0.0069  \n",
      "<<<iteration:[120/525] - total_loss: 0.2609  obj_loss: 0.1543  noobj_loss: 0.1173  bbox_loss: 0.0067  cls_loss: 0.0146  \n",
      "<<<iteration:[140/525] - total_loss: 0.2462  obj_loss: 0.1450  noobj_loss: 0.1113  bbox_loss: 0.0065  cls_loss: 0.0128  \n",
      "<<<iteration:[160/525] - total_loss: 0.2695  obj_loss: 0.1517  noobj_loss: 0.1218  bbox_loss: 0.0073  cls_loss: 0.0204  \n",
      "<<<iteration:[180/525] - total_loss: 0.2428  obj_loss: 0.1506  noobj_loss: 0.1027  bbox_loss: 0.0062  cls_loss: 0.0099  \n",
      "<<<iteration:[200/525] - total_loss: 0.2699  obj_loss: 0.1611  noobj_loss: 0.1138  bbox_loss: 0.0075  cls_loss: 0.0145  \n",
      "<<<iteration:[220/525] - total_loss: 0.2444  obj_loss: 0.1426  noobj_loss: 0.1150  bbox_loss: 0.0063  cls_loss: 0.0127  \n",
      "<<<iteration:[240/525] - total_loss: 0.2472  obj_loss: 0.1450  noobj_loss: 0.1114  bbox_loss: 0.0074  cls_loss: 0.0097  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<<<iteration:[260/525] - total_loss: 0.2519  obj_loss: 0.1529  noobj_loss: 0.1172  bbox_loss: 0.0066  cls_loss: 0.0077  \n",
      "<<<iteration:[280/525] - total_loss: 0.2742  obj_loss: 0.1739  noobj_loss: 0.1128  bbox_loss: 0.0063  cls_loss: 0.0124  \n",
      "<<<iteration:[300/525] - total_loss: 0.2620  obj_loss: 0.1612  noobj_loss: 0.1160  bbox_loss: 0.0065  cls_loss: 0.0105  \n",
      "<<<iteration:[320/525] - total_loss: 0.2298  obj_loss: 0.1234  noobj_loss: 0.1141  bbox_loss: 0.0072  cls_loss: 0.0135  \n",
      "<<<iteration:[340/525] - total_loss: 0.2453  obj_loss: 0.1489  noobj_loss: 0.1071  bbox_loss: 0.0058  cls_loss: 0.0139  \n",
      "<<<iteration:[360/525] - total_loss: 0.2587  obj_loss: 0.1561  noobj_loss: 0.1219  bbox_loss: 0.0068  cls_loss: 0.0078  \n",
      "<<<iteration:[380/525] - total_loss: 0.2437  obj_loss: 0.1381  noobj_loss: 0.1193  bbox_loss: 0.0072  cls_loss: 0.0101  \n",
      "<<<iteration:[400/525] - total_loss: 0.2612  obj_loss: 0.1638  noobj_loss: 0.1109  bbox_loss: 0.0067  cls_loss: 0.0083  \n",
      "<<<iteration:[420/525] - total_loss: 0.2598  obj_loss: 0.1471  noobj_loss: 0.1230  bbox_loss: 0.0079  cls_loss: 0.0118  \n",
      "<<<iteration:[440/525] - total_loss: 0.2561  obj_loss: 0.1623  noobj_loss: 0.1100  bbox_loss: 0.0054  cls_loss: 0.0120  \n",
      "<<<iteration:[460/525] - total_loss: 0.2527  obj_loss: 0.1483  noobj_loss: 0.1256  bbox_loss: 0.0067  cls_loss: 0.0080  \n",
      "<<<iteration:[480/525] - total_loss: 0.2619  obj_loss: 0.1624  noobj_loss: 0.1086  bbox_loss: 0.0063  cls_loss: 0.0135  \n",
      "<<<iteration:[500/525] - total_loss: 0.2708  obj_loss: 0.1684  noobj_loss: 0.1191  bbox_loss: 0.0057  cls_loss: 0.0144  \n",
      "<<<iteration:[520/525] - total_loss: 0.2400  obj_loss: 0.1429  noobj_loss: 0.1210  bbox_loss: 0.0059  cls_loss: 0.0074  \n",
      "\n",
      "epoch:83/100 - Train Loss: 0.2539, Val Loss: 0.2652\n",
      "\n",
      "<<<iteration:[20/525] - total_loss: 0.2764  obj_loss: 0.1800  noobj_loss: 0.1212  bbox_loss: 0.0051  cls_loss: 0.0101  \n",
      "<<<iteration:[40/525] - total_loss: 0.2586  obj_loss: 0.1574  noobj_loss: 0.1262  bbox_loss: 0.0058  cls_loss: 0.0089  \n",
      "<<<iteration:[60/525] - total_loss: 0.2642  obj_loss: 0.1630  noobj_loss: 0.1230  bbox_loss: 0.0061  cls_loss: 0.0093  \n",
      "<<<iteration:[80/525] - total_loss: 0.2473  obj_loss: 0.1525  noobj_loss: 0.1190  bbox_loss: 0.0052  cls_loss: 0.0092  \n",
      "<<<iteration:[100/525] - total_loss: 0.2366  obj_loss: 0.1409  noobj_loss: 0.1107  bbox_loss: 0.0062  cls_loss: 0.0092  \n",
      "<<<iteration:[120/525] - total_loss: 0.2325  obj_loss: 0.1385  noobj_loss: 0.1132  bbox_loss: 0.0060  cls_loss: 0.0073  \n",
      "<<<iteration:[140/525] - total_loss: 0.2558  obj_loss: 0.1483  noobj_loss: 0.1255  bbox_loss: 0.0060  cls_loss: 0.0147  \n",
      "<<<iteration:[160/525] - total_loss: 0.2650  obj_loss: 0.1576  noobj_loss: 0.1243  bbox_loss: 0.0063  cls_loss: 0.0137  \n",
      "<<<iteration:[180/525] - total_loss: 0.2730  obj_loss: 0.1636  noobj_loss: 0.1227  bbox_loss: 0.0076  cls_loss: 0.0102  \n",
      "<<<iteration:[200/525] - total_loss: 0.2542  obj_loss: 0.1494  noobj_loss: 0.1249  bbox_loss: 0.0063  cls_loss: 0.0106  \n",
      "<<<iteration:[220/525] - total_loss: 0.2469  obj_loss: 0.1427  noobj_loss: 0.1176  bbox_loss: 0.0077  cls_loss: 0.0071  \n",
      "<<<iteration:[240/525] - total_loss: 0.2707  obj_loss: 0.1503  noobj_loss: 0.1128  bbox_loss: 0.0088  cls_loss: 0.0200  \n",
      "<<<iteration:[260/525] - total_loss: 0.2396  obj_loss: 0.1423  noobj_loss: 0.1104  bbox_loss: 0.0060  cls_loss: 0.0120  \n",
      "<<<iteration:[280/525] - total_loss: 0.2405  obj_loss: 0.1423  noobj_loss: 0.1093  bbox_loss: 0.0070  cls_loss: 0.0084  \n",
      "<<<iteration:[300/525] - total_loss: 0.2760  obj_loss: 0.1731  noobj_loss: 0.1205  bbox_loss: 0.0060  cls_loss: 0.0126  \n",
      "<<<iteration:[320/525] - total_loss: 0.2313  obj_loss: 0.1318  noobj_loss: 0.1099  bbox_loss: 0.0069  cls_loss: 0.0102  \n",
      "<<<iteration:[340/525] - total_loss: 0.2325  obj_loss: 0.1344  noobj_loss: 0.1112  bbox_loss: 0.0071  cls_loss: 0.0070  \n",
      "<<<iteration:[360/525] - total_loss: 0.2556  obj_loss: 0.1568  noobj_loss: 0.1125  bbox_loss: 0.0064  cls_loss: 0.0105  \n",
      "<<<iteration:[380/525] - total_loss: 0.2561  obj_loss: 0.1619  noobj_loss: 0.1162  bbox_loss: 0.0056  cls_loss: 0.0079  \n",
      "<<<iteration:[400/525] - total_loss: 0.2545  obj_loss: 0.1526  noobj_loss: 0.1174  bbox_loss: 0.0059  cls_loss: 0.0136  \n",
      "<<<iteration:[420/525] - total_loss: 0.2573  obj_loss: 0.1478  noobj_loss: 0.1191  bbox_loss: 0.0079  cls_loss: 0.0103  \n",
      "<<<iteration:[440/525] - total_loss: 0.2431  obj_loss: 0.1300  noobj_loss: 0.1135  bbox_loss: 0.0086  cls_loss: 0.0134  \n",
      "<<<iteration:[460/525] - total_loss: 0.2593  obj_loss: 0.1618  noobj_loss: 0.1088  bbox_loss: 0.0061  cls_loss: 0.0128  \n",
      "<<<iteration:[480/525] - total_loss: 0.2588  obj_loss: 0.1439  noobj_loss: 0.1112  bbox_loss: 0.0066  cls_loss: 0.0261  \n",
      "<<<iteration:[500/525] - total_loss: 0.2690  obj_loss: 0.1590  noobj_loss: 0.1259  bbox_loss: 0.0068  cls_loss: 0.0130  \n",
      "<<<iteration:[520/525] - total_loss: 0.2679  obj_loss: 0.1594  noobj_loss: 0.1229  bbox_loss: 0.0069  cls_loss: 0.0124  \n",
      "\n",
      "epoch:84/100 - Train Loss: 0.2547, Val Loss: 0.2582\n",
      "\n",
      "<<<iteration:[20/525] - total_loss: 0.2882  obj_loss: 0.1710  noobj_loss: 0.1273  bbox_loss: 0.0062  cls_loss: 0.0225  \n",
      "<<<iteration:[40/525] - total_loss: 0.2387  obj_loss: 0.1406  noobj_loss: 0.1188  bbox_loss: 0.0057  cls_loss: 0.0102  \n",
      "<<<iteration:[60/525] - total_loss: 0.2359  obj_loss: 0.1423  noobj_loss: 0.1148  bbox_loss: 0.0056  cls_loss: 0.0080  \n",
      "<<<iteration:[80/525] - total_loss: 0.2579  obj_loss: 0.1552  noobj_loss: 0.1189  bbox_loss: 0.0057  cls_loss: 0.0150  \n",
      "<<<iteration:[100/525] - total_loss: 0.2437  obj_loss: 0.1407  noobj_loss: 0.1331  bbox_loss: 0.0057  cls_loss: 0.0078  \n",
      "<<<iteration:[120/525] - total_loss: 0.2376  obj_loss: 0.1407  noobj_loss: 0.1130  bbox_loss: 0.0067  cls_loss: 0.0068  \n",
      "<<<iteration:[140/525] - total_loss: 0.2555  obj_loss: 0.1589  noobj_loss: 0.1166  bbox_loss: 0.0059  cls_loss: 0.0088  \n",
      "<<<iteration:[160/525] - total_loss: 0.2823  obj_loss: 0.1758  noobj_loss: 0.1258  bbox_loss: 0.0059  cls_loss: 0.0140  \n",
      "<<<iteration:[180/525] - total_loss: 0.2384  obj_loss: 0.1352  noobj_loss: 0.1211  bbox_loss: 0.0069  cls_loss: 0.0083  \n",
      "<<<iteration:[200/525] - total_loss: 0.2434  obj_loss: 0.1466  noobj_loss: 0.1200  bbox_loss: 0.0055  cls_loss: 0.0095  \n",
      "<<<iteration:[220/525] - total_loss: 0.2601  obj_loss: 0.1529  noobj_loss: 0.1238  bbox_loss: 0.0069  cls_loss: 0.0109  \n",
      "<<<iteration:[240/525] - total_loss: 0.2613  obj_loss: 0.1593  noobj_loss: 0.1271  bbox_loss: 0.0060  cls_loss: 0.0084  \n",
      "<<<iteration:[260/525] - total_loss: 0.2503  obj_loss: 0.1448  noobj_loss: 0.1197  bbox_loss: 0.0070  cls_loss: 0.0104  \n",
      "<<<iteration:[280/525] - total_loss: 0.2455  obj_loss: 0.1480  noobj_loss: 0.1145  bbox_loss: 0.0059  cls_loss: 0.0106  \n",
      "<<<iteration:[300/525] - total_loss: 0.2648  obj_loss: 0.1675  noobj_loss: 0.1176  bbox_loss: 0.0058  cls_loss: 0.0096  \n",
      "<<<iteration:[320/525] - total_loss: 0.2528  obj_loss: 0.1506  noobj_loss: 0.1214  bbox_loss: 0.0063  cls_loss: 0.0102  \n",
      "<<<iteration:[340/525] - total_loss: 0.2538  obj_loss: 0.1492  noobj_loss: 0.1171  bbox_loss: 0.0068  cls_loss: 0.0122  \n",
      "<<<iteration:[360/525] - total_loss: 0.2619  obj_loss: 0.1590  noobj_loss: 0.1305  bbox_loss: 0.0056  cls_loss: 0.0099  \n",
      "<<<iteration:[380/525] - total_loss: 0.2432  obj_loss: 0.1419  noobj_loss: 0.1111  bbox_loss: 0.0073  cls_loss: 0.0091  \n",
      "<<<iteration:[400/525] - total_loss: 0.2475  obj_loss: 0.1449  noobj_loss: 0.1196  bbox_loss: 0.0066  cls_loss: 0.0098  \n",
      "<<<iteration:[420/525] - total_loss: 0.2591  obj_loss: 0.1497  noobj_loss: 0.1121  bbox_loss: 0.0076  cls_loss: 0.0152  \n",
      "<<<iteration:[440/525] - total_loss: 0.2602  obj_loss: 0.1634  noobj_loss: 0.1296  bbox_loss: 0.0051  cls_loss: 0.0065  \n",
      "<<<iteration:[460/525] - total_loss: 0.2462  obj_loss: 0.1462  noobj_loss: 0.1128  bbox_loss: 0.0072  cls_loss: 0.0076  \n",
      "<<<iteration:[480/525] - total_loss: 0.2688  obj_loss: 0.1605  noobj_loss: 0.1231  bbox_loss: 0.0066  cls_loss: 0.0136  \n",
      "<<<iteration:[500/525] - total_loss: 0.2673  obj_loss: 0.1592  noobj_loss: 0.1210  bbox_loss: 0.0066  cls_loss: 0.0148  \n",
      "<<<iteration:[520/525] - total_loss: 0.2359  obj_loss: 0.1335  noobj_loss: 0.1213  bbox_loss: 0.0063  cls_loss: 0.0102  \n",
      "\n",
      "epoch:85/100 - Train Loss: 0.2531, Val Loss: 0.2568\n",
      "\n",
      "<<<iteration:[20/525] - total_loss: 0.2513  obj_loss: 0.1569  noobj_loss: 0.1202  bbox_loss: 0.0056  cls_loss: 0.0063  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<<<iteration:[40/525] - total_loss: 0.2405  obj_loss: 0.1418  noobj_loss: 0.1230  bbox_loss: 0.0057  cls_loss: 0.0087  \n",
      "<<<iteration:[60/525] - total_loss: 0.2439  obj_loss: 0.1443  noobj_loss: 0.1110  bbox_loss: 0.0059  cls_loss: 0.0144  \n",
      "<<<iteration:[80/525] - total_loss: 0.2517  obj_loss: 0.1645  noobj_loss: 0.1093  bbox_loss: 0.0053  cls_loss: 0.0060  \n",
      "<<<iteration:[100/525] - total_loss: 0.2418  obj_loss: 0.1413  noobj_loss: 0.1092  bbox_loss: 0.0061  cls_loss: 0.0154  \n",
      "<<<iteration:[120/525] - total_loss: 0.2344  obj_loss: 0.1392  noobj_loss: 0.1192  bbox_loss: 0.0056  cls_loss: 0.0077  \n",
      "<<<iteration:[140/525] - total_loss: 0.2394  obj_loss: 0.1400  noobj_loss: 0.1218  bbox_loss: 0.0060  cls_loss: 0.0087  \n",
      "<<<iteration:[160/525] - total_loss: 0.2630  obj_loss: 0.1492  noobj_loss: 0.1203  bbox_loss: 0.0087  cls_loss: 0.0100  \n",
      "<<<iteration:[180/525] - total_loss: 0.2570  obj_loss: 0.1577  noobj_loss: 0.1218  bbox_loss: 0.0058  cls_loss: 0.0093  \n",
      "<<<iteration:[200/525] - total_loss: 0.2766  obj_loss: 0.1717  noobj_loss: 0.1146  bbox_loss: 0.0066  cls_loss: 0.0148  \n",
      "<<<iteration:[220/525] - total_loss: 0.2607  obj_loss: 0.1462  noobj_loss: 0.1197  bbox_loss: 0.0074  cls_loss: 0.0177  \n",
      "<<<iteration:[240/525] - total_loss: 0.2371  obj_loss: 0.1386  noobj_loss: 0.1122  bbox_loss: 0.0070  cls_loss: 0.0074  \n",
      "<<<iteration:[260/525] - total_loss: 0.2545  obj_loss: 0.1478  noobj_loss: 0.1179  bbox_loss: 0.0067  cls_loss: 0.0140  \n",
      "<<<iteration:[280/525] - total_loss: 0.2456  obj_loss: 0.1482  noobj_loss: 0.1185  bbox_loss: 0.0065  cls_loss: 0.0058  \n",
      "<<<iteration:[300/525] - total_loss: 0.2447  obj_loss: 0.1427  noobj_loss: 0.1218  bbox_loss: 0.0061  cls_loss: 0.0107  \n",
      "<<<iteration:[320/525] - total_loss: 0.2494  obj_loss: 0.1424  noobj_loss: 0.1236  bbox_loss: 0.0062  cls_loss: 0.0142  \n",
      "<<<iteration:[340/525] - total_loss: 0.2577  obj_loss: 0.1515  noobj_loss: 0.1150  bbox_loss: 0.0076  cls_loss: 0.0107  \n",
      "<<<iteration:[360/525] - total_loss: 0.2572  obj_loss: 0.1482  noobj_loss: 0.1291  bbox_loss: 0.0065  cls_loss: 0.0118  \n",
      "<<<iteration:[380/525] - total_loss: 0.2705  obj_loss: 0.1733  noobj_loss: 0.1197  bbox_loss: 0.0057  cls_loss: 0.0087  \n",
      "<<<iteration:[400/525] - total_loss: 0.2336  obj_loss: 0.1444  noobj_loss: 0.1096  bbox_loss: 0.0050  cls_loss: 0.0096  \n",
      "<<<iteration:[420/525] - total_loss: 0.2485  obj_loss: 0.1475  noobj_loss: 0.1176  bbox_loss: 0.0065  cls_loss: 0.0097  \n",
      "<<<iteration:[440/525] - total_loss: 0.2350  obj_loss: 0.1356  noobj_loss: 0.1104  bbox_loss: 0.0066  cls_loss: 0.0111  \n",
      "<<<iteration:[460/525] - total_loss: 0.2553  obj_loss: 0.1517  noobj_loss: 0.1157  bbox_loss: 0.0068  cls_loss: 0.0117  \n",
      "<<<iteration:[480/525] - total_loss: 0.2345  obj_loss: 0.1406  noobj_loss: 0.1161  bbox_loss: 0.0053  cls_loss: 0.0094  \n",
      "<<<iteration:[500/525] - total_loss: 0.2398  obj_loss: 0.1407  noobj_loss: 0.1187  bbox_loss: 0.0065  cls_loss: 0.0071  \n",
      "<<<iteration:[520/525] - total_loss: 0.2635  obj_loss: 0.1655  noobj_loss: 0.1178  bbox_loss: 0.0054  cls_loss: 0.0123  \n",
      "\n",
      "epoch:86/100 - Train Loss: 0.2495, Val Loss: 0.2535\n",
      "\n",
      "<<<iteration:[20/525] - total_loss: 0.2511  obj_loss: 0.1458  noobj_loss: 0.1312  bbox_loss: 0.0059  cls_loss: 0.0102  \n",
      "<<<iteration:[40/525] - total_loss: 0.2460  obj_loss: 0.1447  noobj_loss: 0.1160  bbox_loss: 0.0070  cls_loss: 0.0084  \n",
      "<<<iteration:[60/525] - total_loss: 0.2335  obj_loss: 0.1341  noobj_loss: 0.1202  bbox_loss: 0.0061  cls_loss: 0.0090  \n",
      "<<<iteration:[80/525] - total_loss: 0.2515  obj_loss: 0.1581  noobj_loss: 0.1146  bbox_loss: 0.0056  cls_loss: 0.0081  \n",
      "<<<iteration:[100/525] - total_loss: 0.2649  obj_loss: 0.1563  noobj_loss: 0.1240  bbox_loss: 0.0069  cls_loss: 0.0122  \n",
      "<<<iteration:[120/525] - total_loss: 0.2363  obj_loss: 0.1404  noobj_loss: 0.1171  bbox_loss: 0.0059  cls_loss: 0.0080  \n",
      "<<<iteration:[140/525] - total_loss: 0.2755  obj_loss: 0.1749  noobj_loss: 0.1243  bbox_loss: 0.0060  cls_loss: 0.0084  \n",
      "<<<iteration:[160/525] - total_loss: 0.2448  obj_loss: 0.1454  noobj_loss: 0.1288  bbox_loss: 0.0057  cls_loss: 0.0065  \n",
      "<<<iteration:[180/525] - total_loss: 0.2502  obj_loss: 0.1384  noobj_loss: 0.1239  bbox_loss: 0.0075  cls_loss: 0.0122  \n",
      "<<<iteration:[200/525] - total_loss: 0.2509  obj_loss: 0.1492  noobj_loss: 0.1217  bbox_loss: 0.0061  cls_loss: 0.0101  \n",
      "<<<iteration:[220/525] - total_loss: 0.2501  obj_loss: 0.1545  noobj_loss: 0.1193  bbox_loss: 0.0057  cls_loss: 0.0076  \n",
      "<<<iteration:[240/525] - total_loss: 0.2419  obj_loss: 0.1433  noobj_loss: 0.1207  bbox_loss: 0.0063  cls_loss: 0.0067  \n",
      "<<<iteration:[260/525] - total_loss: 0.2471  obj_loss: 0.1406  noobj_loss: 0.1079  bbox_loss: 0.0061  cls_loss: 0.0219  \n",
      "<<<iteration:[280/525] - total_loss: 0.2652  obj_loss: 0.1598  noobj_loss: 0.1215  bbox_loss: 0.0063  cls_loss: 0.0130  \n",
      "<<<iteration:[300/525] - total_loss: 0.2598  obj_loss: 0.1552  noobj_loss: 0.1194  bbox_loss: 0.0069  cls_loss: 0.0106  \n",
      "<<<iteration:[320/525] - total_loss: 0.2360  obj_loss: 0.1380  noobj_loss: 0.1252  bbox_loss: 0.0057  cls_loss: 0.0068  \n",
      "<<<iteration:[340/525] - total_loss: 0.2793  obj_loss: 0.1648  noobj_loss: 0.1296  bbox_loss: 0.0064  cls_loss: 0.0179  \n",
      "<<<iteration:[360/525] - total_loss: 0.2463  obj_loss: 0.1462  noobj_loss: 0.1267  bbox_loss: 0.0058  cls_loss: 0.0076  \n",
      "<<<iteration:[380/525] - total_loss: 0.2639  obj_loss: 0.1563  noobj_loss: 0.1282  bbox_loss: 0.0054  cls_loss: 0.0164  \n",
      "<<<iteration:[400/525] - total_loss: 0.2484  obj_loss: 0.1470  noobj_loss: 0.1155  bbox_loss: 0.0071  cls_loss: 0.0083  \n",
      "<<<iteration:[420/525] - total_loss: 0.2504  obj_loss: 0.1569  noobj_loss: 0.1202  bbox_loss: 0.0050  cls_loss: 0.0085  \n",
      "<<<iteration:[440/525] - total_loss: 0.2627  obj_loss: 0.1577  noobj_loss: 0.1310  bbox_loss: 0.0058  cls_loss: 0.0107  \n",
      "<<<iteration:[460/525] - total_loss: 0.2371  obj_loss: 0.1401  noobj_loss: 0.1105  bbox_loss: 0.0069  cls_loss: 0.0071  \n",
      "<<<iteration:[480/525] - total_loss: 0.2628  obj_loss: 0.1583  noobj_loss: 0.1266  bbox_loss: 0.0058  cls_loss: 0.0120  \n",
      "<<<iteration:[500/525] - total_loss: 0.2465  obj_loss: 0.1512  noobj_loss: 0.1160  bbox_loss: 0.0056  cls_loss: 0.0091  \n",
      "<<<iteration:[520/525] - total_loss: 0.2403  obj_loss: 0.1399  noobj_loss: 0.1286  bbox_loss: 0.0060  cls_loss: 0.0064  \n",
      "\n",
      "epoch:87/100 - Train Loss: 0.2511, Val Loss: 0.2554\n",
      "\n",
      "<<<iteration:[20/525] - total_loss: 0.2457  obj_loss: 0.1466  noobj_loss: 0.1301  bbox_loss: 0.0056  cls_loss: 0.0062  \n",
      "<<<iteration:[40/525] - total_loss: 0.2471  obj_loss: 0.1435  noobj_loss: 0.1135  bbox_loss: 0.0071  cls_loss: 0.0114  \n",
      "<<<iteration:[60/525] - total_loss: 0.2508  obj_loss: 0.1528  noobj_loss: 0.1262  bbox_loss: 0.0056  cls_loss: 0.0068  \n",
      "<<<iteration:[80/525] - total_loss: 0.2454  obj_loss: 0.1517  noobj_loss: 0.1162  bbox_loss: 0.0047  cls_loss: 0.0118  \n",
      "<<<iteration:[100/525] - total_loss: 0.2541  obj_loss: 0.1596  noobj_loss: 0.1247  bbox_loss: 0.0054  cls_loss: 0.0052  \n",
      "<<<iteration:[120/525] - total_loss: 0.2523  obj_loss: 0.1541  noobj_loss: 0.1235  bbox_loss: 0.0054  cls_loss: 0.0094  \n",
      "<<<iteration:[140/525] - total_loss: 0.2444  obj_loss: 0.1511  noobj_loss: 0.1193  bbox_loss: 0.0052  cls_loss: 0.0074  \n",
      "<<<iteration:[160/525] - total_loss: 0.2343  obj_loss: 0.1349  noobj_loss: 0.1192  bbox_loss: 0.0058  cls_loss: 0.0107  \n",
      "<<<iteration:[180/525] - total_loss: 0.2631  obj_loss: 0.1521  noobj_loss: 0.1253  bbox_loss: 0.0063  cls_loss: 0.0167  \n",
      "<<<iteration:[200/525] - total_loss: 0.2420  obj_loss: 0.1488  noobj_loss: 0.1097  bbox_loss: 0.0058  cls_loss: 0.0093  \n",
      "<<<iteration:[220/525] - total_loss: 0.2457  obj_loss: 0.1526  noobj_loss: 0.1223  bbox_loss: 0.0054  cls_loss: 0.0050  \n",
      "<<<iteration:[240/525] - total_loss: 0.2295  obj_loss: 0.1305  noobj_loss: 0.1110  bbox_loss: 0.0061  cls_loss: 0.0132  \n",
      "<<<iteration:[260/525] - total_loss: 0.2614  obj_loss: 0.1630  noobj_loss: 0.1284  bbox_loss: 0.0054  cls_loss: 0.0071  \n",
      "<<<iteration:[280/525] - total_loss: 0.2580  obj_loss: 0.1546  noobj_loss: 0.1220  bbox_loss: 0.0063  cls_loss: 0.0107  \n",
      "<<<iteration:[300/525] - total_loss: 0.2388  obj_loss: 0.1356  noobj_loss: 0.1303  bbox_loss: 0.0057  cls_loss: 0.0098  \n",
      "<<<iteration:[320/525] - total_loss: 0.2486  obj_loss: 0.1422  noobj_loss: 0.1174  bbox_loss: 0.0071  cls_loss: 0.0123  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<<<iteration:[340/525] - total_loss: 0.2774  obj_loss: 0.1670  noobj_loss: 0.1152  bbox_loss: 0.0068  cls_loss: 0.0186  \n",
      "<<<iteration:[360/525] - total_loss: 0.2536  obj_loss: 0.1512  noobj_loss: 0.1184  bbox_loss: 0.0067  cls_loss: 0.0097  \n",
      "<<<iteration:[380/525] - total_loss: 0.2670  obj_loss: 0.1726  noobj_loss: 0.1235  bbox_loss: 0.0052  cls_loss: 0.0063  \n",
      "<<<iteration:[400/525] - total_loss: 0.2567  obj_loss: 0.1502  noobj_loss: 0.1268  bbox_loss: 0.0064  cls_loss: 0.0111  \n",
      "<<<iteration:[420/525] - total_loss: 0.2677  obj_loss: 0.1660  noobj_loss: 0.1212  bbox_loss: 0.0059  cls_loss: 0.0114  \n",
      "<<<iteration:[440/525] - total_loss: 0.2531  obj_loss: 0.1471  noobj_loss: 0.1302  bbox_loss: 0.0057  cls_loss: 0.0122  \n",
      "<<<iteration:[460/525] - total_loss: 0.2508  obj_loss: 0.1490  noobj_loss: 0.1144  bbox_loss: 0.0068  cls_loss: 0.0108  \n",
      "<<<iteration:[480/525] - total_loss: 0.2332  obj_loss: 0.1446  noobj_loss: 0.1142  bbox_loss: 0.0051  cls_loss: 0.0058  \n",
      "<<<iteration:[500/525] - total_loss: 0.2462  obj_loss: 0.1544  noobj_loss: 0.1227  bbox_loss: 0.0047  cls_loss: 0.0069  \n",
      "<<<iteration:[520/525] - total_loss: 0.2562  obj_loss: 0.1519  noobj_loss: 0.1256  bbox_loss: 0.0067  cls_loss: 0.0080  \n",
      "\n",
      "epoch:88/100 - Train Loss: 0.2504, Val Loss: 0.2564\n",
      "\n",
      "<<<iteration:[20/525] - total_loss: 0.2801  obj_loss: 0.1632  noobj_loss: 0.1364  bbox_loss: 0.0065  cls_loss: 0.0163  \n",
      "<<<iteration:[40/525] - total_loss: 0.2775  obj_loss: 0.1629  noobj_loss: 0.1220  bbox_loss: 0.0065  cls_loss: 0.0213  \n",
      "<<<iteration:[60/525] - total_loss: 0.2555  obj_loss: 0.1528  noobj_loss: 0.1183  bbox_loss: 0.0071  cls_loss: 0.0078  \n",
      "<<<iteration:[80/525] - total_loss: 0.2367  obj_loss: 0.1407  noobj_loss: 0.1176  bbox_loss: 0.0063  cls_loss: 0.0056  \n",
      "<<<iteration:[100/525] - total_loss: 0.2635  obj_loss: 0.1556  noobj_loss: 0.1303  bbox_loss: 0.0063  cls_loss: 0.0111  \n",
      "<<<iteration:[120/525] - total_loss: 0.2553  obj_loss: 0.1526  noobj_loss: 0.1236  bbox_loss: 0.0065  cls_loss: 0.0084  \n",
      "<<<iteration:[140/525] - total_loss: 0.2472  obj_loss: 0.1468  noobj_loss: 0.1222  bbox_loss: 0.0053  cls_loss: 0.0129  \n",
      "<<<iteration:[160/525] - total_loss: 0.2410  obj_loss: 0.1475  noobj_loss: 0.1183  bbox_loss: 0.0058  cls_loss: 0.0056  \n",
      "<<<iteration:[180/525] - total_loss: 0.2442  obj_loss: 0.1402  noobj_loss: 0.1180  bbox_loss: 0.0070  cls_loss: 0.0099  \n",
      "<<<iteration:[200/525] - total_loss: 0.2495  obj_loss: 0.1538  noobj_loss: 0.1261  bbox_loss: 0.0052  cls_loss: 0.0068  \n",
      "<<<iteration:[220/525] - total_loss: 0.2436  obj_loss: 0.1399  noobj_loss: 0.1278  bbox_loss: 0.0059  cls_loss: 0.0102  \n",
      "<<<iteration:[240/525] - total_loss: 0.2418  obj_loss: 0.1404  noobj_loss: 0.1270  bbox_loss: 0.0052  cls_loss: 0.0119  \n",
      "<<<iteration:[260/525] - total_loss: 0.2464  obj_loss: 0.1460  noobj_loss: 0.1298  bbox_loss: 0.0052  cls_loss: 0.0093  \n",
      "<<<iteration:[280/525] - total_loss: 0.2736  obj_loss: 0.1748  noobj_loss: 0.1290  bbox_loss: 0.0053  cls_loss: 0.0078  \n",
      "<<<iteration:[300/525] - total_loss: 0.2457  obj_loss: 0.1423  noobj_loss: 0.1239  bbox_loss: 0.0053  cls_loss: 0.0150  \n",
      "<<<iteration:[320/525] - total_loss: 0.2542  obj_loss: 0.1537  noobj_loss: 0.1305  bbox_loss: 0.0059  cls_loss: 0.0059  \n",
      "<<<iteration:[340/525] - total_loss: 0.2453  obj_loss: 0.1489  noobj_loss: 0.1207  bbox_loss: 0.0049  cls_loss: 0.0115  \n",
      "<<<iteration:[360/525] - total_loss: 0.2377  obj_loss: 0.1457  noobj_loss: 0.1103  bbox_loss: 0.0054  cls_loss: 0.0097  \n",
      "<<<iteration:[380/525] - total_loss: 0.2555  obj_loss: 0.1546  noobj_loss: 0.1259  bbox_loss: 0.0060  cls_loss: 0.0082  \n",
      "<<<iteration:[400/525] - total_loss: 0.2536  obj_loss: 0.1533  noobj_loss: 0.1244  bbox_loss: 0.0057  cls_loss: 0.0093  \n",
      "<<<iteration:[420/525] - total_loss: 0.2366  obj_loss: 0.1442  noobj_loss: 0.1124  bbox_loss: 0.0058  cls_loss: 0.0073  \n",
      "<<<iteration:[440/525] - total_loss: 0.2641  obj_loss: 0.1564  noobj_loss: 0.1349  bbox_loss: 0.0065  cls_loss: 0.0078  \n",
      "<<<iteration:[460/525] - total_loss: 0.2580  obj_loss: 0.1630  noobj_loss: 0.1277  bbox_loss: 0.0051  cls_loss: 0.0057  \n",
      "<<<iteration:[480/525] - total_loss: 0.2441  obj_loss: 0.1452  noobj_loss: 0.1150  bbox_loss: 0.0070  cls_loss: 0.0065  \n",
      "<<<iteration:[500/525] - total_loss: 0.2650  obj_loss: 0.1582  noobj_loss: 0.1233  bbox_loss: 0.0063  cls_loss: 0.0135  \n",
      "<<<iteration:[520/525] - total_loss: 0.2686  obj_loss: 0.1630  noobj_loss: 0.1250  bbox_loss: 0.0065  cls_loss: 0.0104  \n",
      "\n",
      "epoch:89/100 - Train Loss: 0.2526, Val Loss: 0.2568\n",
      "\n",
      "<<<iteration:[20/525] - total_loss: 0.2607  obj_loss: 0.1622  noobj_loss: 0.1315  bbox_loss: 0.0055  cls_loss: 0.0055  \n",
      "<<<iteration:[40/525] - total_loss: 0.2652  obj_loss: 0.1554  noobj_loss: 0.1232  bbox_loss: 0.0065  cls_loss: 0.0157  \n",
      "<<<iteration:[60/525] - total_loss: 0.2377  obj_loss: 0.1446  noobj_loss: 0.1209  bbox_loss: 0.0050  cls_loss: 0.0078  \n",
      "<<<iteration:[80/525] - total_loss: 0.2497  obj_loss: 0.1469  noobj_loss: 0.1280  bbox_loss: 0.0047  cls_loss: 0.0153  \n",
      "<<<iteration:[100/525] - total_loss: 0.2369  obj_loss: 0.1474  noobj_loss: 0.1172  bbox_loss: 0.0051  cls_loss: 0.0055  \n",
      "<<<iteration:[120/525] - total_loss: 0.2709  obj_loss: 0.1590  noobj_loss: 0.1293  bbox_loss: 0.0065  cls_loss: 0.0149  \n",
      "<<<iteration:[140/525] - total_loss: 0.2618  obj_loss: 0.1615  noobj_loss: 0.1204  bbox_loss: 0.0057  cls_loss: 0.0118  \n",
      "<<<iteration:[160/525] - total_loss: 0.2460  obj_loss: 0.1468  noobj_loss: 0.1253  bbox_loss: 0.0054  cls_loss: 0.0096  \n",
      "<<<iteration:[180/525] - total_loss: 0.2569  obj_loss: 0.1623  noobj_loss: 0.1193  bbox_loss: 0.0054  cls_loss: 0.0078  \n",
      "<<<iteration:[200/525] - total_loss: 0.2744  obj_loss: 0.1576  noobj_loss: 0.1410  bbox_loss: 0.0075  cls_loss: 0.0089  \n",
      "<<<iteration:[220/525] - total_loss: 0.2548  obj_loss: 0.1572  noobj_loss: 0.1202  bbox_loss: 0.0057  cls_loss: 0.0092  \n",
      "<<<iteration:[240/525] - total_loss: 0.2583  obj_loss: 0.1580  noobj_loss: 0.1353  bbox_loss: 0.0053  cls_loss: 0.0064  \n",
      "<<<iteration:[260/525] - total_loss: 0.2422  obj_loss: 0.1448  noobj_loss: 0.1178  bbox_loss: 0.0058  cls_loss: 0.0094  \n",
      "<<<iteration:[280/525] - total_loss: 0.2532  obj_loss: 0.1521  noobj_loss: 0.1307  bbox_loss: 0.0060  cls_loss: 0.0056  \n",
      "<<<iteration:[300/525] - total_loss: 0.2486  obj_loss: 0.1530  noobj_loss: 0.1243  bbox_loss: 0.0056  cls_loss: 0.0054  \n",
      "<<<iteration:[320/525] - total_loss: 0.2405  obj_loss: 0.1368  noobj_loss: 0.1129  bbox_loss: 0.0070  cls_loss: 0.0123  \n",
      "<<<iteration:[340/525] - total_loss: 0.2460  obj_loss: 0.1543  noobj_loss: 0.1194  bbox_loss: 0.0051  cls_loss: 0.0066  \n",
      "<<<iteration:[360/525] - total_loss: 0.2527  obj_loss: 0.1469  noobj_loss: 0.1267  bbox_loss: 0.0058  cls_loss: 0.0135  \n",
      "<<<iteration:[380/525] - total_loss: 0.2493  obj_loss: 0.1507  noobj_loss: 0.1226  bbox_loss: 0.0055  cls_loss: 0.0096  \n",
      "<<<iteration:[400/525] - total_loss: 0.2492  obj_loss: 0.1511  noobj_loss: 0.1213  bbox_loss: 0.0061  cls_loss: 0.0069  \n",
      "<<<iteration:[420/525] - total_loss: 0.2595  obj_loss: 0.1680  noobj_loss: 0.1197  bbox_loss: 0.0051  cls_loss: 0.0063  \n",
      "<<<iteration:[440/525] - total_loss: 0.2484  obj_loss: 0.1524  noobj_loss: 0.1277  bbox_loss: 0.0052  cls_loss: 0.0063  \n",
      "<<<iteration:[460/525] - total_loss: 0.2637  obj_loss: 0.1557  noobj_loss: 0.1290  bbox_loss: 0.0070  cls_loss: 0.0084  \n",
      "<<<iteration:[480/525] - total_loss: 0.2466  obj_loss: 0.1438  noobj_loss: 0.1217  bbox_loss: 0.0061  cls_loss: 0.0115  \n",
      "<<<iteration:[500/525] - total_loss: 0.2504  obj_loss: 0.1487  noobj_loss: 0.1185  bbox_loss: 0.0065  cls_loss: 0.0099  \n",
      "<<<iteration:[520/525] - total_loss: 0.2488  obj_loss: 0.1420  noobj_loss: 0.1185  bbox_loss: 0.0059  cls_loss: 0.0179  \n",
      "\n",
      "epoch:90/100 - Train Loss: 0.2521, Val Loss: 0.2489\n",
      "\n",
      "<<<iteration:[20/525] - total_loss: 0.2789  obj_loss: 0.1698  noobj_loss: 0.1433  bbox_loss: 0.0060  cls_loss: 0.0075  \n",
      "<<<iteration:[40/525] - total_loss: 0.2656  obj_loss: 0.1628  noobj_loss: 0.1219  bbox_loss: 0.0064  cls_loss: 0.0097  \n",
      "<<<iteration:[60/525] - total_loss: 0.2580  obj_loss: 0.1576  noobj_loss: 0.1274  bbox_loss: 0.0052  cls_loss: 0.0105  \n",
      "<<<iteration:[80/525] - total_loss: 0.2408  obj_loss: 0.1379  noobj_loss: 0.1222  bbox_loss: 0.0064  cls_loss: 0.0098  \n",
      "<<<iteration:[100/525] - total_loss: 0.2378  obj_loss: 0.1456  noobj_loss: 0.1289  bbox_loss: 0.0045  cls_loss: 0.0053  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<<<iteration:[120/525] - total_loss: 0.2435  obj_loss: 0.1424  noobj_loss: 0.1193  bbox_loss: 0.0065  cls_loss: 0.0092  \n",
      "<<<iteration:[140/525] - total_loss: 0.2570  obj_loss: 0.1518  noobj_loss: 0.1257  bbox_loss: 0.0060  cls_loss: 0.0123  \n",
      "<<<iteration:[160/525] - total_loss: 0.2574  obj_loss: 0.1536  noobj_loss: 0.1337  bbox_loss: 0.0063  cls_loss: 0.0056  \n",
      "<<<iteration:[180/525] - total_loss: 0.2300  obj_loss: 0.1324  noobj_loss: 0.1197  bbox_loss: 0.0058  cls_loss: 0.0087  \n",
      "<<<iteration:[200/525] - total_loss: 0.2921  obj_loss: 0.1719  noobj_loss: 0.1232  bbox_loss: 0.0069  cls_loss: 0.0240  \n",
      "<<<iteration:[220/525] - total_loss: 0.2398  obj_loss: 0.1445  noobj_loss: 0.1191  bbox_loss: 0.0058  cls_loss: 0.0069  \n",
      "<<<iteration:[240/525] - total_loss: 0.2716  obj_loss: 0.1664  noobj_loss: 0.1312  bbox_loss: 0.0060  cls_loss: 0.0097  \n",
      "<<<iteration:[260/525] - total_loss: 0.2537  obj_loss: 0.1479  noobj_loss: 0.1295  bbox_loss: 0.0057  cls_loss: 0.0123  \n",
      "<<<iteration:[280/525] - total_loss: 0.2524  obj_loss: 0.1538  noobj_loss: 0.1157  bbox_loss: 0.0058  cls_loss: 0.0116  \n",
      "<<<iteration:[300/525] - total_loss: 0.2574  obj_loss: 0.1551  noobj_loss: 0.1248  bbox_loss: 0.0061  cls_loss: 0.0092  \n",
      "<<<iteration:[320/525] - total_loss: 0.2375  obj_loss: 0.1445  noobj_loss: 0.1130  bbox_loss: 0.0055  cls_loss: 0.0091  \n",
      "<<<iteration:[340/525] - total_loss: 0.2351  obj_loss: 0.1398  noobj_loss: 0.1198  bbox_loss: 0.0052  cls_loss: 0.0096  \n",
      "<<<iteration:[360/525] - total_loss: 0.2449  obj_loss: 0.1305  noobj_loss: 0.1181  bbox_loss: 0.0079  cls_loss: 0.0159  \n",
      "<<<iteration:[380/525] - total_loss: 0.2454  obj_loss: 0.1401  noobj_loss: 0.1188  bbox_loss: 0.0068  cls_loss: 0.0119  \n",
      "<<<iteration:[400/525] - total_loss: 0.2499  obj_loss: 0.1515  noobj_loss: 0.1178  bbox_loss: 0.0058  cls_loss: 0.0104  \n",
      "<<<iteration:[420/525] - total_loss: 0.2504  obj_loss: 0.1572  noobj_loss: 0.1294  bbox_loss: 0.0047  cls_loss: 0.0050  \n",
      "<<<iteration:[440/525] - total_loss: 0.2698  obj_loss: 0.1655  noobj_loss: 0.1305  bbox_loss: 0.0060  cls_loss: 0.0092  \n",
      "<<<iteration:[460/525] - total_loss: 0.2516  obj_loss: 0.1476  noobj_loss: 0.1250  bbox_loss: 0.0052  cls_loss: 0.0158  \n",
      "<<<iteration:[480/525] - total_loss: 0.2596  obj_loss: 0.1529  noobj_loss: 0.1361  bbox_loss: 0.0060  cls_loss: 0.0086  \n",
      "<<<iteration:[500/525] - total_loss: 0.2519  obj_loss: 0.1518  noobj_loss: 0.1223  bbox_loss: 0.0060  cls_loss: 0.0088  \n",
      "<<<iteration:[520/525] - total_loss: 0.2265  obj_loss: 0.1291  noobj_loss: 0.1165  bbox_loss: 0.0066  cls_loss: 0.0062  \n",
      "\n",
      "epoch:91/100 - Train Loss: 0.2517, Val Loss: 0.2577\n",
      "\n",
      "<<<iteration:[20/525] - total_loss: 0.2648  obj_loss: 0.1575  noobj_loss: 0.1320  bbox_loss: 0.0060  cls_loss: 0.0111  \n",
      "<<<iteration:[40/525] - total_loss: 0.2311  obj_loss: 0.1393  noobj_loss: 0.1157  bbox_loss: 0.0057  cls_loss: 0.0057  \n",
      "<<<iteration:[60/525] - total_loss: 0.2566  obj_loss: 0.1564  noobj_loss: 0.1246  bbox_loss: 0.0059  cls_loss: 0.0085  \n",
      "<<<iteration:[80/525] - total_loss: 0.2483  obj_loss: 0.1428  noobj_loss: 0.1250  bbox_loss: 0.0059  cls_loss: 0.0135  \n",
      "<<<iteration:[100/525] - total_loss: 0.2518  obj_loss: 0.1527  noobj_loss: 0.1231  bbox_loss: 0.0061  cls_loss: 0.0072  \n",
      "<<<iteration:[120/525] - total_loss: 0.2692  obj_loss: 0.1618  noobj_loss: 0.1298  bbox_loss: 0.0062  cls_loss: 0.0115  \n",
      "<<<iteration:[140/525] - total_loss: 0.2476  obj_loss: 0.1509  noobj_loss: 0.1170  bbox_loss: 0.0065  cls_loss: 0.0057  \n",
      "<<<iteration:[160/525] - total_loss: 0.2453  obj_loss: 0.1482  noobj_loss: 0.1194  bbox_loss: 0.0052  cls_loss: 0.0113  \n",
      "<<<iteration:[180/525] - total_loss: 0.2614  obj_loss: 0.1595  noobj_loss: 0.1281  bbox_loss: 0.0060  cls_loss: 0.0078  \n",
      "<<<iteration:[200/525] - total_loss: 0.2698  obj_loss: 0.1702  noobj_loss: 0.1223  bbox_loss: 0.0057  cls_loss: 0.0100  \n",
      "<<<iteration:[220/525] - total_loss: 0.2471  obj_loss: 0.1502  noobj_loss: 0.1180  bbox_loss: 0.0061  cls_loss: 0.0074  \n",
      "<<<iteration:[240/525] - total_loss: 0.2395  obj_loss: 0.1447  noobj_loss: 0.1179  bbox_loss: 0.0054  cls_loss: 0.0089  \n",
      "<<<iteration:[260/525] - total_loss: 0.2483  obj_loss: 0.1519  noobj_loss: 0.1248  bbox_loss: 0.0046  cls_loss: 0.0108  \n",
      "<<<iteration:[280/525] - total_loss: 0.2500  obj_loss: 0.1550  noobj_loss: 0.1284  bbox_loss: 0.0052  cls_loss: 0.0047  \n",
      "<<<iteration:[300/525] - total_loss: 0.2339  obj_loss: 0.1306  noobj_loss: 0.1333  bbox_loss: 0.0056  cls_loss: 0.0087  \n",
      "<<<iteration:[320/525] - total_loss: 0.2623  obj_loss: 0.1583  noobj_loss: 0.1203  bbox_loss: 0.0065  cls_loss: 0.0112  \n",
      "<<<iteration:[340/525] - total_loss: 0.2389  obj_loss: 0.1486  noobj_loss: 0.1154  bbox_loss: 0.0046  cls_loss: 0.0094  \n",
      "<<<iteration:[360/525] - total_loss: 0.2450  obj_loss: 0.1369  noobj_loss: 0.1289  bbox_loss: 0.0060  cls_loss: 0.0135  \n",
      "<<<iteration:[380/525] - total_loss: 0.2489  obj_loss: 0.1547  noobj_loss: 0.1210  bbox_loss: 0.0051  cls_loss: 0.0079  \n",
      "<<<iteration:[400/525] - total_loss: 0.2701  obj_loss: 0.1682  noobj_loss: 0.1275  bbox_loss: 0.0051  cls_loss: 0.0125  \n",
      "<<<iteration:[420/525] - total_loss: 0.2473  obj_loss: 0.1473  noobj_loss: 0.1210  bbox_loss: 0.0066  cls_loss: 0.0067  \n",
      "<<<iteration:[440/525] - total_loss: 0.2699  obj_loss: 0.1646  noobj_loss: 0.1293  bbox_loss: 0.0062  cls_loss: 0.0096  \n",
      "<<<iteration:[460/525] - total_loss: 0.2456  obj_loss: 0.1437  noobj_loss: 0.1352  bbox_loss: 0.0054  cls_loss: 0.0072  \n",
      "<<<iteration:[480/525] - total_loss: 0.2591  obj_loss: 0.1603  noobj_loss: 0.1243  bbox_loss: 0.0052  cls_loss: 0.0107  \n",
      "<<<iteration:[500/525] - total_loss: 0.2484  obj_loss: 0.1492  noobj_loss: 0.1198  bbox_loss: 0.0062  cls_loss: 0.0083  \n",
      "<<<iteration:[520/525] - total_loss: 0.2460  obj_loss: 0.1512  noobj_loss: 0.1120  bbox_loss: 0.0062  cls_loss: 0.0077  \n",
      "\n",
      "epoch:92/100 - Train Loss: 0.2511, Val Loss: 0.2584\n",
      "\n",
      "<<<iteration:[20/525] - total_loss: 0.2540  obj_loss: 0.1469  noobj_loss: 0.1375  bbox_loss: 0.0064  cls_loss: 0.0063  \n",
      "<<<iteration:[40/525] - total_loss: 0.2514  obj_loss: 0.1535  noobj_loss: 0.1176  bbox_loss: 0.0059  cls_loss: 0.0096  \n",
      "<<<iteration:[60/525] - total_loss: 0.2856  obj_loss: 0.1754  noobj_loss: 0.1315  bbox_loss: 0.0063  cls_loss: 0.0129  \n",
      "<<<iteration:[80/525] - total_loss: 0.2335  obj_loss: 0.1429  noobj_loss: 0.1184  bbox_loss: 0.0053  cls_loss: 0.0048  \n",
      "<<<iteration:[100/525] - total_loss: 0.2448  obj_loss: 0.1553  noobj_loss: 0.1092  bbox_loss: 0.0053  cls_loss: 0.0085  \n",
      "<<<iteration:[120/525] - total_loss: 0.2299  obj_loss: 0.1360  noobj_loss: 0.1214  bbox_loss: 0.0049  cls_loss: 0.0087  \n",
      "<<<iteration:[140/525] - total_loss: 0.2574  obj_loss: 0.1610  noobj_loss: 0.1210  bbox_loss: 0.0054  cls_loss: 0.0089  \n",
      "<<<iteration:[160/525] - total_loss: 0.2471  obj_loss: 0.1432  noobj_loss: 0.1227  bbox_loss: 0.0059  cls_loss: 0.0130  \n",
      "<<<iteration:[180/525] - total_loss: 0.2581  obj_loss: 0.1559  noobj_loss: 0.1238  bbox_loss: 0.0055  cls_loss: 0.0130  \n",
      "<<<iteration:[200/525] - total_loss: 0.2307  obj_loss: 0.1322  noobj_loss: 0.1185  bbox_loss: 0.0055  cls_loss: 0.0117  \n",
      "<<<iteration:[220/525] - total_loss: 0.2434  obj_loss: 0.1474  noobj_loss: 0.1265  bbox_loss: 0.0054  cls_loss: 0.0059  \n",
      "<<<iteration:[240/525] - total_loss: 0.2664  obj_loss: 0.1628  noobj_loss: 0.1182  bbox_loss: 0.0068  cls_loss: 0.0106  \n",
      "<<<iteration:[260/525] - total_loss: 0.2666  obj_loss: 0.1652  noobj_loss: 0.1362  bbox_loss: 0.0056  cls_loss: 0.0054  \n",
      "<<<iteration:[280/525] - total_loss: 0.2605  obj_loss: 0.1590  noobj_loss: 0.1332  bbox_loss: 0.0057  cls_loss: 0.0064  \n",
      "<<<iteration:[300/525] - total_loss: 0.2519  obj_loss: 0.1512  noobj_loss: 0.1321  bbox_loss: 0.0052  cls_loss: 0.0084  \n",
      "<<<iteration:[320/525] - total_loss: 0.2676  obj_loss: 0.1597  noobj_loss: 0.1311  bbox_loss: 0.0062  cls_loss: 0.0116  \n",
      "<<<iteration:[340/525] - total_loss: 0.2839  obj_loss: 0.1771  noobj_loss: 0.1275  bbox_loss: 0.0059  cls_loss: 0.0137  \n",
      "<<<iteration:[360/525] - total_loss: 0.2236  obj_loss: 0.1280  noobj_loss: 0.1287  bbox_loss: 0.0048  cls_loss: 0.0073  \n",
      "<<<iteration:[380/525] - total_loss: 0.2727  obj_loss: 0.1653  noobj_loss: 0.1206  bbox_loss: 0.0075  cls_loss: 0.0095  \n",
      "<<<iteration:[400/525] - total_loss: 0.2363  obj_loss: 0.1410  noobj_loss: 0.1262  bbox_loss: 0.0056  cls_loss: 0.0041  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<<<iteration:[420/525] - total_loss: 0.2703  obj_loss: 0.1669  noobj_loss: 0.1347  bbox_loss: 0.0049  cls_loss: 0.0114  \n",
      "<<<iteration:[440/525] - total_loss: 0.2216  obj_loss: 0.1253  noobj_loss: 0.1197  bbox_loss: 0.0060  cls_loss: 0.0065  \n",
      "<<<iteration:[460/525] - total_loss: 0.2370  obj_loss: 0.1372  noobj_loss: 0.1207  bbox_loss: 0.0056  cls_loss: 0.0113  \n",
      "<<<iteration:[480/525] - total_loss: 0.2547  obj_loss: 0.1618  noobj_loss: 0.1193  bbox_loss: 0.0053  cls_loss: 0.0070  \n",
      "<<<iteration:[500/525] - total_loss: 0.2508  obj_loss: 0.1507  noobj_loss: 0.1322  bbox_loss: 0.0056  cls_loss: 0.0060  \n",
      "<<<iteration:[520/525] - total_loss: 0.2647  obj_loss: 0.1733  noobj_loss: 0.1212  bbox_loss: 0.0045  cls_loss: 0.0083  \n",
      "\n",
      "epoch:93/100 - Train Loss: 0.2518, Val Loss: 0.2607\n",
      "\n",
      "<<<iteration:[20/525] - total_loss: 0.2728  obj_loss: 0.1731  noobj_loss: 0.1273  bbox_loss: 0.0056  cls_loss: 0.0078  \n",
      "<<<iteration:[40/525] - total_loss: 0.2560  obj_loss: 0.1612  noobj_loss: 0.1205  bbox_loss: 0.0050  cls_loss: 0.0095  \n",
      "<<<iteration:[60/525] - total_loss: 0.2467  obj_loss: 0.1403  noobj_loss: 0.1262  bbox_loss: 0.0061  cls_loss: 0.0129  \n",
      "<<<iteration:[80/525] - total_loss: 0.2415  obj_loss: 0.1395  noobj_loss: 0.1282  bbox_loss: 0.0055  cls_loss: 0.0102  \n",
      "<<<iteration:[100/525] - total_loss: 0.2553  obj_loss: 0.1598  noobj_loss: 0.1344  bbox_loss: 0.0045  cls_loss: 0.0057  \n",
      "<<<iteration:[120/525] - total_loss: 0.2579  obj_loss: 0.1558  noobj_loss: 0.1254  bbox_loss: 0.0061  cls_loss: 0.0090  \n",
      "<<<iteration:[140/525] - total_loss: 0.2473  obj_loss: 0.1544  noobj_loss: 0.1220  bbox_loss: 0.0052  cls_loss: 0.0059  \n",
      "<<<iteration:[160/525] - total_loss: 0.2239  obj_loss: 0.1237  noobj_loss: 0.1153  bbox_loss: 0.0071  cls_loss: 0.0072  \n",
      "<<<iteration:[180/525] - total_loss: 0.2582  obj_loss: 0.1579  noobj_loss: 0.1286  bbox_loss: 0.0060  cls_loss: 0.0062  \n",
      "<<<iteration:[200/525] - total_loss: 0.2618  obj_loss: 0.1602  noobj_loss: 0.1272  bbox_loss: 0.0053  cls_loss: 0.0116  \n",
      "<<<iteration:[220/525] - total_loss: 0.2430  obj_loss: 0.1413  noobj_loss: 0.1241  bbox_loss: 0.0055  cls_loss: 0.0121  \n",
      "<<<iteration:[240/525] - total_loss: 0.2408  obj_loss: 0.1388  noobj_loss: 0.1204  bbox_loss: 0.0060  cls_loss: 0.0117  \n",
      "<<<iteration:[260/525] - total_loss: 0.2469  obj_loss: 0.1459  noobj_loss: 0.1130  bbox_loss: 0.0059  cls_loss: 0.0152  \n",
      "<<<iteration:[280/525] - total_loss: 0.2242  obj_loss: 0.1363  noobj_loss: 0.1115  bbox_loss: 0.0050  cls_loss: 0.0071  \n",
      "<<<iteration:[300/525] - total_loss: 0.2671  obj_loss: 0.1648  noobj_loss: 0.1367  bbox_loss: 0.0053  cls_loss: 0.0076  \n",
      "<<<iteration:[320/525] - total_loss: 0.2513  obj_loss: 0.1528  noobj_loss: 0.1319  bbox_loss: 0.0050  cls_loss: 0.0077  \n",
      "<<<iteration:[340/525] - total_loss: 0.2446  obj_loss: 0.1527  noobj_loss: 0.1123  bbox_loss: 0.0049  cls_loss: 0.0112  \n",
      "<<<iteration:[360/525] - total_loss: 0.2646  obj_loss: 0.1637  noobj_loss: 0.1298  bbox_loss: 0.0055  cls_loss: 0.0085  \n",
      "<<<iteration:[380/525] - total_loss: 0.2592  obj_loss: 0.1472  noobj_loss: 0.1329  bbox_loss: 0.0057  cls_loss: 0.0170  \n",
      "<<<iteration:[400/525] - total_loss: 0.2470  obj_loss: 0.1452  noobj_loss: 0.1319  bbox_loss: 0.0056  cls_loss: 0.0081  \n",
      "<<<iteration:[420/525] - total_loss: 0.2589  obj_loss: 0.1624  noobj_loss: 0.1260  bbox_loss: 0.0051  cls_loss: 0.0077  \n",
      "<<<iteration:[440/525] - total_loss: 0.2574  obj_loss: 0.1539  noobj_loss: 0.1270  bbox_loss: 0.0067  cls_loss: 0.0063  \n",
      "<<<iteration:[460/525] - total_loss: 0.2578  obj_loss: 0.1459  noobj_loss: 0.1254  bbox_loss: 0.0065  cls_loss: 0.0169  \n",
      "<<<iteration:[480/525] - total_loss: 0.2562  obj_loss: 0.1576  noobj_loss: 0.1229  bbox_loss: 0.0059  cls_loss: 0.0079  \n",
      "<<<iteration:[500/525] - total_loss: 0.2521  obj_loss: 0.1488  noobj_loss: 0.1278  bbox_loss: 0.0064  cls_loss: 0.0073  \n",
      "<<<iteration:[520/525] - total_loss: 0.2456  obj_loss: 0.1544  noobj_loss: 0.1197  bbox_loss: 0.0053  cls_loss: 0.0050  \n",
      "\n",
      "epoch:94/100 - Train Loss: 0.2511, Val Loss: 0.2542\n",
      "\n",
      "<<<iteration:[20/525] - total_loss: 0.2575  obj_loss: 0.1465  noobj_loss: 0.1347  bbox_loss: 0.0063  cls_loss: 0.0119  \n",
      "<<<iteration:[40/525] - total_loss: 0.2495  obj_loss: 0.1488  noobj_loss: 0.1249  bbox_loss: 0.0056  cls_loss: 0.0101  \n",
      "<<<iteration:[60/525] - total_loss: 0.2466  obj_loss: 0.1457  noobj_loss: 0.1160  bbox_loss: 0.0059  cls_loss: 0.0133  \n",
      "<<<iteration:[80/525] - total_loss: 0.2353  obj_loss: 0.1377  noobj_loss: 0.1223  bbox_loss: 0.0054  cls_loss: 0.0093  \n",
      "<<<iteration:[100/525] - total_loss: 0.2599  obj_loss: 0.1627  noobj_loss: 0.1271  bbox_loss: 0.0050  cls_loss: 0.0088  \n",
      "<<<iteration:[120/525] - total_loss: 0.2593  obj_loss: 0.1560  noobj_loss: 0.1275  bbox_loss: 0.0063  cls_loss: 0.0080  \n",
      "<<<iteration:[140/525] - total_loss: 0.2507  obj_loss: 0.1504  noobj_loss: 0.1259  bbox_loss: 0.0054  cls_loss: 0.0105  \n",
      "<<<iteration:[160/525] - total_loss: 0.2409  obj_loss: 0.1408  noobj_loss: 0.1243  bbox_loss: 0.0057  cls_loss: 0.0095  \n",
      "<<<iteration:[180/525] - total_loss: 0.2672  obj_loss: 0.1681  noobj_loss: 0.1276  bbox_loss: 0.0053  cls_loss: 0.0089  \n",
      "<<<iteration:[200/525] - total_loss: 0.2599  obj_loss: 0.1610  noobj_loss: 0.1276  bbox_loss: 0.0048  cls_loss: 0.0109  \n",
      "<<<iteration:[220/525] - total_loss: 0.2440  obj_loss: 0.1480  noobj_loss: 0.1277  bbox_loss: 0.0047  cls_loss: 0.0086  \n",
      "<<<iteration:[240/525] - total_loss: 0.2451  obj_loss: 0.1466  noobj_loss: 0.1277  bbox_loss: 0.0056  cls_loss: 0.0066  \n",
      "<<<iteration:[260/525] - total_loss: 0.2360  obj_loss: 0.1355  noobj_loss: 0.1254  bbox_loss: 0.0060  cls_loss: 0.0079  \n",
      "<<<iteration:[280/525] - total_loss: 0.2624  obj_loss: 0.1658  noobj_loss: 0.1125  bbox_loss: 0.0056  cls_loss: 0.0125  \n",
      "<<<iteration:[300/525] - total_loss: 0.2517  obj_loss: 0.1494  noobj_loss: 0.1281  bbox_loss: 0.0053  cls_loss: 0.0119  \n",
      "<<<iteration:[320/525] - total_loss: 0.2649  obj_loss: 0.1664  noobj_loss: 0.1261  bbox_loss: 0.0051  cls_loss: 0.0099  \n",
      "<<<iteration:[340/525] - total_loss: 0.2559  obj_loss: 0.1404  noobj_loss: 0.1324  bbox_loss: 0.0067  cls_loss: 0.0156  \n",
      "<<<iteration:[360/525] - total_loss: 0.2604  obj_loss: 0.1659  noobj_loss: 0.1230  bbox_loss: 0.0055  cls_loss: 0.0053  \n",
      "<<<iteration:[380/525] - total_loss: 0.2659  obj_loss: 0.1580  noobj_loss: 0.1326  bbox_loss: 0.0061  cls_loss: 0.0108  \n",
      "<<<iteration:[400/525] - total_loss: 0.2435  obj_loss: 0.1456  noobj_loss: 0.1241  bbox_loss: 0.0050  cls_loss: 0.0106  \n",
      "<<<iteration:[420/525] - total_loss: 0.2446  obj_loss: 0.1454  noobj_loss: 0.1276  bbox_loss: 0.0059  cls_loss: 0.0058  \n",
      "<<<iteration:[440/525] - total_loss: 0.2479  obj_loss: 0.1496  noobj_loss: 0.1251  bbox_loss: 0.0056  cls_loss: 0.0075  \n",
      "<<<iteration:[460/525] - total_loss: 0.2571  obj_loss: 0.1563  noobj_loss: 0.1225  bbox_loss: 0.0059  cls_loss: 0.0103  \n",
      "<<<iteration:[480/525] - total_loss: 0.2703  obj_loss: 0.1536  noobj_loss: 0.1278  bbox_loss: 0.0070  cls_loss: 0.0176  \n",
      "<<<iteration:[500/525] - total_loss: 0.2588  obj_loss: 0.1612  noobj_loss: 0.1281  bbox_loss: 0.0055  cls_loss: 0.0061  \n",
      "<<<iteration:[520/525] - total_loss: 0.2641  obj_loss: 0.1679  noobj_loss: 0.1286  bbox_loss: 0.0050  cls_loss: 0.0067  \n",
      "\n",
      "epoch:95/100 - Train Loss: 0.2529, Val Loss: 0.2558\n",
      "\n",
      "<<<iteration:[20/525] - total_loss: 0.2561  obj_loss: 0.1524  noobj_loss: 0.1379  bbox_loss: 0.0057  cls_loss: 0.0064  \n",
      "<<<iteration:[40/525] - total_loss: 0.2534  obj_loss: 0.1571  noobj_loss: 0.1295  bbox_loss: 0.0053  cls_loss: 0.0053  \n",
      "<<<iteration:[60/525] - total_loss: 0.2414  obj_loss: 0.1449  noobj_loss: 0.1287  bbox_loss: 0.0053  cls_loss: 0.0058  \n",
      "<<<iteration:[80/525] - total_loss: 0.2488  obj_loss: 0.1485  noobj_loss: 0.1357  bbox_loss: 0.0054  cls_loss: 0.0056  \n",
      "<<<iteration:[100/525] - total_loss: 0.2583  obj_loss: 0.1567  noobj_loss: 0.1345  bbox_loss: 0.0058  cls_loss: 0.0055  \n",
      "<<<iteration:[120/525] - total_loss: 0.2485  obj_loss: 0.1449  noobj_loss: 0.1359  bbox_loss: 0.0060  cls_loss: 0.0060  \n",
      "<<<iteration:[140/525] - total_loss: 0.2666  obj_loss: 0.1658  noobj_loss: 0.1329  bbox_loss: 0.0052  cls_loss: 0.0084  \n",
      "<<<iteration:[160/525] - total_loss: 0.2905  obj_loss: 0.1809  noobj_loss: 0.1333  bbox_loss: 0.0058  cls_loss: 0.0139  \n",
      "<<<iteration:[180/525] - total_loss: 0.2685  obj_loss: 0.1692  noobj_loss: 0.1304  bbox_loss: 0.0052  cls_loss: 0.0081  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<<<iteration:[200/525] - total_loss: 0.2678  obj_loss: 0.1618  noobj_loss: 0.1340  bbox_loss: 0.0062  cls_loss: 0.0077  \n",
      "<<<iteration:[220/525] - total_loss: 0.2494  obj_loss: 0.1465  noobj_loss: 0.1297  bbox_loss: 0.0053  cls_loss: 0.0114  \n",
      "<<<iteration:[240/525] - total_loss: 0.2594  obj_loss: 0.1593  noobj_loss: 0.1379  bbox_loss: 0.0048  cls_loss: 0.0070  \n",
      "<<<iteration:[260/525] - total_loss: 0.2394  obj_loss: 0.1403  noobj_loss: 0.1284  bbox_loss: 0.0056  cls_loss: 0.0068  \n",
      "<<<iteration:[280/525] - total_loss: 0.2604  obj_loss: 0.1590  noobj_loss: 0.1271  bbox_loss: 0.0057  cls_loss: 0.0091  \n",
      "<<<iteration:[300/525] - total_loss: 0.2595  obj_loss: 0.1579  noobj_loss: 0.1222  bbox_loss: 0.0066  cls_loss: 0.0077  \n",
      "<<<iteration:[320/525] - total_loss: 0.2654  obj_loss: 0.1647  noobj_loss: 0.1223  bbox_loss: 0.0060  cls_loss: 0.0094  \n",
      "<<<iteration:[340/525] - total_loss: 0.2466  obj_loss: 0.1553  noobj_loss: 0.1287  bbox_loss: 0.0044  cls_loss: 0.0049  \n",
      "<<<iteration:[360/525] - total_loss: 0.2473  obj_loss: 0.1431  noobj_loss: 0.1207  bbox_loss: 0.0067  cls_loss: 0.0106  \n",
      "<<<iteration:[380/525] - total_loss: 0.2526  obj_loss: 0.1402  noobj_loss: 0.1401  bbox_loss: 0.0060  cls_loss: 0.0124  \n",
      "<<<iteration:[400/525] - total_loss: 0.2460  obj_loss: 0.1398  noobj_loss: 0.1226  bbox_loss: 0.0058  cls_loss: 0.0162  \n",
      "<<<iteration:[420/525] - total_loss: 0.2551  obj_loss: 0.1566  noobj_loss: 0.1331  bbox_loss: 0.0048  cls_loss: 0.0081  \n",
      "<<<iteration:[440/525] - total_loss: 0.2749  obj_loss: 0.1727  noobj_loss: 0.1303  bbox_loss: 0.0058  cls_loss: 0.0082  \n",
      "<<<iteration:[460/525] - total_loss: 0.2473  obj_loss: 0.1414  noobj_loss: 0.1290  bbox_loss: 0.0066  cls_loss: 0.0085  \n",
      "<<<iteration:[480/525] - total_loss: 0.2464  obj_loss: 0.1495  noobj_loss: 0.1339  bbox_loss: 0.0048  cls_loss: 0.0060  \n",
      "<<<iteration:[500/525] - total_loss: 0.2537  obj_loss: 0.1554  noobj_loss: 0.1305  bbox_loss: 0.0052  cls_loss: 0.0071  \n",
      "<<<iteration:[520/525] - total_loss: 0.2326  obj_loss: 0.1409  noobj_loss: 0.1294  bbox_loss: 0.0045  cls_loss: 0.0044  \n",
      "\n",
      "epoch:96/100 - Train Loss: 0.2543, Val Loss: 0.2518\n",
      "\n",
      "<<<iteration:[20/525] - total_loss: 0.2623  obj_loss: 0.1579  noobj_loss: 0.1307  bbox_loss: 0.0065  cls_loss: 0.0067  \n",
      "<<<iteration:[40/525] - total_loss: 0.2492  obj_loss: 0.1524  noobj_loss: 0.1296  bbox_loss: 0.0052  cls_loss: 0.0058  \n",
      "<<<iteration:[60/525] - total_loss: 0.2670  obj_loss: 0.1591  noobj_loss: 0.1324  bbox_loss: 0.0059  cls_loss: 0.0121  \n",
      "<<<iteration:[80/525] - total_loss: 0.2811  obj_loss: 0.1739  noobj_loss: 0.1303  bbox_loss: 0.0057  cls_loss: 0.0136  \n",
      "<<<iteration:[100/525] - total_loss: 0.2531  obj_loss: 0.1516  noobj_loss: 0.1262  bbox_loss: 0.0056  cls_loss: 0.0102  \n",
      "<<<iteration:[120/525] - total_loss: 0.2453  obj_loss: 0.1444  noobj_loss: 0.1281  bbox_loss: 0.0060  cls_loss: 0.0070  \n",
      "<<<iteration:[140/525] - total_loss: 0.2510  obj_loss: 0.1529  noobj_loss: 0.1345  bbox_loss: 0.0045  cls_loss: 0.0084  \n",
      "<<<iteration:[160/525] - total_loss: 0.2481  obj_loss: 0.1451  noobj_loss: 0.1249  bbox_loss: 0.0059  cls_loss: 0.0111  \n",
      "<<<iteration:[180/525] - total_loss: 0.2543  obj_loss: 0.1548  noobj_loss: 0.1259  bbox_loss: 0.0056  cls_loss: 0.0082  \n",
      "<<<iteration:[200/525] - total_loss: 0.2545  obj_loss: 0.1546  noobj_loss: 0.1209  bbox_loss: 0.0062  cls_loss: 0.0086  \n",
      "<<<iteration:[220/525] - total_loss: 0.2522  obj_loss: 0.1470  noobj_loss: 0.1224  bbox_loss: 0.0065  cls_loss: 0.0116  \n",
      "<<<iteration:[240/525] - total_loss: 0.2370  obj_loss: 0.1468  noobj_loss: 0.1152  bbox_loss: 0.0050  cls_loss: 0.0076  \n",
      "<<<iteration:[260/525] - total_loss: 0.2552  obj_loss: 0.1468  noobj_loss: 0.1278  bbox_loss: 0.0067  cls_loss: 0.0109  \n",
      "<<<iteration:[280/525] - total_loss: 0.2621  obj_loss: 0.1580  noobj_loss: 0.1296  bbox_loss: 0.0051  cls_loss: 0.0141  \n",
      "<<<iteration:[300/525] - total_loss: 0.2550  obj_loss: 0.1555  noobj_loss: 0.1322  bbox_loss: 0.0055  cls_loss: 0.0059  \n",
      "<<<iteration:[320/525] - total_loss: 0.2623  obj_loss: 0.1659  noobj_loss: 0.1257  bbox_loss: 0.0051  cls_loss: 0.0078  \n",
      "<<<iteration:[340/525] - total_loss: 0.2403  obj_loss: 0.1363  noobj_loss: 0.1378  bbox_loss: 0.0054  cls_loss: 0.0080  \n",
      "<<<iteration:[360/525] - total_loss: 0.2371  obj_loss: 0.1379  noobj_loss: 0.1295  bbox_loss: 0.0055  cls_loss: 0.0071  \n",
      "<<<iteration:[380/525] - total_loss: 0.2384  obj_loss: 0.1332  noobj_loss: 0.1313  bbox_loss: 0.0061  cls_loss: 0.0088  \n",
      "<<<iteration:[400/525] - total_loss: 0.2530  obj_loss: 0.1462  noobj_loss: 0.1266  bbox_loss: 0.0061  cls_loss: 0.0130  \n",
      "<<<iteration:[420/525] - total_loss: 0.2275  obj_loss: 0.1272  noobj_loss: 0.1274  bbox_loss: 0.0058  cls_loss: 0.0076  \n",
      "<<<iteration:[440/525] - total_loss: 0.2558  obj_loss: 0.1566  noobj_loss: 0.1179  bbox_loss: 0.0065  cls_loss: 0.0075  \n",
      "<<<iteration:[460/525] - total_loss: 0.2848  obj_loss: 0.1633  noobj_loss: 0.1298  bbox_loss: 0.0064  cls_loss: 0.0244  \n",
      "<<<iteration:[480/525] - total_loss: 0.2533  obj_loss: 0.1604  noobj_loss: 0.1302  bbox_loss: 0.0043  cls_loss: 0.0060  \n",
      "<<<iteration:[500/525] - total_loss: 0.2521  obj_loss: 0.1511  noobj_loss: 0.1323  bbox_loss: 0.0051  cls_loss: 0.0094  \n",
      "<<<iteration:[520/525] - total_loss: 0.2350  obj_loss: 0.1332  noobj_loss: 0.1273  bbox_loss: 0.0057  cls_loss: 0.0097  \n",
      "\n",
      "epoch:97/100 - Train Loss: 0.2521, Val Loss: 0.2613\n",
      "\n",
      "<<<iteration:[20/525] - total_loss: 0.2767  obj_loss: 0.1643  noobj_loss: 0.1445  bbox_loss: 0.0067  cls_loss: 0.0068  \n",
      "<<<iteration:[40/525] - total_loss: 0.2323  obj_loss: 0.1334  noobj_loss: 0.1183  bbox_loss: 0.0062  cls_loss: 0.0090  \n",
      "<<<iteration:[60/525] - total_loss: 0.2835  obj_loss: 0.1877  noobj_loss: 0.1257  bbox_loss: 0.0054  cls_loss: 0.0059  \n",
      "<<<iteration:[80/525] - total_loss: 0.2505  obj_loss: 0.1481  noobj_loss: 0.1234  bbox_loss: 0.0058  cls_loss: 0.0118  \n",
      "<<<iteration:[100/525] - total_loss: 0.2568  obj_loss: 0.1519  noobj_loss: 0.1362  bbox_loss: 0.0059  cls_loss: 0.0071  \n",
      "<<<iteration:[120/525] - total_loss: 0.2526  obj_loss: 0.1559  noobj_loss: 0.1136  bbox_loss: 0.0060  cls_loss: 0.0097  \n",
      "<<<iteration:[140/525] - total_loss: 0.2231  obj_loss: 0.1281  noobj_loss: 0.1214  bbox_loss: 0.0050  cls_loss: 0.0093  \n",
      "<<<iteration:[160/525] - total_loss: 0.2595  obj_loss: 0.1606  noobj_loss: 0.1266  bbox_loss: 0.0052  cls_loss: 0.0094  \n",
      "<<<iteration:[180/525] - total_loss: 0.2541  obj_loss: 0.1430  noobj_loss: 0.1339  bbox_loss: 0.0062  cls_loss: 0.0132  \n",
      "<<<iteration:[200/525] - total_loss: 0.2622  obj_loss: 0.1578  noobj_loss: 0.1303  bbox_loss: 0.0065  cls_loss: 0.0069  \n",
      "<<<iteration:[220/525] - total_loss: 0.2582  obj_loss: 0.1637  noobj_loss: 0.1280  bbox_loss: 0.0044  cls_loss: 0.0083  \n",
      "<<<iteration:[240/525] - total_loss: 0.2740  obj_loss: 0.1644  noobj_loss: 0.1327  bbox_loss: 0.0064  cls_loss: 0.0115  \n",
      "<<<iteration:[260/525] - total_loss: 0.2452  obj_loss: 0.1462  noobj_loss: 0.1243  bbox_loss: 0.0056  cls_loss: 0.0090  \n",
      "<<<iteration:[280/525] - total_loss: 0.2552  obj_loss: 0.1488  noobj_loss: 0.1391  bbox_loss: 0.0052  cls_loss: 0.0107  \n",
      "<<<iteration:[300/525] - total_loss: 0.2624  obj_loss: 0.1548  noobj_loss: 0.1388  bbox_loss: 0.0052  cls_loss: 0.0122  \n",
      "<<<iteration:[320/525] - total_loss: 0.2676  obj_loss: 0.1669  noobj_loss: 0.1248  bbox_loss: 0.0055  cls_loss: 0.0110  \n",
      "<<<iteration:[340/525] - total_loss: 0.2584  obj_loss: 0.1426  noobj_loss: 0.1361  bbox_loss: 0.0062  cls_loss: 0.0168  \n",
      "<<<iteration:[360/525] - total_loss: 0.2547  obj_loss: 0.1494  noobj_loss: 0.1185  bbox_loss: 0.0065  cls_loss: 0.0136  \n",
      "<<<iteration:[380/525] - total_loss: 0.2469  obj_loss: 0.1502  noobj_loss: 0.1306  bbox_loss: 0.0052  cls_loss: 0.0057  \n",
      "<<<iteration:[400/525] - total_loss: 0.2428  obj_loss: 0.1492  noobj_loss: 0.1237  bbox_loss: 0.0051  cls_loss: 0.0060  \n",
      "<<<iteration:[420/525] - total_loss: 0.2489  obj_loss: 0.1495  noobj_loss: 0.1295  bbox_loss: 0.0056  cls_loss: 0.0067  \n",
      "<<<iteration:[440/525] - total_loss: 0.2705  obj_loss: 0.1647  noobj_loss: 0.1337  bbox_loss: 0.0053  cls_loss: 0.0125  \n",
      "<<<iteration:[460/525] - total_loss: 0.2595  obj_loss: 0.1587  noobj_loss: 0.1311  bbox_loss: 0.0054  cls_loss: 0.0083  \n",
      "<<<iteration:[480/525] - total_loss: 0.2568  obj_loss: 0.1569  noobj_loss: 0.1177  bbox_loss: 0.0060  cls_loss: 0.0109  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<<<iteration:[500/525] - total_loss: 0.2487  obj_loss: 0.1503  noobj_loss: 0.1393  bbox_loss: 0.0049  cls_loss: 0.0044  \n",
      "<<<iteration:[520/525] - total_loss: 0.2343  obj_loss: 0.1407  noobj_loss: 0.1282  bbox_loss: 0.0047  cls_loss: 0.0061  \n",
      "\n",
      "epoch:98/100 - Train Loss: 0.2549, Val Loss: 0.2608\n",
      "\n",
      "<<<iteration:[20/525] - total_loss: 0.2649  obj_loss: 0.1676  noobj_loss: 0.1381  bbox_loss: 0.0047  cls_loss: 0.0044  \n",
      "<<<iteration:[40/525] - total_loss: 0.2672  obj_loss: 0.1632  noobj_loss: 0.1297  bbox_loss: 0.0059  cls_loss: 0.0097  \n",
      "<<<iteration:[60/525] - total_loss: 0.2302  obj_loss: 0.1341  noobj_loss: 0.1287  bbox_loss: 0.0051  cls_loss: 0.0064  \n",
      "<<<iteration:[80/525] - total_loss: 0.2520  obj_loss: 0.1544  noobj_loss: 0.1389  bbox_loss: 0.0045  cls_loss: 0.0056  \n",
      "<<<iteration:[100/525] - total_loss: 0.2640  obj_loss: 0.1590  noobj_loss: 0.1331  bbox_loss: 0.0048  cls_loss: 0.0146  \n",
      "<<<iteration:[120/525] - total_loss: 0.2503  obj_loss: 0.1431  noobj_loss: 0.1344  bbox_loss: 0.0064  cls_loss: 0.0078  \n",
      "<<<iteration:[140/525] - total_loss: 0.2738  obj_loss: 0.1577  noobj_loss: 0.1360  bbox_loss: 0.0070  cls_loss: 0.0134  \n",
      "<<<iteration:[160/525] - total_loss: 0.2624  obj_loss: 0.1535  noobj_loss: 0.1319  bbox_loss: 0.0060  cls_loss: 0.0128  \n",
      "<<<iteration:[180/525] - total_loss: 0.2895  obj_loss: 0.1507  noobj_loss: 0.1441  bbox_loss: 0.0067  cls_loss: 0.0331  \n",
      "<<<iteration:[200/525] - total_loss: 0.2522  obj_loss: 0.1395  noobj_loss: 0.1358  bbox_loss: 0.0073  cls_loss: 0.0082  \n",
      "<<<iteration:[220/525] - total_loss: 0.2680  obj_loss: 0.1564  noobj_loss: 0.1358  bbox_loss: 0.0065  cls_loss: 0.0113  \n",
      "<<<iteration:[240/525] - total_loss: 0.2333  obj_loss: 0.1384  noobj_loss: 0.1212  bbox_loss: 0.0052  cls_loss: 0.0085  \n",
      "<<<iteration:[260/525] - total_loss: 0.2549  obj_loss: 0.1571  noobj_loss: 0.1209  bbox_loss: 0.0062  cls_loss: 0.0065  \n",
      "<<<iteration:[280/525] - total_loss: 0.2424  obj_loss: 0.1469  noobj_loss: 0.1247  bbox_loss: 0.0056  cls_loss: 0.0052  \n",
      "<<<iteration:[300/525] - total_loss: 0.2426  obj_loss: 0.1512  noobj_loss: 0.1277  bbox_loss: 0.0043  cls_loss: 0.0061  \n",
      "<<<iteration:[320/525] - total_loss: 0.2417  obj_loss: 0.1443  noobj_loss: 0.1203  bbox_loss: 0.0058  cls_loss: 0.0085  \n",
      "<<<iteration:[340/525] - total_loss: 0.2532  obj_loss: 0.1518  noobj_loss: 0.1283  bbox_loss: 0.0055  cls_loss: 0.0096  \n",
      "<<<iteration:[360/525] - total_loss: 0.2428  obj_loss: 0.1388  noobj_loss: 0.1270  bbox_loss: 0.0057  cls_loss: 0.0119  \n",
      "<<<iteration:[380/525] - total_loss: 0.2429  obj_loss: 0.1414  noobj_loss: 0.1341  bbox_loss: 0.0054  cls_loss: 0.0077  \n",
      "<<<iteration:[400/525] - total_loss: 0.2645  obj_loss: 0.1731  noobj_loss: 0.1250  bbox_loss: 0.0045  cls_loss: 0.0064  \n",
      "<<<iteration:[420/525] - total_loss: 0.2536  obj_loss: 0.1575  noobj_loss: 0.1245  bbox_loss: 0.0056  cls_loss: 0.0059  \n",
      "<<<iteration:[440/525] - total_loss: 0.2598  obj_loss: 0.1595  noobj_loss: 0.1295  bbox_loss: 0.0056  cls_loss: 0.0076  \n",
      "<<<iteration:[460/525] - total_loss: 0.2479  obj_loss: 0.1510  noobj_loss: 0.1253  bbox_loss: 0.0055  cls_loss: 0.0070  \n",
      "<<<iteration:[480/525] - total_loss: 0.2561  obj_loss: 0.1489  noobj_loss: 0.1486  bbox_loss: 0.0049  cls_loss: 0.0086  \n",
      "<<<iteration:[500/525] - total_loss: 0.2588  obj_loss: 0.1580  noobj_loss: 0.1210  bbox_loss: 0.0060  cls_loss: 0.0101  \n",
      "<<<iteration:[520/525] - total_loss: 0.2508  obj_loss: 0.1527  noobj_loss: 0.1354  bbox_loss: 0.0051  cls_loss: 0.0051  \n",
      "\n",
      "epoch:99/100 - Train Loss: 0.2541, Val Loss: 0.2623\n",
      "\n",
      "<<<iteration:[20/525] - total_loss: 0.2721  obj_loss: 0.1660  noobj_loss: 0.1313  bbox_loss: 0.0059  cls_loss: 0.0110  \n",
      "<<<iteration:[40/525] - total_loss: 0.2702  obj_loss: 0.1616  noobj_loss: 0.1241  bbox_loss: 0.0059  cls_loss: 0.0169  \n",
      "<<<iteration:[60/525] - total_loss: 0.2586  obj_loss: 0.1567  noobj_loss: 0.1329  bbox_loss: 0.0055  cls_loss: 0.0080  \n",
      "<<<iteration:[80/525] - total_loss: 0.2401  obj_loss: 0.1396  noobj_loss: 0.1367  bbox_loss: 0.0051  cls_loss: 0.0065  \n",
      "<<<iteration:[100/525] - total_loss: 0.2541  obj_loss: 0.1544  noobj_loss: 0.1347  bbox_loss: 0.0053  cls_loss: 0.0056  \n",
      "<<<iteration:[120/525] - total_loss: 0.2695  obj_loss: 0.1527  noobj_loss: 0.1422  bbox_loss: 0.0052  cls_loss: 0.0195  \n",
      "<<<iteration:[140/525] - total_loss: 0.2533  obj_loss: 0.1553  noobj_loss: 0.1265  bbox_loss: 0.0047  cls_loss: 0.0115  \n",
      "<<<iteration:[160/525] - total_loss: 0.2441  obj_loss: 0.1519  noobj_loss: 0.1252  bbox_loss: 0.0049  cls_loss: 0.0048  \n",
      "<<<iteration:[180/525] - total_loss: 0.2624  obj_loss: 0.1597  noobj_loss: 0.1361  bbox_loss: 0.0056  cls_loss: 0.0064  \n",
      "<<<iteration:[200/525] - total_loss: 0.2295  obj_loss: 0.1176  noobj_loss: 0.1218  bbox_loss: 0.0086  cls_loss: 0.0082  \n",
      "<<<iteration:[220/525] - total_loss: 0.2422  obj_loss: 0.1313  noobj_loss: 0.1145  bbox_loss: 0.0090  cls_loss: 0.0087  \n",
      "<<<iteration:[240/525] - total_loss: 0.2431  obj_loss: 0.1499  noobj_loss: 0.1201  bbox_loss: 0.0054  cls_loss: 0.0060  \n",
      "<<<iteration:[260/525] - total_loss: 0.2506  obj_loss: 0.1500  noobj_loss: 0.1300  bbox_loss: 0.0060  cls_loss: 0.0058  \n",
      "<<<iteration:[280/525] - total_loss: 0.2398  obj_loss: 0.1480  noobj_loss: 0.1241  bbox_loss: 0.0047  cls_loss: 0.0063  \n",
      "<<<iteration:[300/525] - total_loss: 0.2368  obj_loss: 0.1430  noobj_loss: 0.1286  bbox_loss: 0.0046  cls_loss: 0.0063  \n",
      "<<<iteration:[320/525] - total_loss: 0.2271  obj_loss: 0.1269  noobj_loss: 0.1202  bbox_loss: 0.0059  cls_loss: 0.0107  \n",
      "<<<iteration:[340/525] - total_loss: 0.2433  obj_loss: 0.1484  noobj_loss: 0.1258  bbox_loss: 0.0050  cls_loss: 0.0069  \n",
      "<<<iteration:[360/525] - total_loss: 0.2768  obj_loss: 0.1750  noobj_loss: 0.1294  bbox_loss: 0.0053  cls_loss: 0.0107  \n",
      "<<<iteration:[380/525] - total_loss: 0.2711  obj_loss: 0.1615  noobj_loss: 0.1441  bbox_loss: 0.0061  cls_loss: 0.0074  \n",
      "<<<iteration:[400/525] - total_loss: 0.2305  obj_loss: 0.1369  noobj_loss: 0.1254  bbox_loss: 0.0052  cls_loss: 0.0049  \n",
      "<<<iteration:[420/525] - total_loss: 0.2362  obj_loss: 0.1407  noobj_loss: 0.1258  bbox_loss: 0.0051  cls_loss: 0.0074  \n",
      "<<<iteration:[440/525] - total_loss: 0.2627  obj_loss: 0.1620  noobj_loss: 0.1232  bbox_loss: 0.0055  cls_loss: 0.0119  \n",
      "<<<iteration:[460/525] - total_loss: 0.2420  obj_loss: 0.1428  noobj_loss: 0.1348  bbox_loss: 0.0054  cls_loss: 0.0046  \n",
      "<<<iteration:[480/525] - total_loss: 0.2421  obj_loss: 0.1562  noobj_loss: 0.1202  bbox_loss: 0.0043  cls_loss: 0.0042  \n",
      "<<<iteration:[500/525] - total_loss: 0.2518  obj_loss: 0.1540  noobj_loss: 0.1287  bbox_loss: 0.0052  cls_loss: 0.0074  \n",
      "<<<iteration:[520/525] - total_loss: 0.2593  obj_loss: 0.1612  noobj_loss: 0.1170  bbox_loss: 0.0055  cls_loss: 0.0119  \n",
      "\n",
      "epoch:100/100 - Train Loss: 0.2502, Val Loss: 0.2685\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>Train Loss</td><td>█▂▁▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>Train bbox Loss</td><td>█▃▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>Train class Loss</td><td>█▄▃▃▂▂▂▂▂▂▂▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>Train obj Loss</td><td>▁▂▅▅▇▇▇████████████████▇▇██████▆▇▇▇▇▇▇▇▇</td></tr><tr><td>Val Loss</td><td>█▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>Val bbox Loss</td><td>█▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>Val class Loss</td><td>█▄▃▃▂▂▂▂▂▂▂▂▁▁▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>Val obj Loss</td><td>▁▄▆▆▇▇█▇█████▇█▇▇▇▇█▇▇▇▇▇▇▇▇▇▇▇▆▆▆▆▆▆▆▆▇</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>Train Loss</td><td>0.25024</td></tr><tr><td>Train bbox Loss</td><td>0.00558</td></tr><tr><td>Train class Loss</td><td>0.00841</td></tr><tr><td>Train obj Loss</td><td>0.1501</td></tr><tr><td>Val Loss</td><td>0.26846</td></tr><tr><td>Val bbox Loss</td><td>0.00763</td></tr><tr><td>Val class Loss</td><td>0.00489</td></tr><tr><td>Val obj Loss</td><td>0.15236</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">young-puddle-1</strong> at: <a href='https://wandb.ai/urp/yolo_swin_neck/runs/uqwmtmk5' target=\"_blank\">https://wandb.ai/urp/yolo_swin_neck/runs/uqwmtmk5</a><br/> View job at <a href='https://wandb.ai/urp/yolo_swin_neck/jobs/QXJ0aWZhY3RDb2xsZWN0aW9uOjEwNjc5NTc0OQ==/version_details/v0' target=\"_blank\">https://wandb.ai/urp/yolo_swin_neck/jobs/QXJ0aWZhY3RDb2xsZWN0aW9uOjEwNjc5NTc0OQ==/version_details/v0</a><br/>Synced 5 W&B file(s), 0 media file(s), 2 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20231014_160918-uqwmtmk5/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "best_epoch = 0\n",
    "best_score = float('inf')\n",
    "train_losses = []\n",
    "val_losses = []\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    train_loss, val_loss = train_one_epoch(dataloaders, model, criterion, optimizer, device)\n",
    "    train_losses.append(train_loss)\n",
    "    val_losses.append(val_loss)\n",
    "#     train_loss[\"obj_loss\"] += obj_loss\n",
    "#     train_loss[\"noobj_loss\"] += noobj_loss\n",
    "#     train_loss[\"bbox_loss\"] += bbox_loss\n",
    "#     train_loss[\"cls_loss\"] += cls_loss\n",
    "    wandb.log({\"Train Loss\": train_loss['total_loss'],\n",
    "               \"Train obj Loss\":train_loss[\"obj_loss\"],\n",
    "               \"Train bbox Loss\":train_loss[\"bbox_loss\"],\n",
    "               \"Train class Loss\":train_loss[\"cls_loss\"],\n",
    "               \"Val Loss\": val_loss['total_loss'],\n",
    "               \"Val obj Loss\":val_loss[\"obj_loss\"],\n",
    "               \"Val bbox Loss\":val_loss[\"bbox_loss\"],\n",
    "               \"Val class Loss\":val_loss[\"cls_loss\"],})\n",
    "    print(f\"\\nepoch:{epoch+1}/{num_epochs} - Train Loss: {train_loss['total_loss']:.4f}, Val Loss: {val_loss['total_loss']:.4f}\\n\")\n",
    "    \n",
    "    if (epoch+1) % 10 == 0:\n",
    "        save_model(model.state_dict(), f'model_{epoch+1}.pth', save_dir=f\"./trained_model/{BACKBONE}_{PART}_LR{LR}_AUG{AUG_FACTOR}\")\n",
    "wandb.finish()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4de7fe95",
   "metadata": {},
   "source": [
    "# Test Dataset Inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "b71f9334",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import os \n",
    "import pandas as pd\n",
    "import cv2\n",
    "import torch\n",
    "import matplotlib.pyplot as plt\n",
    "from ipywidgets import interact\n",
    "import albumentations as A\n",
    "from albumentations.pytorch import ToTensorV2\n",
    "import torchvision\n",
    "from torch import nn\n",
    "import torchsummary\n",
    "from torch.utils.data import DataLoader\n",
    "from collections import defaultdict\n",
    "from torchvision.utils import make_grid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "63f8dfc5",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "64dd5b10",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_model(ckpt_path, num_classes, device):\n",
    "    checkpoint = torch.load(ckpt_path, map_location=device)\n",
    "    model = YOLO_SWIN(num_classes=num_classes)\n",
    "    model.load_state_dict(checkpoint)\n",
    "    model = model.to(device)\n",
    "    model.eval()\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "4d80869e",
   "metadata": {},
   "outputs": [],
   "source": [
    "IMAGE_SIZE=448\n",
    "transformer = A.Compose([\n",
    "            A.Resize(height=IMAGE_SIZE, width=IMAGE_SIZE),\n",
    "            A.Normalize(mean=(0.485, 0.456, 0.406),std=(0.229, 0.224, 0.225)),\n",
    "            ToTensorV2(),\n",
    "        ],\n",
    "        bbox_params=A.BboxParams(format='yolo', label_fields=['class_ids']),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "76bcd114",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ckpt_path=\"./trained_model/YOLO_SWIN_T_body_LR0.0001_AUG30/model_90.pth\"\n",
    "ckpt_path=\"/workspace/Plastic_Bottle_defect_detection/trained_model/YOLO_SWIN_T_neck_LR0.0001_AUG20/model_100.pth\"\n",
    "model = load_model(ckpt_path, NUM_CLASSES, device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "0d42c594",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "start making augmented images-- augmented factor:0\n",
      "total length of augmented images: 0\n"
     ]
    }
   ],
   "source": [
    "NECK_PATH = '/home/host_data/PET_data/Neck'\n",
    "BODY_PATH = '/home/host_data/PET_data/Body'\n",
    "test_dataset=PET_dataset(\"neck\" ,neck_dir=NECK_PATH,body_dir=BODY_PATH,phase='test', transformer=transformer, aug=None)\n",
    "test_dataloaders = DataLoader(test_dataset, batch_size=1, shuffle=False, collate_fn=collate_fn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "07fed11f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "25"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(test_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "3709c974",
   "metadata": {},
   "outputs": [],
   "source": [
    "@torch.no_grad()\n",
    "def model_predict(image, model, conf_thres=0.2, iou_threshold=0.1):\n",
    "    predictions = model(image)\n",
    "    prediction = predictions.detach().cpu().squeeze(dim=0)\n",
    "#     print(prediction.shape)\n",
    "    \n",
    "    grid_size = prediction.shape[-1]\n",
    "    y_grid, x_grid = torch.meshgrid(torch.arange(grid_size), torch.arange(grid_size))\n",
    "    stride_size = IMAGE_SIZE/grid_size\n",
    "\n",
    "    conf = prediction[[0,5], ...].reshape(1, -1)\n",
    "    xc = (prediction[[1,6], ...] * IMAGE_SIZE + x_grid*stride_size).reshape(1,-1)\n",
    "    yc = (prediction[[2,7], ...] * IMAGE_SIZE + y_grid*stride_size).reshape(1,-1)\n",
    "    w = (prediction[[3,8], ...] * IMAGE_SIZE).reshape(1,-1)\n",
    "    h = (prediction[[4,9], ...] * IMAGE_SIZE).reshape(1,-1)\n",
    "    cls = torch.max(prediction[10:, ...].reshape(NUM_CLASSES, -1), dim=0).indices.tile(1,2)\n",
    "    \n",
    "    x_min = xc - w/2\n",
    "    y_min = yc - h/2\n",
    "    x_max = xc + w/2\n",
    "    y_max = yc + h/2\n",
    "\n",
    "    prediction_res = torch.cat([x_min, y_min, x_max, y_max, conf, cls], dim=0)\n",
    "    prediction_res = prediction_res.transpose(0,1)\n",
    "\n",
    "    # x_min과 y_min이 음수가 되지않고, x_max와 y_max가 이미지 크기를 넘지 않게 제한\n",
    "    prediction_res[:, 2].clip(min=0, max=image.shape[1]) \n",
    "    prediction_res[:, 3].clip(min=0, max=image.shape[0])\n",
    "        \n",
    "    pred_res = prediction_res[prediction_res[:, 4] > conf_thres]\n",
    "    nms_index = torchvision.ops.nms(boxes=pred_res[:, 0:4], scores=pred_res[:, 4], iou_threshold=iou_threshold)\n",
    "    pred_res_ = pred_res[nms_index].numpy()\n",
    "    \n",
    "    n_obj = pred_res_.shape[0]\n",
    "    bboxes = np.zeros(shape=(n_obj, 4), dtype=np.float32)\n",
    "    bboxes[:, 0:2] = (pred_res_[:, 0:2] + pred_res_[:, 2:4]) / 2\n",
    "    bboxes[:, 2:4] = pred_res_[:, 2:4] - pred_res_[:, 0:2]\n",
    "    scores = pred_res_[:, 4]\n",
    "    class_ids = pred_res_[:, 5]\n",
    "    \n",
    "    # 이미지 값이 들어가면 모델을 통해서, 후처리까지 포함된 yolo 포멧의 box좌표, 그 좌표에 대한 confidence score\n",
    "    # 그리고 class id를 반환\n",
    "    return bboxes, scores, class_ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "10dddcd9",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.8/dist-packages/torch/functional.py:504: UserWarning: torch.meshgrid: in an upcoming release, it will be required to pass the indexing argument. (Triggered internally at /opt/pytorch/pytorch/aten/src/ATen/native/TensorShape.cpp:3423.)\n",
      "  return _VF.meshgrid(tensors, **kwargs)  # type: ignore[attr-defined]\n"
     ]
    }
   ],
   "source": [
    "pred_images = []\n",
    "pred_labels =[]\n",
    "\n",
    "for index, batch in enumerate(test_dataloaders):\n",
    "    images = batch[0].to(device)\n",
    "    bboxes, scores, class_ids = model_predict(images, model, conf_thres=0.1, iou_threshold=0.1)\n",
    "    \n",
    "    if len(bboxes) > 0:\n",
    "        prediction_yolo = np.concatenate([bboxes, scores[:, np.newaxis], class_ids[:, np.newaxis]], axis=1)\n",
    "    else:\n",
    "        prediction_yolo = np.array([])\n",
    "    \n",
    "    # 텐서형의 이미지를 다시 unnormalize를 시키고, 다시 chw를 hwc로 바꾸고 넘파이로 바꾼다.\n",
    "    np_image = make_grid(images[0], normalize=True).cpu().permute(1,2,0).numpy()\n",
    "    pred_images.append(np_image)\n",
    "    pred_labels.append(prediction_yolo)\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "b07fa545",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f20d3fcf09fc4cf59e29766c77f20489",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "interactive(children=(IntSlider(value=0, description='index', max=24), Output()), _dom_classes=('widget-intera…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from ipywidgets import interact\n",
    "\n",
    "@interact(index=(0,len(pred_images)-1))\n",
    "def show_result(index=0):\n",
    "    print(pred_labels[index])\n",
    "    if len(pred_labels[index]) > 0:\n",
    "        result = visualize(pred_images[index], pred_labels[index][:, 0:4], pred_labels[index][:, 5])\n",
    "    else:\n",
    "        result = pred_images[index]\n",
    "        \n",
    "    plt.figure(figsize=(6,6))\n",
    "    plt.imshow(result)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24c0544e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
