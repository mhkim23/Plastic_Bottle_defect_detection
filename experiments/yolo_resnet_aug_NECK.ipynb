{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3c025da0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import os \n",
    "import pandas as pd\n",
    "import cv2\n",
    "import torch\n",
    "import matplotlib.pyplot as plt\n",
    "from ipywidgets import interact\n",
    "import albumentations as A\n",
    "from albumentations.pytorch import ToTensorV2\n",
    "import torchvision\n",
    "from torch import nn\n",
    "import torchsummary\n",
    "from torch.utils.data import DataLoader\n",
    "from collections import defaultdict\n",
    "from torchvision.utils import make_grid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5d503acd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cuda', index=0)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "device"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ee9eb3c",
   "metadata": {},
   "source": [
    "# Utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c7fac7d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "CLASS_NAME_TO_ID = {'Unformed': 0, 'Burr': 1}\n",
    "CLASS_ID_TO_NAME = {0: 'Unformed', 1: 'Burr'}\n",
    "BOX_COLOR = {'Unformed':(200, 0, 0), 'Burr':(0, 0, 200)}\n",
    "TEXT_COLOR = (255, 255, 255)\n",
    "\n",
    "def save_model(model_state, model_name, save_dir=\"./trained_model\"):\n",
    "    os.makedirs(save_dir, exist_ok=True)\n",
    "    torch.save(model_state, os.path.join(save_dir, model_name))\n",
    "\n",
    "\n",
    "def visualize_bbox(image, bbox, class_name, color=BOX_COLOR, thickness=2):\n",
    "    x_center, y_center, w, h = bbox\n",
    "    x_min = int(x_center - w/2)\n",
    "    y_min = int(y_center - h/2)\n",
    "    x_max = int(x_center + w/2)\n",
    "    y_max = int(y_center + h/2)\n",
    "    \n",
    "    cv2.rectangle(image, (x_min, y_min), (x_max, y_max), color=color[class_name], thickness=thickness)\n",
    "    \n",
    "    ((text_width, text_height), _) = cv2.getTextSize(class_name, cv2.FONT_HERSHEY_SIMPLEX, 0.35, 1)    \n",
    "    cv2.rectangle(image, (x_min, y_min - int(1.3 * text_height)), (x_min + text_width, y_min), color[class_name], -1)\n",
    "    cv2.putText(\n",
    "        image,\n",
    "        text=class_name,\n",
    "        org=(x_min, y_min - int(0.3 * text_height)),\n",
    "        fontFace=cv2.FONT_HERSHEY_SIMPLEX,\n",
    "        fontScale=0.35, \n",
    "        color=TEXT_COLOR, \n",
    "        lineType=cv2.LINE_AA,\n",
    "    )\n",
    "    return image\n",
    "\n",
    "\n",
    "def visualize(image, bboxes, category_ids):\n",
    "    img = image.copy()\n",
    "    for bbox, category_id in zip(bboxes, category_ids):\n",
    "#         print('category_id: ',category_id)\n",
    "        class_name = CLASS_ID_TO_NAME[category_id.item()]\n",
    "        img = visualize_bbox(img, bbox, class_name)\n",
    "    return img"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62c7da98",
   "metadata": {},
   "source": [
    "# Datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ea0166e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "class PET_dataset():\n",
    "    def __init__(self,part,neck_dir,body_dir,phase, transformer=None, aug=None, aug_factor=0):\n",
    "        self.neck_dir=neck_dir\n",
    "        self.body_dir=body_dir\n",
    "        self.part=part\n",
    "        self.phase=phase\n",
    "        self.transformer=transformer\n",
    "        self.aug=aug\n",
    "        self.aug_factor=aug_factor\n",
    "        if(self.part==\"body\"):\n",
    "            self.image_files = sorted([fn for fn in os.listdir(self.body_dir+\"/\"+self.phase+\"/image\") if fn.endswith(\"jpg\")])\n",
    "            self.label_files= sorted([lab for lab in os.listdir(self.body_dir+\"/\"+self.phase+\"/label\") if lab.endswith(\"txt\")])\n",
    "        elif(self.part==\"neck\"):\n",
    "            self.image_files = sorted([fn for fn in os.listdir(self.neck_dir+\"/\"+self.phase+\"/image\") if fn.endswith(\"jpg\")])\n",
    "            self.label_files= sorted([lab for lab in os.listdir(self.neck_dir+\"/\"+self.phase+\"/label\") if lab.endswith(\"txt\")])\n",
    "        \n",
    "        self.auged_img_list, self.auged_label_list=self.make_aug_list(self.image_files, self.label_files)\n",
    "        \n",
    "    def __getitem__(self,index):\n",
    "        if(self.aug==None):\n",
    "            filename, image = self.get_image(self.part, index)\n",
    "            bboxes, class_ids = self.get_label(self.part, index)\n",
    "\n",
    "            if(self.transformer):\n",
    "                transformed_data=self.transformer(image=image, bboxes=bboxes, class_ids=class_ids)\n",
    "                image = transformed_data['image']\n",
    "                bboxes = np.array(transformed_data['bboxes'])\n",
    "                class_ids = np.array(transformed_data['class_ids'])\n",
    "\n",
    "\n",
    "            target = {}\n",
    "    #         print(f'bboxes:{bboxes}\\nclass_ids:{class_ids}\\nlen_bboxes:{len(bboxes)}\\nlen_class_ids:{len(class_ids)}')\n",
    "    #         print(f'filename: {filename}')\n",
    "            target[\"boxes\"] = torch.Tensor(bboxes).float()\n",
    "            target[\"labels\"] = torch.Tensor(class_ids).long()\n",
    "\n",
    "            ###\n",
    "            bboxes=torch.Tensor(bboxes).float()\n",
    "            class_ids=torch.Tensor(class_ids).long()\n",
    "            target = np.concatenate((bboxes, class_ids[:, np.newaxis]), axis=1)\n",
    "            ###\n",
    "        else:\n",
    "            image=self.auged_img_list[index][1]\n",
    "            target=self.auged_label_list[index]\n",
    "            filename=self.auged_img_list[index][0]\n",
    "        return image, target, filename\n",
    "    \n",
    "    def __len__(self, ):\n",
    "        length=0\n",
    "        if(self.aug==None):\n",
    "            length=len(self.image_files)\n",
    "        else:\n",
    "            length=len(self.auged_img_list)\n",
    "        return length\n",
    "    \n",
    "    def make_aug_list(self,ori_image_list,ori_label_files):\n",
    "        aug_image_list=[]\n",
    "        aug_label_list=[]\n",
    "        \n",
    "        print(f\"start making augmented images-- augmented factor:{self.aug_factor}\")\n",
    "        for i in range(len(ori_image_list)):\n",
    "            filename, ori_image = self.get_image(self.part, i)\n",
    "            ori_bboxes, ori_class_ids = self.get_label(self.part, i)\n",
    "            for j in range(self.aug_factor):\n",
    "                auged_data=self.aug(image=ori_image, bboxes=ori_bboxes, class_ids=ori_class_ids)\n",
    "                image = auged_data['image']\n",
    "                bboxes = np.array(auged_data['bboxes'])\n",
    "                class_ids = np.array(auged_data['class_ids'])\n",
    "                \n",
    "                bboxes=torch.Tensor(bboxes).float()\n",
    "                class_ids=torch.Tensor(class_ids).long()\n",
    "                \n",
    "                aug_image_list.append((filename, image))\n",
    "                aug_label_list.append(np.concatenate((bboxes, class_ids[:, np.newaxis]), axis=1))\n",
    "        \n",
    "        print(f\"total length of augmented images: {len(aug_image_list)}\")\n",
    "        \n",
    "        return aug_image_list, aug_label_list\n",
    "        \n",
    "    \n",
    "    def get_image(self, part, index): # 이미지 불러오는 함수\n",
    "        filename = self.image_files[index]\n",
    "        if(part==\"body\"):\n",
    "#             print(f\"body called!-> {self.part}\")\n",
    "            image_path = self.body_dir+\"/\"+self.phase+\"/image/\"+filename\n",
    "        elif(part==\"neck\"):\n",
    "#             print(f\"neck called!-> {self.part}\")\n",
    "            image_path = self.neck_dir+\"/\"+self.phase+\"/image/\"+filename\n",
    "        image = cv2.imread(image_path)\n",
    "        image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "        return filename, image\n",
    "    \n",
    "    def get_label(self, part, index): # label (box좌표, class_id) 불러오는 함수\n",
    "        label_filename=self.label_files[index]\n",
    "        if(part==\"body\"):\n",
    "#             print(f\"body label called!-> {self.part}\")\n",
    "            label_path = self.body_dir+\"/\"+self.phase+\"/label/\"+label_filename\n",
    "        elif(part==\"neck\"):\n",
    "#             print(f\"neck label called!-> {self.part}\")\n",
    "            label_path = self.neck_dir+\"/\"+self.phase+\"/label/\"+label_filename\n",
    "        with open(label_path, 'r') as file:\n",
    "            labels = file.readlines()\n",
    "        \n",
    "        class_ids=[]\n",
    "        bboxes=[]\n",
    "        for label in labels:\n",
    "            label=label.replace(\"\\n\", \"\")\n",
    "            obj=label.split(' ')[0]\n",
    "            coor=label.split(' ')[1:]\n",
    "            obj=int(obj)\n",
    "            coor=list(map(float, coor))\n",
    "            class_ids.append(obj)\n",
    "            bboxes.append(coor)\n",
    "            \n",
    "        return bboxes, class_ids\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "235e7cec",
   "metadata": {},
   "outputs": [],
   "source": [
    "IMAGE_SIZE = 448\n",
    "\n",
    "transformer = A.Compose([ \n",
    "        # bounding box의 변환, augmentation에서 albumentations는 Detection 학습을 할 때 굉장히 유용하다. \n",
    "        A.Resize(height=IMAGE_SIZE, width=IMAGE_SIZE),\n",
    "        A.Normalize(mean=(0.485, 0.456, 0.406),std=(0.229, 0.224, 0.225)),\n",
    "        ToTensorV2(),\n",
    "        # albumentations 라이브러리에서는 Normalization을 먼저 진행해 주고 tensor화를 진행해 주어야한다.\n",
    "    ],\n",
    "    # box 위치에 대한 transformation도 함께 진행된다. \n",
    "    bbox_params=A.BboxParams(format='yolo', label_fields=['class_ids']),\n",
    ")\n",
    "\n",
    "augmentator=A.Compose([\n",
    "#     A.Resize(height=IMAGE_SIZE, width=IMAGE_SIZE),\n",
    "    A.HorizontalFlip(p=0.7),\n",
    "#     A.Sharpen(p=0.7),\n",
    "    A.BBoxSafeRandomCrop(p=0.6),\n",
    "    A.VerticalFlip (p=0.5),\n",
    "    A.HueSaturationValue(p=0.5),\n",
    "    A.Resize(height=IMAGE_SIZE, width=IMAGE_SIZE),\n",
    "    A.Normalize(mean=(0.485, 0.456, 0.406),std=(0.229, 0.224, 0.225)),\n",
    "    ToTensorV2(),\n",
    "    ],\n",
    "    bbox_params=A.BboxParams(format='yolo', label_fields=['class_ids']),\n",
    ")\n",
    "\n",
    "def collate_fn(batch):\n",
    "    image_list = []\n",
    "    target_list = []\n",
    "    filename_list = []\n",
    "    \n",
    "    for a,b,c in batch:\n",
    "        image_list.append(a)\n",
    "        target_list.append(b)\n",
    "        filename_list.append(c)\n",
    "\n",
    "    return torch.stack(image_list, dim=0), target_list, filename_list\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a6d5c32a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "start making augmented images-- augmented factor:20\n",
      "total length of augmented images: 4200\n",
      "start making augmented images-- augmented factor:0\n",
      "total length of augmented images: 0\n"
     ]
    }
   ],
   "source": [
    "NECK_PATH = '/home/host_data/PET_data/Neck'\n",
    "BODY_PATH = '/home/host_data/PET_data/Body'\n",
    "trainset_yes_aug=PET_dataset(part='neck',neck_dir=NECK_PATH,body_dir=BODY_PATH,phase='train', transformer=transformer, aug=augmentator, aug_factor=20)\n",
    "trainset_no_aug=PET_dataset(part='neck',neck_dir=NECK_PATH,body_dir=BODY_PATH,phase='train', transformer=transformer, aug=None)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c0fbcd25",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4200"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(trainset_yes_aug)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "5db4ebba",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d4b856c26c044a9ab78c8d7e31982d34",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "interactive(children=(IntSlider(value=0, description='index', max=209), Output()), _dom_classes=('widget-inter…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "@interact(index=(0, len(trainset_no_aug)-1))\n",
    "\n",
    "def show_sample(index=0):\n",
    "    image, target, filename = trainset_no_aug[index]\n",
    "    image=image.permute(1,2,0).numpy()\n",
    "    img_H, img_W, _ = image.shape\n",
    "    print(filename)\n",
    "    print(image.shape)\n",
    "#     print(image)\n",
    "\n",
    "#     bboxes = target['boxes']\n",
    "#     class_ids = target[\"labels\"]\n",
    "    \n",
    "    ###\n",
    "    bboxes = target[:, 0:4]\n",
    "    class_ids = target[:, 4]\n",
    "    ###\n",
    "    bboxes[:, [0,2]] *= img_W\n",
    "    bboxes[:, [1,3]] *= img_H\n",
    "\n",
    "    canvas = visualize(image, bboxes, class_ids)\n",
    "    plt.figure(figsize=(6,6))\n",
    "    plt.imshow(canvas)\n",
    "    plt.axis('off')\n",
    "    plt.show()\n",
    "\n",
    "# show_sample()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "5e341d7c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "02aba7bff687487d820693f0a6c1a896",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "interactive(children=(IntSlider(value=0, description='index', max=4199), Output()), _dom_classes=('widget-inte…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "@interact(index=(0, len(trainset_yes_aug)-1))\n",
    "\n",
    "def show_sample(index=0):\n",
    "    image, target, filename = trainset_yes_aug[index]\n",
    "    image=image.permute(1,2,0).numpy()\n",
    "    img_H, img_W, _ = image.shape\n",
    "    print(filename)\n",
    "    print(image.shape)\n",
    "#     print(image)\n",
    "\n",
    "#     bboxes = target['boxes']\n",
    "#     class_ids = target[\"labels\"]\n",
    "    ###\n",
    "    bboxes = target[:, 0:4]\n",
    "    class_ids = target[:, 4]\n",
    "    ###\n",
    "    bboxes[:, [0,2]] *= img_W\n",
    "    bboxes[:, [1,3]] *= img_H\n",
    "    print(bboxes)\n",
    "\n",
    "    canvas = visualize(image, bboxes, class_ids)\n",
    "    plt.figure(figsize=(6,6))\n",
    "    plt.imshow(canvas)\n",
    "    plt.axis('off')\n",
    "    plt.show()\n",
    "\n",
    "# show_sample()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f151003",
   "metadata": {},
   "source": [
    "## Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "729f2964",
   "metadata": {},
   "outputs": [],
   "source": [
    "class YOLO_RESNET18(nn.Module):\n",
    "    def __init__(self, num_classes):\n",
    "        super().__init__()\n",
    "\n",
    "        self.num_classes = num_classes\n",
    "        self.num_bboxes = 2\n",
    "        self.grid_size = 7\n",
    "\n",
    "        resnet18 = torchvision.models.resnet18(pretrained = True)\n",
    "        swin=torchvision.models.swin_v2_t(weights='IMAGENET1K_V1')\n",
    "        layers = [m for m in resnet18.children()] #Resnet에서 Yolo에서 가져올수 있을만한 layer만 선별적으로 가져오기 위해서\n",
    "\n",
    "        # 기존 Resnet18의 layer들중에서 맨 뒤에 두개만 제외하고 다 가져와서 Backbone으로 사용\n",
    "        self.backbone = nn.Sequential(*layers[:-2]) \n",
    "        self.head = nn.Sequential(\n",
    "                nn.Conv2d(in_channels=512, out_channels=1024, kernel_size=1, padding=0,bias=False),\n",
    "                nn.BatchNorm2d(1024),\n",
    "                nn.ReLU(inplace=True),\n",
    "                nn.Conv2d(in_channels=1024, out_channels=1024, kernel_size=3, padding=1,bias=False),\n",
    "                nn.BatchNorm2d(1024),\n",
    "                nn.ReLU(inplace=True),\n",
    "                nn.Conv2d(in_channels=1024, out_channels=1024, kernel_size=3, padding=1,bias=False),\n",
    "                nn.BatchNorm2d(1024),\n",
    "                nn.ReLU(inplace=True),\n",
    "                nn.Conv2d(in_channels=1024, out_channels=1024, kernel_size=3, padding=1,bias=False),\n",
    "                nn.BatchNorm2d(1024),\n",
    "                nn.ReLU(inplace=True),\n",
    "\n",
    "                nn.Conv2d(in_channels=1024, out_channels=(4+1)*self.num_bboxes+num_classes, kernel_size=1, padding=0, bias=False),\n",
    "                nn.AdaptiveAvgPool2d(output_size=(self.grid_size, self.grid_size))\n",
    "            )\n",
    "\n",
    "    def forward(self, x):\n",
    "        out = self.backbone(x)\n",
    "        # out = self.neck(out)\n",
    "        out = self.head(out) # input (batch, 3, 448, 448) -> output feature (batch, 12, 7, 7)\n",
    "        return out\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b0a6eb83",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.8/dist-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.8/dist-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ResNet18_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet18_Weights.DEFAULT` to get the most up-to-date weights.\n",
      "  warnings.warn(msg)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "YOLO_RESNET18(\n",
       "  (backbone): Sequential(\n",
       "    (0): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
       "    (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU(inplace=True)\n",
       "    (3): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
       "    (4): Sequential(\n",
       "      (0): BasicBlock(\n",
       "        (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (1): BasicBlock(\n",
       "        (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (5): Sequential(\n",
       "      (0): BasicBlock(\n",
       "        (conv1): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (downsample): Sequential(\n",
       "          (0): Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "          (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "      )\n",
       "      (1): BasicBlock(\n",
       "        (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (6): Sequential(\n",
       "      (0): BasicBlock(\n",
       "        (conv1): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (downsample): Sequential(\n",
       "          (0): Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "          (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "      )\n",
       "      (1): BasicBlock(\n",
       "        (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (7): Sequential(\n",
       "      (0): BasicBlock(\n",
       "        (conv1): Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (downsample): Sequential(\n",
       "          (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "          (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "      )\n",
       "      (1): BasicBlock(\n",
       "        (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (head): Sequential(\n",
       "    (0): Conv2d(512, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "    (1): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU(inplace=True)\n",
       "    (3): Conv2d(1024, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "    (4): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (5): ReLU(inplace=True)\n",
       "    (6): Conv2d(1024, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "    (7): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (8): ReLU(inplace=True)\n",
       "    (9): Conv2d(1024, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "    (10): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (11): ReLU(inplace=True)\n",
       "    (12): Conv2d(1024, 12, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "    (13): AdaptiveAvgPool2d(output_size=(7, 7))\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "NUM_CLASSES = 2\n",
    "model = YOLO_RESNET18(num_classes=NUM_CLASSES)\n",
    "model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "361cde55",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------------------------------\n",
      "        Layer (type)               Output Shape         Param #\n",
      "================================================================\n",
      "            Conv2d-1         [-1, 64, 224, 224]           9,408\n",
      "       BatchNorm2d-2         [-1, 64, 224, 224]             128\n",
      "              ReLU-3         [-1, 64, 224, 224]               0\n",
      "         MaxPool2d-4         [-1, 64, 112, 112]               0\n",
      "            Conv2d-5         [-1, 64, 112, 112]          36,864\n",
      "       BatchNorm2d-6         [-1, 64, 112, 112]             128\n",
      "              ReLU-7         [-1, 64, 112, 112]               0\n",
      "            Conv2d-8         [-1, 64, 112, 112]          36,864\n",
      "       BatchNorm2d-9         [-1, 64, 112, 112]             128\n",
      "             ReLU-10         [-1, 64, 112, 112]               0\n",
      "       BasicBlock-11         [-1, 64, 112, 112]               0\n",
      "           Conv2d-12         [-1, 64, 112, 112]          36,864\n",
      "      BatchNorm2d-13         [-1, 64, 112, 112]             128\n",
      "             ReLU-14         [-1, 64, 112, 112]               0\n",
      "           Conv2d-15         [-1, 64, 112, 112]          36,864\n",
      "      BatchNorm2d-16         [-1, 64, 112, 112]             128\n",
      "             ReLU-17         [-1, 64, 112, 112]               0\n",
      "       BasicBlock-18         [-1, 64, 112, 112]               0\n",
      "           Conv2d-19          [-1, 128, 56, 56]          73,728\n",
      "      BatchNorm2d-20          [-1, 128, 56, 56]             256\n",
      "             ReLU-21          [-1, 128, 56, 56]               0\n",
      "           Conv2d-22          [-1, 128, 56, 56]         147,456\n",
      "      BatchNorm2d-23          [-1, 128, 56, 56]             256\n",
      "           Conv2d-24          [-1, 128, 56, 56]           8,192\n",
      "      BatchNorm2d-25          [-1, 128, 56, 56]             256\n",
      "             ReLU-26          [-1, 128, 56, 56]               0\n",
      "       BasicBlock-27          [-1, 128, 56, 56]               0\n",
      "           Conv2d-28          [-1, 128, 56, 56]         147,456\n",
      "      BatchNorm2d-29          [-1, 128, 56, 56]             256\n",
      "             ReLU-30          [-1, 128, 56, 56]               0\n",
      "           Conv2d-31          [-1, 128, 56, 56]         147,456\n",
      "      BatchNorm2d-32          [-1, 128, 56, 56]             256\n",
      "             ReLU-33          [-1, 128, 56, 56]               0\n",
      "       BasicBlock-34          [-1, 128, 56, 56]               0\n",
      "           Conv2d-35          [-1, 256, 28, 28]         294,912\n",
      "      BatchNorm2d-36          [-1, 256, 28, 28]             512\n",
      "             ReLU-37          [-1, 256, 28, 28]               0\n",
      "           Conv2d-38          [-1, 256, 28, 28]         589,824\n",
      "      BatchNorm2d-39          [-1, 256, 28, 28]             512\n",
      "           Conv2d-40          [-1, 256, 28, 28]          32,768\n",
      "      BatchNorm2d-41          [-1, 256, 28, 28]             512\n",
      "             ReLU-42          [-1, 256, 28, 28]               0\n",
      "       BasicBlock-43          [-1, 256, 28, 28]               0\n",
      "           Conv2d-44          [-1, 256, 28, 28]         589,824\n",
      "      BatchNorm2d-45          [-1, 256, 28, 28]             512\n",
      "             ReLU-46          [-1, 256, 28, 28]               0\n",
      "           Conv2d-47          [-1, 256, 28, 28]         589,824\n",
      "      BatchNorm2d-48          [-1, 256, 28, 28]             512\n",
      "             ReLU-49          [-1, 256, 28, 28]               0\n",
      "       BasicBlock-50          [-1, 256, 28, 28]               0\n",
      "           Conv2d-51          [-1, 512, 14, 14]       1,179,648\n",
      "      BatchNorm2d-52          [-1, 512, 14, 14]           1,024\n",
      "             ReLU-53          [-1, 512, 14, 14]               0\n",
      "           Conv2d-54          [-1, 512, 14, 14]       2,359,296\n",
      "      BatchNorm2d-55          [-1, 512, 14, 14]           1,024\n",
      "           Conv2d-56          [-1, 512, 14, 14]         131,072\n",
      "      BatchNorm2d-57          [-1, 512, 14, 14]           1,024\n",
      "             ReLU-58          [-1, 512, 14, 14]               0\n",
      "       BasicBlock-59          [-1, 512, 14, 14]               0\n",
      "           Conv2d-60          [-1, 512, 14, 14]       2,359,296\n",
      "      BatchNorm2d-61          [-1, 512, 14, 14]           1,024\n",
      "             ReLU-62          [-1, 512, 14, 14]               0\n",
      "           Conv2d-63          [-1, 512, 14, 14]       2,359,296\n",
      "      BatchNorm2d-64          [-1, 512, 14, 14]           1,024\n",
      "             ReLU-65          [-1, 512, 14, 14]               0\n",
      "       BasicBlock-66          [-1, 512, 14, 14]               0\n",
      "           Conv2d-67         [-1, 1024, 14, 14]         524,288\n",
      "      BatchNorm2d-68         [-1, 1024, 14, 14]           2,048\n",
      "             ReLU-69         [-1, 1024, 14, 14]               0\n",
      "           Conv2d-70         [-1, 1024, 14, 14]       9,437,184\n",
      "      BatchNorm2d-71         [-1, 1024, 14, 14]           2,048\n",
      "             ReLU-72         [-1, 1024, 14, 14]               0\n",
      "           Conv2d-73         [-1, 1024, 14, 14]       9,437,184\n",
      "      BatchNorm2d-74         [-1, 1024, 14, 14]           2,048\n",
      "             ReLU-75         [-1, 1024, 14, 14]               0\n",
      "           Conv2d-76         [-1, 1024, 14, 14]       9,437,184\n",
      "      BatchNorm2d-77         [-1, 1024, 14, 14]           2,048\n",
      "             ReLU-78         [-1, 1024, 14, 14]               0\n",
      "           Conv2d-79           [-1, 12, 14, 14]          12,288\n",
      "AdaptiveAvgPool2d-80             [-1, 12, 7, 7]               0\n",
      "================================================================\n",
      "Total params: 40,032,832\n",
      "Trainable params: 40,032,832\n",
      "Non-trainable params: 0\n",
      "----------------------------------------------------------------\n",
      "Input size (MB): 2.30\n",
      "Forward/backward pass size (MB): 269.52\n",
      "Params size (MB): 152.71\n",
      "Estimated Total Size (MB): 424.53\n",
      "----------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "torchsummary.summary(model, (3,448,448))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "4cf3af4c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 12, 7, 7])\n"
     ]
    }
   ],
   "source": [
    "x = torch.randn(1, 3, 448, 448).to(device)\n",
    "with torch.no_grad():\n",
    "    y = model(x)\n",
    "print(y.shape)"
   ]
  },
  {
   "cell_type": "raw",
   "id": "f4c05720",
   "metadata": {
    "scrolled": true
   },
   "source": [
    "# data_dir = \"/content/drive/MyDrive/fastCamMedicalProj/DATASET/DATASET/Detection/\"\n",
    "BATCH_SIZE = 1\n",
    "\n",
    "# trainset = Detection_dataset(data_dir=data_dir, phase=\"train\", transformer=transformer)\n",
    "NECK_PATH = '/home/host_data/PET_data/Neck'\n",
    "BODY_PATH = '/home/host_data/PET_data/Body'\n",
    "trainset=PET_dataset(part='body',neck_dir=NECK_PATH,body_dir=BODY_PATH,phase='train', transformer=transformer)\n",
    "trainloader = DataLoader(trainset, batch_size=BATCH_SIZE, shuffle=False, collate_fn=collate_fn)\n",
    "\n",
    "model = YOLO_SWIN(num_classes=NUM_CLASSES)\n",
    "\n",
    "for index, batch in enumerate(trainloader):\n",
    "    images = batch[0]\n",
    "    targets = batch[1]\n",
    "    filenames = batch[2]\n",
    "    \n",
    "    predictions = model(images)\n",
    "    print(f\"filename:{filenames}, target:{targets}\")\n",
    "#     print(f\"{index}--input shape:{images.shape} -> output shape: {predictions.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8da970d7",
   "metadata": {},
   "source": [
    "# Loss func"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "3c66945c",
   "metadata": {},
   "outputs": [],
   "source": [
    "class YOLO_LOSS():\n",
    "    def __init__(self, num_classes, device, lambda_coord=5., lambda_noobj=0.5):\n",
    "        self.num_classes = num_classes\n",
    "        self.device = device\n",
    "        self.grid_size = 7\n",
    "        self.lambda_coord = lambda_coord\n",
    "        self.lambda_noobj = lambda_noobj\n",
    "        self.mse_loss = nn.MSELoss(reduction=\"sum\")\n",
    "\n",
    "    def __call__(self, predictions, targets):\n",
    "        self.batch_size, _, _, _ = predictions.shape\n",
    "        groundtruths = self.build_batch_target_grid(targets)\n",
    "        groundtruths = groundtruths.to(self.device)\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            iou1 = self.get_IoU(predictions[:, 1:5, ...], groundtruths[:, 1:5, ...])\n",
    "            iou2 = self.get_IoU(predictions[:, 6:10, ...], groundtruths[:, 1:5, ...])\n",
    "\n",
    "        ious = torch.stack([iou1, iou2], dim=1)\n",
    "        max_iou, best_box = ious.max(dim=1, keepdim=True)\n",
    "        max_iou = torch.cat([max_iou, max_iou], dim=1)\n",
    "        best_box = torch.cat([best_box.eq(0), best_box.eq(1)], dim=1)\n",
    "\n",
    "        predictions_ = predictions[:, :5*2, ...].reshape(self.batch_size, 2, 5, self.grid_size, self.grid_size)\n",
    "        obj_pred = predictions_[:, :, 0, ...]\n",
    "        xy_pred = predictions_[:, :, 1:3, ...]\n",
    "        wh_pred = predictions_[:, :, 3:5, ...]\n",
    "        cls_pred = predictions[:, 5*2:, ...]\n",
    "\n",
    "        groundtruths_ = groundtruths[:, :5, ...].reshape(self.batch_size, 1, 5, self.grid_size, self.grid_size)\n",
    "        obj_target = groundtruths_[:, :, 0, ...]\n",
    "        xy_target = groundtruths_[:, :, 1:3, ...]\n",
    "        wh_target= groundtruths_[:, :, 3:5, ...]\n",
    "        cls_target = groundtruths[:, 5:, ...]\n",
    "        \n",
    "        positive = obj_target * best_box\n",
    "\n",
    "        obj_loss = self.mse_loss(positive * obj_pred, positive * ious)\n",
    "        noobj_loss = self.mse_loss((1 - positive) * obj_pred, ious*0)\n",
    "        xy_loss = self.mse_loss(positive.unsqueeze(dim=2) * xy_pred, positive.unsqueeze(dim=2) * xy_target)\n",
    "        wh_loss = self.mse_loss(positive.unsqueeze(dim=2) * (wh_pred.sign() * (wh_pred.abs() + 1e-8).sqrt()),\n",
    "                           positive.unsqueeze(dim=2) * (wh_target + 1e-8).sqrt())\n",
    "        cls_loss = self.mse_loss(obj_target * cls_pred, cls_target)\n",
    "        \n",
    "        obj_loss /= self.batch_size\n",
    "        noobj_loss /= self.batch_size\n",
    "        bbox_loss = (xy_loss+wh_loss) / self.batch_size\n",
    "        cls_loss /= self.batch_size\n",
    "        \n",
    "        total_loss = obj_loss + self.lambda_noobj*noobj_loss + self.lambda_coord*bbox_loss + cls_loss\n",
    "        return total_loss, (obj_loss.item(), noobj_loss.item(), bbox_loss.item(), cls_loss.item())\n",
    "    \n",
    "    def build_target_grid(self, target):\n",
    "        target_grid = torch.zeros((1+4+self.num_classes, self.grid_size, self.grid_size), device=self.device)\n",
    "\n",
    "        for gt in target:\n",
    "            xc, yc, w, h, cls_id = gt\n",
    "            xn = (xc % (1/self.grid_size))\n",
    "            yn = (yc % (1/self.grid_size))\n",
    "            cls_id = int(cls_id)\n",
    "\n",
    "            i_grid = int(xc * self.grid_size)\n",
    "            j_grid = int(yc * self.grid_size)\n",
    "            target_grid[0, j_grid, i_grid] = 1\n",
    "            target_grid[1:5, j_grid, i_grid] = torch.Tensor([xn,yn,w,h])\n",
    "#             print(5+cls_id, j_grid, i_grid)\n",
    "            target_grid[5+cls_id, j_grid, i_grid] = 1\n",
    "\n",
    "        return target_grid\n",
    "    \n",
    "    def build_batch_target_grid(self, targets):\n",
    "        target_grid_batch = torch.stack([self.build_target_grid(target) for target in targets], dim=0)\n",
    "        return target_grid_batch\n",
    "    \n",
    "    def get_IoU(self, cbox1, cbox2):\n",
    "        box1 = self.xywh_to_xyxy(cbox1)\n",
    "        box2 = self.xywh_to_xyxy(cbox2)\n",
    "\n",
    "        x1 = torch.max(box1[:, 0, ...], box2[:, 0, ...])\n",
    "        y1 = torch.max(box1[:, 1, ...], box2[:, 1, ...])\n",
    "        x2 = torch.min(box1[:, 2, ...], box2[:, 2, ...])\n",
    "        y2 = torch.min(box1[:, 3, ...], box2[:, 3, ...])\n",
    "\n",
    "        intersection = (x2-x1).clamp(min=0) * (y2-y1).clamp(min=0)\n",
    "        union = abs(cbox1[:, 2, ...]*cbox1[:, 3, ...]) + \\\n",
    "                abs(cbox2[:, 2, ...]*cbox2[:, 3, ...]) - intersection\n",
    "\n",
    "        intersection[intersection.gt(0)] = intersection[intersection.gt(0)] / union[intersection.gt(0)]\n",
    "        return intersection\n",
    "    \n",
    "    def generate_xy_normed_grid(self):\n",
    "        y_offset, x_offset = torch.meshgrid(torch.arange(self.grid_size), torch.arange(self.grid_size))\n",
    "        xy_grid = torch.stack([x_offset, y_offset], dim=0)\n",
    "        xy_normed_grid = xy_grid / self.grid_size\n",
    "        return xy_normed_grid.to(self.device)\n",
    "\n",
    "    def xywh_to_xyxy(self, bboxes):\n",
    "        xy_normed_grid = self.generate_xy_normed_grid()\n",
    "        xcyc = bboxes[:,0:2,...] + xy_normed_grid.tile(self.batch_size, 1,1,1)\n",
    "        wh = bboxes[:,2:4,...]\n",
    "        x1y1 = xcyc - (wh/2)\n",
    "        x2y2 = xcyc + (wh/2)\n",
    "        return torch.cat([x1y1, x2y2], dim=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c46ad931",
   "metadata": {},
   "source": [
    "# Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "b1729df2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_one_epoch(dataloaders, model, criterion, optimizer, device):\n",
    "    train_loss = defaultdict(float)\n",
    "    val_loss = defaultdict(float)\n",
    "    \n",
    "    for phase in [\"train\", \"val\"]:\n",
    "        if phase == \"train\":\n",
    "            model.train()\n",
    "        else:\n",
    "            model.eval()\n",
    "        \n",
    "        running_loss = defaultdict(float)\n",
    "        for index, batch in enumerate(dataloaders[phase]):\n",
    "            images = batch[0].to(device)\n",
    "            targets = batch[1]\n",
    "            filenames = batch[2]\n",
    "            \n",
    "            with torch.set_grad_enabled(phase == \"train\"): # phase가 train 일때만 gradient 추적기능을 킨다.\n",
    "                predictions = model(images) #prediction shape=> B,12,7,7\n",
    "#             print(f\"predictions:{predictions}, \\ntargets: {targets}\\n\")\n",
    "            loss, (obj_loss, noobj_loss, bbox_loss, cls_loss) = criterion(predictions, targets)\n",
    "#             print(f\"loss:{loss}, obj_loss:{obj_loss}, noobj_loss:{noobj_loss}\\nbbox_loss:{bbox_loss}, cls_loss:{cls_loss}\\n--------------\\n\")\n",
    "            if phase == \"train\":\n",
    "                optimizer.zero_grad()\n",
    "                loss.backward()\n",
    "                optimizer.step()\n",
    "                \n",
    "                # 현재 epoch단계에서 loss가 얼마인지 running loss 가출력\n",
    "                running_loss[\"total_loss\"] += loss.item()\n",
    "                running_loss[\"obj_loss\"] += obj_loss\n",
    "                running_loss[\"noobj_loss\"] += noobj_loss\n",
    "                running_loss[\"bbox_loss\"] += bbox_loss\n",
    "                running_loss[\"cls_loss\"] += cls_loss\n",
    "                \n",
    "                train_loss[\"total_loss\"] += loss.item()\n",
    "                train_loss[\"obj_loss\"] += obj_loss\n",
    "                train_loss[\"noobj_loss\"] += noobj_loss\n",
    "                train_loss[\"bbox_loss\"] += bbox_loss\n",
    "                train_loss[\"cls_loss\"] += cls_loss\n",
    "                \n",
    "                if (index > 0) and (index % VERBOSE_FREQ) == 0:\n",
    "                    text = f\"<<<iteration:[{index}/{len(dataloaders[phase])}] - \"\n",
    "                    for k, v in running_loss.items():\n",
    "                        text += f\"{k}: {v/VERBOSE_FREQ:.4f}  \"\n",
    "                        running_loss[k] = 0.\n",
    "                    print(text)\n",
    "            else:\n",
    "                val_loss[\"total_loss\"] += loss.item()\n",
    "                val_loss[\"obj_loss\"] += obj_loss\n",
    "                val_loss[\"noobj_loss\"] += noobj_loss\n",
    "                val_loss[\"bbox_loss\"] += bbox_loss\n",
    "                val_loss[\"cls_loss\"] += cls_loss\n",
    "\n",
    "    for k in train_loss.keys():\n",
    "        train_loss[k] /= len(dataloaders[\"train\"])\n",
    "        val_loss[k] /= len(dataloaders[\"val\"])\n",
    "    return train_loss, val_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "cc20c145",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_dataloader(part, NECK_PATH, BODY_PATH, batch_size=2, aug_factor=0):\n",
    "    IMAGE_SIZE = 448\n",
    "    transformer = A.Compose([\n",
    "            A.Resize(height=IMAGE_SIZE, width=IMAGE_SIZE),\n",
    "            A.Normalize(mean=(0.485, 0.456, 0.406),std=(0.229, 0.224, 0.225)),\n",
    "            ToTensorV2(),\n",
    "        ],\n",
    "        bbox_params=A.BboxParams(format='yolo', label_fields=['class_ids']),\n",
    "    )\n",
    "    augmentator=A.Compose([\n",
    "    #     A.Resize(height=IMAGE_SIZE, width=IMAGE_SIZE),\n",
    "        A.HorizontalFlip(p=0.7),\n",
    "    #     A.Sharpen(p=0.7),\n",
    "        A.BBoxSafeRandomCrop(p=0.6),\n",
    "        A.VerticalFlip (p=0.6),\n",
    "        A.HueSaturationValue(p=0.6),\n",
    "        A.Resize(height=IMAGE_SIZE, width=IMAGE_SIZE),\n",
    "        A.Normalize(mean=(0.485, 0.456, 0.406),std=(0.229, 0.224, 0.225)),\n",
    "        ToTensorV2(),\n",
    "        ],\n",
    "        bbox_params=A.BboxParams(format='yolo', label_fields=['class_ids']),\n",
    "    )\n",
    "    \n",
    "    dataloaders = {}\n",
    "#     train_dataset = Detection_dataset(data_dir=data_dir, phase=\"train\", transformer=transformer)\n",
    "    train_dataset=PET_dataset(part ,neck_dir=NECK_PATH,body_dir=BODY_PATH,phase='train', transformer=transformer, aug=augmentator, aug_factor=aug_factor)\n",
    "    dataloaders[\"train\"] = DataLoader(train_dataset, batch_size=batch_size, shuffle=True, collate_fn=collate_fn)\n",
    "\n",
    "#     val_dataset = Detection_dataset(data_dir=data_dir, phase=\"val\", transformer=transformer)\n",
    "    val_dataset=PET_dataset(part ,neck_dir=NECK_PATH,body_dir=BODY_PATH,phase='valid', transformer=transformer, aug=augmentator, aug_factor=aug_factor)\n",
    "    dataloaders[\"val\"] = DataLoader(val_dataset, batch_size=batch_size, shuffle=False, collate_fn=collate_fn)\n",
    "    return dataloaders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "2771b438",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "start making augmented images-- augmented factor:20\n",
      "total length of augmented images: 4200\n",
      "start making augmented images-- augmented factor:20\n",
      "total length of augmented images: 720\n"
     ]
    }
   ],
   "source": [
    "# data_dir = \"/content/drive/MyDrive/fastCamMedicalProj/DATASET/DATASET/Detection/\"\n",
    "NECK_PATH = '/home/host_data/PET_data/Neck'\n",
    "BODY_PATH = '/home/host_data/PET_data/Body'\n",
    "is_cuda = True\n",
    "\n",
    "NUM_CLASSES = 2\n",
    "IMAGE_SIZE = 448\n",
    "BATCH_SIZE = 16\n",
    "VERBOSE_FREQ = 20\n",
    "LR=0.0001\n",
    "AUG_FACTOR=20\n",
    "BACKBONE=\"RESNET18\"\n",
    "PART=\"neck\"\n",
    "num_epochs = 100\n",
    "# DEVICE = torch.device('cuda' if torch.cuda.is_available and is_cuda else 'cpu')\n",
    "\n",
    "dataloaders = build_dataloader(part=PART,NECK_PATH=NECK_PATH,BODY_PATH=BODY_PATH,batch_size=BATCH_SIZE, aug_factor=AUG_FACTOR)\n",
    "model = YOLO_RESNET18(num_classes=NUM_CLASSES)\n",
    "model = model.to(device)\n",
    "criterion = YOLO_LOSS(num_classes=NUM_CLASSES, device=device)\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=LR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "060a24e6",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mgomduribo\u001b[0m (\u001b[33murp\u001b[0m). Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bdb1691239ed44d893f47657232050e7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='Waiting for wandb.init()...\\r'), FloatProgress(value=0.011113778666670744, max=1.0…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.15.12 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.15.11"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/workspace/Plastic_Bottle_defect_detection/experiments/wandb/run-20231024_161635-0hyt161t</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/urp/yolo_resnet_neck/runs/0hyt161t' target=\"_blank\">wandering-tree-1</a></strong> to <a href='https://wandb.ai/urp/yolo_resnet_neck' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/urp/yolo_resnet_neck' target=\"_blank\">https://wandb.ai/urp/yolo_resnet_neck</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/urp/yolo_resnet_neck/runs/0hyt161t' target=\"_blank\">https://wandb.ai/urp/yolo_resnet_neck/runs/0hyt161t</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<button onClick=\"this.nextSibling.style.display='block';this.style.display='none';\">Display W&B run</button><iframe src='https://wandb.ai/urp/yolo_resnet_neck/runs/0hyt161t?jupyter=true' style='border:none;width:100%;height:420px;display:none;'></iframe>"
      ],
      "text/plain": [
       "<wandb.sdk.wandb_run.Run at 0x7f2f4887fd90>"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import wandb\n",
    "import random\n",
    "\n",
    "# start a new wandb run to track this script\n",
    "wandb.init(\n",
    "    # set the wandb project where this run will be logged\n",
    "    project=\"yolo_resnet_neck\",\n",
    "    \n",
    "    # track hyperparameters and run metadata\n",
    "    config={\n",
    "    \"learning_rate\": LR,\n",
    "    \"batch_size\": BATCH_SIZE,\n",
    "    \"architecture\": BACKBONE,\n",
    "    \"dataset\": PART,\n",
    "    \"epochs\": num_epochs,\n",
    "    \"aug factor\":AUG_FACTOR,\n",
    "    }\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "8ebab5dc",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.8/dist-packages/torch/functional.py:504: UserWarning: torch.meshgrid: in an upcoming release, it will be required to pass the indexing argument. (Triggered internally at /opt/pytorch/pytorch/aten/src/ATen/native/TensorShape.cpp:3423.)\n",
      "  return _VF.meshgrid(tensors, **kwargs)  # type: ignore[attr-defined]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<<<iteration:[20/263] - total_loss: 5.7435  obj_loss: 0.0715  noobj_loss: 4.7979  bbox_loss: 0.4961  cls_loss: 0.7924  \n",
      "<<<iteration:[40/263] - total_loss: 4.2361  obj_loss: 0.0634  noobj_loss: 3.5838  bbox_loss: 0.3766  cls_loss: 0.4978  \n",
      "<<<iteration:[60/263] - total_loss: 3.6727  obj_loss: 0.0619  noobj_loss: 3.0938  bbox_loss: 0.3348  cls_loss: 0.3897  \n",
      "<<<iteration:[80/263] - total_loss: 3.4641  obj_loss: 0.0438  noobj_loss: 2.8264  bbox_loss: 0.3382  cls_loss: 0.3160  \n",
      "<<<iteration:[100/263] - total_loss: 3.4294  obj_loss: 0.0498  noobj_loss: 2.6097  bbox_loss: 0.3553  cls_loss: 0.2984  \n",
      "<<<iteration:[120/263] - total_loss: 3.1805  obj_loss: 0.0387  noobj_loss: 2.3963  bbox_loss: 0.3319  cls_loss: 0.2839  \n",
      "<<<iteration:[140/263] - total_loss: 2.9631  obj_loss: 0.0439  noobj_loss: 2.2691  bbox_loss: 0.3046  cls_loss: 0.2615  \n",
      "<<<iteration:[160/263] - total_loss: 2.7794  obj_loss: 0.0400  noobj_loss: 2.1793  bbox_loss: 0.2786  cls_loss: 0.2567  \n",
      "<<<iteration:[180/263] - total_loss: 2.6596  obj_loss: 0.0372  noobj_loss: 2.0492  bbox_loss: 0.2762  cls_loss: 0.2166  \n",
      "<<<iteration:[200/263] - total_loss: 2.5738  obj_loss: 0.0374  noobj_loss: 1.9483  bbox_loss: 0.2632  cls_loss: 0.2464  \n",
      "<<<iteration:[220/263] - total_loss: 2.4558  obj_loss: 0.0380  noobj_loss: 1.8800  bbox_loss: 0.2529  cls_loss: 0.2133  \n",
      "<<<iteration:[240/263] - total_loss: 2.4541  obj_loss: 0.0308  noobj_loss: 1.7944  bbox_loss: 0.2609  cls_loss: 0.2219  \n",
      "<<<iteration:[260/263] - total_loss: 2.2877  obj_loss: 0.0351  noobj_loss: 1.6895  bbox_loss: 0.2448  cls_loss: 0.1840  \n",
      "\n",
      "epoch:1/100 - Train Loss: 3.2050, Val Loss: 2.4572\n",
      "\n",
      "<<<iteration:[20/263] - total_loss: 2.2473  obj_loss: 0.0362  noobj_loss: 1.6723  bbox_loss: 0.2393  cls_loss: 0.1786  \n",
      "<<<iteration:[40/263] - total_loss: 2.1233  obj_loss: 0.0324  noobj_loss: 1.5507  bbox_loss: 0.2248  cls_loss: 0.1917  \n",
      "<<<iteration:[60/263] - total_loss: 2.1710  obj_loss: 0.0340  noobj_loss: 1.5080  bbox_loss: 0.2386  cls_loss: 0.1901  \n",
      "<<<iteration:[80/263] - total_loss: 2.1719  obj_loss: 0.0349  noobj_loss: 1.4662  bbox_loss: 0.2452  cls_loss: 0.1782  \n",
      "<<<iteration:[100/263] - total_loss: 1.9224  obj_loss: 0.0316  noobj_loss: 1.4063  bbox_loss: 0.2044  cls_loss: 0.1657  \n",
      "<<<iteration:[120/263] - total_loss: 1.8641  obj_loss: 0.0359  noobj_loss: 1.3472  bbox_loss: 0.1944  cls_loss: 0.1824  \n",
      "<<<iteration:[140/263] - total_loss: 1.8425  obj_loss: 0.0335  noobj_loss: 1.2938  bbox_loss: 0.1973  cls_loss: 0.1759  \n",
      "<<<iteration:[160/263] - total_loss: 1.7968  obj_loss: 0.0320  noobj_loss: 1.2587  bbox_loss: 0.1944  cls_loss: 0.1635  \n",
      "<<<iteration:[180/263] - total_loss: 1.8361  obj_loss: 0.0313  noobj_loss: 1.2245  bbox_loss: 0.2051  cls_loss: 0.1671  \n",
      "<<<iteration:[200/263] - total_loss: 1.8609  obj_loss: 0.0278  noobj_loss: 1.2094  bbox_loss: 0.2121  cls_loss: 0.1677  \n",
      "<<<iteration:[220/263] - total_loss: 1.7359  obj_loss: 0.0262  noobj_loss: 1.1721  bbox_loss: 0.1921  cls_loss: 0.1631  \n",
      "<<<iteration:[240/263] - total_loss: 1.6844  obj_loss: 0.0325  noobj_loss: 1.1467  bbox_loss: 0.1839  cls_loss: 0.1589  \n",
      "<<<iteration:[260/263] - total_loss: 1.5703  obj_loss: 0.0361  noobj_loss: 1.1095  bbox_loss: 0.1653  cls_loss: 0.1528  \n",
      "\n",
      "epoch:2/100 - Train Loss: 1.9002, Val Loss: 1.7263\n",
      "\n",
      "<<<iteration:[20/263] - total_loss: 1.5789  obj_loss: 0.0328  noobj_loss: 1.1019  bbox_loss: 0.1663  cls_loss: 0.1633  \n",
      "<<<iteration:[40/263] - total_loss: 1.3979  obj_loss: 0.0325  noobj_loss: 1.0077  bbox_loss: 0.1454  cls_loss: 0.1346  \n",
      "<<<iteration:[60/263] - total_loss: 1.3925  obj_loss: 0.0326  noobj_loss: 0.9770  bbox_loss: 0.1435  cls_loss: 0.1539  \n",
      "<<<iteration:[80/263] - total_loss: 1.4039  obj_loss: 0.0342  noobj_loss: 0.9499  bbox_loss: 0.1513  cls_loss: 0.1380  \n",
      "<<<iteration:[100/263] - total_loss: 1.4795  obj_loss: 0.0324  noobj_loss: 0.9568  bbox_loss: 0.1633  cls_loss: 0.1520  \n",
      "<<<iteration:[120/263] - total_loss: 1.3592  obj_loss: 0.0369  noobj_loss: 0.8920  bbox_loss: 0.1494  cls_loss: 0.1292  \n",
      "<<<iteration:[140/263] - total_loss: 1.3641  obj_loss: 0.0291  noobj_loss: 0.8743  bbox_loss: 0.1482  cls_loss: 0.1570  \n",
      "<<<iteration:[160/263] - total_loss: 1.2144  obj_loss: 0.0332  noobj_loss: 0.8581  bbox_loss: 0.1208  cls_loss: 0.1480  \n",
      "<<<iteration:[180/263] - total_loss: 1.1888  obj_loss: 0.0364  noobj_loss: 0.8303  bbox_loss: 0.1204  cls_loss: 0.1354  \n",
      "<<<iteration:[200/263] - total_loss: 1.2179  obj_loss: 0.0335  noobj_loss: 0.8078  bbox_loss: 0.1289  cls_loss: 0.1362  \n",
      "<<<iteration:[220/263] - total_loss: 1.1951  obj_loss: 0.0429  noobj_loss: 0.7806  bbox_loss: 0.1233  cls_loss: 0.1452  \n",
      "<<<iteration:[240/263] - total_loss: 1.2312  obj_loss: 0.0358  noobj_loss: 0.7770  bbox_loss: 0.1368  cls_loss: 0.1230  \n",
      "<<<iteration:[260/263] - total_loss: 1.0732  obj_loss: 0.0319  noobj_loss: 0.7385  bbox_loss: 0.1099  cls_loss: 0.1224  \n",
      "\n",
      "epoch:3/100 - Train Loss: 1.3084, Val Loss: 1.1771\n",
      "\n",
      "<<<iteration:[20/263] - total_loss: 1.0896  obj_loss: 0.0423  noobj_loss: 0.7549  bbox_loss: 0.1059  cls_loss: 0.1403  \n",
      "<<<iteration:[40/263] - total_loss: 1.0544  obj_loss: 0.0346  noobj_loss: 0.7068  bbox_loss: 0.1122  cls_loss: 0.1052  \n",
      "<<<iteration:[60/263] - total_loss: 0.9821  obj_loss: 0.0417  noobj_loss: 0.6583  bbox_loss: 0.1022  cls_loss: 0.1005  \n",
      "<<<iteration:[80/263] - total_loss: 1.0040  obj_loss: 0.0376  noobj_loss: 0.6487  bbox_loss: 0.1027  cls_loss: 0.1285  \n",
      "<<<iteration:[100/263] - total_loss: 0.9796  obj_loss: 0.0392  noobj_loss: 0.6303  bbox_loss: 0.1009  cls_loss: 0.1206  \n",
      "<<<iteration:[120/263] - total_loss: 0.9221  obj_loss: 0.0438  noobj_loss: 0.6123  bbox_loss: 0.0927  cls_loss: 0.1087  \n",
      "<<<iteration:[140/263] - total_loss: 0.9037  obj_loss: 0.0507  noobj_loss: 0.6025  bbox_loss: 0.0888  cls_loss: 0.1076  \n",
      "<<<iteration:[160/263] - total_loss: 0.8915  obj_loss: 0.0411  noobj_loss: 0.5794  bbox_loss: 0.0900  cls_loss: 0.1110  \n",
      "<<<iteration:[180/263] - total_loss: 0.8696  obj_loss: 0.0439  noobj_loss: 0.5664  bbox_loss: 0.0834  cls_loss: 0.1256  \n",
      "<<<iteration:[200/263] - total_loss: 0.8880  obj_loss: 0.0400  noobj_loss: 0.5470  bbox_loss: 0.0901  cls_loss: 0.1241  \n",
      "<<<iteration:[220/263] - total_loss: 0.8791  obj_loss: 0.0477  noobj_loss: 0.5275  bbox_loss: 0.0878  cls_loss: 0.1286  \n",
      "<<<iteration:[240/263] - total_loss: 0.8564  obj_loss: 0.0436  noobj_loss: 0.5209  bbox_loss: 0.0907  cls_loss: 0.0988  \n",
      "<<<iteration:[260/263] - total_loss: 0.8556  obj_loss: 0.0457  noobj_loss: 0.5016  bbox_loss: 0.0890  cls_loss: 0.1140  \n",
      "\n",
      "epoch:4/100 - Train Loss: 0.9309, Val Loss: 0.8792\n",
      "\n",
      "<<<iteration:[20/263] - total_loss: 0.8015  obj_loss: 0.0524  noobj_loss: 0.5033  bbox_loss: 0.0804  cls_loss: 0.0954  \n",
      "<<<iteration:[40/263] - total_loss: 0.7598  obj_loss: 0.0423  noobj_loss: 0.4720  bbox_loss: 0.0770  cls_loss: 0.0966  \n",
      "<<<iteration:[60/263] - total_loss: 0.7311  obj_loss: 0.0529  noobj_loss: 0.4573  bbox_loss: 0.0720  cls_loss: 0.0898  \n",
      "<<<iteration:[80/263] - total_loss: 0.7092  obj_loss: 0.0441  noobj_loss: 0.4430  bbox_loss: 0.0714  cls_loss: 0.0867  \n",
      "<<<iteration:[100/263] - total_loss: 0.7293  obj_loss: 0.0451  noobj_loss: 0.4283  bbox_loss: 0.0732  cls_loss: 0.1041  \n",
      "<<<iteration:[120/263] - total_loss: 0.6952  obj_loss: 0.0473  noobj_loss: 0.4189  bbox_loss: 0.0705  cls_loss: 0.0861  \n",
      "<<<iteration:[140/263] - total_loss: 0.6711  obj_loss: 0.0481  noobj_loss: 0.4044  bbox_loss: 0.0658  cls_loss: 0.0917  \n",
      "<<<iteration:[160/263] - total_loss: 0.6546  obj_loss: 0.0454  noobj_loss: 0.3970  bbox_loss: 0.0603  cls_loss: 0.1089  \n",
      "<<<iteration:[180/263] - total_loss: 0.6337  obj_loss: 0.0540  noobj_loss: 0.3877  bbox_loss: 0.0588  cls_loss: 0.0918  \n",
      "<<<iteration:[200/263] - total_loss: 0.6950  obj_loss: 0.0565  noobj_loss: 0.3852  bbox_loss: 0.0680  cls_loss: 0.1059  \n",
      "<<<iteration:[220/263] - total_loss: 0.6292  obj_loss: 0.0595  noobj_loss: 0.3785  bbox_loss: 0.0593  cls_loss: 0.0838  \n",
      "<<<iteration:[240/263] - total_loss: 0.6343  obj_loss: 0.0479  noobj_loss: 0.3575  bbox_loss: 0.0647  cls_loss: 0.0843  \n",
      "<<<iteration:[260/263] - total_loss: 0.7181  obj_loss: 0.0560  noobj_loss: 0.3561  bbox_loss: 0.0742  cls_loss: 0.1132  \n",
      "\n",
      "epoch:5/100 - Train Loss: 0.6935, Val Loss: 0.7266\n",
      "\n",
      "<<<iteration:[20/263] - total_loss: 0.6561  obj_loss: 0.0606  noobj_loss: 0.3586  bbox_loss: 0.0648  cls_loss: 0.0921  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<<<iteration:[40/263] - total_loss: 0.5834  obj_loss: 0.0553  noobj_loss: 0.3390  bbox_loss: 0.0555  cls_loss: 0.0813  \n",
      "<<<iteration:[60/263] - total_loss: 0.5569  obj_loss: 0.0621  noobj_loss: 0.3186  bbox_loss: 0.0481  cls_loss: 0.0949  \n",
      "<<<iteration:[80/263] - total_loss: 0.5542  obj_loss: 0.0605  noobj_loss: 0.3248  bbox_loss: 0.0516  cls_loss: 0.0734  \n",
      "<<<iteration:[100/263] - total_loss: 0.5231  obj_loss: 0.0663  noobj_loss: 0.3140  bbox_loss: 0.0441  cls_loss: 0.0791  \n",
      "<<<iteration:[120/263] - total_loss: 0.5305  obj_loss: 0.0599  noobj_loss: 0.3051  bbox_loss: 0.0472  cls_loss: 0.0821  \n",
      "<<<iteration:[140/263] - total_loss: 0.5279  obj_loss: 0.0673  noobj_loss: 0.3035  bbox_loss: 0.0453  cls_loss: 0.0826  \n",
      "<<<iteration:[160/263] - total_loss: 0.5334  obj_loss: 0.0700  noobj_loss: 0.2893  bbox_loss: 0.0483  cls_loss: 0.0772  \n",
      "<<<iteration:[180/263] - total_loss: 0.5446  obj_loss: 0.0657  noobj_loss: 0.2800  bbox_loss: 0.0521  cls_loss: 0.0783  \n",
      "<<<iteration:[200/263] - total_loss: 0.5385  obj_loss: 0.0638  noobj_loss: 0.2760  bbox_loss: 0.0499  cls_loss: 0.0874  \n",
      "<<<iteration:[220/263] - total_loss: 0.5109  obj_loss: 0.0545  noobj_loss: 0.2698  bbox_loss: 0.0463  cls_loss: 0.0901  \n",
      "<<<iteration:[240/263] - total_loss: 0.5048  obj_loss: 0.0634  noobj_loss: 0.2672  bbox_loss: 0.0451  cls_loss: 0.0822  \n",
      "<<<iteration:[260/263] - total_loss: 0.5536  obj_loss: 0.0666  noobj_loss: 0.2592  bbox_loss: 0.0537  cls_loss: 0.0888  \n",
      "\n",
      "epoch:6/100 - Train Loss: 0.5456, Val Loss: 0.5896\n",
      "\n",
      "<<<iteration:[20/263] - total_loss: 0.5617  obj_loss: 0.0704  noobj_loss: 0.2721  bbox_loss: 0.0559  cls_loss: 0.0757  \n",
      "<<<iteration:[40/263] - total_loss: 0.4978  obj_loss: 0.0702  noobj_loss: 0.2593  bbox_loss: 0.0430  cls_loss: 0.0830  \n",
      "<<<iteration:[60/263] - total_loss: 0.4767  obj_loss: 0.0805  noobj_loss: 0.2424  bbox_loss: 0.0405  cls_loss: 0.0725  \n",
      "<<<iteration:[80/263] - total_loss: 0.4749  obj_loss: 0.0729  noobj_loss: 0.2423  bbox_loss: 0.0413  cls_loss: 0.0743  \n",
      "<<<iteration:[100/263] - total_loss: 0.4593  obj_loss: 0.0734  noobj_loss: 0.2365  bbox_loss: 0.0398  cls_loss: 0.0686  \n",
      "<<<iteration:[120/263] - total_loss: 0.4750  obj_loss: 0.0851  noobj_loss: 0.2286  bbox_loss: 0.0422  cls_loss: 0.0644  \n",
      "<<<iteration:[140/263] - total_loss: 0.4890  obj_loss: 0.0699  noobj_loss: 0.2237  bbox_loss: 0.0435  cls_loss: 0.0896  \n",
      "<<<iteration:[160/263] - total_loss: 0.4898  obj_loss: 0.0789  noobj_loss: 0.2250  bbox_loss: 0.0441  cls_loss: 0.0779  \n",
      "<<<iteration:[180/263] - total_loss: 0.4742  obj_loss: 0.0774  noobj_loss: 0.2162  bbox_loss: 0.0389  cls_loss: 0.0941  \n",
      "<<<iteration:[200/263] - total_loss: 0.4414  obj_loss: 0.0725  noobj_loss: 0.2129  bbox_loss: 0.0394  cls_loss: 0.0652  \n",
      "<<<iteration:[220/263] - total_loss: 0.4532  obj_loss: 0.0800  noobj_loss: 0.2121  bbox_loss: 0.0387  cls_loss: 0.0737  \n",
      "<<<iteration:[240/263] - total_loss: 0.4533  obj_loss: 0.0831  noobj_loss: 0.2126  bbox_loss: 0.0385  cls_loss: 0.0716  \n",
      "<<<iteration:[260/263] - total_loss: 0.4594  obj_loss: 0.0770  noobj_loss: 0.2079  bbox_loss: 0.0400  cls_loss: 0.0785  \n",
      "\n",
      "epoch:7/100 - Train Loss: 0.4761, Val Loss: 0.5195\n",
      "\n",
      "<<<iteration:[20/263] - total_loss: 0.4397  obj_loss: 0.0804  noobj_loss: 0.2065  bbox_loss: 0.0379  cls_loss: 0.0666  \n",
      "<<<iteration:[40/263] - total_loss: 0.4114  obj_loss: 0.0826  noobj_loss: 0.2012  bbox_loss: 0.0344  cls_loss: 0.0563  \n",
      "<<<iteration:[60/263] - total_loss: 0.4260  obj_loss: 0.0864  noobj_loss: 0.2006  bbox_loss: 0.0347  cls_loss: 0.0659  \n",
      "<<<iteration:[80/263] - total_loss: 0.4127  obj_loss: 0.0784  noobj_loss: 0.1933  bbox_loss: 0.0353  cls_loss: 0.0611  \n",
      "<<<iteration:[100/263] - total_loss: 0.4576  obj_loss: 0.0739  noobj_loss: 0.1930  bbox_loss: 0.0416  cls_loss: 0.0792  \n",
      "<<<iteration:[120/263] - total_loss: 0.4149  obj_loss: 0.0848  noobj_loss: 0.1882  bbox_loss: 0.0355  cls_loss: 0.0584  \n",
      "<<<iteration:[140/263] - total_loss: 0.3611  obj_loss: 0.0778  noobj_loss: 0.1820  bbox_loss: 0.0290  cls_loss: 0.0476  \n",
      "<<<iteration:[160/263] - total_loss: 0.3962  obj_loss: 0.0692  noobj_loss: 0.1857  bbox_loss: 0.0347  cls_loss: 0.0606  \n",
      "<<<iteration:[180/263] - total_loss: 0.4124  obj_loss: 0.0905  noobj_loss: 0.1819  bbox_loss: 0.0325  cls_loss: 0.0684  \n",
      "<<<iteration:[200/263] - total_loss: 0.3775  obj_loss: 0.0872  noobj_loss: 0.1770  bbox_loss: 0.0291  cls_loss: 0.0562  \n",
      "<<<iteration:[220/263] - total_loss: 0.3960  obj_loss: 0.0811  noobj_loss: 0.1725  bbox_loss: 0.0304  cls_loss: 0.0766  \n",
      "<<<iteration:[240/263] - total_loss: 0.4198  obj_loss: 0.0932  noobj_loss: 0.1751  bbox_loss: 0.0313  cls_loss: 0.0826  \n",
      "<<<iteration:[260/263] - total_loss: 0.4091  obj_loss: 0.0827  noobj_loss: 0.1684  bbox_loss: 0.0327  cls_loss: 0.0788  \n",
      "\n",
      "epoch:8/100 - Train Loss: 0.4087, Val Loss: 0.4376\n",
      "\n",
      "<<<iteration:[20/263] - total_loss: 0.4102  obj_loss: 0.1010  noobj_loss: 0.1740  bbox_loss: 0.0304  cls_loss: 0.0702  \n",
      "<<<iteration:[40/263] - total_loss: 0.3728  obj_loss: 0.0793  noobj_loss: 0.1684  bbox_loss: 0.0296  cls_loss: 0.0612  \n",
      "<<<iteration:[60/263] - total_loss: 0.3882  obj_loss: 0.0926  noobj_loss: 0.1671  bbox_loss: 0.0313  cls_loss: 0.0557  \n",
      "<<<iteration:[80/263] - total_loss: 0.3809  obj_loss: 0.0822  noobj_loss: 0.1660  bbox_loss: 0.0309  cls_loss: 0.0613  \n",
      "<<<iteration:[100/263] - total_loss: 0.3817  obj_loss: 0.0874  noobj_loss: 0.1605  bbox_loss: 0.0320  cls_loss: 0.0538  \n",
      "<<<iteration:[120/263] - total_loss: 0.4021  obj_loss: 0.0945  noobj_loss: 0.1617  bbox_loss: 0.0316  cls_loss: 0.0689  \n",
      "<<<iteration:[140/263] - total_loss: 0.3642  obj_loss: 0.0884  noobj_loss: 0.1562  bbox_loss: 0.0279  cls_loss: 0.0583  \n",
      "<<<iteration:[160/263] - total_loss: 0.3775  obj_loss: 0.0892  noobj_loss: 0.1592  bbox_loss: 0.0283  cls_loss: 0.0672  \n",
      "<<<iteration:[180/263] - total_loss: 0.3863  obj_loss: 0.0798  noobj_loss: 0.1580  bbox_loss: 0.0297  cls_loss: 0.0789  \n",
      "<<<iteration:[200/263] - total_loss: 0.4834  obj_loss: 0.0758  noobj_loss: 0.1564  bbox_loss: 0.0546  cls_loss: 0.0565  \n",
      "<<<iteration:[220/263] - total_loss: 0.4234  obj_loss: 0.0856  noobj_loss: 0.1481  bbox_loss: 0.0410  cls_loss: 0.0587  \n",
      "<<<iteration:[240/263] - total_loss: 0.3885  obj_loss: 0.0899  noobj_loss: 0.1462  bbox_loss: 0.0330  cls_loss: 0.0607  \n",
      "<<<iteration:[260/263] - total_loss: 0.3864  obj_loss: 0.0896  noobj_loss: 0.1480  bbox_loss: 0.0329  cls_loss: 0.0583  \n",
      "\n",
      "epoch:9/100 - Train Loss: 0.3948, Val Loss: 0.4202\n",
      "\n",
      "<<<iteration:[20/263] - total_loss: 0.3650  obj_loss: 0.0887  noobj_loss: 0.1500  bbox_loss: 0.0288  cls_loss: 0.0571  \n",
      "<<<iteration:[40/263] - total_loss: 0.3588  obj_loss: 0.1007  noobj_loss: 0.1440  bbox_loss: 0.0264  cls_loss: 0.0541  \n",
      "<<<iteration:[60/263] - total_loss: 0.3511  obj_loss: 0.0951  noobj_loss: 0.1427  bbox_loss: 0.0263  cls_loss: 0.0532  \n",
      "<<<iteration:[80/263] - total_loss: 0.3471  obj_loss: 0.0982  noobj_loss: 0.1413  bbox_loss: 0.0246  cls_loss: 0.0552  \n",
      "<<<iteration:[100/263] - total_loss: 0.3660  obj_loss: 0.0927  noobj_loss: 0.1375  bbox_loss: 0.0309  cls_loss: 0.0500  \n",
      "<<<iteration:[120/263] - total_loss: 0.3718  obj_loss: 0.0939  noobj_loss: 0.1418  bbox_loss: 0.0279  cls_loss: 0.0673  \n",
      "<<<iteration:[140/263] - total_loss: 0.3508  obj_loss: 0.0882  noobj_loss: 0.1377  bbox_loss: 0.0275  cls_loss: 0.0565  \n",
      "<<<iteration:[160/263] - total_loss: 0.3574  obj_loss: 0.0911  noobj_loss: 0.1376  bbox_loss: 0.0269  cls_loss: 0.0628  \n",
      "<<<iteration:[180/263] - total_loss: 0.3684  obj_loss: 0.0993  noobj_loss: 0.1317  bbox_loss: 0.0295  cls_loss: 0.0559  \n",
      "<<<iteration:[200/263] - total_loss: 0.3547  obj_loss: 0.1028  noobj_loss: 0.1364  bbox_loss: 0.0258  cls_loss: 0.0548  \n",
      "<<<iteration:[220/263] - total_loss: 0.3400  obj_loss: 0.0983  noobj_loss: 0.1326  bbox_loss: 0.0249  cls_loss: 0.0510  \n",
      "<<<iteration:[240/263] - total_loss: 0.3715  obj_loss: 0.1073  noobj_loss: 0.1351  bbox_loss: 0.0250  cls_loss: 0.0716  \n",
      "<<<iteration:[260/263] - total_loss: 0.3572  obj_loss: 0.0915  noobj_loss: 0.1309  bbox_loss: 0.0272  cls_loss: 0.0642  \n",
      "\n",
      "epoch:10/100 - Train Loss: 0.3568, Val Loss: 0.3922\n",
      "\n",
      "<<<iteration:[20/263] - total_loss: 0.3534  obj_loss: 0.0927  noobj_loss: 0.1369  bbox_loss: 0.0259  cls_loss: 0.0626  \n",
      "<<<iteration:[40/263] - total_loss: 0.3358  obj_loss: 0.0922  noobj_loss: 0.1282  bbox_loss: 0.0246  cls_loss: 0.0567  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<<<iteration:[60/263] - total_loss: 0.3126  obj_loss: 0.0924  noobj_loss: 0.1236  bbox_loss: 0.0225  cls_loss: 0.0458  \n",
      "<<<iteration:[80/263] - total_loss: 0.3256  obj_loss: 0.1002  noobj_loss: 0.1254  bbox_loss: 0.0218  cls_loss: 0.0538  \n",
      "<<<iteration:[100/263] - total_loss: 0.3308  obj_loss: 0.0956  noobj_loss: 0.1240  bbox_loss: 0.0241  cls_loss: 0.0526  \n",
      "<<<iteration:[120/263] - total_loss: 0.3331  obj_loss: 0.1092  noobj_loss: 0.1244  bbox_loss: 0.0214  cls_loss: 0.0548  \n",
      "<<<iteration:[140/263] - total_loss: 0.3270  obj_loss: 0.1100  noobj_loss: 0.1252  bbox_loss: 0.0208  cls_loss: 0.0505  \n",
      "<<<iteration:[160/263] - total_loss: 0.3571  obj_loss: 0.1177  noobj_loss: 0.1237  bbox_loss: 0.0238  cls_loss: 0.0586  \n",
      "<<<iteration:[180/263] - total_loss: 0.3345  obj_loss: 0.0983  noobj_loss: 0.1226  bbox_loss: 0.0238  cls_loss: 0.0561  \n",
      "<<<iteration:[200/263] - total_loss: 0.3221  obj_loss: 0.0981  noobj_loss: 0.1191  bbox_loss: 0.0223  cls_loss: 0.0530  \n",
      "<<<iteration:[220/263] - total_loss: 0.3242  obj_loss: 0.0999  noobj_loss: 0.1205  bbox_loss: 0.0236  cls_loss: 0.0460  \n",
      "<<<iteration:[240/263] - total_loss: 0.3503  obj_loss: 0.1138  noobj_loss: 0.1197  bbox_loss: 0.0236  cls_loss: 0.0587  \n",
      "<<<iteration:[260/263] - total_loss: 0.3333  obj_loss: 0.1006  noobj_loss: 0.1190  bbox_loss: 0.0241  cls_loss: 0.0526  \n",
      "\n",
      "epoch:11/100 - Train Loss: 0.3326, Val Loss: 0.3740\n",
      "\n",
      "<<<iteration:[20/263] - total_loss: 0.3385  obj_loss: 0.1130  noobj_loss: 0.1229  bbox_loss: 0.0225  cls_loss: 0.0516  \n",
      "<<<iteration:[40/263] - total_loss: 0.3220  obj_loss: 0.1218  noobj_loss: 0.1206  bbox_loss: 0.0185  cls_loss: 0.0475  \n",
      "<<<iteration:[60/263] - total_loss: 0.3248  obj_loss: 0.1101  noobj_loss: 0.1171  bbox_loss: 0.0197  cls_loss: 0.0574  \n",
      "<<<iteration:[80/263] - total_loss: 0.3078  obj_loss: 0.1057  noobj_loss: 0.1163  bbox_loss: 0.0191  cls_loss: 0.0484  \n",
      "<<<iteration:[100/263] - total_loss: 0.3294  obj_loss: 0.1107  noobj_loss: 0.1158  bbox_loss: 0.0226  cls_loss: 0.0479  \n",
      "<<<iteration:[120/263] - total_loss: 0.3286  obj_loss: 0.1190  noobj_loss: 0.1172  bbox_loss: 0.0199  cls_loss: 0.0517  \n",
      "<<<iteration:[140/263] - total_loss: 0.3486  obj_loss: 0.1084  noobj_loss: 0.1159  bbox_loss: 0.0230  cls_loss: 0.0670  \n",
      "<<<iteration:[160/263] - total_loss: 0.3016  obj_loss: 0.1002  noobj_loss: 0.1117  bbox_loss: 0.0199  cls_loss: 0.0461  \n",
      "<<<iteration:[180/263] - total_loss: 0.3264  obj_loss: 0.1078  noobj_loss: 0.1117  bbox_loss: 0.0216  cls_loss: 0.0547  \n",
      "<<<iteration:[200/263] - total_loss: 0.3430  obj_loss: 0.1112  noobj_loss: 0.1158  bbox_loss: 0.0245  cls_loss: 0.0515  \n",
      "<<<iteration:[220/263] - total_loss: 0.3127  obj_loss: 0.1083  noobj_loss: 0.1094  bbox_loss: 0.0210  cls_loss: 0.0447  \n",
      "<<<iteration:[240/263] - total_loss: 0.3078  obj_loss: 0.1077  noobj_loss: 0.1098  bbox_loss: 0.0192  cls_loss: 0.0491  \n",
      "<<<iteration:[260/263] - total_loss: 0.3146  obj_loss: 0.1046  noobj_loss: 0.1095  bbox_loss: 0.0203  cls_loss: 0.0536  \n",
      "\n",
      "epoch:12/100 - Train Loss: 0.3226, Val Loss: 0.3691\n",
      "\n",
      "<<<iteration:[20/263] - total_loss: 0.3325  obj_loss: 0.1226  noobj_loss: 0.1121  bbox_loss: 0.0203  cls_loss: 0.0525  \n",
      "<<<iteration:[40/263] - total_loss: 0.3313  obj_loss: 0.1151  noobj_loss: 0.1097  bbox_loss: 0.0207  cls_loss: 0.0578  \n",
      "<<<iteration:[60/263] - total_loss: 0.3034  obj_loss: 0.1156  noobj_loss: 0.1102  bbox_loss: 0.0183  cls_loss: 0.0413  \n",
      "<<<iteration:[80/263] - total_loss: 0.2944  obj_loss: 0.1086  noobj_loss: 0.1079  bbox_loss: 0.0184  cls_loss: 0.0400  \n",
      "<<<iteration:[100/263] - total_loss: 0.3173  obj_loss: 0.1184  noobj_loss: 0.1069  bbox_loss: 0.0201  cls_loss: 0.0449  \n",
      "<<<iteration:[120/263] - total_loss: 0.3173  obj_loss: 0.1184  noobj_loss: 0.1079  bbox_loss: 0.0182  cls_loss: 0.0537  \n",
      "<<<iteration:[140/263] - total_loss: 0.3107  obj_loss: 0.1085  noobj_loss: 0.1056  bbox_loss: 0.0210  cls_loss: 0.0443  \n",
      "<<<iteration:[160/263] - total_loss: 0.3095  obj_loss: 0.1007  noobj_loss: 0.1070  bbox_loss: 0.0214  cls_loss: 0.0482  \n",
      "<<<iteration:[180/263] - total_loss: 0.3324  obj_loss: 0.1191  noobj_loss: 0.1086  bbox_loss: 0.0202  cls_loss: 0.0581  \n",
      "<<<iteration:[200/263] - total_loss: 0.3090  obj_loss: 0.1115  noobj_loss: 0.1049  bbox_loss: 0.0185  cls_loss: 0.0528  \n",
      "<<<iteration:[220/263] - total_loss: 0.3003  obj_loss: 0.1082  noobj_loss: 0.1028  bbox_loss: 0.0192  cls_loss: 0.0449  \n",
      "<<<iteration:[240/263] - total_loss: 0.2943  obj_loss: 0.1166  noobj_loss: 0.1034  bbox_loss: 0.0181  cls_loss: 0.0356  \n",
      "<<<iteration:[260/263] - total_loss: 0.3051  obj_loss: 0.1151  noobj_loss: 0.1043  bbox_loss: 0.0190  cls_loss: 0.0428  \n",
      "\n",
      "epoch:13/100 - Train Loss: 0.3104, Val Loss: 0.3435\n",
      "\n",
      "<<<iteration:[20/263] - total_loss: 0.2954  obj_loss: 0.1201  noobj_loss: 0.1056  bbox_loss: 0.0175  cls_loss: 0.0352  \n",
      "<<<iteration:[40/263] - total_loss: 0.3066  obj_loss: 0.1182  noobj_loss: 0.0999  bbox_loss: 0.0177  cls_loss: 0.0497  \n",
      "<<<iteration:[60/263] - total_loss: 0.3028  obj_loss: 0.1094  noobj_loss: 0.1017  bbox_loss: 0.0185  cls_loss: 0.0502  \n",
      "<<<iteration:[80/263] - total_loss: 0.3059  obj_loss: 0.1255  noobj_loss: 0.1016  bbox_loss: 0.0175  cls_loss: 0.0420  \n",
      "<<<iteration:[100/263] - total_loss: 0.3122  obj_loss: 0.1150  noobj_loss: 0.1029  bbox_loss: 0.0177  cls_loss: 0.0571  \n",
      "<<<iteration:[120/263] - total_loss: 0.3100  obj_loss: 0.1218  noobj_loss: 0.1026  bbox_loss: 0.0178  cls_loss: 0.0479  \n",
      "<<<iteration:[140/263] - total_loss: 0.3024  obj_loss: 0.1303  noobj_loss: 0.1026  bbox_loss: 0.0181  cls_loss: 0.0301  \n",
      "<<<iteration:[160/263] - total_loss: 0.3021  obj_loss: 0.1215  noobj_loss: 0.0989  bbox_loss: 0.0180  cls_loss: 0.0412  \n",
      "<<<iteration:[180/263] - total_loss: 0.3002  obj_loss: 0.1155  noobj_loss: 0.1004  bbox_loss: 0.0170  cls_loss: 0.0497  \n",
      "<<<iteration:[200/263] - total_loss: 0.3115  obj_loss: 0.1136  noobj_loss: 0.1011  bbox_loss: 0.0196  cls_loss: 0.0496  \n",
      "<<<iteration:[220/263] - total_loss: 0.3000  obj_loss: 0.1233  noobj_loss: 0.0999  bbox_loss: 0.0177  cls_loss: 0.0382  \n",
      "<<<iteration:[240/263] - total_loss: 0.3176  obj_loss: 0.1175  noobj_loss: 0.1006  bbox_loss: 0.0206  cls_loss: 0.0470  \n",
      "<<<iteration:[260/263] - total_loss: 0.3018  obj_loss: 0.1132  noobj_loss: 0.0976  bbox_loss: 0.0188  cls_loss: 0.0459  \n",
      "\n",
      "epoch:14/100 - Train Loss: 0.3042, Val Loss: 0.3418\n",
      "\n",
      "<<<iteration:[20/263] - total_loss: 0.3236  obj_loss: 0.1318  noobj_loss: 0.1043  bbox_loss: 0.0182  cls_loss: 0.0488  \n",
      "<<<iteration:[40/263] - total_loss: 0.3142  obj_loss: 0.1313  noobj_loss: 0.0997  bbox_loss: 0.0171  cls_loss: 0.0478  \n",
      "<<<iteration:[60/263] - total_loss: 0.2937  obj_loss: 0.1239  noobj_loss: 0.0977  bbox_loss: 0.0149  cls_loss: 0.0462  \n",
      "<<<iteration:[80/263] - total_loss: 0.3067  obj_loss: 0.1202  noobj_loss: 0.1002  bbox_loss: 0.0191  cls_loss: 0.0411  \n",
      "<<<iteration:[100/263] - total_loss: 0.3048  obj_loss: 0.1186  noobj_loss: 0.0946  bbox_loss: 0.0189  cls_loss: 0.0444  \n",
      "<<<iteration:[120/263] - total_loss: 0.3089  obj_loss: 0.1391  noobj_loss: 0.0982  bbox_loss: 0.0167  cls_loss: 0.0373  \n",
      "<<<iteration:[140/263] - total_loss: 0.3033  obj_loss: 0.1248  noobj_loss: 0.0981  bbox_loss: 0.0171  cls_loss: 0.0441  \n",
      "<<<iteration:[160/263] - total_loss: 0.3012  obj_loss: 0.1234  noobj_loss: 0.0965  bbox_loss: 0.0176  cls_loss: 0.0415  \n",
      "<<<iteration:[180/263] - total_loss: 0.2900  obj_loss: 0.1196  noobj_loss: 0.0959  bbox_loss: 0.0178  cls_loss: 0.0337  \n",
      "<<<iteration:[200/263] - total_loss: 0.2895  obj_loss: 0.1265  noobj_loss: 0.0937  bbox_loss: 0.0146  cls_loss: 0.0431  \n",
      "<<<iteration:[220/263] - total_loss: 0.3052  obj_loss: 0.1236  noobj_loss: 0.0966  bbox_loss: 0.0179  cls_loss: 0.0440  \n",
      "<<<iteration:[240/263] - total_loss: 0.2877  obj_loss: 0.1177  noobj_loss: 0.0905  bbox_loss: 0.0159  cls_loss: 0.0451  \n",
      "<<<iteration:[260/263] - total_loss: 0.2904  obj_loss: 0.1132  noobj_loss: 0.0939  bbox_loss: 0.0182  cls_loss: 0.0395  \n",
      "\n",
      "epoch:15/100 - Train Loss: 0.2998, Val Loss: 0.3464\n",
      "\n",
      "<<<iteration:[20/263] - total_loss: 0.3364  obj_loss: 0.1445  noobj_loss: 0.0982  bbox_loss: 0.0188  cls_loss: 0.0486  \n",
      "<<<iteration:[40/263] - total_loss: 0.2984  obj_loss: 0.1232  noobj_loss: 0.0944  bbox_loss: 0.0166  cls_loss: 0.0449  \n",
      "<<<iteration:[60/263] - total_loss: 0.2804  obj_loss: 0.1114  noobj_loss: 0.0948  bbox_loss: 0.0167  cls_loss: 0.0383  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<<<iteration:[80/263] - total_loss: 0.2815  obj_loss: 0.1241  noobj_loss: 0.0903  bbox_loss: 0.0160  cls_loss: 0.0324  \n",
      "<<<iteration:[100/263] - total_loss: 0.2844  obj_loss: 0.1208  noobj_loss: 0.0923  bbox_loss: 0.0151  cls_loss: 0.0418  \n",
      "<<<iteration:[120/263] - total_loss: 0.3035  obj_loss: 0.1322  noobj_loss: 0.0902  bbox_loss: 0.0152  cls_loss: 0.0501  \n",
      "<<<iteration:[140/263] - total_loss: 0.2901  obj_loss: 0.1276  noobj_loss: 0.0916  bbox_loss: 0.0154  cls_loss: 0.0397  \n",
      "<<<iteration:[160/263] - total_loss: 0.2796  obj_loss: 0.1170  noobj_loss: 0.0937  bbox_loss: 0.0154  cls_loss: 0.0387  \n",
      "<<<iteration:[180/263] - total_loss: 0.2809  obj_loss: 0.1283  noobj_loss: 0.0925  bbox_loss: 0.0138  cls_loss: 0.0373  \n",
      "<<<iteration:[200/263] - total_loss: 0.2875  obj_loss: 0.1325  noobj_loss: 0.0906  bbox_loss: 0.0148  cls_loss: 0.0356  \n",
      "<<<iteration:[220/263] - total_loss: 0.2944  obj_loss: 0.1243  noobj_loss: 0.0946  bbox_loss: 0.0155  cls_loss: 0.0455  \n",
      "<<<iteration:[240/263] - total_loss: 0.2871  obj_loss: 0.1336  noobj_loss: 0.0918  bbox_loss: 0.0144  cls_loss: 0.0353  \n",
      "<<<iteration:[260/263] - total_loss: 0.2864  obj_loss: 0.1188  noobj_loss: 0.0891  bbox_loss: 0.0157  cls_loss: 0.0444  \n",
      "\n",
      "epoch:16/100 - Train Loss: 0.2904, Val Loss: 0.3282\n",
      "\n",
      "<<<iteration:[20/263] - total_loss: 0.3022  obj_loss: 0.1414  noobj_loss: 0.0931  bbox_loss: 0.0147  cls_loss: 0.0409  \n",
      "<<<iteration:[40/263] - total_loss: 0.2921  obj_loss: 0.1314  noobj_loss: 0.0933  bbox_loss: 0.0150  cls_loss: 0.0389  \n",
      "<<<iteration:[60/263] - total_loss: 0.2897  obj_loss: 0.1286  noobj_loss: 0.0916  bbox_loss: 0.0160  cls_loss: 0.0352  \n",
      "<<<iteration:[80/263] - total_loss: 0.2785  obj_loss: 0.1252  noobj_loss: 0.0890  bbox_loss: 0.0145  cls_loss: 0.0364  \n",
      "<<<iteration:[100/263] - total_loss: 0.2921  obj_loss: 0.1308  noobj_loss: 0.0908  bbox_loss: 0.0158  cls_loss: 0.0366  \n",
      "<<<iteration:[120/263] - total_loss: 0.3003  obj_loss: 0.1327  noobj_loss: 0.0901  bbox_loss: 0.0151  cls_loss: 0.0469  \n",
      "<<<iteration:[140/263] - total_loss: 0.2825  obj_loss: 0.1290  noobj_loss: 0.0894  bbox_loss: 0.0153  cls_loss: 0.0321  \n",
      "<<<iteration:[160/263] - total_loss: 0.3059  obj_loss: 0.1363  noobj_loss: 0.0887  bbox_loss: 0.0155  cls_loss: 0.0475  \n",
      "<<<iteration:[180/263] - total_loss: 0.2826  obj_loss: 0.1298  noobj_loss: 0.0890  bbox_loss: 0.0151  cls_loss: 0.0327  \n",
      "<<<iteration:[200/263] - total_loss: 0.3189  obj_loss: 0.1264  noobj_loss: 0.0935  bbox_loss: 0.0216  cls_loss: 0.0378  \n",
      "<<<iteration:[220/263] - total_loss: 0.3144  obj_loss: 0.1293  noobj_loss: 0.0897  bbox_loss: 0.0194  cls_loss: 0.0431  \n",
      "<<<iteration:[240/263] - total_loss: 0.2992  obj_loss: 0.1269  noobj_loss: 0.0921  bbox_loss: 0.0180  cls_loss: 0.0362  \n",
      "<<<iteration:[260/263] - total_loss: 0.3003  obj_loss: 0.1360  noobj_loss: 0.0885  bbox_loss: 0.0153  cls_loss: 0.0435  \n",
      "\n",
      "epoch:17/100 - Train Loss: 0.2955, Val Loss: 0.3233\n",
      "\n",
      "<<<iteration:[20/263] - total_loss: 0.3143  obj_loss: 0.1457  noobj_loss: 0.0978  bbox_loss: 0.0169  cls_loss: 0.0354  \n",
      "<<<iteration:[40/263] - total_loss: 0.2812  obj_loss: 0.1349  noobj_loss: 0.0906  bbox_loss: 0.0131  cls_loss: 0.0356  \n",
      "<<<iteration:[60/263] - total_loss: 0.2889  obj_loss: 0.1324  noobj_loss: 0.0897  bbox_loss: 0.0147  cls_loss: 0.0382  \n",
      "<<<iteration:[80/263] - total_loss: 0.2883  obj_loss: 0.1280  noobj_loss: 0.0871  bbox_loss: 0.0156  cls_loss: 0.0389  \n",
      "<<<iteration:[100/263] - total_loss: 0.2927  obj_loss: 0.1354  noobj_loss: 0.0865  bbox_loss: 0.0157  cls_loss: 0.0354  \n",
      "<<<iteration:[120/263] - total_loss: 0.2869  obj_loss: 0.1295  noobj_loss: 0.0870  bbox_loss: 0.0158  cls_loss: 0.0349  \n",
      "<<<iteration:[140/263] - total_loss: 0.2886  obj_loss: 0.1284  noobj_loss: 0.0909  bbox_loss: 0.0162  cls_loss: 0.0335  \n",
      "<<<iteration:[160/263] - total_loss: 0.3001  obj_loss: 0.1393  noobj_loss: 0.0844  bbox_loss: 0.0154  cls_loss: 0.0418  \n",
      "<<<iteration:[180/263] - total_loss: 0.2880  obj_loss: 0.1325  noobj_loss: 0.0868  bbox_loss: 0.0156  cls_loss: 0.0340  \n",
      "<<<iteration:[200/263] - total_loss: 0.2825  obj_loss: 0.1343  noobj_loss: 0.0866  bbox_loss: 0.0143  cls_loss: 0.0334  \n",
      "<<<iteration:[220/263] - total_loss: 0.3010  obj_loss: 0.1326  noobj_loss: 0.0852  bbox_loss: 0.0167  cls_loss: 0.0422  \n",
      "<<<iteration:[240/263] - total_loss: 0.2736  obj_loss: 0.1266  noobj_loss: 0.0882  bbox_loss: 0.0138  cls_loss: 0.0337  \n",
      "<<<iteration:[260/263] - total_loss: 0.3014  obj_loss: 0.1456  noobj_loss: 0.0897  bbox_loss: 0.0146  cls_loss: 0.0380  \n",
      "\n",
      "epoch:18/100 - Train Loss: 0.2901, Val Loss: 0.3157\n",
      "\n",
      "<<<iteration:[20/263] - total_loss: 0.3029  obj_loss: 0.1430  noobj_loss: 0.0923  bbox_loss: 0.0162  cls_loss: 0.0328  \n",
      "<<<iteration:[40/263] - total_loss: 0.2917  obj_loss: 0.1305  noobj_loss: 0.0844  bbox_loss: 0.0154  cls_loss: 0.0422  \n",
      "<<<iteration:[60/263] - total_loss: 0.2924  obj_loss: 0.1399  noobj_loss: 0.0861  bbox_loss: 0.0148  cls_loss: 0.0354  \n",
      "<<<iteration:[80/263] - total_loss: 0.2881  obj_loss: 0.1395  noobj_loss: 0.0861  bbox_loss: 0.0143  cls_loss: 0.0338  \n",
      "<<<iteration:[100/263] - total_loss: 0.2956  obj_loss: 0.1430  noobj_loss: 0.0898  bbox_loss: 0.0155  cls_loss: 0.0304  \n",
      "<<<iteration:[120/263] - total_loss: 0.2731  obj_loss: 0.1345  noobj_loss: 0.0865  bbox_loss: 0.0131  cls_loss: 0.0300  \n",
      "<<<iteration:[140/263] - total_loss: 0.2771  obj_loss: 0.1286  noobj_loss: 0.0878  bbox_loss: 0.0137  cls_loss: 0.0361  \n",
      "<<<iteration:[160/263] - total_loss: 0.2939  obj_loss: 0.1392  noobj_loss: 0.0867  bbox_loss: 0.0131  cls_loss: 0.0459  \n",
      "<<<iteration:[180/263] - total_loss: 0.2934  obj_loss: 0.1374  noobj_loss: 0.0855  bbox_loss: 0.0145  cls_loss: 0.0409  \n",
      "<<<iteration:[200/263] - total_loss: 0.2805  obj_loss: 0.1422  noobj_loss: 0.0849  bbox_loss: 0.0135  cls_loss: 0.0282  \n",
      "<<<iteration:[220/263] - total_loss: 0.2811  obj_loss: 0.1310  noobj_loss: 0.0883  bbox_loss: 0.0139  cls_loss: 0.0367  \n",
      "<<<iteration:[240/263] - total_loss: 0.2744  obj_loss: 0.1366  noobj_loss: 0.0842  bbox_loss: 0.0137  cls_loss: 0.0274  \n",
      "<<<iteration:[260/263] - total_loss: 0.2719  obj_loss: 0.1277  noobj_loss: 0.0877  bbox_loss: 0.0134  cls_loss: 0.0331  \n",
      "\n",
      "epoch:19/100 - Train Loss: 0.2847, Val Loss: 0.3207\n",
      "\n",
      "<<<iteration:[20/263] - total_loss: 0.2935  obj_loss: 0.1377  noobj_loss: 0.0876  bbox_loss: 0.0170  cls_loss: 0.0268  \n",
      "<<<iteration:[40/263] - total_loss: 0.3080  obj_loss: 0.1345  noobj_loss: 0.0853  bbox_loss: 0.0179  cls_loss: 0.0414  \n",
      "<<<iteration:[60/263] - total_loss: 0.2813  obj_loss: 0.1289  noobj_loss: 0.0858  bbox_loss: 0.0149  cls_loss: 0.0352  \n",
      "<<<iteration:[80/263] - total_loss: 0.2997  obj_loss: 0.1422  noobj_loss: 0.0858  bbox_loss: 0.0140  cls_loss: 0.0446  \n",
      "<<<iteration:[100/263] - total_loss: 0.2833  obj_loss: 0.1297  noobj_loss: 0.0868  bbox_loss: 0.0142  cls_loss: 0.0391  \n",
      "<<<iteration:[120/263] - total_loss: 0.2917  obj_loss: 0.1366  noobj_loss: 0.0841  bbox_loss: 0.0154  cls_loss: 0.0362  \n",
      "<<<iteration:[140/263] - total_loss: 0.2907  obj_loss: 0.1374  noobj_loss: 0.0849  bbox_loss: 0.0147  cls_loss: 0.0374  \n",
      "<<<iteration:[160/263] - total_loss: 0.2964  obj_loss: 0.1496  noobj_loss: 0.0899  bbox_loss: 0.0136  cls_loss: 0.0338  \n",
      "<<<iteration:[180/263] - total_loss: 0.2818  obj_loss: 0.1401  noobj_loss: 0.0813  bbox_loss: 0.0137  cls_loss: 0.0325  \n",
      "<<<iteration:[200/263] - total_loss: 0.2807  obj_loss: 0.1378  noobj_loss: 0.0834  bbox_loss: 0.0128  cls_loss: 0.0371  \n",
      "<<<iteration:[220/263] - total_loss: 0.2569  obj_loss: 0.1301  noobj_loss: 0.0851  bbox_loss: 0.0116  cls_loss: 0.0265  \n",
      "<<<iteration:[240/263] - total_loss: 0.2793  obj_loss: 0.1371  noobj_loss: 0.0838  bbox_loss: 0.0126  cls_loss: 0.0371  \n",
      "<<<iteration:[260/263] - total_loss: 0.2629  obj_loss: 0.1263  noobj_loss: 0.0835  bbox_loss: 0.0136  cls_loss: 0.0268  \n",
      "\n",
      "epoch:20/100 - Train Loss: 0.2841, Val Loss: 0.3185\n",
      "\n",
      "<<<iteration:[20/263] - total_loss: 0.3145  obj_loss: 0.1613  noobj_loss: 0.0899  bbox_loss: 0.0136  cls_loss: 0.0400  \n",
      "<<<iteration:[40/263] - total_loss: 0.2878  obj_loss: 0.1401  noobj_loss: 0.0853  bbox_loss: 0.0139  cls_loss: 0.0354  \n",
      "<<<iteration:[60/263] - total_loss: 0.2702  obj_loss: 0.1410  noobj_loss: 0.0791  bbox_loss: 0.0120  cls_loss: 0.0295  \n",
      "<<<iteration:[80/263] - total_loss: 0.2938  obj_loss: 0.1362  noobj_loss: 0.0863  bbox_loss: 0.0151  cls_loss: 0.0389  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<<<iteration:[100/263] - total_loss: 0.2822  obj_loss: 0.1445  noobj_loss: 0.0809  bbox_loss: 0.0133  cls_loss: 0.0307  \n",
      "<<<iteration:[120/263] - total_loss: 0.2829  obj_loss: 0.1308  noobj_loss: 0.0807  bbox_loss: 0.0145  cls_loss: 0.0395  \n",
      "<<<iteration:[140/263] - total_loss: 0.2491  obj_loss: 0.1312  noobj_loss: 0.0854  bbox_loss: 0.0108  cls_loss: 0.0213  \n",
      "<<<iteration:[160/263] - total_loss: 0.2814  obj_loss: 0.1378  noobj_loss: 0.0826  bbox_loss: 0.0139  cls_loss: 0.0331  \n",
      "<<<iteration:[180/263] - total_loss: 0.2935  obj_loss: 0.1543  noobj_loss: 0.0840  bbox_loss: 0.0140  cls_loss: 0.0273  \n",
      "<<<iteration:[200/263] - total_loss: 0.2981  obj_loss: 0.1462  noobj_loss: 0.0873  bbox_loss: 0.0153  cls_loss: 0.0317  \n",
      "<<<iteration:[220/263] - total_loss: 0.3005  obj_loss: 0.1542  noobj_loss: 0.0837  bbox_loss: 0.0144  cls_loss: 0.0323  \n",
      "<<<iteration:[240/263] - total_loss: 0.2712  obj_loss: 0.1285  noobj_loss: 0.0831  bbox_loss: 0.0129  cls_loss: 0.0364  \n",
      "<<<iteration:[260/263] - total_loss: 0.2769  obj_loss: 0.1460  noobj_loss: 0.0842  bbox_loss: 0.0127  cls_loss: 0.0252  \n",
      "\n",
      "epoch:21/100 - Train Loss: 0.2834, Val Loss: 0.3127\n",
      "\n",
      "<<<iteration:[20/263] - total_loss: 0.2969  obj_loss: 0.1474  noobj_loss: 0.0874  bbox_loss: 0.0142  cls_loss: 0.0349  \n",
      "<<<iteration:[40/263] - total_loss: 0.2712  obj_loss: 0.1260  noobj_loss: 0.0860  bbox_loss: 0.0142  cls_loss: 0.0310  \n",
      "<<<iteration:[60/263] - total_loss: 0.2850  obj_loss: 0.1334  noobj_loss: 0.0855  bbox_loss: 0.0149  cls_loss: 0.0344  \n",
      "<<<iteration:[80/263] - total_loss: 0.2855  obj_loss: 0.1376  noobj_loss: 0.0839  bbox_loss: 0.0144  cls_loss: 0.0338  \n",
      "<<<iteration:[100/263] - total_loss: 0.2823  obj_loss: 0.1486  noobj_loss: 0.0845  bbox_loss: 0.0124  cls_loss: 0.0296  \n",
      "<<<iteration:[120/263] - total_loss: 0.2783  obj_loss: 0.1405  noobj_loss: 0.0819  bbox_loss: 0.0131  cls_loss: 0.0312  \n",
      "<<<iteration:[140/263] - total_loss: 0.2651  obj_loss: 0.1292  noobj_loss: 0.0830  bbox_loss: 0.0127  cls_loss: 0.0307  \n",
      "<<<iteration:[160/263] - total_loss: 0.2775  obj_loss: 0.1348  noobj_loss: 0.0850  bbox_loss: 0.0129  cls_loss: 0.0358  \n",
      "<<<iteration:[180/263] - total_loss: 0.2985  obj_loss: 0.1368  noobj_loss: 0.0841  bbox_loss: 0.0159  cls_loss: 0.0403  \n",
      "<<<iteration:[200/263] - total_loss: 0.2823  obj_loss: 0.1416  noobj_loss: 0.0805  bbox_loss: 0.0142  cls_loss: 0.0294  \n",
      "<<<iteration:[220/263] - total_loss: 0.2806  obj_loss: 0.1347  noobj_loss: 0.0832  bbox_loss: 0.0131  cls_loss: 0.0389  \n",
      "<<<iteration:[240/263] - total_loss: 0.2655  obj_loss: 0.1349  noobj_loss: 0.0826  bbox_loss: 0.0133  cls_loss: 0.0229  \n",
      "<<<iteration:[260/263] - total_loss: 0.2602  obj_loss: 0.1374  noobj_loss: 0.0814  bbox_loss: 0.0117  cls_loss: 0.0237  \n",
      "\n",
      "epoch:22/100 - Train Loss: 0.2783, Val Loss: 0.3066\n",
      "\n",
      "<<<iteration:[20/263] - total_loss: 0.2819  obj_loss: 0.1410  noobj_loss: 0.0874  bbox_loss: 0.0130  cls_loss: 0.0323  \n",
      "<<<iteration:[40/263] - total_loss: 0.2794  obj_loss: 0.1456  noobj_loss: 0.0836  bbox_loss: 0.0115  cls_loss: 0.0343  \n",
      "<<<iteration:[60/263] - total_loss: 0.2760  obj_loss: 0.1441  noobj_loss: 0.0825  bbox_loss: 0.0115  cls_loss: 0.0331  \n",
      "<<<iteration:[80/263] - total_loss: 0.2707  obj_loss: 0.1332  noobj_loss: 0.0843  bbox_loss: 0.0125  cls_loss: 0.0329  \n",
      "<<<iteration:[100/263] - total_loss: 0.2735  obj_loss: 0.1393  noobj_loss: 0.0837  bbox_loss: 0.0126  cls_loss: 0.0293  \n",
      "<<<iteration:[120/263] - total_loss: 0.2840  obj_loss: 0.1351  noobj_loss: 0.0820  bbox_loss: 0.0146  cls_loss: 0.0349  \n",
      "<<<iteration:[140/263] - total_loss: 0.2884  obj_loss: 0.1533  noobj_loss: 0.0866  bbox_loss: 0.0129  cls_loss: 0.0274  \n",
      "<<<iteration:[160/263] - total_loss: 0.2653  obj_loss: 0.1474  noobj_loss: 0.0815  bbox_loss: 0.0101  cls_loss: 0.0268  \n",
      "<<<iteration:[180/263] - total_loss: 0.2766  obj_loss: 0.1475  noobj_loss: 0.0801  bbox_loss: 0.0130  cls_loss: 0.0238  \n",
      "<<<iteration:[200/263] - total_loss: 0.2913  obj_loss: 0.1448  noobj_loss: 0.0826  bbox_loss: 0.0140  cls_loss: 0.0352  \n",
      "<<<iteration:[220/263] - total_loss: 0.2722  obj_loss: 0.1334  noobj_loss: 0.0846  bbox_loss: 0.0119  cls_loss: 0.0369  \n",
      "<<<iteration:[240/263] - total_loss: 0.2831  obj_loss: 0.1453  noobj_loss: 0.0807  bbox_loss: 0.0129  cls_loss: 0.0330  \n",
      "<<<iteration:[260/263] - total_loss: 0.2660  obj_loss: 0.1380  noobj_loss: 0.0806  bbox_loss: 0.0122  cls_loss: 0.0268  \n",
      "\n",
      "epoch:23/100 - Train Loss: 0.2770, Val Loss: 0.3002\n",
      "\n",
      "<<<iteration:[20/263] - total_loss: 0.2831  obj_loss: 0.1405  noobj_loss: 0.0890  bbox_loss: 0.0132  cls_loss: 0.0320  \n",
      "<<<iteration:[40/263] - total_loss: 0.2707  obj_loss: 0.1436  noobj_loss: 0.0826  bbox_loss: 0.0118  cls_loss: 0.0266  \n",
      "<<<iteration:[60/263] - total_loss: 0.2773  obj_loss: 0.1431  noobj_loss: 0.0824  bbox_loss: 0.0123  cls_loss: 0.0317  \n",
      "<<<iteration:[80/263] - total_loss: 0.2598  obj_loss: 0.1406  noobj_loss: 0.0805  bbox_loss: 0.0113  cls_loss: 0.0227  \n",
      "<<<iteration:[100/263] - total_loss: 0.2704  obj_loss: 0.1389  noobj_loss: 0.0790  bbox_loss: 0.0125  cls_loss: 0.0297  \n",
      "<<<iteration:[120/263] - total_loss: 0.2798  obj_loss: 0.1618  noobj_loss: 0.0794  bbox_loss: 0.0108  cls_loss: 0.0243  \n",
      "<<<iteration:[140/263] - total_loss: 0.2641  obj_loss: 0.1379  noobj_loss: 0.0817  bbox_loss: 0.0122  cls_loss: 0.0240  \n",
      "<<<iteration:[160/263] - total_loss: 0.2779  obj_loss: 0.1418  noobj_loss: 0.0813  bbox_loss: 0.0123  cls_loss: 0.0338  \n",
      "<<<iteration:[180/263] - total_loss: 0.2785  obj_loss: 0.1468  noobj_loss: 0.0818  bbox_loss: 0.0117  cls_loss: 0.0325  \n",
      "<<<iteration:[200/263] - total_loss: 0.2629  obj_loss: 0.1380  noobj_loss: 0.0820  bbox_loss: 0.0116  cls_loss: 0.0261  \n",
      "<<<iteration:[220/263] - total_loss: 0.2625  obj_loss: 0.1498  noobj_loss: 0.0815  bbox_loss: 0.0100  cls_loss: 0.0222  \n",
      "<<<iteration:[240/263] - total_loss: 0.2800  obj_loss: 0.1428  noobj_loss: 0.0802  bbox_loss: 0.0132  cls_loss: 0.0310  \n",
      "<<<iteration:[260/263] - total_loss: 0.2780  obj_loss: 0.1429  noobj_loss: 0.0815  bbox_loss: 0.0128  cls_loss: 0.0303  \n",
      "\n",
      "epoch:24/100 - Train Loss: 0.2718, Val Loss: 0.3038\n",
      "\n",
      "<<<iteration:[20/263] - total_loss: 0.2757  obj_loss: 0.1481  noobj_loss: 0.0841  bbox_loss: 0.0116  cls_loss: 0.0275  \n",
      "<<<iteration:[40/263] - total_loss: 0.2655  obj_loss: 0.1374  noobj_loss: 0.0846  bbox_loss: 0.0112  cls_loss: 0.0295  \n",
      "<<<iteration:[60/263] - total_loss: 0.2679  obj_loss: 0.1452  noobj_loss: 0.0803  bbox_loss: 0.0116  cls_loss: 0.0246  \n",
      "<<<iteration:[80/263] - total_loss: 0.2647  obj_loss: 0.1449  noobj_loss: 0.0827  bbox_loss: 0.0111  cls_loss: 0.0230  \n",
      "<<<iteration:[100/263] - total_loss: 0.2865  obj_loss: 0.1501  noobj_loss: 0.0822  bbox_loss: 0.0118  cls_loss: 0.0365  \n",
      "<<<iteration:[120/263] - total_loss: 0.2634  obj_loss: 0.1444  noobj_loss: 0.0812  bbox_loss: 0.0110  cls_loss: 0.0237  \n",
      "<<<iteration:[140/263] - total_loss: 0.2763  obj_loss: 0.1601  noobj_loss: 0.0793  bbox_loss: 0.0104  cls_loss: 0.0243  \n",
      "<<<iteration:[160/263] - total_loss: 0.2885  obj_loss: 0.1513  noobj_loss: 0.0822  bbox_loss: 0.0129  cls_loss: 0.0317  \n",
      "<<<iteration:[180/263] - total_loss: 0.2921  obj_loss: 0.1526  noobj_loss: 0.0836  bbox_loss: 0.0138  cls_loss: 0.0284  \n",
      "<<<iteration:[200/263] - total_loss: 0.2834  obj_loss: 0.1462  noobj_loss: 0.0862  bbox_loss: 0.0132  cls_loss: 0.0279  \n",
      "<<<iteration:[220/263] - total_loss: 0.2666  obj_loss: 0.1418  noobj_loss: 0.0800  bbox_loss: 0.0114  cls_loss: 0.0277  \n",
      "<<<iteration:[240/263] - total_loss: 0.2721  obj_loss: 0.1361  noobj_loss: 0.0811  bbox_loss: 0.0123  cls_loss: 0.0342  \n",
      "<<<iteration:[260/263] - total_loss: 0.2777  obj_loss: 0.1552  noobj_loss: 0.0824  bbox_loss: 0.0107  cls_loss: 0.0278  \n",
      "\n",
      "epoch:25/100 - Train Loss: 0.2740, Val Loss: 0.2975\n",
      "\n",
      "<<<iteration:[20/263] - total_loss: 0.2852  obj_loss: 0.1553  noobj_loss: 0.0877  bbox_loss: 0.0118  cls_loss: 0.0273  \n",
      "<<<iteration:[40/263] - total_loss: 0.2771  obj_loss: 0.1479  noobj_loss: 0.0812  bbox_loss: 0.0125  cls_loss: 0.0261  \n",
      "<<<iteration:[60/263] - total_loss: 0.2794  obj_loss: 0.1389  noobj_loss: 0.0834  bbox_loss: 0.0126  cls_loss: 0.0357  \n",
      "<<<iteration:[80/263] - total_loss: 0.2698  obj_loss: 0.1250  noobj_loss: 0.0778  bbox_loss: 0.0156  cls_loss: 0.0280  \n",
      "<<<iteration:[100/263] - total_loss: 0.2676  obj_loss: 0.1333  noobj_loss: 0.0802  bbox_loss: 0.0133  cls_loss: 0.0276  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<<<iteration:[120/263] - total_loss: 0.2725  obj_loss: 0.1439  noobj_loss: 0.0823  bbox_loss: 0.0121  cls_loss: 0.0270  \n",
      "<<<iteration:[140/263] - total_loss: 0.2724  obj_loss: 0.1462  noobj_loss: 0.0810  bbox_loss: 0.0110  cls_loss: 0.0306  \n",
      "<<<iteration:[160/263] - total_loss: 0.2741  obj_loss: 0.1520  noobj_loss: 0.0848  bbox_loss: 0.0101  cls_loss: 0.0290  \n",
      "<<<iteration:[180/263] - total_loss: 0.2710  obj_loss: 0.1447  noobj_loss: 0.0797  bbox_loss: 0.0111  cls_loss: 0.0312  \n",
      "<<<iteration:[200/263] - total_loss: 0.2720  obj_loss: 0.1453  noobj_loss: 0.0817  bbox_loss: 0.0113  cls_loss: 0.0292  \n",
      "<<<iteration:[220/263] - total_loss: 0.2706  obj_loss: 0.1422  noobj_loss: 0.0796  bbox_loss: 0.0122  cls_loss: 0.0274  \n",
      "<<<iteration:[240/263] - total_loss: 0.2703  obj_loss: 0.1454  noobj_loss: 0.0814  bbox_loss: 0.0113  cls_loss: 0.0276  \n",
      "<<<iteration:[260/263] - total_loss: 0.2562  obj_loss: 0.1407  noobj_loss: 0.0797  bbox_loss: 0.0102  cls_loss: 0.0247  \n",
      "\n",
      "epoch:26/100 - Train Loss: 0.2712, Val Loss: 0.2946\n",
      "\n",
      "<<<iteration:[20/263] - total_loss: 0.2921  obj_loss: 0.1550  noobj_loss: 0.0846  bbox_loss: 0.0123  cls_loss: 0.0332  \n",
      "<<<iteration:[40/263] - total_loss: 0.2726  obj_loss: 0.1477  noobj_loss: 0.0812  bbox_loss: 0.0111  cls_loss: 0.0290  \n",
      "<<<iteration:[60/263] - total_loss: 0.2654  obj_loss: 0.1422  noobj_loss: 0.0808  bbox_loss: 0.0106  cls_loss: 0.0297  \n",
      "<<<iteration:[80/263] - total_loss: 0.2849  obj_loss: 0.1602  noobj_loss: 0.0845  bbox_loss: 0.0109  cls_loss: 0.0279  \n",
      "<<<iteration:[100/263] - total_loss: 0.2606  obj_loss: 0.1385  noobj_loss: 0.0866  bbox_loss: 0.0102  cls_loss: 0.0277  \n",
      "<<<iteration:[120/263] - total_loss: 0.2763  obj_loss: 0.1547  noobj_loss: 0.0829  bbox_loss: 0.0097  cls_loss: 0.0317  \n",
      "<<<iteration:[140/263] - total_loss: 0.2705  obj_loss: 0.1464  noobj_loss: 0.0848  bbox_loss: 0.0111  cls_loss: 0.0260  \n",
      "<<<iteration:[160/263] - total_loss: 0.2702  obj_loss: 0.1419  noobj_loss: 0.0809  bbox_loss: 0.0124  cls_loss: 0.0259  \n",
      "<<<iteration:[180/263] - total_loss: 0.2566  obj_loss: 0.1414  noobj_loss: 0.0793  bbox_loss: 0.0099  cls_loss: 0.0259  \n",
      "<<<iteration:[200/263] - total_loss: 0.2908  obj_loss: 0.1650  noobj_loss: 0.0839  bbox_loss: 0.0110  cls_loss: 0.0288  \n",
      "<<<iteration:[220/263] - total_loss: 0.2652  obj_loss: 0.1545  noobj_loss: 0.0794  bbox_loss: 0.0100  cls_loss: 0.0210  \n",
      "<<<iteration:[240/263] - total_loss: 0.2782  obj_loss: 0.1559  noobj_loss: 0.0810  bbox_loss: 0.0115  cls_loss: 0.0245  \n",
      "<<<iteration:[260/263] - total_loss: 0.2809  obj_loss: 0.1607  noobj_loss: 0.0836  bbox_loss: 0.0111  cls_loss: 0.0227  \n",
      "\n",
      "epoch:27/100 - Train Loss: 0.2729, Val Loss: 0.2916\n",
      "\n",
      "<<<iteration:[20/263] - total_loss: 0.2942  obj_loss: 0.1696  noobj_loss: 0.0879  bbox_loss: 0.0106  cls_loss: 0.0279  \n",
      "<<<iteration:[40/263] - total_loss: 0.2754  obj_loss: 0.1404  noobj_loss: 0.0831  bbox_loss: 0.0116  cls_loss: 0.0353  \n",
      "<<<iteration:[60/263] - total_loss: 0.2677  obj_loss: 0.1561  noobj_loss: 0.0819  bbox_loss: 0.0094  cls_loss: 0.0237  \n",
      "<<<iteration:[80/263] - total_loss: 0.2662  obj_loss: 0.1525  noobj_loss: 0.0837  bbox_loss: 0.0098  cls_loss: 0.0228  \n",
      "<<<iteration:[100/263] - total_loss: 0.2728  obj_loss: 0.1603  noobj_loss: 0.0824  bbox_loss: 0.0103  cls_loss: 0.0195  \n",
      "<<<iteration:[120/263] - total_loss: 0.2778  obj_loss: 0.1582  noobj_loss: 0.0838  bbox_loss: 0.0113  cls_loss: 0.0212  \n",
      "<<<iteration:[140/263] - total_loss: 0.2854  obj_loss: 0.1636  noobj_loss: 0.0829  bbox_loss: 0.0101  cls_loss: 0.0297  \n",
      "<<<iteration:[160/263] - total_loss: 0.2613  obj_loss: 0.1413  noobj_loss: 0.0809  bbox_loss: 0.0103  cls_loss: 0.0280  \n",
      "<<<iteration:[180/263] - total_loss: 0.2784  obj_loss: 0.1535  noobj_loss: 0.0824  bbox_loss: 0.0107  cls_loss: 0.0303  \n",
      "<<<iteration:[200/263] - total_loss: 0.2817  obj_loss: 0.1569  noobj_loss: 0.0869  bbox_loss: 0.0104  cls_loss: 0.0292  \n",
      "<<<iteration:[220/263] - total_loss: 0.2575  obj_loss: 0.1226  noobj_loss: 0.0817  bbox_loss: 0.0128  cls_loss: 0.0298  \n",
      "<<<iteration:[240/263] - total_loss: 0.2626  obj_loss: 0.1358  noobj_loss: 0.0845  bbox_loss: 0.0115  cls_loss: 0.0269  \n",
      "<<<iteration:[260/263] - total_loss: 0.2646  obj_loss: 0.1441  noobj_loss: 0.0818  bbox_loss: 0.0109  cls_loss: 0.0250  \n",
      "\n",
      "epoch:28/100 - Train Loss: 0.2714, Val Loss: 0.2941\n",
      "\n",
      "<<<iteration:[20/263] - total_loss: 0.2843  obj_loss: 0.1592  noobj_loss: 0.0879  bbox_loss: 0.0110  cls_loss: 0.0261  \n",
      "<<<iteration:[40/263] - total_loss: 0.2721  obj_loss: 0.1448  noobj_loss: 0.0811  bbox_loss: 0.0111  cls_loss: 0.0310  \n",
      "<<<iteration:[60/263] - total_loss: 0.2573  obj_loss: 0.1502  noobj_loss: 0.0783  bbox_loss: 0.0094  cls_loss: 0.0210  \n",
      "<<<iteration:[80/263] - total_loss: 0.2736  obj_loss: 0.1507  noobj_loss: 0.0808  bbox_loss: 0.0115  cls_loss: 0.0250  \n",
      "<<<iteration:[100/263] - total_loss: 0.2768  obj_loss: 0.1432  noobj_loss: 0.0852  bbox_loss: 0.0118  cls_loss: 0.0321  \n",
      "<<<iteration:[120/263] - total_loss: 0.2717  obj_loss: 0.1443  noobj_loss: 0.0832  bbox_loss: 0.0112  cls_loss: 0.0296  \n",
      "<<<iteration:[140/263] - total_loss: 0.2636  obj_loss: 0.1493  noobj_loss: 0.0818  bbox_loss: 0.0096  cls_loss: 0.0254  \n",
      "<<<iteration:[160/263] - total_loss: 0.2633  obj_loss: 0.1466  noobj_loss: 0.0808  bbox_loss: 0.0106  cls_loss: 0.0235  \n",
      "<<<iteration:[180/263] - total_loss: 0.2788  obj_loss: 0.1594  noobj_loss: 0.0819  bbox_loss: 0.0102  cls_loss: 0.0274  \n",
      "<<<iteration:[200/263] - total_loss: 0.2764  obj_loss: 0.1628  noobj_loss: 0.0837  bbox_loss: 0.0100  cls_loss: 0.0218  \n",
      "<<<iteration:[220/263] - total_loss: 0.2577  obj_loss: 0.1532  noobj_loss: 0.0785  bbox_loss: 0.0093  cls_loss: 0.0185  \n",
      "<<<iteration:[240/263] - total_loss: 0.2763  obj_loss: 0.1608  noobj_loss: 0.0791  bbox_loss: 0.0106  cls_loss: 0.0228  \n",
      "<<<iteration:[260/263] - total_loss: 0.2685  obj_loss: 0.1499  noobj_loss: 0.0807  bbox_loss: 0.0103  cls_loss: 0.0268  \n",
      "\n",
      "epoch:29/100 - Train Loss: 0.2699, Val Loss: 0.2920\n",
      "\n",
      "<<<iteration:[20/263] - total_loss: 0.2954  obj_loss: 0.1591  noobj_loss: 0.0898  bbox_loss: 0.0124  cls_loss: 0.0295  \n",
      "<<<iteration:[40/263] - total_loss: 0.2577  obj_loss: 0.1484  noobj_loss: 0.0800  bbox_loss: 0.0090  cls_loss: 0.0243  \n",
      "<<<iteration:[60/263] - total_loss: 0.2562  obj_loss: 0.1480  noobj_loss: 0.0829  bbox_loss: 0.0088  cls_loss: 0.0228  \n",
      "<<<iteration:[80/263] - total_loss: 0.2632  obj_loss: 0.1479  noobj_loss: 0.0821  bbox_loss: 0.0103  cls_loss: 0.0228  \n",
      "<<<iteration:[100/263] - total_loss: 0.2634  obj_loss: 0.1434  noobj_loss: 0.0849  bbox_loss: 0.0097  cls_loss: 0.0290  \n",
      "<<<iteration:[120/263] - total_loss: 0.2809  obj_loss: 0.1537  noobj_loss: 0.0826  bbox_loss: 0.0115  cls_loss: 0.0285  \n",
      "<<<iteration:[140/263] - total_loss: 0.2693  obj_loss: 0.1422  noobj_loss: 0.0838  bbox_loss: 0.0112  cls_loss: 0.0292  \n",
      "<<<iteration:[160/263] - total_loss: 0.2676  obj_loss: 0.1517  noobj_loss: 0.0830  bbox_loss: 0.0099  cls_loss: 0.0252  \n",
      "<<<iteration:[180/263] - total_loss: 0.2587  obj_loss: 0.1439  noobj_loss: 0.0804  bbox_loss: 0.0102  cls_loss: 0.0235  \n",
      "<<<iteration:[200/263] - total_loss: 0.2606  obj_loss: 0.1510  noobj_loss: 0.0813  bbox_loss: 0.0092  cls_loss: 0.0231  \n",
      "<<<iteration:[220/263] - total_loss: 0.2705  obj_loss: 0.1557  noobj_loss: 0.0857  bbox_loss: 0.0097  cls_loss: 0.0232  \n",
      "<<<iteration:[240/263] - total_loss: 0.2743  obj_loss: 0.1556  noobj_loss: 0.0831  bbox_loss: 0.0107  cls_loss: 0.0234  \n",
      "<<<iteration:[260/263] - total_loss: 0.2577  obj_loss: 0.1469  noobj_loss: 0.0815  bbox_loss: 0.0100  cls_loss: 0.0199  \n",
      "\n",
      "epoch:30/100 - Train Loss: 0.2662, Val Loss: 0.2815\n",
      "\n",
      "<<<iteration:[20/263] - total_loss: 0.2755  obj_loss: 0.1643  noobj_loss: 0.0877  bbox_loss: 0.0092  cls_loss: 0.0215  \n",
      "<<<iteration:[40/263] - total_loss: 0.2718  obj_loss: 0.1595  noobj_loss: 0.0834  bbox_loss: 0.0100  cls_loss: 0.0204  \n",
      "<<<iteration:[60/263] - total_loss: 0.2782  obj_loss: 0.1597  noobj_loss: 0.0828  bbox_loss: 0.0103  cls_loss: 0.0258  \n",
      "<<<iteration:[80/263] - total_loss: 0.2763  obj_loss: 0.1529  noobj_loss: 0.0856  bbox_loss: 0.0105  cls_loss: 0.0281  \n",
      "<<<iteration:[100/263] - total_loss: 0.2809  obj_loss: 0.1653  noobj_loss: 0.0841  bbox_loss: 0.0102  cls_loss: 0.0226  \n",
      "<<<iteration:[120/263] - total_loss: 0.2527  obj_loss: 0.1533  noobj_loss: 0.0789  bbox_loss: 0.0086  cls_loss: 0.0167  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<<<iteration:[140/263] - total_loss: 0.2923  obj_loss: 0.1614  noobj_loss: 0.0878  bbox_loss: 0.0110  cls_loss: 0.0319  \n",
      "<<<iteration:[160/263] - total_loss: 0.2643  obj_loss: 0.1486  noobj_loss: 0.0862  bbox_loss: 0.0105  cls_loss: 0.0200  \n",
      "<<<iteration:[180/263] - total_loss: 0.2721  obj_loss: 0.1501  noobj_loss: 0.0853  bbox_loss: 0.0105  cls_loss: 0.0268  \n",
      "<<<iteration:[200/263] - total_loss: 0.2755  obj_loss: 0.1599  noobj_loss: 0.0850  bbox_loss: 0.0099  cls_loss: 0.0238  \n",
      "<<<iteration:[220/263] - total_loss: 0.2592  obj_loss: 0.1463  noobj_loss: 0.0808  bbox_loss: 0.0098  cls_loss: 0.0235  \n",
      "<<<iteration:[240/263] - total_loss: 0.2683  obj_loss: 0.1574  noobj_loss: 0.0831  bbox_loss: 0.0094  cls_loss: 0.0226  \n",
      "<<<iteration:[260/263] - total_loss: 0.2645  obj_loss: 0.1452  noobj_loss: 0.0844  bbox_loss: 0.0101  cls_loss: 0.0263  \n",
      "\n",
      "epoch:31/100 - Train Loss: 0.2708, Val Loss: 0.2968\n",
      "\n",
      "<<<iteration:[20/263] - total_loss: 0.2710  obj_loss: 0.1482  noobj_loss: 0.0866  bbox_loss: 0.0118  cls_loss: 0.0204  \n",
      "<<<iteration:[40/263] - total_loss: 0.2665  obj_loss: 0.1467  noobj_loss: 0.0812  bbox_loss: 0.0110  cls_loss: 0.0244  \n",
      "<<<iteration:[60/263] - total_loss: 0.2683  obj_loss: 0.1531  noobj_loss: 0.0809  bbox_loss: 0.0103  cls_loss: 0.0231  \n",
      "<<<iteration:[80/263] - total_loss: 0.2721  obj_loss: 0.1578  noobj_loss: 0.0839  bbox_loss: 0.0102  cls_loss: 0.0216  \n",
      "<<<iteration:[100/263] - total_loss: 0.2765  obj_loss: 0.1617  noobj_loss: 0.0840  bbox_loss: 0.0101  cls_loss: 0.0222  \n",
      "<<<iteration:[120/263] - total_loss: 0.2689  obj_loss: 0.1438  noobj_loss: 0.0827  bbox_loss: 0.0112  cls_loss: 0.0280  \n",
      "<<<iteration:[140/263] - total_loss: 0.2806  obj_loss: 0.1588  noobj_loss: 0.0879  bbox_loss: 0.0099  cls_loss: 0.0284  \n",
      "<<<iteration:[160/263] - total_loss: 0.2572  obj_loss: 0.1403  noobj_loss: 0.0835  bbox_loss: 0.0101  cls_loss: 0.0245  \n",
      "<<<iteration:[180/263] - total_loss: 0.2703  obj_loss: 0.1468  noobj_loss: 0.0812  bbox_loss: 0.0117  cls_loss: 0.0244  \n",
      "<<<iteration:[200/263] - total_loss: 0.2810  obj_loss: 0.1640  noobj_loss: 0.0827  bbox_loss: 0.0101  cls_loss: 0.0252  \n",
      "<<<iteration:[220/263] - total_loss: 0.2515  obj_loss: 0.1419  noobj_loss: 0.0815  bbox_loss: 0.0098  cls_loss: 0.0199  \n",
      "<<<iteration:[240/263] - total_loss: 0.2736  obj_loss: 0.1479  noobj_loss: 0.0815  bbox_loss: 0.0120  cls_loss: 0.0251  \n",
      "<<<iteration:[260/263] - total_loss: 0.2631  obj_loss: 0.1548  noobj_loss: 0.0840  bbox_loss: 0.0098  cls_loss: 0.0171  \n",
      "\n",
      "epoch:32/100 - Train Loss: 0.2680, Val Loss: 0.2839\n",
      "\n",
      "<<<iteration:[20/263] - total_loss: 0.2712  obj_loss: 0.1585  noobj_loss: 0.0830  bbox_loss: 0.0103  cls_loss: 0.0199  \n",
      "<<<iteration:[40/263] - total_loss: 0.2571  obj_loss: 0.1481  noobj_loss: 0.0792  bbox_loss: 0.0094  cls_loss: 0.0223  \n",
      "<<<iteration:[60/263] - total_loss: 0.2627  obj_loss: 0.1547  noobj_loss: 0.0818  bbox_loss: 0.0088  cls_loss: 0.0229  \n",
      "<<<iteration:[80/263] - total_loss: 0.2627  obj_loss: 0.1570  noobj_loss: 0.0852  bbox_loss: 0.0088  cls_loss: 0.0193  \n",
      "<<<iteration:[100/263] - total_loss: 0.2780  obj_loss: 0.1683  noobj_loss: 0.0837  bbox_loss: 0.0097  cls_loss: 0.0193  \n",
      "<<<iteration:[120/263] - total_loss: 0.2691  obj_loss: 0.1595  noobj_loss: 0.0822  bbox_loss: 0.0100  cls_loss: 0.0188  \n",
      "<<<iteration:[140/263] - total_loss: 0.2766  obj_loss: 0.1494  noobj_loss: 0.0858  bbox_loss: 0.0106  cls_loss: 0.0313  \n",
      "<<<iteration:[160/263] - total_loss: 0.2733  obj_loss: 0.1605  noobj_loss: 0.0823  bbox_loss: 0.0093  cls_loss: 0.0250  \n",
      "<<<iteration:[180/263] - total_loss: 0.2815  obj_loss: 0.1613  noobj_loss: 0.0854  bbox_loss: 0.0113  cls_loss: 0.0211  \n",
      "<<<iteration:[200/263] - total_loss: 0.2620  obj_loss: 0.1544  noobj_loss: 0.0853  bbox_loss: 0.0085  cls_loss: 0.0222  \n",
      "<<<iteration:[220/263] - total_loss: 0.2681  obj_loss: 0.1577  noobj_loss: 0.0827  bbox_loss: 0.0098  cls_loss: 0.0200  \n",
      "<<<iteration:[240/263] - total_loss: 0.2756  obj_loss: 0.1627  noobj_loss: 0.0860  bbox_loss: 0.0091  cls_loss: 0.0243  \n",
      "<<<iteration:[260/263] - total_loss: 0.2714  obj_loss: 0.1531  noobj_loss: 0.0854  bbox_loss: 0.0101  cls_loss: 0.0251  \n",
      "\n",
      "epoch:33/100 - Train Loss: 0.2690, Val Loss: 0.2808\n",
      "\n",
      "<<<iteration:[20/263] - total_loss: 0.2852  obj_loss: 0.1697  noobj_loss: 0.0912  bbox_loss: 0.0094  cls_loss: 0.0227  \n",
      "<<<iteration:[40/263] - total_loss: 0.2671  obj_loss: 0.1541  noobj_loss: 0.0855  bbox_loss: 0.0095  cls_loss: 0.0230  \n",
      "<<<iteration:[60/263] - total_loss: 0.2660  obj_loss: 0.1569  noobj_loss: 0.0832  bbox_loss: 0.0091  cls_loss: 0.0220  \n",
      "<<<iteration:[80/263] - total_loss: 0.2638  obj_loss: 0.1526  noobj_loss: 0.0831  bbox_loss: 0.0095  cls_loss: 0.0222  \n",
      "<<<iteration:[100/263] - total_loss: 0.2706  obj_loss: 0.1575  noobj_loss: 0.0858  bbox_loss: 0.0091  cls_loss: 0.0249  \n",
      "<<<iteration:[120/263] - total_loss: 0.2530  obj_loss: 0.1460  noobj_loss: 0.0845  bbox_loss: 0.0089  cls_loss: 0.0202  \n",
      "<<<iteration:[140/263] - total_loss: 0.2576  obj_loss: 0.1559  noobj_loss: 0.0853  bbox_loss: 0.0087  cls_loss: 0.0157  \n",
      "<<<iteration:[160/263] - total_loss: 0.2729  obj_loss: 0.1599  noobj_loss: 0.0827  bbox_loss: 0.0100  cls_loss: 0.0215  \n",
      "<<<iteration:[180/263] - total_loss: 0.2814  obj_loss: 0.1641  noobj_loss: 0.0851  bbox_loss: 0.0109  cls_loss: 0.0202  \n",
      "<<<iteration:[200/263] - total_loss: 0.2622  obj_loss: 0.1520  noobj_loss: 0.0861  bbox_loss: 0.0081  cls_loss: 0.0265  \n",
      "<<<iteration:[220/263] - total_loss: 0.2661  obj_loss: 0.1580  noobj_loss: 0.0862  bbox_loss: 0.0086  cls_loss: 0.0218  \n",
      "<<<iteration:[240/263] - total_loss: 0.2644  obj_loss: 0.1588  noobj_loss: 0.0852  bbox_loss: 0.0092  cls_loss: 0.0169  \n",
      "<<<iteration:[260/263] - total_loss: 0.2570  obj_loss: 0.1475  noobj_loss: 0.0860  bbox_loss: 0.0090  cls_loss: 0.0217  \n",
      "\n",
      "epoch:34/100 - Train Loss: 0.2653, Val Loss: 0.2772\n",
      "\n",
      "<<<iteration:[20/263] - total_loss: 0.2827  obj_loss: 0.1658  noobj_loss: 0.0895  bbox_loss: 0.0099  cls_loss: 0.0225  \n",
      "<<<iteration:[40/263] - total_loss: 0.2808  obj_loss: 0.1580  noobj_loss: 0.0846  bbox_loss: 0.0103  cls_loss: 0.0291  \n",
      "<<<iteration:[60/263] - total_loss: 0.2689  obj_loss: 0.1624  noobj_loss: 0.0866  bbox_loss: 0.0086  cls_loss: 0.0203  \n",
      "<<<iteration:[80/263] - total_loss: 0.2445  obj_loss: 0.1403  noobj_loss: 0.0847  bbox_loss: 0.0091  cls_loss: 0.0162  \n",
      "<<<iteration:[100/263] - total_loss: 0.2500  obj_loss: 0.1507  noobj_loss: 0.0830  bbox_loss: 0.0082  cls_loss: 0.0168  \n",
      "<<<iteration:[120/263] - total_loss: 0.2537  obj_loss: 0.1535  noobj_loss: 0.0858  bbox_loss: 0.0080  cls_loss: 0.0174  \n",
      "<<<iteration:[140/263] - total_loss: 0.2614  obj_loss: 0.1556  noobj_loss: 0.0853  bbox_loss: 0.0086  cls_loss: 0.0200  \n",
      "<<<iteration:[160/263] - total_loss: 0.2779  obj_loss: 0.1644  noobj_loss: 0.0859  bbox_loss: 0.0089  cls_loss: 0.0259  \n",
      "<<<iteration:[180/263] - total_loss: 0.2589  obj_loss: 0.1490  noobj_loss: 0.0838  bbox_loss: 0.0092  cls_loss: 0.0220  \n",
      "<<<iteration:[200/263] - total_loss: 0.2706  obj_loss: 0.1547  noobj_loss: 0.0881  bbox_loss: 0.0105  cls_loss: 0.0194  \n",
      "<<<iteration:[220/263] - total_loss: 0.2576  obj_loss: 0.1489  noobj_loss: 0.0832  bbox_loss: 0.0093  cls_loss: 0.0204  \n",
      "<<<iteration:[240/263] - total_loss: 0.2568  obj_loss: 0.1554  noobj_loss: 0.0854  bbox_loss: 0.0084  cls_loss: 0.0168  \n",
      "<<<iteration:[260/263] - total_loss: 0.2501  obj_loss: 0.1491  noobj_loss: 0.0833  bbox_loss: 0.0082  cls_loss: 0.0183  \n",
      "\n",
      "epoch:35/100 - Train Loss: 0.2617, Val Loss: 0.2792\n",
      "\n",
      "<<<iteration:[20/263] - total_loss: 0.2665  obj_loss: 0.1603  noobj_loss: 0.0864  bbox_loss: 0.0086  cls_loss: 0.0202  \n",
      "<<<iteration:[40/263] - total_loss: 0.2540  obj_loss: 0.1527  noobj_loss: 0.0836  bbox_loss: 0.0085  cls_loss: 0.0170  \n",
      "<<<iteration:[60/263] - total_loss: 0.2509  obj_loss: 0.1406  noobj_loss: 0.0843  bbox_loss: 0.0096  cls_loss: 0.0201  \n",
      "<<<iteration:[80/263] - total_loss: 0.2629  obj_loss: 0.1560  noobj_loss: 0.0880  bbox_loss: 0.0086  cls_loss: 0.0198  \n",
      "<<<iteration:[100/263] - total_loss: 0.2755  obj_loss: 0.1686  noobj_loss: 0.0830  bbox_loss: 0.0086  cls_loss: 0.0224  \n",
      "<<<iteration:[120/263] - total_loss: 0.2709  obj_loss: 0.1605  noobj_loss: 0.0845  bbox_loss: 0.0093  cls_loss: 0.0218  \n",
      "<<<iteration:[140/263] - total_loss: 0.2783  obj_loss: 0.1675  noobj_loss: 0.0885  bbox_loss: 0.0094  cls_loss: 0.0196  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<<<iteration:[160/263] - total_loss: 0.2688  obj_loss: 0.1584  noobj_loss: 0.0878  bbox_loss: 0.0092  cls_loss: 0.0207  \n",
      "<<<iteration:[180/263] - total_loss: 0.2472  obj_loss: 0.1446  noobj_loss: 0.0844  bbox_loss: 0.0087  cls_loss: 0.0172  \n",
      "<<<iteration:[200/263] - total_loss: 0.2677  obj_loss: 0.1563  noobj_loss: 0.0856  bbox_loss: 0.0089  cls_loss: 0.0243  \n",
      "<<<iteration:[220/263] - total_loss: 0.2571  obj_loss: 0.1519  noobj_loss: 0.0857  bbox_loss: 0.0081  cls_loss: 0.0216  \n",
      "<<<iteration:[240/263] - total_loss: 0.2730  obj_loss: 0.1642  noobj_loss: 0.0891  bbox_loss: 0.0086  cls_loss: 0.0213  \n",
      "<<<iteration:[260/263] - total_loss: 0.2728  obj_loss: 0.1661  noobj_loss: 0.0860  bbox_loss: 0.0095  cls_loss: 0.0162  \n",
      "\n",
      "epoch:36/100 - Train Loss: 0.2642, Val Loss: 0.2851\n",
      "\n",
      "<<<iteration:[20/263] - total_loss: 0.2782  obj_loss: 0.1709  noobj_loss: 0.0931  bbox_loss: 0.0084  cls_loss: 0.0189  \n",
      "<<<iteration:[40/263] - total_loss: 0.2541  obj_loss: 0.1550  noobj_loss: 0.0856  bbox_loss: 0.0076  cls_loss: 0.0182  \n",
      "<<<iteration:[60/263] - total_loss: 0.2740  obj_loss: 0.1693  noobj_loss: 0.0873  bbox_loss: 0.0084  cls_loss: 0.0193  \n",
      "<<<iteration:[80/263] - total_loss: 0.2670  obj_loss: 0.1672  noobj_loss: 0.0895  bbox_loss: 0.0074  cls_loss: 0.0178  \n",
      "<<<iteration:[100/263] - total_loss: 0.2684  obj_loss: 0.1592  noobj_loss: 0.0862  bbox_loss: 0.0091  cls_loss: 0.0205  \n",
      "<<<iteration:[120/263] - total_loss: 0.2599  obj_loss: 0.1567  noobj_loss: 0.0865  bbox_loss: 0.0083  cls_loss: 0.0186  \n",
      "<<<iteration:[140/263] - total_loss: 0.2819  obj_loss: 0.1720  noobj_loss: 0.0861  bbox_loss: 0.0092  cls_loss: 0.0206  \n",
      "<<<iteration:[160/263] - total_loss: 0.2596  obj_loss: 0.1558  noobj_loss: 0.0858  bbox_loss: 0.0082  cls_loss: 0.0198  \n",
      "<<<iteration:[180/263] - total_loss: 0.2676  obj_loss: 0.1548  noobj_loss: 0.0858  bbox_loss: 0.0099  cls_loss: 0.0206  \n",
      "<<<iteration:[200/263] - total_loss: 0.2769  obj_loss: 0.1604  noobj_loss: 0.0889  bbox_loss: 0.0093  cls_loss: 0.0255  \n",
      "<<<iteration:[220/263] - total_loss: 0.2610  obj_loss: 0.1568  noobj_loss: 0.0899  bbox_loss: 0.0076  cls_loss: 0.0213  \n",
      "<<<iteration:[240/263] - total_loss: 0.2537  obj_loss: 0.1461  noobj_loss: 0.0818  bbox_loss: 0.0088  cls_loss: 0.0227  \n",
      "<<<iteration:[260/263] - total_loss: 0.2779  obj_loss: 0.1635  noobj_loss: 0.0887  bbox_loss: 0.0094  cls_loss: 0.0231  \n",
      "\n",
      "epoch:37/100 - Train Loss: 0.2673, Val Loss: 0.2762\n",
      "\n",
      "<<<iteration:[20/263] - total_loss: 0.2769  obj_loss: 0.1727  noobj_loss: 0.0938  bbox_loss: 0.0081  cls_loss: 0.0168  \n",
      "<<<iteration:[40/263] - total_loss: 0.2677  obj_loss: 0.1603  noobj_loss: 0.0886  bbox_loss: 0.0088  cls_loss: 0.0192  \n",
      "<<<iteration:[60/263] - total_loss: 0.2549  obj_loss: 0.1516  noobj_loss: 0.0865  bbox_loss: 0.0086  cls_loss: 0.0168  \n",
      "<<<iteration:[80/263] - total_loss: 0.2767  obj_loss: 0.1722  noobj_loss: 0.0887  bbox_loss: 0.0085  cls_loss: 0.0176  \n",
      "<<<iteration:[100/263] - total_loss: 0.2593  obj_loss: 0.1596  noobj_loss: 0.0856  bbox_loss: 0.0073  cls_loss: 0.0205  \n",
      "<<<iteration:[120/263] - total_loss: 0.2726  obj_loss: 0.1655  noobj_loss: 0.0878  bbox_loss: 0.0083  cls_loss: 0.0216  \n",
      "<<<iteration:[140/263] - total_loss: 0.2808  obj_loss: 0.1664  noobj_loss: 0.0890  bbox_loss: 0.0087  cls_loss: 0.0265  \n",
      "<<<iteration:[160/263] - total_loss: 0.2586  obj_loss: 0.1590  noobj_loss: 0.0839  bbox_loss: 0.0077  cls_loss: 0.0190  \n",
      "<<<iteration:[180/263] - total_loss: 0.2530  obj_loss: 0.1556  noobj_loss: 0.0844  bbox_loss: 0.0074  cls_loss: 0.0181  \n",
      "<<<iteration:[200/263] - total_loss: 0.2797  obj_loss: 0.1721  noobj_loss: 0.0906  bbox_loss: 0.0080  cls_loss: 0.0224  \n",
      "<<<iteration:[220/263] - total_loss: 0.2749  obj_loss: 0.1729  noobj_loss: 0.0900  bbox_loss: 0.0077  cls_loss: 0.0187  \n",
      "<<<iteration:[240/263] - total_loss: 0.2556  obj_loss: 0.1442  noobj_loss: 0.0904  bbox_loss: 0.0088  cls_loss: 0.0222  \n",
      "<<<iteration:[260/263] - total_loss: 0.2582  obj_loss: 0.1467  noobj_loss: 0.0879  bbox_loss: 0.0094  cls_loss: 0.0208  \n",
      "\n",
      "epoch:38/100 - Train Loss: 0.2657, Val Loss: 0.2751\n",
      "\n",
      "<<<iteration:[20/263] - total_loss: 0.2708  obj_loss: 0.1647  noobj_loss: 0.0900  bbox_loss: 0.0081  cls_loss: 0.0205  \n",
      "<<<iteration:[40/263] - total_loss: 0.2650  obj_loss: 0.1610  noobj_loss: 0.0847  bbox_loss: 0.0074  cls_loss: 0.0248  \n",
      "<<<iteration:[60/263] - total_loss: 0.2781  obj_loss: 0.1709  noobj_loss: 0.0873  bbox_loss: 0.0081  cls_loss: 0.0228  \n",
      "<<<iteration:[80/263] - total_loss: 0.2596  obj_loss: 0.1459  noobj_loss: 0.0870  bbox_loss: 0.0097  cls_loss: 0.0217  \n",
      "<<<iteration:[100/263] - total_loss: 0.2624  obj_loss: 0.1530  noobj_loss: 0.0880  bbox_loss: 0.0089  cls_loss: 0.0207  \n",
      "<<<iteration:[120/263] - total_loss: 0.2634  obj_loss: 0.1558  noobj_loss: 0.0882  bbox_loss: 0.0086  cls_loss: 0.0206  \n",
      "<<<iteration:[140/263] - total_loss: 0.2614  obj_loss: 0.1669  noobj_loss: 0.0898  bbox_loss: 0.0071  cls_loss: 0.0139  \n",
      "<<<iteration:[160/263] - total_loss: 0.2738  obj_loss: 0.1650  noobj_loss: 0.0901  bbox_loss: 0.0079  cls_loss: 0.0240  \n",
      "<<<iteration:[180/263] - total_loss: 0.2779  obj_loss: 0.1666  noobj_loss: 0.0914  bbox_loss: 0.0096  cls_loss: 0.0175  \n",
      "<<<iteration:[200/263] - total_loss: 0.2636  obj_loss: 0.1570  noobj_loss: 0.0862  bbox_loss: 0.0085  cls_loss: 0.0207  \n",
      "<<<iteration:[220/263] - total_loss: 0.2679  obj_loss: 0.1706  noobj_loss: 0.0839  bbox_loss: 0.0081  cls_loss: 0.0149  \n",
      "<<<iteration:[240/263] - total_loss: 0.2549  obj_loss: 0.1484  noobj_loss: 0.0888  bbox_loss: 0.0087  cls_loss: 0.0186  \n",
      "<<<iteration:[260/263] - total_loss: 0.2720  obj_loss: 0.1646  noobj_loss: 0.0870  bbox_loss: 0.0085  cls_loss: 0.0215  \n",
      "\n",
      "epoch:39/100 - Train Loss: 0.2660, Val Loss: 0.2745\n",
      "\n",
      "<<<iteration:[20/263] - total_loss: 0.2715  obj_loss: 0.1605  noobj_loss: 0.0962  bbox_loss: 0.0087  cls_loss: 0.0196  \n",
      "<<<iteration:[40/263] - total_loss: 0.2553  obj_loss: 0.1572  noobj_loss: 0.0900  bbox_loss: 0.0076  cls_loss: 0.0152  \n",
      "<<<iteration:[60/263] - total_loss: 0.2725  obj_loss: 0.1703  noobj_loss: 0.0891  bbox_loss: 0.0081  cls_loss: 0.0173  \n",
      "<<<iteration:[80/263] - total_loss: 0.2637  obj_loss: 0.1662  noobj_loss: 0.0891  bbox_loss: 0.0075  cls_loss: 0.0155  \n",
      "<<<iteration:[100/263] - total_loss: 0.2758  obj_loss: 0.1606  noobj_loss: 0.0897  bbox_loss: 0.0088  cls_loss: 0.0263  \n",
      "<<<iteration:[120/263] - total_loss: 0.2619  obj_loss: 0.1551  noobj_loss: 0.0871  bbox_loss: 0.0092  cls_loss: 0.0176  \n",
      "<<<iteration:[140/263] - total_loss: 0.2569  obj_loss: 0.1529  noobj_loss: 0.0869  bbox_loss: 0.0081  cls_loss: 0.0199  \n",
      "<<<iteration:[160/263] - total_loss: 0.2674  obj_loss: 0.1581  noobj_loss: 0.0880  bbox_loss: 0.0094  cls_loss: 0.0183  \n",
      "<<<iteration:[180/263] - total_loss: 0.2580  obj_loss: 0.1540  noobj_loss: 0.0904  bbox_loss: 0.0073  cls_loss: 0.0223  \n",
      "<<<iteration:[200/263] - total_loss: 0.2597  obj_loss: 0.1522  noobj_loss: 0.0883  bbox_loss: 0.0090  cls_loss: 0.0184  \n",
      "<<<iteration:[220/263] - total_loss: 0.2468  obj_loss: 0.1505  noobj_loss: 0.0851  bbox_loss: 0.0080  cls_loss: 0.0138  \n",
      "<<<iteration:[240/263] - total_loss: 0.2697  obj_loss: 0.1707  noobj_loss: 0.0864  bbox_loss: 0.0076  cls_loss: 0.0180  \n",
      "<<<iteration:[260/263] - total_loss: 0.2623  obj_loss: 0.1564  noobj_loss: 0.0886  bbox_loss: 0.0083  cls_loss: 0.0201  \n",
      "\n",
      "epoch:40/100 - Train Loss: 0.2623, Val Loss: 0.2752\n",
      "\n",
      "<<<iteration:[20/263] - total_loss: 0.2810  obj_loss: 0.1716  noobj_loss: 0.0955  bbox_loss: 0.0087  cls_loss: 0.0179  \n",
      "<<<iteration:[40/263] - total_loss: 0.2587  obj_loss: 0.1546  noobj_loss: 0.0863  bbox_loss: 0.0079  cls_loss: 0.0215  \n",
      "<<<iteration:[60/263] - total_loss: 0.2593  obj_loss: 0.1618  noobj_loss: 0.0865  bbox_loss: 0.0076  cls_loss: 0.0162  \n",
      "<<<iteration:[80/263] - total_loss: 0.2638  obj_loss: 0.1569  noobj_loss: 0.0930  bbox_loss: 0.0079  cls_loss: 0.0207  \n",
      "<<<iteration:[100/263] - total_loss: 0.2637  obj_loss: 0.1559  noobj_loss: 0.0913  bbox_loss: 0.0084  cls_loss: 0.0203  \n",
      "<<<iteration:[120/263] - total_loss: 0.2671  obj_loss: 0.1577  noobj_loss: 0.0907  bbox_loss: 0.0089  cls_loss: 0.0194  \n",
      "<<<iteration:[140/263] - total_loss: 0.2636  obj_loss: 0.1629  noobj_loss: 0.0899  bbox_loss: 0.0081  cls_loss: 0.0152  \n",
      "<<<iteration:[160/263] - total_loss: 0.2583  obj_loss: 0.1576  noobj_loss: 0.0875  bbox_loss: 0.0077  cls_loss: 0.0183  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<<<iteration:[180/263] - total_loss: 0.2740  obj_loss: 0.1679  noobj_loss: 0.0887  bbox_loss: 0.0087  cls_loss: 0.0183  \n",
      "<<<iteration:[200/263] - total_loss: 0.2545  obj_loss: 0.1554  noobj_loss: 0.0882  bbox_loss: 0.0081  cls_loss: 0.0147  \n",
      "<<<iteration:[220/263] - total_loss: 0.2651  obj_loss: 0.1627  noobj_loss: 0.0905  bbox_loss: 0.0081  cls_loss: 0.0169  \n",
      "<<<iteration:[240/263] - total_loss: 0.2568  obj_loss: 0.1552  noobj_loss: 0.0885  bbox_loss: 0.0082  cls_loss: 0.0163  \n",
      "<<<iteration:[260/263] - total_loss: 0.2608  obj_loss: 0.1583  noobj_loss: 0.0863  bbox_loss: 0.0085  cls_loss: 0.0171  \n",
      "\n",
      "epoch:41/100 - Train Loss: 0.2629, Val Loss: 0.2794\n",
      "\n",
      "<<<iteration:[20/263] - total_loss: 0.2892  obj_loss: 0.1755  noobj_loss: 0.0973  bbox_loss: 0.0089  cls_loss: 0.0207  \n",
      "<<<iteration:[40/263] - total_loss: 0.2704  obj_loss: 0.1618  noobj_loss: 0.0901  bbox_loss: 0.0089  cls_loss: 0.0192  \n",
      "<<<iteration:[60/263] - total_loss: 0.2561  obj_loss: 0.1552  noobj_loss: 0.0900  bbox_loss: 0.0075  cls_loss: 0.0185  \n",
      "<<<iteration:[80/263] - total_loss: 0.2555  obj_loss: 0.1591  noobj_loss: 0.0877  bbox_loss: 0.0071  cls_loss: 0.0171  \n",
      "<<<iteration:[100/263] - total_loss: 0.2566  obj_loss: 0.1553  noobj_loss: 0.0895  bbox_loss: 0.0079  cls_loss: 0.0169  \n",
      "<<<iteration:[120/263] - total_loss: 0.2657  obj_loss: 0.1659  noobj_loss: 0.0892  bbox_loss: 0.0073  cls_loss: 0.0184  \n",
      "<<<iteration:[140/263] - total_loss: 0.2585  obj_loss: 0.1542  noobj_loss: 0.0898  bbox_loss: 0.0081  cls_loss: 0.0187  \n",
      "<<<iteration:[160/263] - total_loss: 0.2721  obj_loss: 0.1674  noobj_loss: 0.0868  bbox_loss: 0.0084  cls_loss: 0.0195  \n",
      "<<<iteration:[180/263] - total_loss: 0.2630  obj_loss: 0.1665  noobj_loss: 0.0872  bbox_loss: 0.0076  cls_loss: 0.0148  \n",
      "<<<iteration:[200/263] - total_loss: 0.2692  obj_loss: 0.1624  noobj_loss: 0.0886  bbox_loss: 0.0082  cls_loss: 0.0216  \n",
      "<<<iteration:[220/263] - total_loss: 0.2766  obj_loss: 0.1752  noobj_loss: 0.0845  bbox_loss: 0.0084  cls_loss: 0.0170  \n",
      "<<<iteration:[240/263] - total_loss: 0.2611  obj_loss: 0.1559  noobj_loss: 0.0940  bbox_loss: 0.0085  cls_loss: 0.0155  \n",
      "<<<iteration:[260/263] - total_loss: 0.2631  obj_loss: 0.1608  noobj_loss: 0.0879  bbox_loss: 0.0083  cls_loss: 0.0171  \n",
      "\n",
      "epoch:42/100 - Train Loss: 0.2648, Val Loss: 0.2728\n",
      "\n",
      "<<<iteration:[20/263] - total_loss: 0.2569  obj_loss: 0.1427  noobj_loss: 0.0905  bbox_loss: 0.0093  cls_loss: 0.0222  \n",
      "<<<iteration:[40/263] - total_loss: 0.2572  obj_loss: 0.1494  noobj_loss: 0.0894  bbox_loss: 0.0084  cls_loss: 0.0212  \n",
      "<<<iteration:[60/263] - total_loss: 0.2595  obj_loss: 0.1500  noobj_loss: 0.0898  bbox_loss: 0.0090  cls_loss: 0.0195  \n",
      "<<<iteration:[80/263] - total_loss: 0.2572  obj_loss: 0.1577  noobj_loss: 0.0886  bbox_loss: 0.0075  cls_loss: 0.0177  \n",
      "<<<iteration:[100/263] - total_loss: 0.2543  obj_loss: 0.1578  noobj_loss: 0.0867  bbox_loss: 0.0076  cls_loss: 0.0152  \n",
      "<<<iteration:[120/263] - total_loss: 0.2682  obj_loss: 0.1630  noobj_loss: 0.0907  bbox_loss: 0.0079  cls_loss: 0.0205  \n",
      "<<<iteration:[140/263] - total_loss: 0.2651  obj_loss: 0.1701  noobj_loss: 0.0875  bbox_loss: 0.0076  cls_loss: 0.0134  \n",
      "<<<iteration:[160/263] - total_loss: 0.2590  obj_loss: 0.1626  noobj_loss: 0.0866  bbox_loss: 0.0077  cls_loss: 0.0147  \n",
      "<<<iteration:[180/263] - total_loss: 0.2546  obj_loss: 0.1565  noobj_loss: 0.0864  bbox_loss: 0.0073  cls_loss: 0.0182  \n",
      "<<<iteration:[200/263] - total_loss: 0.2780  obj_loss: 0.1706  noobj_loss: 0.0926  bbox_loss: 0.0086  cls_loss: 0.0183  \n",
      "<<<iteration:[220/263] - total_loss: 0.2728  obj_loss: 0.1718  noobj_loss: 0.0950  bbox_loss: 0.0074  cls_loss: 0.0163  \n",
      "<<<iteration:[240/263] - total_loss: 0.2638  obj_loss: 0.1568  noobj_loss: 0.0924  bbox_loss: 0.0085  cls_loss: 0.0184  \n",
      "<<<iteration:[260/263] - total_loss: 0.2750  obj_loss: 0.1674  noobj_loss: 0.0959  bbox_loss: 0.0081  cls_loss: 0.0193  \n",
      "\n",
      "epoch:43/100 - Train Loss: 0.2622, Val Loss: 0.2718\n",
      "\n",
      "<<<iteration:[20/263] - total_loss: 0.2802  obj_loss: 0.1734  noobj_loss: 0.0977  bbox_loss: 0.0084  cls_loss: 0.0159  \n",
      "<<<iteration:[40/263] - total_loss: 0.2591  obj_loss: 0.1638  noobj_loss: 0.0901  bbox_loss: 0.0073  cls_loss: 0.0135  \n",
      "<<<iteration:[60/263] - total_loss: 0.2573  obj_loss: 0.1470  noobj_loss: 0.0919  bbox_loss: 0.0089  cls_loss: 0.0196  \n",
      "<<<iteration:[80/263] - total_loss: 0.2545  obj_loss: 0.1614  noobj_loss: 0.0862  bbox_loss: 0.0073  cls_loss: 0.0138  \n",
      "<<<iteration:[100/263] - total_loss: 0.2681  obj_loss: 0.1584  noobj_loss: 0.0885  bbox_loss: 0.0095  cls_loss: 0.0181  \n",
      "<<<iteration:[120/263] - total_loss: 0.2549  obj_loss: 0.1563  noobj_loss: 0.0889  bbox_loss: 0.0079  cls_loss: 0.0144  \n",
      "<<<iteration:[140/263] - total_loss: 0.2786  obj_loss: 0.1726  noobj_loss: 0.0933  bbox_loss: 0.0087  cls_loss: 0.0158  \n",
      "<<<iteration:[160/263] - total_loss: 0.2643  obj_loss: 0.1668  noobj_loss: 0.0875  bbox_loss: 0.0071  cls_loss: 0.0182  \n",
      "<<<iteration:[180/263] - total_loss: 0.2740  obj_loss: 0.1683  noobj_loss: 0.0891  bbox_loss: 0.0083  cls_loss: 0.0198  \n",
      "<<<iteration:[200/263] - total_loss: 0.2715  obj_loss: 0.1680  noobj_loss: 0.0953  bbox_loss: 0.0075  cls_loss: 0.0181  \n",
      "<<<iteration:[220/263] - total_loss: 0.2745  obj_loss: 0.1680  noobj_loss: 0.0922  bbox_loss: 0.0084  cls_loss: 0.0184  \n",
      "<<<iteration:[240/263] - total_loss: 0.2531  obj_loss: 0.1474  noobj_loss: 0.0940  bbox_loss: 0.0081  cls_loss: 0.0184  \n",
      "<<<iteration:[260/263] - total_loss: 0.2750  obj_loss: 0.1771  noobj_loss: 0.0927  bbox_loss: 0.0074  cls_loss: 0.0145  \n",
      "\n",
      "epoch:44/100 - Train Loss: 0.2654, Val Loss: 0.2737\n",
      "\n",
      "<<<iteration:[20/263] - total_loss: 0.2653  obj_loss: 0.1634  noobj_loss: 0.0967  bbox_loss: 0.0082  cls_loss: 0.0127  \n",
      "<<<iteration:[40/263] - total_loss: 0.2569  obj_loss: 0.1615  noobj_loss: 0.0901  bbox_loss: 0.0071  cls_loss: 0.0148  \n",
      "<<<iteration:[60/263] - total_loss: 0.2687  obj_loss: 0.1650  noobj_loss: 0.0884  bbox_loss: 0.0081  cls_loss: 0.0192  \n",
      "<<<iteration:[80/263] - total_loss: 0.2778  obj_loss: 0.1692  noobj_loss: 0.0933  bbox_loss: 0.0081  cls_loss: 0.0215  \n",
      "<<<iteration:[100/263] - total_loss: 0.2725  obj_loss: 0.1732  noobj_loss: 0.0895  bbox_loss: 0.0072  cls_loss: 0.0183  \n",
      "<<<iteration:[120/263] - total_loss: 0.2673  obj_loss: 0.1695  noobj_loss: 0.0946  bbox_loss: 0.0071  cls_loss: 0.0151  \n",
      "<<<iteration:[140/263] - total_loss: 0.2616  obj_loss: 0.1564  noobj_loss: 0.0902  bbox_loss: 0.0081  cls_loss: 0.0195  \n",
      "<<<iteration:[160/263] - total_loss: 0.2533  obj_loss: 0.1487  noobj_loss: 0.0915  bbox_loss: 0.0084  cls_loss: 0.0168  \n",
      "<<<iteration:[180/263] - total_loss: 0.2504  obj_loss: 0.1433  noobj_loss: 0.0948  bbox_loss: 0.0084  cls_loss: 0.0176  \n",
      "<<<iteration:[200/263] - total_loss: 0.2531  obj_loss: 0.1501  noobj_loss: 0.0879  bbox_loss: 0.0081  cls_loss: 0.0186  \n",
      "<<<iteration:[220/263] - total_loss: 0.2567  obj_loss: 0.1572  noobj_loss: 0.0860  bbox_loss: 0.0079  cls_loss: 0.0172  \n",
      "<<<iteration:[240/263] - total_loss: 0.2633  obj_loss: 0.1609  noobj_loss: 0.0975  bbox_loss: 0.0075  cls_loss: 0.0163  \n",
      "<<<iteration:[260/263] - total_loss: 0.2546  obj_loss: 0.1423  noobj_loss: 0.0858  bbox_loss: 0.0104  cls_loss: 0.0175  \n",
      "\n",
      "epoch:45/100 - Train Loss: 0.2607, Val Loss: 0.2771\n",
      "\n",
      "<<<iteration:[20/263] - total_loss: 0.2573  obj_loss: 0.1534  noobj_loss: 0.0877  bbox_loss: 0.0083  cls_loss: 0.0188  \n",
      "<<<iteration:[40/263] - total_loss: 0.2627  obj_loss: 0.1650  noobj_loss: 0.0888  bbox_loss: 0.0073  cls_loss: 0.0170  \n",
      "<<<iteration:[60/263] - total_loss: 0.2519  obj_loss: 0.1557  noobj_loss: 0.0854  bbox_loss: 0.0080  cls_loss: 0.0134  \n",
      "<<<iteration:[80/263] - total_loss: 0.2638  obj_loss: 0.1589  noobj_loss: 0.0902  bbox_loss: 0.0082  cls_loss: 0.0187  \n",
      "<<<iteration:[100/263] - total_loss: 0.2578  obj_loss: 0.1662  noobj_loss: 0.0894  bbox_loss: 0.0065  cls_loss: 0.0146  \n",
      "<<<iteration:[120/263] - total_loss: 0.2673  obj_loss: 0.1574  noobj_loss: 0.0909  bbox_loss: 0.0097  cls_loss: 0.0162  \n",
      "<<<iteration:[140/263] - total_loss: 0.2694  obj_loss: 0.1673  noobj_loss: 0.0887  bbox_loss: 0.0086  cls_loss: 0.0147  \n",
      "<<<iteration:[160/263] - total_loss: 0.2785  obj_loss: 0.1762  noobj_loss: 0.0919  bbox_loss: 0.0077  cls_loss: 0.0178  \n",
      "<<<iteration:[180/263] - total_loss: 0.2625  obj_loss: 0.1654  noobj_loss: 0.0936  bbox_loss: 0.0075  cls_loss: 0.0127  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<<<iteration:[200/263] - total_loss: 0.2562  obj_loss: 0.1530  noobj_loss: 0.0925  bbox_loss: 0.0078  cls_loss: 0.0180  \n",
      "<<<iteration:[220/263] - total_loss: 0.2585  obj_loss: 0.1534  noobj_loss: 0.0901  bbox_loss: 0.0089  cls_loss: 0.0156  \n",
      "<<<iteration:[240/263] - total_loss: 0.2640  obj_loss: 0.1605  noobj_loss: 0.0923  bbox_loss: 0.0080  cls_loss: 0.0174  \n",
      "<<<iteration:[260/263] - total_loss: 0.2766  obj_loss: 0.1573  noobj_loss: 0.0945  bbox_loss: 0.0100  cls_loss: 0.0221  \n",
      "\n",
      "epoch:46/100 - Train Loss: 0.2631, Val Loss: 0.2869\n",
      "\n",
      "<<<iteration:[20/263] - total_loss: 0.2738  obj_loss: 0.1605  noobj_loss: 0.0968  bbox_loss: 0.0093  cls_loss: 0.0184  \n",
      "<<<iteration:[40/263] - total_loss: 0.2830  obj_loss: 0.1749  noobj_loss: 0.0899  bbox_loss: 0.0089  cls_loss: 0.0184  \n",
      "<<<iteration:[60/263] - total_loss: 0.2583  obj_loss: 0.1494  noobj_loss: 0.0925  bbox_loss: 0.0091  cls_loss: 0.0173  \n",
      "<<<iteration:[80/263] - total_loss: 0.2606  obj_loss: 0.1631  noobj_loss: 0.0910  bbox_loss: 0.0078  cls_loss: 0.0131  \n",
      "<<<iteration:[100/263] - total_loss: 0.2650  obj_loss: 0.1719  noobj_loss: 0.0918  bbox_loss: 0.0071  cls_loss: 0.0118  \n",
      "<<<iteration:[120/263] - total_loss: 0.2628  obj_loss: 0.1566  noobj_loss: 0.0965  bbox_loss: 0.0085  cls_loss: 0.0153  \n",
      "<<<iteration:[140/263] - total_loss: 0.2643  obj_loss: 0.1657  noobj_loss: 0.0935  bbox_loss: 0.0071  cls_loss: 0.0165  \n",
      "<<<iteration:[160/263] - total_loss: 0.2664  obj_loss: 0.1667  noobj_loss: 0.0917  bbox_loss: 0.0079  cls_loss: 0.0145  \n",
      "<<<iteration:[180/263] - total_loss: 0.2596  obj_loss: 0.1630  noobj_loss: 0.0933  bbox_loss: 0.0067  cls_loss: 0.0162  \n",
      "<<<iteration:[200/263] - total_loss: 0.2640  obj_loss: 0.1593  noobj_loss: 0.0942  bbox_loss: 0.0081  cls_loss: 0.0172  \n",
      "<<<iteration:[220/263] - total_loss: 0.2522  obj_loss: 0.1550  noobj_loss: 0.0902  bbox_loss: 0.0074  cls_loss: 0.0153  \n",
      "<<<iteration:[240/263] - total_loss: 0.2451  obj_loss: 0.1477  noobj_loss: 0.0865  bbox_loss: 0.0080  cls_loss: 0.0143  \n",
      "<<<iteration:[260/263] - total_loss: 0.2709  obj_loss: 0.1657  noobj_loss: 0.0945  bbox_loss: 0.0081  cls_loss: 0.0176  \n",
      "\n",
      "epoch:47/100 - Train Loss: 0.2629, Val Loss: 0.2725\n",
      "\n",
      "<<<iteration:[20/263] - total_loss: 0.2940  obj_loss: 0.1838  noobj_loss: 0.1020  bbox_loss: 0.0081  cls_loss: 0.0188  \n",
      "<<<iteration:[40/263] - total_loss: 0.2539  obj_loss: 0.1558  noobj_loss: 0.0935  bbox_loss: 0.0073  cls_loss: 0.0146  \n",
      "<<<iteration:[60/263] - total_loss: 0.2607  obj_loss: 0.1585  noobj_loss: 0.0938  bbox_loss: 0.0081  cls_loss: 0.0147  \n",
      "<<<iteration:[80/263] - total_loss: 0.2537  obj_loss: 0.1576  noobj_loss: 0.0898  bbox_loss: 0.0069  cls_loss: 0.0168  \n",
      "<<<iteration:[100/263] - total_loss: 0.2534  obj_loss: 0.1607  noobj_loss: 0.0880  bbox_loss: 0.0065  cls_loss: 0.0160  \n",
      "<<<iteration:[120/263] - total_loss: 0.2631  obj_loss: 0.1631  noobj_loss: 0.0883  bbox_loss: 0.0079  cls_loss: 0.0163  \n",
      "<<<iteration:[140/263] - total_loss: 0.2765  obj_loss: 0.1811  noobj_loss: 0.0961  bbox_loss: 0.0069  cls_loss: 0.0130  \n",
      "<<<iteration:[160/263] - total_loss: 0.2601  obj_loss: 0.1576  noobj_loss: 0.0969  bbox_loss: 0.0075  cls_loss: 0.0168  \n",
      "<<<iteration:[180/263] - total_loss: 0.2691  obj_loss: 0.1681  noobj_loss: 0.0940  bbox_loss: 0.0075  cls_loss: 0.0163  \n",
      "<<<iteration:[200/263] - total_loss: 0.2565  obj_loss: 0.1578  noobj_loss: 0.0921  bbox_loss: 0.0075  cls_loss: 0.0154  \n",
      "<<<iteration:[220/263] - total_loss: 0.2745  obj_loss: 0.1716  noobj_loss: 0.0934  bbox_loss: 0.0073  cls_loss: 0.0197  \n",
      "<<<iteration:[240/263] - total_loss: 0.2421  obj_loss: 0.1424  noobj_loss: 0.0897  bbox_loss: 0.0077  cls_loss: 0.0166  \n",
      "<<<iteration:[260/263] - total_loss: 0.2552  obj_loss: 0.1524  noobj_loss: 0.0902  bbox_loss: 0.0080  cls_loss: 0.0178  \n",
      "\n",
      "epoch:48/100 - Train Loss: 0.2614, Val Loss: 0.2708\n",
      "\n",
      "<<<iteration:[20/263] - total_loss: 0.2734  obj_loss: 0.1824  noobj_loss: 0.0933  bbox_loss: 0.0060  cls_loss: 0.0141  \n",
      "<<<iteration:[40/263] - total_loss: 0.2461  obj_loss: 0.1495  noobj_loss: 0.0940  bbox_loss: 0.0069  cls_loss: 0.0148  \n",
      "<<<iteration:[60/263] - total_loss: 0.2662  obj_loss: 0.1669  noobj_loss: 0.0951  bbox_loss: 0.0073  cls_loss: 0.0153  \n",
      "<<<iteration:[80/263] - total_loss: 0.2635  obj_loss: 0.1689  noobj_loss: 0.0936  bbox_loss: 0.0068  cls_loss: 0.0139  \n",
      "<<<iteration:[100/263] - total_loss: 0.2628  obj_loss: 0.1679  noobj_loss: 0.0916  bbox_loss: 0.0073  cls_loss: 0.0128  \n",
      "<<<iteration:[120/263] - total_loss: 0.2493  obj_loss: 0.1503  noobj_loss: 0.0921  bbox_loss: 0.0074  cls_loss: 0.0161  \n",
      "<<<iteration:[140/263] - total_loss: 0.2629  obj_loss: 0.1643  noobj_loss: 0.0921  bbox_loss: 0.0079  cls_loss: 0.0132  \n",
      "<<<iteration:[160/263] - total_loss: 0.2568  obj_loss: 0.1581  noobj_loss: 0.0956  bbox_loss: 0.0070  cls_loss: 0.0159  \n",
      "<<<iteration:[180/263] - total_loss: 0.2519  obj_loss: 0.1550  noobj_loss: 0.0953  bbox_loss: 0.0070  cls_loss: 0.0144  \n",
      "<<<iteration:[200/263] - total_loss: 0.2566  obj_loss: 0.1526  noobj_loss: 0.0961  bbox_loss: 0.0078  cls_loss: 0.0169  \n",
      "<<<iteration:[220/263] - total_loss: 0.2602  obj_loss: 0.1580  noobj_loss: 0.0930  bbox_loss: 0.0083  cls_loss: 0.0141  \n",
      "<<<iteration:[240/263] - total_loss: 0.2667  obj_loss: 0.1699  noobj_loss: 0.0935  bbox_loss: 0.0071  cls_loss: 0.0148  \n",
      "<<<iteration:[260/263] - total_loss: 0.2624  obj_loss: 0.1615  noobj_loss: 0.0880  bbox_loss: 0.0074  cls_loss: 0.0198  \n",
      "\n",
      "epoch:49/100 - Train Loss: 0.2591, Val Loss: 0.2712\n",
      "\n",
      "<<<iteration:[20/263] - total_loss: 0.2711  obj_loss: 0.1680  noobj_loss: 0.0990  bbox_loss: 0.0074  cls_loss: 0.0164  \n",
      "<<<iteration:[40/263] - total_loss: 0.2519  obj_loss: 0.1551  noobj_loss: 0.0885  bbox_loss: 0.0068  cls_loss: 0.0185  \n",
      "<<<iteration:[60/263] - total_loss: 0.2579  obj_loss: 0.1567  noobj_loss: 0.0948  bbox_loss: 0.0076  cls_loss: 0.0159  \n",
      "<<<iteration:[80/263] - total_loss: 0.2548  obj_loss: 0.1596  noobj_loss: 0.0921  bbox_loss: 0.0072  cls_loss: 0.0132  \n",
      "<<<iteration:[100/263] - total_loss: 0.2620  obj_loss: 0.1678  noobj_loss: 0.0916  bbox_loss: 0.0070  cls_loss: 0.0133  \n",
      "<<<iteration:[120/263] - total_loss: 0.2563  obj_loss: 0.1559  noobj_loss: 0.0908  bbox_loss: 0.0075  cls_loss: 0.0174  \n",
      "<<<iteration:[140/263] - total_loss: 0.2502  obj_loss: 0.1498  noobj_loss: 0.0905  bbox_loss: 0.0077  cls_loss: 0.0167  \n",
      "<<<iteration:[160/263] - total_loss: 0.2631  obj_loss: 0.1561  noobj_loss: 0.0977  bbox_loss: 0.0074  cls_loss: 0.0214  \n",
      "<<<iteration:[180/263] - total_loss: 0.2705  obj_loss: 0.1706  noobj_loss: 0.0995  bbox_loss: 0.0072  cls_loss: 0.0143  \n",
      "<<<iteration:[200/263] - total_loss: 0.2818  obj_loss: 0.1749  noobj_loss: 0.0946  bbox_loss: 0.0085  cls_loss: 0.0169  \n",
      "<<<iteration:[220/263] - total_loss: 0.2656  obj_loss: 0.1634  noobj_loss: 0.0977  bbox_loss: 0.0076  cls_loss: 0.0154  \n",
      "<<<iteration:[240/263] - total_loss: 0.2735  obj_loss: 0.1685  noobj_loss: 0.0962  bbox_loss: 0.0075  cls_loss: 0.0196  \n",
      "<<<iteration:[260/263] - total_loss: 0.2515  obj_loss: 0.1595  noobj_loss: 0.0931  bbox_loss: 0.0067  cls_loss: 0.0121  \n",
      "\n",
      "epoch:50/100 - Train Loss: 0.2612, Val Loss: 0.2754\n",
      "\n",
      "<<<iteration:[20/263] - total_loss: 0.2660  obj_loss: 0.1655  noobj_loss: 0.0984  bbox_loss: 0.0074  cls_loss: 0.0142  \n",
      "<<<iteration:[40/263] - total_loss: 0.2639  obj_loss: 0.1667  noobj_loss: 0.0876  bbox_loss: 0.0072  cls_loss: 0.0175  \n",
      "<<<iteration:[60/263] - total_loss: 0.2616  obj_loss: 0.1628  noobj_loss: 0.0946  bbox_loss: 0.0073  cls_loss: 0.0151  \n",
      "<<<iteration:[80/263] - total_loss: 0.2542  obj_loss: 0.1607  noobj_loss: 0.0980  bbox_loss: 0.0065  cls_loss: 0.0118  \n",
      "<<<iteration:[100/263] - total_loss: 0.2698  obj_loss: 0.1705  noobj_loss: 0.0959  bbox_loss: 0.0069  cls_loss: 0.0168  \n",
      "<<<iteration:[120/263] - total_loss: 0.2763  obj_loss: 0.1673  noobj_loss: 0.0986  bbox_loss: 0.0079  cls_loss: 0.0203  \n",
      "<<<iteration:[140/263] - total_loss: 0.2625  obj_loss: 0.1675  noobj_loss: 0.0950  bbox_loss: 0.0067  cls_loss: 0.0142  \n",
      "<<<iteration:[160/263] - total_loss: 0.2571  obj_loss: 0.1586  noobj_loss: 0.0962  bbox_loss: 0.0069  cls_loss: 0.0160  \n",
      "<<<iteration:[180/263] - total_loss: 0.2617  obj_loss: 0.1678  noobj_loss: 0.0921  bbox_loss: 0.0067  cls_loss: 0.0146  \n",
      "<<<iteration:[200/263] - total_loss: 0.2478  obj_loss: 0.1507  noobj_loss: 0.0933  bbox_loss: 0.0069  cls_loss: 0.0162  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<<<iteration:[220/263] - total_loss: 0.2616  obj_loss: 0.1618  noobj_loss: 0.0958  bbox_loss: 0.0069  cls_loss: 0.0172  \n",
      "<<<iteration:[240/263] - total_loss: 0.2573  obj_loss: 0.1591  noobj_loss: 0.0943  bbox_loss: 0.0075  cls_loss: 0.0134  \n",
      "<<<iteration:[260/263] - total_loss: 0.2602  obj_loss: 0.1615  noobj_loss: 0.0966  bbox_loss: 0.0070  cls_loss: 0.0153  \n",
      "\n",
      "epoch:51/100 - Train Loss: 0.2601, Val Loss: 0.2728\n",
      "\n",
      "<<<iteration:[20/263] - total_loss: 0.2758  obj_loss: 0.1765  noobj_loss: 0.1013  bbox_loss: 0.0068  cls_loss: 0.0147  \n",
      "<<<iteration:[40/263] - total_loss: 0.2621  obj_loss: 0.1645  noobj_loss: 0.0970  bbox_loss: 0.0069  cls_loss: 0.0146  \n",
      "<<<iteration:[60/263] - total_loss: 0.2478  obj_loss: 0.1521  noobj_loss: 0.0962  bbox_loss: 0.0067  cls_loss: 0.0140  \n",
      "<<<iteration:[80/263] - total_loss: 0.2523  obj_loss: 0.1591  noobj_loss: 0.0926  bbox_loss: 0.0068  cls_loss: 0.0128  \n",
      "<<<iteration:[100/263] - total_loss: 0.2673  obj_loss: 0.1700  noobj_loss: 0.0945  bbox_loss: 0.0068  cls_loss: 0.0161  \n",
      "<<<iteration:[120/263] - total_loss: 0.2553  obj_loss: 0.1590  noobj_loss: 0.0914  bbox_loss: 0.0070  cls_loss: 0.0155  \n",
      "<<<iteration:[140/263] - total_loss: 0.2537  obj_loss: 0.1617  noobj_loss: 0.0946  bbox_loss: 0.0063  cls_loss: 0.0132  \n",
      "<<<iteration:[160/263] - total_loss: 0.2574  obj_loss: 0.1672  noobj_loss: 0.0973  bbox_loss: 0.0062  cls_loss: 0.0105  \n",
      "<<<iteration:[180/263] - total_loss: 0.2508  obj_loss: 0.1551  noobj_loss: 0.0937  bbox_loss: 0.0068  cls_loss: 0.0150  \n",
      "<<<iteration:[200/263] - total_loss: 0.2530  obj_loss: 0.1589  noobj_loss: 0.0971  bbox_loss: 0.0068  cls_loss: 0.0117  \n",
      "<<<iteration:[220/263] - total_loss: 0.2706  obj_loss: 0.1737  noobj_loss: 0.0981  bbox_loss: 0.0064  cls_loss: 0.0158  \n",
      "<<<iteration:[240/263] - total_loss: 0.2609  obj_loss: 0.1626  noobj_loss: 0.0947  bbox_loss: 0.0070  cls_loss: 0.0162  \n",
      "<<<iteration:[260/263] - total_loss: 0.2702  obj_loss: 0.1726  noobj_loss: 0.0957  bbox_loss: 0.0068  cls_loss: 0.0156  \n",
      "\n",
      "epoch:52/100 - Train Loss: 0.2589, Val Loss: 0.2671\n",
      "\n",
      "<<<iteration:[20/263] - total_loss: 0.2722  obj_loss: 0.1703  noobj_loss: 0.1045  bbox_loss: 0.0068  cls_loss: 0.0154  \n",
      "<<<iteration:[40/263] - total_loss: 0.2547  obj_loss: 0.1552  noobj_loss: 0.0986  bbox_loss: 0.0075  cls_loss: 0.0128  \n",
      "<<<iteration:[60/263] - total_loss: 0.2509  obj_loss: 0.1513  noobj_loss: 0.0973  bbox_loss: 0.0075  cls_loss: 0.0133  \n",
      "<<<iteration:[80/263] - total_loss: 0.2452  obj_loss: 0.1457  noobj_loss: 0.0919  bbox_loss: 0.0082  cls_loss: 0.0127  \n",
      "<<<iteration:[100/263] - total_loss: 0.2527  obj_loss: 0.1553  noobj_loss: 0.0956  bbox_loss: 0.0072  cls_loss: 0.0136  \n",
      "<<<iteration:[120/263] - total_loss: 0.2611  obj_loss: 0.1665  noobj_loss: 0.0959  bbox_loss: 0.0064  cls_loss: 0.0147  \n",
      "<<<iteration:[140/263] - total_loss: 0.2617  obj_loss: 0.1585  noobj_loss: 0.0967  bbox_loss: 0.0079  cls_loss: 0.0155  \n",
      "<<<iteration:[160/263] - total_loss: 0.2542  obj_loss: 0.1627  noobj_loss: 0.0913  bbox_loss: 0.0069  cls_loss: 0.0116  \n",
      "<<<iteration:[180/263] - total_loss: 0.2630  obj_loss: 0.1659  noobj_loss: 0.0990  bbox_loss: 0.0068  cls_loss: 0.0137  \n",
      "<<<iteration:[200/263] - total_loss: 0.2599  obj_loss: 0.1636  noobj_loss: 0.0986  bbox_loss: 0.0066  cls_loss: 0.0138  \n",
      "<<<iteration:[220/263] - total_loss: 0.2724  obj_loss: 0.1694  noobj_loss: 0.0943  bbox_loss: 0.0079  cls_loss: 0.0165  \n",
      "<<<iteration:[240/263] - total_loss: 0.2606  obj_loss: 0.1582  noobj_loss: 0.0977  bbox_loss: 0.0067  cls_loss: 0.0199  \n",
      "<<<iteration:[260/263] - total_loss: 0.2562  obj_loss: 0.1603  noobj_loss: 0.0977  bbox_loss: 0.0066  cls_loss: 0.0139  \n",
      "\n",
      "epoch:53/100 - Train Loss: 0.2576, Val Loss: 0.2687\n",
      "\n",
      "<<<iteration:[20/263] - total_loss: 0.2727  obj_loss: 0.1786  noobj_loss: 0.0953  bbox_loss: 0.0068  cls_loss: 0.0126  \n",
      "<<<iteration:[40/263] - total_loss: 0.2595  obj_loss: 0.1574  noobj_loss: 0.0966  bbox_loss: 0.0076  cls_loss: 0.0156  \n",
      "<<<iteration:[60/263] - total_loss: 0.2558  obj_loss: 0.1586  noobj_loss: 0.0944  bbox_loss: 0.0068  cls_loss: 0.0159  \n",
      "<<<iteration:[80/263] - total_loss: 0.2695  obj_loss: 0.1729  noobj_loss: 0.0938  bbox_loss: 0.0070  cls_loss: 0.0148  \n",
      "<<<iteration:[100/263] - total_loss: 0.2500  obj_loss: 0.1590  noobj_loss: 0.0997  bbox_loss: 0.0056  cls_loss: 0.0131  \n",
      "<<<iteration:[120/263] - total_loss: 0.2591  obj_loss: 0.1574  noobj_loss: 0.1003  bbox_loss: 0.0070  cls_loss: 0.0168  \n",
      "<<<iteration:[140/263] - total_loss: 0.2440  obj_loss: 0.1542  noobj_loss: 0.0961  bbox_loss: 0.0061  cls_loss: 0.0112  \n",
      "<<<iteration:[160/263] - total_loss: 0.2697  obj_loss: 0.1714  noobj_loss: 0.0973  bbox_loss: 0.0073  cls_loss: 0.0131  \n",
      "<<<iteration:[180/263] - total_loss: 0.2681  obj_loss: 0.1731  noobj_loss: 0.0950  bbox_loss: 0.0067  cls_loss: 0.0141  \n",
      "<<<iteration:[200/263] - total_loss: 0.2563  obj_loss: 0.1650  noobj_loss: 0.0957  bbox_loss: 0.0065  cls_loss: 0.0107  \n",
      "<<<iteration:[220/263] - total_loss: 0.2685  obj_loss: 0.1733  noobj_loss: 0.0978  bbox_loss: 0.0067  cls_loss: 0.0127  \n",
      "<<<iteration:[240/263] - total_loss: 0.2621  obj_loss: 0.1643  noobj_loss: 0.0990  bbox_loss: 0.0062  cls_loss: 0.0173  \n",
      "<<<iteration:[260/263] - total_loss: 0.2593  obj_loss: 0.1609  noobj_loss: 0.0971  bbox_loss: 0.0067  cls_loss: 0.0164  \n",
      "\n",
      "epoch:54/100 - Train Loss: 0.2601, Val Loss: 0.2720\n",
      "\n",
      "<<<iteration:[20/263] - total_loss: 0.2668  obj_loss: 0.1635  noobj_loss: 0.1004  bbox_loss: 0.0078  cls_loss: 0.0142  \n",
      "<<<iteration:[40/263] - total_loss: 0.2599  obj_loss: 0.1519  noobj_loss: 0.0950  bbox_loss: 0.0084  cls_loss: 0.0185  \n",
      "<<<iteration:[60/263] - total_loss: 0.2524  obj_loss: 0.1518  noobj_loss: 0.0990  bbox_loss: 0.0075  cls_loss: 0.0136  \n",
      "<<<iteration:[80/263] - total_loss: 0.2756  obj_loss: 0.1769  noobj_loss: 0.0976  bbox_loss: 0.0064  cls_loss: 0.0178  \n",
      "<<<iteration:[100/263] - total_loss: 0.2482  obj_loss: 0.1546  noobj_loss: 0.1001  bbox_loss: 0.0065  cls_loss: 0.0110  \n",
      "<<<iteration:[120/263] - total_loss: 0.2495  obj_loss: 0.1586  noobj_loss: 0.0939  bbox_loss: 0.0066  cls_loss: 0.0111  \n",
      "<<<iteration:[140/263] - total_loss: 0.2471  obj_loss: 0.1459  noobj_loss: 0.0984  bbox_loss: 0.0073  cls_loss: 0.0155  \n",
      "<<<iteration:[160/263] - total_loss: 0.2562  obj_loss: 0.1626  noobj_loss: 0.0944  bbox_loss: 0.0065  cls_loss: 0.0141  \n",
      "<<<iteration:[180/263] - total_loss: 0.2835  obj_loss: 0.1795  noobj_loss: 0.0977  bbox_loss: 0.0071  cls_loss: 0.0197  \n",
      "<<<iteration:[200/263] - total_loss: 0.2596  obj_loss: 0.1666  noobj_loss: 0.0949  bbox_loss: 0.0067  cls_loss: 0.0123  \n",
      "<<<iteration:[220/263] - total_loss: 0.2528  obj_loss: 0.1658  noobj_loss: 0.0959  bbox_loss: 0.0057  cls_loss: 0.0107  \n",
      "<<<iteration:[240/263] - total_loss: 0.2733  obj_loss: 0.1721  noobj_loss: 0.0983  bbox_loss: 0.0071  cls_loss: 0.0166  \n",
      "<<<iteration:[260/263] - total_loss: 0.2472  obj_loss: 0.1522  noobj_loss: 0.0966  bbox_loss: 0.0062  cls_loss: 0.0155  \n",
      "\n",
      "epoch:55/100 - Train Loss: 0.2582, Val Loss: 0.2668\n",
      "\n",
      "<<<iteration:[20/263] - total_loss: 0.2606  obj_loss: 0.1581  noobj_loss: 0.0998  bbox_loss: 0.0074  cls_loss: 0.0156  \n",
      "<<<iteration:[40/263] - total_loss: 0.2668  obj_loss: 0.1683  noobj_loss: 0.1020  bbox_loss: 0.0067  cls_loss: 0.0138  \n",
      "<<<iteration:[60/263] - total_loss: 0.2602  obj_loss: 0.1660  noobj_loss: 0.0924  bbox_loss: 0.0062  cls_loss: 0.0168  \n",
      "<<<iteration:[80/263] - total_loss: 0.2539  obj_loss: 0.1635  noobj_loss: 0.0913  bbox_loss: 0.0067  cls_loss: 0.0112  \n",
      "<<<iteration:[100/263] - total_loss: 0.2627  obj_loss: 0.1645  noobj_loss: 0.0951  bbox_loss: 0.0069  cls_loss: 0.0163  \n",
      "<<<iteration:[120/263] - total_loss: 0.2401  obj_loss: 0.1396  noobj_loss: 0.0976  bbox_loss: 0.0067  cls_loss: 0.0180  \n",
      "<<<iteration:[140/263] - total_loss: 0.2606  obj_loss: 0.1650  noobj_loss: 0.0966  bbox_loss: 0.0068  cls_loss: 0.0131  \n",
      "<<<iteration:[160/263] - total_loss: 0.2641  obj_loss: 0.1670  noobj_loss: 0.0995  bbox_loss: 0.0065  cls_loss: 0.0146  \n",
      "<<<iteration:[180/263] - total_loss: 0.2627  obj_loss: 0.1643  noobj_loss: 0.0960  bbox_loss: 0.0070  cls_loss: 0.0152  \n",
      "<<<iteration:[200/263] - total_loss: 0.2574  obj_loss: 0.1645  noobj_loss: 0.0951  bbox_loss: 0.0066  cls_loss: 0.0125  \n",
      "<<<iteration:[220/263] - total_loss: 0.2719  obj_loss: 0.1803  noobj_loss: 0.0992  bbox_loss: 0.0059  cls_loss: 0.0123  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<<<iteration:[240/263] - total_loss: 0.2579  obj_loss: 0.1641  noobj_loss: 0.1019  bbox_loss: 0.0063  cls_loss: 0.0115  \n",
      "<<<iteration:[260/263] - total_loss: 0.2606  obj_loss: 0.1661  noobj_loss: 0.1010  bbox_loss: 0.0063  cls_loss: 0.0127  \n",
      "\n",
      "epoch:56/100 - Train Loss: 0.2588, Val Loss: 0.2724\n",
      "\n",
      "<<<iteration:[20/263] - total_loss: 0.2797  obj_loss: 0.1790  noobj_loss: 0.1064  bbox_loss: 0.0071  cls_loss: 0.0121  \n",
      "<<<iteration:[40/263] - total_loss: 0.2551  obj_loss: 0.1592  noobj_loss: 0.0974  bbox_loss: 0.0065  cls_loss: 0.0145  \n",
      "<<<iteration:[60/263] - total_loss: 0.2657  obj_loss: 0.1693  noobj_loss: 0.1018  bbox_loss: 0.0067  cls_loss: 0.0122  \n",
      "<<<iteration:[80/263] - total_loss: 0.2610  obj_loss: 0.1693  noobj_loss: 0.1003  bbox_loss: 0.0058  cls_loss: 0.0124  \n",
      "<<<iteration:[100/263] - total_loss: 0.2667  obj_loss: 0.1727  noobj_loss: 0.0978  bbox_loss: 0.0063  cls_loss: 0.0134  \n",
      "<<<iteration:[120/263] - total_loss: 0.2485  obj_loss: 0.1484  noobj_loss: 0.1016  bbox_loss: 0.0070  cls_loss: 0.0142  \n",
      "<<<iteration:[140/263] - total_loss: 0.2566  obj_loss: 0.1615  noobj_loss: 0.0948  bbox_loss: 0.0067  cls_loss: 0.0144  \n",
      "<<<iteration:[160/263] - total_loss: 0.2627  obj_loss: 0.1717  noobj_loss: 0.0945  bbox_loss: 0.0061  cls_loss: 0.0132  \n",
      "<<<iteration:[180/263] - total_loss: 0.2560  obj_loss: 0.1592  noobj_loss: 0.0943  bbox_loss: 0.0065  cls_loss: 0.0174  \n",
      "<<<iteration:[200/263] - total_loss: 0.2667  obj_loss: 0.1714  noobj_loss: 0.1047  bbox_loss: 0.0060  cls_loss: 0.0131  \n",
      "<<<iteration:[220/263] - total_loss: 0.2604  obj_loss: 0.1659  noobj_loss: 0.1023  bbox_loss: 0.0063  cls_loss: 0.0117  \n",
      "<<<iteration:[240/263] - total_loss: 0.2722  obj_loss: 0.1703  noobj_loss: 0.1077  bbox_loss: 0.0067  cls_loss: 0.0145  \n",
      "<<<iteration:[260/263] - total_loss: 0.2577  obj_loss: 0.1628  noobj_loss: 0.0969  bbox_loss: 0.0067  cls_loss: 0.0129  \n",
      "\n",
      "epoch:57/100 - Train Loss: 0.2610, Val Loss: 0.2683\n",
      "\n",
      "<<<iteration:[20/263] - total_loss: 0.2742  obj_loss: 0.1762  noobj_loss: 0.1027  bbox_loss: 0.0065  cls_loss: 0.0142  \n",
      "<<<iteration:[40/263] - total_loss: 0.2499  obj_loss: 0.1576  noobj_loss: 0.0976  bbox_loss: 0.0067  cls_loss: 0.0101  \n",
      "<<<iteration:[60/263] - total_loss: 0.2666  obj_loss: 0.1711  noobj_loss: 0.1028  bbox_loss: 0.0063  cls_loss: 0.0127  \n",
      "<<<iteration:[80/263] - total_loss: 0.2534  obj_loss: 0.1603  noobj_loss: 0.0970  bbox_loss: 0.0069  cls_loss: 0.0102  \n",
      "<<<iteration:[100/263] - total_loss: 0.2605  obj_loss: 0.1635  noobj_loss: 0.0996  bbox_loss: 0.0066  cls_loss: 0.0141  \n",
      "<<<iteration:[120/263] - total_loss: 0.2794  obj_loss: 0.1796  noobj_loss: 0.1060  bbox_loss: 0.0063  cls_loss: 0.0154  \n",
      "<<<iteration:[140/263] - total_loss: 0.2581  obj_loss: 0.1613  noobj_loss: 0.0957  bbox_loss: 0.0066  cls_loss: 0.0159  \n",
      "<<<iteration:[160/263] - total_loss: 0.2671  obj_loss: 0.1698  noobj_loss: 0.1009  bbox_loss: 0.0067  cls_loss: 0.0135  \n",
      "<<<iteration:[180/263] - total_loss: 0.2566  obj_loss: 0.1578  noobj_loss: 0.1008  bbox_loss: 0.0068  cls_loss: 0.0144  \n",
      "<<<iteration:[200/263] - total_loss: 0.2532  obj_loss: 0.1621  noobj_loss: 0.0968  bbox_loss: 0.0063  cls_loss: 0.0114  \n",
      "<<<iteration:[220/263] - total_loss: 0.2600  obj_loss: 0.1629  noobj_loss: 0.1040  bbox_loss: 0.0063  cls_loss: 0.0137  \n",
      "<<<iteration:[240/263] - total_loss: 0.2670  obj_loss: 0.1697  noobj_loss: 0.1022  bbox_loss: 0.0067  cls_loss: 0.0126  \n",
      "<<<iteration:[260/263] - total_loss: 0.2657  obj_loss: 0.1662  noobj_loss: 0.1007  bbox_loss: 0.0069  cls_loss: 0.0145  \n",
      "\n",
      "epoch:58/100 - Train Loss: 0.2615, Val Loss: 0.2723\n",
      "\n",
      "<<<iteration:[20/263] - total_loss: 0.2735  obj_loss: 0.1670  noobj_loss: 0.1055  bbox_loss: 0.0075  cls_loss: 0.0165  \n",
      "<<<iteration:[40/263] - total_loss: 0.2732  obj_loss: 0.1744  noobj_loss: 0.0998  bbox_loss: 0.0074  cls_loss: 0.0122  \n",
      "<<<iteration:[60/263] - total_loss: 0.2582  obj_loss: 0.1634  noobj_loss: 0.1036  bbox_loss: 0.0066  cls_loss: 0.0103  \n",
      "<<<iteration:[80/263] - total_loss: 0.2602  obj_loss: 0.1450  noobj_loss: 0.1042  bbox_loss: 0.0094  cls_loss: 0.0163  \n",
      "<<<iteration:[100/263] - total_loss: 0.2553  obj_loss: 0.1500  noobj_loss: 0.0988  bbox_loss: 0.0082  cls_loss: 0.0151  \n",
      "<<<iteration:[120/263] - total_loss: 0.2634  obj_loss: 0.1571  noobj_loss: 0.1028  bbox_loss: 0.0085  cls_loss: 0.0126  \n",
      "<<<iteration:[140/263] - total_loss: 0.2611  obj_loss: 0.1670  noobj_loss: 0.0940  bbox_loss: 0.0067  cls_loss: 0.0136  \n",
      "<<<iteration:[160/263] - total_loss: 0.2510  obj_loss: 0.1502  noobj_loss: 0.1038  bbox_loss: 0.0069  cls_loss: 0.0144  \n",
      "<<<iteration:[180/263] - total_loss: 0.2533  obj_loss: 0.1582  noobj_loss: 0.0976  bbox_loss: 0.0067  cls_loss: 0.0130  \n",
      "<<<iteration:[200/263] - total_loss: 0.2542  obj_loss: 0.1627  noobj_loss: 0.0937  bbox_loss: 0.0062  cls_loss: 0.0135  \n",
      "<<<iteration:[220/263] - total_loss: 0.2487  obj_loss: 0.1597  noobj_loss: 0.0969  bbox_loss: 0.0056  cls_loss: 0.0126  \n",
      "<<<iteration:[240/263] - total_loss: 0.2443  obj_loss: 0.1522  noobj_loss: 0.1020  bbox_loss: 0.0057  cls_loss: 0.0124  \n",
      "<<<iteration:[260/263] - total_loss: 0.2652  obj_loss: 0.1673  noobj_loss: 0.1013  bbox_loss: 0.0068  cls_loss: 0.0132  \n",
      "\n",
      "epoch:59/100 - Train Loss: 0.2573, Val Loss: 0.2723\n",
      "\n",
      "<<<iteration:[20/263] - total_loss: 0.2604  obj_loss: 0.1629  noobj_loss: 0.0988  bbox_loss: 0.0071  cls_loss: 0.0128  \n",
      "<<<iteration:[40/263] - total_loss: 0.2580  obj_loss: 0.1667  noobj_loss: 0.1009  bbox_loss: 0.0057  cls_loss: 0.0124  \n",
      "<<<iteration:[60/263] - total_loss: 0.2467  obj_loss: 0.1495  noobj_loss: 0.0982  bbox_loss: 0.0073  cls_loss: 0.0116  \n",
      "<<<iteration:[80/263] - total_loss: 0.2531  obj_loss: 0.1635  noobj_loss: 0.0948  bbox_loss: 0.0061  cls_loss: 0.0119  \n",
      "<<<iteration:[100/263] - total_loss: 0.2420  obj_loss: 0.1499  noobj_loss: 0.0995  bbox_loss: 0.0066  cls_loss: 0.0096  \n",
      "<<<iteration:[120/263] - total_loss: 0.2663  obj_loss: 0.1656  noobj_loss: 0.1026  bbox_loss: 0.0065  cls_loss: 0.0170  \n",
      "<<<iteration:[140/263] - total_loss: 0.2625  obj_loss: 0.1702  noobj_loss: 0.0987  bbox_loss: 0.0062  cls_loss: 0.0118  \n",
      "<<<iteration:[160/263] - total_loss: 0.2511  obj_loss: 0.1547  noobj_loss: 0.1025  bbox_loss: 0.0062  cls_loss: 0.0140  \n",
      "<<<iteration:[180/263] - total_loss: 0.2676  obj_loss: 0.1673  noobj_loss: 0.1058  bbox_loss: 0.0064  cls_loss: 0.0156  \n",
      "<<<iteration:[200/263] - total_loss: 0.2463  obj_loss: 0.1513  noobj_loss: 0.0992  bbox_loss: 0.0065  cls_loss: 0.0129  \n",
      "<<<iteration:[220/263] - total_loss: 0.2747  obj_loss: 0.1779  noobj_loss: 0.0976  bbox_loss: 0.0070  cls_loss: 0.0131  \n",
      "<<<iteration:[240/263] - total_loss: 0.2434  obj_loss: 0.1475  noobj_loss: 0.0976  bbox_loss: 0.0063  cls_loss: 0.0156  \n",
      "<<<iteration:[260/263] - total_loss: 0.2614  obj_loss: 0.1610  noobj_loss: 0.1039  bbox_loss: 0.0069  cls_loss: 0.0139  \n",
      "\n",
      "epoch:60/100 - Train Loss: 0.2552, Val Loss: 0.2643\n",
      "\n",
      "<<<iteration:[20/263] - total_loss: 0.2782  obj_loss: 0.1792  noobj_loss: 0.1054  bbox_loss: 0.0067  cls_loss: 0.0130  \n",
      "<<<iteration:[40/263] - total_loss: 0.2559  obj_loss: 0.1632  noobj_loss: 0.0997  bbox_loss: 0.0059  cls_loss: 0.0132  \n",
      "<<<iteration:[60/263] - total_loss: 0.2673  obj_loss: 0.1679  noobj_loss: 0.1052  bbox_loss: 0.0064  cls_loss: 0.0149  \n",
      "<<<iteration:[80/263] - total_loss: 0.2515  obj_loss: 0.1528  noobj_loss: 0.0989  bbox_loss: 0.0069  cls_loss: 0.0149  \n",
      "<<<iteration:[100/263] - total_loss: 0.2687  obj_loss: 0.1701  noobj_loss: 0.1018  bbox_loss: 0.0068  cls_loss: 0.0138  \n",
      "<<<iteration:[120/263] - total_loss: 0.2617  obj_loss: 0.1696  noobj_loss: 0.0963  bbox_loss: 0.0064  cls_loss: 0.0118  \n",
      "<<<iteration:[140/263] - total_loss: 0.2598  obj_loss: 0.1636  noobj_loss: 0.1044  bbox_loss: 0.0065  cls_loss: 0.0115  \n",
      "<<<iteration:[160/263] - total_loss: 0.2615  obj_loss: 0.1673  noobj_loss: 0.1004  bbox_loss: 0.0066  cls_loss: 0.0112  \n",
      "<<<iteration:[180/263] - total_loss: 0.2644  obj_loss: 0.1666  noobj_loss: 0.1014  bbox_loss: 0.0068  cls_loss: 0.0131  \n",
      "<<<iteration:[200/263] - total_loss: 0.2533  obj_loss: 0.1596  noobj_loss: 0.0993  bbox_loss: 0.0065  cls_loss: 0.0117  \n",
      "<<<iteration:[220/263] - total_loss: 0.2420  obj_loss: 0.1493  noobj_loss: 0.1011  bbox_loss: 0.0064  cls_loss: 0.0104  \n",
      "<<<iteration:[240/263] - total_loss: 0.2581  obj_loss: 0.1638  noobj_loss: 0.1038  bbox_loss: 0.0058  cls_loss: 0.0133  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<<<iteration:[260/263] - total_loss: 0.2435  obj_loss: 0.1542  noobj_loss: 0.0964  bbox_loss: 0.0061  cls_loss: 0.0105  \n",
      "\n",
      "epoch:61/100 - Train Loss: 0.2578, Val Loss: 0.2636\n",
      "\n",
      "<<<iteration:[20/263] - total_loss: 0.2757  obj_loss: 0.1755  noobj_loss: 0.1052  bbox_loss: 0.0070  cls_loss: 0.0127  \n",
      "<<<iteration:[40/263] - total_loss: 0.2580  obj_loss: 0.1629  noobj_loss: 0.0989  bbox_loss: 0.0063  cls_loss: 0.0140  \n",
      "<<<iteration:[60/263] - total_loss: 0.2427  obj_loss: 0.1516  noobj_loss: 0.0976  bbox_loss: 0.0064  cls_loss: 0.0105  \n",
      "<<<iteration:[80/263] - total_loss: 0.2663  obj_loss: 0.1723  noobj_loss: 0.1042  bbox_loss: 0.0064  cls_loss: 0.0098  \n",
      "<<<iteration:[100/263] - total_loss: 0.2628  obj_loss: 0.1638  noobj_loss: 0.1033  bbox_loss: 0.0064  cls_loss: 0.0151  \n",
      "<<<iteration:[120/263] - total_loss: 0.2612  obj_loss: 0.1590  noobj_loss: 0.1043  bbox_loss: 0.0067  cls_loss: 0.0167  \n",
      "<<<iteration:[140/263] - total_loss: 0.2615  obj_loss: 0.1647  noobj_loss: 0.1043  bbox_loss: 0.0062  cls_loss: 0.0134  \n",
      "<<<iteration:[160/263] - total_loss: 0.2561  obj_loss: 0.1595  noobj_loss: 0.1073  bbox_loss: 0.0060  cls_loss: 0.0128  \n",
      "<<<iteration:[180/263] - total_loss: 0.2629  obj_loss: 0.1636  noobj_loss: 0.0973  bbox_loss: 0.0072  cls_loss: 0.0147  \n",
      "<<<iteration:[200/263] - total_loss: 0.2535  obj_loss: 0.1613  noobj_loss: 0.0997  bbox_loss: 0.0061  cls_loss: 0.0119  \n",
      "<<<iteration:[220/263] - total_loss: 0.2633  obj_loss: 0.1682  noobj_loss: 0.1029  bbox_loss: 0.0062  cls_loss: 0.0127  \n",
      "<<<iteration:[240/263] - total_loss: 0.2520  obj_loss: 0.1543  noobj_loss: 0.1006  bbox_loss: 0.0068  cls_loss: 0.0135  \n",
      "<<<iteration:[260/263] - total_loss: 0.2594  obj_loss: 0.1682  noobj_loss: 0.1030  bbox_loss: 0.0058  cls_loss: 0.0106  \n",
      "\n",
      "epoch:62/100 - Train Loss: 0.2586, Val Loss: 0.2677\n",
      "\n",
      "<<<iteration:[20/263] - total_loss: 0.2747  obj_loss: 0.1783  noobj_loss: 0.1078  bbox_loss: 0.0063  cls_loss: 0.0113  \n",
      "<<<iteration:[40/263] - total_loss: 0.2661  obj_loss: 0.1738  noobj_loss: 0.1058  bbox_loss: 0.0055  cls_loss: 0.0120  \n",
      "<<<iteration:[60/263] - total_loss: 0.2335  obj_loss: 0.1439  noobj_loss: 0.0979  bbox_loss: 0.0060  cls_loss: 0.0105  \n",
      "<<<iteration:[80/263] - total_loss: 0.2593  obj_loss: 0.1638  noobj_loss: 0.1033  bbox_loss: 0.0064  cls_loss: 0.0118  \n",
      "<<<iteration:[100/263] - total_loss: 0.2626  obj_loss: 0.1683  noobj_loss: 0.1045  bbox_loss: 0.0063  cls_loss: 0.0107  \n",
      "<<<iteration:[120/263] - total_loss: 0.2549  obj_loss: 0.1633  noobj_loss: 0.0973  bbox_loss: 0.0059  cls_loss: 0.0134  \n",
      "<<<iteration:[140/263] - total_loss: 0.2449  obj_loss: 0.1496  noobj_loss: 0.1027  bbox_loss: 0.0063  cls_loss: 0.0124  \n",
      "<<<iteration:[160/263] - total_loss: 0.2449  obj_loss: 0.1538  noobj_loss: 0.0988  bbox_loss: 0.0057  cls_loss: 0.0133  \n",
      "<<<iteration:[180/263] - total_loss: 0.2689  obj_loss: 0.1801  noobj_loss: 0.1050  bbox_loss: 0.0052  cls_loss: 0.0103  \n",
      "<<<iteration:[200/263] - total_loss: 0.2481  obj_loss: 0.1506  noobj_loss: 0.1004  bbox_loss: 0.0064  cls_loss: 0.0152  \n",
      "<<<iteration:[220/263] - total_loss: 0.2627  obj_loss: 0.1611  noobj_loss: 0.1035  bbox_loss: 0.0070  cls_loss: 0.0149  \n",
      "<<<iteration:[240/263] - total_loss: 0.2477  obj_loss: 0.1564  noobj_loss: 0.1004  bbox_loss: 0.0061  cls_loss: 0.0107  \n",
      "<<<iteration:[260/263] - total_loss: 0.2633  obj_loss: 0.1723  noobj_loss: 0.1008  bbox_loss: 0.0059  cls_loss: 0.0113  \n",
      "\n",
      "epoch:63/100 - Train Loss: 0.2554, Val Loss: 0.2661\n",
      "\n",
      "<<<iteration:[20/263] - total_loss: 0.2776  obj_loss: 0.1805  noobj_loss: 0.1087  bbox_loss: 0.0063  cls_loss: 0.0115  \n",
      "<<<iteration:[40/263] - total_loss: 0.2488  obj_loss: 0.1544  noobj_loss: 0.1027  bbox_loss: 0.0056  cls_loss: 0.0148  \n",
      "<<<iteration:[60/263] - total_loss: 0.2544  obj_loss: 0.1612  noobj_loss: 0.1017  bbox_loss: 0.0063  cls_loss: 0.0109  \n",
      "<<<iteration:[80/263] - total_loss: 0.2610  obj_loss: 0.1656  noobj_loss: 0.1038  bbox_loss: 0.0058  cls_loss: 0.0145  \n",
      "<<<iteration:[100/263] - total_loss: 0.2587  obj_loss: 0.1638  noobj_loss: 0.1031  bbox_loss: 0.0063  cls_loss: 0.0119  \n",
      "<<<iteration:[120/263] - total_loss: 0.2674  obj_loss: 0.1726  noobj_loss: 0.1031  bbox_loss: 0.0062  cls_loss: 0.0124  \n",
      "<<<iteration:[140/263] - total_loss: 0.2455  obj_loss: 0.1549  noobj_loss: 0.1010  bbox_loss: 0.0057  cls_loss: 0.0117  \n",
      "<<<iteration:[160/263] - total_loss: 0.2706  obj_loss: 0.1741  noobj_loss: 0.1037  bbox_loss: 0.0062  cls_loss: 0.0139  \n",
      "<<<iteration:[180/263] - total_loss: 0.2449  obj_loss: 0.1547  noobj_loss: 0.0967  bbox_loss: 0.0062  cls_loss: 0.0109  \n",
      "<<<iteration:[200/263] - total_loss: 0.2504  obj_loss: 0.1578  noobj_loss: 0.1015  bbox_loss: 0.0060  cls_loss: 0.0119  \n",
      "<<<iteration:[220/263] - total_loss: 0.2587  obj_loss: 0.1622  noobj_loss: 0.1069  bbox_loss: 0.0065  cls_loss: 0.0107  \n",
      "<<<iteration:[240/263] - total_loss: 0.2567  obj_loss: 0.1661  noobj_loss: 0.0976  bbox_loss: 0.0060  cls_loss: 0.0117  \n",
      "<<<iteration:[260/263] - total_loss: 0.2492  obj_loss: 0.1573  noobj_loss: 0.1009  bbox_loss: 0.0063  cls_loss: 0.0098  \n",
      "\n",
      "epoch:64/100 - Train Loss: 0.2561, Val Loss: 0.2674\n",
      "\n",
      "<<<iteration:[20/263] - total_loss: 0.2602  obj_loss: 0.1636  noobj_loss: 0.1070  bbox_loss: 0.0060  cls_loss: 0.0132  \n",
      "<<<iteration:[40/263] - total_loss: 0.2575  obj_loss: 0.1587  noobj_loss: 0.1024  bbox_loss: 0.0063  cls_loss: 0.0159  \n",
      "<<<iteration:[60/263] - total_loss: 0.2624  obj_loss: 0.1687  noobj_loss: 0.1029  bbox_loss: 0.0060  cls_loss: 0.0121  \n",
      "<<<iteration:[80/263] - total_loss: 0.2688  obj_loss: 0.1774  noobj_loss: 0.1030  bbox_loss: 0.0057  cls_loss: 0.0114  \n",
      "<<<iteration:[100/263] - total_loss: 0.2541  obj_loss: 0.1617  noobj_loss: 0.1065  bbox_loss: 0.0058  cls_loss: 0.0100  \n",
      "<<<iteration:[120/263] - total_loss: 0.2528  obj_loss: 0.1631  noobj_loss: 0.1019  bbox_loss: 0.0056  cls_loss: 0.0106  \n",
      "<<<iteration:[140/263] - total_loss: 0.2555  obj_loss: 0.1602  noobj_loss: 0.1036  bbox_loss: 0.0059  cls_loss: 0.0140  \n",
      "<<<iteration:[160/263] - total_loss: 0.2621  obj_loss: 0.1678  noobj_loss: 0.1013  bbox_loss: 0.0059  cls_loss: 0.0140  \n",
      "<<<iteration:[180/263] - total_loss: 0.2576  obj_loss: 0.1572  noobj_loss: 0.1067  bbox_loss: 0.0067  cls_loss: 0.0134  \n",
      "<<<iteration:[200/263] - total_loss: 0.2556  obj_loss: 0.1529  noobj_loss: 0.1040  bbox_loss: 0.0070  cls_loss: 0.0158  \n",
      "<<<iteration:[220/263] - total_loss: 0.2609  obj_loss: 0.1697  noobj_loss: 0.0993  bbox_loss: 0.0058  cls_loss: 0.0124  \n",
      "<<<iteration:[240/263] - total_loss: 0.2404  obj_loss: 0.1476  noobj_loss: 0.1034  bbox_loss: 0.0061  cls_loss: 0.0106  \n",
      "<<<iteration:[260/263] - total_loss: 0.2600  obj_loss: 0.1597  noobj_loss: 0.0991  bbox_loss: 0.0078  cls_loss: 0.0117  \n",
      "\n",
      "epoch:65/100 - Train Loss: 0.2567, Val Loss: 0.2666\n",
      "\n",
      "<<<iteration:[20/263] - total_loss: 0.2906  obj_loss: 0.1878  noobj_loss: 0.1148  bbox_loss: 0.0064  cls_loss: 0.0133  \n",
      "<<<iteration:[40/263] - total_loss: 0.2793  obj_loss: 0.1863  noobj_loss: 0.1082  bbox_loss: 0.0058  cls_loss: 0.0101  \n",
      "<<<iteration:[60/263] - total_loss: 0.2560  obj_loss: 0.1578  noobj_loss: 0.1040  bbox_loss: 0.0064  cls_loss: 0.0140  \n",
      "<<<iteration:[80/263] - total_loss: 0.2427  obj_loss: 0.1465  noobj_loss: 0.1000  bbox_loss: 0.0066  cls_loss: 0.0129  \n",
      "<<<iteration:[100/263] - total_loss: 0.2661  obj_loss: 0.1706  noobj_loss: 0.1068  bbox_loss: 0.0061  cls_loss: 0.0115  \n",
      "<<<iteration:[120/263] - total_loss: 0.2649  obj_loss: 0.1729  noobj_loss: 0.1055  bbox_loss: 0.0057  cls_loss: 0.0109  \n",
      "<<<iteration:[140/263] - total_loss: 0.2578  obj_loss: 0.1612  noobj_loss: 0.1034  bbox_loss: 0.0064  cls_loss: 0.0128  \n",
      "<<<iteration:[160/263] - total_loss: 0.2505  obj_loss: 0.1549  noobj_loss: 0.1050  bbox_loss: 0.0061  cls_loss: 0.0126  \n",
      "<<<iteration:[180/263] - total_loss: 0.2603  obj_loss: 0.1665  noobj_loss: 0.1067  bbox_loss: 0.0056  cls_loss: 0.0123  \n",
      "<<<iteration:[200/263] - total_loss: 0.2625  obj_loss: 0.1664  noobj_loss: 0.1109  bbox_loss: 0.0057  cls_loss: 0.0124  \n",
      "<<<iteration:[220/263] - total_loss: 0.2568  obj_loss: 0.1668  noobj_loss: 0.1036  bbox_loss: 0.0058  cls_loss: 0.0093  \n",
      "<<<iteration:[240/263] - total_loss: 0.2500  obj_loss: 0.1545  noobj_loss: 0.1049  bbox_loss: 0.0064  cls_loss: 0.0112  \n",
      "<<<iteration:[260/263] - total_loss: 0.2488  obj_loss: 0.1536  noobj_loss: 0.1019  bbox_loss: 0.0064  cls_loss: 0.0122  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "epoch:66/100 - Train Loss: 0.2593, Val Loss: 0.2612\n",
      "\n",
      "<<<iteration:[20/263] - total_loss: 0.2740  obj_loss: 0.1799  noobj_loss: 0.1101  bbox_loss: 0.0054  cls_loss: 0.0121  \n",
      "<<<iteration:[40/263] - total_loss: 0.2516  obj_loss: 0.1541  noobj_loss: 0.1050  bbox_loss: 0.0062  cls_loss: 0.0142  \n",
      "<<<iteration:[60/263] - total_loss: 0.2616  obj_loss: 0.1657  noobj_loss: 0.1069  bbox_loss: 0.0063  cls_loss: 0.0110  \n",
      "<<<iteration:[80/263] - total_loss: 0.2620  obj_loss: 0.1653  noobj_loss: 0.1069  bbox_loss: 0.0060  cls_loss: 0.0130  \n",
      "<<<iteration:[100/263] - total_loss: 0.2543  obj_loss: 0.1653  noobj_loss: 0.1068  bbox_loss: 0.0051  cls_loss: 0.0103  \n",
      "<<<iteration:[120/263] - total_loss: 0.2444  obj_loss: 0.1565  noobj_loss: 0.1056  bbox_loss: 0.0049  cls_loss: 0.0104  \n",
      "<<<iteration:[140/263] - total_loss: 0.2667  obj_loss: 0.1720  noobj_loss: 0.1051  bbox_loss: 0.0059  cls_loss: 0.0126  \n",
      "<<<iteration:[160/263] - total_loss: 0.2590  obj_loss: 0.1636  noobj_loss: 0.1039  bbox_loss: 0.0063  cls_loss: 0.0122  \n",
      "<<<iteration:[180/263] - total_loss: 0.2678  obj_loss: 0.1702  noobj_loss: 0.1047  bbox_loss: 0.0066  cls_loss: 0.0125  \n",
      "<<<iteration:[200/263] - total_loss: 0.2438  obj_loss: 0.1541  noobj_loss: 0.1085  bbox_loss: 0.0050  cls_loss: 0.0105  \n",
      "<<<iteration:[220/263] - total_loss: 0.2636  obj_loss: 0.1707  noobj_loss: 0.1043  bbox_loss: 0.0056  cls_loss: 0.0127  \n",
      "<<<iteration:[240/263] - total_loss: 0.2475  obj_loss: 0.1577  noobj_loss: 0.1045  bbox_loss: 0.0056  cls_loss: 0.0095  \n",
      "<<<iteration:[260/263] - total_loss: 0.2539  obj_loss: 0.1558  noobj_loss: 0.1095  bbox_loss: 0.0064  cls_loss: 0.0116  \n",
      "\n",
      "epoch:67/100 - Train Loss: 0.2569, Val Loss: 0.2690\n",
      "\n",
      "<<<iteration:[20/263] - total_loss: 0.2565  obj_loss: 0.1587  noobj_loss: 0.1069  bbox_loss: 0.0061  cls_loss: 0.0141  \n",
      "<<<iteration:[40/263] - total_loss: 0.2586  obj_loss: 0.1663  noobj_loss: 0.1084  bbox_loss: 0.0050  cls_loss: 0.0128  \n",
      "<<<iteration:[60/263] - total_loss: 0.2613  obj_loss: 0.1678  noobj_loss: 0.1082  bbox_loss: 0.0055  cls_loss: 0.0120  \n",
      "<<<iteration:[80/263] - total_loss: 0.2791  obj_loss: 0.1868  noobj_loss: 0.1031  bbox_loss: 0.0059  cls_loss: 0.0110  \n",
      "<<<iteration:[100/263] - total_loss: 0.2538  obj_loss: 0.1610  noobj_loss: 0.1055  bbox_loss: 0.0060  cls_loss: 0.0102  \n",
      "<<<iteration:[120/263] - total_loss: 0.2645  obj_loss: 0.1689  noobj_loss: 0.1069  bbox_loss: 0.0058  cls_loss: 0.0130  \n",
      "<<<iteration:[140/263] - total_loss: 0.2501  obj_loss: 0.1551  noobj_loss: 0.1042  bbox_loss: 0.0063  cls_loss: 0.0114  \n",
      "<<<iteration:[160/263] - total_loss: 0.2458  obj_loss: 0.1581  noobj_loss: 0.1018  bbox_loss: 0.0054  cls_loss: 0.0098  \n",
      "<<<iteration:[180/263] - total_loss: 0.2536  obj_loss: 0.1548  noobj_loss: 0.1039  bbox_loss: 0.0062  cls_loss: 0.0156  \n",
      "<<<iteration:[200/263] - total_loss: 0.2596  obj_loss: 0.1639  noobj_loss: 0.1008  bbox_loss: 0.0062  cls_loss: 0.0140  \n",
      "<<<iteration:[220/263] - total_loss: 0.2491  obj_loss: 0.1524  noobj_loss: 0.1065  bbox_loss: 0.0064  cls_loss: 0.0113  \n",
      "<<<iteration:[240/263] - total_loss: 0.2505  obj_loss: 0.1564  noobj_loss: 0.1034  bbox_loss: 0.0059  cls_loss: 0.0128  \n",
      "<<<iteration:[260/263] - total_loss: 0.2502  obj_loss: 0.1559  noobj_loss: 0.1028  bbox_loss: 0.0064  cls_loss: 0.0112  \n",
      "\n",
      "epoch:68/100 - Train Loss: 0.2554, Val Loss: 0.2640\n",
      "\n",
      "<<<iteration:[20/263] - total_loss: 0.2781  obj_loss: 0.1835  noobj_loss: 0.1111  bbox_loss: 0.0051  cls_loss: 0.0134  \n",
      "<<<iteration:[40/263] - total_loss: 0.2611  obj_loss: 0.1680  noobj_loss: 0.1088  bbox_loss: 0.0055  cls_loss: 0.0114  \n",
      "<<<iteration:[60/263] - total_loss: 0.2573  obj_loss: 0.1604  noobj_loss: 0.1065  bbox_loss: 0.0065  cls_loss: 0.0112  \n",
      "<<<iteration:[80/263] - total_loss: 0.2491  obj_loss: 0.1554  noobj_loss: 0.1067  bbox_loss: 0.0058  cls_loss: 0.0113  \n",
      "<<<iteration:[100/263] - total_loss: 0.2563  obj_loss: 0.1620  noobj_loss: 0.1041  bbox_loss: 0.0064  cls_loss: 0.0102  \n",
      "<<<iteration:[120/263] - total_loss: 0.2694  obj_loss: 0.1663  noobj_loss: 0.1088  bbox_loss: 0.0065  cls_loss: 0.0165  \n",
      "<<<iteration:[140/263] - total_loss: 0.2568  obj_loss: 0.1639  noobj_loss: 0.1039  bbox_loss: 0.0057  cls_loss: 0.0127  \n",
      "<<<iteration:[160/263] - total_loss: 0.2589  obj_loss: 0.1671  noobj_loss: 0.1073  bbox_loss: 0.0055  cls_loss: 0.0105  \n",
      "<<<iteration:[180/263] - total_loss: 0.2648  obj_loss: 0.1728  noobj_loss: 0.1054  bbox_loss: 0.0057  cls_loss: 0.0106  \n",
      "<<<iteration:[200/263] - total_loss: 0.2511  obj_loss: 0.1583  noobj_loss: 0.1010  bbox_loss: 0.0058  cls_loss: 0.0132  \n",
      "<<<iteration:[220/263] - total_loss: 0.2533  obj_loss: 0.1607  noobj_loss: 0.1072  bbox_loss: 0.0056  cls_loss: 0.0109  \n",
      "<<<iteration:[240/263] - total_loss: 0.2461  obj_loss: 0.1572  noobj_loss: 0.1001  bbox_loss: 0.0058  cls_loss: 0.0101  \n",
      "<<<iteration:[260/263] - total_loss: 0.2595  obj_loss: 0.1627  noobj_loss: 0.1043  bbox_loss: 0.0061  cls_loss: 0.0139  \n",
      "\n",
      "epoch:69/100 - Train Loss: 0.2578, Val Loss: 0.2657\n",
      "\n",
      "<<<iteration:[20/263] - total_loss: 0.2738  obj_loss: 0.1733  noobj_loss: 0.1102  bbox_loss: 0.0066  cls_loss: 0.0124  \n",
      "<<<iteration:[40/263] - total_loss: 0.2503  obj_loss: 0.1558  noobj_loss: 0.1075  bbox_loss: 0.0056  cls_loss: 0.0127  \n",
      "<<<iteration:[60/263] - total_loss: 0.2415  obj_loss: 0.1554  noobj_loss: 0.1003  bbox_loss: 0.0053  cls_loss: 0.0094  \n",
      "<<<iteration:[80/263] - total_loss: 0.2769  obj_loss: 0.1854  noobj_loss: 0.1082  bbox_loss: 0.0053  cls_loss: 0.0109  \n",
      "<<<iteration:[100/263] - total_loss: 0.2545  obj_loss: 0.1586  noobj_loss: 0.1087  bbox_loss: 0.0059  cls_loss: 0.0121  \n",
      "<<<iteration:[120/263] - total_loss: 0.2489  obj_loss: 0.1595  noobj_loss: 0.1009  bbox_loss: 0.0054  cls_loss: 0.0120  \n",
      "<<<iteration:[140/263] - total_loss: 0.2546  obj_loss: 0.1607  noobj_loss: 0.1093  bbox_loss: 0.0056  cls_loss: 0.0113  \n",
      "<<<iteration:[160/263] - total_loss: 0.2542  obj_loss: 0.1610  noobj_loss: 0.1056  bbox_loss: 0.0061  cls_loss: 0.0097  \n",
      "<<<iteration:[180/263] - total_loss: 0.2460  obj_loss: 0.1479  noobj_loss: 0.1068  bbox_loss: 0.0064  cls_loss: 0.0126  \n",
      "<<<iteration:[200/263] - total_loss: 0.2556  obj_loss: 0.1649  noobj_loss: 0.1041  bbox_loss: 0.0057  cls_loss: 0.0103  \n",
      "<<<iteration:[220/263] - total_loss: 0.2676  obj_loss: 0.1652  noobj_loss: 0.1063  bbox_loss: 0.0069  cls_loss: 0.0149  \n",
      "<<<iteration:[240/263] - total_loss: 0.2499  obj_loss: 0.1600  noobj_loss: 0.1046  bbox_loss: 0.0052  cls_loss: 0.0117  \n",
      "<<<iteration:[260/263] - total_loss: 0.2454  obj_loss: 0.1489  noobj_loss: 0.1070  bbox_loss: 0.0061  cls_loss: 0.0126  \n",
      "\n",
      "epoch:70/100 - Train Loss: 0.2541, Val Loss: 0.2617\n",
      "\n",
      "<<<iteration:[20/263] - total_loss: 0.2688  obj_loss: 0.1686  noobj_loss: 0.1146  bbox_loss: 0.0063  cls_loss: 0.0115  \n",
      "<<<iteration:[40/263] - total_loss: 0.2544  obj_loss: 0.1601  noobj_loss: 0.1089  bbox_loss: 0.0056  cls_loss: 0.0119  \n",
      "<<<iteration:[60/263] - total_loss: 0.2473  obj_loss: 0.1520  noobj_loss: 0.1112  bbox_loss: 0.0057  cls_loss: 0.0109  \n",
      "<<<iteration:[80/263] - total_loss: 0.2477  obj_loss: 0.1606  noobj_loss: 0.0984  bbox_loss: 0.0057  cls_loss: 0.0096  \n",
      "<<<iteration:[100/263] - total_loss: 0.2642  obj_loss: 0.1679  noobj_loss: 0.1073  bbox_loss: 0.0063  cls_loss: 0.0113  \n",
      "<<<iteration:[120/263] - total_loss: 0.2559  obj_loss: 0.1598  noobj_loss: 0.1132  bbox_loss: 0.0060  cls_loss: 0.0095  \n",
      "<<<iteration:[140/263] - total_loss: 0.2552  obj_loss: 0.1648  noobj_loss: 0.1129  bbox_loss: 0.0050  cls_loss: 0.0088  \n",
      "<<<iteration:[160/263] - total_loss: 0.2703  obj_loss: 0.1762  noobj_loss: 0.1082  bbox_loss: 0.0057  cls_loss: 0.0115  \n",
      "<<<iteration:[180/263] - total_loss: 0.2543  obj_loss: 0.1613  noobj_loss: 0.1098  bbox_loss: 0.0053  cls_loss: 0.0116  \n",
      "<<<iteration:[200/263] - total_loss: 0.2440  obj_loss: 0.1550  noobj_loss: 0.1031  bbox_loss: 0.0052  cls_loss: 0.0113  \n",
      "<<<iteration:[220/263] - total_loss: 0.2469  obj_loss: 0.1529  noobj_loss: 0.1093  bbox_loss: 0.0056  cls_loss: 0.0114  \n",
      "<<<iteration:[240/263] - total_loss: 0.2670  obj_loss: 0.1720  noobj_loss: 0.1114  bbox_loss: 0.0057  cls_loss: 0.0107  \n",
      "<<<iteration:[260/263] - total_loss: 0.2607  obj_loss: 0.1716  noobj_loss: 0.1015  bbox_loss: 0.0053  cls_loss: 0.0117  \n",
      "\n",
      "epoch:71/100 - Train Loss: 0.2560, Val Loss: 0.2599\n",
      "\n",
      "<<<iteration:[20/263] - total_loss: 0.2779  obj_loss: 0.1775  noobj_loss: 0.1137  bbox_loss: 0.0058  cls_loss: 0.0147  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<<<iteration:[40/263] - total_loss: 0.2508  obj_loss: 0.1571  noobj_loss: 0.1040  bbox_loss: 0.0054  cls_loss: 0.0147  \n",
      "<<<iteration:[60/263] - total_loss: 0.2637  obj_loss: 0.1645  noobj_loss: 0.1098  bbox_loss: 0.0059  cls_loss: 0.0147  \n",
      "<<<iteration:[80/263] - total_loss: 0.2536  obj_loss: 0.1626  noobj_loss: 0.1087  bbox_loss: 0.0051  cls_loss: 0.0114  \n",
      "<<<iteration:[100/263] - total_loss: 0.2560  obj_loss: 0.1671  noobj_loss: 0.1034  bbox_loss: 0.0052  cls_loss: 0.0112  \n",
      "<<<iteration:[120/263] - total_loss: 0.2511  obj_loss: 0.1617  noobj_loss: 0.1067  bbox_loss: 0.0051  cls_loss: 0.0107  \n",
      "<<<iteration:[140/263] - total_loss: 0.2440  obj_loss: 0.1522  noobj_loss: 0.1066  bbox_loss: 0.0057  cls_loss: 0.0102  \n",
      "<<<iteration:[160/263] - total_loss: 0.2652  obj_loss: 0.1717  noobj_loss: 0.1107  bbox_loss: 0.0056  cls_loss: 0.0104  \n",
      "<<<iteration:[180/263] - total_loss: 0.2472  obj_loss: 0.1558  noobj_loss: 0.1021  bbox_loss: 0.0061  cls_loss: 0.0099  \n",
      "<<<iteration:[200/263] - total_loss: 0.2450  obj_loss: 0.1559  noobj_loss: 0.1043  bbox_loss: 0.0057  cls_loss: 0.0086  \n",
      "<<<iteration:[220/263] - total_loss: 0.2717  obj_loss: 0.1755  noobj_loss: 0.1138  bbox_loss: 0.0055  cls_loss: 0.0117  \n",
      "<<<iteration:[240/263] - total_loss: 0.2480  obj_loss: 0.1602  noobj_loss: 0.1016  bbox_loss: 0.0053  cls_loss: 0.0106  \n",
      "<<<iteration:[260/263] - total_loss: 0.2549  obj_loss: 0.1571  noobj_loss: 0.1067  bbox_loss: 0.0063  cls_loss: 0.0129  \n",
      "\n",
      "epoch:72/100 - Train Loss: 0.2549, Val Loss: 0.2621\n",
      "\n",
      "<<<iteration:[20/263] - total_loss: 0.2681  obj_loss: 0.1757  noobj_loss: 0.1044  bbox_loss: 0.0059  cls_loss: 0.0105  \n",
      "<<<iteration:[40/263] - total_loss: 0.2540  obj_loss: 0.1621  noobj_loss: 0.1083  bbox_loss: 0.0053  cls_loss: 0.0114  \n",
      "<<<iteration:[60/263] - total_loss: 0.2557  obj_loss: 0.1607  noobj_loss: 0.1120  bbox_loss: 0.0056  cls_loss: 0.0112  \n",
      "<<<iteration:[80/263] - total_loss: 0.2456  obj_loss: 0.1560  noobj_loss: 0.1007  bbox_loss: 0.0057  cls_loss: 0.0106  \n",
      "<<<iteration:[100/263] - total_loss: 0.2548  obj_loss: 0.1564  noobj_loss: 0.1098  bbox_loss: 0.0061  cls_loss: 0.0130  \n",
      "<<<iteration:[120/263] - total_loss: 0.2498  obj_loss: 0.1552  noobj_loss: 0.1139  bbox_loss: 0.0055  cls_loss: 0.0103  \n",
      "<<<iteration:[140/263] - total_loss: 0.2386  obj_loss: 0.1532  noobj_loss: 0.0983  bbox_loss: 0.0052  cls_loss: 0.0104  \n",
      "<<<iteration:[160/263] - total_loss: 0.2665  obj_loss: 0.1698  noobj_loss: 0.1037  bbox_loss: 0.0064  cls_loss: 0.0129  \n",
      "<<<iteration:[180/263] - total_loss: 0.2507  obj_loss: 0.1594  noobj_loss: 0.1098  bbox_loss: 0.0054  cls_loss: 0.0096  \n",
      "<<<iteration:[200/263] - total_loss: 0.2587  obj_loss: 0.1675  noobj_loss: 0.1048  bbox_loss: 0.0054  cls_loss: 0.0119  \n",
      "<<<iteration:[220/263] - total_loss: 0.2513  obj_loss: 0.1593  noobj_loss: 0.1095  bbox_loss: 0.0056  cls_loss: 0.0090  \n",
      "<<<iteration:[240/263] - total_loss: 0.2595  obj_loss: 0.1656  noobj_loss: 0.1137  bbox_loss: 0.0053  cls_loss: 0.0105  \n",
      "<<<iteration:[260/263] - total_loss: 0.2476  obj_loss: 0.1562  noobj_loss: 0.1093  bbox_loss: 0.0053  cls_loss: 0.0101  \n",
      "\n",
      "epoch:73/100 - Train Loss: 0.2528, Val Loss: 0.2563\n",
      "\n",
      "<<<iteration:[20/263] - total_loss: 0.2675  obj_loss: 0.1720  noobj_loss: 0.1153  bbox_loss: 0.0058  cls_loss: 0.0087  \n",
      "<<<iteration:[40/263] - total_loss: 0.2647  obj_loss: 0.1693  noobj_loss: 0.1130  bbox_loss: 0.0055  cls_loss: 0.0115  \n",
      "<<<iteration:[60/263] - total_loss: 0.2540  obj_loss: 0.1659  noobj_loss: 0.1065  bbox_loss: 0.0048  cls_loss: 0.0108  \n",
      "<<<iteration:[80/263] - total_loss: 0.2568  obj_loss: 0.1671  noobj_loss: 0.1079  bbox_loss: 0.0053  cls_loss: 0.0090  \n",
      "<<<iteration:[100/263] - total_loss: 0.2484  obj_loss: 0.1603  noobj_loss: 0.1077  bbox_loss: 0.0051  cls_loss: 0.0089  \n",
      "<<<iteration:[120/263] - total_loss: 0.2597  obj_loss: 0.1716  noobj_loss: 0.1088  bbox_loss: 0.0048  cls_loss: 0.0096  \n",
      "<<<iteration:[140/263] - total_loss: 0.2447  obj_loss: 0.1543  noobj_loss: 0.1069  bbox_loss: 0.0053  cls_loss: 0.0104  \n",
      "<<<iteration:[160/263] - total_loss: 0.2650  obj_loss: 0.1702  noobj_loss: 0.1097  bbox_loss: 0.0058  cls_loss: 0.0107  \n",
      "<<<iteration:[180/263] - total_loss: 0.2578  obj_loss: 0.1652  noobj_loss: 0.1039  bbox_loss: 0.0058  cls_loss: 0.0118  \n",
      "<<<iteration:[200/263] - total_loss: 0.2635  obj_loss: 0.1681  noobj_loss: 0.1144  bbox_loss: 0.0055  cls_loss: 0.0106  \n",
      "<<<iteration:[220/263] - total_loss: 0.2468  obj_loss: 0.1530  noobj_loss: 0.1127  bbox_loss: 0.0055  cls_loss: 0.0098  \n",
      "<<<iteration:[240/263] - total_loss: 0.2550  obj_loss: 0.1595  noobj_loss: 0.1158  bbox_loss: 0.0055  cls_loss: 0.0101  \n",
      "<<<iteration:[260/263] - total_loss: 0.2512  obj_loss: 0.1577  noobj_loss: 0.1094  bbox_loss: 0.0054  cls_loss: 0.0119  \n",
      "\n",
      "epoch:74/100 - Train Loss: 0.2557, Val Loss: 0.2612\n",
      "\n",
      "<<<iteration:[20/263] - total_loss: 0.2732  obj_loss: 0.1714  noobj_loss: 0.1146  bbox_loss: 0.0062  cls_loss: 0.0133  \n",
      "<<<iteration:[40/263] - total_loss: 0.2537  obj_loss: 0.1639  noobj_loss: 0.1115  bbox_loss: 0.0051  cls_loss: 0.0087  \n",
      "<<<iteration:[60/263] - total_loss: 0.2498  obj_loss: 0.1569  noobj_loss: 0.1098  bbox_loss: 0.0049  cls_loss: 0.0134  \n",
      "<<<iteration:[80/263] - total_loss: 0.2419  obj_loss: 0.1492  noobj_loss: 0.1040  bbox_loss: 0.0061  cls_loss: 0.0099  \n",
      "<<<iteration:[100/263] - total_loss: 0.2460  obj_loss: 0.1584  noobj_loss: 0.1051  bbox_loss: 0.0051  cls_loss: 0.0094  \n",
      "<<<iteration:[120/263] - total_loss: 0.2516  obj_loss: 0.1614  noobj_loss: 0.1070  bbox_loss: 0.0056  cls_loss: 0.0087  \n",
      "<<<iteration:[140/263] - total_loss: 0.2543  obj_loss: 0.1570  noobj_loss: 0.1140  bbox_loss: 0.0059  cls_loss: 0.0110  \n",
      "<<<iteration:[160/263] - total_loss: 0.2350  obj_loss: 0.1431  noobj_loss: 0.1057  bbox_loss: 0.0057  cls_loss: 0.0107  \n",
      "<<<iteration:[180/263] - total_loss: 0.2450  obj_loss: 0.1545  noobj_loss: 0.1042  bbox_loss: 0.0055  cls_loss: 0.0109  \n",
      "<<<iteration:[200/263] - total_loss: 0.2420  obj_loss: 0.1515  noobj_loss: 0.1072  bbox_loss: 0.0054  cls_loss: 0.0099  \n",
      "<<<iteration:[220/263] - total_loss: 0.2613  obj_loss: 0.1730  noobj_loss: 0.1036  bbox_loss: 0.0054  cls_loss: 0.0095  \n",
      "<<<iteration:[240/263] - total_loss: 0.2538  obj_loss: 0.1572  noobj_loss: 0.1072  bbox_loss: 0.0061  cls_loss: 0.0128  \n",
      "<<<iteration:[260/263] - total_loss: 0.2398  obj_loss: 0.1523  noobj_loss: 0.1041  bbox_loss: 0.0051  cls_loss: 0.0100  \n",
      "\n",
      "epoch:75/100 - Train Loss: 0.2490, Val Loss: 0.2630\n",
      "\n",
      "<<<iteration:[20/263] - total_loss: 0.2600  obj_loss: 0.1666  noobj_loss: 0.1133  bbox_loss: 0.0057  cls_loss: 0.0082  \n",
      "<<<iteration:[40/263] - total_loss: 0.2487  obj_loss: 0.1573  noobj_loss: 0.1063  bbox_loss: 0.0054  cls_loss: 0.0112  \n",
      "<<<iteration:[60/263] - total_loss: 0.2557  obj_loss: 0.1666  noobj_loss: 0.1086  bbox_loss: 0.0051  cls_loss: 0.0093  \n",
      "<<<iteration:[80/263] - total_loss: 0.2407  obj_loss: 0.1459  noobj_loss: 0.1037  bbox_loss: 0.0059  cls_loss: 0.0135  \n",
      "<<<iteration:[100/263] - total_loss: 0.2501  obj_loss: 0.1582  noobj_loss: 0.1066  bbox_loss: 0.0054  cls_loss: 0.0118  \n",
      "<<<iteration:[120/263] - total_loss: 0.2531  obj_loss: 0.1590  noobj_loss: 0.1094  bbox_loss: 0.0060  cls_loss: 0.0093  \n",
      "<<<iteration:[140/263] - total_loss: 0.2654  obj_loss: 0.1759  noobj_loss: 0.1072  bbox_loss: 0.0054  cls_loss: 0.0089  \n",
      "<<<iteration:[160/263] - total_loss: 0.2489  obj_loss: 0.1529  noobj_loss: 0.1101  bbox_loss: 0.0060  cls_loss: 0.0111  \n",
      "<<<iteration:[180/263] - total_loss: 0.2329  obj_loss: 0.1419  noobj_loss: 0.1071  bbox_loss: 0.0053  cls_loss: 0.0111  \n",
      "<<<iteration:[200/263] - total_loss: 0.2490  obj_loss: 0.1586  noobj_loss: 0.1030  bbox_loss: 0.0060  cls_loss: 0.0088  \n",
      "<<<iteration:[220/263] - total_loss: 0.2526  obj_loss: 0.1625  noobj_loss: 0.1100  bbox_loss: 0.0052  cls_loss: 0.0093  \n",
      "<<<iteration:[240/263] - total_loss: 0.2536  obj_loss: 0.1635  noobj_loss: 0.1092  bbox_loss: 0.0051  cls_loss: 0.0101  \n",
      "<<<iteration:[260/263] - total_loss: 0.2635  obj_loss: 0.1676  noobj_loss: 0.1175  bbox_loss: 0.0053  cls_loss: 0.0106  \n",
      "\n",
      "epoch:76/100 - Train Loss: 0.2507, Val Loss: 0.2573\n",
      "\n",
      "<<<iteration:[20/263] - total_loss: 0.2583  obj_loss: 0.1606  noobj_loss: 0.1116  bbox_loss: 0.0060  cls_loss: 0.0116  \n",
      "<<<iteration:[40/263] - total_loss: 0.2658  obj_loss: 0.1713  noobj_loss: 0.1114  bbox_loss: 0.0054  cls_loss: 0.0117  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<<<iteration:[60/263] - total_loss: 0.2545  obj_loss: 0.1627  noobj_loss: 0.1060  bbox_loss: 0.0054  cls_loss: 0.0117  \n",
      "<<<iteration:[80/263] - total_loss: 0.2628  obj_loss: 0.1674  noobj_loss: 0.1159  bbox_loss: 0.0052  cls_loss: 0.0113  \n",
      "<<<iteration:[100/263] - total_loss: 0.2584  obj_loss: 0.1674  noobj_loss: 0.1150  bbox_loss: 0.0049  cls_loss: 0.0090  \n",
      "<<<iteration:[120/263] - total_loss: 0.2418  obj_loss: 0.1490  noobj_loss: 0.1100  bbox_loss: 0.0056  cls_loss: 0.0098  \n",
      "<<<iteration:[140/263] - total_loss: 0.2534  obj_loss: 0.1514  noobj_loss: 0.1066  bbox_loss: 0.0076  cls_loss: 0.0109  \n",
      "<<<iteration:[160/263] - total_loss: 0.2547  obj_loss: 0.1657  noobj_loss: 0.0998  bbox_loss: 0.0058  cls_loss: 0.0098  \n",
      "<<<iteration:[180/263] - total_loss: 0.2551  obj_loss: 0.1649  noobj_loss: 0.1054  bbox_loss: 0.0055  cls_loss: 0.0100  \n",
      "<<<iteration:[200/263] - total_loss: 0.2460  obj_loss: 0.1541  noobj_loss: 0.1111  bbox_loss: 0.0052  cls_loss: 0.0102  \n",
      "<<<iteration:[220/263] - total_loss: 0.2421  obj_loss: 0.1508  noobj_loss: 0.1079  bbox_loss: 0.0055  cls_loss: 0.0100  \n",
      "<<<iteration:[240/263] - total_loss: 0.2577  obj_loss: 0.1624  noobj_loss: 0.1160  bbox_loss: 0.0053  cls_loss: 0.0106  \n",
      "<<<iteration:[260/263] - total_loss: 0.2530  obj_loss: 0.1626  noobj_loss: 0.1084  bbox_loss: 0.0053  cls_loss: 0.0099  \n",
      "\n",
      "epoch:77/100 - Train Loss: 0.2528, Val Loss: 0.2571\n",
      "\n",
      "<<<iteration:[20/263] - total_loss: 0.2638  obj_loss: 0.1667  noobj_loss: 0.1125  bbox_loss: 0.0059  cls_loss: 0.0114  \n",
      "<<<iteration:[40/263] - total_loss: 0.2496  obj_loss: 0.1560  noobj_loss: 0.1154  bbox_loss: 0.0056  cls_loss: 0.0080  \n",
      "<<<iteration:[60/263] - total_loss: 0.2437  obj_loss: 0.1530  noobj_loss: 0.1102  bbox_loss: 0.0054  cls_loss: 0.0085  \n",
      "<<<iteration:[80/263] - total_loss: 0.2545  obj_loss: 0.1651  noobj_loss: 0.1092  bbox_loss: 0.0052  cls_loss: 0.0088  \n",
      "<<<iteration:[100/263] - total_loss: 0.2565  obj_loss: 0.1647  noobj_loss: 0.1111  bbox_loss: 0.0050  cls_loss: 0.0110  \n",
      "<<<iteration:[120/263] - total_loss: 0.2607  obj_loss: 0.1679  noobj_loss: 0.1134  bbox_loss: 0.0051  cls_loss: 0.0107  \n",
      "<<<iteration:[140/263] - total_loss: 0.2442  obj_loss: 0.1480  noobj_loss: 0.1141  bbox_loss: 0.0058  cls_loss: 0.0099  \n",
      "<<<iteration:[160/263] - total_loss: 0.2444  obj_loss: 0.1509  noobj_loss: 0.1092  bbox_loss: 0.0057  cls_loss: 0.0103  \n",
      "<<<iteration:[180/263] - total_loss: 0.2333  obj_loss: 0.1409  noobj_loss: 0.1076  bbox_loss: 0.0055  cls_loss: 0.0110  \n",
      "<<<iteration:[200/263] - total_loss: 0.2478  obj_loss: 0.1570  noobj_loss: 0.1067  bbox_loss: 0.0053  cls_loss: 0.0108  \n",
      "<<<iteration:[220/263] - total_loss: 0.2737  obj_loss: 0.1772  noobj_loss: 0.1149  bbox_loss: 0.0055  cls_loss: 0.0117  \n",
      "<<<iteration:[240/263] - total_loss: 0.2488  obj_loss: 0.1526  noobj_loss: 0.1058  bbox_loss: 0.0065  cls_loss: 0.0109  \n",
      "<<<iteration:[260/263] - total_loss: 0.2506  obj_loss: 0.1650  noobj_loss: 0.1073  bbox_loss: 0.0049  cls_loss: 0.0074  \n",
      "\n",
      "epoch:78/100 - Train Loss: 0.2508, Val Loss: 0.2654\n",
      "\n",
      "<<<iteration:[20/263] - total_loss: 0.2659  obj_loss: 0.1684  noobj_loss: 0.1173  bbox_loss: 0.0053  cls_loss: 0.0123  \n",
      "<<<iteration:[40/263] - total_loss: 0.2471  obj_loss: 0.1552  noobj_loss: 0.1083  bbox_loss: 0.0056  cls_loss: 0.0096  \n",
      "<<<iteration:[60/263] - total_loss: 0.2537  obj_loss: 0.1669  noobj_loss: 0.1089  bbox_loss: 0.0046  cls_loss: 0.0092  \n",
      "<<<iteration:[80/263] - total_loss: 0.2501  obj_loss: 0.1610  noobj_loss: 0.1075  bbox_loss: 0.0052  cls_loss: 0.0092  \n",
      "<<<iteration:[100/263] - total_loss: 0.2488  obj_loss: 0.1556  noobj_loss: 0.1152  bbox_loss: 0.0052  cls_loss: 0.0094  \n",
      "<<<iteration:[120/263] - total_loss: 0.2538  obj_loss: 0.1623  noobj_loss: 0.1090  bbox_loss: 0.0054  cls_loss: 0.0099  \n",
      "<<<iteration:[140/263] - total_loss: 0.2510  obj_loss: 0.1630  noobj_loss: 0.1055  bbox_loss: 0.0053  cls_loss: 0.0090  \n",
      "<<<iteration:[160/263] - total_loss: 0.2635  obj_loss: 0.1697  noobj_loss: 0.1123  bbox_loss: 0.0054  cls_loss: 0.0107  \n",
      "<<<iteration:[180/263] - total_loss: 0.2544  obj_loss: 0.1654  noobj_loss: 0.1043  bbox_loss: 0.0054  cls_loss: 0.0097  \n",
      "<<<iteration:[200/263] - total_loss: 0.2539  obj_loss: 0.1602  noobj_loss: 0.1121  bbox_loss: 0.0053  cls_loss: 0.0111  \n",
      "<<<iteration:[220/263] - total_loss: 0.2480  obj_loss: 0.1567  noobj_loss: 0.1128  bbox_loss: 0.0052  cls_loss: 0.0087  \n",
      "<<<iteration:[240/263] - total_loss: 0.2456  obj_loss: 0.1486  noobj_loss: 0.1123  bbox_loss: 0.0063  cls_loss: 0.0096  \n",
      "<<<iteration:[260/263] - total_loss: 0.2444  obj_loss: 0.1551  noobj_loss: 0.1072  bbox_loss: 0.0054  cls_loss: 0.0089  \n",
      "\n",
      "epoch:79/100 - Train Loss: 0.2510, Val Loss: 0.2593\n",
      "\n",
      "<<<iteration:[20/263] - total_loss: 0.2766  obj_loss: 0.1795  noobj_loss: 0.1161  bbox_loss: 0.0056  cls_loss: 0.0108  \n",
      "<<<iteration:[40/263] - total_loss: 0.2396  obj_loss: 0.1446  noobj_loss: 0.1155  bbox_loss: 0.0052  cls_loss: 0.0111  \n",
      "<<<iteration:[60/263] - total_loss: 0.2476  obj_loss: 0.1542  noobj_loss: 0.1144  bbox_loss: 0.0052  cls_loss: 0.0102  \n",
      "<<<iteration:[80/263] - total_loss: 0.2599  obj_loss: 0.1632  noobj_loss: 0.1114  bbox_loss: 0.0059  cls_loss: 0.0115  \n",
      "<<<iteration:[100/263] - total_loss: 0.2667  obj_loss: 0.1761  noobj_loss: 0.1073  bbox_loss: 0.0053  cls_loss: 0.0103  \n",
      "<<<iteration:[120/263] - total_loss: 0.2635  obj_loss: 0.1683  noobj_loss: 0.1142  bbox_loss: 0.0053  cls_loss: 0.0115  \n",
      "<<<iteration:[140/263] - total_loss: 0.2503  obj_loss: 0.1569  noobj_loss: 0.1091  bbox_loss: 0.0059  cls_loss: 0.0092  \n",
      "<<<iteration:[160/263] - total_loss: 0.2417  obj_loss: 0.1522  noobj_loss: 0.1093  bbox_loss: 0.0051  cls_loss: 0.0092  \n",
      "<<<iteration:[180/263] - total_loss: 0.2368  obj_loss: 0.1486  noobj_loss: 0.1093  bbox_loss: 0.0050  cls_loss: 0.0087  \n",
      "<<<iteration:[200/263] - total_loss: 0.2454  obj_loss: 0.1550  noobj_loss: 0.1068  bbox_loss: 0.0054  cls_loss: 0.0101  \n",
      "<<<iteration:[220/263] - total_loss: 0.2507  obj_loss: 0.1621  noobj_loss: 0.1147  bbox_loss: 0.0045  cls_loss: 0.0088  \n",
      "<<<iteration:[240/263] - total_loss: 0.2523  obj_loss: 0.1588  noobj_loss: 0.1103  bbox_loss: 0.0055  cls_loss: 0.0110  \n",
      "<<<iteration:[260/263] - total_loss: 0.2560  obj_loss: 0.1573  noobj_loss: 0.1184  bbox_loss: 0.0052  cls_loss: 0.0136  \n",
      "\n",
      "epoch:80/100 - Train Loss: 0.2520, Val Loss: 0.2670\n",
      "\n",
      "<<<iteration:[20/263] - total_loss: 0.2550  obj_loss: 0.1597  noobj_loss: 0.1157  bbox_loss: 0.0053  cls_loss: 0.0108  \n",
      "<<<iteration:[40/263] - total_loss: 0.2670  obj_loss: 0.1724  noobj_loss: 0.1137  bbox_loss: 0.0053  cls_loss: 0.0112  \n",
      "<<<iteration:[60/263] - total_loss: 0.2558  obj_loss: 0.1674  noobj_loss: 0.1087  bbox_loss: 0.0051  cls_loss: 0.0084  \n",
      "<<<iteration:[80/263] - total_loss: 0.2555  obj_loss: 0.1654  noobj_loss: 0.1053  bbox_loss: 0.0052  cls_loss: 0.0116  \n",
      "<<<iteration:[100/263] - total_loss: 0.2422  obj_loss: 0.1540  noobj_loss: 0.1085  bbox_loss: 0.0051  cls_loss: 0.0084  \n",
      "<<<iteration:[120/263] - total_loss: 0.2543  obj_loss: 0.1651  noobj_loss: 0.1140  bbox_loss: 0.0045  cls_loss: 0.0095  \n",
      "<<<iteration:[140/263] - total_loss: 0.2532  obj_loss: 0.1575  noobj_loss: 0.1131  bbox_loss: 0.0058  cls_loss: 0.0103  \n",
      "<<<iteration:[160/263] - total_loss: 0.2665  obj_loss: 0.1763  noobj_loss: 0.1113  bbox_loss: 0.0048  cls_loss: 0.0107  \n",
      "<<<iteration:[180/263] - total_loss: 0.2674  obj_loss: 0.1764  noobj_loss: 0.1146  bbox_loss: 0.0049  cls_loss: 0.0091  \n",
      "<<<iteration:[200/263] - total_loss: 0.2472  obj_loss: 0.1517  noobj_loss: 0.1138  bbox_loss: 0.0056  cls_loss: 0.0108  \n",
      "<<<iteration:[220/263] - total_loss: 0.2486  obj_loss: 0.1491  noobj_loss: 0.1165  bbox_loss: 0.0058  cls_loss: 0.0124  \n",
      "<<<iteration:[240/263] - total_loss: 0.2544  obj_loss: 0.1670  noobj_loss: 0.1077  bbox_loss: 0.0050  cls_loss: 0.0086  \n",
      "<<<iteration:[260/263] - total_loss: 0.2461  obj_loss: 0.1503  noobj_loss: 0.1131  bbox_loss: 0.0058  cls_loss: 0.0104  \n",
      "\n",
      "epoch:81/100 - Train Loss: 0.2542, Val Loss: 0.2576\n",
      "\n",
      "<<<iteration:[20/263] - total_loss: 0.2575  obj_loss: 0.1615  noobj_loss: 0.1165  bbox_loss: 0.0056  cls_loss: 0.0099  \n",
      "<<<iteration:[40/263] - total_loss: 0.2575  obj_loss: 0.1628  noobj_loss: 0.1166  bbox_loss: 0.0053  cls_loss: 0.0097  \n",
      "<<<iteration:[60/263] - total_loss: 0.2704  obj_loss: 0.1806  noobj_loss: 0.1149  bbox_loss: 0.0047  cls_loss: 0.0090  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<<<iteration:[80/263] - total_loss: 0.2538  obj_loss: 0.1616  noobj_loss: 0.1153  bbox_loss: 0.0051  cls_loss: 0.0091  \n",
      "<<<iteration:[100/263] - total_loss: 0.2570  obj_loss: 0.1649  noobj_loss: 0.1134  bbox_loss: 0.0052  cls_loss: 0.0096  \n",
      "<<<iteration:[120/263] - total_loss: 0.2568  obj_loss: 0.1684  noobj_loss: 0.1079  bbox_loss: 0.0052  cls_loss: 0.0084  \n",
      "<<<iteration:[140/263] - total_loss: 0.2560  obj_loss: 0.1650  noobj_loss: 0.1145  bbox_loss: 0.0049  cls_loss: 0.0094  \n",
      "<<<iteration:[160/263] - total_loss: 0.2568  obj_loss: 0.1664  noobj_loss: 0.1151  bbox_loss: 0.0044  cls_loss: 0.0108  \n",
      "<<<iteration:[180/263] - total_loss: 0.2459  obj_loss: 0.1565  noobj_loss: 0.1110  bbox_loss: 0.0052  cls_loss: 0.0079  \n",
      "<<<iteration:[200/263] - total_loss: 0.2650  obj_loss: 0.1737  noobj_loss: 0.1146  bbox_loss: 0.0052  cls_loss: 0.0081  \n",
      "<<<iteration:[220/263] - total_loss: 0.2488  obj_loss: 0.1589  noobj_loss: 0.1136  bbox_loss: 0.0049  cls_loss: 0.0087  \n",
      "<<<iteration:[240/263] - total_loss: 0.2497  obj_loss: 0.1542  noobj_loss: 0.1137  bbox_loss: 0.0056  cls_loss: 0.0105  \n",
      "<<<iteration:[260/263] - total_loss: 0.2529  obj_loss: 0.1640  noobj_loss: 0.1121  bbox_loss: 0.0049  cls_loss: 0.0082  \n",
      "\n",
      "epoch:82/100 - Train Loss: 0.2548, Val Loss: 0.2621\n",
      "\n",
      "<<<iteration:[20/263] - total_loss: 0.2685  obj_loss: 0.1715  noobj_loss: 0.1211  bbox_loss: 0.0055  cls_loss: 0.0090  \n",
      "<<<iteration:[40/263] - total_loss: 0.2566  obj_loss: 0.1614  noobj_loss: 0.1197  bbox_loss: 0.0050  cls_loss: 0.0105  \n",
      "<<<iteration:[60/263] - total_loss: 0.2467  obj_loss: 0.1546  noobj_loss: 0.1145  bbox_loss: 0.0051  cls_loss: 0.0093  \n",
      "<<<iteration:[80/263] - total_loss: 0.2568  obj_loss: 0.1613  noobj_loss: 0.1176  bbox_loss: 0.0052  cls_loss: 0.0106  \n",
      "<<<iteration:[100/263] - total_loss: 0.2522  obj_loss: 0.1591  noobj_loss: 0.1037  bbox_loss: 0.0058  cls_loss: 0.0123  \n",
      "<<<iteration:[120/263] - total_loss: 0.2688  obj_loss: 0.1770  noobj_loss: 0.1140  bbox_loss: 0.0051  cls_loss: 0.0091  \n",
      "<<<iteration:[140/263] - total_loss: 0.2376  obj_loss: 0.1453  noobj_loss: 0.1115  bbox_loss: 0.0056  cls_loss: 0.0087  \n",
      "<<<iteration:[160/263] - total_loss: 0.2517  obj_loss: 0.1554  noobj_loss: 0.1121  bbox_loss: 0.0056  cls_loss: 0.0123  \n",
      "<<<iteration:[180/263] - total_loss: 0.2657  obj_loss: 0.1744  noobj_loss: 0.1145  bbox_loss: 0.0050  cls_loss: 0.0092  \n",
      "<<<iteration:[200/263] - total_loss: 0.2397  obj_loss: 0.1518  noobj_loss: 0.1141  bbox_loss: 0.0047  cls_loss: 0.0074  \n",
      "<<<iteration:[220/263] - total_loss: 0.2479  obj_loss: 0.1567  noobj_loss: 0.1143  bbox_loss: 0.0049  cls_loss: 0.0095  \n",
      "<<<iteration:[240/263] - total_loss: 0.2515  obj_loss: 0.1608  noobj_loss: 0.1124  bbox_loss: 0.0050  cls_loss: 0.0095  \n",
      "<<<iteration:[260/263] - total_loss: 0.2565  obj_loss: 0.1661  noobj_loss: 0.1122  bbox_loss: 0.0051  cls_loss: 0.0086  \n",
      "\n",
      "epoch:83/100 - Train Loss: 0.2525, Val Loss: 0.2584\n",
      "\n",
      "<<<iteration:[20/263] - total_loss: 0.2773  obj_loss: 0.1769  noobj_loss: 0.1165  bbox_loss: 0.0058  cls_loss: 0.0130  \n",
      "<<<iteration:[40/263] - total_loss: 0.2500  obj_loss: 0.1568  noobj_loss: 0.1151  bbox_loss: 0.0054  cls_loss: 0.0087  \n",
      "<<<iteration:[60/263] - total_loss: 0.2405  obj_loss: 0.1482  noobj_loss: 0.1090  bbox_loss: 0.0059  cls_loss: 0.0083  \n",
      "<<<iteration:[80/263] - total_loss: 0.2548  obj_loss: 0.1604  noobj_loss: 0.1144  bbox_loss: 0.0057  cls_loss: 0.0086  \n",
      "<<<iteration:[100/263] - total_loss: 0.2509  obj_loss: 0.1599  noobj_loss: 0.1148  bbox_loss: 0.0049  cls_loss: 0.0090  \n",
      "<<<iteration:[120/263] - total_loss: 0.2508  obj_loss: 0.1551  noobj_loss: 0.1189  bbox_loss: 0.0056  cls_loss: 0.0084  \n",
      "<<<iteration:[140/263] - total_loss: 0.2555  obj_loss: 0.1598  noobj_loss: 0.1175  bbox_loss: 0.0054  cls_loss: 0.0099  \n",
      "<<<iteration:[160/263] - total_loss: 0.2430  obj_loss: 0.1474  noobj_loss: 0.1129  bbox_loss: 0.0060  cls_loss: 0.0093  \n",
      "<<<iteration:[180/263] - total_loss: 0.2484  obj_loss: 0.1646  noobj_loss: 0.1057  bbox_loss: 0.0046  cls_loss: 0.0081  \n",
      "<<<iteration:[200/263] - total_loss: 0.2684  obj_loss: 0.1742  noobj_loss: 0.1200  bbox_loss: 0.0047  cls_loss: 0.0109  \n",
      "<<<iteration:[220/263] - total_loss: 0.2367  obj_loss: 0.1413  noobj_loss: 0.1211  bbox_loss: 0.0051  cls_loss: 0.0093  \n",
      "<<<iteration:[240/263] - total_loss: 0.2432  obj_loss: 0.1500  noobj_loss: 0.1094  bbox_loss: 0.0054  cls_loss: 0.0113  \n",
      "<<<iteration:[260/263] - total_loss: 0.2455  obj_loss: 0.1547  noobj_loss: 0.1125  bbox_loss: 0.0048  cls_loss: 0.0106  \n",
      "\n",
      "epoch:84/100 - Train Loss: 0.2499, Val Loss: 0.2579\n",
      "\n",
      "<<<iteration:[20/263] - total_loss: 0.2624  obj_loss: 0.1633  noobj_loss: 0.1173  bbox_loss: 0.0060  cls_loss: 0.0103  \n",
      "<<<iteration:[40/263] - total_loss: 0.2516  obj_loss: 0.1632  noobj_loss: 0.1106  bbox_loss: 0.0049  cls_loss: 0.0087  \n",
      "<<<iteration:[60/263] - total_loss: 0.2524  obj_loss: 0.1633  noobj_loss: 0.1166  bbox_loss: 0.0044  cls_loss: 0.0088  \n",
      "<<<iteration:[80/263] - total_loss: 0.2383  obj_loss: 0.1475  noobj_loss: 0.1053  bbox_loss: 0.0055  cls_loss: 0.0105  \n",
      "<<<iteration:[100/263] - total_loss: 0.2648  obj_loss: 0.1691  noobj_loss: 0.1187  bbox_loss: 0.0054  cls_loss: 0.0092  \n",
      "<<<iteration:[120/263] - total_loss: 0.2379  obj_loss: 0.1511  noobj_loss: 0.1092  bbox_loss: 0.0049  cls_loss: 0.0077  \n",
      "<<<iteration:[140/263] - total_loss: 0.2498  obj_loss: 0.1598  noobj_loss: 0.1129  bbox_loss: 0.0048  cls_loss: 0.0096  \n",
      "<<<iteration:[160/263] - total_loss: 0.2353  obj_loss: 0.1464  noobj_loss: 0.1169  bbox_loss: 0.0046  cls_loss: 0.0073  \n",
      "<<<iteration:[180/263] - total_loss: 0.2552  obj_loss: 0.1671  noobj_loss: 0.1111  bbox_loss: 0.0047  cls_loss: 0.0090  \n",
      "<<<iteration:[200/263] - total_loss: 0.2421  obj_loss: 0.1457  noobj_loss: 0.1145  bbox_loss: 0.0052  cls_loss: 0.0132  \n",
      "<<<iteration:[220/263] - total_loss: 0.2636  obj_loss: 0.1676  noobj_loss: 0.1251  bbox_loss: 0.0048  cls_loss: 0.0092  \n",
      "<<<iteration:[240/263] - total_loss: 0.2452  obj_loss: 0.1541  noobj_loss: 0.1116  bbox_loss: 0.0050  cls_loss: 0.0100  \n",
      "<<<iteration:[260/263] - total_loss: 0.2590  obj_loss: 0.1657  noobj_loss: 0.1140  bbox_loss: 0.0056  cls_loss: 0.0084  \n",
      "\n",
      "epoch:85/100 - Train Loss: 0.2496, Val Loss: 0.2582\n",
      "\n",
      "<<<iteration:[20/263] - total_loss: 0.2716  obj_loss: 0.1751  noobj_loss: 0.1240  bbox_loss: 0.0049  cls_loss: 0.0099  \n",
      "<<<iteration:[40/263] - total_loss: 0.2510  obj_loss: 0.1579  noobj_loss: 0.1129  bbox_loss: 0.0048  cls_loss: 0.0125  \n",
      "<<<iteration:[60/263] - total_loss: 0.2576  obj_loss: 0.1643  noobj_loss: 0.1218  bbox_loss: 0.0046  cls_loss: 0.0097  \n",
      "<<<iteration:[80/263] - total_loss: 0.2559  obj_loss: 0.1665  noobj_loss: 0.1139  bbox_loss: 0.0048  cls_loss: 0.0084  \n",
      "<<<iteration:[100/263] - total_loss: 0.2472  obj_loss: 0.1590  noobj_loss: 0.1130  bbox_loss: 0.0045  cls_loss: 0.0091  \n",
      "<<<iteration:[120/263] - total_loss: 0.2622  obj_loss: 0.1685  noobj_loss: 0.1185  bbox_loss: 0.0051  cls_loss: 0.0090  \n",
      "<<<iteration:[140/263] - total_loss: 0.2515  obj_loss: 0.1600  noobj_loss: 0.1131  bbox_loss: 0.0051  cls_loss: 0.0093  \n",
      "<<<iteration:[160/263] - total_loss: 0.2562  obj_loss: 0.1619  noobj_loss: 0.1155  bbox_loss: 0.0051  cls_loss: 0.0112  \n",
      "<<<iteration:[180/263] - total_loss: 0.2359  obj_loss: 0.1445  noobj_loss: 0.1161  bbox_loss: 0.0051  cls_loss: 0.0079  \n",
      "<<<iteration:[200/263] - total_loss: 0.2555  obj_loss: 0.1641  noobj_loss: 0.1130  bbox_loss: 0.0050  cls_loss: 0.0101  \n",
      "<<<iteration:[220/263] - total_loss: 0.2462  obj_loss: 0.1518  noobj_loss: 0.1189  bbox_loss: 0.0052  cls_loss: 0.0090  \n",
      "<<<iteration:[240/263] - total_loss: 0.2589  obj_loss: 0.1660  noobj_loss: 0.1085  bbox_loss: 0.0060  cls_loss: 0.0086  \n",
      "<<<iteration:[260/263] - total_loss: 0.2477  obj_loss: 0.1593  noobj_loss: 0.1098  bbox_loss: 0.0048  cls_loss: 0.0096  \n",
      "\n",
      "epoch:86/100 - Train Loss: 0.2524, Val Loss: 0.2622\n",
      "\n",
      "<<<iteration:[20/263] - total_loss: 0.2641  obj_loss: 0.1642  noobj_loss: 0.1253  bbox_loss: 0.0054  cls_loss: 0.0103  \n",
      "<<<iteration:[40/263] - total_loss: 0.2407  obj_loss: 0.1468  noobj_loss: 0.1122  bbox_loss: 0.0054  cls_loss: 0.0107  \n",
      "<<<iteration:[60/263] - total_loss: 0.2502  obj_loss: 0.1628  noobj_loss: 0.1104  bbox_loss: 0.0048  cls_loss: 0.0083  \n",
      "<<<iteration:[80/263] - total_loss: 0.2504  obj_loss: 0.1584  noobj_loss: 0.1173  bbox_loss: 0.0047  cls_loss: 0.0096  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<<<iteration:[100/263] - total_loss: 0.2546  obj_loss: 0.1594  noobj_loss: 0.1171  bbox_loss: 0.0052  cls_loss: 0.0104  \n",
      "<<<iteration:[120/263] - total_loss: 0.2713  obj_loss: 0.1707  noobj_loss: 0.1206  bbox_loss: 0.0053  cls_loss: 0.0136  \n",
      "<<<iteration:[140/263] - total_loss: 0.2472  obj_loss: 0.1539  noobj_loss: 0.1136  bbox_loss: 0.0051  cls_loss: 0.0111  \n",
      "<<<iteration:[160/263] - total_loss: 0.2504  obj_loss: 0.1611  noobj_loss: 0.1136  bbox_loss: 0.0048  cls_loss: 0.0084  \n",
      "<<<iteration:[180/263] - total_loss: 0.2444  obj_loss: 0.1524  noobj_loss: 0.1165  bbox_loss: 0.0047  cls_loss: 0.0099  \n",
      "<<<iteration:[200/263] - total_loss: 0.2484  obj_loss: 0.1556  noobj_loss: 0.1209  bbox_loss: 0.0049  cls_loss: 0.0080  \n",
      "<<<iteration:[220/263] - total_loss: 0.2597  obj_loss: 0.1682  noobj_loss: 0.1172  bbox_loss: 0.0050  cls_loss: 0.0081  \n",
      "<<<iteration:[240/263] - total_loss: 0.2584  obj_loss: 0.1598  noobj_loss: 0.1190  bbox_loss: 0.0058  cls_loss: 0.0100  \n",
      "<<<iteration:[260/263] - total_loss: 0.2487  obj_loss: 0.1606  noobj_loss: 0.1124  bbox_loss: 0.0046  cls_loss: 0.0091  \n",
      "\n",
      "epoch:87/100 - Train Loss: 0.2518, Val Loss: 0.2587\n",
      "\n",
      "<<<iteration:[20/263] - total_loss: 0.2681  obj_loss: 0.1684  noobj_loss: 0.1250  bbox_loss: 0.0054  cls_loss: 0.0102  \n",
      "<<<iteration:[40/263] - total_loss: 0.2632  obj_loss: 0.1670  noobj_loss: 0.1161  bbox_loss: 0.0054  cls_loss: 0.0111  \n",
      "<<<iteration:[60/263] - total_loss: 0.2436  obj_loss: 0.1524  noobj_loss: 0.1146  bbox_loss: 0.0048  cls_loss: 0.0097  \n",
      "<<<iteration:[80/263] - total_loss: 0.2530  obj_loss: 0.1649  noobj_loss: 0.1172  bbox_loss: 0.0043  cls_loss: 0.0080  \n",
      "<<<iteration:[100/263] - total_loss: 0.2411  obj_loss: 0.1516  noobj_loss: 0.1151  bbox_loss: 0.0049  cls_loss: 0.0076  \n",
      "<<<iteration:[120/263] - total_loss: 0.2453  obj_loss: 0.1542  noobj_loss: 0.1128  bbox_loss: 0.0054  cls_loss: 0.0078  \n",
      "<<<iteration:[140/263] - total_loss: 0.2453  obj_loss: 0.1530  noobj_loss: 0.1157  bbox_loss: 0.0052  cls_loss: 0.0082  \n",
      "<<<iteration:[160/263] - total_loss: 0.2548  obj_loss: 0.1620  noobj_loss: 0.1138  bbox_loss: 0.0051  cls_loss: 0.0105  \n",
      "<<<iteration:[180/263] - total_loss: 0.2351  obj_loss: 0.1429  noobj_loss: 0.1149  bbox_loss: 0.0050  cls_loss: 0.0095  \n",
      "<<<iteration:[200/263] - total_loss: 0.2617  obj_loss: 0.1740  noobj_loss: 0.1166  bbox_loss: 0.0046  cls_loss: 0.0065  \n",
      "<<<iteration:[220/263] - total_loss: 0.2457  obj_loss: 0.1553  noobj_loss: 0.1193  bbox_loss: 0.0045  cls_loss: 0.0081  \n",
      "<<<iteration:[240/263] - total_loss: 0.2415  obj_loss: 0.1498  noobj_loss: 0.1126  bbox_loss: 0.0051  cls_loss: 0.0097  \n",
      "<<<iteration:[260/263] - total_loss: 0.2490  obj_loss: 0.1539  noobj_loss: 0.1216  bbox_loss: 0.0049  cls_loss: 0.0100  \n",
      "\n",
      "epoch:88/100 - Train Loss: 0.2491, Val Loss: 0.2547\n",
      "\n",
      "<<<iteration:[20/263] - total_loss: 0.2704  obj_loss: 0.1759  noobj_loss: 0.1184  bbox_loss: 0.0051  cls_loss: 0.0099  \n",
      "<<<iteration:[40/263] - total_loss: 0.2581  obj_loss: 0.1723  noobj_loss: 0.1127  bbox_loss: 0.0042  cls_loss: 0.0085  \n",
      "<<<iteration:[60/263] - total_loss: 0.2349  obj_loss: 0.1391  noobj_loss: 0.1171  bbox_loss: 0.0053  cls_loss: 0.0108  \n",
      "<<<iteration:[80/263] - total_loss: 0.2599  obj_loss: 0.1699  noobj_loss: 0.1192  bbox_loss: 0.0047  cls_loss: 0.0070  \n",
      "<<<iteration:[100/263] - total_loss: 0.2435  obj_loss: 0.1535  noobj_loss: 0.1138  bbox_loss: 0.0045  cls_loss: 0.0108  \n",
      "<<<iteration:[120/263] - total_loss: 0.2564  obj_loss: 0.1613  noobj_loss: 0.1233  bbox_loss: 0.0048  cls_loss: 0.0095  \n",
      "<<<iteration:[140/263] - total_loss: 0.2537  obj_loss: 0.1626  noobj_loss: 0.1135  bbox_loss: 0.0049  cls_loss: 0.0096  \n",
      "<<<iteration:[160/263] - total_loss: 0.2412  obj_loss: 0.1533  noobj_loss: 0.1101  bbox_loss: 0.0050  cls_loss: 0.0078  \n",
      "<<<iteration:[180/263] - total_loss: 0.2629  obj_loss: 0.1676  noobj_loss: 0.1199  bbox_loss: 0.0051  cls_loss: 0.0097  \n",
      "<<<iteration:[200/263] - total_loss: 0.2456  obj_loss: 0.1540  noobj_loss: 0.1134  bbox_loss: 0.0053  cls_loss: 0.0083  \n",
      "<<<iteration:[220/263] - total_loss: 0.2514  obj_loss: 0.1609  noobj_loss: 0.1135  bbox_loss: 0.0050  cls_loss: 0.0090  \n",
      "<<<iteration:[240/263] - total_loss: 0.2482  obj_loss: 0.1602  noobj_loss: 0.1115  bbox_loss: 0.0047  cls_loss: 0.0087  \n",
      "<<<iteration:[260/263] - total_loss: 0.2396  obj_loss: 0.1508  noobj_loss: 0.1121  bbox_loss: 0.0048  cls_loss: 0.0088  \n",
      "\n",
      "epoch:89/100 - Train Loss: 0.2505, Val Loss: 0.2567\n",
      "\n",
      "<<<iteration:[20/263] - total_loss: 0.2774  obj_loss: 0.1782  noobj_loss: 0.1243  bbox_loss: 0.0057  cls_loss: 0.0088  \n",
      "<<<iteration:[40/263] - total_loss: 0.2654  obj_loss: 0.1727  noobj_loss: 0.1177  bbox_loss: 0.0048  cls_loss: 0.0100  \n",
      "<<<iteration:[60/263] - total_loss: 0.2429  obj_loss: 0.1493  noobj_loss: 0.1171  bbox_loss: 0.0051  cls_loss: 0.0094  \n",
      "<<<iteration:[80/263] - total_loss: 0.2558  obj_loss: 0.1670  noobj_loss: 0.1098  bbox_loss: 0.0049  cls_loss: 0.0095  \n",
      "<<<iteration:[100/263] - total_loss: 0.2536  obj_loss: 0.1639  noobj_loss: 0.1193  bbox_loss: 0.0040  cls_loss: 0.0100  \n",
      "<<<iteration:[120/263] - total_loss: 0.2550  obj_loss: 0.1606  noobj_loss: 0.1217  bbox_loss: 0.0050  cls_loss: 0.0086  \n",
      "<<<iteration:[140/263] - total_loss: 0.2459  obj_loss: 0.1538  noobj_loss: 0.1188  bbox_loss: 0.0050  cls_loss: 0.0078  \n",
      "<<<iteration:[160/263] - total_loss: 0.2319  obj_loss: 0.1412  noobj_loss: 0.1137  bbox_loss: 0.0050  cls_loss: 0.0087  \n",
      "<<<iteration:[180/263] - total_loss: 0.2471  obj_loss: 0.1549  noobj_loss: 0.1176  bbox_loss: 0.0052  cls_loss: 0.0076  \n",
      "<<<iteration:[200/263] - total_loss: 0.2578  obj_loss: 0.1657  noobj_loss: 0.1178  bbox_loss: 0.0049  cls_loss: 0.0088  \n",
      "<<<iteration:[220/263] - total_loss: 0.2543  obj_loss: 0.1594  noobj_loss: 0.1218  bbox_loss: 0.0050  cls_loss: 0.0090  \n",
      "<<<iteration:[240/263] - total_loss: 0.2647  obj_loss: 0.1715  noobj_loss: 0.1182  bbox_loss: 0.0049  cls_loss: 0.0098  \n",
      "<<<iteration:[260/263] - total_loss: 0.2374  obj_loss: 0.1490  noobj_loss: 0.1100  bbox_loss: 0.0049  cls_loss: 0.0088  \n",
      "\n",
      "epoch:90/100 - Train Loss: 0.2520, Val Loss: 0.2543\n",
      "\n",
      "<<<iteration:[20/263] - total_loss: 0.2625  obj_loss: 0.1623  noobj_loss: 0.1290  bbox_loss: 0.0052  cls_loss: 0.0100  \n",
      "<<<iteration:[40/263] - total_loss: 0.2546  obj_loss: 0.1660  noobj_loss: 0.1167  bbox_loss: 0.0042  cls_loss: 0.0094  \n",
      "<<<iteration:[60/263] - total_loss: 0.2511  obj_loss: 0.1575  noobj_loss: 0.1221  bbox_loss: 0.0046  cls_loss: 0.0093  \n",
      "<<<iteration:[80/263] - total_loss: 0.2377  obj_loss: 0.1484  noobj_loss: 0.1190  bbox_loss: 0.0047  cls_loss: 0.0066  \n",
      "<<<iteration:[100/263] - total_loss: 0.2517  obj_loss: 0.1597  noobj_loss: 0.1172  bbox_loss: 0.0048  cls_loss: 0.0095  \n",
      "<<<iteration:[120/263] - total_loss: 0.2616  obj_loss: 0.1666  noobj_loss: 0.1159  bbox_loss: 0.0049  cls_loss: 0.0125  \n",
      "<<<iteration:[140/263] - total_loss: 0.2431  obj_loss: 0.1517  noobj_loss: 0.1151  bbox_loss: 0.0051  cls_loss: 0.0083  \n",
      "<<<iteration:[160/263] - total_loss: 0.2590  obj_loss: 0.1649  noobj_loss: 0.1190  bbox_loss: 0.0048  cls_loss: 0.0108  \n",
      "<<<iteration:[180/263] - total_loss: 0.2663  obj_loss: 0.1736  noobj_loss: 0.1176  bbox_loss: 0.0051  cls_loss: 0.0086  \n",
      "<<<iteration:[200/263] - total_loss: 0.2461  obj_loss: 0.1535  noobj_loss: 0.1121  bbox_loss: 0.0055  cls_loss: 0.0092  \n",
      "<<<iteration:[220/263] - total_loss: 0.2499  obj_loss: 0.1625  noobj_loss: 0.1163  bbox_loss: 0.0044  cls_loss: 0.0073  \n",
      "<<<iteration:[240/263] - total_loss: 0.2445  obj_loss: 0.1520  noobj_loss: 0.1173  bbox_loss: 0.0051  cls_loss: 0.0082  \n",
      "<<<iteration:[260/263] - total_loss: 0.2547  obj_loss: 0.1517  noobj_loss: 0.1231  bbox_loss: 0.0060  cls_loss: 0.0116  \n",
      "\n",
      "epoch:91/100 - Train Loss: 0.2511, Val Loss: 0.2554\n",
      "\n",
      "<<<iteration:[20/263] - total_loss: 0.2623  obj_loss: 0.1663  noobj_loss: 0.1287  bbox_loss: 0.0047  cls_loss: 0.0082  \n",
      "<<<iteration:[40/263] - total_loss: 0.2533  obj_loss: 0.1606  noobj_loss: 0.1152  bbox_loss: 0.0050  cls_loss: 0.0102  \n",
      "<<<iteration:[60/263] - total_loss: 0.2423  obj_loss: 0.1538  noobj_loss: 0.1133  bbox_loss: 0.0046  cls_loss: 0.0086  \n",
      "<<<iteration:[80/263] - total_loss: 0.2437  obj_loss: 0.1517  noobj_loss: 0.1153  bbox_loss: 0.0051  cls_loss: 0.0089  \n",
      "<<<iteration:[100/263] - total_loss: 0.2480  obj_loss: 0.1526  noobj_loss: 0.1214  bbox_loss: 0.0050  cls_loss: 0.0097  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<<<iteration:[120/263] - total_loss: 0.2596  obj_loss: 0.1712  noobj_loss: 0.1060  bbox_loss: 0.0052  cls_loss: 0.0092  \n",
      "<<<iteration:[140/263] - total_loss: 0.2434  obj_loss: 0.1521  noobj_loss: 0.1174  bbox_loss: 0.0048  cls_loss: 0.0086  \n",
      "<<<iteration:[160/263] - total_loss: 0.2426  obj_loss: 0.1505  noobj_loss: 0.1222  bbox_loss: 0.0046  cls_loss: 0.0080  \n",
      "<<<iteration:[180/263] - total_loss: 0.2443  obj_loss: 0.1532  noobj_loss: 0.1134  bbox_loss: 0.0052  cls_loss: 0.0086  \n",
      "<<<iteration:[200/263] - total_loss: 0.2423  obj_loss: 0.1552  noobj_loss: 0.1120  bbox_loss: 0.0045  cls_loss: 0.0087  \n",
      "<<<iteration:[220/263] - total_loss: 0.2443  obj_loss: 0.1562  noobj_loss: 0.1192  bbox_loss: 0.0042  cls_loss: 0.0078  \n",
      "<<<iteration:[240/263] - total_loss: 0.2327  obj_loss: 0.1435  noobj_loss: 0.1102  bbox_loss: 0.0049  cls_loss: 0.0095  \n",
      "<<<iteration:[260/263] - total_loss: 0.2432  obj_loss: 0.1499  noobj_loss: 0.1192  bbox_loss: 0.0049  cls_loss: 0.0092  \n",
      "\n",
      "epoch:92/100 - Train Loss: 0.2454, Val Loss: 0.2607\n",
      "\n",
      "<<<iteration:[20/263] - total_loss: 0.2564  obj_loss: 0.1650  noobj_loss: 0.1183  bbox_loss: 0.0047  cls_loss: 0.0086  \n",
      "<<<iteration:[40/263] - total_loss: 0.2425  obj_loss: 0.1522  noobj_loss: 0.1118  bbox_loss: 0.0052  cls_loss: 0.0086  \n",
      "<<<iteration:[60/263] - total_loss: 0.2662  obj_loss: 0.1711  noobj_loss: 0.1234  bbox_loss: 0.0048  cls_loss: 0.0097  \n",
      "<<<iteration:[80/263] - total_loss: 0.2553  obj_loss: 0.1640  noobj_loss: 0.1148  bbox_loss: 0.0048  cls_loss: 0.0100  \n",
      "<<<iteration:[100/263] - total_loss: 0.2599  obj_loss: 0.1689  noobj_loss: 0.1154  bbox_loss: 0.0048  cls_loss: 0.0094  \n",
      "<<<iteration:[120/263] - total_loss: 0.2475  obj_loss: 0.1567  noobj_loss: 0.1150  bbox_loss: 0.0050  cls_loss: 0.0082  \n",
      "<<<iteration:[140/263] - total_loss: 0.2443  obj_loss: 0.1542  noobj_loss: 0.1138  bbox_loss: 0.0050  cls_loss: 0.0083  \n",
      "<<<iteration:[160/263] - total_loss: 0.2505  obj_loss: 0.1600  noobj_loss: 0.1154  bbox_loss: 0.0049  cls_loss: 0.0081  \n",
      "<<<iteration:[180/263] - total_loss: 0.2580  obj_loss: 0.1645  noobj_loss: 0.1239  bbox_loss: 0.0043  cls_loss: 0.0101  \n",
      "<<<iteration:[200/263] - total_loss: 0.2405  obj_loss: 0.1530  noobj_loss: 0.1138  bbox_loss: 0.0046  cls_loss: 0.0075  \n",
      "<<<iteration:[220/263] - total_loss: 0.2634  obj_loss: 0.1710  noobj_loss: 0.1248  bbox_loss: 0.0044  cls_loss: 0.0080  \n",
      "<<<iteration:[240/263] - total_loss: 0.2382  obj_loss: 0.1473  noobj_loss: 0.1158  bbox_loss: 0.0046  cls_loss: 0.0102  \n",
      "<<<iteration:[260/263] - total_loss: 0.2543  obj_loss: 0.1635  noobj_loss: 0.1195  bbox_loss: 0.0044  cls_loss: 0.0089  \n",
      "\n",
      "epoch:93/100 - Train Loss: 0.2510, Val Loss: 0.2578\n",
      "\n",
      "<<<iteration:[20/263] - total_loss: 0.2700  obj_loss: 0.1732  noobj_loss: 0.1234  bbox_loss: 0.0051  cls_loss: 0.0094  \n",
      "<<<iteration:[40/263] - total_loss: 0.2497  obj_loss: 0.1558  noobj_loss: 0.1173  bbox_loss: 0.0052  cls_loss: 0.0094  \n",
      "<<<iteration:[60/263] - total_loss: 0.2319  obj_loss: 0.1476  noobj_loss: 0.1128  bbox_loss: 0.0042  cls_loss: 0.0070  \n",
      "<<<iteration:[80/263] - total_loss: 0.2457  obj_loss: 0.1535  noobj_loss: 0.1178  bbox_loss: 0.0050  cls_loss: 0.0082  \n",
      "<<<iteration:[100/263] - total_loss: 0.2514  obj_loss: 0.1620  noobj_loss: 0.1187  bbox_loss: 0.0047  cls_loss: 0.0064  \n",
      "<<<iteration:[120/263] - total_loss: 0.2513  obj_loss: 0.1610  noobj_loss: 0.1131  bbox_loss: 0.0050  cls_loss: 0.0087  \n",
      "<<<iteration:[140/263] - total_loss: 0.2421  obj_loss: 0.1495  noobj_loss: 0.1217  bbox_loss: 0.0046  cls_loss: 0.0086  \n",
      "<<<iteration:[160/263] - total_loss: 0.2532  obj_loss: 0.1608  noobj_loss: 0.1178  bbox_loss: 0.0051  cls_loss: 0.0083  \n",
      "<<<iteration:[180/263] - total_loss: 0.2455  obj_loss: 0.1492  noobj_loss: 0.1189  bbox_loss: 0.0054  cls_loss: 0.0099  \n",
      "<<<iteration:[200/263] - total_loss: 0.2465  obj_loss: 0.1559  noobj_loss: 0.1162  bbox_loss: 0.0047  cls_loss: 0.0088  \n",
      "<<<iteration:[220/263] - total_loss: 0.2453  obj_loss: 0.1553  noobj_loss: 0.1154  bbox_loss: 0.0046  cls_loss: 0.0091  \n",
      "<<<iteration:[240/263] - total_loss: 0.2465  obj_loss: 0.1502  noobj_loss: 0.1170  bbox_loss: 0.0056  cls_loss: 0.0098  \n",
      "<<<iteration:[260/263] - total_loss: 0.2556  obj_loss: 0.1606  noobj_loss: 0.1267  bbox_loss: 0.0046  cls_loss: 0.0087  \n",
      "\n",
      "epoch:94/100 - Train Loss: 0.2475, Val Loss: 0.2562\n",
      "\n",
      "<<<iteration:[20/263] - total_loss: 0.2563  obj_loss: 0.1629  noobj_loss: 0.1202  bbox_loss: 0.0049  cls_loss: 0.0088  \n",
      "<<<iteration:[40/263] - total_loss: 0.2490  obj_loss: 0.1577  noobj_loss: 0.1146  bbox_loss: 0.0050  cls_loss: 0.0091  \n",
      "<<<iteration:[60/263] - total_loss: 0.2536  obj_loss: 0.1638  noobj_loss: 0.1140  bbox_loss: 0.0048  cls_loss: 0.0086  \n",
      "<<<iteration:[80/263] - total_loss: 0.2622  obj_loss: 0.1646  noobj_loss: 0.1301  bbox_loss: 0.0047  cls_loss: 0.0091  \n",
      "<<<iteration:[100/263] - total_loss: 0.2385  obj_loss: 0.1493  noobj_loss: 0.1170  bbox_loss: 0.0046  cls_loss: 0.0078  \n",
      "<<<iteration:[120/263] - total_loss: 0.2492  obj_loss: 0.1547  noobj_loss: 0.1153  bbox_loss: 0.0054  cls_loss: 0.0099  \n",
      "<<<iteration:[140/263] - total_loss: 0.2485  obj_loss: 0.1575  noobj_loss: 0.1206  bbox_loss: 0.0044  cls_loss: 0.0087  \n",
      "<<<iteration:[160/263] - total_loss: 0.2434  obj_loss: 0.1515  noobj_loss: 0.1168  bbox_loss: 0.0050  cls_loss: 0.0086  \n",
      "<<<iteration:[180/263] - total_loss: 0.2538  obj_loss: 0.1632  noobj_loss: 0.1218  bbox_loss: 0.0043  cls_loss: 0.0081  \n",
      "<<<iteration:[200/263] - total_loss: 0.2496  obj_loss: 0.1580  noobj_loss: 0.1180  bbox_loss: 0.0049  cls_loss: 0.0083  \n",
      "<<<iteration:[220/263] - total_loss: 0.2686  obj_loss: 0.1801  noobj_loss: 0.1154  bbox_loss: 0.0047  cls_loss: 0.0073  \n",
      "<<<iteration:[240/263] - total_loss: 0.2380  obj_loss: 0.1468  noobj_loss: 0.1177  bbox_loss: 0.0047  cls_loss: 0.0089  \n",
      "<<<iteration:[260/263] - total_loss: 0.2482  obj_loss: 0.1596  noobj_loss: 0.1141  bbox_loss: 0.0046  cls_loss: 0.0089  \n",
      "\n",
      "epoch:95/100 - Train Loss: 0.2495, Val Loss: 0.2546\n",
      "\n",
      "<<<iteration:[20/263] - total_loss: 0.2602  obj_loss: 0.1658  noobj_loss: 0.1182  bbox_loss: 0.0052  cls_loss: 0.0091  \n",
      "<<<iteration:[40/263] - total_loss: 0.2417  obj_loss: 0.1463  noobj_loss: 0.1257  bbox_loss: 0.0048  cls_loss: 0.0087  \n",
      "<<<iteration:[60/263] - total_loss: 0.2277  obj_loss: 0.1408  noobj_loss: 0.1135  bbox_loss: 0.0044  cls_loss: 0.0080  \n",
      "<<<iteration:[80/263] - total_loss: 0.2457  obj_loss: 0.1548  noobj_loss: 0.1138  bbox_loss: 0.0050  cls_loss: 0.0088  \n",
      "<<<iteration:[100/263] - total_loss: 0.2562  obj_loss: 0.1662  noobj_loss: 0.1162  bbox_loss: 0.0049  cls_loss: 0.0077  \n",
      "<<<iteration:[120/263] - total_loss: 0.2521  obj_loss: 0.1523  noobj_loss: 0.1193  bbox_loss: 0.0068  cls_loss: 0.0060  \n",
      "<<<iteration:[140/263] - total_loss: 0.2580  obj_loss: 0.1518  noobj_loss: 0.1194  bbox_loss: 0.0067  cls_loss: 0.0127  \n",
      "<<<iteration:[160/263] - total_loss: 0.2553  obj_loss: 0.1661  noobj_loss: 0.1145  bbox_loss: 0.0047  cls_loss: 0.0086  \n",
      "<<<iteration:[180/263] - total_loss: 0.2424  obj_loss: 0.1427  noobj_loss: 0.1213  bbox_loss: 0.0057  cls_loss: 0.0107  \n",
      "<<<iteration:[200/263] - total_loss: 0.2443  obj_loss: 0.1516  noobj_loss: 0.1248  bbox_loss: 0.0047  cls_loss: 0.0069  \n",
      "<<<iteration:[220/263] - total_loss: 0.2457  obj_loss: 0.1569  noobj_loss: 0.1166  bbox_loss: 0.0045  cls_loss: 0.0077  \n",
      "<<<iteration:[240/263] - total_loss: 0.2486  obj_loss: 0.1590  noobj_loss: 0.1233  bbox_loss: 0.0043  cls_loss: 0.0062  \n",
      "<<<iteration:[260/263] - total_loss: 0.2386  obj_loss: 0.1505  noobj_loss: 0.1151  bbox_loss: 0.0046  cls_loss: 0.0074  \n",
      "\n",
      "epoch:96/100 - Train Loss: 0.2465, Val Loss: 0.2544\n",
      "\n",
      "<<<iteration:[20/263] - total_loss: 0.2480  obj_loss: 0.1531  noobj_loss: 0.1248  bbox_loss: 0.0049  cls_loss: 0.0082  \n",
      "<<<iteration:[40/263] - total_loss: 0.2460  obj_loss: 0.1571  noobj_loss: 0.1130  bbox_loss: 0.0050  cls_loss: 0.0072  \n",
      "<<<iteration:[60/263] - total_loss: 0.2498  obj_loss: 0.1572  noobj_loss: 0.1222  bbox_loss: 0.0047  cls_loss: 0.0079  \n",
      "<<<iteration:[80/263] - total_loss: 0.2428  obj_loss: 0.1535  noobj_loss: 0.1157  bbox_loss: 0.0045  cls_loss: 0.0088  \n",
      "<<<iteration:[100/263] - total_loss: 0.2610  obj_loss: 0.1687  noobj_loss: 0.1235  bbox_loss: 0.0042  cls_loss: 0.0093  \n",
      "<<<iteration:[120/263] - total_loss: 0.2504  obj_loss: 0.1590  noobj_loss: 0.1157  bbox_loss: 0.0050  cls_loss: 0.0088  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<<<iteration:[140/263] - total_loss: 0.2558  obj_loss: 0.1640  noobj_loss: 0.1224  bbox_loss: 0.0044  cls_loss: 0.0086  \n",
      "<<<iteration:[160/263] - total_loss: 0.2317  obj_loss: 0.1449  noobj_loss: 0.1171  bbox_loss: 0.0042  cls_loss: 0.0073  \n",
      "<<<iteration:[180/263] - total_loss: 0.2587  obj_loss: 0.1640  noobj_loss: 0.1187  bbox_loss: 0.0049  cls_loss: 0.0108  \n",
      "<<<iteration:[200/263] - total_loss: 0.2529  obj_loss: 0.1653  noobj_loss: 0.1170  bbox_loss: 0.0044  cls_loss: 0.0071  \n",
      "<<<iteration:[220/263] - total_loss: 0.2448  obj_loss: 0.1535  noobj_loss: 0.1193  bbox_loss: 0.0047  cls_loss: 0.0084  \n",
      "<<<iteration:[240/263] - total_loss: 0.2433  obj_loss: 0.1502  noobj_loss: 0.1220  bbox_loss: 0.0046  cls_loss: 0.0093  \n",
      "<<<iteration:[260/263] - total_loss: 0.2489  obj_loss: 0.1576  noobj_loss: 0.1189  bbox_loss: 0.0047  cls_loss: 0.0083  \n",
      "\n",
      "epoch:97/100 - Train Loss: 0.2479, Val Loss: 0.2504\n",
      "\n",
      "<<<iteration:[20/263] - total_loss: 0.2618  obj_loss: 0.1692  noobj_loss: 0.1262  bbox_loss: 0.0046  cls_loss: 0.0064  \n",
      "<<<iteration:[40/263] - total_loss: 0.2710  obj_loss: 0.1728  noobj_loss: 0.1252  bbox_loss: 0.0051  cls_loss: 0.0099  \n",
      "<<<iteration:[60/263] - total_loss: 0.2425  obj_loss: 0.1559  noobj_loss: 0.1167  bbox_loss: 0.0041  cls_loss: 0.0078  \n",
      "<<<iteration:[80/263] - total_loss: 0.2471  obj_loss: 0.1566  noobj_loss: 0.1177  bbox_loss: 0.0047  cls_loss: 0.0084  \n",
      "<<<iteration:[100/263] - total_loss: 0.2563  obj_loss: 0.1648  noobj_loss: 0.1158  bbox_loss: 0.0048  cls_loss: 0.0093  \n",
      "<<<iteration:[120/263] - total_loss: 0.2324  obj_loss: 0.1435  noobj_loss: 0.1162  bbox_loss: 0.0044  cls_loss: 0.0086  \n",
      "<<<iteration:[140/263] - total_loss: 0.2481  obj_loss: 0.1612  noobj_loss: 0.1115  bbox_loss: 0.0043  cls_loss: 0.0097  \n",
      "<<<iteration:[160/263] - total_loss: 0.2341  obj_loss: 0.1440  noobj_loss: 0.1216  bbox_loss: 0.0041  cls_loss: 0.0090  \n",
      "<<<iteration:[180/263] - total_loss: 0.2566  obj_loss: 0.1594  noobj_loss: 0.1291  bbox_loss: 0.0049  cls_loss: 0.0080  \n",
      "<<<iteration:[200/263] - total_loss: 0.2351  obj_loss: 0.1464  noobj_loss: 0.1220  bbox_loss: 0.0040  cls_loss: 0.0077  \n",
      "<<<iteration:[220/263] - total_loss: 0.2542  obj_loss: 0.1623  noobj_loss: 0.1182  bbox_loss: 0.0049  cls_loss: 0.0086  \n",
      "<<<iteration:[240/263] - total_loss: 0.2424  obj_loss: 0.1520  noobj_loss: 0.1161  bbox_loss: 0.0047  cls_loss: 0.0091  \n",
      "<<<iteration:[260/263] - total_loss: 0.2525  obj_loss: 0.1544  noobj_loss: 0.1348  bbox_loss: 0.0044  cls_loss: 0.0086  \n",
      "\n",
      "epoch:98/100 - Train Loss: 0.2476, Val Loss: 0.2575\n",
      "\n",
      "<<<iteration:[20/263] - total_loss: 0.2519  obj_loss: 0.1558  noobj_loss: 0.1218  bbox_loss: 0.0050  cls_loss: 0.0104  \n",
      "<<<iteration:[40/263] - total_loss: 0.2581  obj_loss: 0.1614  noobj_loss: 0.1234  bbox_loss: 0.0050  cls_loss: 0.0102  \n",
      "<<<iteration:[60/263] - total_loss: 0.2483  obj_loss: 0.1576  noobj_loss: 0.1222  bbox_loss: 0.0046  cls_loss: 0.0068  \n",
      "<<<iteration:[80/263] - total_loss: 0.2514  obj_loss: 0.1536  noobj_loss: 0.1236  bbox_loss: 0.0051  cls_loss: 0.0105  \n",
      "<<<iteration:[100/263] - total_loss: 0.2460  obj_loss: 0.1539  noobj_loss: 0.1220  bbox_loss: 0.0046  cls_loss: 0.0083  \n",
      "<<<iteration:[120/263] - total_loss: 0.2450  obj_loss: 0.1529  noobj_loss: 0.1182  bbox_loss: 0.0049  cls_loss: 0.0084  \n",
      "<<<iteration:[140/263] - total_loss: 0.2514  obj_loss: 0.1641  noobj_loss: 0.1215  bbox_loss: 0.0041  cls_loss: 0.0061  \n",
      "<<<iteration:[160/263] - total_loss: 0.2526  obj_loss: 0.1593  noobj_loss: 0.1299  bbox_loss: 0.0042  cls_loss: 0.0073  \n",
      "<<<iteration:[180/263] - total_loss: 0.2469  obj_loss: 0.1557  noobj_loss: 0.1193  bbox_loss: 0.0045  cls_loss: 0.0090  \n",
      "<<<iteration:[200/263] - total_loss: 0.2615  obj_loss: 0.1692  noobj_loss: 0.1182  bbox_loss: 0.0049  cls_loss: 0.0085  \n",
      "<<<iteration:[220/263] - total_loss: 0.2459  obj_loss: 0.1576  noobj_loss: 0.1186  bbox_loss: 0.0042  cls_loss: 0.0078  \n",
      "<<<iteration:[240/263] - total_loss: 0.2470  obj_loss: 0.1590  noobj_loss: 0.1177  bbox_loss: 0.0042  cls_loss: 0.0082  \n",
      "<<<iteration:[260/263] - total_loss: 0.2569  obj_loss: 0.1662  noobj_loss: 0.1258  bbox_loss: 0.0042  cls_loss: 0.0069  \n",
      "\n",
      "epoch:99/100 - Train Loss: 0.2499, Val Loss: 0.2592\n",
      "\n",
      "<<<iteration:[20/263] - total_loss: 0.2564  obj_loss: 0.1621  noobj_loss: 0.1263  bbox_loss: 0.0045  cls_loss: 0.0088  \n",
      "<<<iteration:[40/263] - total_loss: 0.2454  obj_loss: 0.1523  noobj_loss: 0.1239  bbox_loss: 0.0047  cls_loss: 0.0077  \n",
      "<<<iteration:[60/263] - total_loss: 0.2535  obj_loss: 0.1607  noobj_loss: 0.1205  bbox_loss: 0.0046  cls_loss: 0.0094  \n",
      "<<<iteration:[80/263] - total_loss: 0.2589  obj_loss: 0.1672  noobj_loss: 0.1212  bbox_loss: 0.0047  cls_loss: 0.0078  \n",
      "<<<iteration:[100/263] - total_loss: 0.2476  obj_loss: 0.1587  noobj_loss: 0.1201  bbox_loss: 0.0043  cls_loss: 0.0076  \n",
      "<<<iteration:[120/263] - total_loss: 0.2358  obj_loss: 0.1449  noobj_loss: 0.1204  bbox_loss: 0.0048  cls_loss: 0.0069  \n",
      "<<<iteration:[140/263] - total_loss: 0.2702  obj_loss: 0.1794  noobj_loss: 0.1200  bbox_loss: 0.0045  cls_loss: 0.0084  \n",
      "<<<iteration:[160/263] - total_loss: 0.2396  obj_loss: 0.1466  noobj_loss: 0.1166  bbox_loss: 0.0056  cls_loss: 0.0068  \n",
      "<<<iteration:[180/263] - total_loss: 0.2471  obj_loss: 0.1579  noobj_loss: 0.1230  bbox_loss: 0.0043  cls_loss: 0.0065  \n",
      "<<<iteration:[200/263] - total_loss: 0.2472  obj_loss: 0.1567  noobj_loss: 0.1223  bbox_loss: 0.0042  cls_loss: 0.0085  \n",
      "<<<iteration:[220/263] - total_loss: 0.2391  obj_loss: 0.1488  noobj_loss: 0.1173  bbox_loss: 0.0048  cls_loss: 0.0074  \n",
      "<<<iteration:[240/263] - total_loss: 0.2622  obj_loss: 0.1649  noobj_loss: 0.1266  bbox_loss: 0.0045  cls_loss: 0.0112  \n",
      "<<<iteration:[260/263] - total_loss: 0.2432  obj_loss: 0.1480  noobj_loss: 0.1277  bbox_loss: 0.0047  cls_loss: 0.0081  \n",
      "\n",
      "epoch:100/100 - Train Loss: 0.2486, Val Loss: 0.2561\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>Train Loss</td><td>█▄▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>Train bbox Loss</td><td>█▄▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>Train class Loss</td><td>█▄▃▂▂▂▂▂▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>Train obj Loss</td><td>▂▁▃▄▅▅▆▆▇▇▇▇▇███████████████████████▇███</td></tr><tr><td>Val Loss</td><td>█▄▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>Val bbox Loss</td><td>█▄▂▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>Val class Loss</td><td>█▆▄▃▃▂▂▂▂▂▂▂▂▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>Val obj Loss</td><td>▁▁▃▅▆▇▇▇▇██▇█▇█▇███▇████▇█▇█▇▇▇▇▇▇▇▇▇▇▆▇</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>Train Loss</td><td>0.24857</td></tr><tr><td>Train bbox Loss</td><td>0.0046</td></tr><tr><td>Train class Loss</td><td>0.00811</td></tr><tr><td>Train obj Loss</td><td>0.15668</td></tr><tr><td>Val Loss</td><td>0.25613</td></tr><tr><td>Val bbox Loss</td><td>0.01434</td></tr><tr><td>Val class Loss</td><td>0.01602</td></tr><tr><td>Val obj Loss</td><td>0.10882</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">wandering-tree-1</strong> at: <a href='https://wandb.ai/urp/yolo_resnet_neck/runs/0hyt161t' target=\"_blank\">https://wandb.ai/urp/yolo_resnet_neck/runs/0hyt161t</a><br/> View job at <a href='https://wandb.ai/urp/yolo_resnet_neck/jobs/QXJ0aWZhY3RDb2xsZWN0aW9uOjEwOTU4MDg2NQ==/version_details/v0' target=\"_blank\">https://wandb.ai/urp/yolo_resnet_neck/jobs/QXJ0aWZhY3RDb2xsZWN0aW9uOjEwOTU4MDg2NQ==/version_details/v0</a><br/>Synced 5 W&B file(s), 0 media file(s), 2 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20231024_161635-0hyt161t/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "best_epoch = 0\n",
    "best_score = float('inf')\n",
    "train_losses = []\n",
    "val_losses = []\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    train_loss, val_loss = train_one_epoch(dataloaders, model, criterion, optimizer, device)\n",
    "    train_losses.append(train_loss)\n",
    "    val_losses.append(val_loss)\n",
    "#     train_loss[\"obj_loss\"] += obj_loss\n",
    "#     train_loss[\"noobj_loss\"] += noobj_loss\n",
    "#     train_loss[\"bbox_loss\"] += bbox_loss\n",
    "#     train_loss[\"cls_loss\"] += cls_loss\n",
    "    wandb.log({\"Train Loss\": train_loss['total_loss'],\n",
    "               \"Train obj Loss\":train_loss[\"obj_loss\"],\n",
    "               \"Train bbox Loss\":train_loss[\"bbox_loss\"],\n",
    "               \"Train class Loss\":train_loss[\"cls_loss\"],\n",
    "               \"Val Loss\": val_loss['total_loss'],\n",
    "               \"Val obj Loss\":val_loss[\"obj_loss\"],\n",
    "               \"Val bbox Loss\":val_loss[\"bbox_loss\"],\n",
    "               \"Val class Loss\":val_loss[\"cls_loss\"],})\n",
    "    print(f\"\\nepoch:{epoch+1}/{num_epochs} - Train Loss: {train_loss['total_loss']:.4f}, Val Loss: {val_loss['total_loss']:.4f}\\n\")\n",
    "    \n",
    "    if (epoch+1) % 10 == 0:\n",
    "        save_model(model.state_dict(), f'model_{epoch+1}.pth', save_dir=f\"./trained_model/{BACKBONE}_{PART}_LR{LR}_AUG{AUG_FACTOR}\")\n",
    "wandb.finish()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4de7fe95",
   "metadata": {},
   "source": [
    "# Test Dataset Inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "b71f9334",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import os \n",
    "import pandas as pd\n",
    "import cv2\n",
    "import torch\n",
    "import matplotlib.pyplot as plt\n",
    "from ipywidgets import interact\n",
    "import albumentations as A\n",
    "from albumentations.pytorch import ToTensorV2\n",
    "import torchvision\n",
    "from torch import nn\n",
    "import torchsummary\n",
    "from torch.utils.data import DataLoader\n",
    "from collections import defaultdict\n",
    "from torchvision.utils import make_grid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "63f8dfc5",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "64dd5b10",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_model(ckpt_path, num_classes, device):\n",
    "    checkpoint = torch.load(ckpt_path, map_location=device)\n",
    "    model = YOLO_SWIN(num_classes=num_classes)\n",
    "    model.load_state_dict(checkpoint)\n",
    "    model = model.to(device)\n",
    "    model.eval()\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "4d80869e",
   "metadata": {},
   "outputs": [],
   "source": [
    "IMAGE_SIZE=448\n",
    "transformer = A.Compose([\n",
    "            A.Resize(height=IMAGE_SIZE, width=IMAGE_SIZE),\n",
    "            A.Normalize(mean=(0.485, 0.456, 0.406),std=(0.229, 0.224, 0.225)),\n",
    "            ToTensorV2(),\n",
    "        ],\n",
    "        bbox_params=A.BboxParams(format='yolo', label_fields=['class_ids']),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "76bcd114",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ckpt_path=\"./trained_model/YOLO_SWIN_T_body_LR0.0001_AUG30/model_90.pth\"\n",
    "ckpt_path=\"/workspace/Plastic_Bottle_defect_detection/trained_model/YOLO_SWIN_T_neck_LR0.0001_AUG20/model_100.pth\"\n",
    "model = load_model(ckpt_path, NUM_CLASSES, device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "0d42c594",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "start making augmented images-- augmented factor:0\n",
      "total length of augmented images: 0\n"
     ]
    }
   ],
   "source": [
    "NECK_PATH = '/home/host_data/PET_data/Neck'\n",
    "BODY_PATH = '/home/host_data/PET_data/Body'\n",
    "test_dataset=PET_dataset(\"neck\" ,neck_dir=NECK_PATH,body_dir=BODY_PATH,phase='test', transformer=transformer, aug=None)\n",
    "test_dataloaders = DataLoader(test_dataset, batch_size=1, shuffle=False, collate_fn=collate_fn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "07fed11f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "25"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(test_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "3709c974",
   "metadata": {},
   "outputs": [],
   "source": [
    "@torch.no_grad()\n",
    "def model_predict(image, model, conf_thres=0.2, iou_threshold=0.1):\n",
    "    predictions = model(image)\n",
    "    prediction = predictions.detach().cpu().squeeze(dim=0)\n",
    "#     print(prediction.shape)\n",
    "    \n",
    "    grid_size = prediction.shape[-1]\n",
    "    y_grid, x_grid = torch.meshgrid(torch.arange(grid_size), torch.arange(grid_size))\n",
    "    stride_size = IMAGE_SIZE/grid_size\n",
    "\n",
    "    conf = prediction[[0,5], ...].reshape(1, -1)\n",
    "    xc = (prediction[[1,6], ...] * IMAGE_SIZE + x_grid*stride_size).reshape(1,-1)\n",
    "    yc = (prediction[[2,7], ...] * IMAGE_SIZE + y_grid*stride_size).reshape(1,-1)\n",
    "    w = (prediction[[3,8], ...] * IMAGE_SIZE).reshape(1,-1)\n",
    "    h = (prediction[[4,9], ...] * IMAGE_SIZE).reshape(1,-1)\n",
    "    cls = torch.max(prediction[10:, ...].reshape(NUM_CLASSES, -1), dim=0).indices.tile(1,2)\n",
    "    \n",
    "    x_min = xc - w/2\n",
    "    y_min = yc - h/2\n",
    "    x_max = xc + w/2\n",
    "    y_max = yc + h/2\n",
    "\n",
    "    prediction_res = torch.cat([x_min, y_min, x_max, y_max, conf, cls], dim=0)\n",
    "    prediction_res = prediction_res.transpose(0,1)\n",
    "\n",
    "    # x_min과 y_min이 음수가 되지않고, x_max와 y_max가 이미지 크기를 넘지 않게 제한\n",
    "    prediction_res[:, 2].clip(min=0, max=image.shape[1]) \n",
    "    prediction_res[:, 3].clip(min=0, max=image.shape[0])\n",
    "        \n",
    "    pred_res = prediction_res[prediction_res[:, 4] > conf_thres]\n",
    "    nms_index = torchvision.ops.nms(boxes=pred_res[:, 0:4], scores=pred_res[:, 4], iou_threshold=iou_threshold)\n",
    "    pred_res_ = pred_res[nms_index].numpy()\n",
    "    \n",
    "    n_obj = pred_res_.shape[0]\n",
    "    bboxes = np.zeros(shape=(n_obj, 4), dtype=np.float32)\n",
    "    bboxes[:, 0:2] = (pred_res_[:, 0:2] + pred_res_[:, 2:4]) / 2\n",
    "    bboxes[:, 2:4] = pred_res_[:, 2:4] - pred_res_[:, 0:2]\n",
    "    scores = pred_res_[:, 4]\n",
    "    class_ids = pred_res_[:, 5]\n",
    "    \n",
    "    # 이미지 값이 들어가면 모델을 통해서, 후처리까지 포함된 yolo 포멧의 box좌표, 그 좌표에 대한 confidence score\n",
    "    # 그리고 class id를 반환\n",
    "    return bboxes, scores, class_ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "10dddcd9",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.8/dist-packages/torch/functional.py:504: UserWarning: torch.meshgrid: in an upcoming release, it will be required to pass the indexing argument. (Triggered internally at /opt/pytorch/pytorch/aten/src/ATen/native/TensorShape.cpp:3423.)\n",
      "  return _VF.meshgrid(tensors, **kwargs)  # type: ignore[attr-defined]\n"
     ]
    }
   ],
   "source": [
    "pred_images = []\n",
    "pred_labels =[]\n",
    "\n",
    "for index, batch in enumerate(test_dataloaders):\n",
    "    images = batch[0].to(device)\n",
    "    bboxes, scores, class_ids = model_predict(images, model, conf_thres=0.1, iou_threshold=0.1)\n",
    "    \n",
    "    if len(bboxes) > 0:\n",
    "        prediction_yolo = np.concatenate([bboxes, scores[:, np.newaxis], class_ids[:, np.newaxis]], axis=1)\n",
    "    else:\n",
    "        prediction_yolo = np.array([])\n",
    "    \n",
    "    # 텐서형의 이미지를 다시 unnormalize를 시키고, 다시 chw를 hwc로 바꾸고 넘파이로 바꾼다.\n",
    "    np_image = make_grid(images[0], normalize=True).cpu().permute(1,2,0).numpy()\n",
    "    pred_images.append(np_image)\n",
    "    pred_labels.append(prediction_yolo)\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "b07fa545",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f20d3fcf09fc4cf59e29766c77f20489",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "interactive(children=(IntSlider(value=0, description='index', max=24), Output()), _dom_classes=('widget-intera…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from ipywidgets import interact\n",
    "\n",
    "@interact(index=(0,len(pred_images)-1))\n",
    "def show_result(index=0):\n",
    "    print(pred_labels[index])\n",
    "    if len(pred_labels[index]) > 0:\n",
    "        result = visualize(pred_images[index], pred_labels[index][:, 0:4], pred_labels[index][:, 5])\n",
    "    else:\n",
    "        result = pred_images[index]\n",
    "        \n",
    "    plt.figure(figsize=(6,6))\n",
    "    plt.imshow(result)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24c0544e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
