{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3c025da0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import os \n",
    "import pandas as pd\n",
    "import cv2\n",
    "import torch\n",
    "import matplotlib.pyplot as plt\n",
    "from ipywidgets import interact\n",
    "import albumentations as A\n",
    "from albumentations.pytorch import ToTensorV2\n",
    "import torchvision\n",
    "from torch import nn\n",
    "import torchsummary\n",
    "from torch.utils.data import DataLoader\n",
    "from collections import defaultdict\n",
    "from torchvision.utils import make_grid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5d503acd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cuda', index=0)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "device"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ee9eb3c",
   "metadata": {},
   "source": [
    "# Utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c7fac7d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "CLASS_NAME_TO_ID = {'stray': 0, 'target': 1}\n",
    "CLASS_ID_TO_NAME = {0: 'stray', 1: 'target'}\n",
    "BOX_COLOR = {'stray':(200, 0, 0), 'target':(0, 0, 200)}\n",
    "TEXT_COLOR = (255, 255, 255)\n",
    "\n",
    "def save_model(model_state, model_name, save_dir=\"./trained_model\"):\n",
    "    os.makedirs(save_dir, exist_ok=True)\n",
    "    torch.save(model_state, os.path.join(save_dir, model_name))\n",
    "\n",
    "\n",
    "def visualize_bbox(image, bbox, class_name, color=BOX_COLOR, thickness=2):\n",
    "    x_center, y_center, w, h = bbox\n",
    "    x_min = int(x_center - w/2)\n",
    "    y_min = int(y_center - h/2)\n",
    "    x_max = int(x_center + w/2)\n",
    "    y_max = int(y_center + h/2)\n",
    "    \n",
    "    cv2.rectangle(image, (x_min, y_min), (x_max, y_max), color=color[class_name], thickness=thickness)\n",
    "    \n",
    "    ((text_width, text_height), _) = cv2.getTextSize(class_name, cv2.FONT_HERSHEY_SIMPLEX, 0.35, 1)    \n",
    "    cv2.rectangle(image, (x_min, y_min - int(1.3 * text_height)), (x_min + text_width, y_min), color[class_name], -1)\n",
    "    cv2.putText(\n",
    "        image,\n",
    "        text=class_name,\n",
    "        org=(x_min, y_min - int(0.3 * text_height)),\n",
    "        fontFace=cv2.FONT_HERSHEY_SIMPLEX,\n",
    "        fontScale=0.35, \n",
    "        color=TEXT_COLOR, \n",
    "        lineType=cv2.LINE_AA,\n",
    "    )\n",
    "    return image\n",
    "\n",
    "\n",
    "def visualize(image, bboxes, category_ids):\n",
    "    img = image.copy()\n",
    "    for bbox, category_id in zip(bboxes, category_ids):\n",
    "#         print('category_id: ',category_id)\n",
    "        class_name = CLASS_ID_TO_NAME[category_id.item()]\n",
    "        img = visualize_bbox(img, bbox, class_name)\n",
    "    return img"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62c7da98",
   "metadata": {},
   "source": [
    "# Datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ea0166e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Radio_dataset():\n",
    "    def __init__(self, path, phase, transformer=None, aug=None, aug_factor=0):\n",
    "        self.path=path\n",
    "        self.phase=phase\n",
    "        self.transformer=transformer\n",
    "        self.aug=aug\n",
    "        self.aug_factor=aug_factor\n",
    "        \n",
    "        self.image_files = sorted([fn for fn in os.listdir(self.path+\"/\"+self.phase+\"/image\") if fn.endswith(\"jpg\")])\n",
    "        self.label_files= sorted([lab for lab in os.listdir(self.path+\"/\"+self.phase+\"/label\") if lab.endswith(\"txt\")])\n",
    "        \n",
    "        self.auged_img_list, self.auged_label_list=self.make_aug_list(self.image_files, self.label_files)\n",
    "        \n",
    "    def __getitem__(self,index):\n",
    "        if(self.aug==None):\n",
    "            filename, image = self.get_image(index)\n",
    "            bboxes, class_ids = self.get_label(index)\n",
    "\n",
    "            if(self.transformer):\n",
    "                transformed_data=self.transformer(image=image, bboxes=bboxes, class_ids=class_ids)\n",
    "                image = transformed_data['image']\n",
    "                bboxes = np.array(transformed_data['bboxes'])\n",
    "                class_ids = np.array(transformed_data['class_ids'])\n",
    "\n",
    "\n",
    "            target = {}\n",
    "    #         print(f'bboxes:{bboxes}\\nclass_ids:{class_ids}\\nlen_bboxes:{len(bboxes)}\\nlen_class_ids:{len(class_ids)}')\n",
    "    #         print(f'filename: {filename}')\n",
    "            target[\"boxes\"] = torch.Tensor(bboxes).float()\n",
    "            target[\"labels\"] = torch.Tensor(class_ids).long()\n",
    "\n",
    "            ###\n",
    "            bboxes=torch.Tensor(bboxes).float()\n",
    "            class_ids=torch.Tensor(class_ids).long()\n",
    "#             print(f\"bboxes:{bboxes}\\nclass_ids:{class_ids}\\n---------\")\n",
    "            target = np.concatenate((bboxes, class_ids[:, np.newaxis]), axis=1)\n",
    "            ###\n",
    "        else:\n",
    "            image=self.auged_img_list[index][1]\n",
    "            target=self.auged_label_list[index]\n",
    "            filename=self.auged_img_list[index][0]\n",
    "        return image, target, filename\n",
    "    \n",
    "    def __len__(self, ):\n",
    "        length=0\n",
    "        if(self.aug==None):\n",
    "            length=len(self.image_files)\n",
    "        else:\n",
    "            length=len(self.auged_img_list)\n",
    "        return length\n",
    "    \n",
    "    def make_aug_list(self,ori_image_list,ori_label_files):\n",
    "        aug_image_list=[]\n",
    "        aug_label_list=[]\n",
    "        \n",
    "        print(f\"start making augmented images-- augmented factor:{self.aug_factor}\")\n",
    "        for i in range(len(ori_image_list)):\n",
    "            filename, ori_image = self.get_image(i)\n",
    "            ori_bboxes, ori_class_ids = self.get_label(i)\n",
    "            for j in range(self.aug_factor):\n",
    "                auged_data=self.aug(image=ori_image, bboxes=ori_bboxes, class_ids=ori_class_ids)\n",
    "                image = auged_data['image']\n",
    "                bboxes = np.array(auged_data['bboxes'])\n",
    "                class_ids = np.array(auged_data['class_ids'])\n",
    "                \n",
    "                bboxes=torch.Tensor(bboxes).float()\n",
    "                class_ids=torch.Tensor(class_ids).long()\n",
    "                \n",
    "                aug_image_list.append((filename, image))\n",
    "#                 print(f\"{filename}, {bboxes}, {class_ids[:, np.newaxis]}\")\n",
    "                aug_label_list.append(np.concatenate((bboxes, class_ids[:, np.newaxis]), axis=1))\n",
    "        \n",
    "        print(f\"total length of augmented images: {len(aug_image_list)}\")\n",
    "        \n",
    "        return aug_image_list, aug_label_list\n",
    "        \n",
    "    \n",
    "    def get_image(self, index): # 이미지 불러오는 함수\n",
    "        filename = self.image_files[index]\n",
    "        \n",
    "        image_path = self.path+\"/\"+self.phase+\"/image/\"+filename\n",
    "        image = cv2.imread(image_path)\n",
    "        image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "        return filename, image\n",
    "    \n",
    "    def get_label(self, index): # label (box좌표, class_id) 불러오는 함수\n",
    "        label_filename=self.label_files[index]\n",
    "        label_path = self.path+\"/\"+self.phase+\"/label/\"+label_filename\n",
    "        with open(label_path, 'r') as file:\n",
    "            labels = file.readlines()\n",
    "        \n",
    "        class_ids=[]\n",
    "        bboxes=[]\n",
    "        for label in labels:\n",
    "            label=label.replace(\"\\n\", \"\")\n",
    "            obj=label.split(' ')[0]\n",
    "            coor=label.split(' ')[1:]\n",
    "            obj=int(obj)\n",
    "            coor=list(map(float, coor))\n",
    "            class_ids.append(obj)\n",
    "            bboxes.append(coor)\n",
    "            \n",
    "        return bboxes, class_ids\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "235e7cec",
   "metadata": {},
   "outputs": [],
   "source": [
    "IMAGE_SIZE = 448\n",
    "\n",
    "transformer = A.Compose([ \n",
    "        # bounding box의 변환, augmentation에서 albumentations는 Detection 학습을 할 때 굉장히 유용하다. \n",
    "        A.Resize(height=IMAGE_SIZE, width=IMAGE_SIZE),\n",
    "#         A.Normalize(mean=(0.485, 0.456, 0.406),std=(0.229, 0.224, 0.225)),\n",
    "        ToTensorV2(),\n",
    "        # albumentations 라이브러리에서는 Normalization을 먼저 진행해 주고 tensor화를 진행해 주어야한다.\n",
    "    ],\n",
    "    # box 위치에 대한 transformation도 함께 진행된다. \n",
    "    bbox_params=A.BboxParams(format='yolo', label_fields=['class_ids']),\n",
    ")\n",
    "\n",
    "augmentator=A.Compose([\n",
    "#     A.Resize(height=IMAGE_SIZE, width=IMAGE_SIZE),\n",
    "    A.HorizontalFlip(p=0.7),\n",
    "    A.VerticalFlip (p=0.5),\n",
    "    A.HueSaturationValue(p=0.5),\n",
    "    A.Resize(height=IMAGE_SIZE, width=IMAGE_SIZE),\n",
    "    A.Normalize(mean=(0.485, 0.456, 0.406),std=(0.229, 0.224, 0.225)),\n",
    "    ToTensorV2(),\n",
    "    ],\n",
    "    bbox_params=A.BboxParams(format='yolo', label_fields=['class_ids']),\n",
    ")\n",
    "\n",
    "def collate_fn(batch):\n",
    "    image_list = []\n",
    "    target_list = []\n",
    "    filename_list = []\n",
    "    \n",
    "    for a,b,c in batch:\n",
    "        image_list.append(a)\n",
    "        target_list.append(b)\n",
    "        filename_list.append(c)\n",
    "\n",
    "    return torch.stack(image_list, dim=0), target_list, filename_list\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "a6d5c32a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "start making augmented images-- augmented factor:0\n",
      "total length of augmented images: 0\n"
     ]
    }
   ],
   "source": [
    "# NECK_PATH = '/home/host_data/PET_data/Neck'\n",
    "# BODY_PATH = '/home/host_data/PET_data/Body'\n",
    "\n",
    "NECK_PATH = '/home/host_data/PET_data_IP_AUG/aug_patched_Neck/'\n",
    "BODY_PATH = '/home/host_data/PET_data_image_patching/Body'\n",
    "\n",
    "PATH='/home/host_data/radio_signal_data_organized/'\n",
    "\n",
    "# trainset_yes_aug=PET_dataset(part='neck',neck_dir=NECK_PATH,body_dir=BODY_PATH,phase='train', transformer=transformer, aug=augmentator, aug_factor=5)\n",
    "trainset_no_aug=Radio_dataset(path=PATH, phase='valid', transformer=transformer, aug=None, aug_factor=0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "c0fbcd25",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "565"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(trainset_no_aug)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "5db4ebba",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f57e2458e0254cc3a7f4338e52493653",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "interactive(children=(IntSlider(value=0, description='index', max=564), Output()), _dom_classes=('widget-inter…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "@interact(index=(0, len(trainset_no_aug)-1))\n",
    "\n",
    "def show_sample(index=0):\n",
    "    image, target, filename = trainset_no_aug[index]\n",
    "    image=image.permute(1,2,0).numpy()\n",
    "    img_H, img_W, _ = image.shape\n",
    "    print(filename)\n",
    "    print(image.shape)\n",
    "#     print(image)\n",
    "\n",
    "#     bboxes = target['boxes']\n",
    "#     class_ids = target[\"labels\"]\n",
    "    \n",
    "    ###\n",
    "    bboxes = target[:, 0:4]\n",
    "    class_ids = target[:, 4]\n",
    "    ###\n",
    "    bboxes[:, [0,2]] *= img_W\n",
    "    bboxes[:, [1,3]] *= img_H\n",
    "\n",
    "    canvas = visualize(image, bboxes, class_ids)\n",
    "    plt.figure(figsize=(6,6))\n",
    "    plt.imshow(canvas)\n",
    "    plt.axis('off')\n",
    "    plt.show()\n",
    "\n",
    "# show_sample()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "5e341d7c",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'trainset_yes_aug' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[13], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[38;5;129m@interact\u001b[39m(index\u001b[38;5;241m=\u001b[39m(\u001b[38;5;241m0\u001b[39m, \u001b[38;5;28mlen\u001b[39m(\u001b[43mtrainset_yes_aug\u001b[49m)\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m))\n\u001b[1;32m      2\u001b[0m \n\u001b[1;32m      3\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mshow_sample\u001b[39m(index\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m):\n\u001b[1;32m      4\u001b[0m     image, target, filename \u001b[38;5;241m=\u001b[39m trainset_yes_aug[index]\n\u001b[1;32m      5\u001b[0m     image\u001b[38;5;241m=\u001b[39mimage\u001b[38;5;241m.\u001b[39mpermute(\u001b[38;5;241m1\u001b[39m,\u001b[38;5;241m2\u001b[39m,\u001b[38;5;241m0\u001b[39m)\u001b[38;5;241m.\u001b[39mnumpy()\n",
      "\u001b[0;31mNameError\u001b[0m: name 'trainset_yes_aug' is not defined"
     ]
    }
   ],
   "source": [
    "@interact(index=(0, len(trainset_yes_aug)-1))\n",
    "\n",
    "def show_sample(index=0):\n",
    "    image, target, filename = trainset_yes_aug[index]\n",
    "    image=image.permute(1,2,0).numpy()\n",
    "    img_H, img_W, _ = image.shape\n",
    "    print(filename)\n",
    "    print(image.shape)\n",
    "#     print(image)\n",
    "\n",
    "#     bboxes = target['boxes']\n",
    "#     class_ids = target[\"labels\"]\n",
    "    ###\n",
    "    bboxes = target[:, 0:4]\n",
    "    class_ids = target[:, 4]\n",
    "    ###\n",
    "    bboxes[:, [0,2]] *= img_W\n",
    "    bboxes[:, [1,3]] *= img_H\n",
    "    print(bboxes)\n",
    "\n",
    "    canvas = visualize(image, bboxes, class_ids)\n",
    "    plt.figure(figsize=(6,6))\n",
    "    plt.imshow(canvas)\n",
    "    plt.axis('off')\n",
    "    plt.show()\n",
    "\n",
    "# show_sample()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f151003",
   "metadata": {},
   "source": [
    "## Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "729f2964",
   "metadata": {},
   "outputs": [],
   "source": [
    "class YOLO_SWIN(nn.Module):\n",
    "    def __init__(self, num_classes):\n",
    "        super().__init__()\n",
    "\n",
    "        self.num_classes = num_classes\n",
    "        self.num_bboxes = 2\n",
    "        self.grid_size = 7\n",
    "\n",
    "#         resnet18 = torchvision.models.resnet18(pretrained = True)\n",
    "        swin=torchvision.models.swin_v2_t(weights='IMAGENET1K_V1')\n",
    "        layers = [m for m in swin.children()] #Resnet에서 Yolo에서 가져올수 있을만한 layer만 선별적으로 가져오기 위해서\n",
    "\n",
    "        # 기존 Resnet18의 layer들중에서 맨 뒤에 두개만 제외하고 다 가져와서 Backbone으로 사용\n",
    "        self.backbone = nn.Sequential(*layers[:-3]) \n",
    "        self.head = nn.Sequential(\n",
    "                nn.Conv2d(in_channels=768, out_channels=1024, kernel_size=1, padding=0,bias=False),\n",
    "                nn.BatchNorm2d(1024),\n",
    "                nn.ReLU(inplace=True),\n",
    "                nn.Conv2d(in_channels=1024, out_channels=1024, kernel_size=3, padding=1,bias=False),\n",
    "                nn.BatchNorm2d(1024),\n",
    "                nn.ReLU(inplace=True),\n",
    "                nn.Conv2d(in_channels=1024, out_channels=1024, kernel_size=3, padding=1,bias=False),\n",
    "                nn.BatchNorm2d(1024),\n",
    "                nn.ReLU(inplace=True),\n",
    "                nn.Conv2d(in_channels=1024, out_channels=1024, kernel_size=3, padding=1,bias=False),\n",
    "                nn.BatchNorm2d(1024),\n",
    "                nn.ReLU(inplace=True),\n",
    "\n",
    "                nn.Conv2d(in_channels=1024, out_channels=(4+1)*self.num_bboxes+num_classes, kernel_size=1, padding=0, bias=False),\n",
    "                nn.AdaptiveAvgPool2d(output_size=(self.grid_size, self.grid_size))\n",
    "            )\n",
    "\n",
    "    def forward(self, x):\n",
    "        out = self.backbone(x)\n",
    "        # out = self.neck(out)\n",
    "        out = self.head(out) # input (batch, 3, 448, 448) -> output feature (batch, 12, 7, 7)\n",
    "        return out\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b0a6eb83",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "YOLO_SWIN(\n",
       "  (backbone): Sequential(\n",
       "    (0): Sequential(\n",
       "      (0): Sequential(\n",
       "        (0): Conv2d(3, 96, kernel_size=(4, 4), stride=(4, 4))\n",
       "        (1): Permute()\n",
       "        (2): LayerNorm((96,), eps=1e-05, elementwise_affine=True)\n",
       "      )\n",
       "      (1): Sequential(\n",
       "        (0): SwinTransformerBlockV2(\n",
       "          (norm1): LayerNorm((96,), eps=1e-05, elementwise_affine=True)\n",
       "          (attn): ShiftedWindowAttentionV2(\n",
       "            (qkv): Linear(in_features=96, out_features=288, bias=True)\n",
       "            (proj): Linear(in_features=96, out_features=96, bias=True)\n",
       "            (cpb_mlp): Sequential(\n",
       "              (0): Linear(in_features=2, out_features=512, bias=True)\n",
       "              (1): ReLU(inplace=True)\n",
       "              (2): Linear(in_features=512, out_features=3, bias=False)\n",
       "            )\n",
       "          )\n",
       "          (stochastic_depth): StochasticDepth(p=0.0, mode=row)\n",
       "          (norm2): LayerNorm((96,), eps=1e-05, elementwise_affine=True)\n",
       "          (mlp): MLP(\n",
       "            (0): Linear(in_features=96, out_features=384, bias=True)\n",
       "            (1): GELU(approximate='none')\n",
       "            (2): Dropout(p=0.0, inplace=False)\n",
       "            (3): Linear(in_features=384, out_features=96, bias=True)\n",
       "            (4): Dropout(p=0.0, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (1): SwinTransformerBlockV2(\n",
       "          (norm1): LayerNorm((96,), eps=1e-05, elementwise_affine=True)\n",
       "          (attn): ShiftedWindowAttentionV2(\n",
       "            (qkv): Linear(in_features=96, out_features=288, bias=True)\n",
       "            (proj): Linear(in_features=96, out_features=96, bias=True)\n",
       "            (cpb_mlp): Sequential(\n",
       "              (0): Linear(in_features=2, out_features=512, bias=True)\n",
       "              (1): ReLU(inplace=True)\n",
       "              (2): Linear(in_features=512, out_features=3, bias=False)\n",
       "            )\n",
       "          )\n",
       "          (stochastic_depth): StochasticDepth(p=0.018181818181818184, mode=row)\n",
       "          (norm2): LayerNorm((96,), eps=1e-05, elementwise_affine=True)\n",
       "          (mlp): MLP(\n",
       "            (0): Linear(in_features=96, out_features=384, bias=True)\n",
       "            (1): GELU(approximate='none')\n",
       "            (2): Dropout(p=0.0, inplace=False)\n",
       "            (3): Linear(in_features=384, out_features=96, bias=True)\n",
       "            (4): Dropout(p=0.0, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (2): PatchMergingV2(\n",
       "        (reduction): Linear(in_features=384, out_features=192, bias=False)\n",
       "        (norm): LayerNorm((192,), eps=1e-05, elementwise_affine=True)\n",
       "      )\n",
       "      (3): Sequential(\n",
       "        (0): SwinTransformerBlockV2(\n",
       "          (norm1): LayerNorm((192,), eps=1e-05, elementwise_affine=True)\n",
       "          (attn): ShiftedWindowAttentionV2(\n",
       "            (qkv): Linear(in_features=192, out_features=576, bias=True)\n",
       "            (proj): Linear(in_features=192, out_features=192, bias=True)\n",
       "            (cpb_mlp): Sequential(\n",
       "              (0): Linear(in_features=2, out_features=512, bias=True)\n",
       "              (1): ReLU(inplace=True)\n",
       "              (2): Linear(in_features=512, out_features=6, bias=False)\n",
       "            )\n",
       "          )\n",
       "          (stochastic_depth): StochasticDepth(p=0.03636363636363637, mode=row)\n",
       "          (norm2): LayerNorm((192,), eps=1e-05, elementwise_affine=True)\n",
       "          (mlp): MLP(\n",
       "            (0): Linear(in_features=192, out_features=768, bias=True)\n",
       "            (1): GELU(approximate='none')\n",
       "            (2): Dropout(p=0.0, inplace=False)\n",
       "            (3): Linear(in_features=768, out_features=192, bias=True)\n",
       "            (4): Dropout(p=0.0, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (1): SwinTransformerBlockV2(\n",
       "          (norm1): LayerNorm((192,), eps=1e-05, elementwise_affine=True)\n",
       "          (attn): ShiftedWindowAttentionV2(\n",
       "            (qkv): Linear(in_features=192, out_features=576, bias=True)\n",
       "            (proj): Linear(in_features=192, out_features=192, bias=True)\n",
       "            (cpb_mlp): Sequential(\n",
       "              (0): Linear(in_features=2, out_features=512, bias=True)\n",
       "              (1): ReLU(inplace=True)\n",
       "              (2): Linear(in_features=512, out_features=6, bias=False)\n",
       "            )\n",
       "          )\n",
       "          (stochastic_depth): StochasticDepth(p=0.05454545454545456, mode=row)\n",
       "          (norm2): LayerNorm((192,), eps=1e-05, elementwise_affine=True)\n",
       "          (mlp): MLP(\n",
       "            (0): Linear(in_features=192, out_features=768, bias=True)\n",
       "            (1): GELU(approximate='none')\n",
       "            (2): Dropout(p=0.0, inplace=False)\n",
       "            (3): Linear(in_features=768, out_features=192, bias=True)\n",
       "            (4): Dropout(p=0.0, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (4): PatchMergingV2(\n",
       "        (reduction): Linear(in_features=768, out_features=384, bias=False)\n",
       "        (norm): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n",
       "      )\n",
       "      (5): Sequential(\n",
       "        (0): SwinTransformerBlockV2(\n",
       "          (norm1): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n",
       "          (attn): ShiftedWindowAttentionV2(\n",
       "            (qkv): Linear(in_features=384, out_features=1152, bias=True)\n",
       "            (proj): Linear(in_features=384, out_features=384, bias=True)\n",
       "            (cpb_mlp): Sequential(\n",
       "              (0): Linear(in_features=2, out_features=512, bias=True)\n",
       "              (1): ReLU(inplace=True)\n",
       "              (2): Linear(in_features=512, out_features=12, bias=False)\n",
       "            )\n",
       "          )\n",
       "          (stochastic_depth): StochasticDepth(p=0.07272727272727274, mode=row)\n",
       "          (norm2): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n",
       "          (mlp): MLP(\n",
       "            (0): Linear(in_features=384, out_features=1536, bias=True)\n",
       "            (1): GELU(approximate='none')\n",
       "            (2): Dropout(p=0.0, inplace=False)\n",
       "            (3): Linear(in_features=1536, out_features=384, bias=True)\n",
       "            (4): Dropout(p=0.0, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (1): SwinTransformerBlockV2(\n",
       "          (norm1): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n",
       "          (attn): ShiftedWindowAttentionV2(\n",
       "            (qkv): Linear(in_features=384, out_features=1152, bias=True)\n",
       "            (proj): Linear(in_features=384, out_features=384, bias=True)\n",
       "            (cpb_mlp): Sequential(\n",
       "              (0): Linear(in_features=2, out_features=512, bias=True)\n",
       "              (1): ReLU(inplace=True)\n",
       "              (2): Linear(in_features=512, out_features=12, bias=False)\n",
       "            )\n",
       "          )\n",
       "          (stochastic_depth): StochasticDepth(p=0.09090909090909091, mode=row)\n",
       "          (norm2): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n",
       "          (mlp): MLP(\n",
       "            (0): Linear(in_features=384, out_features=1536, bias=True)\n",
       "            (1): GELU(approximate='none')\n",
       "            (2): Dropout(p=0.0, inplace=False)\n",
       "            (3): Linear(in_features=1536, out_features=384, bias=True)\n",
       "            (4): Dropout(p=0.0, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (2): SwinTransformerBlockV2(\n",
       "          (norm1): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n",
       "          (attn): ShiftedWindowAttentionV2(\n",
       "            (qkv): Linear(in_features=384, out_features=1152, bias=True)\n",
       "            (proj): Linear(in_features=384, out_features=384, bias=True)\n",
       "            (cpb_mlp): Sequential(\n",
       "              (0): Linear(in_features=2, out_features=512, bias=True)\n",
       "              (1): ReLU(inplace=True)\n",
       "              (2): Linear(in_features=512, out_features=12, bias=False)\n",
       "            )\n",
       "          )\n",
       "          (stochastic_depth): StochasticDepth(p=0.10909090909090911, mode=row)\n",
       "          (norm2): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n",
       "          (mlp): MLP(\n",
       "            (0): Linear(in_features=384, out_features=1536, bias=True)\n",
       "            (1): GELU(approximate='none')\n",
       "            (2): Dropout(p=0.0, inplace=False)\n",
       "            (3): Linear(in_features=1536, out_features=384, bias=True)\n",
       "            (4): Dropout(p=0.0, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (3): SwinTransformerBlockV2(\n",
       "          (norm1): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n",
       "          (attn): ShiftedWindowAttentionV2(\n",
       "            (qkv): Linear(in_features=384, out_features=1152, bias=True)\n",
       "            (proj): Linear(in_features=384, out_features=384, bias=True)\n",
       "            (cpb_mlp): Sequential(\n",
       "              (0): Linear(in_features=2, out_features=512, bias=True)\n",
       "              (1): ReLU(inplace=True)\n",
       "              (2): Linear(in_features=512, out_features=12, bias=False)\n",
       "            )\n",
       "          )\n",
       "          (stochastic_depth): StochasticDepth(p=0.1272727272727273, mode=row)\n",
       "          (norm2): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n",
       "          (mlp): MLP(\n",
       "            (0): Linear(in_features=384, out_features=1536, bias=True)\n",
       "            (1): GELU(approximate='none')\n",
       "            (2): Dropout(p=0.0, inplace=False)\n",
       "            (3): Linear(in_features=1536, out_features=384, bias=True)\n",
       "            (4): Dropout(p=0.0, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (4): SwinTransformerBlockV2(\n",
       "          (norm1): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n",
       "          (attn): ShiftedWindowAttentionV2(\n",
       "            (qkv): Linear(in_features=384, out_features=1152, bias=True)\n",
       "            (proj): Linear(in_features=384, out_features=384, bias=True)\n",
       "            (cpb_mlp): Sequential(\n",
       "              (0): Linear(in_features=2, out_features=512, bias=True)\n",
       "              (1): ReLU(inplace=True)\n",
       "              (2): Linear(in_features=512, out_features=12, bias=False)\n",
       "            )\n",
       "          )\n",
       "          (stochastic_depth): StochasticDepth(p=0.14545454545454548, mode=row)\n",
       "          (norm2): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n",
       "          (mlp): MLP(\n",
       "            (0): Linear(in_features=384, out_features=1536, bias=True)\n",
       "            (1): GELU(approximate='none')\n",
       "            (2): Dropout(p=0.0, inplace=False)\n",
       "            (3): Linear(in_features=1536, out_features=384, bias=True)\n",
       "            (4): Dropout(p=0.0, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (5): SwinTransformerBlockV2(\n",
       "          (norm1): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n",
       "          (attn): ShiftedWindowAttentionV2(\n",
       "            (qkv): Linear(in_features=384, out_features=1152, bias=True)\n",
       "            (proj): Linear(in_features=384, out_features=384, bias=True)\n",
       "            (cpb_mlp): Sequential(\n",
       "              (0): Linear(in_features=2, out_features=512, bias=True)\n",
       "              (1): ReLU(inplace=True)\n",
       "              (2): Linear(in_features=512, out_features=12, bias=False)\n",
       "            )\n",
       "          )\n",
       "          (stochastic_depth): StochasticDepth(p=0.16363636363636364, mode=row)\n",
       "          (norm2): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n",
       "          (mlp): MLP(\n",
       "            (0): Linear(in_features=384, out_features=1536, bias=True)\n",
       "            (1): GELU(approximate='none')\n",
       "            (2): Dropout(p=0.0, inplace=False)\n",
       "            (3): Linear(in_features=1536, out_features=384, bias=True)\n",
       "            (4): Dropout(p=0.0, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (6): PatchMergingV2(\n",
       "        (reduction): Linear(in_features=1536, out_features=768, bias=False)\n",
       "        (norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "      )\n",
       "      (7): Sequential(\n",
       "        (0): SwinTransformerBlockV2(\n",
       "          (norm1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "          (attn): ShiftedWindowAttentionV2(\n",
       "            (qkv): Linear(in_features=768, out_features=2304, bias=True)\n",
       "            (proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (cpb_mlp): Sequential(\n",
       "              (0): Linear(in_features=2, out_features=512, bias=True)\n",
       "              (1): ReLU(inplace=True)\n",
       "              (2): Linear(in_features=512, out_features=24, bias=False)\n",
       "            )\n",
       "          )\n",
       "          (stochastic_depth): StochasticDepth(p=0.18181818181818182, mode=row)\n",
       "          (norm2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "          (mlp): MLP(\n",
       "            (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (1): GELU(approximate='none')\n",
       "            (2): Dropout(p=0.0, inplace=False)\n",
       "            (3): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (4): Dropout(p=0.0, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (1): SwinTransformerBlockV2(\n",
       "          (norm1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "          (attn): ShiftedWindowAttentionV2(\n",
       "            (qkv): Linear(in_features=768, out_features=2304, bias=True)\n",
       "            (proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (cpb_mlp): Sequential(\n",
       "              (0): Linear(in_features=2, out_features=512, bias=True)\n",
       "              (1): ReLU(inplace=True)\n",
       "              (2): Linear(in_features=512, out_features=24, bias=False)\n",
       "            )\n",
       "          )\n",
       "          (stochastic_depth): StochasticDepth(p=0.2, mode=row)\n",
       "          (norm2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "          (mlp): MLP(\n",
       "            (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (1): GELU(approximate='none')\n",
       "            (2): Dropout(p=0.0, inplace=False)\n",
       "            (3): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (4): Dropout(p=0.0, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "    (2): Permute()\n",
       "  )\n",
       "  (head): Sequential(\n",
       "    (0): Conv2d(768, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "    (1): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU(inplace=True)\n",
       "    (3): Conv2d(1024, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "    (4): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (5): ReLU(inplace=True)\n",
       "    (6): Conv2d(1024, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "    (7): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (8): ReLU(inplace=True)\n",
       "    (9): Conv2d(1024, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "    (10): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (11): ReLU(inplace=True)\n",
       "    (12): Conv2d(1024, 12, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "    (13): AdaptiveAvgPool2d(output_size=(7, 7))\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "NUM_CLASSES = 2\n",
    "model = YOLO_SWIN(num_classes=NUM_CLASSES)\n",
    "model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "361cde55",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------------------------------\n",
      "        Layer (type)               Output Shape         Param #\n",
      "================================================================\n",
      "            Conv2d-1         [-1, 96, 112, 112]           4,704\n",
      "           Permute-2         [-1, 112, 112, 96]               0\n",
      "         LayerNorm-3         [-1, 112, 112, 96]             192\n",
      "            Linear-4          [-1, 15, 15, 512]           1,536\n",
      "              ReLU-5          [-1, 15, 15, 512]               0\n",
      "            Linear-6            [-1, 15, 15, 3]           1,536\n",
      "ShiftedWindowAttentionV2-7         [-1, 112, 112, 96]               0\n",
      "         LayerNorm-8         [-1, 112, 112, 96]             192\n",
      "   StochasticDepth-9         [-1, 112, 112, 96]               0\n",
      "           Linear-10        [-1, 112, 112, 384]          37,248\n",
      "             GELU-11        [-1, 112, 112, 384]               0\n",
      "          Dropout-12        [-1, 112, 112, 384]               0\n",
      "           Linear-13         [-1, 112, 112, 96]          36,960\n",
      "          Dropout-14         [-1, 112, 112, 96]               0\n",
      "        LayerNorm-15         [-1, 112, 112, 96]             192\n",
      "  StochasticDepth-16         [-1, 112, 112, 96]               0\n",
      "SwinTransformerBlockV2-17         [-1, 112, 112, 96]               0\n",
      "           Linear-18          [-1, 15, 15, 512]           1,536\n",
      "             ReLU-19          [-1, 15, 15, 512]               0\n",
      "           Linear-20            [-1, 15, 15, 3]           1,536\n",
      "ShiftedWindowAttentionV2-21         [-1, 112, 112, 96]               0\n",
      "        LayerNorm-22         [-1, 112, 112, 96]             192\n",
      "  StochasticDepth-23         [-1, 112, 112, 96]               0\n",
      "           Linear-24        [-1, 112, 112, 384]          37,248\n",
      "             GELU-25        [-1, 112, 112, 384]               0\n",
      "          Dropout-26        [-1, 112, 112, 384]               0\n",
      "           Linear-27         [-1, 112, 112, 96]          36,960\n",
      "          Dropout-28         [-1, 112, 112, 96]               0\n",
      "        LayerNorm-29         [-1, 112, 112, 96]             192\n",
      "  StochasticDepth-30         [-1, 112, 112, 96]               0\n",
      "SwinTransformerBlockV2-31         [-1, 112, 112, 96]               0\n",
      "           Linear-32          [-1, 56, 56, 192]          73,728\n",
      "        LayerNorm-33          [-1, 56, 56, 192]             384\n",
      "   PatchMergingV2-34          [-1, 56, 56, 192]               0\n",
      "           Linear-35          [-1, 15, 15, 512]           1,536\n",
      "             ReLU-36          [-1, 15, 15, 512]               0\n",
      "           Linear-37            [-1, 15, 15, 6]           3,072\n",
      "ShiftedWindowAttentionV2-38          [-1, 56, 56, 192]               0\n",
      "        LayerNorm-39          [-1, 56, 56, 192]             384\n",
      "  StochasticDepth-40          [-1, 56, 56, 192]               0\n",
      "           Linear-41          [-1, 56, 56, 768]         148,224\n",
      "             GELU-42          [-1, 56, 56, 768]               0\n",
      "          Dropout-43          [-1, 56, 56, 768]               0\n",
      "           Linear-44          [-1, 56, 56, 192]         147,648\n",
      "          Dropout-45          [-1, 56, 56, 192]               0\n",
      "        LayerNorm-46          [-1, 56, 56, 192]             384\n",
      "  StochasticDepth-47          [-1, 56, 56, 192]               0\n",
      "SwinTransformerBlockV2-48          [-1, 56, 56, 192]               0\n",
      "           Linear-49          [-1, 15, 15, 512]           1,536\n",
      "             ReLU-50          [-1, 15, 15, 512]               0\n",
      "           Linear-51            [-1, 15, 15, 6]           3,072\n",
      "ShiftedWindowAttentionV2-52          [-1, 56, 56, 192]               0\n",
      "        LayerNorm-53          [-1, 56, 56, 192]             384\n",
      "  StochasticDepth-54          [-1, 56, 56, 192]               0\n",
      "           Linear-55          [-1, 56, 56, 768]         148,224\n",
      "             GELU-56          [-1, 56, 56, 768]               0\n",
      "          Dropout-57          [-1, 56, 56, 768]               0\n",
      "           Linear-58          [-1, 56, 56, 192]         147,648\n",
      "          Dropout-59          [-1, 56, 56, 192]               0\n",
      "        LayerNorm-60          [-1, 56, 56, 192]             384\n",
      "  StochasticDepth-61          [-1, 56, 56, 192]               0\n",
      "SwinTransformerBlockV2-62          [-1, 56, 56, 192]               0\n",
      "           Linear-63          [-1, 28, 28, 384]         294,912\n",
      "        LayerNorm-64          [-1, 28, 28, 384]             768\n",
      "   PatchMergingV2-65          [-1, 28, 28, 384]               0\n",
      "           Linear-66          [-1, 15, 15, 512]           1,536\n",
      "             ReLU-67          [-1, 15, 15, 512]               0\n",
      "           Linear-68           [-1, 15, 15, 12]           6,144\n",
      "ShiftedWindowAttentionV2-69          [-1, 28, 28, 384]               0\n",
      "        LayerNorm-70          [-1, 28, 28, 384]             768\n",
      "  StochasticDepth-71          [-1, 28, 28, 384]               0\n",
      "           Linear-72         [-1, 28, 28, 1536]         591,360\n",
      "             GELU-73         [-1, 28, 28, 1536]               0\n",
      "          Dropout-74         [-1, 28, 28, 1536]               0\n",
      "           Linear-75          [-1, 28, 28, 384]         590,208\n",
      "          Dropout-76          [-1, 28, 28, 384]               0\n",
      "        LayerNorm-77          [-1, 28, 28, 384]             768\n",
      "  StochasticDepth-78          [-1, 28, 28, 384]               0\n",
      "SwinTransformerBlockV2-79          [-1, 28, 28, 384]               0\n",
      "           Linear-80          [-1, 15, 15, 512]           1,536\n",
      "             ReLU-81          [-1, 15, 15, 512]               0\n",
      "           Linear-82           [-1, 15, 15, 12]           6,144\n",
      "ShiftedWindowAttentionV2-83          [-1, 28, 28, 384]               0\n",
      "        LayerNorm-84          [-1, 28, 28, 384]             768\n",
      "  StochasticDepth-85          [-1, 28, 28, 384]               0\n",
      "           Linear-86         [-1, 28, 28, 1536]         591,360\n",
      "             GELU-87         [-1, 28, 28, 1536]               0\n",
      "          Dropout-88         [-1, 28, 28, 1536]               0\n",
      "           Linear-89          [-1, 28, 28, 384]         590,208\n",
      "          Dropout-90          [-1, 28, 28, 384]               0\n",
      "        LayerNorm-91          [-1, 28, 28, 384]             768\n",
      "  StochasticDepth-92          [-1, 28, 28, 384]               0\n",
      "SwinTransformerBlockV2-93          [-1, 28, 28, 384]               0\n",
      "           Linear-94          [-1, 15, 15, 512]           1,536\n",
      "             ReLU-95          [-1, 15, 15, 512]               0\n",
      "           Linear-96           [-1, 15, 15, 12]           6,144\n",
      "ShiftedWindowAttentionV2-97          [-1, 28, 28, 384]               0\n",
      "        LayerNorm-98          [-1, 28, 28, 384]             768\n",
      "  StochasticDepth-99          [-1, 28, 28, 384]               0\n",
      "          Linear-100         [-1, 28, 28, 1536]         591,360\n",
      "            GELU-101         [-1, 28, 28, 1536]               0\n",
      "         Dropout-102         [-1, 28, 28, 1536]               0\n",
      "          Linear-103          [-1, 28, 28, 384]         590,208\n",
      "         Dropout-104          [-1, 28, 28, 384]               0\n",
      "       LayerNorm-105          [-1, 28, 28, 384]             768\n",
      " StochasticDepth-106          [-1, 28, 28, 384]               0\n",
      "SwinTransformerBlockV2-107          [-1, 28, 28, 384]               0\n",
      "          Linear-108          [-1, 15, 15, 512]           1,536\n",
      "            ReLU-109          [-1, 15, 15, 512]               0\n",
      "          Linear-110           [-1, 15, 15, 12]           6,144\n",
      "ShiftedWindowAttentionV2-111          [-1, 28, 28, 384]               0\n",
      "       LayerNorm-112          [-1, 28, 28, 384]             768\n",
      " StochasticDepth-113          [-1, 28, 28, 384]               0\n",
      "          Linear-114         [-1, 28, 28, 1536]         591,360\n",
      "            GELU-115         [-1, 28, 28, 1536]               0\n",
      "         Dropout-116         [-1, 28, 28, 1536]               0\n",
      "          Linear-117          [-1, 28, 28, 384]         590,208\n",
      "         Dropout-118          [-1, 28, 28, 384]               0\n",
      "       LayerNorm-119          [-1, 28, 28, 384]             768\n",
      " StochasticDepth-120          [-1, 28, 28, 384]               0\n",
      "SwinTransformerBlockV2-121          [-1, 28, 28, 384]               0\n",
      "          Linear-122          [-1, 15, 15, 512]           1,536\n",
      "            ReLU-123          [-1, 15, 15, 512]               0\n",
      "          Linear-124           [-1, 15, 15, 12]           6,144\n",
      "ShiftedWindowAttentionV2-125          [-1, 28, 28, 384]               0\n",
      "       LayerNorm-126          [-1, 28, 28, 384]             768\n",
      " StochasticDepth-127          [-1, 28, 28, 384]               0\n",
      "          Linear-128         [-1, 28, 28, 1536]         591,360\n",
      "            GELU-129         [-1, 28, 28, 1536]               0\n",
      "         Dropout-130         [-1, 28, 28, 1536]               0\n",
      "          Linear-131          [-1, 28, 28, 384]         590,208\n",
      "         Dropout-132          [-1, 28, 28, 384]               0\n",
      "       LayerNorm-133          [-1, 28, 28, 384]             768\n",
      " StochasticDepth-134          [-1, 28, 28, 384]               0\n",
      "SwinTransformerBlockV2-135          [-1, 28, 28, 384]               0\n",
      "          Linear-136          [-1, 15, 15, 512]           1,536\n",
      "            ReLU-137          [-1, 15, 15, 512]               0\n",
      "          Linear-138           [-1, 15, 15, 12]           6,144\n",
      "ShiftedWindowAttentionV2-139          [-1, 28, 28, 384]               0\n",
      "       LayerNorm-140          [-1, 28, 28, 384]             768\n",
      " StochasticDepth-141          [-1, 28, 28, 384]               0\n",
      "          Linear-142         [-1, 28, 28, 1536]         591,360\n",
      "            GELU-143         [-1, 28, 28, 1536]               0\n",
      "         Dropout-144         [-1, 28, 28, 1536]               0\n",
      "          Linear-145          [-1, 28, 28, 384]         590,208\n",
      "         Dropout-146          [-1, 28, 28, 384]               0\n",
      "       LayerNorm-147          [-1, 28, 28, 384]             768\n",
      " StochasticDepth-148          [-1, 28, 28, 384]               0\n",
      "SwinTransformerBlockV2-149          [-1, 28, 28, 384]               0\n",
      "          Linear-150          [-1, 14, 14, 768]       1,179,648\n",
      "       LayerNorm-151          [-1, 14, 14, 768]           1,536\n",
      "  PatchMergingV2-152          [-1, 14, 14, 768]               0\n",
      "          Linear-153          [-1, 15, 15, 512]           1,536\n",
      "            ReLU-154          [-1, 15, 15, 512]               0\n",
      "          Linear-155           [-1, 15, 15, 24]          12,288\n",
      "ShiftedWindowAttentionV2-156          [-1, 14, 14, 768]               0\n",
      "       LayerNorm-157          [-1, 14, 14, 768]           1,536\n",
      " StochasticDepth-158          [-1, 14, 14, 768]               0\n",
      "          Linear-159         [-1, 14, 14, 3072]       2,362,368\n",
      "            GELU-160         [-1, 14, 14, 3072]               0\n",
      "         Dropout-161         [-1, 14, 14, 3072]               0\n",
      "          Linear-162          [-1, 14, 14, 768]       2,360,064\n",
      "         Dropout-163          [-1, 14, 14, 768]               0\n",
      "       LayerNorm-164          [-1, 14, 14, 768]           1,536\n",
      " StochasticDepth-165          [-1, 14, 14, 768]               0\n",
      "SwinTransformerBlockV2-166          [-1, 14, 14, 768]               0\n",
      "          Linear-167          [-1, 15, 15, 512]           1,536\n",
      "            ReLU-168          [-1, 15, 15, 512]               0\n",
      "          Linear-169           [-1, 15, 15, 24]          12,288\n",
      "ShiftedWindowAttentionV2-170          [-1, 14, 14, 768]               0\n",
      "       LayerNorm-171          [-1, 14, 14, 768]           1,536\n",
      " StochasticDepth-172          [-1, 14, 14, 768]               0\n",
      "          Linear-173         [-1, 14, 14, 3072]       2,362,368\n",
      "            GELU-174         [-1, 14, 14, 3072]               0\n",
      "         Dropout-175         [-1, 14, 14, 3072]               0\n",
      "          Linear-176          [-1, 14, 14, 768]       2,360,064\n",
      "         Dropout-177          [-1, 14, 14, 768]               0\n",
      "       LayerNorm-178          [-1, 14, 14, 768]           1,536\n",
      " StochasticDepth-179          [-1, 14, 14, 768]               0\n",
      "SwinTransformerBlockV2-180          [-1, 14, 14, 768]               0\n",
      "       LayerNorm-181          [-1, 14, 14, 768]           1,536\n",
      "         Permute-182          [-1, 768, 14, 14]               0\n",
      "          Conv2d-183         [-1, 1024, 14, 14]         786,432\n",
      "     BatchNorm2d-184         [-1, 1024, 14, 14]           2,048\n",
      "            ReLU-185         [-1, 1024, 14, 14]               0\n",
      "          Conv2d-186         [-1, 1024, 14, 14]       9,437,184\n",
      "     BatchNorm2d-187         [-1, 1024, 14, 14]           2,048\n",
      "            ReLU-188         [-1, 1024, 14, 14]               0\n",
      "          Conv2d-189         [-1, 1024, 14, 14]       9,437,184\n",
      "     BatchNorm2d-190         [-1, 1024, 14, 14]           2,048\n",
      "            ReLU-191         [-1, 1024, 14, 14]               0\n",
      "          Conv2d-192         [-1, 1024, 14, 14]       9,437,184\n",
      "     BatchNorm2d-193         [-1, 1024, 14, 14]           2,048\n",
      "            ReLU-194         [-1, 1024, 14, 14]               0\n",
      "          Conv2d-195           [-1, 12, 14, 14]          12,288\n",
      "AdaptiveAvgPool2d-196             [-1, 12, 7, 7]               0\n",
      "================================================================\n",
      "Total params: 48,057,056\n",
      "Trainable params: 48,057,056\n",
      "Non-trainable params: 0\n",
      "----------------------------------------------------------------\n",
      "Input size (MB): 2.30\n",
      "Forward/backward pass size (MB): 966.52\n",
      "Params size (MB): 183.32\n",
      "Estimated Total Size (MB): 1152.14\n",
      "----------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "torchsummary.summary(model, (3,448,448))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "4cf3af4c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 12, 7, 7])\n"
     ]
    }
   ],
   "source": [
    "x = torch.randn(1, 3, 448, 448).to(device)\n",
    "with torch.no_grad():\n",
    "    y = model(x)\n",
    "print(y.shape)"
   ]
  },
  {
   "cell_type": "raw",
   "id": "f4c05720",
   "metadata": {
    "scrolled": true
   },
   "source": [
    "# data_dir = \"/content/drive/MyDrive/fastCamMedicalProj/DATASET/DATASET/Detection/\"\n",
    "BATCH_SIZE = 1\n",
    "\n",
    "# trainset = Detection_dataset(data_dir=data_dir, phase=\"train\", transformer=transformer)\n",
    "NECK_PATH = '/home/host_data/PET_data/Neck'\n",
    "BODY_PATH = '/home/host_data/PET_data/Body'\n",
    "trainset=PET_dataset(part='body',neck_dir=NECK_PATH,body_dir=BODY_PATH,phase='train', transformer=transformer)\n",
    "trainloader = DataLoader(trainset, batch_size=BATCH_SIZE, shuffle=False, collate_fn=collate_fn)\n",
    "\n",
    "model = YOLO_SWIN(num_classes=NUM_CLASSES)\n",
    "\n",
    "for index, batch in enumerate(trainloader):\n",
    "    images = batch[0]\n",
    "    targets = batch[1]\n",
    "    filenames = batch[2]\n",
    "    \n",
    "    predictions = model(images)\n",
    "    print(f\"filename:{filenames}, target:{targets}\")\n",
    "#     print(f\"{index}--input shape:{images.shape} -> output shape: {predictions.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8da970d7",
   "metadata": {},
   "source": [
    "# Loss func"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "3c66945c",
   "metadata": {},
   "outputs": [],
   "source": [
    "class YOLO_LOSS():\n",
    "    def __init__(self, num_classes, device, lambda_coord=5., lambda_noobj=0.5):\n",
    "        self.num_classes = num_classes\n",
    "        self.device = device\n",
    "        self.grid_size = 7\n",
    "        self.lambda_coord = lambda_coord\n",
    "        self.lambda_noobj = lambda_noobj\n",
    "        self.mse_loss = nn.MSELoss(reduction=\"sum\")\n",
    "\n",
    "    def __call__(self, predictions, targets):\n",
    "        self.batch_size, _, _, _ = predictions.shape\n",
    "        groundtruths = self.build_batch_target_grid(targets)\n",
    "        groundtruths = groundtruths.to(self.device)\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            iou1 = self.get_IoU(predictions[:, 1:5, ...], groundtruths[:, 1:5, ...])\n",
    "            iou2 = self.get_IoU(predictions[:, 6:10, ...], groundtruths[:, 1:5, ...])\n",
    "\n",
    "        ious = torch.stack([iou1, iou2], dim=1)\n",
    "        max_iou, best_box = ious.max(dim=1, keepdim=True)\n",
    "        max_iou = torch.cat([max_iou, max_iou], dim=1)\n",
    "        best_box = torch.cat([best_box.eq(0), best_box.eq(1)], dim=1)\n",
    "\n",
    "        predictions_ = predictions[:, :5*2, ...].reshape(self.batch_size, 2, 5, self.grid_size, self.grid_size)\n",
    "        obj_pred = predictions_[:, :, 0, ...]\n",
    "        xy_pred = predictions_[:, :, 1:3, ...]\n",
    "        wh_pred = predictions_[:, :, 3:5, ...]\n",
    "        cls_pred = predictions[:, 5*2:, ...]\n",
    "\n",
    "        groundtruths_ = groundtruths[:, :5, ...].reshape(self.batch_size, 1, 5, self.grid_size, self.grid_size)\n",
    "        obj_target = groundtruths_[:, :, 0, ...]\n",
    "        xy_target = groundtruths_[:, :, 1:3, ...]\n",
    "        wh_target= groundtruths_[:, :, 3:5, ...]\n",
    "        cls_target = groundtruths[:, 5:, ...]\n",
    "        \n",
    "        positive = obj_target * best_box\n",
    "\n",
    "        obj_loss = self.mse_loss(positive * obj_pred, positive * ious)\n",
    "        noobj_loss = self.mse_loss((1 - positive) * obj_pred, ious*0)\n",
    "        xy_loss = self.mse_loss(positive.unsqueeze(dim=2) * xy_pred, positive.unsqueeze(dim=2) * xy_target)\n",
    "        wh_loss = self.mse_loss(positive.unsqueeze(dim=2) * (wh_pred.sign() * (wh_pred.abs() + 1e-8).sqrt()),\n",
    "                           positive.unsqueeze(dim=2) * (wh_target + 1e-8).sqrt())\n",
    "        cls_loss = self.mse_loss(obj_target * cls_pred, cls_target)\n",
    "        \n",
    "        obj_loss /= self.batch_size\n",
    "        noobj_loss /= self.batch_size\n",
    "        bbox_loss = (xy_loss+wh_loss) / self.batch_size\n",
    "        cls_loss /= self.batch_size\n",
    "        \n",
    "        total_loss = obj_loss + self.lambda_noobj*noobj_loss + self.lambda_coord*bbox_loss + cls_loss\n",
    "        return total_loss, (obj_loss.item(), noobj_loss.item(), bbox_loss.item(), cls_loss.item())\n",
    "    \n",
    "    def build_target_grid(self, target):\n",
    "        target_grid = torch.zeros((1+4+self.num_classes, self.grid_size, self.grid_size), device=self.device)\n",
    "\n",
    "        for gt in target:\n",
    "            xc, yc, w, h, cls_id = gt\n",
    "            xn = (xc % (1/self.grid_size))\n",
    "            yn = (yc % (1/self.grid_size))\n",
    "            cls_id = int(cls_id)\n",
    "\n",
    "            i_grid = int(xc * self.grid_size)\n",
    "            j_grid = int(yc * self.grid_size)\n",
    "            target_grid[0, j_grid, i_grid] = 1\n",
    "            target_grid[1:5, j_grid, i_grid] = torch.Tensor([xn,yn,w,h])\n",
    "#             print(5+cls_id, j_grid, i_grid)\n",
    "            target_grid[5+cls_id, j_grid, i_grid] = 1\n",
    "\n",
    "        return target_grid\n",
    "    \n",
    "    def build_batch_target_grid(self, targets):\n",
    "        target_grid_batch = torch.stack([self.build_target_grid(target) for target in targets], dim=0)\n",
    "        return target_grid_batch\n",
    "    \n",
    "    def get_IoU(self, cbox1, cbox2):\n",
    "        box1 = self.xywh_to_xyxy(cbox1)\n",
    "        box2 = self.xywh_to_xyxy(cbox2)\n",
    "\n",
    "        x1 = torch.max(box1[:, 0, ...], box2[:, 0, ...])\n",
    "        y1 = torch.max(box1[:, 1, ...], box2[:, 1, ...])\n",
    "        x2 = torch.min(box1[:, 2, ...], box2[:, 2, ...])\n",
    "        y2 = torch.min(box1[:, 3, ...], box2[:, 3, ...])\n",
    "\n",
    "        intersection = (x2-x1).clamp(min=0) * (y2-y1).clamp(min=0)\n",
    "        union = abs(cbox1[:, 2, ...]*cbox1[:, 3, ...]) + \\\n",
    "                abs(cbox2[:, 2, ...]*cbox2[:, 3, ...]) - intersection\n",
    "\n",
    "        intersection[intersection.gt(0)] = intersection[intersection.gt(0)] / union[intersection.gt(0)]\n",
    "        return intersection\n",
    "    \n",
    "    def generate_xy_normed_grid(self):\n",
    "        y_offset, x_offset = torch.meshgrid(torch.arange(self.grid_size), torch.arange(self.grid_size))\n",
    "        xy_grid = torch.stack([x_offset, y_offset], dim=0)\n",
    "        xy_normed_grid = xy_grid / self.grid_size\n",
    "        return xy_normed_grid.to(self.device)\n",
    "\n",
    "    def xywh_to_xyxy(self, bboxes):\n",
    "        xy_normed_grid = self.generate_xy_normed_grid()\n",
    "        xcyc = bboxes[:,0:2,...] + xy_normed_grid.tile(self.batch_size, 1,1,1)\n",
    "        wh = bboxes[:,2:4,...]\n",
    "        x1y1 = xcyc - (wh/2)\n",
    "        x2y2 = xcyc + (wh/2)\n",
    "        return torch.cat([x1y1, x2y2], dim=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c46ad931",
   "metadata": {},
   "source": [
    "## Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "b1729df2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_one_epoch(dataloaders, model, criterion, optimizer, device):\n",
    "    train_loss = defaultdict(float)\n",
    "    val_loss = defaultdict(float)\n",
    "    \n",
    "    for phase in [\"train\", \"val\"]:\n",
    "        if phase == \"train\":\n",
    "            model.train()\n",
    "        else:\n",
    "            model.eval()\n",
    "        \n",
    "        running_loss = defaultdict(float)\n",
    "        for index, batch in enumerate(dataloaders[phase]):\n",
    "            images = batch[0].to(device)\n",
    "            targets = batch[1]\n",
    "            filenames = batch[2]\n",
    "            \n",
    "            with torch.set_grad_enabled(phase == \"train\"): # phase가 train 일때만 gradient 추적기능을 킨다.\n",
    "                predictions = model(images) #prediction shape=> B,12,7,7\n",
    "#             print(f\"predictions:{predictions}, \\ntargets: {targets}\\n\")\n",
    "            loss, (obj_loss, noobj_loss, bbox_loss, cls_loss) = criterion(predictions, targets)\n",
    "#             print(f\"loss:{loss}, obj_loss:{obj_loss}, noobj_loss:{noobj_loss}\\nbbox_loss:{bbox_loss}, cls_loss:{cls_loss}\\n--------------\\n\")\n",
    "            if phase == \"train\":\n",
    "                optimizer.zero_grad()\n",
    "                loss.backward()\n",
    "                optimizer.step()\n",
    "                \n",
    "                # 현재 epoch단계에서 loss가 얼마인지 running loss 가출력\n",
    "                running_loss[\"total_loss\"] += loss.item()\n",
    "                running_loss[\"obj_loss\"] += obj_loss\n",
    "                running_loss[\"noobj_loss\"] += noobj_loss\n",
    "                running_loss[\"bbox_loss\"] += bbox_loss\n",
    "                running_loss[\"cls_loss\"] += cls_loss\n",
    "                \n",
    "                train_loss[\"total_loss\"] += loss.item()\n",
    "                train_loss[\"obj_loss\"] += obj_loss\n",
    "                train_loss[\"noobj_loss\"] += noobj_loss\n",
    "                train_loss[\"bbox_loss\"] += bbox_loss\n",
    "                train_loss[\"cls_loss\"] += cls_loss\n",
    "                \n",
    "                if (index > 0) and (index % VERBOSE_FREQ) == 0:\n",
    "                    text = f\"<<<iteration:[{index}/{len(dataloaders[phase])}] - \"\n",
    "                    for k, v in running_loss.items():\n",
    "                        text += f\"{k}: {v/VERBOSE_FREQ:.4f}  \"\n",
    "                        running_loss[k] = 0.\n",
    "                    print(text)\n",
    "            else:\n",
    "                val_loss[\"total_loss\"] += loss.item()\n",
    "                val_loss[\"obj_loss\"] += obj_loss\n",
    "                val_loss[\"noobj_loss\"] += noobj_loss\n",
    "                val_loss[\"bbox_loss\"] += bbox_loss\n",
    "                val_loss[\"cls_loss\"] += cls_loss\n",
    "\n",
    "    for k in train_loss.keys():\n",
    "        train_loss[k] /= len(dataloaders[\"train\"])\n",
    "        val_loss[k] /= len(dataloaders[\"val\"])\n",
    "    return train_loss, val_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "cc20c145",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_dataloader(PATH, batch_size=2, aug_factor=0):\n",
    "    IMAGE_SIZE = 448\n",
    "    transformer = A.Compose([\n",
    "            A.Resize(height=IMAGE_SIZE, width=IMAGE_SIZE),\n",
    "            A.Normalize(mean=(0.485, 0.456, 0.406),std=(0.229, 0.224, 0.225)),\n",
    "            ToTensorV2(),\n",
    "        ],\n",
    "        bbox_params=A.BboxParams(format='yolo', label_fields=['class_ids']),\n",
    "    )\n",
    "    augmentator=A.Compose([\n",
    "        A.HorizontalFlip(p=0.7),\n",
    "        A.VerticalFlip (p=0.5),\n",
    "        A.HueSaturationValue(p=0.5),\n",
    "        A.Resize(height=IMAGE_SIZE, width=IMAGE_SIZE),\n",
    "        A.Normalize(mean=(0.485, 0.456, 0.406),std=(0.229, 0.224, 0.225)),\n",
    "        ToTensorV2(),\n",
    "        ],\n",
    "        bbox_params=A.BboxParams(format='yolo', label_fields=['class_ids']),\n",
    "    )\n",
    "    \n",
    "#     Radio_dataset(path=PATH, phase='train', transformer=transformer, aug=None)\n",
    "#     trainset_no_aug=Radio_dataset(path=PATH, phase='train', transformer=transformer, aug=augmentator, aug_factor=2)\n",
    "    dataloaders = {}\n",
    "    train_dataset=Radio_dataset(path=PATH, phase='train', transformer=transformer, aug=augmentator, aug_factor=2)\n",
    "    dataloaders[\"train\"] = DataLoader(train_dataset, batch_size=batch_size, shuffle=True, collate_fn=collate_fn)\n",
    "\n",
    "    val_dataset=Radio_dataset(path=PATH, phase='valid', transformer=transformer, aug=augmentator, aug_factor=2)\n",
    "    dataloaders[\"val\"] = DataLoader(val_dataset, batch_size=batch_size, shuffle=False, collate_fn=collate_fn)\n",
    "    print(f\"trainset:{len(train_dataset)} validset:{len(val_dataset)}\")\n",
    "    return dataloaders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "2771b438",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "start making augmented images-- augmented factor:2\n",
      "total length of augmented images: 3898\n",
      "start making augmented images-- augmented factor:2\n",
      "total length of augmented images: 1130\n",
      "trainset:3898 validset:1130\n"
     ]
    }
   ],
   "source": [
    "# data_dir = \"/content/drive/MyDrive/fastCamMedicalProj/DATASET/DATASET/Detection/\"\n",
    "# NECK_PATH = '/home/host_data/PET_data/Neck'\n",
    "# BODY_PATH = '/home/host_data/PET_data/Body'\n",
    "# NECK_PATH = '/home/host_data/PET_data_IP_AUG/aug_patched_Neck'\n",
    "# BODY_PATH = '/home/host_data/PET_data_IP_AUG/Body'\n",
    "\n",
    "path='/home/host_data/radio_signal_data_organized/'\n",
    "is_cuda = True\n",
    "\n",
    "NUM_CLASSES = 2\n",
    "IMAGE_SIZE = 448\n",
    "BATCH_SIZE = 16\n",
    "VERBOSE_FREQ = 20\n",
    "LR=0.0001\n",
    "AUG_FACTOR=4\n",
    "PATCH_FACTOR=50\n",
    "BACKBONE=\"YOLO_SWIN_T\"\n",
    "PART=\"RADIO\"\n",
    "num_epochs = 100\n",
    "# DEVICE = torch.device('cuda' if torch.cuda.is_available and is_cuda else 'cpu')\n",
    "\n",
    "dataloaders = build_dataloader(PATH=path,batch_size=BATCH_SIZE, aug_factor=AUG_FACTOR)\n",
    "model = YOLO_SWIN(num_classes=NUM_CLASSES)\n",
    "model = model.to(device)\n",
    "criterion = YOLO_LOSS(num_classes=NUM_CLASSES, device=device)\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=LR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "060a24e6",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mgomduribo\u001b[0m (\u001b[33murp\u001b[0m). Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.15.12 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.15.11"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/workspace/Plastic_Bottle_defect_detection/experiments/wandb/run-20231104_154304-g53vekx1</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/urp/yolo_swin_RADIO/runs/g53vekx1' target=\"_blank\">drawn-hill-2</a></strong> to <a href='https://wandb.ai/urp/yolo_swin_RADIO' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/urp/yolo_swin_RADIO' target=\"_blank\">https://wandb.ai/urp/yolo_swin_RADIO</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/urp/yolo_swin_RADIO/runs/g53vekx1' target=\"_blank\">https://wandb.ai/urp/yolo_swin_RADIO/runs/g53vekx1</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<button onClick=\"this.nextSibling.style.display='block';this.style.display='none';\">Display W&B run</button><iframe src='https://wandb.ai/urp/yolo_swin_RADIO/runs/g53vekx1?jupyter=true' style='border:none;width:100%;height:420px;display:none;'></iframe>"
      ],
      "text/plain": [
       "<wandb.sdk.wandb_run.Run at 0x7fe8814aaca0>"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import wandb\n",
    "import random\n",
    "\n",
    "# start a new wandb run to track this script\n",
    "wandb.init(\n",
    "    # set the wandb project where this run will be logged\n",
    "    project=\"yolo_swin_RADIO\",\n",
    "    \n",
    "    # track hyperparameters and run metadata\n",
    "    config={\n",
    "    \"learning_rate\": LR,\n",
    "    \"batch_size\": BATCH_SIZE,\n",
    "    \"architecture\": BACKBONE,\n",
    "    \"dataset\": PART,\n",
    "    \"epochs\": num_epochs,\n",
    "    \"patch factor\":PATCH_FACTOR,\n",
    "    \"aug factor\":AUG_FACTOR,\n",
    "    }\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "8ebab5dc",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.8/dist-packages/torch/functional.py:504: UserWarning: torch.meshgrid: in an upcoming release, it will be required to pass the indexing argument. (Triggered internally at /opt/pytorch/pytorch/aten/src/ATen/native/TensorShape.cpp:3423.)\n",
      "  return _VF.meshgrid(tensors, **kwargs)  # type: ignore[attr-defined]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<<<iteration:[20/244] - total_loss: 8.3863  obj_loss: 0.1300  noobj_loss: 4.1590  bbox_loss: 1.1092  cls_loss: 0.6306  \n",
      "<<<iteration:[40/244] - total_loss: 3.1869  obj_loss: 0.0331  noobj_loss: 2.5107  bbox_loss: 0.2963  cls_loss: 0.4168  \n",
      "<<<iteration:[60/244] - total_loss: 2.4855  obj_loss: 0.0258  noobj_loss: 2.1914  bbox_loss: 0.2101  cls_loss: 0.3134  \n",
      "<<<iteration:[80/244] - total_loss: 2.3666  obj_loss: 0.0188  noobj_loss: 2.0186  bbox_loss: 0.2095  cls_loss: 0.2907  \n",
      "<<<iteration:[100/244] - total_loss: 2.2551  obj_loss: 0.0177  noobj_loss: 1.7921  bbox_loss: 0.2086  cls_loss: 0.2983  \n",
      "<<<iteration:[120/244] - total_loss: 2.0739  obj_loss: 0.0193  noobj_loss: 1.6154  bbox_loss: 0.1973  cls_loss: 0.2605  \n",
      "<<<iteration:[140/244] - total_loss: 2.3663  obj_loss: 0.0208  noobj_loss: 1.8065  bbox_loss: 0.2327  cls_loss: 0.2787  \n",
      "<<<iteration:[160/244] - total_loss: 1.9459  obj_loss: 0.0163  noobj_loss: 1.3542  bbox_loss: 0.1976  cls_loss: 0.2647  \n",
      "<<<iteration:[180/244] - total_loss: 1.7824  obj_loss: 0.0174  noobj_loss: 1.2662  bbox_loss: 0.1692  cls_loss: 0.2860  \n",
      "<<<iteration:[200/244] - total_loss: 1.5849  obj_loss: 0.0180  noobj_loss: 1.1841  bbox_loss: 0.1471  cls_loss: 0.2395  \n",
      "<<<iteration:[220/244] - total_loss: 1.9584  obj_loss: 0.0135  noobj_loss: 1.0901  bbox_loss: 0.2362  cls_loss: 0.2189  \n",
      "<<<iteration:[240/244] - total_loss: 1.5106  obj_loss: 0.0171  noobj_loss: 1.0570  bbox_loss: 0.1480  cls_loss: 0.2249  \n",
      "\n",
      "epoch:1/100 - Train Loss: 2.6296, Val Loss: 1.5215\n",
      "\n",
      "<<<iteration:[20/244] - total_loss: 1.4035  obj_loss: 0.0171  noobj_loss: 1.0436  bbox_loss: 0.1230  cls_loss: 0.2496  \n",
      "<<<iteration:[40/244] - total_loss: 1.2628  obj_loss: 0.0155  noobj_loss: 0.9069  bbox_loss: 0.1137  cls_loss: 0.2252  \n",
      "<<<iteration:[60/244] - total_loss: 1.1407  obj_loss: 0.0151  noobj_loss: 0.8294  bbox_loss: 0.1005  cls_loss: 0.2081  \n",
      "<<<iteration:[80/244] - total_loss: 1.3773  obj_loss: 0.0140  noobj_loss: 0.7786  bbox_loss: 0.1493  cls_loss: 0.2274  \n",
      "<<<iteration:[100/244] - total_loss: 1.0943  obj_loss: 0.0153  noobj_loss: 0.7328  bbox_loss: 0.1045  cls_loss: 0.1901  \n",
      "<<<iteration:[120/244] - total_loss: 0.9928  obj_loss: 0.0199  noobj_loss: 0.7486  bbox_loss: 0.0852  cls_loss: 0.1725  \n",
      "<<<iteration:[140/244] - total_loss: 1.0672  obj_loss: 0.0168  noobj_loss: 0.7133  bbox_loss: 0.0962  cls_loss: 0.2126  \n",
      "<<<iteration:[160/244] - total_loss: 0.9481  obj_loss: 0.0181  noobj_loss: 0.6470  bbox_loss: 0.0779  cls_loss: 0.2173  \n",
      "<<<iteration:[180/244] - total_loss: 0.8886  obj_loss: 0.0198  noobj_loss: 0.6327  bbox_loss: 0.0667  cls_loss: 0.2188  \n",
      "<<<iteration:[200/244] - total_loss: 0.9400  obj_loss: 0.0190  noobj_loss: 0.6017  bbox_loss: 0.0767  cls_loss: 0.2365  \n",
      "<<<iteration:[220/244] - total_loss: 0.8608  obj_loss: 0.0226  noobj_loss: 0.5314  bbox_loss: 0.0715  cls_loss: 0.2152  \n",
      "<<<iteration:[240/244] - total_loss: 0.9128  obj_loss: 0.0198  noobj_loss: 0.5353  bbox_loss: 0.0840  cls_loss: 0.2055  \n",
      "\n",
      "epoch:2/100 - Train Loss: 1.0662, Val Loss: 0.7228\n",
      "\n",
      "<<<iteration:[20/244] - total_loss: 0.7834  obj_loss: 0.0259  noobj_loss: 0.4892  bbox_loss: 0.0570  cls_loss: 0.2280  \n",
      "<<<iteration:[40/244] - total_loss: 0.7535  obj_loss: 0.0257  noobj_loss: 0.5118  bbox_loss: 0.0579  cls_loss: 0.1824  \n",
      "<<<iteration:[60/244] - total_loss: 0.8196  obj_loss: 0.0183  noobj_loss: 0.6006  bbox_loss: 0.0581  cls_loss: 0.2106  \n",
      "<<<iteration:[80/244] - total_loss: 0.7760  obj_loss: 0.0208  noobj_loss: 0.5252  bbox_loss: 0.0574  cls_loss: 0.2057  \n",
      "<<<iteration:[100/244] - total_loss: 0.6470  obj_loss: 0.0307  noobj_loss: 0.3641  bbox_loss: 0.0462  cls_loss: 0.2034  \n",
      "<<<iteration:[120/244] - total_loss: 0.5796  obj_loss: 0.0274  noobj_loss: 0.3521  bbox_loss: 0.0412  cls_loss: 0.1701  \n",
      "<<<iteration:[140/244] - total_loss: 0.6689  obj_loss: 0.0286  noobj_loss: 0.3677  bbox_loss: 0.0522  cls_loss: 0.1953  \n",
      "<<<iteration:[160/244] - total_loss: 0.6246  obj_loss: 0.0245  noobj_loss: 0.3436  bbox_loss: 0.0401  cls_loss: 0.2278  \n",
      "<<<iteration:[180/244] - total_loss: 0.5325  obj_loss: 0.0304  noobj_loss: 0.2924  bbox_loss: 0.0364  cls_loss: 0.1738  \n",
      "<<<iteration:[200/244] - total_loss: 0.5742  obj_loss: 0.0306  noobj_loss: 0.2997  bbox_loss: 0.0414  cls_loss: 0.1865  \n",
      "<<<iteration:[220/244] - total_loss: 0.5335  obj_loss: 0.0284  noobj_loss: 0.2860  bbox_loss: 0.0392  cls_loss: 0.1660  \n",
      "<<<iteration:[240/244] - total_loss: 0.5829  obj_loss: 0.0296  noobj_loss: 0.3704  bbox_loss: 0.0358  cls_loss: 0.1890  \n",
      "\n",
      "epoch:3/100 - Train Loss: 0.6540, Val Loss: 0.5501\n",
      "\n",
      "<<<iteration:[20/244] - total_loss: 0.5839  obj_loss: 0.0321  noobj_loss: 0.3221  bbox_loss: 0.0385  cls_loss: 0.1981  \n",
      "<<<iteration:[40/244] - total_loss: 0.5422  obj_loss: 0.0267  noobj_loss: 0.2892  bbox_loss: 0.0332  cls_loss: 0.2050  \n",
      "<<<iteration:[60/244] - total_loss: 0.5147  obj_loss: 0.0370  noobj_loss: 0.2639  bbox_loss: 0.0317  cls_loss: 0.1871  \n",
      "<<<iteration:[80/244] - total_loss: 0.5057  obj_loss: 0.0274  noobj_loss: 0.2696  bbox_loss: 0.0364  cls_loss: 0.1616  \n",
      "<<<iteration:[100/244] - total_loss: 0.4941  obj_loss: 0.0325  noobj_loss: 0.2359  bbox_loss: 0.0309  cls_loss: 0.1892  \n",
      "<<<iteration:[120/244] - total_loss: 0.5150  obj_loss: 0.0346  noobj_loss: 0.2692  bbox_loss: 0.0383  cls_loss: 0.1542  \n",
      "<<<iteration:[140/244] - total_loss: 0.5066  obj_loss: 0.0307  noobj_loss: 0.2487  bbox_loss: 0.0295  cls_loss: 0.2043  \n",
      "<<<iteration:[160/244] - total_loss: 0.4873  obj_loss: 0.0329  noobj_loss: 0.2458  bbox_loss: 0.0305  cls_loss: 0.1791  \n",
      "<<<iteration:[180/244] - total_loss: 0.4722  obj_loss: 0.0350  noobj_loss: 0.2485  bbox_loss: 0.0267  cls_loss: 0.1797  \n",
      "<<<iteration:[200/244] - total_loss: 0.4218  obj_loss: 0.0406  noobj_loss: 0.2185  bbox_loss: 0.0230  cls_loss: 0.1567  \n",
      "<<<iteration:[220/244] - total_loss: 0.5344  obj_loss: 0.0337  noobj_loss: 0.2332  bbox_loss: 0.0337  cls_loss: 0.2155  \n",
      "<<<iteration:[240/244] - total_loss: 0.4399  obj_loss: 0.0390  noobj_loss: 0.2012  bbox_loss: 0.0222  cls_loss: 0.1890  \n",
      "\n",
      "epoch:4/100 - Train Loss: 0.4996, Val Loss: 0.4505\n",
      "\n",
      "<<<iteration:[20/244] - total_loss: 0.4739  obj_loss: 0.0379  noobj_loss: 0.2133  bbox_loss: 0.0281  cls_loss: 0.1888  \n",
      "<<<iteration:[40/244] - total_loss: 0.4244  obj_loss: 0.0403  noobj_loss: 0.1919  bbox_loss: 0.0240  cls_loss: 0.1682  \n",
      "<<<iteration:[60/244] - total_loss: 0.4067  obj_loss: 0.0395  noobj_loss: 0.2011  bbox_loss: 0.0196  cls_loss: 0.1687  \n",
      "<<<iteration:[80/244] - total_loss: 0.4564  obj_loss: 0.0468  noobj_loss: 0.1823  bbox_loss: 0.0223  cls_loss: 0.2069  \n",
      "<<<iteration:[100/244] - total_loss: 0.4170  obj_loss: 0.0382  noobj_loss: 0.1729  bbox_loss: 0.0245  cls_loss: 0.1698  \n",
      "<<<iteration:[120/244] - total_loss: 0.3938  obj_loss: 0.0372  noobj_loss: 0.1716  bbox_loss: 0.0206  cls_loss: 0.1676  \n",
      "<<<iteration:[140/244] - total_loss: 0.4060  obj_loss: 0.0387  noobj_loss: 0.1796  bbox_loss: 0.0202  cls_loss: 0.1766  \n",
      "<<<iteration:[160/244] - total_loss: 0.3756  obj_loss: 0.0408  noobj_loss: 0.1620  bbox_loss: 0.0191  cls_loss: 0.1580  \n",
      "<<<iteration:[180/244] - total_loss: 0.3893  obj_loss: 0.0399  noobj_loss: 0.1534  bbox_loss: 0.0188  cls_loss: 0.1788  \n",
      "<<<iteration:[200/244] - total_loss: 0.3776  obj_loss: 0.0392  noobj_loss: 0.1516  bbox_loss: 0.0266  cls_loss: 0.1297  \n",
      "<<<iteration:[220/244] - total_loss: 0.3960  obj_loss: 0.0474  noobj_loss: 0.1520  bbox_loss: 0.0207  cls_loss: 0.1691  \n",
      "<<<iteration:[240/244] - total_loss: 0.3786  obj_loss: 0.0485  noobj_loss: 0.1514  bbox_loss: 0.0187  cls_loss: 0.1608  \n",
      "\n",
      "epoch:5/100 - Train Loss: 0.4055, Val Loss: 0.3542\n",
      "\n",
      "<<<iteration:[20/244] - total_loss: 0.4052  obj_loss: 0.0406  noobj_loss: 0.1898  bbox_loss: 0.0197  cls_loss: 0.1709  \n",
      "<<<iteration:[40/244] - total_loss: 0.4180  obj_loss: 0.0466  noobj_loss: 0.1686  bbox_loss: 0.0221  cls_loss: 0.1768  \n",
      "<<<iteration:[60/244] - total_loss: 0.4053  obj_loss: 0.0418  noobj_loss: 0.1531  bbox_loss: 0.0179  cls_loss: 0.1975  \n",
      "<<<iteration:[80/244] - total_loss: 0.3110  obj_loss: 0.0515  noobj_loss: 0.1306  bbox_loss: 0.0133  cls_loss: 0.1277  \n",
      "<<<iteration:[100/244] - total_loss: 0.3540  obj_loss: 0.0517  noobj_loss: 0.1332  bbox_loss: 0.0166  cls_loss: 0.1529  \n",
      "<<<iteration:[120/244] - total_loss: 0.3706  obj_loss: 0.0492  noobj_loss: 0.1296  bbox_loss: 0.0150  cls_loss: 0.1813  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<<<iteration:[140/244] - total_loss: 0.3418  obj_loss: 0.0430  noobj_loss: 0.1404  bbox_loss: 0.0177  cls_loss: 0.1401  \n",
      "<<<iteration:[160/244] - total_loss: 0.3682  obj_loss: 0.0439  noobj_loss: 0.1529  bbox_loss: 0.0158  cls_loss: 0.1688  \n",
      "<<<iteration:[180/244] - total_loss: 0.3392  obj_loss: 0.0538  noobj_loss: 0.1357  bbox_loss: 0.0141  cls_loss: 0.1468  \n",
      "<<<iteration:[200/244] - total_loss: 0.3855  obj_loss: 0.0458  noobj_loss: 0.1322  bbox_loss: 0.0179  cls_loss: 0.1840  \n",
      "<<<iteration:[220/244] - total_loss: 0.3840  obj_loss: 0.0411  noobj_loss: 0.1338  bbox_loss: 0.0168  cls_loss: 0.1919  \n",
      "<<<iteration:[240/244] - total_loss: 0.3417  obj_loss: 0.0490  noobj_loss: 0.1274  bbox_loss: 0.0138  cls_loss: 0.1599  \n",
      "\n",
      "epoch:6/100 - Train Loss: 0.3673, Val Loss: 0.3350\n",
      "\n",
      "<<<iteration:[20/244] - total_loss: 0.3196  obj_loss: 0.0405  noobj_loss: 0.1294  bbox_loss: 0.0171  cls_loss: 0.1290  \n",
      "<<<iteration:[40/244] - total_loss: 0.3146  obj_loss: 0.0471  noobj_loss: 0.1178  bbox_loss: 0.0159  cls_loss: 0.1290  \n",
      "<<<iteration:[60/244] - total_loss: 0.3238  obj_loss: 0.0470  noobj_loss: 0.1177  bbox_loss: 0.0141  cls_loss: 0.1473  \n",
      "<<<iteration:[80/244] - total_loss: 0.3730  obj_loss: 0.0459  noobj_loss: 0.1274  bbox_loss: 0.0253  cls_loss: 0.1369  \n",
      "<<<iteration:[100/244] - total_loss: 0.3399  obj_loss: 0.0426  noobj_loss: 0.1155  bbox_loss: 0.0187  cls_loss: 0.1459  \n",
      "<<<iteration:[120/244] - total_loss: 0.3582  obj_loss: 0.0413  noobj_loss: 0.1122  bbox_loss: 0.0147  cls_loss: 0.1871  \n",
      "<<<iteration:[140/244] - total_loss: 0.3739  obj_loss: 0.0456  noobj_loss: 0.1206  bbox_loss: 0.0204  cls_loss: 0.1662  \n",
      "<<<iteration:[160/244] - total_loss: 0.3353  obj_loss: 0.0479  noobj_loss: 0.1102  bbox_loss: 0.0149  cls_loss: 0.1579  \n",
      "<<<iteration:[180/244] - total_loss: 0.3570  obj_loss: 0.0553  noobj_loss: 0.1096  bbox_loss: 0.0153  cls_loss: 0.1702  \n",
      "<<<iteration:[200/244] - total_loss: 0.2961  obj_loss: 0.0494  noobj_loss: 0.1128  bbox_loss: 0.0124  cls_loss: 0.1283  \n",
      "<<<iteration:[220/244] - total_loss: 0.3859  obj_loss: 0.0463  noobj_loss: 0.1161  bbox_loss: 0.0179  cls_loss: 0.1921  \n",
      "<<<iteration:[240/244] - total_loss: 0.3260  obj_loss: 0.0471  noobj_loss: 0.1018  bbox_loss: 0.0153  cls_loss: 0.1515  \n",
      "\n",
      "epoch:7/100 - Train Loss: 0.3413, Val Loss: 0.3548\n",
      "\n",
      "<<<iteration:[20/244] - total_loss: 0.3203  obj_loss: 0.0513  noobj_loss: 0.1014  bbox_loss: 0.0163  cls_loss: 0.1370  \n",
      "<<<iteration:[40/244] - total_loss: 0.3343  obj_loss: 0.0396  noobj_loss: 0.1017  bbox_loss: 0.0145  cls_loss: 0.1713  \n",
      "<<<iteration:[60/244] - total_loss: 0.3080  obj_loss: 0.0505  noobj_loss: 0.1035  bbox_loss: 0.0154  cls_loss: 0.1287  \n",
      "<<<iteration:[80/244] - total_loss: 0.3590  obj_loss: 0.0452  noobj_loss: 0.0960  bbox_loss: 0.0185  cls_loss: 0.1734  \n",
      "<<<iteration:[100/244] - total_loss: 0.3251  obj_loss: 0.0414  noobj_loss: 0.1030  bbox_loss: 0.0164  cls_loss: 0.1501  \n",
      "<<<iteration:[120/244] - total_loss: 0.3189  obj_loss: 0.0466  noobj_loss: 0.0976  bbox_loss: 0.0158  cls_loss: 0.1446  \n",
      "<<<iteration:[140/244] - total_loss: 0.2963  obj_loss: 0.0473  noobj_loss: 0.0885  bbox_loss: 0.0133  cls_loss: 0.1380  \n",
      "<<<iteration:[160/244] - total_loss: 0.3564  obj_loss: 0.0530  noobj_loss: 0.0958  bbox_loss: 0.0148  cls_loss: 0.1812  \n",
      "<<<iteration:[180/244] - total_loss: 0.3165  obj_loss: 0.0479  noobj_loss: 0.0986  bbox_loss: 0.0133  cls_loss: 0.1528  \n",
      "<<<iteration:[200/244] - total_loss: 0.3110  obj_loss: 0.0418  noobj_loss: 0.1090  bbox_loss: 0.0134  cls_loss: 0.1476  \n",
      "<<<iteration:[220/244] - total_loss: 0.3188  obj_loss: 0.0638  noobj_loss: 0.0978  bbox_loss: 0.0121  cls_loss: 0.1455  \n",
      "<<<iteration:[240/244] - total_loss: 0.2911  obj_loss: 0.0534  noobj_loss: 0.0914  bbox_loss: 0.0136  cls_loss: 0.1241  \n",
      "\n",
      "epoch:8/100 - Train Loss: 0.3196, Val Loss: 0.3036\n",
      "\n",
      "<<<iteration:[20/244] - total_loss: 0.3241  obj_loss: 0.0584  noobj_loss: 0.0931  bbox_loss: 0.0113  cls_loss: 0.1624  \n",
      "<<<iteration:[40/244] - total_loss: 0.2879  obj_loss: 0.0491  noobj_loss: 0.0901  bbox_loss: 0.0141  cls_loss: 0.1233  \n",
      "<<<iteration:[60/244] - total_loss: 0.3111  obj_loss: 0.0469  noobj_loss: 0.0841  bbox_loss: 0.0127  cls_loss: 0.1584  \n",
      "<<<iteration:[80/244] - total_loss: 0.3227  obj_loss: 0.0482  noobj_loss: 0.0869  bbox_loss: 0.0129  cls_loss: 0.1667  \n",
      "<<<iteration:[100/244] - total_loss: 0.2756  obj_loss: 0.0501  noobj_loss: 0.0904  bbox_loss: 0.0133  cls_loss: 0.1138  \n",
      "<<<iteration:[120/244] - total_loss: 0.3204  obj_loss: 0.0553  noobj_loss: 0.0854  bbox_loss: 0.0128  cls_loss: 0.1582  \n",
      "<<<iteration:[140/244] - total_loss: 0.2984  obj_loss: 0.0526  noobj_loss: 0.0953  bbox_loss: 0.0117  cls_loss: 0.1397  \n",
      "<<<iteration:[160/244] - total_loss: 0.2835  obj_loss: 0.0521  noobj_loss: 0.0818  bbox_loss: 0.0114  cls_loss: 0.1333  \n",
      "<<<iteration:[180/244] - total_loss: 0.2848  obj_loss: 0.0511  noobj_loss: 0.0948  bbox_loss: 0.0132  cls_loss: 0.1206  \n",
      "<<<iteration:[200/244] - total_loss: 0.2992  obj_loss: 0.0603  noobj_loss: 0.0913  bbox_loss: 0.0113  cls_loss: 0.1367  \n",
      "<<<iteration:[220/244] - total_loss: 0.3429  obj_loss: 0.0490  noobj_loss: 0.0831  bbox_loss: 0.0204  cls_loss: 0.1503  \n",
      "<<<iteration:[240/244] - total_loss: 0.3000  obj_loss: 0.0459  noobj_loss: 0.0757  bbox_loss: 0.0174  cls_loss: 0.1291  \n",
      "\n",
      "epoch:9/100 - Train Loss: 0.3029, Val Loss: 0.2750\n",
      "\n",
      "<<<iteration:[20/244] - total_loss: 0.3022  obj_loss: 0.0502  noobj_loss: 0.0891  bbox_loss: 0.0127  cls_loss: 0.1442  \n",
      "<<<iteration:[40/244] - total_loss: 0.3006  obj_loss: 0.0503  noobj_loss: 0.0802  bbox_loss: 0.0116  cls_loss: 0.1523  \n",
      "<<<iteration:[60/244] - total_loss: 0.2847  obj_loss: 0.0555  noobj_loss: 0.0820  bbox_loss: 0.0115  cls_loss: 0.1307  \n",
      "<<<iteration:[80/244] - total_loss: 0.3002  obj_loss: 0.0496  noobj_loss: 0.0820  bbox_loss: 0.0134  cls_loss: 0.1427  \n",
      "<<<iteration:[100/244] - total_loss: 0.2873  obj_loss: 0.0432  noobj_loss: 0.0864  bbox_loss: 0.0129  cls_loss: 0.1362  \n",
      "<<<iteration:[120/244] - total_loss: 0.2606  obj_loss: 0.0577  noobj_loss: 0.0814  bbox_loss: 0.0103  cls_loss: 0.1106  \n",
      "<<<iteration:[140/244] - total_loss: 0.3385  obj_loss: 0.0619  noobj_loss: 0.0912  bbox_loss: 0.0135  cls_loss: 0.1634  \n",
      "<<<iteration:[160/244] - total_loss: 0.2804  obj_loss: 0.0488  noobj_loss: 0.0793  bbox_loss: 0.0115  cls_loss: 0.1347  \n",
      "<<<iteration:[180/244] - total_loss: 0.2920  obj_loss: 0.0485  noobj_loss: 0.0808  bbox_loss: 0.0110  cls_loss: 0.1482  \n",
      "<<<iteration:[200/244] - total_loss: 0.2913  obj_loss: 0.0501  noobj_loss: 0.0789  bbox_loss: 0.0108  cls_loss: 0.1479  \n",
      "<<<iteration:[220/244] - total_loss: 0.3027  obj_loss: 0.0571  noobj_loss: 0.0766  bbox_loss: 0.0106  cls_loss: 0.1541  \n",
      "<<<iteration:[240/244] - total_loss: 0.2732  obj_loss: 0.0593  noobj_loss: 0.0713  bbox_loss: 0.0098  cls_loss: 0.1294  \n",
      "\n",
      "epoch:10/100 - Train Loss: 0.2905, Val Loss: 0.2693\n",
      "\n",
      "<<<iteration:[20/244] - total_loss: 0.3047  obj_loss: 0.0634  noobj_loss: 0.0764  bbox_loss: 0.0100  cls_loss: 0.1530  \n",
      "<<<iteration:[40/244] - total_loss: 0.2767  obj_loss: 0.0497  noobj_loss: 0.0693  bbox_loss: 0.0112  cls_loss: 0.1365  \n",
      "<<<iteration:[60/244] - total_loss: 0.2903  obj_loss: 0.0501  noobj_loss: 0.0770  bbox_loss: 0.0116  cls_loss: 0.1435  \n",
      "<<<iteration:[80/244] - total_loss: 0.3008  obj_loss: 0.0540  noobj_loss: 0.0724  bbox_loss: 0.0124  cls_loss: 0.1485  \n",
      "<<<iteration:[100/244] - total_loss: 0.2987  obj_loss: 0.0548  noobj_loss: 0.0756  bbox_loss: 0.0129  cls_loss: 0.1413  \n",
      "<<<iteration:[120/244] - total_loss: 0.2774  obj_loss: 0.0541  noobj_loss: 0.0704  bbox_loss: 0.0130  cls_loss: 0.1230  \n",
      "<<<iteration:[140/244] - total_loss: 0.2578  obj_loss: 0.0567  noobj_loss: 0.0721  bbox_loss: 0.0097  cls_loss: 0.1164  \n",
      "<<<iteration:[160/244] - total_loss: 0.2718  obj_loss: 0.0522  noobj_loss: 0.0778  bbox_loss: 0.0129  cls_loss: 0.1164  \n",
      "<<<iteration:[180/244] - total_loss: 0.2965  obj_loss: 0.0620  noobj_loss: 0.0715  bbox_loss: 0.0099  cls_loss: 0.1495  \n",
      "<<<iteration:[200/244] - total_loss: 0.2946  obj_loss: 0.0615  noobj_loss: 0.0643  bbox_loss: 0.0096  cls_loss: 0.1530  \n",
      "<<<iteration:[220/244] - total_loss: 0.2630  obj_loss: 0.0586  noobj_loss: 0.0754  bbox_loss: 0.0116  cls_loss: 0.1088  \n",
      "<<<iteration:[240/244] - total_loss: 0.2565  obj_loss: 0.0541  noobj_loss: 0.0673  bbox_loss: 0.0092  cls_loss: 0.1228  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "epoch:11/100 - Train Loss: 0.2819, Val Loss: 0.2731\n",
      "\n",
      "<<<iteration:[20/244] - total_loss: 0.3066  obj_loss: 0.0605  noobj_loss: 0.0739  bbox_loss: 0.0106  cls_loss: 0.1562  \n",
      "<<<iteration:[40/244] - total_loss: 0.2781  obj_loss: 0.0596  noobj_loss: 0.0687  bbox_loss: 0.0102  cls_loss: 0.1332  \n",
      "<<<iteration:[60/244] - total_loss: 0.2731  obj_loss: 0.0626  noobj_loss: 0.0781  bbox_loss: 0.0109  cls_loss: 0.1169  \n",
      "<<<iteration:[80/244] - total_loss: 0.2516  obj_loss: 0.0478  noobj_loss: 0.0665  bbox_loss: 0.0100  cls_loss: 0.1207  \n",
      "<<<iteration:[100/244] - total_loss: 0.2753  obj_loss: 0.0615  noobj_loss: 0.0710  bbox_loss: 0.0094  cls_loss: 0.1315  \n",
      "<<<iteration:[120/244] - total_loss: 0.2790  obj_loss: 0.0602  noobj_loss: 0.0612  bbox_loss: 0.0095  cls_loss: 0.1405  \n",
      "<<<iteration:[140/244] - total_loss: 0.2547  obj_loss: 0.0580  noobj_loss: 0.0628  bbox_loss: 0.0083  cls_loss: 0.1239  \n",
      "<<<iteration:[160/244] - total_loss: 0.2758  obj_loss: 0.0570  noobj_loss: 0.0638  bbox_loss: 0.0105  cls_loss: 0.1347  \n",
      "<<<iteration:[180/244] - total_loss: 0.2632  obj_loss: 0.0522  noobj_loss: 0.0747  bbox_loss: 0.0106  cls_loss: 0.1208  \n",
      "<<<iteration:[200/244] - total_loss: 0.2861  obj_loss: 0.0560  noobj_loss: 0.0661  bbox_loss: 0.0107  cls_loss: 0.1436  \n",
      "<<<iteration:[220/244] - total_loss: 0.2588  obj_loss: 0.0563  noobj_loss: 0.0700  bbox_loss: 0.0096  cls_loss: 0.1196  \n",
      "<<<iteration:[240/244] - total_loss: 0.2836  obj_loss: 0.0588  noobj_loss: 0.0653  bbox_loss: 0.0081  cls_loss: 0.1515  \n",
      "\n",
      "epoch:12/100 - Train Loss: 0.2719, Val Loss: 0.2630\n",
      "\n",
      "<<<iteration:[20/244] - total_loss: 0.2907  obj_loss: 0.0654  noobj_loss: 0.0647  bbox_loss: 0.0088  cls_loss: 0.1490  \n",
      "<<<iteration:[40/244] - total_loss: 0.2614  obj_loss: 0.0605  noobj_loss: 0.0682  bbox_loss: 0.0092  cls_loss: 0.1206  \n",
      "<<<iteration:[60/244] - total_loss: 0.2747  obj_loss: 0.0569  noobj_loss: 0.0636  bbox_loss: 0.0118  cls_loss: 0.1270  \n",
      "<<<iteration:[80/244] - total_loss: 0.2434  obj_loss: 0.0669  noobj_loss: 0.0593  bbox_loss: 0.0079  cls_loss: 0.1075  \n",
      "<<<iteration:[100/244] - total_loss: 0.2873  obj_loss: 0.0643  noobj_loss: 0.0656  bbox_loss: 0.0084  cls_loss: 0.1480  \n",
      "<<<iteration:[120/244] - total_loss: 0.2604  obj_loss: 0.0507  noobj_loss: 0.0655  bbox_loss: 0.0108  cls_loss: 0.1230  \n",
      "<<<iteration:[140/244] - total_loss: 0.2385  obj_loss: 0.0536  noobj_loss: 0.0653  bbox_loss: 0.0083  cls_loss: 0.1105  \n",
      "<<<iteration:[160/244] - total_loss: 0.2586  obj_loss: 0.0564  noobj_loss: 0.0681  bbox_loss: 0.0100  cls_loss: 0.1183  \n",
      "<<<iteration:[180/244] - total_loss: 0.2517  obj_loss: 0.0630  noobj_loss: 0.0595  bbox_loss: 0.0085  cls_loss: 0.1167  \n",
      "<<<iteration:[200/244] - total_loss: 0.2629  obj_loss: 0.0575  noobj_loss: 0.0678  bbox_loss: 0.0084  cls_loss: 0.1298  \n",
      "<<<iteration:[220/244] - total_loss: 0.2673  obj_loss: 0.0571  noobj_loss: 0.0633  bbox_loss: 0.0084  cls_loss: 0.1365  \n",
      "<<<iteration:[240/244] - total_loss: 0.2692  obj_loss: 0.0592  noobj_loss: 0.0592  bbox_loss: 0.0090  cls_loss: 0.1355  \n",
      "\n",
      "epoch:13/100 - Train Loss: 0.2617, Val Loss: 0.2531\n",
      "\n",
      "<<<iteration:[20/244] - total_loss: 0.2510  obj_loss: 0.0553  noobj_loss: 0.0625  bbox_loss: 0.0098  cls_loss: 0.1152  \n",
      "<<<iteration:[40/244] - total_loss: 0.2644  obj_loss: 0.0581  noobj_loss: 0.0614  bbox_loss: 0.0078  cls_loss: 0.1367  \n",
      "<<<iteration:[60/244] - total_loss: 0.3015  obj_loss: 0.0553  noobj_loss: 0.0575  bbox_loss: 0.0097  cls_loss: 0.1689  \n",
      "<<<iteration:[80/244] - total_loss: 0.2445  obj_loss: 0.0540  noobj_loss: 0.0617  bbox_loss: 0.0111  cls_loss: 0.1040  \n",
      "<<<iteration:[100/244] - total_loss: 0.2746  obj_loss: 0.0589  noobj_loss: 0.0587  bbox_loss: 0.0098  cls_loss: 0.1375  \n",
      "<<<iteration:[120/244] - total_loss: 0.2235  obj_loss: 0.0598  noobj_loss: 0.0589  bbox_loss: 0.0080  cls_loss: 0.0941  \n",
      "<<<iteration:[140/244] - total_loss: 0.2461  obj_loss: 0.0632  noobj_loss: 0.0536  bbox_loss: 0.0083  cls_loss: 0.1148  \n",
      "<<<iteration:[160/244] - total_loss: 0.2353  obj_loss: 0.0586  noobj_loss: 0.0576  bbox_loss: 0.0093  cls_loss: 0.1012  \n",
      "<<<iteration:[180/244] - total_loss: 0.2572  obj_loss: 0.0690  noobj_loss: 0.0568  bbox_loss: 0.0074  cls_loss: 0.1227  \n",
      "<<<iteration:[200/244] - total_loss: 0.2687  obj_loss: 0.0584  noobj_loss: 0.0598  bbox_loss: 0.0088  cls_loss: 0.1363  \n",
      "<<<iteration:[220/244] - total_loss: 0.2686  obj_loss: 0.0563  noobj_loss: 0.0600  bbox_loss: 0.0089  cls_loss: 0.1380  \n",
      "<<<iteration:[240/244] - total_loss: 0.2745  obj_loss: 0.0689  noobj_loss: 0.0592  bbox_loss: 0.0082  cls_loss: 0.1351  \n",
      "\n",
      "epoch:14/100 - Train Loss: 0.2588, Val Loss: 0.2453\n",
      "\n",
      "<<<iteration:[20/244] - total_loss: 0.2622  obj_loss: 0.0670  noobj_loss: 0.0637  bbox_loss: 0.0080  cls_loss: 0.1232  \n",
      "<<<iteration:[40/244] - total_loss: 0.2385  obj_loss: 0.0623  noobj_loss: 0.0607  bbox_loss: 0.0091  cls_loss: 0.1002  \n",
      "<<<iteration:[60/244] - total_loss: 0.2431  obj_loss: 0.0553  noobj_loss: 0.0611  bbox_loss: 0.0066  cls_loss: 0.1244  \n",
      "<<<iteration:[80/244] - total_loss: 0.2414  obj_loss: 0.0588  noobj_loss: 0.0593  bbox_loss: 0.0083  cls_loss: 0.1116  \n",
      "<<<iteration:[100/244] - total_loss: 0.2499  obj_loss: 0.0669  noobj_loss: 0.0597  bbox_loss: 0.0077  cls_loss: 0.1146  \n",
      "<<<iteration:[120/244] - total_loss: 0.2971  obj_loss: 0.0639  noobj_loss: 0.0617  bbox_loss: 0.0124  cls_loss: 0.1402  \n",
      "<<<iteration:[140/244] - total_loss: 0.2591  obj_loss: 0.0635  noobj_loss: 0.0584  bbox_loss: 0.0080  cls_loss: 0.1264  \n",
      "<<<iteration:[160/244] - total_loss: 0.2333  obj_loss: 0.0550  noobj_loss: 0.0531  bbox_loss: 0.0078  cls_loss: 0.1130  \n",
      "<<<iteration:[180/244] - total_loss: 0.2752  obj_loss: 0.0569  noobj_loss: 0.0595  bbox_loss: 0.0088  cls_loss: 0.1448  \n",
      "<<<iteration:[200/244] - total_loss: 0.2505  obj_loss: 0.0576  noobj_loss: 0.0535  bbox_loss: 0.0080  cls_loss: 0.1260  \n",
      "<<<iteration:[220/244] - total_loss: 0.2483  obj_loss: 0.0649  noobj_loss: 0.0504  bbox_loss: 0.0076  cls_loss: 0.1201  \n",
      "<<<iteration:[240/244] - total_loss: 0.2168  obj_loss: 0.0568  noobj_loss: 0.0525  bbox_loss: 0.0079  cls_loss: 0.0944  \n",
      "\n",
      "epoch:15/100 - Train Loss: 0.2505, Val Loss: 0.2324\n",
      "\n",
      "<<<iteration:[20/244] - total_loss: 0.2567  obj_loss: 0.0684  noobj_loss: 0.0592  bbox_loss: 0.0080  cls_loss: 0.1187  \n",
      "<<<iteration:[40/244] - total_loss: 0.2912  obj_loss: 0.0706  noobj_loss: 0.0601  bbox_loss: 0.0074  cls_loss: 0.1535  \n",
      "<<<iteration:[60/244] - total_loss: 0.2447  obj_loss: 0.0593  noobj_loss: 0.0565  bbox_loss: 0.0075  cls_loss: 0.1196  \n",
      "<<<iteration:[80/244] - total_loss: 0.2479  obj_loss: 0.0569  noobj_loss: 0.0565  bbox_loss: 0.0068  cls_loss: 0.1287  \n",
      "<<<iteration:[100/244] - total_loss: 0.2382  obj_loss: 0.0620  noobj_loss: 0.0628  bbox_loss: 0.0083  cls_loss: 0.1033  \n",
      "<<<iteration:[120/244] - total_loss: 0.2248  obj_loss: 0.0616  noobj_loss: 0.0550  bbox_loss: 0.0079  cls_loss: 0.0962  \n",
      "<<<iteration:[140/244] - total_loss: 0.2505  obj_loss: 0.0592  noobj_loss: 0.0527  bbox_loss: 0.0081  cls_loss: 0.1246  \n",
      "<<<iteration:[160/244] - total_loss: 0.2518  obj_loss: 0.0698  noobj_loss: 0.0609  bbox_loss: 0.0082  cls_loss: 0.1108  \n",
      "<<<iteration:[180/244] - total_loss: 0.2757  obj_loss: 0.0508  noobj_loss: 0.0804  bbox_loss: 0.0129  cls_loss: 0.1201  \n",
      "<<<iteration:[200/244] - total_loss: 0.2514  obj_loss: 0.0652  noobj_loss: 0.0523  bbox_loss: 0.0079  cls_loss: 0.1204  \n",
      "<<<iteration:[220/244] - total_loss: 0.2384  obj_loss: 0.0596  noobj_loss: 0.0524  bbox_loss: 0.0075  cls_loss: 0.1151  \n",
      "<<<iteration:[240/244] - total_loss: 0.2520  obj_loss: 0.0529  noobj_loss: 0.0530  bbox_loss: 0.0100  cls_loss: 0.1229  \n",
      "\n",
      "epoch:16/100 - Train Loss: 0.2519, Val Loss: 0.2417\n",
      "\n",
      "<<<iteration:[20/244] - total_loss: 0.2438  obj_loss: 0.0676  noobj_loss: 0.0552  bbox_loss: 0.0080  cls_loss: 0.1086  \n",
      "<<<iteration:[40/244] - total_loss: 0.2461  obj_loss: 0.0638  noobj_loss: 0.0557  bbox_loss: 0.0083  cls_loss: 0.1128  \n",
      "<<<iteration:[60/244] - total_loss: 0.2459  obj_loss: 0.0689  noobj_loss: 0.0540  bbox_loss: 0.0069  cls_loss: 0.1157  \n",
      "<<<iteration:[80/244] - total_loss: 0.2723  obj_loss: 0.0544  noobj_loss: 0.0522  bbox_loss: 0.0083  cls_loss: 0.1503  \n",
      "<<<iteration:[100/244] - total_loss: 0.2587  obj_loss: 0.0630  noobj_loss: 0.0517  bbox_loss: 0.0073  cls_loss: 0.1335  \n",
      "<<<iteration:[120/244] - total_loss: 0.2456  obj_loss: 0.0620  noobj_loss: 0.0580  bbox_loss: 0.0082  cls_loss: 0.1139  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<<<iteration:[140/244] - total_loss: 0.2288  obj_loss: 0.0639  noobj_loss: 0.0480  bbox_loss: 0.0065  cls_loss: 0.1084  \n",
      "<<<iteration:[160/244] - total_loss: 0.2678  obj_loss: 0.0653  noobj_loss: 0.0531  bbox_loss: 0.0066  cls_loss: 0.1429  \n",
      "<<<iteration:[180/244] - total_loss: 0.2294  obj_loss: 0.0678  noobj_loss: 0.0560  bbox_loss: 0.0072  cls_loss: 0.0978  \n",
      "<<<iteration:[200/244] - total_loss: 0.2439  obj_loss: 0.0697  noobj_loss: 0.0534  bbox_loss: 0.0077  cls_loss: 0.1088  \n",
      "<<<iteration:[220/244] - total_loss: 0.2557  obj_loss: 0.0586  noobj_loss: 0.0626  bbox_loss: 0.0092  cls_loss: 0.1197  \n",
      "<<<iteration:[240/244] - total_loss: 0.2594  obj_loss: 0.0673  noobj_loss: 0.0513  bbox_loss: 0.0083  cls_loss: 0.1249  \n",
      "\n",
      "epoch:17/100 - Train Loss: 0.2493, Val Loss: 0.2377\n",
      "\n",
      "<<<iteration:[20/244] - total_loss: 0.2356  obj_loss: 0.0623  noobj_loss: 0.0552  bbox_loss: 0.0077  cls_loss: 0.1070  \n",
      "<<<iteration:[40/244] - total_loss: 0.2159  obj_loss: 0.0584  noobj_loss: 0.0513  bbox_loss: 0.0073  cls_loss: 0.0952  \n",
      "<<<iteration:[60/244] - total_loss: 0.2282  obj_loss: 0.0519  noobj_loss: 0.0543  bbox_loss: 0.0074  cls_loss: 0.1120  \n",
      "<<<iteration:[80/244] - total_loss: 0.2121  obj_loss: 0.0596  noobj_loss: 0.0503  bbox_loss: 0.0066  cls_loss: 0.0944  \n",
      "<<<iteration:[100/244] - total_loss: 0.2408  obj_loss: 0.0661  noobj_loss: 0.0533  bbox_loss: 0.0067  cls_loss: 0.1147  \n",
      "<<<iteration:[120/244] - total_loss: 0.2479  obj_loss: 0.0594  noobj_loss: 0.0522  bbox_loss: 0.0075  cls_loss: 0.1246  \n",
      "<<<iteration:[140/244] - total_loss: 0.2609  obj_loss: 0.0629  noobj_loss: 0.0513  bbox_loss: 0.0075  cls_loss: 0.1351  \n",
      "<<<iteration:[160/244] - total_loss: 0.2548  obj_loss: 0.0676  noobj_loss: 0.0560  bbox_loss: 0.0074  cls_loss: 0.1225  \n",
      "<<<iteration:[180/244] - total_loss: 0.2462  obj_loss: 0.0630  noobj_loss: 0.0604  bbox_loss: 0.0087  cls_loss: 0.1098  \n",
      "<<<iteration:[200/244] - total_loss: 0.2111  obj_loss: 0.0559  noobj_loss: 0.0467  bbox_loss: 0.0061  cls_loss: 0.1015  \n",
      "<<<iteration:[220/244] - total_loss: 0.2453  obj_loss: 0.0583  noobj_loss: 0.0533  bbox_loss: 0.0075  cls_loss: 0.1226  \n",
      "<<<iteration:[240/244] - total_loss: 0.2317  obj_loss: 0.0551  noobj_loss: 0.0539  bbox_loss: 0.0069  cls_loss: 0.1153  \n",
      "\n",
      "epoch:18/100 - Train Loss: 0.2363, Val Loss: 0.2341\n",
      "\n",
      "<<<iteration:[20/244] - total_loss: 0.2367  obj_loss: 0.0608  noobj_loss: 0.0548  bbox_loss: 0.0076  cls_loss: 0.1104  \n",
      "<<<iteration:[40/244] - total_loss: 0.2258  obj_loss: 0.0681  noobj_loss: 0.0550  bbox_loss: 0.0064  cls_loss: 0.0979  \n",
      "<<<iteration:[60/244] - total_loss: 0.2282  obj_loss: 0.0730  noobj_loss: 0.0555  bbox_loss: 0.0064  cls_loss: 0.0957  \n",
      "<<<iteration:[80/244] - total_loss: 0.2444  obj_loss: 0.0626  noobj_loss: 0.0592  bbox_loss: 0.0073  cls_loss: 0.1155  \n",
      "<<<iteration:[100/244] - total_loss: 0.2123  obj_loss: 0.0692  noobj_loss: 0.0509  bbox_loss: 0.0067  cls_loss: 0.0842  \n",
      "<<<iteration:[120/244] - total_loss: 0.2329  obj_loss: 0.0564  noobj_loss: 0.0517  bbox_loss: 0.0074  cls_loss: 0.1137  \n",
      "<<<iteration:[140/244] - total_loss: 0.2597  obj_loss: 0.0632  noobj_loss: 0.0510  bbox_loss: 0.0077  cls_loss: 0.1323  \n",
      "<<<iteration:[160/244] - total_loss: 0.2312  obj_loss: 0.0699  noobj_loss: 0.0483  bbox_loss: 0.0064  cls_loss: 0.1053  \n",
      "<<<iteration:[180/244] - total_loss: 0.2096  obj_loss: 0.0601  noobj_loss: 0.0550  bbox_loss: 0.0071  cls_loss: 0.0866  \n",
      "<<<iteration:[200/244] - total_loss: 0.2321  obj_loss: 0.0567  noobj_loss: 0.0530  bbox_loss: 0.0071  cls_loss: 0.1134  \n",
      "<<<iteration:[220/244] - total_loss: 0.2706  obj_loss: 0.0668  noobj_loss: 0.0515  bbox_loss: 0.0075  cls_loss: 0.1407  \n",
      "<<<iteration:[240/244] - total_loss: 0.2380  obj_loss: 0.0601  noobj_loss: 0.0523  bbox_loss: 0.0065  cls_loss: 0.1191  \n",
      "\n",
      "epoch:19/100 - Train Loss: 0.2335, Val Loss: 0.2269\n",
      "\n",
      "<<<iteration:[20/244] - total_loss: 0.2294  obj_loss: 0.0701  noobj_loss: 0.0539  bbox_loss: 0.0080  cls_loss: 0.0925  \n",
      "<<<iteration:[40/244] - total_loss: 0.2192  obj_loss: 0.0603  noobj_loss: 0.0537  bbox_loss: 0.0067  cls_loss: 0.0989  \n",
      "<<<iteration:[60/244] - total_loss: 0.2251  obj_loss: 0.0633  noobj_loss: 0.0490  bbox_loss: 0.0065  cls_loss: 0.1048  \n",
      "<<<iteration:[80/244] - total_loss: 0.2356  obj_loss: 0.0640  noobj_loss: 0.0541  bbox_loss: 0.0078  cls_loss: 0.1058  \n",
      "<<<iteration:[100/244] - total_loss: 0.2357  obj_loss: 0.0599  noobj_loss: 0.0466  bbox_loss: 0.0072  cls_loss: 0.1164  \n",
      "<<<iteration:[120/244] - total_loss: 0.2467  obj_loss: 0.0596  noobj_loss: 0.0518  bbox_loss: 0.0072  cls_loss: 0.1251  \n",
      "<<<iteration:[140/244] - total_loss: 0.2129  obj_loss: 0.0612  noobj_loss: 0.0517  bbox_loss: 0.0060  cls_loss: 0.0958  \n",
      "<<<iteration:[160/244] - total_loss: 0.2530  obj_loss: 0.0625  noobj_loss: 0.0506  bbox_loss: 0.0072  cls_loss: 0.1291  \n",
      "<<<iteration:[180/244] - total_loss: 0.2116  obj_loss: 0.0629  noobj_loss: 0.0478  bbox_loss: 0.0071  cls_loss: 0.0894  \n",
      "<<<iteration:[200/244] - total_loss: 0.2312  obj_loss: 0.0749  noobj_loss: 0.0435  bbox_loss: 0.0054  cls_loss: 0.1076  \n",
      "<<<iteration:[220/244] - total_loss: 0.2233  obj_loss: 0.0570  noobj_loss: 0.0466  bbox_loss: 0.0069  cls_loss: 0.1087  \n",
      "<<<iteration:[240/244] - total_loss: 0.2469  obj_loss: 0.0699  noobj_loss: 0.0464  bbox_loss: 0.0063  cls_loss: 0.1224  \n",
      "\n",
      "epoch:20/100 - Train Loss: 0.2292, Val Loss: 0.2257\n",
      "\n",
      "<<<iteration:[20/244] - total_loss: 0.2593  obj_loss: 0.0654  noobj_loss: 0.0543  bbox_loss: 0.0069  cls_loss: 0.1325  \n",
      "<<<iteration:[40/244] - total_loss: 0.2057  obj_loss: 0.0678  noobj_loss: 0.0486  bbox_loss: 0.0055  cls_loss: 0.0863  \n",
      "<<<iteration:[60/244] - total_loss: 0.2445  obj_loss: 0.0591  noobj_loss: 0.0515  bbox_loss: 0.0070  cls_loss: 0.1244  \n",
      "<<<iteration:[80/244] - total_loss: 0.2015  obj_loss: 0.0605  noobj_loss: 0.0485  bbox_loss: 0.0055  cls_loss: 0.0892  \n",
      "<<<iteration:[100/244] - total_loss: 0.2394  obj_loss: 0.0642  noobj_loss: 0.0475  bbox_loss: 0.0080  cls_loss: 0.1112  \n",
      "<<<iteration:[120/244] - total_loss: 0.2106  obj_loss: 0.0670  noobj_loss: 0.0496  bbox_loss: 0.0059  cls_loss: 0.0892  \n",
      "<<<iteration:[140/244] - total_loss: 0.2333  obj_loss: 0.0588  noobj_loss: 0.0590  bbox_loss: 0.0085  cls_loss: 0.1026  \n",
      "<<<iteration:[160/244] - total_loss: 0.2253  obj_loss: 0.0643  noobj_loss: 0.0495  bbox_loss: 0.0066  cls_loss: 0.1031  \n",
      "<<<iteration:[180/244] - total_loss: 0.2242  obj_loss: 0.0635  noobj_loss: 0.0482  bbox_loss: 0.0063  cls_loss: 0.1052  \n",
      "<<<iteration:[200/244] - total_loss: 0.2361  obj_loss: 0.0616  noobj_loss: 0.0519  bbox_loss: 0.0083  cls_loss: 0.1073  \n",
      "<<<iteration:[220/244] - total_loss: 0.2555  obj_loss: 0.0735  noobj_loss: 0.0497  bbox_loss: 0.0084  cls_loss: 0.1154  \n",
      "<<<iteration:[240/244] - total_loss: 0.2377  obj_loss: 0.0688  noobj_loss: 0.0435  bbox_loss: 0.0055  cls_loss: 0.1194  \n",
      "\n",
      "epoch:21/100 - Train Loss: 0.2306, Val Loss: 0.2381\n",
      "\n",
      "<<<iteration:[20/244] - total_loss: 0.2592  obj_loss: 0.0663  noobj_loss: 0.0526  bbox_loss: 0.0069  cls_loss: 0.1322  \n",
      "<<<iteration:[40/244] - total_loss: 0.2310  obj_loss: 0.0613  noobj_loss: 0.0456  bbox_loss: 0.0063  cls_loss: 0.1155  \n",
      "<<<iteration:[60/244] - total_loss: 0.2454  obj_loss: 0.0617  noobj_loss: 0.0501  bbox_loss: 0.0075  cls_loss: 0.1209  \n",
      "<<<iteration:[80/244] - total_loss: 0.2191  obj_loss: 0.0635  noobj_loss: 0.0456  bbox_loss: 0.0058  cls_loss: 0.1039  \n",
      "<<<iteration:[100/244] - total_loss: 0.2219  obj_loss: 0.0658  noobj_loss: 0.0501  bbox_loss: 0.0063  cls_loss: 0.0998  \n",
      "<<<iteration:[120/244] - total_loss: 0.2209  obj_loss: 0.0536  noobj_loss: 0.0468  bbox_loss: 0.0064  cls_loss: 0.1119  \n",
      "<<<iteration:[140/244] - total_loss: 0.2026  obj_loss: 0.0630  noobj_loss: 0.0499  bbox_loss: 0.0078  cls_loss: 0.0760  \n",
      "<<<iteration:[160/244] - total_loss: 0.2434  obj_loss: 0.0692  noobj_loss: 0.0545  bbox_loss: 0.0073  cls_loss: 0.1103  \n",
      "<<<iteration:[180/244] - total_loss: 0.2204  obj_loss: 0.0669  noobj_loss: 0.0467  bbox_loss: 0.0061  cls_loss: 0.0995  \n",
      "<<<iteration:[200/244] - total_loss: 0.2449  obj_loss: 0.0758  noobj_loss: 0.0478  bbox_loss: 0.0061  cls_loss: 0.1148  \n",
      "<<<iteration:[220/244] - total_loss: 0.2071  obj_loss: 0.0623  noobj_loss: 0.0444  bbox_loss: 0.0060  cls_loss: 0.0927  \n",
      "<<<iteration:[240/244] - total_loss: 0.2144  obj_loss: 0.0627  noobj_loss: 0.0471  bbox_loss: 0.0064  cls_loss: 0.0962  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "epoch:22/100 - Train Loss: 0.2266, Val Loss: 0.2235\n",
      "\n",
      "<<<iteration:[20/244] - total_loss: 0.2305  obj_loss: 0.0719  noobj_loss: 0.0501  bbox_loss: 0.0062  cls_loss: 0.1027  \n",
      "<<<iteration:[40/244] - total_loss: 0.2226  obj_loss: 0.0595  noobj_loss: 0.0451  bbox_loss: 0.0070  cls_loss: 0.1055  \n",
      "<<<iteration:[60/244] - total_loss: 0.2249  obj_loss: 0.0679  noobj_loss: 0.0480  bbox_loss: 0.0070  cls_loss: 0.0981  \n",
      "<<<iteration:[80/244] - total_loss: 0.2656  obj_loss: 0.0792  noobj_loss: 0.0450  bbox_loss: 0.0063  cls_loss: 0.1326  \n",
      "<<<iteration:[100/244] - total_loss: 0.2244  obj_loss: 0.0665  noobj_loss: 0.0426  bbox_loss: 0.0059  cls_loss: 0.1070  \n",
      "<<<iteration:[120/244] - total_loss: 0.2303  obj_loss: 0.0655  noobj_loss: 0.0449  bbox_loss: 0.0064  cls_loss: 0.1103  \n",
      "<<<iteration:[140/244] - total_loss: 0.2436  obj_loss: 0.0641  noobj_loss: 0.0509  bbox_loss: 0.0063  cls_loss: 0.1227  \n",
      "<<<iteration:[160/244] - total_loss: 0.2205  obj_loss: 0.0616  noobj_loss: 0.0479  bbox_loss: 0.0059  cls_loss: 0.1053  \n",
      "<<<iteration:[180/244] - total_loss: 0.2025  obj_loss: 0.0711  noobj_loss: 0.0452  bbox_loss: 0.0068  cls_loss: 0.0750  \n",
      "<<<iteration:[200/244] - total_loss: 0.2162  obj_loss: 0.0682  noobj_loss: 0.0460  bbox_loss: 0.0071  cls_loss: 0.0897  \n",
      "<<<iteration:[220/244] - total_loss: 0.2061  obj_loss: 0.0639  noobj_loss: 0.0439  bbox_loss: 0.0058  cls_loss: 0.0915  \n",
      "<<<iteration:[240/244] - total_loss: 0.2329  obj_loss: 0.0627  noobj_loss: 0.0458  bbox_loss: 0.0064  cls_loss: 0.1153  \n",
      "\n",
      "epoch:23/100 - Train Loss: 0.2261, Val Loss: 0.2210\n",
      "\n",
      "<<<iteration:[20/244] - total_loss: 0.2477  obj_loss: 0.0636  noobj_loss: 0.0540  bbox_loss: 0.0067  cls_loss: 0.1238  \n",
      "<<<iteration:[40/244] - total_loss: 0.2385  obj_loss: 0.0641  noobj_loss: 0.0475  bbox_loss: 0.0063  cls_loss: 0.1190  \n",
      "<<<iteration:[60/244] - total_loss: 0.2207  obj_loss: 0.0715  noobj_loss: 0.0446  bbox_loss: 0.0054  cls_loss: 0.1001  \n",
      "<<<iteration:[80/244] - total_loss: 0.2302  obj_loss: 0.0580  noobj_loss: 0.0420  bbox_loss: 0.0073  cls_loss: 0.1145  \n",
      "<<<iteration:[100/244] - total_loss: 0.2294  obj_loss: 0.0652  noobj_loss: 0.0493  bbox_loss: 0.0069  cls_loss: 0.1048  \n",
      "<<<iteration:[120/244] - total_loss: 0.2065  obj_loss: 0.0759  noobj_loss: 0.0462  bbox_loss: 0.0056  cls_loss: 0.0796  \n",
      "<<<iteration:[140/244] - total_loss: 0.2194  obj_loss: 0.0600  noobj_loss: 0.0427  bbox_loss: 0.0065  cls_loss: 0.1055  \n",
      "<<<iteration:[160/244] - total_loss: 0.2252  obj_loss: 0.0689  noobj_loss: 0.0433  bbox_loss: 0.0061  cls_loss: 0.1040  \n",
      "<<<iteration:[180/244] - total_loss: 0.1923  obj_loss: 0.0646  noobj_loss: 0.0474  bbox_loss: 0.0057  cls_loss: 0.0754  \n",
      "<<<iteration:[200/244] - total_loss: 0.2115  obj_loss: 0.0660  noobj_loss: 0.0488  bbox_loss: 0.0079  cls_loss: 0.0814  \n",
      "<<<iteration:[220/244] - total_loss: 0.2437  obj_loss: 0.0657  noobj_loss: 0.0454  bbox_loss: 0.0063  cls_loss: 0.1239  \n",
      "<<<iteration:[240/244] - total_loss: 0.2159  obj_loss: 0.0746  noobj_loss: 0.0450  bbox_loss: 0.0063  cls_loss: 0.0873  \n",
      "\n",
      "epoch:24/100 - Train Loss: 0.2224, Val Loss: 0.2232\n",
      "\n",
      "<<<iteration:[20/244] - total_loss: 0.2455  obj_loss: 0.0792  noobj_loss: 0.0432  bbox_loss: 0.0057  cls_loss: 0.1163  \n",
      "<<<iteration:[40/244] - total_loss: 0.2222  obj_loss: 0.0608  noobj_loss: 0.0439  bbox_loss: 0.0061  cls_loss: 0.1088  \n",
      "<<<iteration:[60/244] - total_loss: 0.2142  obj_loss: 0.0623  noobj_loss: 0.0514  bbox_loss: 0.0074  cls_loss: 0.0891  \n",
      "<<<iteration:[80/244] - total_loss: 0.2008  obj_loss: 0.0540  noobj_loss: 0.0464  bbox_loss: 0.0073  cls_loss: 0.0869  \n",
      "<<<iteration:[100/244] - total_loss: 0.2113  obj_loss: 0.0659  noobj_loss: 0.0440  bbox_loss: 0.0058  cls_loss: 0.0944  \n",
      "<<<iteration:[120/244] - total_loss: 0.2165  obj_loss: 0.0590  noobj_loss: 0.0443  bbox_loss: 0.0065  cls_loss: 0.1029  \n",
      "<<<iteration:[140/244] - total_loss: 0.2142  obj_loss: 0.0535  noobj_loss: 0.0424  bbox_loss: 0.0059  cls_loss: 0.1099  \n",
      "<<<iteration:[160/244] - total_loss: 0.2283  obj_loss: 0.0608  noobj_loss: 0.0451  bbox_loss: 0.0059  cls_loss: 0.1153  \n",
      "<<<iteration:[180/244] - total_loss: 0.2125  obj_loss: 0.0671  noobj_loss: 0.0401  bbox_loss: 0.0059  cls_loss: 0.0958  \n",
      "<<<iteration:[200/244] - total_loss: 0.2239  obj_loss: 0.0737  noobj_loss: 0.0469  bbox_loss: 0.0055  cls_loss: 0.0991  \n",
      "<<<iteration:[220/244] - total_loss: 0.2317  obj_loss: 0.0719  noobj_loss: 0.0443  bbox_loss: 0.0064  cls_loss: 0.1053  \n",
      "<<<iteration:[240/244] - total_loss: 0.1944  obj_loss: 0.0641  noobj_loss: 0.0436  bbox_loss: 0.0061  cls_loss: 0.0780  \n",
      "\n",
      "epoch:25/100 - Train Loss: 0.2180, Val Loss: 0.2228\n",
      "\n",
      "<<<iteration:[20/244] - total_loss: 0.2325  obj_loss: 0.0652  noobj_loss: 0.0471  bbox_loss: 0.0066  cls_loss: 0.1109  \n",
      "<<<iteration:[40/244] - total_loss: 0.2402  obj_loss: 0.0695  noobj_loss: 0.0452  bbox_loss: 0.0056  cls_loss: 0.1199  \n",
      "<<<iteration:[60/244] - total_loss: 0.1913  obj_loss: 0.0582  noobj_loss: 0.0422  bbox_loss: 0.0061  cls_loss: 0.0815  \n",
      "<<<iteration:[80/244] - total_loss: 0.2161  obj_loss: 0.0604  noobj_loss: 0.0441  bbox_loss: 0.0058  cls_loss: 0.1049  \n",
      "<<<iteration:[100/244] - total_loss: 0.2246  obj_loss: 0.0710  noobj_loss: 0.0436  bbox_loss: 0.0061  cls_loss: 0.1013  \n",
      "<<<iteration:[120/244] - total_loss: 0.2073  obj_loss: 0.0765  noobj_loss: 0.0435  bbox_loss: 0.0057  cls_loss: 0.0804  \n",
      "<<<iteration:[140/244] - total_loss: 0.2067  obj_loss: 0.0666  noobj_loss: 0.0416  bbox_loss: 0.0060  cls_loss: 0.0894  \n",
      "<<<iteration:[160/244] - total_loss: 0.2338  obj_loss: 0.0648  noobj_loss: 0.0447  bbox_loss: 0.0060  cls_loss: 0.1165  \n",
      "<<<iteration:[180/244] - total_loss: 0.1979  obj_loss: 0.0648  noobj_loss: 0.0427  bbox_loss: 0.0063  cls_loss: 0.0804  \n",
      "<<<iteration:[200/244] - total_loss: 0.2053  obj_loss: 0.0690  noobj_loss: 0.0434  bbox_loss: 0.0060  cls_loss: 0.0848  \n",
      "<<<iteration:[220/244] - total_loss: 0.2204  obj_loss: 0.0616  noobj_loss: 0.0436  bbox_loss: 0.0054  cls_loss: 0.1102  \n",
      "<<<iteration:[240/244] - total_loss: 0.2211  obj_loss: 0.0628  noobj_loss: 0.0432  bbox_loss: 0.0063  cls_loss: 0.1051  \n",
      "\n",
      "epoch:26/100 - Train Loss: 0.2147, Val Loss: 0.2157\n",
      "\n",
      "<<<iteration:[20/244] - total_loss: 0.2426  obj_loss: 0.0636  noobj_loss: 0.0486  bbox_loss: 0.0071  cls_loss: 0.1193  \n",
      "<<<iteration:[40/244] - total_loss: 0.1977  obj_loss: 0.0581  noobj_loss: 0.0411  bbox_loss: 0.0062  cls_loss: 0.0880  \n",
      "<<<iteration:[60/244] - total_loss: 0.2161  obj_loss: 0.0685  noobj_loss: 0.0419  bbox_loss: 0.0053  cls_loss: 0.1001  \n",
      "<<<iteration:[80/244] - total_loss: 0.2103  obj_loss: 0.0594  noobj_loss: 0.0431  bbox_loss: 0.0061  cls_loss: 0.0991  \n",
      "<<<iteration:[100/244] - total_loss: 0.2006  obj_loss: 0.0625  noobj_loss: 0.0368  bbox_loss: 0.0050  cls_loss: 0.0949  \n",
      "<<<iteration:[120/244] - total_loss: 0.2559  obj_loss: 0.0763  noobj_loss: 0.0429  bbox_loss: 0.0062  cls_loss: 0.1274  \n",
      "<<<iteration:[140/244] - total_loss: 0.2372  obj_loss: 0.0618  noobj_loss: 0.0408  bbox_loss: 0.0062  cls_loss: 0.1239  \n",
      "<<<iteration:[160/244] - total_loss: 0.1873  obj_loss: 0.0626  noobj_loss: 0.0408  bbox_loss: 0.0054  cls_loss: 0.0772  \n",
      "<<<iteration:[180/244] - total_loss: 0.2217  obj_loss: 0.0646  noobj_loss: 0.0462  bbox_loss: 0.0070  cls_loss: 0.0991  \n",
      "<<<iteration:[200/244] - total_loss: 0.2131  obj_loss: 0.0649  noobj_loss: 0.0421  bbox_loss: 0.0062  cls_loss: 0.0964  \n",
      "<<<iteration:[220/244] - total_loss: 0.2085  obj_loss: 0.0702  noobj_loss: 0.0481  bbox_loss: 0.0065  cls_loss: 0.0820  \n",
      "<<<iteration:[240/244] - total_loss: 0.2196  obj_loss: 0.0694  noobj_loss: 0.0437  bbox_loss: 0.0058  cls_loss: 0.0992  \n",
      "\n",
      "epoch:27/100 - Train Loss: 0.2164, Val Loss: 0.2175\n",
      "\n",
      "<<<iteration:[20/244] - total_loss: 0.2214  obj_loss: 0.0680  noobj_loss: 0.0447  bbox_loss: 0.0062  cls_loss: 0.0999  \n",
      "<<<iteration:[40/244] - total_loss: 0.2034  obj_loss: 0.0697  noobj_loss: 0.0423  bbox_loss: 0.0052  cls_loss: 0.0868  \n",
      "<<<iteration:[60/244] - total_loss: 0.2438  obj_loss: 0.0686  noobj_loss: 0.0410  bbox_loss: 0.0063  cls_loss: 0.1233  \n",
      "<<<iteration:[80/244] - total_loss: 0.2121  obj_loss: 0.0682  noobj_loss: 0.0402  bbox_loss: 0.0051  cls_loss: 0.0984  \n",
      "<<<iteration:[100/244] - total_loss: 0.2133  obj_loss: 0.0635  noobj_loss: 0.0432  bbox_loss: 0.0059  cls_loss: 0.0985  \n",
      "<<<iteration:[120/244] - total_loss: 0.2313  obj_loss: 0.0683  noobj_loss: 0.0411  bbox_loss: 0.0059  cls_loss: 0.1128  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<<<iteration:[140/244] - total_loss: 0.1986  obj_loss: 0.0636  noobj_loss: 0.0413  bbox_loss: 0.0049  cls_loss: 0.0900  \n",
      "<<<iteration:[160/244] - total_loss: 0.2233  obj_loss: 0.0697  noobj_loss: 0.0455  bbox_loss: 0.0063  cls_loss: 0.0995  \n",
      "<<<iteration:[180/244] - total_loss: 0.1976  obj_loss: 0.0702  noobj_loss: 0.0415  bbox_loss: 0.0056  cls_loss: 0.0786  \n",
      "<<<iteration:[200/244] - total_loss: 0.2155  obj_loss: 0.0673  noobj_loss: 0.0421  bbox_loss: 0.0057  cls_loss: 0.0985  \n",
      "<<<iteration:[220/244] - total_loss: 0.2092  obj_loss: 0.0662  noobj_loss: 0.0423  bbox_loss: 0.0054  cls_loss: 0.0946  \n",
      "<<<iteration:[240/244] - total_loss: 0.2049  obj_loss: 0.0692  noobj_loss: 0.0425  bbox_loss: 0.0059  cls_loss: 0.0848  \n",
      "\n",
      "epoch:28/100 - Train Loss: 0.2134, Val Loss: 0.2165\n",
      "\n",
      "<<<iteration:[20/244] - total_loss: 0.2199  obj_loss: 0.0720  noobj_loss: 0.0459  bbox_loss: 0.0059  cls_loss: 0.0954  \n",
      "<<<iteration:[40/244] - total_loss: 0.2372  obj_loss: 0.0771  noobj_loss: 0.0488  bbox_loss: 0.0056  cls_loss: 0.1076  \n",
      "<<<iteration:[60/244] - total_loss: 0.1838  obj_loss: 0.0661  noobj_loss: 0.0416  bbox_loss: 0.0056  cls_loss: 0.0687  \n",
      "<<<iteration:[80/244] - total_loss: 0.1990  obj_loss: 0.0596  noobj_loss: 0.0391  bbox_loss: 0.0047  cls_loss: 0.0962  \n",
      "<<<iteration:[100/244] - total_loss: 0.2198  obj_loss: 0.0711  noobj_loss: 0.0397  bbox_loss: 0.0048  cls_loss: 0.1049  \n",
      "<<<iteration:[120/244] - total_loss: 0.2560  obj_loss: 0.0617  noobj_loss: 0.0414  bbox_loss: 0.0073  cls_loss: 0.1369  \n",
      "<<<iteration:[140/244] - total_loss: 0.1980  obj_loss: 0.0676  noobj_loss: 0.0471  bbox_loss: 0.0059  cls_loss: 0.0774  \n",
      "<<<iteration:[160/244] - total_loss: 0.2427  obj_loss: 0.0645  noobj_loss: 0.0416  bbox_loss: 0.0059  cls_loss: 0.1280  \n",
      "<<<iteration:[180/244] - total_loss: 0.1758  obj_loss: 0.0657  noobj_loss: 0.0405  bbox_loss: 0.0057  cls_loss: 0.0611  \n",
      "<<<iteration:[200/244] - total_loss: 0.2345  obj_loss: 0.0735  noobj_loss: 0.0428  bbox_loss: 0.0056  cls_loss: 0.1115  \n",
      "<<<iteration:[220/244] - total_loss: 0.1994  obj_loss: 0.0591  noobj_loss: 0.0410  bbox_loss: 0.0057  cls_loss: 0.0913  \n",
      "<<<iteration:[240/244] - total_loss: 0.1991  obj_loss: 0.0617  noobj_loss: 0.0448  bbox_loss: 0.0055  cls_loss: 0.0873  \n",
      "\n",
      "epoch:29/100 - Train Loss: 0.2120, Val Loss: 0.2144\n",
      "\n",
      "<<<iteration:[20/244] - total_loss: 0.1779  obj_loss: 0.0632  noobj_loss: 0.0444  bbox_loss: 0.0059  cls_loss: 0.0631  \n",
      "<<<iteration:[40/244] - total_loss: 0.1841  obj_loss: 0.0622  noobj_loss: 0.0420  bbox_loss: 0.0061  cls_loss: 0.0703  \n",
      "<<<iteration:[60/244] - total_loss: 0.2092  obj_loss: 0.0622  noobj_loss: 0.0438  bbox_loss: 0.0061  cls_loss: 0.0947  \n",
      "<<<iteration:[80/244] - total_loss: 0.2303  obj_loss: 0.0775  noobj_loss: 0.0435  bbox_loss: 0.0051  cls_loss: 0.1054  \n",
      "<<<iteration:[100/244] - total_loss: 0.2177  obj_loss: 0.0685  noobj_loss: 0.0393  bbox_loss: 0.0052  cls_loss: 0.1038  \n",
      "<<<iteration:[120/244] - total_loss: 0.2462  obj_loss: 0.0652  noobj_loss: 0.0431  bbox_loss: 0.0058  cls_loss: 0.1306  \n",
      "<<<iteration:[140/244] - total_loss: 0.2100  obj_loss: 0.0609  noobj_loss: 0.0425  bbox_loss: 0.0058  cls_loss: 0.0989  \n",
      "<<<iteration:[160/244] - total_loss: 0.2307  obj_loss: 0.0704  noobj_loss: 0.0446  bbox_loss: 0.0059  cls_loss: 0.1087  \n",
      "<<<iteration:[180/244] - total_loss: 0.2597  obj_loss: 0.0695  noobj_loss: 0.0436  bbox_loss: 0.0061  cls_loss: 0.1378  \n",
      "<<<iteration:[200/244] - total_loss: 0.1917  obj_loss: 0.0658  noobj_loss: 0.0406  bbox_loss: 0.0052  cls_loss: 0.0796  \n",
      "<<<iteration:[220/244] - total_loss: 0.2102  obj_loss: 0.0669  noobj_loss: 0.0463  bbox_loss: 0.0066  cls_loss: 0.0872  \n",
      "<<<iteration:[240/244] - total_loss: 0.2139  obj_loss: 0.0624  noobj_loss: 0.0406  bbox_loss: 0.0053  cls_loss: 0.1045  \n",
      "\n",
      "epoch:30/100 - Train Loss: 0.2134, Val Loss: 0.2178\n",
      "\n",
      "<<<iteration:[20/244] - total_loss: 0.2087  obj_loss: 0.0657  noobj_loss: 0.0464  bbox_loss: 0.0061  cls_loss: 0.0894  \n",
      "<<<iteration:[40/244] - total_loss: 0.1888  obj_loss: 0.0634  noobj_loss: 0.0433  bbox_loss: 0.0051  cls_loss: 0.0783  \n",
      "<<<iteration:[60/244] - total_loss: 0.2027  obj_loss: 0.0641  noobj_loss: 0.0379  bbox_loss: 0.0053  cls_loss: 0.0929  \n",
      "<<<iteration:[80/244] - total_loss: 0.2261  obj_loss: 0.0682  noobj_loss: 0.0479  bbox_loss: 0.0060  cls_loss: 0.1039  \n",
      "<<<iteration:[100/244] - total_loss: 0.2105  obj_loss: 0.0635  noobj_loss: 0.0395  bbox_loss: 0.0060  cls_loss: 0.0971  \n",
      "<<<iteration:[120/244] - total_loss: 0.2050  obj_loss: 0.0740  noobj_loss: 0.0420  bbox_loss: 0.0055  cls_loss: 0.0822  \n",
      "<<<iteration:[140/244] - total_loss: 0.2300  obj_loss: 0.0640  noobj_loss: 0.0419  bbox_loss: 0.0051  cls_loss: 0.1195  \n",
      "<<<iteration:[160/244] - total_loss: 0.2333  obj_loss: 0.0746  noobj_loss: 0.0453  bbox_loss: 0.0052  cls_loss: 0.1100  \n",
      "<<<iteration:[180/244] - total_loss: 0.1977  obj_loss: 0.0678  noobj_loss: 0.0396  bbox_loss: 0.0057  cls_loss: 0.0814  \n",
      "<<<iteration:[200/244] - total_loss: 0.2255  obj_loss: 0.0696  noobj_loss: 0.0451  bbox_loss: 0.0054  cls_loss: 0.1064  \n",
      "<<<iteration:[220/244] - total_loss: 0.2166  obj_loss: 0.0669  noobj_loss: 0.0435  bbox_loss: 0.0055  cls_loss: 0.1005  \n",
      "<<<iteration:[240/244] - total_loss: 0.1894  obj_loss: 0.0679  noobj_loss: 0.0470  bbox_loss: 0.0069  cls_loss: 0.0637  \n",
      "\n",
      "epoch:31/100 - Train Loss: 0.2097, Val Loss: 0.2164\n",
      "\n",
      "<<<iteration:[20/244] - total_loss: 0.2274  obj_loss: 0.0630  noobj_loss: 0.0459  bbox_loss: 0.0073  cls_loss: 0.1050  \n",
      "<<<iteration:[40/244] - total_loss: 0.2215  obj_loss: 0.0736  noobj_loss: 0.0475  bbox_loss: 0.0055  cls_loss: 0.0968  \n",
      "<<<iteration:[60/244] - total_loss: 0.2159  obj_loss: 0.0619  noobj_loss: 0.0446  bbox_loss: 0.0059  cls_loss: 0.1022  \n",
      "<<<iteration:[80/244] - total_loss: 0.2257  obj_loss: 0.0691  noobj_loss: 0.0480  bbox_loss: 0.0066  cls_loss: 0.0993  \n",
      "<<<iteration:[100/244] - total_loss: 0.2047  obj_loss: 0.0608  noobj_loss: 0.0399  bbox_loss: 0.0053  cls_loss: 0.0975  \n",
      "<<<iteration:[120/244] - total_loss: 0.2460  obj_loss: 0.0661  noobj_loss: 0.0390  bbox_loss: 0.0057  cls_loss: 0.1321  \n",
      "<<<iteration:[140/244] - total_loss: 0.2068  obj_loss: 0.0749  noobj_loss: 0.0413  bbox_loss: 0.0049  cls_loss: 0.0867  \n",
      "<<<iteration:[160/244] - total_loss: 0.2254  obj_loss: 0.0741  noobj_loss: 0.0403  bbox_loss: 0.0055  cls_loss: 0.1035  \n",
      "<<<iteration:[180/244] - total_loss: 0.1876  obj_loss: 0.0632  noobj_loss: 0.0393  bbox_loss: 0.0052  cls_loss: 0.0788  \n",
      "<<<iteration:[200/244] - total_loss: 0.2206  obj_loss: 0.0626  noobj_loss: 0.0394  bbox_loss: 0.0056  cls_loss: 0.1103  \n",
      "<<<iteration:[220/244] - total_loss: 0.1700  obj_loss: 0.0610  noobj_loss: 0.0366  bbox_loss: 0.0048  cls_loss: 0.0665  \n",
      "<<<iteration:[240/244] - total_loss: 0.1860  obj_loss: 0.0653  noobj_loss: 0.0404  bbox_loss: 0.0046  cls_loss: 0.0775  \n",
      "\n",
      "epoch:32/100 - Train Loss: 0.2100, Val Loss: 0.2120\n",
      "\n",
      "<<<iteration:[20/244] - total_loss: 0.2078  obj_loss: 0.0747  noobj_loss: 0.0392  bbox_loss: 0.0048  cls_loss: 0.0898  \n",
      "<<<iteration:[40/244] - total_loss: 0.2206  obj_loss: 0.0791  noobj_loss: 0.0396  bbox_loss: 0.0058  cls_loss: 0.0927  \n",
      "<<<iteration:[60/244] - total_loss: 0.2028  obj_loss: 0.0585  noobj_loss: 0.0371  bbox_loss: 0.0057  cls_loss: 0.0971  \n",
      "<<<iteration:[80/244] - total_loss: 0.2174  obj_loss: 0.0689  noobj_loss: 0.0414  bbox_loss: 0.0055  cls_loss: 0.1005  \n",
      "<<<iteration:[100/244] - total_loss: 0.2202  obj_loss: 0.0671  noobj_loss: 0.0413  bbox_loss: 0.0052  cls_loss: 0.1066  \n",
      "<<<iteration:[120/244] - total_loss: 0.2260  obj_loss: 0.0652  noobj_loss: 0.0409  bbox_loss: 0.0049  cls_loss: 0.1157  \n",
      "<<<iteration:[140/244] - total_loss: 0.1787  obj_loss: 0.0639  noobj_loss: 0.0404  bbox_loss: 0.0049  cls_loss: 0.0703  \n",
      "<<<iteration:[160/244] - total_loss: 0.1939  obj_loss: 0.0629  noobj_loss: 0.0404  bbox_loss: 0.0050  cls_loss: 0.0860  \n",
      "<<<iteration:[180/244] - total_loss: 0.2244  obj_loss: 0.0792  noobj_loss: 0.0398  bbox_loss: 0.0050  cls_loss: 0.1003  \n",
      "<<<iteration:[200/244] - total_loss: 0.1800  obj_loss: 0.0678  noobj_loss: 0.0416  bbox_loss: 0.0048  cls_loss: 0.0674  \n",
      "<<<iteration:[220/244] - total_loss: 0.2014  obj_loss: 0.0704  noobj_loss: 0.0394  bbox_loss: 0.0051  cls_loss: 0.0858  \n",
      "<<<iteration:[240/244] - total_loss: 0.1990  obj_loss: 0.0703  noobj_loss: 0.0393  bbox_loss: 0.0049  cls_loss: 0.0844  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "epoch:33/100 - Train Loss: 0.2054, Val Loss: 0.2120\n",
      "\n",
      "<<<iteration:[20/244] - total_loss: 0.2080  obj_loss: 0.0765  noobj_loss: 0.0416  bbox_loss: 0.0053  cls_loss: 0.0844  \n",
      "<<<iteration:[40/244] - total_loss: 0.2062  obj_loss: 0.0698  noobj_loss: 0.0392  bbox_loss: 0.0053  cls_loss: 0.0902  \n",
      "<<<iteration:[60/244] - total_loss: 0.2032  obj_loss: 0.0637  noobj_loss: 0.0415  bbox_loss: 0.0053  cls_loss: 0.0921  \n",
      "<<<iteration:[80/244] - total_loss: 0.2101  obj_loss: 0.0616  noobj_loss: 0.0396  bbox_loss: 0.0059  cls_loss: 0.0993  \n",
      "<<<iteration:[100/244] - total_loss: 0.2289  obj_loss: 0.0659  noobj_loss: 0.0395  bbox_loss: 0.0047  cls_loss: 0.1196  \n",
      "<<<iteration:[120/244] - total_loss: 0.1944  obj_loss: 0.0685  noobj_loss: 0.0408  bbox_loss: 0.0054  cls_loss: 0.0785  \n",
      "<<<iteration:[140/244] - total_loss: 0.2297  obj_loss: 0.0678  noobj_loss: 0.0389  bbox_loss: 0.0055  cls_loss: 0.1150  \n",
      "<<<iteration:[160/244] - total_loss: 0.2228  obj_loss: 0.0737  noobj_loss: 0.0400  bbox_loss: 0.0051  cls_loss: 0.1038  \n",
      "<<<iteration:[180/244] - total_loss: 0.2023  obj_loss: 0.0628  noobj_loss: 0.0416  bbox_loss: 0.0067  cls_loss: 0.0850  \n",
      "<<<iteration:[200/244] - total_loss: 0.1855  obj_loss: 0.0695  noobj_loss: 0.0415  bbox_loss: 0.0050  cls_loss: 0.0702  \n",
      "<<<iteration:[220/244] - total_loss: 0.1990  obj_loss: 0.0638  noobj_loss: 0.0449  bbox_loss: 0.0078  cls_loss: 0.0736  \n",
      "<<<iteration:[240/244] - total_loss: 0.2214  obj_loss: 0.0698  noobj_loss: 0.0402  bbox_loss: 0.0060  cls_loss: 0.1017  \n",
      "\n",
      "epoch:34/100 - Train Loss: 0.2074, Val Loss: 0.2136\n",
      "\n",
      "<<<iteration:[20/244] - total_loss: 0.2188  obj_loss: 0.0770  noobj_loss: 0.0444  bbox_loss: 0.0057  cls_loss: 0.0912  \n",
      "<<<iteration:[40/244] - total_loss: 0.1937  obj_loss: 0.0742  noobj_loss: 0.0444  bbox_loss: 0.0059  cls_loss: 0.0678  \n",
      "<<<iteration:[60/244] - total_loss: 0.1962  obj_loss: 0.0722  noobj_loss: 0.0415  bbox_loss: 0.0047  cls_loss: 0.0798  \n",
      "<<<iteration:[80/244] - total_loss: 0.2361  obj_loss: 0.0711  noobj_loss: 0.0403  bbox_loss: 0.0051  cls_loss: 0.1196  \n",
      "<<<iteration:[100/244] - total_loss: 0.2208  obj_loss: 0.0682  noobj_loss: 0.0390  bbox_loss: 0.0048  cls_loss: 0.1092  \n",
      "<<<iteration:[120/244] - total_loss: 0.1920  obj_loss: 0.0663  noobj_loss: 0.0414  bbox_loss: 0.0056  cls_loss: 0.0770  \n",
      "<<<iteration:[140/244] - total_loss: 0.2135  obj_loss: 0.0640  noobj_loss: 0.0469  bbox_loss: 0.0067  cls_loss: 0.0926  \n",
      "<<<iteration:[160/244] - total_loss: 0.2167  obj_loss: 0.0622  noobj_loss: 0.0413  bbox_loss: 0.0059  cls_loss: 0.1042  \n",
      "<<<iteration:[180/244] - total_loss: 0.2199  obj_loss: 0.0749  noobj_loss: 0.0407  bbox_loss: 0.0051  cls_loss: 0.0993  \n",
      "<<<iteration:[200/244] - total_loss: 0.2073  obj_loss: 0.0676  noobj_loss: 0.0397  bbox_loss: 0.0049  cls_loss: 0.0954  \n",
      "<<<iteration:[220/244] - total_loss: 0.1953  obj_loss: 0.0696  noobj_loss: 0.0388  bbox_loss: 0.0056  cls_loss: 0.0785  \n",
      "<<<iteration:[240/244] - total_loss: 0.2026  obj_loss: 0.0621  noobj_loss: 0.0393  bbox_loss: 0.0051  cls_loss: 0.0952  \n",
      "\n",
      "epoch:35/100 - Train Loss: 0.2079, Val Loss: 0.2154\n",
      "\n",
      "<<<iteration:[20/244] - total_loss: 0.2169  obj_loss: 0.0739  noobj_loss: 0.0409  bbox_loss: 0.0058  cls_loss: 0.0934  \n",
      "<<<iteration:[40/244] - total_loss: 0.1831  obj_loss: 0.0666  noobj_loss: 0.0385  bbox_loss: 0.0047  cls_loss: 0.0739  \n",
      "<<<iteration:[60/244] - total_loss: 0.2105  obj_loss: 0.0761  noobj_loss: 0.0391  bbox_loss: 0.0049  cls_loss: 0.0903  \n",
      "<<<iteration:[80/244] - total_loss: 0.2565  obj_loss: 0.0700  noobj_loss: 0.0446  bbox_loss: 0.0063  cls_loss: 0.1327  \n",
      "<<<iteration:[100/244] - total_loss: 0.1960  obj_loss: 0.0688  noobj_loss: 0.0432  bbox_loss: 0.0055  cls_loss: 0.0783  \n",
      "<<<iteration:[120/244] - total_loss: 0.1989  obj_loss: 0.0644  noobj_loss: 0.0402  bbox_loss: 0.0047  cls_loss: 0.0908  \n",
      "<<<iteration:[140/244] - total_loss: 0.2247  obj_loss: 0.0802  noobj_loss: 0.0398  bbox_loss: 0.0055  cls_loss: 0.0969  \n",
      "<<<iteration:[160/244] - total_loss: 0.2243  obj_loss: 0.0667  noobj_loss: 0.0390  bbox_loss: 0.0051  cls_loss: 0.1124  \n",
      "<<<iteration:[180/244] - total_loss: 0.1728  obj_loss: 0.0695  noobj_loss: 0.0399  bbox_loss: 0.0045  cls_loss: 0.0607  \n",
      "<<<iteration:[200/244] - total_loss: 0.1938  obj_loss: 0.0666  noobj_loss: 0.0383  bbox_loss: 0.0059  cls_loss: 0.0787  \n",
      "<<<iteration:[220/244] - total_loss: 0.2076  obj_loss: 0.0670  noobj_loss: 0.0426  bbox_loss: 0.0057  cls_loss: 0.0910  \n",
      "<<<iteration:[240/244] - total_loss: 0.1999  obj_loss: 0.0675  noobj_loss: 0.0391  bbox_loss: 0.0052  cls_loss: 0.0867  \n",
      "\n",
      "epoch:36/100 - Train Loss: 0.2056, Val Loss: 0.2162\n",
      "\n",
      "<<<iteration:[20/244] - total_loss: 0.2198  obj_loss: 0.0729  noobj_loss: 0.0427  bbox_loss: 0.0051  cls_loss: 0.1001  \n",
      "<<<iteration:[40/244] - total_loss: 0.1932  obj_loss: 0.0678  noobj_loss: 0.0385  bbox_loss: 0.0048  cls_loss: 0.0823  \n",
      "<<<iteration:[60/244] - total_loss: 0.2070  obj_loss: 0.0723  noobj_loss: 0.0412  bbox_loss: 0.0049  cls_loss: 0.0896  \n",
      "<<<iteration:[80/244] - total_loss: 0.2021  obj_loss: 0.0748  noobj_loss: 0.0398  bbox_loss: 0.0043  cls_loss: 0.0860  \n",
      "<<<iteration:[100/244] - total_loss: 0.1896  obj_loss: 0.0741  noobj_loss: 0.0404  bbox_loss: 0.0056  cls_loss: 0.0674  \n",
      "<<<iteration:[120/244] - total_loss: 0.2198  obj_loss: 0.0707  noobj_loss: 0.0482  bbox_loss: 0.0053  cls_loss: 0.0986  \n",
      "<<<iteration:[140/244] - total_loss: 0.1933  obj_loss: 0.0601  noobj_loss: 0.0393  bbox_loss: 0.0053  cls_loss: 0.0872  \n",
      "<<<iteration:[160/244] - total_loss: 0.1985  obj_loss: 0.0712  noobj_loss: 0.0451  bbox_loss: 0.0061  cls_loss: 0.0744  \n",
      "<<<iteration:[180/244] - total_loss: 0.2218  obj_loss: 0.0685  noobj_loss: 0.0399  bbox_loss: 0.0056  cls_loss: 0.1053  \n",
      "<<<iteration:[200/244] - total_loss: 0.1837  obj_loss: 0.0659  noobj_loss: 0.0423  bbox_loss: 0.0059  cls_loss: 0.0674  \n",
      "<<<iteration:[220/244] - total_loss: 0.2178  obj_loss: 0.0776  noobj_loss: 0.0389  bbox_loss: 0.0049  cls_loss: 0.0960  \n",
      "<<<iteration:[240/244] - total_loss: 0.2021  obj_loss: 0.0694  noobj_loss: 0.0416  bbox_loss: 0.0059  cls_loss: 0.0825  \n",
      "\n",
      "epoch:37/100 - Train Loss: 0.2038, Val Loss: 0.2158\n",
      "\n",
      "<<<iteration:[20/244] - total_loss: 0.2122  obj_loss: 0.0713  noobj_loss: 0.0438  bbox_loss: 0.0053  cls_loss: 0.0926  \n",
      "<<<iteration:[40/244] - total_loss: 0.2046  obj_loss: 0.0618  noobj_loss: 0.0364  bbox_loss: 0.0047  cls_loss: 0.1011  \n",
      "<<<iteration:[60/244] - total_loss: 0.1694  obj_loss: 0.0645  noobj_loss: 0.0383  bbox_loss: 0.0047  cls_loss: 0.0621  \n",
      "<<<iteration:[80/244] - total_loss: 0.2468  obj_loss: 0.0825  noobj_loss: 0.0422  bbox_loss: 0.0048  cls_loss: 0.1191  \n",
      "<<<iteration:[100/244] - total_loss: 0.2305  obj_loss: 0.0705  noobj_loss: 0.0411  bbox_loss: 0.0056  cls_loss: 0.1115  \n",
      "<<<iteration:[120/244] - total_loss: 0.2046  obj_loss: 0.0683  noobj_loss: 0.0397  bbox_loss: 0.0050  cls_loss: 0.0916  \n",
      "<<<iteration:[140/244] - total_loss: 0.2049  obj_loss: 0.0703  noobj_loss: 0.0401  bbox_loss: 0.0052  cls_loss: 0.0885  \n",
      "<<<iteration:[160/244] - total_loss: 0.2023  obj_loss: 0.0733  noobj_loss: 0.0394  bbox_loss: 0.0045  cls_loss: 0.0866  \n",
      "<<<iteration:[180/244] - total_loss: 0.1746  obj_loss: 0.0649  noobj_loss: 0.0392  bbox_loss: 0.0051  cls_loss: 0.0646  \n",
      "<<<iteration:[200/244] - total_loss: 0.1949  obj_loss: 0.0706  noobj_loss: 0.0381  bbox_loss: 0.0056  cls_loss: 0.0770  \n",
      "<<<iteration:[220/244] - total_loss: 0.2120  obj_loss: 0.0774  noobj_loss: 0.0417  bbox_loss: 0.0050  cls_loss: 0.0889  \n",
      "<<<iteration:[240/244] - total_loss: 0.2041  obj_loss: 0.0640  noobj_loss: 0.0379  bbox_loss: 0.0050  cls_loss: 0.0962  \n",
      "\n",
      "epoch:38/100 - Train Loss: 0.2041, Val Loss: 0.2112\n",
      "\n",
      "<<<iteration:[20/244] - total_loss: 0.2134  obj_loss: 0.0722  noobj_loss: 0.0403  bbox_loss: 0.0051  cls_loss: 0.0957  \n",
      "<<<iteration:[40/244] - total_loss: 0.1881  obj_loss: 0.0620  noobj_loss: 0.0434  bbox_loss: 0.0050  cls_loss: 0.0796  \n",
      "<<<iteration:[60/244] - total_loss: 0.2173  obj_loss: 0.0647  noobj_loss: 0.0376  bbox_loss: 0.0053  cls_loss: 0.1073  \n",
      "<<<iteration:[80/244] - total_loss: 0.2180  obj_loss: 0.0784  noobj_loss: 0.0403  bbox_loss: 0.0052  cls_loss: 0.0934  \n",
      "<<<iteration:[100/244] - total_loss: 0.2089  obj_loss: 0.0702  noobj_loss: 0.0419  bbox_loss: 0.0049  cls_loss: 0.0931  \n",
      "<<<iteration:[120/244] - total_loss: 0.1992  obj_loss: 0.0663  noobj_loss: 0.0367  bbox_loss: 0.0049  cls_loss: 0.0902  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<<<iteration:[140/244] - total_loss: 0.1850  obj_loss: 0.0641  noobj_loss: 0.0389  bbox_loss: 0.0055  cls_loss: 0.0740  \n",
      "<<<iteration:[160/244] - total_loss: 0.2030  obj_loss: 0.0595  noobj_loss: 0.0399  bbox_loss: 0.0068  cls_loss: 0.0893  \n",
      "<<<iteration:[180/244] - total_loss: 0.1850  obj_loss: 0.0716  noobj_loss: 0.0385  bbox_loss: 0.0069  cls_loss: 0.0598  \n",
      "<<<iteration:[200/244] - total_loss: 0.2045  obj_loss: 0.0591  noobj_loss: 0.0396  bbox_loss: 0.0053  cls_loss: 0.0988  \n",
      "<<<iteration:[220/244] - total_loss: 0.2061  obj_loss: 0.0670  noobj_loss: 0.0435  bbox_loss: 0.0070  cls_loss: 0.0825  \n",
      "<<<iteration:[240/244] - total_loss: 0.2061  obj_loss: 0.0713  noobj_loss: 0.0400  bbox_loss: 0.0060  cls_loss: 0.0848  \n",
      "\n",
      "epoch:39/100 - Train Loss: 0.2013, Val Loss: 0.2121\n",
      "\n",
      "<<<iteration:[20/244] - total_loss: 0.2073  obj_loss: 0.0700  noobj_loss: 0.0412  bbox_loss: 0.0057  cls_loss: 0.0882  \n",
      "<<<iteration:[40/244] - total_loss: 0.2244  obj_loss: 0.0805  noobj_loss: 0.0402  bbox_loss: 0.0052  cls_loss: 0.0978  \n",
      "<<<iteration:[60/244] - total_loss: 0.2026  obj_loss: 0.0676  noobj_loss: 0.0396  bbox_loss: 0.0064  cls_loss: 0.0831  \n",
      "<<<iteration:[80/244] - total_loss: 0.1845  obj_loss: 0.0679  noobj_loss: 0.0351  bbox_loss: 0.0049  cls_loss: 0.0742  \n",
      "<<<iteration:[100/244] - total_loss: 0.1962  obj_loss: 0.0642  noobj_loss: 0.0407  bbox_loss: 0.0065  cls_loss: 0.0794  \n",
      "<<<iteration:[120/244] - total_loss: 0.2012  obj_loss: 0.0725  noobj_loss: 0.0380  bbox_loss: 0.0049  cls_loss: 0.0849  \n",
      "<<<iteration:[140/244] - total_loss: 0.2312  obj_loss: 0.0664  noobj_loss: 0.0391  bbox_loss: 0.0051  cls_loss: 0.1196  \n",
      "<<<iteration:[160/244] - total_loss: 0.1995  obj_loss: 0.0646  noobj_loss: 0.0383  bbox_loss: 0.0049  cls_loss: 0.0915  \n",
      "<<<iteration:[180/244] - total_loss: 0.2032  obj_loss: 0.0755  noobj_loss: 0.0384  bbox_loss: 0.0049  cls_loss: 0.0841  \n",
      "<<<iteration:[200/244] - total_loss: 0.1946  obj_loss: 0.0664  noobj_loss: 0.0406  bbox_loss: 0.0054  cls_loss: 0.0808  \n",
      "<<<iteration:[220/244] - total_loss: 0.1914  obj_loss: 0.0746  noobj_loss: 0.0373  bbox_loss: 0.0049  cls_loss: 0.0738  \n",
      "<<<iteration:[240/244] - total_loss: 0.1848  obj_loss: 0.0652  noobj_loss: 0.0399  bbox_loss: 0.0053  cls_loss: 0.0732  \n",
      "\n",
      "epoch:40/100 - Train Loss: 0.2009, Val Loss: 0.2113\n",
      "\n",
      "<<<iteration:[20/244] - total_loss: 0.2172  obj_loss: 0.0694  noobj_loss: 0.0420  bbox_loss: 0.0055  cls_loss: 0.0994  \n",
      "<<<iteration:[40/244] - total_loss: 0.2176  obj_loss: 0.0741  noobj_loss: 0.0424  bbox_loss: 0.0055  cls_loss: 0.0949  \n",
      "<<<iteration:[60/244] - total_loss: 0.1773  obj_loss: 0.0670  noobj_loss: 0.0360  bbox_loss: 0.0045  cls_loss: 0.0699  \n",
      "<<<iteration:[80/244] - total_loss: 0.1745  obj_loss: 0.0650  noobj_loss: 0.0413  bbox_loss: 0.0049  cls_loss: 0.0645  \n",
      "<<<iteration:[100/244] - total_loss: 0.1814  obj_loss: 0.0718  noobj_loss: 0.0408  bbox_loss: 0.0046  cls_loss: 0.0662  \n",
      "<<<iteration:[120/244] - total_loss: 0.2178  obj_loss: 0.0783  noobj_loss: 0.0397  bbox_loss: 0.0044  cls_loss: 0.0974  \n",
      "<<<iteration:[140/244] - total_loss: 0.2184  obj_loss: 0.0679  noobj_loss: 0.0383  bbox_loss: 0.0058  cls_loss: 0.1025  \n",
      "<<<iteration:[160/244] - total_loss: 0.2209  obj_loss: 0.0715  noobj_loss: 0.0420  bbox_loss: 0.0058  cls_loss: 0.0997  \n",
      "<<<iteration:[180/244] - total_loss: 0.2304  obj_loss: 0.0740  noobj_loss: 0.0383  bbox_loss: 0.0053  cls_loss: 0.1107  \n",
      "<<<iteration:[200/244] - total_loss: 0.2009  obj_loss: 0.0670  noobj_loss: 0.0417  bbox_loss: 0.0061  cls_loss: 0.0827  \n",
      "<<<iteration:[220/244] - total_loss: 0.1853  obj_loss: 0.0742  noobj_loss: 0.0391  bbox_loss: 0.0048  cls_loss: 0.0673  \n",
      "<<<iteration:[240/244] - total_loss: 0.1866  obj_loss: 0.0708  noobj_loss: 0.0377  bbox_loss: 0.0043  cls_loss: 0.0752  \n",
      "\n",
      "epoch:41/100 - Train Loss: 0.2029, Val Loss: 0.2103\n",
      "\n",
      "<<<iteration:[20/244] - total_loss: 0.1745  obj_loss: 0.0683  noobj_loss: 0.0418  bbox_loss: 0.0049  cls_loss: 0.0609  \n",
      "<<<iteration:[40/244] - total_loss: 0.2013  obj_loss: 0.0729  noobj_loss: 0.0386  bbox_loss: 0.0049  cls_loss: 0.0848  \n",
      "<<<iteration:[60/244] - total_loss: 0.2068  obj_loss: 0.0726  noobj_loss: 0.0388  bbox_loss: 0.0042  cls_loss: 0.0936  \n",
      "<<<iteration:[80/244] - total_loss: 0.2281  obj_loss: 0.0707  noobj_loss: 0.0389  bbox_loss: 0.0053  cls_loss: 0.1115  \n",
      "<<<iteration:[100/244] - total_loss: 0.2286  obj_loss: 0.0636  noobj_loss: 0.0391  bbox_loss: 0.0047  cls_loss: 0.1222  \n",
      "<<<iteration:[120/244] - total_loss: 0.1946  obj_loss: 0.0661  noobj_loss: 0.0363  bbox_loss: 0.0044  cls_loss: 0.0884  \n",
      "<<<iteration:[140/244] - total_loss: 0.2261  obj_loss: 0.0668  noobj_loss: 0.0422  bbox_loss: 0.0055  cls_loss: 0.1106  \n",
      "<<<iteration:[160/244] - total_loss: 0.2079  obj_loss: 0.0669  noobj_loss: 0.0380  bbox_loss: 0.0047  cls_loss: 0.0987  \n",
      "<<<iteration:[180/244] - total_loss: 0.1938  obj_loss: 0.0653  noobj_loss: 0.0383  bbox_loss: 0.0055  cls_loss: 0.0820  \n",
      "<<<iteration:[200/244] - total_loss: 0.2069  obj_loss: 0.0852  noobj_loss: 0.0407  bbox_loss: 0.0044  cls_loss: 0.0793  \n",
      "<<<iteration:[220/244] - total_loss: 0.1735  obj_loss: 0.0691  noobj_loss: 0.0385  bbox_loss: 0.0051  cls_loss: 0.0597  \n",
      "<<<iteration:[240/244] - total_loss: 0.1861  obj_loss: 0.0712  noobj_loss: 0.0396  bbox_loss: 0.0055  cls_loss: 0.0677  \n",
      "\n",
      "epoch:42/100 - Train Loss: 0.2010, Val Loss: 0.2122\n",
      "\n",
      "<<<iteration:[20/244] - total_loss: 0.2209  obj_loss: 0.0776  noobj_loss: 0.0400  bbox_loss: 0.0050  cls_loss: 0.0984  \n",
      "<<<iteration:[40/244] - total_loss: 0.2042  obj_loss: 0.0728  noobj_loss: 0.0425  bbox_loss: 0.0053  cls_loss: 0.0836  \n",
      "<<<iteration:[60/244] - total_loss: 0.1905  obj_loss: 0.0745  noobj_loss: 0.0396  bbox_loss: 0.0050  cls_loss: 0.0710  \n",
      "<<<iteration:[80/244] - total_loss: 0.1787  obj_loss: 0.0599  noobj_loss: 0.0349  bbox_loss: 0.0053  cls_loss: 0.0746  \n",
      "<<<iteration:[100/244] - total_loss: 0.2016  obj_loss: 0.0686  noobj_loss: 0.0389  bbox_loss: 0.0048  cls_loss: 0.0895  \n",
      "<<<iteration:[120/244] - total_loss: 0.2068  obj_loss: 0.0646  noobj_loss: 0.0365  bbox_loss: 0.0051  cls_loss: 0.0983  \n",
      "<<<iteration:[140/244] - total_loss: 0.2193  obj_loss: 0.0671  noobj_loss: 0.0404  bbox_loss: 0.0053  cls_loss: 0.1055  \n",
      "<<<iteration:[160/244] - total_loss: 0.2003  obj_loss: 0.0642  noobj_loss: 0.0360  bbox_loss: 0.0047  cls_loss: 0.0943  \n",
      "<<<iteration:[180/244] - total_loss: 0.1677  obj_loss: 0.0637  noobj_loss: 0.0341  bbox_loss: 0.0044  cls_loss: 0.0651  \n",
      "<<<iteration:[200/244] - total_loss: 0.1906  obj_loss: 0.0734  noobj_loss: 0.0375  bbox_loss: 0.0052  cls_loss: 0.0722  \n",
      "<<<iteration:[220/244] - total_loss: 0.2002  obj_loss: 0.0607  noobj_loss: 0.0372  bbox_loss: 0.0051  cls_loss: 0.0954  \n",
      "<<<iteration:[240/244] - total_loss: 0.1864  obj_loss: 0.0726  noobj_loss: 0.0383  bbox_loss: 0.0056  cls_loss: 0.0665  \n",
      "\n",
      "epoch:43/100 - Train Loss: 0.1967, Val Loss: 0.2059\n",
      "\n",
      "<<<iteration:[20/244] - total_loss: 0.1978  obj_loss: 0.0799  noobj_loss: 0.0399  bbox_loss: 0.0050  cls_loss: 0.0728  \n",
      "<<<iteration:[40/244] - total_loss: 0.2144  obj_loss: 0.0769  noobj_loss: 0.0406  bbox_loss: 0.0051  cls_loss: 0.0917  \n",
      "<<<iteration:[60/244] - total_loss: 0.1933  obj_loss: 0.0699  noobj_loss: 0.0396  bbox_loss: 0.0048  cls_loss: 0.0795  \n",
      "<<<iteration:[80/244] - total_loss: 0.1782  obj_loss: 0.0613  noobj_loss: 0.0373  bbox_loss: 0.0064  cls_loss: 0.0664  \n",
      "<<<iteration:[100/244] - total_loss: 0.2157  obj_loss: 0.0682  noobj_loss: 0.0383  bbox_loss: 0.0051  cls_loss: 0.1030  \n",
      "<<<iteration:[120/244] - total_loss: 0.1923  obj_loss: 0.0675  noobj_loss: 0.0376  bbox_loss: 0.0046  cls_loss: 0.0830  \n",
      "<<<iteration:[140/244] - total_loss: 0.2089  obj_loss: 0.0692  noobj_loss: 0.0382  bbox_loss: 0.0047  cls_loss: 0.0970  \n",
      "<<<iteration:[160/244] - total_loss: 0.1982  obj_loss: 0.0722  noobj_loss: 0.0371  bbox_loss: 0.0039  cls_loss: 0.0881  \n",
      "<<<iteration:[180/244] - total_loss: 0.1836  obj_loss: 0.0746  noobj_loss: 0.0404  bbox_loss: 0.0043  cls_loss: 0.0671  \n",
      "<<<iteration:[200/244] - total_loss: 0.1977  obj_loss: 0.0687  noobj_loss: 0.0358  bbox_loss: 0.0050  cls_loss: 0.0861  \n",
      "<<<iteration:[220/244] - total_loss: 0.1924  obj_loss: 0.0714  noobj_loss: 0.0358  bbox_loss: 0.0041  cls_loss: 0.0828  \n",
      "<<<iteration:[240/244] - total_loss: 0.1842  obj_loss: 0.0735  noobj_loss: 0.0359  bbox_loss: 0.0048  cls_loss: 0.0687  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "epoch:44/100 - Train Loss: 0.1957, Val Loss: 0.2076\n",
      "\n",
      "<<<iteration:[20/244] - total_loss: 0.1832  obj_loss: 0.0672  noobj_loss: 0.0413  bbox_loss: 0.0057  cls_loss: 0.0670  \n",
      "<<<iteration:[40/244] - total_loss: 0.1819  obj_loss: 0.0748  noobj_loss: 0.0375  bbox_loss: 0.0047  cls_loss: 0.0648  \n",
      "<<<iteration:[60/244] - total_loss: 0.1817  obj_loss: 0.0663  noobj_loss: 0.0374  bbox_loss: 0.0051  cls_loss: 0.0712  \n",
      "<<<iteration:[80/244] - total_loss: 0.1880  obj_loss: 0.0734  noobj_loss: 0.0373  bbox_loss: 0.0048  cls_loss: 0.0717  \n",
      "<<<iteration:[100/244] - total_loss: 0.1961  obj_loss: 0.0762  noobj_loss: 0.0413  bbox_loss: 0.0047  cls_loss: 0.0755  \n",
      "<<<iteration:[120/244] - total_loss: 0.2370  obj_loss: 0.0719  noobj_loss: 0.0443  bbox_loss: 0.0048  cls_loss: 0.1189  \n",
      "<<<iteration:[140/244] - total_loss: 0.2187  obj_loss: 0.0725  noobj_loss: 0.0393  bbox_loss: 0.0044  cls_loss: 0.1044  \n",
      "<<<iteration:[160/244] - total_loss: 0.1923  obj_loss: 0.0691  noobj_loss: 0.0395  bbox_loss: 0.0048  cls_loss: 0.0796  \n",
      "<<<iteration:[180/244] - total_loss: 0.2076  obj_loss: 0.0769  noobj_loss: 0.0372  bbox_loss: 0.0044  cls_loss: 0.0901  \n",
      "<<<iteration:[200/244] - total_loss: 0.1596  obj_loss: 0.0646  noobj_loss: 0.0379  bbox_loss: 0.0047  cls_loss: 0.0528  \n",
      "<<<iteration:[220/244] - total_loss: 0.2248  obj_loss: 0.0618  noobj_loss: 0.0393  bbox_loss: 0.0056  cls_loss: 0.1154  \n",
      "<<<iteration:[240/244] - total_loss: 0.1903  obj_loss: 0.0770  noobj_loss: 0.0398  bbox_loss: 0.0043  cls_loss: 0.0718  \n",
      "\n",
      "epoch:45/100 - Train Loss: 0.1958, Val Loss: 0.2111\n",
      "\n",
      "<<<iteration:[20/244] - total_loss: 0.1937  obj_loss: 0.0678  noobj_loss: 0.0406  bbox_loss: 0.0060  cls_loss: 0.0757  \n",
      "<<<iteration:[40/244] - total_loss: 0.1882  obj_loss: 0.0634  noobj_loss: 0.0387  bbox_loss: 0.0065  cls_loss: 0.0731  \n",
      "<<<iteration:[60/244] - total_loss: 0.1747  obj_loss: 0.0622  noobj_loss: 0.0354  bbox_loss: 0.0047  cls_loss: 0.0716  \n",
      "<<<iteration:[80/244] - total_loss: 0.1988  obj_loss: 0.0730  noobj_loss: 0.0374  bbox_loss: 0.0045  cls_loss: 0.0848  \n",
      "<<<iteration:[100/244] - total_loss: 0.1777  obj_loss: 0.0671  noobj_loss: 0.0398  bbox_loss: 0.0042  cls_loss: 0.0696  \n",
      "<<<iteration:[120/244] - total_loss: 0.1754  obj_loss: 0.0649  noobj_loss: 0.0371  bbox_loss: 0.0040  cls_loss: 0.0718  \n",
      "<<<iteration:[140/244] - total_loss: 0.1978  obj_loss: 0.0758  noobj_loss: 0.0367  bbox_loss: 0.0041  cls_loss: 0.0833  \n",
      "<<<iteration:[160/244] - total_loss: 0.2097  obj_loss: 0.0679  noobj_loss: 0.0443  bbox_loss: 0.0047  cls_loss: 0.0964  \n",
      "<<<iteration:[180/244] - total_loss: 0.1814  obj_loss: 0.0647  noobj_loss: 0.0360  bbox_loss: 0.0054  cls_loss: 0.0715  \n",
      "<<<iteration:[200/244] - total_loss: 0.2120  obj_loss: 0.0737  noobj_loss: 0.0396  bbox_loss: 0.0048  cls_loss: 0.0944  \n",
      "<<<iteration:[220/244] - total_loss: 0.2068  obj_loss: 0.0676  noobj_loss: 0.0399  bbox_loss: 0.0045  cls_loss: 0.0968  \n",
      "<<<iteration:[240/244] - total_loss: 0.2120  obj_loss: 0.0669  noobj_loss: 0.0361  bbox_loss: 0.0044  cls_loss: 0.1051  \n",
      "\n",
      "epoch:46/100 - Train Loss: 0.1929, Val Loss: 0.2097\n",
      "\n",
      "<<<iteration:[20/244] - total_loss: 0.1882  obj_loss: 0.0755  noobj_loss: 0.0389  bbox_loss: 0.0053  cls_loss: 0.0669  \n",
      "<<<iteration:[40/244] - total_loss: 0.1982  obj_loss: 0.0738  noobj_loss: 0.0423  bbox_loss: 0.0052  cls_loss: 0.0772  \n",
      "<<<iteration:[60/244] - total_loss: 0.2142  obj_loss: 0.0702  noobj_loss: 0.0393  bbox_loss: 0.0047  cls_loss: 0.1007  \n",
      "<<<iteration:[80/244] - total_loss: 0.1841  obj_loss: 0.0668  noobj_loss: 0.0396  bbox_loss: 0.0048  cls_loss: 0.0736  \n",
      "<<<iteration:[100/244] - total_loss: 0.1932  obj_loss: 0.0745  noobj_loss: 0.0387  bbox_loss: 0.0043  cls_loss: 0.0778  \n",
      "<<<iteration:[120/244] - total_loss: 0.1745  obj_loss: 0.0687  noobj_loss: 0.0367  bbox_loss: 0.0042  cls_loss: 0.0664  \n",
      "<<<iteration:[140/244] - total_loss: 0.1887  obj_loss: 0.0661  noobj_loss: 0.0374  bbox_loss: 0.0052  cls_loss: 0.0781  \n",
      "<<<iteration:[160/244] - total_loss: 0.1981  obj_loss: 0.0641  noobj_loss: 0.0374  bbox_loss: 0.0045  cls_loss: 0.0930  \n",
      "<<<iteration:[180/244] - total_loss: 0.2398  obj_loss: 0.0646  noobj_loss: 0.0376  bbox_loss: 0.0129  cls_loss: 0.0919  \n",
      "<<<iteration:[200/244] - total_loss: 0.1977  obj_loss: 0.0671  noobj_loss: 0.0403  bbox_loss: 0.0075  cls_loss: 0.0730  \n",
      "<<<iteration:[220/244] - total_loss: 0.2099  obj_loss: 0.0668  noobj_loss: 0.0400  bbox_loss: 0.0056  cls_loss: 0.0950  \n",
      "<<<iteration:[240/244] - total_loss: 0.1730  obj_loss: 0.0616  noobj_loss: 0.0371  bbox_loss: 0.0059  cls_loss: 0.0634  \n",
      "\n",
      "epoch:47/100 - Train Loss: 0.1958, Val Loss: 0.2110\n",
      "\n",
      "<<<iteration:[20/244] - total_loss: 0.2041  obj_loss: 0.0697  noobj_loss: 0.0416  bbox_loss: 0.0057  cls_loss: 0.0853  \n",
      "<<<iteration:[40/244] - total_loss: 0.1736  obj_loss: 0.0634  noobj_loss: 0.0403  bbox_loss: 0.0056  cls_loss: 0.0623  \n",
      "<<<iteration:[60/244] - total_loss: 0.2246  obj_loss: 0.0702  noobj_loss: 0.0408  bbox_loss: 0.0075  cls_loss: 0.0964  \n",
      "<<<iteration:[80/244] - total_loss: 0.1738  obj_loss: 0.0641  noobj_loss: 0.0356  bbox_loss: 0.0050  cls_loss: 0.0670  \n",
      "<<<iteration:[100/244] - total_loss: 0.1944  obj_loss: 0.0711  noobj_loss: 0.0379  bbox_loss: 0.0050  cls_loss: 0.0793  \n",
      "<<<iteration:[120/244] - total_loss: 0.1890  obj_loss: 0.0718  noobj_loss: 0.0384  bbox_loss: 0.0051  cls_loss: 0.0725  \n",
      "<<<iteration:[140/244] - total_loss: 0.1921  obj_loss: 0.0774  noobj_loss: 0.0385  bbox_loss: 0.0055  cls_loss: 0.0683  \n",
      "<<<iteration:[160/244] - total_loss: 0.3640  obj_loss: 0.0654  noobj_loss: 0.0390  bbox_loss: 0.0394  cls_loss: 0.0822  \n",
      "<<<iteration:[180/244] - total_loss: 0.3918  obj_loss: 0.0520  noobj_loss: 0.0379  bbox_loss: 0.0407  cls_loss: 0.1174  \n",
      "<<<iteration:[200/244] - total_loss: 0.2885  obj_loss: 0.0619  noobj_loss: 0.0376  bbox_loss: 0.0194  cls_loss: 0.1109  \n",
      "<<<iteration:[220/244] - total_loss: 0.2406  obj_loss: 0.0571  noobj_loss: 0.0362  bbox_loss: 0.0128  cls_loss: 0.1016  \n",
      "<<<iteration:[240/244] - total_loss: 0.2385  obj_loss: 0.0630  noobj_loss: 0.0386  bbox_loss: 0.0124  cls_loss: 0.0939  \n",
      "\n",
      "epoch:48/100 - Train Loss: 0.2384, Val Loss: 0.2244\n",
      "\n",
      "<<<iteration:[20/244] - total_loss: 0.2453  obj_loss: 0.0709  noobj_loss: 0.0357  bbox_loss: 0.0081  cls_loss: 0.1157  \n",
      "<<<iteration:[40/244] - total_loss: 0.2145  obj_loss: 0.0657  noobj_loss: 0.0376  bbox_loss: 0.0084  cls_loss: 0.0879  \n",
      "<<<iteration:[60/244] - total_loss: 0.2057  obj_loss: 0.0651  noobj_loss: 0.0377  bbox_loss: 0.0069  cls_loss: 0.0875  \n",
      "<<<iteration:[80/244] - total_loss: 0.1933  obj_loss: 0.0660  noobj_loss: 0.0395  bbox_loss: 0.0066  cls_loss: 0.0745  \n",
      "<<<iteration:[100/244] - total_loss: 0.2217  obj_loss: 0.0650  noobj_loss: 0.0385  bbox_loss: 0.0079  cls_loss: 0.0980  \n",
      "<<<iteration:[120/244] - total_loss: 0.2322  obj_loss: 0.0743  noobj_loss: 0.0402  bbox_loss: 0.0059  cls_loss: 0.1082  \n",
      "<<<iteration:[140/244] - total_loss: 0.1846  obj_loss: 0.0693  noobj_loss: 0.0378  bbox_loss: 0.0054  cls_loss: 0.0693  \n",
      "<<<iteration:[160/244] - total_loss: 0.2032  obj_loss: 0.0650  noobj_loss: 0.0364  bbox_loss: 0.0065  cls_loss: 0.0874  \n",
      "<<<iteration:[180/244] - total_loss: 0.1866  obj_loss: 0.0676  noobj_loss: 0.0370  bbox_loss: 0.0050  cls_loss: 0.0757  \n",
      "<<<iteration:[200/244] - total_loss: 0.1905  obj_loss: 0.0669  noobj_loss: 0.0378  bbox_loss: 0.0064  cls_loss: 0.0727  \n",
      "<<<iteration:[220/244] - total_loss: 0.1988  obj_loss: 0.0677  noobj_loss: 0.0343  bbox_loss: 0.0055  cls_loss: 0.0863  \n",
      "<<<iteration:[240/244] - total_loss: 0.1886  obj_loss: 0.0694  noobj_loss: 0.0389  bbox_loss: 0.0057  cls_loss: 0.0709  \n",
      "\n",
      "epoch:49/100 - Train Loss: 0.2046, Val Loss: 0.2091\n",
      "\n",
      "<<<iteration:[20/244] - total_loss: 0.2005  obj_loss: 0.0714  noobj_loss: 0.0400  bbox_loss: 0.0053  cls_loss: 0.0824  \n",
      "<<<iteration:[40/244] - total_loss: 0.2219  obj_loss: 0.0718  noobj_loss: 0.0397  bbox_loss: 0.0056  cls_loss: 0.1022  \n",
      "<<<iteration:[60/244] - total_loss: 0.1858  obj_loss: 0.0713  noobj_loss: 0.0427  bbox_loss: 0.0053  cls_loss: 0.0669  \n",
      "<<<iteration:[80/244] - total_loss: 0.2043  obj_loss: 0.0725  noobj_loss: 0.0377  bbox_loss: 0.0059  cls_loss: 0.0835  \n",
      "<<<iteration:[100/244] - total_loss: 0.2157  obj_loss: 0.0735  noobj_loss: 0.0398  bbox_loss: 0.0065  cls_loss: 0.0898  \n",
      "<<<iteration:[120/244] - total_loss: 0.2037  obj_loss: 0.0673  noobj_loss: 0.0399  bbox_loss: 0.0054  cls_loss: 0.0896  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<<<iteration:[140/244] - total_loss: 0.2005  obj_loss: 0.0693  noobj_loss: 0.0410  bbox_loss: 0.0050  cls_loss: 0.0859  \n",
      "<<<iteration:[160/244] - total_loss: 0.2111  obj_loss: 0.0687  noobj_loss: 0.0378  bbox_loss: 0.0046  cls_loss: 0.1006  \n",
      "<<<iteration:[180/244] - total_loss: 0.2059  obj_loss: 0.0635  noobj_loss: 0.0425  bbox_loss: 0.0057  cls_loss: 0.0925  \n",
      "<<<iteration:[200/244] - total_loss: 0.1572  obj_loss: 0.0615  noobj_loss: 0.0399  bbox_loss: 0.0054  cls_loss: 0.0489  \n",
      "<<<iteration:[220/244] - total_loss: 0.1907  obj_loss: 0.0848  noobj_loss: 0.0357  bbox_loss: 0.0044  cls_loss: 0.0660  \n",
      "<<<iteration:[240/244] - total_loss: 0.2111  obj_loss: 0.0756  noobj_loss: 0.0383  bbox_loss: 0.0055  cls_loss: 0.0890  \n",
      "\n",
      "epoch:50/100 - Train Loss: 0.1997, Val Loss: 0.2152\n",
      "\n",
      "<<<iteration:[20/244] - total_loss: 0.2009  obj_loss: 0.0699  noobj_loss: 0.0395  bbox_loss: 0.0060  cls_loss: 0.0810  \n",
      "<<<iteration:[40/244] - total_loss: 0.1978  obj_loss: 0.0715  noobj_loss: 0.0361  bbox_loss: 0.0055  cls_loss: 0.0808  \n",
      "<<<iteration:[60/244] - total_loss: 0.2204  obj_loss: 0.0683  noobj_loss: 0.0419  bbox_loss: 0.0047  cls_loss: 0.1076  \n",
      "<<<iteration:[80/244] - total_loss: 0.2046  obj_loss: 0.0730  noobj_loss: 0.0378  bbox_loss: 0.0046  cls_loss: 0.0897  \n",
      "<<<iteration:[100/244] - total_loss: 0.1747  obj_loss: 0.0690  noobj_loss: 0.0400  bbox_loss: 0.0048  cls_loss: 0.0617  \n",
      "<<<iteration:[120/244] - total_loss: 0.2032  obj_loss: 0.0746  noobj_loss: 0.0383  bbox_loss: 0.0049  cls_loss: 0.0851  \n",
      "<<<iteration:[140/244] - total_loss: 0.2142  obj_loss: 0.0729  noobj_loss: 0.0389  bbox_loss: 0.0043  cls_loss: 0.1004  \n",
      "<<<iteration:[160/244] - total_loss: 0.1765  obj_loss: 0.0589  noobj_loss: 0.0367  bbox_loss: 0.0049  cls_loss: 0.0747  \n",
      "<<<iteration:[180/244] - total_loss: 0.1908  obj_loss: 0.0771  noobj_loss: 0.0387  bbox_loss: 0.0052  cls_loss: 0.0684  \n",
      "<<<iteration:[200/244] - total_loss: 0.1902  obj_loss: 0.0741  noobj_loss: 0.0368  bbox_loss: 0.0048  cls_loss: 0.0738  \n",
      "<<<iteration:[220/244] - total_loss: 0.2006  obj_loss: 0.0737  noobj_loss: 0.0389  bbox_loss: 0.0046  cls_loss: 0.0842  \n",
      "<<<iteration:[240/244] - total_loss: 0.2029  obj_loss: 0.0731  noobj_loss: 0.0397  bbox_loss: 0.0050  cls_loss: 0.0850  \n",
      "\n",
      "epoch:51/100 - Train Loss: 0.1967, Val Loss: 0.2082\n",
      "\n",
      "<<<iteration:[20/244] - total_loss: 0.2299  obj_loss: 0.0812  noobj_loss: 0.0400  bbox_loss: 0.0051  cls_loss: 0.1034  \n",
      "<<<iteration:[40/244] - total_loss: 0.1840  obj_loss: 0.0608  noobj_loss: 0.0365  bbox_loss: 0.0051  cls_loss: 0.0795  \n",
      "<<<iteration:[60/244] - total_loss: 0.1902  obj_loss: 0.0794  noobj_loss: 0.0387  bbox_loss: 0.0053  cls_loss: 0.0649  \n",
      "<<<iteration:[80/244] - total_loss: 0.1977  obj_loss: 0.0686  noobj_loss: 0.0391  bbox_loss: 0.0050  cls_loss: 0.0843  \n",
      "<<<iteration:[100/244] - total_loss: 0.1585  obj_loss: 0.0664  noobj_loss: 0.0373  bbox_loss: 0.0044  cls_loss: 0.0513  \n",
      "<<<iteration:[120/244] - total_loss: 0.2044  obj_loss: 0.0683  noobj_loss: 0.0424  bbox_loss: 0.0051  cls_loss: 0.0896  \n",
      "<<<iteration:[140/244] - total_loss: 0.2032  obj_loss: 0.0708  noobj_loss: 0.0382  bbox_loss: 0.0045  cls_loss: 0.0910  \n",
      "<<<iteration:[160/244] - total_loss: 0.1776  obj_loss: 0.0694  noobj_loss: 0.0398  bbox_loss: 0.0056  cls_loss: 0.0603  \n",
      "<<<iteration:[180/244] - total_loss: 0.2017  obj_loss: 0.0706  noobj_loss: 0.0370  bbox_loss: 0.0048  cls_loss: 0.0886  \n",
      "<<<iteration:[200/244] - total_loss: 0.2031  obj_loss: 0.0758  noobj_loss: 0.0394  bbox_loss: 0.0059  cls_loss: 0.0781  \n",
      "<<<iteration:[220/244] - total_loss: 0.2017  obj_loss: 0.0730  noobj_loss: 0.0370  bbox_loss: 0.0046  cls_loss: 0.0874  \n",
      "<<<iteration:[240/244] - total_loss: 0.1811  obj_loss: 0.0660  noobj_loss: 0.0455  bbox_loss: 0.0058  cls_loss: 0.0634  \n",
      "\n",
      "epoch:52/100 - Train Loss: 0.1953, Val Loss: 0.2076\n",
      "\n",
      "<<<iteration:[20/244] - total_loss: 0.1963  obj_loss: 0.0830  noobj_loss: 0.0402  bbox_loss: 0.0059  cls_loss: 0.0639  \n",
      "<<<iteration:[40/244] - total_loss: 0.2148  obj_loss: 0.0686  noobj_loss: 0.0365  bbox_loss: 0.0052  cls_loss: 0.1020  \n",
      "<<<iteration:[60/244] - total_loss: 0.1848  obj_loss: 0.0666  noobj_loss: 0.0399  bbox_loss: 0.0047  cls_loss: 0.0749  \n",
      "<<<iteration:[80/244] - total_loss: 0.1808  obj_loss: 0.0630  noobj_loss: 0.0381  bbox_loss: 0.0045  cls_loss: 0.0762  \n",
      "<<<iteration:[100/244] - total_loss: 0.1798  obj_loss: 0.0690  noobj_loss: 0.0372  bbox_loss: 0.0053  cls_loss: 0.0659  \n",
      "<<<iteration:[120/244] - total_loss: 0.2040  obj_loss: 0.0846  noobj_loss: 0.0383  bbox_loss: 0.0063  cls_loss: 0.0685  \n",
      "<<<iteration:[140/244] - total_loss: 0.2111  obj_loss: 0.0761  noobj_loss: 0.0388  bbox_loss: 0.0048  cls_loss: 0.0917  \n",
      "<<<iteration:[160/244] - total_loss: 0.1897  obj_loss: 0.0626  noobj_loss: 0.0367  bbox_loss: 0.0060  cls_loss: 0.0786  \n",
      "<<<iteration:[180/244] - total_loss: 0.1949  obj_loss: 0.0697  noobj_loss: 0.0393  bbox_loss: 0.0050  cls_loss: 0.0805  \n",
      "<<<iteration:[200/244] - total_loss: 0.1959  obj_loss: 0.0682  noobj_loss: 0.0349  bbox_loss: 0.0043  cls_loss: 0.0886  \n",
      "<<<iteration:[220/244] - total_loss: 0.1940  obj_loss: 0.0634  noobj_loss: 0.0406  bbox_loss: 0.0054  cls_loss: 0.0831  \n",
      "<<<iteration:[240/244] - total_loss: 0.2023  obj_loss: 0.0681  noobj_loss: 0.0369  bbox_loss: 0.0048  cls_loss: 0.0917  \n",
      "\n",
      "epoch:53/100 - Train Loss: 0.1945, Val Loss: 0.2102\n",
      "\n",
      "<<<iteration:[20/244] - total_loss: 0.2162  obj_loss: 0.0757  noobj_loss: 0.0400  bbox_loss: 0.0049  cls_loss: 0.0961  \n",
      "<<<iteration:[40/244] - total_loss: 0.1974  obj_loss: 0.0735  noobj_loss: 0.0392  bbox_loss: 0.0054  cls_loss: 0.0774  \n",
      "<<<iteration:[60/244] - total_loss: 0.1844  obj_loss: 0.0590  noobj_loss: 0.0360  bbox_loss: 0.0055  cls_loss: 0.0801  \n",
      "<<<iteration:[80/244] - total_loss: 0.1896  obj_loss: 0.0662  noobj_loss: 0.0374  bbox_loss: 0.0048  cls_loss: 0.0805  \n",
      "<<<iteration:[100/244] - total_loss: 0.1948  obj_loss: 0.0645  noobj_loss: 0.0388  bbox_loss: 0.0042  cls_loss: 0.0901  \n",
      "<<<iteration:[120/244] - total_loss: 0.1910  obj_loss: 0.0816  noobj_loss: 0.0382  bbox_loss: 0.0045  cls_loss: 0.0676  \n",
      "<<<iteration:[140/244] - total_loss: 0.2029  obj_loss: 0.0724  noobj_loss: 0.0368  bbox_loss: 0.0050  cls_loss: 0.0870  \n",
      "<<<iteration:[160/244] - total_loss: 0.1592  obj_loss: 0.0698  noobj_loss: 0.0348  bbox_loss: 0.0041  cls_loss: 0.0515  \n",
      "<<<iteration:[180/244] - total_loss: 0.1821  obj_loss: 0.0672  noobj_loss: 0.0372  bbox_loss: 0.0047  cls_loss: 0.0730  \n",
      "<<<iteration:[200/244] - total_loss: 0.1776  obj_loss: 0.0782  noobj_loss: 0.0349  bbox_loss: 0.0044  cls_loss: 0.0598  \n",
      "<<<iteration:[220/244] - total_loss: 0.2162  obj_loss: 0.0781  noobj_loss: 0.0380  bbox_loss: 0.0046  cls_loss: 0.0960  \n",
      "<<<iteration:[240/244] - total_loss: 0.1526  obj_loss: 0.0621  noobj_loss: 0.0378  bbox_loss: 0.0047  cls_loss: 0.0479  \n",
      "\n",
      "epoch:54/100 - Train Loss: 0.1874, Val Loss: 0.2046\n",
      "\n",
      "<<<iteration:[20/244] - total_loss: 0.2113  obj_loss: 0.0615  noobj_loss: 0.0399  bbox_loss: 0.0051  cls_loss: 0.1045  \n",
      "<<<iteration:[40/244] - total_loss: 0.2070  obj_loss: 0.0651  noobj_loss: 0.0406  bbox_loss: 0.0046  cls_loss: 0.0984  \n",
      "<<<iteration:[60/244] - total_loss: 0.1956  obj_loss: 0.0719  noobj_loss: 0.0404  bbox_loss: 0.0048  cls_loss: 0.0795  \n",
      "<<<iteration:[80/244] - total_loss: 0.1755  obj_loss: 0.0705  noobj_loss: 0.0365  bbox_loss: 0.0042  cls_loss: 0.0655  \n",
      "<<<iteration:[100/244] - total_loss: 0.2067  obj_loss: 0.0708  noobj_loss: 0.0399  bbox_loss: 0.0053  cls_loss: 0.0892  \n",
      "<<<iteration:[120/244] - total_loss: 0.1749  obj_loss: 0.0678  noobj_loss: 0.0393  bbox_loss: 0.0046  cls_loss: 0.0647  \n",
      "<<<iteration:[140/244] - total_loss: 0.1607  obj_loss: 0.0694  noobj_loss: 0.0373  bbox_loss: 0.0043  cls_loss: 0.0511  \n",
      "<<<iteration:[160/244] - total_loss: 0.1832  obj_loss: 0.0707  noobj_loss: 0.0352  bbox_loss: 0.0041  cls_loss: 0.0743  \n",
      "<<<iteration:[180/244] - total_loss: 0.1900  obj_loss: 0.0698  noobj_loss: 0.0414  bbox_loss: 0.0050  cls_loss: 0.0747  \n",
      "<<<iteration:[200/244] - total_loss: 0.2054  obj_loss: 0.0739  noobj_loss: 0.0396  bbox_loss: 0.0045  cls_loss: 0.0891  \n",
      "<<<iteration:[220/244] - total_loss: 0.1799  obj_loss: 0.0681  noobj_loss: 0.0377  bbox_loss: 0.0043  cls_loss: 0.0716  \n",
      "<<<iteration:[240/244] - total_loss: 0.1798  obj_loss: 0.0728  noobj_loss: 0.0365  bbox_loss: 0.0043  cls_loss: 0.0670  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "epoch:55/100 - Train Loss: 0.1880, Val Loss: 0.2093\n",
      "\n",
      "<<<iteration:[20/244] - total_loss: 0.1959  obj_loss: 0.0689  noobj_loss: 0.0397  bbox_loss: 0.0045  cls_loss: 0.0848  \n",
      "<<<iteration:[40/244] - total_loss: 0.1975  obj_loss: 0.0786  noobj_loss: 0.0392  bbox_loss: 0.0047  cls_loss: 0.0757  \n",
      "<<<iteration:[60/244] - total_loss: 0.2087  obj_loss: 0.0776  noobj_loss: 0.0431  bbox_loss: 0.0052  cls_loss: 0.0836  \n",
      "<<<iteration:[80/244] - total_loss: 0.1690  obj_loss: 0.0646  noobj_loss: 0.0398  bbox_loss: 0.0048  cls_loss: 0.0607  \n",
      "<<<iteration:[100/244] - total_loss: 0.2057  obj_loss: 0.0589  noobj_loss: 0.0378  bbox_loss: 0.0044  cls_loss: 0.1061  \n",
      "<<<iteration:[120/244] - total_loss: 0.1800  obj_loss: 0.0600  noobj_loss: 0.0384  bbox_loss: 0.0044  cls_loss: 0.0790  \n",
      "<<<iteration:[140/244] - total_loss: 0.1692  obj_loss: 0.0778  noobj_loss: 0.0368  bbox_loss: 0.0047  cls_loss: 0.0493  \n",
      "<<<iteration:[160/244] - total_loss: 0.1762  obj_loss: 0.0696  noobj_loss: 0.0389  bbox_loss: 0.0051  cls_loss: 0.0619  \n",
      "<<<iteration:[180/244] - total_loss: 0.2080  obj_loss: 0.0682  noobj_loss: 0.0380  bbox_loss: 0.0043  cls_loss: 0.0993  \n",
      "<<<iteration:[200/244] - total_loss: 0.1866  obj_loss: 0.0762  noobj_loss: 0.0387  bbox_loss: 0.0042  cls_loss: 0.0701  \n",
      "<<<iteration:[220/244] - total_loss: 0.1859  obj_loss: 0.0723  noobj_loss: 0.0412  bbox_loss: 0.0048  cls_loss: 0.0692  \n",
      "<<<iteration:[240/244] - total_loss: 0.1878  obj_loss: 0.0742  noobj_loss: 0.0379  bbox_loss: 0.0046  cls_loss: 0.0714  \n",
      "\n",
      "epoch:56/100 - Train Loss: 0.1887, Val Loss: 0.2080\n",
      "\n",
      "<<<iteration:[20/244] - total_loss: 0.1951  obj_loss: 0.0739  noobj_loss: 0.0421  bbox_loss: 0.0048  cls_loss: 0.0764  \n",
      "<<<iteration:[40/244] - total_loss: 0.1738  obj_loss: 0.0748  noobj_loss: 0.0391  bbox_loss: 0.0044  cls_loss: 0.0576  \n",
      "<<<iteration:[60/244] - total_loss: 0.2138  obj_loss: 0.0711  noobj_loss: 0.0380  bbox_loss: 0.0038  cls_loss: 0.1044  \n",
      "<<<iteration:[80/244] - total_loss: 0.1792  obj_loss: 0.0642  noobj_loss: 0.0383  bbox_loss: 0.0039  cls_loss: 0.0762  \n",
      "<<<iteration:[100/244] - total_loss: 0.1818  obj_loss: 0.0837  noobj_loss: 0.0390  bbox_loss: 0.0040  cls_loss: 0.0584  \n",
      "<<<iteration:[120/244] - total_loss: 0.1860  obj_loss: 0.0644  noobj_loss: 0.0419  bbox_loss: 0.0047  cls_loss: 0.0769  \n",
      "<<<iteration:[140/244] - total_loss: 0.2202  obj_loss: 0.0819  noobj_loss: 0.0385  bbox_loss: 0.0045  cls_loss: 0.0965  \n",
      "<<<iteration:[160/244] - total_loss: 0.1818  obj_loss: 0.0624  noobj_loss: 0.0392  bbox_loss: 0.0047  cls_loss: 0.0763  \n",
      "<<<iteration:[180/244] - total_loss: 0.2078  obj_loss: 0.0741  noobj_loss: 0.0386  bbox_loss: 0.0039  cls_loss: 0.0952  \n",
      "<<<iteration:[200/244] - total_loss: 0.1651  obj_loss: 0.0603  noobj_loss: 0.0386  bbox_loss: 0.0045  cls_loss: 0.0631  \n",
      "<<<iteration:[220/244] - total_loss: 0.1785  obj_loss: 0.0689  noobj_loss: 0.0395  bbox_loss: 0.0044  cls_loss: 0.0676  \n",
      "<<<iteration:[240/244] - total_loss: 0.1848  obj_loss: 0.0716  noobj_loss: 0.0405  bbox_loss: 0.0047  cls_loss: 0.0696  \n",
      "\n",
      "epoch:57/100 - Train Loss: 0.1875, Val Loss: 0.2095\n",
      "\n",
      "<<<iteration:[20/244] - total_loss: 0.1640  obj_loss: 0.0680  noobj_loss: 0.0369  bbox_loss: 0.0041  cls_loss: 0.0571  \n",
      "<<<iteration:[40/244] - total_loss: 0.1793  obj_loss: 0.0740  noobj_loss: 0.0388  bbox_loss: 0.0042  cls_loss: 0.0650  \n",
      "<<<iteration:[60/244] - total_loss: 0.1819  obj_loss: 0.0652  noobj_loss: 0.0387  bbox_loss: 0.0043  cls_loss: 0.0755  \n",
      "<<<iteration:[80/244] - total_loss: 0.2132  obj_loss: 0.0756  noobj_loss: 0.0397  bbox_loss: 0.0042  cls_loss: 0.0967  \n",
      "<<<iteration:[100/244] - total_loss: 0.1920  obj_loss: 0.0718  noobj_loss: 0.0367  bbox_loss: 0.0042  cls_loss: 0.0808  \n",
      "<<<iteration:[120/244] - total_loss: 0.1963  obj_loss: 0.0769  noobj_loss: 0.0406  bbox_loss: 0.0051  cls_loss: 0.0734  \n",
      "<<<iteration:[140/244] - total_loss: 0.1533  obj_loss: 0.0579  noobj_loss: 0.0394  bbox_loss: 0.0043  cls_loss: 0.0539  \n",
      "<<<iteration:[160/244] - total_loss: 0.2072  obj_loss: 0.0685  noobj_loss: 0.0369  bbox_loss: 0.0042  cls_loss: 0.0992  \n",
      "<<<iteration:[180/244] - total_loss: 0.2119  obj_loss: 0.0710  noobj_loss: 0.0380  bbox_loss: 0.0046  cls_loss: 0.0988  \n",
      "<<<iteration:[200/244] - total_loss: 0.1902  obj_loss: 0.0636  noobj_loss: 0.0392  bbox_loss: 0.0053  cls_loss: 0.0806  \n",
      "<<<iteration:[220/244] - total_loss: 0.1767  obj_loss: 0.0746  noobj_loss: 0.0354  bbox_loss: 0.0047  cls_loss: 0.0608  \n",
      "<<<iteration:[240/244] - total_loss: 0.1818  obj_loss: 0.0713  noobj_loss: 0.0396  bbox_loss: 0.0044  cls_loss: 0.0687  \n",
      "\n",
      "epoch:58/100 - Train Loss: 0.1870, Val Loss: 0.2042\n",
      "\n",
      "<<<iteration:[20/244] - total_loss: 0.1880  obj_loss: 0.0744  noobj_loss: 0.0368  bbox_loss: 0.0045  cls_loss: 0.0725  \n",
      "<<<iteration:[40/244] - total_loss: 0.1587  obj_loss: 0.0703  noobj_loss: 0.0371  bbox_loss: 0.0039  cls_loss: 0.0501  \n",
      "<<<iteration:[60/244] - total_loss: 0.1806  obj_loss: 0.0591  noobj_loss: 0.0357  bbox_loss: 0.0043  cls_loss: 0.0822  \n",
      "<<<iteration:[80/244] - total_loss: 0.1901  obj_loss: 0.0728  noobj_loss: 0.0393  bbox_loss: 0.0037  cls_loss: 0.0789  \n",
      "<<<iteration:[100/244] - total_loss: 0.1992  obj_loss: 0.0674  noobj_loss: 0.0399  bbox_loss: 0.0053  cls_loss: 0.0855  \n",
      "<<<iteration:[120/244] - total_loss: 0.1931  obj_loss: 0.0701  noobj_loss: 0.0374  bbox_loss: 0.0044  cls_loss: 0.0821  \n",
      "<<<iteration:[140/244] - total_loss: 0.2055  obj_loss: 0.0784  noobj_loss: 0.0388  bbox_loss: 0.0045  cls_loss: 0.0853  \n",
      "<<<iteration:[160/244] - total_loss: 0.1674  obj_loss: 0.0639  noobj_loss: 0.0371  bbox_loss: 0.0045  cls_loss: 0.0625  \n",
      "<<<iteration:[180/244] - total_loss: 0.2008  obj_loss: 0.0666  noobj_loss: 0.0414  bbox_loss: 0.0049  cls_loss: 0.0892  \n",
      "<<<iteration:[200/244] - total_loss: 0.1797  obj_loss: 0.0683  noobj_loss: 0.0356  bbox_loss: 0.0043  cls_loss: 0.0718  \n",
      "<<<iteration:[220/244] - total_loss: 0.1736  obj_loss: 0.0652  noobj_loss: 0.0370  bbox_loss: 0.0039  cls_loss: 0.0705  \n",
      "<<<iteration:[240/244] - total_loss: 0.1987  obj_loss: 0.0799  noobj_loss: 0.0401  bbox_loss: 0.0039  cls_loss: 0.0792  \n",
      "\n",
      "epoch:59/100 - Train Loss: 0.1852, Val Loss: 0.2070\n",
      "\n",
      "<<<iteration:[20/244] - total_loss: 0.1987  obj_loss: 0.0766  noobj_loss: 0.0407  bbox_loss: 0.0042  cls_loss: 0.0810  \n",
      "<<<iteration:[40/244] - total_loss: 0.1790  obj_loss: 0.0765  noobj_loss: 0.0375  bbox_loss: 0.0041  cls_loss: 0.0635  \n",
      "<<<iteration:[60/244] - total_loss: 0.1971  obj_loss: 0.0751  noobj_loss: 0.0395  bbox_loss: 0.0045  cls_loss: 0.0798  \n",
      "<<<iteration:[80/244] - total_loss: 0.1671  obj_loss: 0.0623  noobj_loss: 0.0360  bbox_loss: 0.0041  cls_loss: 0.0663  \n",
      "<<<iteration:[100/244] - total_loss: 0.1875  obj_loss: 0.0674  noobj_loss: 0.0399  bbox_loss: 0.0053  cls_loss: 0.0737  \n",
      "<<<iteration:[120/244] - total_loss: 0.1989  obj_loss: 0.0724  noobj_loss: 0.0376  bbox_loss: 0.0040  cls_loss: 0.0877  \n",
      "<<<iteration:[140/244] - total_loss: 0.2049  obj_loss: 0.0756  noobj_loss: 0.0382  bbox_loss: 0.0040  cls_loss: 0.0901  \n",
      "<<<iteration:[160/244] - total_loss: 0.1966  obj_loss: 0.0709  noobj_loss: 0.0376  bbox_loss: 0.0039  cls_loss: 0.0875  \n",
      "<<<iteration:[180/244] - total_loss: 0.1650  obj_loss: 0.0676  noobj_loss: 0.0392  bbox_loss: 0.0044  cls_loss: 0.0558  \n",
      "<<<iteration:[200/244] - total_loss: 0.1671  obj_loss: 0.0751  noobj_loss: 0.0389  bbox_loss: 0.0043  cls_loss: 0.0509  \n",
      "<<<iteration:[220/244] - total_loss: 0.2193  obj_loss: 0.0759  noobj_loss: 0.0399  bbox_loss: 0.0048  cls_loss: 0.0995  \n",
      "<<<iteration:[240/244] - total_loss: 0.1683  obj_loss: 0.0662  noobj_loss: 0.0365  bbox_loss: 0.0039  cls_loss: 0.0643  \n",
      "\n",
      "epoch:60/100 - Train Loss: 0.1868, Val Loss: 0.2076\n",
      "\n",
      "<<<iteration:[20/244] - total_loss: 0.2074  obj_loss: 0.0719  noobj_loss: 0.0424  bbox_loss: 0.0041  cls_loss: 0.0940  \n",
      "<<<iteration:[40/244] - total_loss: 0.1617  obj_loss: 0.0697  noobj_loss: 0.0391  bbox_loss: 0.0044  cls_loss: 0.0504  \n",
      "<<<iteration:[60/244] - total_loss: 0.1846  obj_loss: 0.0690  noobj_loss: 0.0400  bbox_loss: 0.0050  cls_loss: 0.0706  \n",
      "<<<iteration:[80/244] - total_loss: 0.1741  obj_loss: 0.0712  noobj_loss: 0.0369  bbox_loss: 0.0042  cls_loss: 0.0633  \n",
      "<<<iteration:[100/244] - total_loss: 0.1790  obj_loss: 0.0753  noobj_loss: 0.0388  bbox_loss: 0.0040  cls_loss: 0.0641  \n",
      "<<<iteration:[120/244] - total_loss: 0.2057  obj_loss: 0.0701  noobj_loss: 0.0408  bbox_loss: 0.0053  cls_loss: 0.0888  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<<<iteration:[140/244] - total_loss: 0.2046  obj_loss: 0.0788  noobj_loss: 0.0387  bbox_loss: 0.0047  cls_loss: 0.0829  \n",
      "<<<iteration:[160/244] - total_loss: 0.2040  obj_loss: 0.0712  noobj_loss: 0.0385  bbox_loss: 0.0045  cls_loss: 0.0910  \n",
      "<<<iteration:[180/244] - total_loss: 0.1958  obj_loss: 0.0746  noobj_loss: 0.0376  bbox_loss: 0.0042  cls_loss: 0.0813  \n",
      "<<<iteration:[200/244] - total_loss: 0.1592  obj_loss: 0.0632  noobj_loss: 0.0356  bbox_loss: 0.0039  cls_loss: 0.0589  \n",
      "<<<iteration:[220/244] - total_loss: 0.1866  obj_loss: 0.0698  noobj_loss: 0.0380  bbox_loss: 0.0043  cls_loss: 0.0765  \n",
      "<<<iteration:[240/244] - total_loss: 0.1900  obj_loss: 0.0710  noobj_loss: 0.0416  bbox_loss: 0.0043  cls_loss: 0.0767  \n",
      "\n",
      "epoch:61/100 - Train Loss: 0.1885, Val Loss: 0.2068\n",
      "\n",
      "<<<iteration:[20/244] - total_loss: 0.1813  obj_loss: 0.0748  noobj_loss: 0.0397  bbox_loss: 0.0044  cls_loss: 0.0645  \n",
      "<<<iteration:[40/244] - total_loss: 0.1743  obj_loss: 0.0617  noobj_loss: 0.0387  bbox_loss: 0.0046  cls_loss: 0.0702  \n",
      "<<<iteration:[60/244] - total_loss: 0.1941  obj_loss: 0.0715  noobj_loss: 0.0403  bbox_loss: 0.0055  cls_loss: 0.0749  \n",
      "<<<iteration:[80/244] - total_loss: 0.1966  obj_loss: 0.0722  noobj_loss: 0.0397  bbox_loss: 0.0051  cls_loss: 0.0792  \n",
      "<<<iteration:[100/244] - total_loss: 0.1803  obj_loss: 0.0737  noobj_loss: 0.0398  bbox_loss: 0.0043  cls_loss: 0.0655  \n",
      "<<<iteration:[120/244] - total_loss: 0.1765  obj_loss: 0.0660  noobj_loss: 0.0402  bbox_loss: 0.0042  cls_loss: 0.0695  \n",
      "<<<iteration:[140/244] - total_loss: 0.2047  obj_loss: 0.0631  noobj_loss: 0.0394  bbox_loss: 0.0046  cls_loss: 0.0990  \n",
      "<<<iteration:[160/244] - total_loss: 0.1921  obj_loss: 0.0647  noobj_loss: 0.0393  bbox_loss: 0.0048  cls_loss: 0.0839  \n",
      "<<<iteration:[180/244] - total_loss: 0.2112  obj_loss: 0.0791  noobj_loss: 0.0403  bbox_loss: 0.0040  cls_loss: 0.0917  \n",
      "<<<iteration:[200/244] - total_loss: 0.2036  obj_loss: 0.0732  noobj_loss: 0.0405  bbox_loss: 0.0039  cls_loss: 0.0907  \n",
      "<<<iteration:[220/244] - total_loss: 0.1832  obj_loss: 0.0676  noobj_loss: 0.0424  bbox_loss: 0.0051  cls_loss: 0.0688  \n",
      "<<<iteration:[240/244] - total_loss: 0.1752  obj_loss: 0.0671  noobj_loss: 0.0372  bbox_loss: 0.0042  cls_loss: 0.0685  \n",
      "\n",
      "epoch:62/100 - Train Loss: 0.1894, Val Loss: 0.2031\n",
      "\n",
      "<<<iteration:[20/244] - total_loss: 0.1996  obj_loss: 0.0649  noobj_loss: 0.0382  bbox_loss: 0.0043  cls_loss: 0.0942  \n",
      "<<<iteration:[40/244] - total_loss: 0.1961  obj_loss: 0.0735  noobj_loss: 0.0428  bbox_loss: 0.0042  cls_loss: 0.0801  \n",
      "<<<iteration:[60/244] - total_loss: 0.1779  obj_loss: 0.0697  noobj_loss: 0.0379  bbox_loss: 0.0039  cls_loss: 0.0696  \n",
      "<<<iteration:[80/244] - total_loss: 0.1626  obj_loss: 0.0713  noobj_loss: 0.0365  bbox_loss: 0.0042  cls_loss: 0.0522  \n",
      "<<<iteration:[100/244] - total_loss: 0.1779  obj_loss: 0.0675  noobj_loss: 0.0396  bbox_loss: 0.0038  cls_loss: 0.0715  \n",
      "<<<iteration:[120/244] - total_loss: 0.1859  obj_loss: 0.0662  noobj_loss: 0.0405  bbox_loss: 0.0043  cls_loss: 0.0779  \n",
      "<<<iteration:[140/244] - total_loss: 0.1844  obj_loss: 0.0687  noobj_loss: 0.0439  bbox_loss: 0.0048  cls_loss: 0.0697  \n",
      "<<<iteration:[160/244] - total_loss: 0.1988  obj_loss: 0.0695  noobj_loss: 0.0379  bbox_loss: 0.0041  cls_loss: 0.0900  \n",
      "<<<iteration:[180/244] - total_loss: 0.1848  obj_loss: 0.0685  noobj_loss: 0.0384  bbox_loss: 0.0043  cls_loss: 0.0755  \n",
      "<<<iteration:[200/244] - total_loss: 0.2079  obj_loss: 0.0696  noobj_loss: 0.0415  bbox_loss: 0.0048  cls_loss: 0.0934  \n",
      "<<<iteration:[220/244] - total_loss: 0.1702  obj_loss: 0.0685  noobj_loss: 0.0376  bbox_loss: 0.0045  cls_loss: 0.0605  \n",
      "<<<iteration:[240/244] - total_loss: 0.1779  obj_loss: 0.0711  noobj_loss: 0.0354  bbox_loss: 0.0046  cls_loss: 0.0660  \n",
      "\n",
      "epoch:63/100 - Train Loss: 0.1839, Val Loss: 0.2080\n",
      "\n",
      "<<<iteration:[20/244] - total_loss: 0.1773  obj_loss: 0.0777  noobj_loss: 0.0372  bbox_loss: 0.0047  cls_loss: 0.0575  \n",
      "<<<iteration:[40/244] - total_loss: 0.2065  obj_loss: 0.0813  noobj_loss: 0.0397  bbox_loss: 0.0039  cls_loss: 0.0859  \n",
      "<<<iteration:[60/244] - total_loss: 0.1897  obj_loss: 0.0646  noobj_loss: 0.0388  bbox_loss: 0.0045  cls_loss: 0.0834  \n",
      "<<<iteration:[80/244] - total_loss: 0.1793  obj_loss: 0.0651  noobj_loss: 0.0419  bbox_loss: 0.0051  cls_loss: 0.0680  \n",
      "<<<iteration:[100/244] - total_loss: 0.1719  obj_loss: 0.0707  noobj_loss: 0.0363  bbox_loss: 0.0042  cls_loss: 0.0618  \n",
      "<<<iteration:[120/244] - total_loss: 0.1664  obj_loss: 0.0665  noobj_loss: 0.0389  bbox_loss: 0.0042  cls_loss: 0.0593  \n",
      "<<<iteration:[140/244] - total_loss: 0.1949  obj_loss: 0.0700  noobj_loss: 0.0382  bbox_loss: 0.0043  cls_loss: 0.0844  \n",
      "<<<iteration:[160/244] - total_loss: 0.2110  obj_loss: 0.0687  noobj_loss: 0.0388  bbox_loss: 0.0048  cls_loss: 0.0989  \n",
      "<<<iteration:[180/244] - total_loss: 0.2165  obj_loss: 0.0743  noobj_loss: 0.0363  bbox_loss: 0.0039  cls_loss: 0.1046  \n",
      "<<<iteration:[200/244] - total_loss: 0.1761  obj_loss: 0.0697  noobj_loss: 0.0418  bbox_loss: 0.0044  cls_loss: 0.0633  \n",
      "<<<iteration:[220/244] - total_loss: 0.1735  obj_loss: 0.0704  noobj_loss: 0.0388  bbox_loss: 0.0038  cls_loss: 0.0649  \n",
      "<<<iteration:[240/244] - total_loss: 0.1780  obj_loss: 0.0731  noobj_loss: 0.0401  bbox_loss: 0.0044  cls_loss: 0.0627  \n",
      "\n",
      "epoch:64/100 - Train Loss: 0.1854, Val Loss: 0.2073\n",
      "\n",
      "<<<iteration:[20/244] - total_loss: 0.1845  obj_loss: 0.0712  noobj_loss: 0.0371  bbox_loss: 0.0042  cls_loss: 0.0738  \n",
      "<<<iteration:[40/244] - total_loss: 0.1881  obj_loss: 0.0736  noobj_loss: 0.0377  bbox_loss: 0.0043  cls_loss: 0.0740  \n",
      "<<<iteration:[60/244] - total_loss: 0.2028  obj_loss: 0.0816  noobj_loss: 0.0376  bbox_loss: 0.0038  cls_loss: 0.0834  \n",
      "<<<iteration:[80/244] - total_loss: 0.1858  obj_loss: 0.0706  noobj_loss: 0.0402  bbox_loss: 0.0044  cls_loss: 0.0731  \n",
      "<<<iteration:[100/244] - total_loss: 0.2231  obj_loss: 0.0749  noobj_loss: 0.0346  bbox_loss: 0.0042  cls_loss: 0.1099  \n",
      "<<<iteration:[120/244] - total_loss: 0.1917  obj_loss: 0.0630  noobj_loss: 0.0352  bbox_loss: 0.0038  cls_loss: 0.0920  \n",
      "<<<iteration:[140/244] - total_loss: 0.1991  obj_loss: 0.0825  noobj_loss: 0.0403  bbox_loss: 0.0040  cls_loss: 0.0763  \n",
      "<<<iteration:[160/244] - total_loss: 0.1582  obj_loss: 0.0712  noobj_loss: 0.0399  bbox_loss: 0.0038  cls_loss: 0.0480  \n",
      "<<<iteration:[180/244] - total_loss: 0.1696  obj_loss: 0.0753  noobj_loss: 0.0406  bbox_loss: 0.0039  cls_loss: 0.0545  \n",
      "<<<iteration:[200/244] - total_loss: 0.1594  obj_loss: 0.0728  noobj_loss: 0.0390  bbox_loss: 0.0044  cls_loss: 0.0450  \n",
      "<<<iteration:[220/244] - total_loss: 0.1848  obj_loss: 0.0673  noobj_loss: 0.0383  bbox_loss: 0.0041  cls_loss: 0.0779  \n",
      "<<<iteration:[240/244] - total_loss: 0.1828  obj_loss: 0.0745  noobj_loss: 0.0371  bbox_loss: 0.0040  cls_loss: 0.0697  \n",
      "\n",
      "epoch:65/100 - Train Loss: 0.1860, Val Loss: 0.2108\n",
      "\n",
      "<<<iteration:[20/244] - total_loss: 0.1868  obj_loss: 0.0757  noobj_loss: 0.0374  bbox_loss: 0.0039  cls_loss: 0.0729  \n",
      "<<<iteration:[40/244] - total_loss: 0.1686  obj_loss: 0.0662  noobj_loss: 0.0398  bbox_loss: 0.0049  cls_loss: 0.0581  \n",
      "<<<iteration:[60/244] - total_loss: 0.1760  obj_loss: 0.0831  noobj_loss: 0.0402  bbox_loss: 0.0040  cls_loss: 0.0529  \n",
      "<<<iteration:[80/244] - total_loss: 0.2080  obj_loss: 0.0655  noobj_loss: 0.0360  bbox_loss: 0.0047  cls_loss: 0.1010  \n",
      "<<<iteration:[100/244] - total_loss: 0.1783  obj_loss: 0.0665  noobj_loss: 0.0356  bbox_loss: 0.0035  cls_loss: 0.0763  \n",
      "<<<iteration:[120/244] - total_loss: 0.1728  obj_loss: 0.0694  noobj_loss: 0.0361  bbox_loss: 0.0042  cls_loss: 0.0642  \n",
      "<<<iteration:[140/244] - total_loss: 0.2215  obj_loss: 0.0750  noobj_loss: 0.0394  bbox_loss: 0.0040  cls_loss: 0.1069  \n",
      "<<<iteration:[160/244] - total_loss: 0.1885  obj_loss: 0.0735  noobj_loss: 0.0367  bbox_loss: 0.0040  cls_loss: 0.0766  \n",
      "<<<iteration:[180/244] - total_loss: 0.1696  obj_loss: 0.0600  noobj_loss: 0.0396  bbox_loss: 0.0044  cls_loss: 0.0678  \n",
      "<<<iteration:[200/244] - total_loss: 0.1930  obj_loss: 0.0682  noobj_loss: 0.0352  bbox_loss: 0.0038  cls_loss: 0.0884  \n",
      "<<<iteration:[220/244] - total_loss: 0.1715  obj_loss: 0.0734  noobj_loss: 0.0391  bbox_loss: 0.0042  cls_loss: 0.0575  \n",
      "<<<iteration:[240/244] - total_loss: 0.1818  obj_loss: 0.0688  noobj_loss: 0.0403  bbox_loss: 0.0048  cls_loss: 0.0688  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "epoch:66/100 - Train Loss: 0.1833, Val Loss: 0.2089\n",
      "\n",
      "<<<iteration:[20/244] - total_loss: 0.1689  obj_loss: 0.0736  noobj_loss: 0.0466  bbox_loss: 0.0045  cls_loss: 0.0496  \n",
      "<<<iteration:[40/244] - total_loss: 0.1777  obj_loss: 0.0671  noobj_loss: 0.0359  bbox_loss: 0.0043  cls_loss: 0.0711  \n",
      "<<<iteration:[60/244] - total_loss: 0.2016  obj_loss: 0.0770  noobj_loss: 0.0408  bbox_loss: 0.0041  cls_loss: 0.0836  \n",
      "<<<iteration:[80/244] - total_loss: 0.2077  obj_loss: 0.0770  noobj_loss: 0.0394  bbox_loss: 0.0037  cls_loss: 0.0926  \n",
      "<<<iteration:[100/244] - total_loss: 0.1797  obj_loss: 0.0721  noobj_loss: 0.0400  bbox_loss: 0.0040  cls_loss: 0.0679  \n",
      "<<<iteration:[120/244] - total_loss: 0.1806  obj_loss: 0.0770  noobj_loss: 0.0350  bbox_loss: 0.0037  cls_loss: 0.0675  \n",
      "<<<iteration:[140/244] - total_loss: 0.1743  obj_loss: 0.0688  noobj_loss: 0.0330  bbox_loss: 0.0039  cls_loss: 0.0696  \n",
      "<<<iteration:[160/244] - total_loss: 0.1704  obj_loss: 0.0689  noobj_loss: 0.0414  bbox_loss: 0.0045  cls_loss: 0.0582  \n",
      "<<<iteration:[180/244] - total_loss: 0.1611  obj_loss: 0.0648  noobj_loss: 0.0388  bbox_loss: 0.0042  cls_loss: 0.0559  \n",
      "<<<iteration:[200/244] - total_loss: 0.2078  obj_loss: 0.0677  noobj_loss: 0.0378  bbox_loss: 0.0046  cls_loss: 0.0980  \n",
      "<<<iteration:[220/244] - total_loss: 0.1572  obj_loss: 0.0666  noobj_loss: 0.0401  bbox_loss: 0.0045  cls_loss: 0.0482  \n",
      "<<<iteration:[240/244] - total_loss: 0.1920  obj_loss: 0.0724  noobj_loss: 0.0356  bbox_loss: 0.0043  cls_loss: 0.0803  \n",
      "\n",
      "epoch:67/100 - Train Loss: 0.1826, Val Loss: 0.2207\n",
      "\n",
      "<<<iteration:[20/244] - total_loss: 0.1870  obj_loss: 0.0759  noobj_loss: 0.0345  bbox_loss: 0.0043  cls_loss: 0.0721  \n",
      "<<<iteration:[40/244] - total_loss: 0.1808  obj_loss: 0.0726  noobj_loss: 0.0363  bbox_loss: 0.0036  cls_loss: 0.0720  \n",
      "<<<iteration:[60/244] - total_loss: 0.1735  obj_loss: 0.0735  noobj_loss: 0.0363  bbox_loss: 0.0036  cls_loss: 0.0638  \n",
      "<<<iteration:[80/244] - total_loss: 0.1870  obj_loss: 0.0740  noobj_loss: 0.0383  bbox_loss: 0.0052  cls_loss: 0.0679  \n",
      "<<<iteration:[100/244] - total_loss: 0.2027  obj_loss: 0.0719  noobj_loss: 0.0367  bbox_loss: 0.0041  cls_loss: 0.0921  \n",
      "<<<iteration:[120/244] - total_loss: 0.1807  obj_loss: 0.0640  noobj_loss: 0.0391  bbox_loss: 0.0040  cls_loss: 0.0768  \n",
      "<<<iteration:[140/244] - total_loss: 0.1786  obj_loss: 0.0653  noobj_loss: 0.0377  bbox_loss: 0.0040  cls_loss: 0.0742  \n",
      "<<<iteration:[160/244] - total_loss: 0.1531  obj_loss: 0.0603  noobj_loss: 0.0410  bbox_loss: 0.0039  cls_loss: 0.0529  \n",
      "<<<iteration:[180/244] - total_loss: 0.1749  obj_loss: 0.0683  noobj_loss: 0.0378  bbox_loss: 0.0047  cls_loss: 0.0642  \n",
      "<<<iteration:[200/244] - total_loss: 0.1953  obj_loss: 0.0765  noobj_loss: 0.0351  bbox_loss: 0.0039  cls_loss: 0.0819  \n",
      "<<<iteration:[220/244] - total_loss: 0.1856  obj_loss: 0.0629  noobj_loss: 0.0376  bbox_loss: 0.0045  cls_loss: 0.0813  \n",
      "<<<iteration:[240/244] - total_loss: 0.2004  obj_loss: 0.0713  noobj_loss: 0.0381  bbox_loss: 0.0039  cls_loss: 0.0903  \n",
      "\n",
      "epoch:68/100 - Train Loss: 0.1825, Val Loss: 0.2089\n",
      "\n",
      "<<<iteration:[20/244] - total_loss: 0.1921  obj_loss: 0.0684  noobj_loss: 0.0403  bbox_loss: 0.0045  cls_loss: 0.0809  \n",
      "<<<iteration:[40/244] - total_loss: 0.1967  obj_loss: 0.0678  noobj_loss: 0.0373  bbox_loss: 0.0037  cls_loss: 0.0919  \n",
      "<<<iteration:[60/244] - total_loss: 0.1780  obj_loss: 0.0643  noobj_loss: 0.0369  bbox_loss: 0.0058  cls_loss: 0.0663  \n",
      "<<<iteration:[80/244] - total_loss: 0.1927  obj_loss: 0.0713  noobj_loss: 0.0354  bbox_loss: 0.0051  cls_loss: 0.0783  \n",
      "<<<iteration:[100/244] - total_loss: 0.1676  obj_loss: 0.0701  noobj_loss: 0.0376  bbox_loss: 0.0042  cls_loss: 0.0577  \n",
      "<<<iteration:[120/244] - total_loss: 0.1613  obj_loss: 0.0704  noobj_loss: 0.0349  bbox_loss: 0.0038  cls_loss: 0.0546  \n",
      "<<<iteration:[140/244] - total_loss: 0.1945  obj_loss: 0.0648  noobj_loss: 0.0365  bbox_loss: 0.0043  cls_loss: 0.0901  \n",
      "<<<iteration:[160/244] - total_loss: 0.2050  obj_loss: 0.0709  noobj_loss: 0.0381  bbox_loss: 0.0044  cls_loss: 0.0928  \n",
      "<<<iteration:[180/244] - total_loss: 0.1634  obj_loss: 0.0706  noobj_loss: 0.0341  bbox_loss: 0.0044  cls_loss: 0.0537  \n",
      "<<<iteration:[200/244] - total_loss: 0.1516  obj_loss: 0.0633  noobj_loss: 0.0366  bbox_loss: 0.0042  cls_loss: 0.0492  \n",
      "<<<iteration:[220/244] - total_loss: 0.1850  obj_loss: 0.0762  noobj_loss: 0.0378  bbox_loss: 0.0039  cls_loss: 0.0703  \n",
      "<<<iteration:[240/244] - total_loss: 0.1967  obj_loss: 0.0697  noobj_loss: 0.0395  bbox_loss: 0.0044  cls_loss: 0.0851  \n",
      "\n",
      "epoch:69/100 - Train Loss: 0.1806, Val Loss: 0.2035\n",
      "\n",
      "<<<iteration:[20/244] - total_loss: 0.2165  obj_loss: 0.0723  noobj_loss: 0.0394  bbox_loss: 0.0040  cls_loss: 0.1045  \n",
      "<<<iteration:[40/244] - total_loss: 0.1898  obj_loss: 0.0756  noobj_loss: 0.0394  bbox_loss: 0.0035  cls_loss: 0.0767  \n",
      "<<<iteration:[60/244] - total_loss: 0.1833  obj_loss: 0.0603  noobj_loss: 0.0400  bbox_loss: 0.0054  cls_loss: 0.0759  \n",
      "<<<iteration:[80/244] - total_loss: 0.1652  obj_loss: 0.0606  noobj_loss: 0.0353  bbox_loss: 0.0037  cls_loss: 0.0685  \n",
      "<<<iteration:[100/244] - total_loss: 0.1698  obj_loss: 0.0752  noobj_loss: 0.0394  bbox_loss: 0.0040  cls_loss: 0.0548  \n",
      "<<<iteration:[120/244] - total_loss: 0.1842  obj_loss: 0.0710  noobj_loss: 0.0376  bbox_loss: 0.0044  cls_loss: 0.0726  \n",
      "<<<iteration:[140/244] - total_loss: 0.1774  obj_loss: 0.0591  noobj_loss: 0.0389  bbox_loss: 0.0051  cls_loss: 0.0731  \n",
      "<<<iteration:[160/244] - total_loss: 0.1762  obj_loss: 0.0671  noobj_loss: 0.0391  bbox_loss: 0.0039  cls_loss: 0.0701  \n",
      "<<<iteration:[180/244] - total_loss: 0.1890  obj_loss: 0.0644  noobj_loss: 0.0373  bbox_loss: 0.0045  cls_loss: 0.0837  \n",
      "<<<iteration:[200/244] - total_loss: 0.1717  obj_loss: 0.0689  noobj_loss: 0.0402  bbox_loss: 0.0044  cls_loss: 0.0609  \n",
      "<<<iteration:[220/244] - total_loss: 0.1616  obj_loss: 0.0686  noobj_loss: 0.0345  bbox_loss: 0.0037  cls_loss: 0.0573  \n",
      "<<<iteration:[240/244] - total_loss: 0.1890  obj_loss: 0.0739  noobj_loss: 0.0370  bbox_loss: 0.0042  cls_loss: 0.0758  \n",
      "\n",
      "epoch:70/100 - Train Loss: 0.1812, Val Loss: 0.2046\n",
      "\n",
      "<<<iteration:[20/244] - total_loss: 0.1884  obj_loss: 0.0731  noobj_loss: 0.0411  bbox_loss: 0.0049  cls_loss: 0.0701  \n",
      "<<<iteration:[40/244] - total_loss: 0.1805  obj_loss: 0.0716  noobj_loss: 0.0370  bbox_loss: 0.0035  cls_loss: 0.0729  \n",
      "<<<iteration:[60/244] - total_loss: 0.1532  obj_loss: 0.0775  noobj_loss: 0.0384  bbox_loss: 0.0044  cls_loss: 0.0346  \n",
      "<<<iteration:[80/244] - total_loss: 0.1865  obj_loss: 0.0665  noobj_loss: 0.0354  bbox_loss: 0.0038  cls_loss: 0.0831  \n",
      "<<<iteration:[100/244] - total_loss: 0.1676  obj_loss: 0.0569  noobj_loss: 0.0370  bbox_loss: 0.0040  cls_loss: 0.0722  \n",
      "<<<iteration:[120/244] - total_loss: 0.1769  obj_loss: 0.0701  noobj_loss: 0.0340  bbox_loss: 0.0038  cls_loss: 0.0709  \n",
      "<<<iteration:[140/244] - total_loss: 0.2073  obj_loss: 0.0727  noobj_loss: 0.0376  bbox_loss: 0.0040  cls_loss: 0.0960  \n",
      "<<<iteration:[160/244] - total_loss: 0.1588  obj_loss: 0.0684  noobj_loss: 0.0382  bbox_loss: 0.0042  cls_loss: 0.0504  \n",
      "<<<iteration:[180/244] - total_loss: 0.1781  obj_loss: 0.0627  noobj_loss: 0.0344  bbox_loss: 0.0039  cls_loss: 0.0789  \n",
      "<<<iteration:[200/244] - total_loss: 0.1918  obj_loss: 0.0702  noobj_loss: 0.0378  bbox_loss: 0.0043  cls_loss: 0.0811  \n",
      "<<<iteration:[220/244] - total_loss: 0.1828  obj_loss: 0.0726  noobj_loss: 0.0366  bbox_loss: 0.0038  cls_loss: 0.0727  \n",
      "<<<iteration:[240/244] - total_loss: 0.1896  obj_loss: 0.0774  noobj_loss: 0.0395  bbox_loss: 0.0036  cls_loss: 0.0744  \n",
      "\n",
      "epoch:71/100 - Train Loss: 0.1790, Val Loss: 0.2029\n",
      "\n",
      "<<<iteration:[20/244] - total_loss: 0.2087  obj_loss: 0.0726  noobj_loss: 0.0400  bbox_loss: 0.0046  cls_loss: 0.0932  \n",
      "<<<iteration:[40/244] - total_loss: 0.1634  obj_loss: 0.0725  noobj_loss: 0.0379  bbox_loss: 0.0045  cls_loss: 0.0494  \n",
      "<<<iteration:[60/244] - total_loss: 0.1931  obj_loss: 0.0695  noobj_loss: 0.0393  bbox_loss: 0.0038  cls_loss: 0.0849  \n",
      "<<<iteration:[80/244] - total_loss: 0.1916  obj_loss: 0.0744  noobj_loss: 0.0380  bbox_loss: 0.0042  cls_loss: 0.0771  \n",
      "<<<iteration:[100/244] - total_loss: 0.1619  obj_loss: 0.0677  noobj_loss: 0.0403  bbox_loss: 0.0037  cls_loss: 0.0554  \n",
      "<<<iteration:[120/244] - total_loss: 0.1828  obj_loss: 0.0709  noobj_loss: 0.0410  bbox_loss: 0.0038  cls_loss: 0.0726  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<<<iteration:[140/244] - total_loss: 0.1516  obj_loss: 0.0624  noobj_loss: 0.0397  bbox_loss: 0.0040  cls_loss: 0.0495  \n",
      "<<<iteration:[160/244] - total_loss: 0.1749  obj_loss: 0.0717  noobj_loss: 0.0386  bbox_loss: 0.0041  cls_loss: 0.0633  \n",
      "<<<iteration:[180/244] - total_loss: 0.1950  obj_loss: 0.0719  noobj_loss: 0.0369  bbox_loss: 0.0041  cls_loss: 0.0841  \n",
      "<<<iteration:[200/244] - total_loss: 0.1884  obj_loss: 0.0744  noobj_loss: 0.0386  bbox_loss: 0.0041  cls_loss: 0.0742  \n",
      "<<<iteration:[220/244] - total_loss: 0.1824  obj_loss: 0.0734  noobj_loss: 0.0366  bbox_loss: 0.0039  cls_loss: 0.0710  \n",
      "<<<iteration:[240/244] - total_loss: 0.1864  obj_loss: 0.0695  noobj_loss: 0.0362  bbox_loss: 0.0043  cls_loss: 0.0774  \n",
      "\n",
      "epoch:72/100 - Train Loss: 0.1804, Val Loss: 0.2034\n",
      "\n",
      "<<<iteration:[20/244] - total_loss: 0.2134  obj_loss: 0.0805  noobj_loss: 0.0403  bbox_loss: 0.0048  cls_loss: 0.0888  \n",
      "<<<iteration:[40/244] - total_loss: 0.1437  obj_loss: 0.0649  noobj_loss: 0.0366  bbox_loss: 0.0040  cls_loss: 0.0407  \n",
      "<<<iteration:[60/244] - total_loss: 0.1690  obj_loss: 0.0731  noobj_loss: 0.0384  bbox_loss: 0.0038  cls_loss: 0.0578  \n",
      "<<<iteration:[80/244] - total_loss: 0.1822  obj_loss: 0.0698  noobj_loss: 0.0396  bbox_loss: 0.0044  cls_loss: 0.0704  \n",
      "<<<iteration:[100/244] - total_loss: 0.2048  obj_loss: 0.0735  noobj_loss: 0.0374  bbox_loss: 0.0040  cls_loss: 0.0927  \n",
      "<<<iteration:[120/244] - total_loss: 0.1922  obj_loss: 0.0670  noobj_loss: 0.0419  bbox_loss: 0.0044  cls_loss: 0.0825  \n",
      "<<<iteration:[140/244] - total_loss: 0.1651  obj_loss: 0.0739  noobj_loss: 0.0376  bbox_loss: 0.0041  cls_loss: 0.0519  \n",
      "<<<iteration:[160/244] - total_loss: 0.1746  obj_loss: 0.0712  noobj_loss: 0.0385  bbox_loss: 0.0038  cls_loss: 0.0649  \n",
      "<<<iteration:[180/244] - total_loss: 0.1745  obj_loss: 0.0749  noobj_loss: 0.0385  bbox_loss: 0.0034  cls_loss: 0.0632  \n",
      "<<<iteration:[200/244] - total_loss: 0.1716  obj_loss: 0.0695  noobj_loss: 0.0358  bbox_loss: 0.0042  cls_loss: 0.0633  \n",
      "<<<iteration:[220/244] - total_loss: 0.1945  obj_loss: 0.0684  noobj_loss: 0.0410  bbox_loss: 0.0043  cls_loss: 0.0841  \n",
      "<<<iteration:[240/244] - total_loss: 0.1706  obj_loss: 0.0612  noobj_loss: 0.0361  bbox_loss: 0.0040  cls_loss: 0.0712  \n",
      "\n",
      "epoch:73/100 - Train Loss: 0.1783, Val Loss: 0.2043\n",
      "\n",
      "<<<iteration:[20/244] - total_loss: 0.2152  obj_loss: 0.0800  noobj_loss: 0.0440  bbox_loss: 0.0049  cls_loss: 0.0887  \n",
      "<<<iteration:[40/244] - total_loss: 0.1836  obj_loss: 0.0638  noobj_loss: 0.0419  bbox_loss: 0.0043  cls_loss: 0.0775  \n",
      "<<<iteration:[60/244] - total_loss: 0.1898  obj_loss: 0.0703  noobj_loss: 0.0383  bbox_loss: 0.0041  cls_loss: 0.0797  \n",
      "<<<iteration:[80/244] - total_loss: 0.1690  obj_loss: 0.0670  noobj_loss: 0.0381  bbox_loss: 0.0035  cls_loss: 0.0658  \n",
      "<<<iteration:[100/244] - total_loss: 0.1776  obj_loss: 0.0725  noobj_loss: 0.0382  bbox_loss: 0.0041  cls_loss: 0.0655  \n",
      "<<<iteration:[120/244] - total_loss: 0.1716  obj_loss: 0.0680  noobj_loss: 0.0370  bbox_loss: 0.0040  cls_loss: 0.0650  \n",
      "<<<iteration:[140/244] - total_loss: 0.1886  obj_loss: 0.0752  noobj_loss: 0.0376  bbox_loss: 0.0036  cls_loss: 0.0764  \n",
      "<<<iteration:[160/244] - total_loss: 0.1845  obj_loss: 0.0721  noobj_loss: 0.0363  bbox_loss: 0.0036  cls_loss: 0.0762  \n",
      "<<<iteration:[180/244] - total_loss: 0.1843  obj_loss: 0.0719  noobj_loss: 0.0388  bbox_loss: 0.0042  cls_loss: 0.0722  \n",
      "<<<iteration:[200/244] - total_loss: 0.1672  obj_loss: 0.0693  noobj_loss: 0.0375  bbox_loss: 0.0042  cls_loss: 0.0581  \n",
      "<<<iteration:[220/244] - total_loss: 0.1830  obj_loss: 0.0690  noobj_loss: 0.0409  bbox_loss: 0.0038  cls_loss: 0.0746  \n",
      "<<<iteration:[240/244] - total_loss: 0.1776  obj_loss: 0.0679  noobj_loss: 0.0367  bbox_loss: 0.0042  cls_loss: 0.0702  \n",
      "\n",
      "epoch:74/100 - Train Loss: 0.1817, Val Loss: 0.2012\n",
      "\n",
      "<<<iteration:[20/244] - total_loss: 0.1717  obj_loss: 0.0670  noobj_loss: 0.0387  bbox_loss: 0.0041  cls_loss: 0.0650  \n",
      "<<<iteration:[40/244] - total_loss: 0.2020  obj_loss: 0.0798  noobj_loss: 0.0421  bbox_loss: 0.0039  cls_loss: 0.0819  \n",
      "<<<iteration:[60/244] - total_loss: 0.1802  obj_loss: 0.0643  noobj_loss: 0.0387  bbox_loss: 0.0041  cls_loss: 0.0761  \n",
      "<<<iteration:[80/244] - total_loss: 0.1854  obj_loss: 0.0708  noobj_loss: 0.0378  bbox_loss: 0.0037  cls_loss: 0.0770  \n",
      "<<<iteration:[100/244] - total_loss: 0.1710  obj_loss: 0.0657  noobj_loss: 0.0406  bbox_loss: 0.0043  cls_loss: 0.0633  \n",
      "<<<iteration:[120/244] - total_loss: 0.1832  obj_loss: 0.0819  noobj_loss: 0.0392  bbox_loss: 0.0046  cls_loss: 0.0588  \n",
      "<<<iteration:[140/244] - total_loss: 0.1545  obj_loss: 0.0704  noobj_loss: 0.0366  bbox_loss: 0.0036  cls_loss: 0.0480  \n",
      "<<<iteration:[160/244] - total_loss: 0.1920  obj_loss: 0.0734  noobj_loss: 0.0404  bbox_loss: 0.0058  cls_loss: 0.0692  \n",
      "<<<iteration:[180/244] - total_loss: 0.1846  obj_loss: 0.0699  noobj_loss: 0.0391  bbox_loss: 0.0036  cls_loss: 0.0771  \n",
      "<<<iteration:[200/244] - total_loss: 0.1995  obj_loss: 0.0641  noobj_loss: 0.0377  bbox_loss: 0.0036  cls_loss: 0.0988  \n",
      "<<<iteration:[220/244] - total_loss: 0.1709  obj_loss: 0.0673  noobj_loss: 0.0353  bbox_loss: 0.0041  cls_loss: 0.0654  \n",
      "<<<iteration:[240/244] - total_loss: 0.1807  obj_loss: 0.0677  noobj_loss: 0.0409  bbox_loss: 0.0049  cls_loss: 0.0679  \n",
      "\n",
      "epoch:75/100 - Train Loss: 0.1802, Val Loss: 0.2068\n",
      "\n",
      "<<<iteration:[20/244] - total_loss: 0.1946  obj_loss: 0.0778  noobj_loss: 0.0392  bbox_loss: 0.0034  cls_loss: 0.0799  \n",
      "<<<iteration:[40/244] - total_loss: 0.1904  obj_loss: 0.0752  noobj_loss: 0.0376  bbox_loss: 0.0039  cls_loss: 0.0768  \n",
      "<<<iteration:[60/244] - total_loss: 0.1828  obj_loss: 0.0733  noobj_loss: 0.0390  bbox_loss: 0.0038  cls_loss: 0.0708  \n",
      "<<<iteration:[80/244] - total_loss: 0.1588  obj_loss: 0.0632  noobj_loss: 0.0356  bbox_loss: 0.0034  cls_loss: 0.0607  \n",
      "<<<iteration:[100/244] - total_loss: 0.1779  obj_loss: 0.0755  noobj_loss: 0.0393  bbox_loss: 0.0034  cls_loss: 0.0656  \n",
      "<<<iteration:[120/244] - total_loss: 0.2003  obj_loss: 0.0765  noobj_loss: 0.0384  bbox_loss: 0.0039  cls_loss: 0.0851  \n",
      "<<<iteration:[140/244] - total_loss: 0.1698  obj_loss: 0.0778  noobj_loss: 0.0395  bbox_loss: 0.0039  cls_loss: 0.0530  \n",
      "<<<iteration:[160/244] - total_loss: 0.1613  obj_loss: 0.0708  noobj_loss: 0.0380  bbox_loss: 0.0038  cls_loss: 0.0524  \n",
      "<<<iteration:[180/244] - total_loss: 0.1711  obj_loss: 0.0617  noobj_loss: 0.0401  bbox_loss: 0.0051  cls_loss: 0.0639  \n",
      "<<<iteration:[200/244] - total_loss: 0.1789  obj_loss: 0.0780  noobj_loss: 0.0350  bbox_loss: 0.0042  cls_loss: 0.0624  \n",
      "<<<iteration:[220/244] - total_loss: 0.1869  obj_loss: 0.0693  noobj_loss: 0.0400  bbox_loss: 0.0039  cls_loss: 0.0779  \n",
      "<<<iteration:[240/244] - total_loss: 0.2038  obj_loss: 0.0739  noobj_loss: 0.0375  bbox_loss: 0.0042  cls_loss: 0.0901  \n",
      "\n",
      "epoch:76/100 - Train Loss: 0.1812, Val Loss: 0.2062\n",
      "\n",
      "<<<iteration:[20/244] - total_loss: 0.2095  obj_loss: 0.0816  noobj_loss: 0.0387  bbox_loss: 0.0040  cls_loss: 0.0885  \n",
      "<<<iteration:[40/244] - total_loss: 0.1730  obj_loss: 0.0752  noobj_loss: 0.0387  bbox_loss: 0.0037  cls_loss: 0.0599  \n",
      "<<<iteration:[60/244] - total_loss: 0.1906  obj_loss: 0.0731  noobj_loss: 0.0370  bbox_loss: 0.0037  cls_loss: 0.0807  \n",
      "<<<iteration:[80/244] - total_loss: 0.1645  obj_loss: 0.0665  noobj_loss: 0.0340  bbox_loss: 0.0041  cls_loss: 0.0605  \n",
      "<<<iteration:[100/244] - total_loss: 0.1682  obj_loss: 0.0715  noobj_loss: 0.0360  bbox_loss: 0.0036  cls_loss: 0.0605  \n",
      "<<<iteration:[120/244] - total_loss: 0.1745  obj_loss: 0.0636  noobj_loss: 0.0359  bbox_loss: 0.0034  cls_loss: 0.0760  \n",
      "<<<iteration:[140/244] - total_loss: 0.1613  obj_loss: 0.0702  noobj_loss: 0.0396  bbox_loss: 0.0040  cls_loss: 0.0513  \n",
      "<<<iteration:[160/244] - total_loss: 0.1767  obj_loss: 0.0668  noobj_loss: 0.0364  bbox_loss: 0.0040  cls_loss: 0.0718  \n",
      "<<<iteration:[180/244] - total_loss: 0.1821  obj_loss: 0.0671  noobj_loss: 0.0374  bbox_loss: 0.0037  cls_loss: 0.0779  \n",
      "<<<iteration:[200/244] - total_loss: 0.1646  obj_loss: 0.0701  noobj_loss: 0.0387  bbox_loss: 0.0040  cls_loss: 0.0555  \n",
      "<<<iteration:[220/244] - total_loss: 0.1759  obj_loss: 0.0628  noobj_loss: 0.0361  bbox_loss: 0.0039  cls_loss: 0.0755  \n",
      "<<<iteration:[240/244] - total_loss: 0.1704  obj_loss: 0.0666  noobj_loss: 0.0389  bbox_loss: 0.0041  cls_loss: 0.0637  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "epoch:77/100 - Train Loss: 0.1751, Val Loss: 0.2050\n",
      "\n",
      "<<<iteration:[20/244] - total_loss: 0.2144  obj_loss: 0.0758  noobj_loss: 0.0431  bbox_loss: 0.0039  cls_loss: 0.0976  \n",
      "<<<iteration:[40/244] - total_loss: 0.1704  obj_loss: 0.0729  noobj_loss: 0.0359  bbox_loss: 0.0035  cls_loss: 0.0618  \n",
      "<<<iteration:[60/244] - total_loss: 0.1861  obj_loss: 0.0723  noobj_loss: 0.0412  bbox_loss: 0.0040  cls_loss: 0.0731  \n",
      "<<<iteration:[80/244] - total_loss: 0.1573  obj_loss: 0.0675  noobj_loss: 0.0380  bbox_loss: 0.0034  cls_loss: 0.0536  \n",
      "<<<iteration:[100/244] - total_loss: 0.1942  obj_loss: 0.0701  noobj_loss: 0.0387  bbox_loss: 0.0045  cls_loss: 0.0824  \n",
      "<<<iteration:[120/244] - total_loss: 0.1862  obj_loss: 0.0593  noobj_loss: 0.0339  bbox_loss: 0.0042  cls_loss: 0.0890  \n",
      "<<<iteration:[140/244] - total_loss: 0.1844  obj_loss: 0.0733  noobj_loss: 0.0365  bbox_loss: 0.0036  cls_loss: 0.0747  \n",
      "<<<iteration:[160/244] - total_loss: 0.1687  obj_loss: 0.0683  noobj_loss: 0.0352  bbox_loss: 0.0035  cls_loss: 0.0654  \n",
      "<<<iteration:[180/244] - total_loss: 0.1531  obj_loss: 0.0731  noobj_loss: 0.0389  bbox_loss: 0.0036  cls_loss: 0.0424  \n",
      "<<<iteration:[200/244] - total_loss: 0.1964  obj_loss: 0.0885  noobj_loss: 0.0398  bbox_loss: 0.0040  cls_loss: 0.0681  \n",
      "<<<iteration:[220/244] - total_loss: 0.1898  obj_loss: 0.0757  noobj_loss: 0.0403  bbox_loss: 0.0047  cls_loss: 0.0704  \n",
      "<<<iteration:[240/244] - total_loss: 0.1704  obj_loss: 0.0738  noobj_loss: 0.0356  bbox_loss: 0.0037  cls_loss: 0.0601  \n",
      "\n",
      "epoch:78/100 - Train Loss: 0.1808, Val Loss: 0.1965\n",
      "\n",
      "<<<iteration:[20/244] - total_loss: 0.1801  obj_loss: 0.0738  noobj_loss: 0.0394  bbox_loss: 0.0042  cls_loss: 0.0656  \n",
      "<<<iteration:[40/244] - total_loss: 0.1898  obj_loss: 0.0752  noobj_loss: 0.0363  bbox_loss: 0.0031  cls_loss: 0.0809  \n",
      "<<<iteration:[60/244] - total_loss: 0.1686  obj_loss: 0.0743  noobj_loss: 0.0379  bbox_loss: 0.0034  cls_loss: 0.0581  \n",
      "<<<iteration:[80/244] - total_loss: 0.1971  obj_loss: 0.0704  noobj_loss: 0.0357  bbox_loss: 0.0039  cls_loss: 0.0893  \n",
      "<<<iteration:[100/244] - total_loss: 0.1678  obj_loss: 0.0687  noobj_loss: 0.0373  bbox_loss: 0.0035  cls_loss: 0.0629  \n",
      "<<<iteration:[120/244] - total_loss: 0.1656  obj_loss: 0.0661  noobj_loss: 0.0377  bbox_loss: 0.0042  cls_loss: 0.0596  \n",
      "<<<iteration:[140/244] - total_loss: 0.1778  obj_loss: 0.0687  noobj_loss: 0.0387  bbox_loss: 0.0041  cls_loss: 0.0690  \n",
      "<<<iteration:[160/244] - total_loss: 0.2005  obj_loss: 0.0698  noobj_loss: 0.0392  bbox_loss: 0.0041  cls_loss: 0.0908  \n",
      "<<<iteration:[180/244] - total_loss: 0.1730  obj_loss: 0.0761  noobj_loss: 0.0373  bbox_loss: 0.0036  cls_loss: 0.0601  \n",
      "<<<iteration:[200/244] - total_loss: 0.1402  obj_loss: 0.0718  noobj_loss: 0.0382  bbox_loss: 0.0034  cls_loss: 0.0324  \n",
      "<<<iteration:[220/244] - total_loss: 0.1858  obj_loss: 0.0703  noobj_loss: 0.0403  bbox_loss: 0.0040  cls_loss: 0.0754  \n",
      "<<<iteration:[240/244] - total_loss: 0.1713  obj_loss: 0.0712  noobj_loss: 0.0402  bbox_loss: 0.0039  cls_loss: 0.0605  \n",
      "\n",
      "epoch:79/100 - Train Loss: 0.1754, Val Loss: 0.2009\n",
      "\n",
      "<<<iteration:[20/244] - total_loss: 0.1686  obj_loss: 0.0660  noobj_loss: 0.0420  bbox_loss: 0.0048  cls_loss: 0.0577  \n",
      "<<<iteration:[40/244] - total_loss: 0.1848  obj_loss: 0.0707  noobj_loss: 0.0389  bbox_loss: 0.0038  cls_loss: 0.0755  \n",
      "<<<iteration:[60/244] - total_loss: 0.1759  obj_loss: 0.0704  noobj_loss: 0.0415  bbox_loss: 0.0042  cls_loss: 0.0637  \n",
      "<<<iteration:[80/244] - total_loss: 0.1818  obj_loss: 0.0726  noobj_loss: 0.0371  bbox_loss: 0.0039  cls_loss: 0.0712  \n",
      "<<<iteration:[100/244] - total_loss: 0.2081  obj_loss: 0.0786  noobj_loss: 0.0346  bbox_loss: 0.0033  cls_loss: 0.0955  \n",
      "<<<iteration:[120/244] - total_loss: 0.1693  obj_loss: 0.0686  noobj_loss: 0.0372  bbox_loss: 0.0036  cls_loss: 0.0641  \n",
      "<<<iteration:[140/244] - total_loss: 0.1841  obj_loss: 0.0676  noobj_loss: 0.0384  bbox_loss: 0.0040  cls_loss: 0.0774  \n",
      "<<<iteration:[160/244] - total_loss: 0.1559  obj_loss: 0.0617  noobj_loss: 0.0374  bbox_loss: 0.0041  cls_loss: 0.0548  \n",
      "<<<iteration:[180/244] - total_loss: 0.1775  obj_loss: 0.0730  noobj_loss: 0.0392  bbox_loss: 0.0041  cls_loss: 0.0647  \n",
      "<<<iteration:[200/244] - total_loss: 0.1639  obj_loss: 0.0726  noobj_loss: 0.0419  bbox_loss: 0.0039  cls_loss: 0.0508  \n",
      "<<<iteration:[220/244] - total_loss: 0.1689  obj_loss: 0.0579  noobj_loss: 0.0399  bbox_loss: 0.0040  cls_loss: 0.0710  \n",
      "<<<iteration:[240/244] - total_loss: 0.1794  obj_loss: 0.0717  noobj_loss: 0.0374  bbox_loss: 0.0040  cls_loss: 0.0689  \n",
      "\n",
      "epoch:80/100 - Train Loss: 0.1759, Val Loss: 0.2017\n",
      "\n",
      "<<<iteration:[20/244] - total_loss: 0.1873  obj_loss: 0.0761  noobj_loss: 0.0379  bbox_loss: 0.0042  cls_loss: 0.0710  \n",
      "<<<iteration:[40/244] - total_loss: 0.1792  obj_loss: 0.0693  noobj_loss: 0.0395  bbox_loss: 0.0039  cls_loss: 0.0707  \n",
      "<<<iteration:[60/244] - total_loss: 0.1745  obj_loss: 0.0781  noobj_loss: 0.0368  bbox_loss: 0.0041  cls_loss: 0.0573  \n",
      "<<<iteration:[80/244] - total_loss: 0.1687  obj_loss: 0.0739  noobj_loss: 0.0393  bbox_loss: 0.0040  cls_loss: 0.0554  \n",
      "<<<iteration:[100/244] - total_loss: 0.1640  obj_loss: 0.0645  noobj_loss: 0.0368  bbox_loss: 0.0037  cls_loss: 0.0624  \n",
      "<<<iteration:[120/244] - total_loss: 0.1685  obj_loss: 0.0749  noobj_loss: 0.0361  bbox_loss: 0.0037  cls_loss: 0.0572  \n",
      "<<<iteration:[140/244] - total_loss: 0.1907  obj_loss: 0.0762  noobj_loss: 0.0392  bbox_loss: 0.0041  cls_loss: 0.0744  \n",
      "<<<iteration:[160/244] - total_loss: 0.1949  obj_loss: 0.0745  noobj_loss: 0.0409  bbox_loss: 0.0041  cls_loss: 0.0791  \n",
      "<<<iteration:[180/244] - total_loss: 0.1704  obj_loss: 0.0690  noobj_loss: 0.0378  bbox_loss: 0.0039  cls_loss: 0.0628  \n",
      "<<<iteration:[200/244] - total_loss: 0.1793  obj_loss: 0.0706  noobj_loss: 0.0412  bbox_loss: 0.0039  cls_loss: 0.0684  \n",
      "<<<iteration:[220/244] - total_loss: 0.1750  obj_loss: 0.0633  noobj_loss: 0.0381  bbox_loss: 0.0038  cls_loss: 0.0734  \n",
      "<<<iteration:[240/244] - total_loss: 0.1817  obj_loss: 0.0716  noobj_loss: 0.0396  bbox_loss: 0.0040  cls_loss: 0.0704  \n",
      "\n",
      "epoch:81/100 - Train Loss: 0.1774, Val Loss: 0.2033\n",
      "\n",
      "<<<iteration:[20/244] - total_loss: 0.1669  obj_loss: 0.0698  noobj_loss: 0.0404  bbox_loss: 0.0037  cls_loss: 0.0585  \n",
      "<<<iteration:[40/244] - total_loss: 0.1659  obj_loss: 0.0600  noobj_loss: 0.0361  bbox_loss: 0.0035  cls_loss: 0.0702  \n",
      "<<<iteration:[60/244] - total_loss: 0.1443  obj_loss: 0.0763  noobj_loss: 0.0369  bbox_loss: 0.0037  cls_loss: 0.0311  \n",
      "<<<iteration:[80/244] - total_loss: 0.2149  obj_loss: 0.0726  noobj_loss: 0.0361  bbox_loss: 0.0037  cls_loss: 0.1055  \n",
      "<<<iteration:[100/244] - total_loss: 0.1789  obj_loss: 0.0735  noobj_loss: 0.0345  bbox_loss: 0.0036  cls_loss: 0.0700  \n",
      "<<<iteration:[120/244] - total_loss: 0.1491  obj_loss: 0.0631  noobj_loss: 0.0363  bbox_loss: 0.0037  cls_loss: 0.0493  \n",
      "<<<iteration:[140/244] - total_loss: 0.1849  obj_loss: 0.0715  noobj_loss: 0.0385  bbox_loss: 0.0042  cls_loss: 0.0732  \n",
      "<<<iteration:[160/244] - total_loss: 0.1862  obj_loss: 0.0773  noobj_loss: 0.0419  bbox_loss: 0.0045  cls_loss: 0.0653  \n",
      "<<<iteration:[180/244] - total_loss: 0.2030  obj_loss: 0.0736  noobj_loss: 0.0397  bbox_loss: 0.0038  cls_loss: 0.0903  \n",
      "<<<iteration:[200/244] - total_loss: 0.1645  obj_loss: 0.0725  noobj_loss: 0.0353  bbox_loss: 0.0033  cls_loss: 0.0577  \n",
      "<<<iteration:[220/244] - total_loss: 0.1526  obj_loss: 0.0679  noobj_loss: 0.0372  bbox_loss: 0.0042  cls_loss: 0.0450  \n",
      "<<<iteration:[240/244] - total_loss: 0.1870  obj_loss: 0.0711  noobj_loss: 0.0386  bbox_loss: 0.0034  cls_loss: 0.0797  \n",
      "\n",
      "epoch:82/100 - Train Loss: 0.1735, Val Loss: 0.2040\n",
      "\n",
      "<<<iteration:[20/244] - total_loss: 0.1862  obj_loss: 0.0843  noobj_loss: 0.0417  bbox_loss: 0.0038  cls_loss: 0.0623  \n",
      "<<<iteration:[40/244] - total_loss: 0.1850  obj_loss: 0.0721  noobj_loss: 0.0379  bbox_loss: 0.0041  cls_loss: 0.0736  \n",
      "<<<iteration:[60/244] - total_loss: 0.1661  obj_loss: 0.0710  noobj_loss: 0.0376  bbox_loss: 0.0040  cls_loss: 0.0563  \n",
      "<<<iteration:[80/244] - total_loss: 0.1785  obj_loss: 0.0832  noobj_loss: 0.0379  bbox_loss: 0.0037  cls_loss: 0.0581  \n",
      "<<<iteration:[100/244] - total_loss: 0.1843  obj_loss: 0.0739  noobj_loss: 0.0400  bbox_loss: 0.0038  cls_loss: 0.0713  \n",
      "<<<iteration:[120/244] - total_loss: 0.1601  obj_loss: 0.0596  noobj_loss: 0.0358  bbox_loss: 0.0038  cls_loss: 0.0635  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<<<iteration:[140/244] - total_loss: 0.1815  obj_loss: 0.0652  noobj_loss: 0.0358  bbox_loss: 0.0038  cls_loss: 0.0795  \n",
      "<<<iteration:[160/244] - total_loss: 0.1599  obj_loss: 0.0702  noobj_loss: 0.0381  bbox_loss: 0.0034  cls_loss: 0.0539  \n",
      "<<<iteration:[180/244] - total_loss: 0.1871  obj_loss: 0.0796  noobj_loss: 0.0469  bbox_loss: 0.0053  cls_loss: 0.0577  \n",
      "<<<iteration:[200/244] - total_loss: 0.1913  obj_loss: 0.0713  noobj_loss: 0.0395  bbox_loss: 0.0037  cls_loss: 0.0816  \n",
      "<<<iteration:[220/244] - total_loss: 0.1732  obj_loss: 0.0697  noobj_loss: 0.0391  bbox_loss: 0.0036  cls_loss: 0.0661  \n",
      "<<<iteration:[240/244] - total_loss: 0.1708  obj_loss: 0.0692  noobj_loss: 0.0395  bbox_loss: 0.0038  cls_loss: 0.0628  \n",
      "\n",
      "epoch:83/100 - Train Loss: 0.1760, Val Loss: 0.1993\n",
      "\n",
      "<<<iteration:[20/244] - total_loss: 0.1843  obj_loss: 0.0645  noobj_loss: 0.0365  bbox_loss: 0.0040  cls_loss: 0.0817  \n",
      "<<<iteration:[40/244] - total_loss: 0.1640  obj_loss: 0.0638  noobj_loss: 0.0420  bbox_loss: 0.0040  cls_loss: 0.0593  \n",
      "<<<iteration:[60/244] - total_loss: 0.1704  obj_loss: 0.0730  noobj_loss: 0.0354  bbox_loss: 0.0036  cls_loss: 0.0615  \n",
      "<<<iteration:[80/244] - total_loss: 0.1739  obj_loss: 0.0711  noobj_loss: 0.0357  bbox_loss: 0.0038  cls_loss: 0.0657  \n",
      "<<<iteration:[100/244] - total_loss: 0.1607  obj_loss: 0.0682  noobj_loss: 0.0372  bbox_loss: 0.0038  cls_loss: 0.0551  \n",
      "<<<iteration:[120/244] - total_loss: 0.1666  obj_loss: 0.0681  noobj_loss: 0.0401  bbox_loss: 0.0036  cls_loss: 0.0603  \n",
      "<<<iteration:[140/244] - total_loss: 0.1744  obj_loss: 0.0710  noobj_loss: 0.0361  bbox_loss: 0.0034  cls_loss: 0.0682  \n",
      "<<<iteration:[160/244] - total_loss: 0.1764  obj_loss: 0.0652  noobj_loss: 0.0393  bbox_loss: 0.0043  cls_loss: 0.0699  \n",
      "<<<iteration:[180/244] - total_loss: 0.1889  obj_loss: 0.0681  noobj_loss: 0.0344  bbox_loss: 0.0031  cls_loss: 0.0879  \n",
      "<<<iteration:[200/244] - total_loss: 0.1894  obj_loss: 0.0796  noobj_loss: 0.0389  bbox_loss: 0.0035  cls_loss: 0.0728  \n",
      "<<<iteration:[220/244] - total_loss: 0.1840  obj_loss: 0.0670  noobj_loss: 0.0372  bbox_loss: 0.0045  cls_loss: 0.0758  \n",
      "<<<iteration:[240/244] - total_loss: 0.1489  obj_loss: 0.0739  noobj_loss: 0.0369  bbox_loss: 0.0034  cls_loss: 0.0397  \n",
      "\n",
      "epoch:84/100 - Train Loss: 0.1729, Val Loss: 0.1982\n",
      "\n",
      "<<<iteration:[20/244] - total_loss: 0.1846  obj_loss: 0.0804  noobj_loss: 0.0393  bbox_loss: 0.0037  cls_loss: 0.0661  \n",
      "<<<iteration:[40/244] - total_loss: 0.1918  obj_loss: 0.0715  noobj_loss: 0.0397  bbox_loss: 0.0040  cls_loss: 0.0803  \n",
      "<<<iteration:[60/244] - total_loss: 0.1633  obj_loss: 0.0572  noobj_loss: 0.0380  bbox_loss: 0.0042  cls_loss: 0.0659  \n",
      "<<<iteration:[80/244] - total_loss: 0.1800  obj_loss: 0.0703  noobj_loss: 0.0368  bbox_loss: 0.0039  cls_loss: 0.0716  \n",
      "<<<iteration:[100/244] - total_loss: 0.1656  obj_loss: 0.0801  noobj_loss: 0.0361  bbox_loss: 0.0034  cls_loss: 0.0504  \n",
      "<<<iteration:[120/244] - total_loss: 0.1913  obj_loss: 0.0753  noobj_loss: 0.0419  bbox_loss: 0.0037  cls_loss: 0.0764  \n",
      "<<<iteration:[140/244] - total_loss: 0.1949  obj_loss: 0.0729  noobj_loss: 0.0403  bbox_loss: 0.0053  cls_loss: 0.0755  \n",
      "<<<iteration:[160/244] - total_loss: 0.1754  obj_loss: 0.0665  noobj_loss: 0.0368  bbox_loss: 0.0041  cls_loss: 0.0703  \n",
      "<<<iteration:[180/244] - total_loss: 0.1839  obj_loss: 0.0769  noobj_loss: 0.0413  bbox_loss: 0.0041  cls_loss: 0.0657  \n",
      "<<<iteration:[200/244] - total_loss: 0.1776  obj_loss: 0.0765  noobj_loss: 0.0408  bbox_loss: 0.0032  cls_loss: 0.0646  \n",
      "<<<iteration:[220/244] - total_loss: 0.1574  obj_loss: 0.0651  noobj_loss: 0.0389  bbox_loss: 0.0044  cls_loss: 0.0507  \n",
      "<<<iteration:[240/244] - total_loss: 0.1613  obj_loss: 0.0674  noobj_loss: 0.0364  bbox_loss: 0.0035  cls_loss: 0.0584  \n",
      "\n",
      "epoch:85/100 - Train Loss: 0.1764, Val Loss: 0.2016\n",
      "\n",
      "<<<iteration:[20/244] - total_loss: 0.1676  obj_loss: 0.0713  noobj_loss: 0.0404  bbox_loss: 0.0036  cls_loss: 0.0579  \n",
      "<<<iteration:[40/244] - total_loss: 0.1916  obj_loss: 0.0786  noobj_loss: 0.0409  bbox_loss: 0.0037  cls_loss: 0.0739  \n",
      "<<<iteration:[60/244] - total_loss: 0.1470  obj_loss: 0.0735  noobj_loss: 0.0397  bbox_loss: 0.0036  cls_loss: 0.0356  \n",
      "<<<iteration:[80/244] - total_loss: 0.1995  obj_loss: 0.0763  noobj_loss: 0.0401  bbox_loss: 0.0046  cls_loss: 0.0801  \n",
      "<<<iteration:[100/244] - total_loss: 0.1846  obj_loss: 0.0669  noobj_loss: 0.0410  bbox_loss: 0.0039  cls_loss: 0.0776  \n",
      "<<<iteration:[120/244] - total_loss: 0.1657  obj_loss: 0.0710  noobj_loss: 0.0349  bbox_loss: 0.0038  cls_loss: 0.0585  \n",
      "<<<iteration:[140/244] - total_loss: 0.1750  obj_loss: 0.0727  noobj_loss: 0.0370  bbox_loss: 0.0039  cls_loss: 0.0643  \n",
      "<<<iteration:[160/244] - total_loss: 0.1901  obj_loss: 0.0601  noobj_loss: 0.0381  bbox_loss: 0.0047  cls_loss: 0.0876  \n",
      "<<<iteration:[180/244] - total_loss: 0.1735  obj_loss: 0.0649  noobj_loss: 0.0372  bbox_loss: 0.0044  cls_loss: 0.0679  \n",
      "<<<iteration:[200/244] - total_loss: 0.1794  obj_loss: 0.0630  noobj_loss: 0.0379  bbox_loss: 0.0040  cls_loss: 0.0777  \n",
      "<<<iteration:[220/244] - total_loss: 0.1667  obj_loss: 0.0720  noobj_loss: 0.0380  bbox_loss: 0.0038  cls_loss: 0.0565  \n",
      "<<<iteration:[240/244] - total_loss: 0.1734  obj_loss: 0.0698  noobj_loss: 0.0380  bbox_loss: 0.0034  cls_loss: 0.0673  \n",
      "\n",
      "epoch:86/100 - Train Loss: 0.1749, Val Loss: 0.2022\n",
      "\n",
      "<<<iteration:[20/244] - total_loss: 0.1731  obj_loss: 0.0797  noobj_loss: 0.0453  bbox_loss: 0.0044  cls_loss: 0.0490  \n",
      "<<<iteration:[40/244] - total_loss: 0.1984  obj_loss: 0.0721  noobj_loss: 0.0404  bbox_loss: 0.0040  cls_loss: 0.0863  \n",
      "<<<iteration:[60/244] - total_loss: 0.1652  obj_loss: 0.0708  noobj_loss: 0.0396  bbox_loss: 0.0039  cls_loss: 0.0550  \n",
      "<<<iteration:[80/244] - total_loss: 0.1828  obj_loss: 0.0788  noobj_loss: 0.0392  bbox_loss: 0.0038  cls_loss: 0.0652  \n",
      "<<<iteration:[100/244] - total_loss: 0.1622  obj_loss: 0.0720  noobj_loss: 0.0396  bbox_loss: 0.0037  cls_loss: 0.0521  \n",
      "<<<iteration:[120/244] - total_loss: 0.1786  obj_loss: 0.0621  noobj_loss: 0.0374  bbox_loss: 0.0043  cls_loss: 0.0766  \n",
      "<<<iteration:[140/244] - total_loss: 0.1486  obj_loss: 0.0723  noobj_loss: 0.0380  bbox_loss: 0.0034  cls_loss: 0.0403  \n",
      "<<<iteration:[160/244] - total_loss: 0.1770  obj_loss: 0.0699  noobj_loss: 0.0383  bbox_loss: 0.0040  cls_loss: 0.0679  \n",
      "<<<iteration:[180/244] - total_loss: 0.1738  obj_loss: 0.0652  noobj_loss: 0.0412  bbox_loss: 0.0041  cls_loss: 0.0674  \n",
      "<<<iteration:[200/244] - total_loss: 0.2037  obj_loss: 0.0682  noobj_loss: 0.0386  bbox_loss: 0.0037  cls_loss: 0.0976  \n",
      "<<<iteration:[220/244] - total_loss: 0.1614  obj_loss: 0.0634  noobj_loss: 0.0385  bbox_loss: 0.0036  cls_loss: 0.0609  \n",
      "<<<iteration:[240/244] - total_loss: 0.1825  obj_loss: 0.0755  noobj_loss: 0.0360  bbox_loss: 0.0031  cls_loss: 0.0737  \n",
      "\n",
      "epoch:87/100 - Train Loss: 0.1744, Val Loss: 0.2009\n",
      "\n",
      "<<<iteration:[20/244] - total_loss: 0.1936  obj_loss: 0.0757  noobj_loss: 0.0395  bbox_loss: 0.0039  cls_loss: 0.0785  \n",
      "<<<iteration:[40/244] - total_loss: 0.1606  obj_loss: 0.0822  noobj_loss: 0.0379  bbox_loss: 0.0035  cls_loss: 0.0419  \n",
      "<<<iteration:[60/244] - total_loss: 0.1873  obj_loss: 0.0720  noobj_loss: 0.0412  bbox_loss: 0.0039  cls_loss: 0.0754  \n",
      "<<<iteration:[80/244] - total_loss: 0.1646  obj_loss: 0.0697  noobj_loss: 0.0391  bbox_loss: 0.0037  cls_loss: 0.0570  \n",
      "<<<iteration:[100/244] - total_loss: 0.1647  obj_loss: 0.0829  noobj_loss: 0.0402  bbox_loss: 0.0038  cls_loss: 0.0429  \n",
      "<<<iteration:[120/244] - total_loss: 0.1509  obj_loss: 0.0730  noobj_loss: 0.0385  bbox_loss: 0.0035  cls_loss: 0.0411  \n",
      "<<<iteration:[140/244] - total_loss: 0.1699  obj_loss: 0.0635  noobj_loss: 0.0346  bbox_loss: 0.0038  cls_loss: 0.0702  \n",
      "<<<iteration:[160/244] - total_loss: 0.1993  obj_loss: 0.0715  noobj_loss: 0.0372  bbox_loss: 0.0031  cls_loss: 0.0936  \n",
      "<<<iteration:[180/244] - total_loss: 0.1975  obj_loss: 0.0773  noobj_loss: 0.0414  bbox_loss: 0.0036  cls_loss: 0.0817  \n",
      "<<<iteration:[200/244] - total_loss: 0.1664  obj_loss: 0.0646  noobj_loss: 0.0381  bbox_loss: 0.0042  cls_loss: 0.0618  \n",
      "<<<iteration:[220/244] - total_loss: 0.1667  obj_loss: 0.0669  noobj_loss: 0.0370  bbox_loss: 0.0041  cls_loss: 0.0609  \n",
      "<<<iteration:[240/244] - total_loss: 0.1658  obj_loss: 0.0686  noobj_loss: 0.0365  bbox_loss: 0.0036  cls_loss: 0.0610  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "epoch:88/100 - Train Loss: 0.1735, Val Loss: 0.2013\n",
      "\n",
      "<<<iteration:[20/244] - total_loss: 0.1508  obj_loss: 0.0705  noobj_loss: 0.0394  bbox_loss: 0.0036  cls_loss: 0.0427  \n",
      "<<<iteration:[40/244] - total_loss: 0.1543  obj_loss: 0.0713  noobj_loss: 0.0365  bbox_loss: 0.0037  cls_loss: 0.0464  \n",
      "<<<iteration:[60/244] - total_loss: 0.1915  obj_loss: 0.0691  noobj_loss: 0.0364  bbox_loss: 0.0034  cls_loss: 0.0873  \n",
      "<<<iteration:[80/244] - total_loss: 0.1636  obj_loss: 0.0685  noobj_loss: 0.0353  bbox_loss: 0.0035  cls_loss: 0.0598  \n",
      "<<<iteration:[100/244] - total_loss: 0.1784  obj_loss: 0.0645  noobj_loss: 0.0375  bbox_loss: 0.0038  cls_loss: 0.0760  \n",
      "<<<iteration:[120/244] - total_loss: 0.1886  obj_loss: 0.0713  noobj_loss: 0.0458  bbox_loss: 0.0039  cls_loss: 0.0747  \n",
      "<<<iteration:[140/244] - total_loss: 0.1849  obj_loss: 0.0665  noobj_loss: 0.0382  bbox_loss: 0.0038  cls_loss: 0.0804  \n",
      "<<<iteration:[160/244] - total_loss: 0.1645  obj_loss: 0.0654  noobj_loss: 0.0388  bbox_loss: 0.0039  cls_loss: 0.0603  \n",
      "<<<iteration:[180/244] - total_loss: 0.1831  obj_loss: 0.0769  noobj_loss: 0.0393  bbox_loss: 0.0040  cls_loss: 0.0666  \n",
      "<<<iteration:[200/244] - total_loss: 0.1604  obj_loss: 0.0720  noobj_loss: 0.0366  bbox_loss: 0.0039  cls_loss: 0.0506  \n",
      "<<<iteration:[220/244] - total_loss: 0.1820  obj_loss: 0.0804  noobj_loss: 0.0374  bbox_loss: 0.0031  cls_loss: 0.0673  \n",
      "<<<iteration:[240/244] - total_loss: 0.1647  obj_loss: 0.0687  noobj_loss: 0.0391  bbox_loss: 0.0037  cls_loss: 0.0579  \n",
      "\n",
      "epoch:89/100 - Train Loss: 0.1714, Val Loss: 0.2029\n",
      "\n",
      "<<<iteration:[20/244] - total_loss: 0.2079  obj_loss: 0.0796  noobj_loss: 0.0398  bbox_loss: 0.0041  cls_loss: 0.0880  \n",
      "<<<iteration:[40/244] - total_loss: 0.1611  obj_loss: 0.0724  noobj_loss: 0.0414  bbox_loss: 0.0034  cls_loss: 0.0509  \n",
      "<<<iteration:[60/244] - total_loss: 0.1565  obj_loss: 0.0631  noobj_loss: 0.0345  bbox_loss: 0.0033  cls_loss: 0.0596  \n",
      "<<<iteration:[80/244] - total_loss: 0.1585  obj_loss: 0.0655  noobj_loss: 0.0409  bbox_loss: 0.0039  cls_loss: 0.0532  \n",
      "<<<iteration:[100/244] - total_loss: 0.1655  obj_loss: 0.0733  noobj_loss: 0.0375  bbox_loss: 0.0035  cls_loss: 0.0558  \n",
      "<<<iteration:[120/244] - total_loss: 0.1924  obj_loss: 0.0714  noobj_loss: 0.0378  bbox_loss: 0.0039  cls_loss: 0.0824  \n",
      "<<<iteration:[140/244] - total_loss: 0.1780  obj_loss: 0.0709  noobj_loss: 0.0387  bbox_loss: 0.0035  cls_loss: 0.0701  \n",
      "<<<iteration:[160/244] - total_loss: 0.1673  obj_loss: 0.0710  noobj_loss: 0.0373  bbox_loss: 0.0034  cls_loss: 0.0606  \n",
      "<<<iteration:[180/244] - total_loss: 0.1652  obj_loss: 0.0707  noobj_loss: 0.0378  bbox_loss: 0.0035  cls_loss: 0.0580  \n",
      "<<<iteration:[200/244] - total_loss: 0.1614  obj_loss: 0.0665  noobj_loss: 0.0410  bbox_loss: 0.0036  cls_loss: 0.0564  \n",
      "<<<iteration:[220/244] - total_loss: 0.1751  obj_loss: 0.0702  noobj_loss: 0.0423  bbox_loss: 0.0041  cls_loss: 0.0633  \n",
      "<<<iteration:[240/244] - total_loss: 0.1752  obj_loss: 0.0695  noobj_loss: 0.0375  bbox_loss: 0.0032  cls_loss: 0.0709  \n",
      "\n",
      "epoch:90/100 - Train Loss: 0.1714, Val Loss: 0.2040\n",
      "\n",
      "<<<iteration:[20/244] - total_loss: 0.1943  obj_loss: 0.0819  noobj_loss: 0.0423  bbox_loss: 0.0038  cls_loss: 0.0725  \n",
      "<<<iteration:[40/244] - total_loss: 0.1437  obj_loss: 0.0710  noobj_loss: 0.0357  bbox_loss: 0.0040  cls_loss: 0.0349  \n",
      "<<<iteration:[60/244] - total_loss: 0.1857  obj_loss: 0.0771  noobj_loss: 0.0430  bbox_loss: 0.0040  cls_loss: 0.0672  \n",
      "<<<iteration:[80/244] - total_loss: 0.1887  obj_loss: 0.0756  noobj_loss: 0.0387  bbox_loss: 0.0040  cls_loss: 0.0739  \n",
      "<<<iteration:[100/244] - total_loss: 0.1813  obj_loss: 0.0657  noobj_loss: 0.0427  bbox_loss: 0.0042  cls_loss: 0.0731  \n",
      "<<<iteration:[120/244] - total_loss: 0.1609  obj_loss: 0.0647  noobj_loss: 0.0428  bbox_loss: 0.0045  cls_loss: 0.0523  \n",
      "<<<iteration:[140/244] - total_loss: 0.1541  obj_loss: 0.0656  noobj_loss: 0.0382  bbox_loss: 0.0035  cls_loss: 0.0519  \n",
      "<<<iteration:[160/244] - total_loss: 0.1769  obj_loss: 0.0697  noobj_loss: 0.0382  bbox_loss: 0.0036  cls_loss: 0.0699  \n",
      "<<<iteration:[180/244] - total_loss: 0.1610  obj_loss: 0.0733  noobj_loss: 0.0387  bbox_loss: 0.0033  cls_loss: 0.0520  \n",
      "<<<iteration:[200/244] - total_loss: 0.1591  obj_loss: 0.0683  noobj_loss: 0.0395  bbox_loss: 0.0040  cls_loss: 0.0511  \n",
      "<<<iteration:[220/244] - total_loss: 0.1756  obj_loss: 0.0693  noobj_loss: 0.0368  bbox_loss: 0.0034  cls_loss: 0.0711  \n",
      "<<<iteration:[240/244] - total_loss: 0.2000  obj_loss: 0.0633  noobj_loss: 0.0413  bbox_loss: 0.0042  cls_loss: 0.0951  \n",
      "\n",
      "epoch:91/100 - Train Loss: 0.1738, Val Loss: 0.2073\n",
      "\n",
      "<<<iteration:[20/244] - total_loss: 0.1672  obj_loss: 0.0781  noobj_loss: 0.0420  bbox_loss: 0.0039  cls_loss: 0.0486  \n",
      "<<<iteration:[40/244] - total_loss: 0.1651  obj_loss: 0.0693  noobj_loss: 0.0390  bbox_loss: 0.0049  cls_loss: 0.0521  \n",
      "<<<iteration:[60/244] - total_loss: 0.1852  obj_loss: 0.0756  noobj_loss: 0.0379  bbox_loss: 0.0040  cls_loss: 0.0709  \n",
      "<<<iteration:[80/244] - total_loss: 0.1687  obj_loss: 0.0715  noobj_loss: 0.0393  bbox_loss: 0.0033  cls_loss: 0.0610  \n",
      "<<<iteration:[100/244] - total_loss: 0.1636  obj_loss: 0.0730  noobj_loss: 0.0362  bbox_loss: 0.0037  cls_loss: 0.0539  \n",
      "<<<iteration:[120/244] - total_loss: 0.1889  obj_loss: 0.0739  noobj_loss: 0.0449  bbox_loss: 0.0042  cls_loss: 0.0715  \n",
      "<<<iteration:[140/244] - total_loss: 0.1755  obj_loss: 0.0751  noobj_loss: 0.0391  bbox_loss: 0.0035  cls_loss: 0.0633  \n",
      "<<<iteration:[160/244] - total_loss: 0.1527  obj_loss: 0.0658  noobj_loss: 0.0374  bbox_loss: 0.0036  cls_loss: 0.0502  \n",
      "<<<iteration:[180/244] - total_loss: 0.1830  obj_loss: 0.0593  noobj_loss: 0.0393  bbox_loss: 0.0038  cls_loss: 0.0851  \n",
      "<<<iteration:[200/244] - total_loss: 0.1749  obj_loss: 0.0630  noobj_loss: 0.0407  bbox_loss: 0.0034  cls_loss: 0.0745  \n",
      "<<<iteration:[220/244] - total_loss: 0.1640  obj_loss: 0.0785  noobj_loss: 0.0364  bbox_loss: 0.0037  cls_loss: 0.0489  \n",
      "<<<iteration:[240/244] - total_loss: 0.1610  obj_loss: 0.0706  noobj_loss: 0.0381  bbox_loss: 0.0036  cls_loss: 0.0536  \n",
      "\n",
      "epoch:92/100 - Train Loss: 0.1697, Val Loss: 0.2018\n",
      "\n",
      "<<<iteration:[20/244] - total_loss: 0.1836  obj_loss: 0.0810  noobj_loss: 0.0401  bbox_loss: 0.0037  cls_loss: 0.0642  \n",
      "<<<iteration:[40/244] - total_loss: 0.1842  obj_loss: 0.0672  noobj_loss: 0.0374  bbox_loss: 0.0038  cls_loss: 0.0791  \n",
      "<<<iteration:[60/244] - total_loss: 0.1752  obj_loss: 0.0757  noobj_loss: 0.0407  bbox_loss: 0.0038  cls_loss: 0.0601  \n",
      "<<<iteration:[80/244] - total_loss: 0.1557  obj_loss: 0.0708  noobj_loss: 0.0382  bbox_loss: 0.0035  cls_loss: 0.0483  \n",
      "<<<iteration:[100/244] - total_loss: 0.2040  obj_loss: 0.0790  noobj_loss: 0.0424  bbox_loss: 0.0042  cls_loss: 0.0830  \n",
      "<<<iteration:[120/244] - total_loss: 0.1741  obj_loss: 0.0692  noobj_loss: 0.0367  bbox_loss: 0.0042  cls_loss: 0.0657  \n",
      "<<<iteration:[140/244] - total_loss: 0.1828  obj_loss: 0.0734  noobj_loss: 0.0382  bbox_loss: 0.0032  cls_loss: 0.0746  \n",
      "<<<iteration:[160/244] - total_loss: 0.1462  obj_loss: 0.0671  noobj_loss: 0.0378  bbox_loss: 0.0034  cls_loss: 0.0434  \n",
      "<<<iteration:[180/244] - total_loss: 0.1703  obj_loss: 0.0696  noobj_loss: 0.0390  bbox_loss: 0.0032  cls_loss: 0.0650  \n",
      "<<<iteration:[200/244] - total_loss: 0.1591  obj_loss: 0.0609  noobj_loss: 0.0369  bbox_loss: 0.0042  cls_loss: 0.0585  \n",
      "<<<iteration:[220/244] - total_loss: 0.1646  obj_loss: 0.0726  noobj_loss: 0.0364  bbox_loss: 0.0036  cls_loss: 0.0559  \n",
      "<<<iteration:[240/244] - total_loss: 0.1848  obj_loss: 0.0734  noobj_loss: 0.0446  bbox_loss: 0.0036  cls_loss: 0.0709  \n",
      "\n",
      "epoch:93/100 - Train Loss: 0.1726, Val Loss: 0.2004\n",
      "\n",
      "<<<iteration:[20/244] - total_loss: 0.1759  obj_loss: 0.0714  noobj_loss: 0.0404  bbox_loss: 0.0041  cls_loss: 0.0637  \n",
      "<<<iteration:[40/244] - total_loss: 0.2173  obj_loss: 0.0629  noobj_loss: 0.0370  bbox_loss: 0.0077  cls_loss: 0.0972  \n",
      "<<<iteration:[60/244] - total_loss: 0.2018  obj_loss: 0.0529  noobj_loss: 0.0360  bbox_loss: 0.0142  cls_loss: 0.0598  \n",
      "<<<iteration:[80/244] - total_loss: 0.1721  obj_loss: 0.0611  noobj_loss: 0.0337  bbox_loss: 0.0060  cls_loss: 0.0641  \n",
      "<<<iteration:[100/244] - total_loss: 0.1757  obj_loss: 0.0746  noobj_loss: 0.0354  bbox_loss: 0.0040  cls_loss: 0.0634  \n",
      "<<<iteration:[120/244] - total_loss: 0.1676  obj_loss: 0.0729  noobj_loss: 0.0365  bbox_loss: 0.0036  cls_loss: 0.0584  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<<<iteration:[140/244] - total_loss: 0.1614  obj_loss: 0.0683  noobj_loss: 0.0381  bbox_loss: 0.0038  cls_loss: 0.0550  \n",
      "<<<iteration:[160/244] - total_loss: 0.1697  obj_loss: 0.0710  noobj_loss: 0.0380  bbox_loss: 0.0042  cls_loss: 0.0589  \n",
      "<<<iteration:[180/244] - total_loss: 0.1789  obj_loss: 0.0722  noobj_loss: 0.0393  bbox_loss: 0.0043  cls_loss: 0.0654  \n",
      "<<<iteration:[200/244] - total_loss: 0.1435  obj_loss: 0.0729  noobj_loss: 0.0379  bbox_loss: 0.0038  cls_loss: 0.0324  \n",
      "<<<iteration:[220/244] - total_loss: 0.1911  obj_loss: 0.0799  noobj_loss: 0.0409  bbox_loss: 0.0039  cls_loss: 0.0714  \n",
      "<<<iteration:[240/244] - total_loss: 0.1933  obj_loss: 0.0710  noobj_loss: 0.0398  bbox_loss: 0.0041  cls_loss: 0.0821  \n",
      "\n",
      "epoch:94/100 - Train Loss: 0.1789, Val Loss: 0.2020\n",
      "\n",
      "<<<iteration:[20/244] - total_loss: 0.1868  obj_loss: 0.0703  noobj_loss: 0.0433  bbox_loss: 0.0046  cls_loss: 0.0721  \n",
      "<<<iteration:[40/244] - total_loss: 0.1774  obj_loss: 0.0731  noobj_loss: 0.0354  bbox_loss: 0.0034  cls_loss: 0.0697  \n",
      "<<<iteration:[60/244] - total_loss: 0.1859  obj_loss: 0.0751  noobj_loss: 0.0417  bbox_loss: 0.0034  cls_loss: 0.0731  \n",
      "<<<iteration:[80/244] - total_loss: 0.1730  obj_loss: 0.0705  noobj_loss: 0.0368  bbox_loss: 0.0042  cls_loss: 0.0633  \n",
      "<<<iteration:[100/244] - total_loss: 0.1668  obj_loss: 0.0694  noobj_loss: 0.0367  bbox_loss: 0.0041  cls_loss: 0.0587  \n",
      "<<<iteration:[120/244] - total_loss: 0.1723  obj_loss: 0.0721  noobj_loss: 0.0381  bbox_loss: 0.0036  cls_loss: 0.0634  \n",
      "<<<iteration:[140/244] - total_loss: 0.1873  obj_loss: 0.0699  noobj_loss: 0.0376  bbox_loss: 0.0037  cls_loss: 0.0800  \n",
      "<<<iteration:[160/244] - total_loss: 0.1761  obj_loss: 0.0722  noobj_loss: 0.0368  bbox_loss: 0.0040  cls_loss: 0.0653  \n",
      "<<<iteration:[180/244] - total_loss: 0.1686  obj_loss: 0.0752  noobj_loss: 0.0409  bbox_loss: 0.0037  cls_loss: 0.0546  \n",
      "<<<iteration:[200/244] - total_loss: 0.1775  obj_loss: 0.0660  noobj_loss: 0.0373  bbox_loss: 0.0041  cls_loss: 0.0724  \n",
      "<<<iteration:[220/244] - total_loss: 0.1562  obj_loss: 0.0659  noobj_loss: 0.0407  bbox_loss: 0.0036  cls_loss: 0.0522  \n",
      "<<<iteration:[240/244] - total_loss: 0.1678  obj_loss: 0.0692  noobj_loss: 0.0405  bbox_loss: 0.0039  cls_loss: 0.0587  \n",
      "\n",
      "epoch:95/100 - Train Loss: 0.1743, Val Loss: 0.2063\n",
      "\n",
      "<<<iteration:[20/244] - total_loss: 0.1784  obj_loss: 0.0703  noobj_loss: 0.0396  bbox_loss: 0.0041  cls_loss: 0.0676  \n",
      "<<<iteration:[40/244] - total_loss: 0.1398  obj_loss: 0.0658  noobj_loss: 0.0342  bbox_loss: 0.0040  cls_loss: 0.0368  \n",
      "<<<iteration:[60/244] - total_loss: 0.1883  obj_loss: 0.0641  noobj_loss: 0.0394  bbox_loss: 0.0041  cls_loss: 0.0840  \n",
      "<<<iteration:[80/244] - total_loss: 0.1966  obj_loss: 0.0786  noobj_loss: 0.0409  bbox_loss: 0.0038  cls_loss: 0.0783  \n",
      "<<<iteration:[100/244] - total_loss: 0.1619  obj_loss: 0.0698  noobj_loss: 0.0364  bbox_loss: 0.0041  cls_loss: 0.0536  \n",
      "<<<iteration:[120/244] - total_loss: 0.1557  obj_loss: 0.0654  noobj_loss: 0.0350  bbox_loss: 0.0035  cls_loss: 0.0552  \n",
      "<<<iteration:[140/244] - total_loss: 0.1727  obj_loss: 0.0760  noobj_loss: 0.0392  bbox_loss: 0.0036  cls_loss: 0.0591  \n",
      "<<<iteration:[160/244] - total_loss: 0.1530  obj_loss: 0.0619  noobj_loss: 0.0403  bbox_loss: 0.0050  cls_loss: 0.0459  \n",
      "<<<iteration:[180/244] - total_loss: 0.1767  obj_loss: 0.0726  noobj_loss: 0.0387  bbox_loss: 0.0040  cls_loss: 0.0647  \n",
      "<<<iteration:[200/244] - total_loss: 0.1462  obj_loss: 0.0674  noobj_loss: 0.0385  bbox_loss: 0.0039  cls_loss: 0.0400  \n",
      "<<<iteration:[220/244] - total_loss: 0.1717  obj_loss: 0.0747  noobj_loss: 0.0388  bbox_loss: 0.0038  cls_loss: 0.0587  \n",
      "<<<iteration:[240/244] - total_loss: 0.1655  obj_loss: 0.0648  noobj_loss: 0.0405  bbox_loss: 0.0038  cls_loss: 0.0614  \n",
      "\n",
      "epoch:96/100 - Train Loss: 0.1675, Val Loss: 0.2044\n",
      "\n",
      "<<<iteration:[20/244] - total_loss: 0.2093  obj_loss: 0.0722  noobj_loss: 0.0412  bbox_loss: 0.0038  cls_loss: 0.0977  \n",
      "<<<iteration:[40/244] - total_loss: 0.1740  obj_loss: 0.0702  noobj_loss: 0.0413  bbox_loss: 0.0039  cls_loss: 0.0638  \n",
      "<<<iteration:[60/244] - total_loss: 0.1886  obj_loss: 0.0754  noobj_loss: 0.0383  bbox_loss: 0.0038  cls_loss: 0.0753  \n",
      "<<<iteration:[80/244] - total_loss: 0.1795  obj_loss: 0.0693  noobj_loss: 0.0390  bbox_loss: 0.0035  cls_loss: 0.0729  \n",
      "<<<iteration:[100/244] - total_loss: 0.1332  obj_loss: 0.0651  noobj_loss: 0.0361  bbox_loss: 0.0036  cls_loss: 0.0321  \n",
      "<<<iteration:[120/244] - total_loss: 0.1775  obj_loss: 0.0767  noobj_loss: 0.0392  bbox_loss: 0.0041  cls_loss: 0.0605  \n",
      "<<<iteration:[140/244] - total_loss: 0.1711  obj_loss: 0.0749  noobj_loss: 0.0379  bbox_loss: 0.0035  cls_loss: 0.0599  \n",
      "<<<iteration:[160/244] - total_loss: 0.1603  obj_loss: 0.0762  noobj_loss: 0.0384  bbox_loss: 0.0037  cls_loss: 0.0463  \n",
      "<<<iteration:[180/244] - total_loss: 0.1878  obj_loss: 0.0815  noobj_loss: 0.0435  bbox_loss: 0.0042  cls_loss: 0.0635  \n",
      "<<<iteration:[200/244] - total_loss: 0.1886  obj_loss: 0.0699  noobj_loss: 0.0395  bbox_loss: 0.0039  cls_loss: 0.0795  \n",
      "<<<iteration:[220/244] - total_loss: 0.1677  obj_loss: 0.0744  noobj_loss: 0.0388  bbox_loss: 0.0040  cls_loss: 0.0538  \n",
      "<<<iteration:[240/244] - total_loss: 0.1679  obj_loss: 0.0795  noobj_loss: 0.0372  bbox_loss: 0.0033  cls_loss: 0.0535  \n",
      "\n",
      "epoch:97/100 - Train Loss: 0.1742, Val Loss: 0.2029\n",
      "\n",
      "<<<iteration:[20/244] - total_loss: 0.1995  obj_loss: 0.0743  noobj_loss: 0.0429  bbox_loss: 0.0035  cls_loss: 0.0863  \n",
      "<<<iteration:[40/244] - total_loss: 0.1768  obj_loss: 0.0773  noobj_loss: 0.0389  bbox_loss: 0.0033  cls_loss: 0.0635  \n",
      "<<<iteration:[60/244] - total_loss: 0.1928  obj_loss: 0.0714  noobj_loss: 0.0380  bbox_loss: 0.0038  cls_loss: 0.0835  \n",
      "<<<iteration:[80/244] - total_loss: 0.1505  obj_loss: 0.0622  noobj_loss: 0.0396  bbox_loss: 0.0035  cls_loss: 0.0510  \n",
      "<<<iteration:[100/244] - total_loss: 0.1604  obj_loss: 0.0753  noobj_loss: 0.0360  bbox_loss: 0.0037  cls_loss: 0.0487  \n",
      "<<<iteration:[120/244] - total_loss: 0.1843  obj_loss: 0.0765  noobj_loss: 0.0411  bbox_loss: 0.0039  cls_loss: 0.0676  \n",
      "<<<iteration:[140/244] - total_loss: 0.1593  obj_loss: 0.0715  noobj_loss: 0.0370  bbox_loss: 0.0033  cls_loss: 0.0527  \n",
      "<<<iteration:[160/244] - total_loss: 0.2170  obj_loss: 0.0687  noobj_loss: 0.0516  bbox_loss: 0.0065  cls_loss: 0.0901  \n",
      "<<<iteration:[180/244] - total_loss: 0.1784  obj_loss: 0.0736  noobj_loss: 0.0385  bbox_loss: 0.0038  cls_loss: 0.0666  \n",
      "<<<iteration:[200/244] - total_loss: 0.1739  obj_loss: 0.0701  noobj_loss: 0.0364  bbox_loss: 0.0037  cls_loss: 0.0672  \n",
      "<<<iteration:[220/244] - total_loss: 0.1436  obj_loss: 0.0685  noobj_loss: 0.0361  bbox_loss: 0.0035  cls_loss: 0.0394  \n",
      "<<<iteration:[240/244] - total_loss: 0.1691  obj_loss: 0.0628  noobj_loss: 0.0395  bbox_loss: 0.0042  cls_loss: 0.0656  \n",
      "\n",
      "epoch:98/100 - Train Loss: 0.1752, Val Loss: 0.2067\n",
      "\n",
      "<<<iteration:[20/244] - total_loss: 0.1874  obj_loss: 0.0740  noobj_loss: 0.0392  bbox_loss: 0.0042  cls_loss: 0.0729  \n",
      "<<<iteration:[40/244] - total_loss: 0.1625  obj_loss: 0.0656  noobj_loss: 0.0382  bbox_loss: 0.0039  cls_loss: 0.0585  \n",
      "<<<iteration:[60/244] - total_loss: 0.1762  obj_loss: 0.0725  noobj_loss: 0.0387  bbox_loss: 0.0036  cls_loss: 0.0666  \n",
      "<<<iteration:[80/244] - total_loss: 0.1726  obj_loss: 0.0764  noobj_loss: 0.0398  bbox_loss: 0.0036  cls_loss: 0.0584  \n",
      "<<<iteration:[100/244] - total_loss: 0.1744  obj_loss: 0.0733  noobj_loss: 0.0379  bbox_loss: 0.0037  cls_loss: 0.0636  \n",
      "<<<iteration:[120/244] - total_loss: 0.1505  obj_loss: 0.0714  noobj_loss: 0.0396  bbox_loss: 0.0037  cls_loss: 0.0410  \n",
      "<<<iteration:[140/244] - total_loss: 0.1964  obj_loss: 0.0749  noobj_loss: 0.0377  bbox_loss: 0.0032  cls_loss: 0.0867  \n",
      "<<<iteration:[160/244] - total_loss: 0.1625  obj_loss: 0.0682  noobj_loss: 0.0412  bbox_loss: 0.0040  cls_loss: 0.0535  \n",
      "<<<iteration:[180/244] - total_loss: 0.1659  obj_loss: 0.0681  noobj_loss: 0.0382  bbox_loss: 0.0038  cls_loss: 0.0595  \n",
      "<<<iteration:[200/244] - total_loss: 0.1839  obj_loss: 0.0787  noobj_loss: 0.0376  bbox_loss: 0.0035  cls_loss: 0.0688  \n",
      "<<<iteration:[220/244] - total_loss: 0.1624  obj_loss: 0.0695  noobj_loss: 0.0369  bbox_loss: 0.0036  cls_loss: 0.0566  \n",
      "<<<iteration:[240/244] - total_loss: 0.1686  obj_loss: 0.0679  noobj_loss: 0.0372  bbox_loss: 0.0034  cls_loss: 0.0650  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "epoch:99/100 - Train Loss: 0.1711, Val Loss: 0.2050\n",
      "\n",
      "<<<iteration:[20/244] - total_loss: 0.1695  obj_loss: 0.0782  noobj_loss: 0.0404  bbox_loss: 0.0034  cls_loss: 0.0540  \n",
      "<<<iteration:[40/244] - total_loss: 0.1784  obj_loss: 0.0801  noobj_loss: 0.0392  bbox_loss: 0.0034  cls_loss: 0.0620  \n",
      "<<<iteration:[60/244] - total_loss: 0.1675  obj_loss: 0.0751  noobj_loss: 0.0404  bbox_loss: 0.0039  cls_loss: 0.0529  \n",
      "<<<iteration:[80/244] - total_loss: 0.1961  obj_loss: 0.0648  noobj_loss: 0.0383  bbox_loss: 0.0042  cls_loss: 0.0912  \n",
      "<<<iteration:[100/244] - total_loss: 0.1475  obj_loss: 0.0696  noobj_loss: 0.0367  bbox_loss: 0.0039  cls_loss: 0.0401  \n",
      "<<<iteration:[120/244] - total_loss: 0.1644  obj_loss: 0.0729  noobj_loss: 0.0410  bbox_loss: 0.0036  cls_loss: 0.0528  \n",
      "<<<iteration:[140/244] - total_loss: 0.1678  obj_loss: 0.0696  noobj_loss: 0.0388  bbox_loss: 0.0036  cls_loss: 0.0607  \n",
      "<<<iteration:[160/244] - total_loss: 0.2026  obj_loss: 0.0721  noobj_loss: 0.0386  bbox_loss: 0.0036  cls_loss: 0.0933  \n",
      "<<<iteration:[180/244] - total_loss: 0.1761  obj_loss: 0.0676  noobj_loss: 0.0371  bbox_loss: 0.0034  cls_loss: 0.0728  \n",
      "<<<iteration:[200/244] - total_loss: 0.1522  obj_loss: 0.0610  noobj_loss: 0.0403  bbox_loss: 0.0034  cls_loss: 0.0542  \n",
      "<<<iteration:[220/244] - total_loss: 0.1696  obj_loss: 0.0717  noobj_loss: 0.0393  bbox_loss: 0.0033  cls_loss: 0.0618  \n",
      "<<<iteration:[240/244] - total_loss: 0.1584  obj_loss: 0.0728  noobj_loss: 0.0382  bbox_loss: 0.0035  cls_loss: 0.0491  \n",
      "\n",
      "epoch:100/100 - Train Loss: 0.1705, Val Loss: 0.2042\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d0b7c5e3fac545cb9bb911d5bb155422",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='0.003 MB of 0.003 MB uploaded (0.000 MB deduped)\\r'), FloatProgress(value=1.0, max…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>Train Loss</td><td>█▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>Train bbox Loss</td><td>█▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>Train class Loss</td><td>█▅▄▄▃▃▃▃▂▂▂▂▂▂▂▂▂▂▂▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>Train obj Loss</td><td>▁▁▄▄▅▆▆▆▇▇▇▇▇▇▇▇██▇▇█▇▇▇███▇█▇▇██▇███▇██</td></tr><tr><td>Val Loss</td><td>█▃▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>Val bbox Loss</td><td>█▃▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>Val class Loss</td><td>█▆▄▃▃▂▂▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>Val obj Loss</td><td>▁▄▇█▇▇▇▇██▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▆▆▇▆</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>Train Loss</td><td>0.17047</td></tr><tr><td>Train bbox Loss</td><td>0.00357</td></tr><tr><td>Train class Loss</td><td>0.06195</td></tr><tr><td>Train obj Loss</td><td>0.07121</td></tr><tr><td>Val Loss</td><td>0.20422</td></tr><tr><td>Val bbox Loss</td><td>0.00376</td></tr><tr><td>Val class Loss</td><td>0.10647</td></tr><tr><td>Val obj Loss</td><td>0.05867</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">drawn-hill-2</strong> at: <a href='https://wandb.ai/urp/yolo_swin_RADIO/runs/g53vekx1' target=\"_blank\">https://wandb.ai/urp/yolo_swin_RADIO/runs/g53vekx1</a><br/> View job at <a href='https://wandb.ai/urp/yolo_swin_RADIO/jobs/QXJ0aWZhY3RDb2xsZWN0aW9uOjExMjY2ODY2MQ==/version_details/v1' target=\"_blank\">https://wandb.ai/urp/yolo_swin_RADIO/jobs/QXJ0aWZhY3RDb2xsZWN0aW9uOjExMjY2ODY2MQ==/version_details/v1</a><br/>Synced 5 W&B file(s), 0 media file(s), 2 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20231104_154304-g53vekx1/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "best_epoch = 0\n",
    "best_score = float('inf')\n",
    "train_losses = []\n",
    "val_losses = []\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    train_loss, val_loss = train_one_epoch(dataloaders, model, criterion, optimizer, device)\n",
    "    train_losses.append(train_loss)\n",
    "    val_losses.append(val_loss)\n",
    "#     train_loss[\"obj_loss\"] += obj_loss\n",
    "#     train_loss[\"noobj_loss\"] += noobj_loss\n",
    "#     train_loss[\"bbox_loss\"] += bbox_loss\n",
    "#     train_loss[\"cls_loss\"] += cls_loss\n",
    "    wandb.log({\"Train Loss\": train_loss['total_loss'],\n",
    "               \"Train obj Loss\":train_loss[\"obj_loss\"],\n",
    "               \"Train bbox Loss\":train_loss[\"bbox_loss\"],\n",
    "               \"Train class Loss\":train_loss[\"cls_loss\"],\n",
    "               \"Val Loss\": val_loss['total_loss'],\n",
    "               \"Val obj Loss\":val_loss[\"obj_loss\"],\n",
    "               \"Val bbox Loss\":val_loss[\"bbox_loss\"],\n",
    "               \"Val class Loss\":val_loss[\"cls_loss\"],})\n",
    "    print(f\"\\nepoch:{epoch+1}/{num_epochs} - Train Loss: {train_loss['total_loss']:.4f}, Val Loss: {val_loss['total_loss']:.4f}\\n\")\n",
    "    \n",
    "    if (epoch+1) % 10 == 0:\n",
    "        save_model(model.state_dict(), f'model_{epoch+1}.pth', save_dir=f\"./trained_model/{BACKBONE}_{PART}_LR{LR}_IP{PATCH_FACTOR}_AUG{AUG_FACTOR}\")\n",
    "wandb.finish()"
   ]
  },
  {
   "cell_type": "raw",
   "id": "6bb02864",
   "metadata": {},
   "source": [
    "#debugging erros\n",
    "path=\"/home/host_data/PET_data_IP_AUG/aug_patched_Neck/valid/label/\"\n",
    "lab_list=os.listdir(path)\n",
    "cnt=0\n",
    "empty_list=[]\n",
    "for i in range(len(lab_list)):\n",
    "    if(lab_list[i]!='.ipynb_checkpoints'):\n",
    "        txt_f_name=lab_list[i]\n",
    "    else:continue\n",
    "    f=open(path+lab_list[i],'r')\n",
    "    data = f.read()\n",
    "    if(data==\"\"):\n",
    "        cnt=cnt+1\n",
    "        empty_list.append(txt_f_name)\n",
    "#     print(data)\n",
    "    f.close()\n",
    "print(cnt)\n",
    "print(empty_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4de7fe95",
   "metadata": {},
   "source": [
    "# Test Dataset Inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "b71f9334",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import os \n",
    "import pandas as pd\n",
    "import cv2\n",
    "import torch\n",
    "import matplotlib.pyplot as plt\n",
    "from ipywidgets import interact\n",
    "import albumentations as A\n",
    "from albumentations.pytorch import ToTensorV2\n",
    "import torchvision\n",
    "from torch import nn\n",
    "import torchsummary\n",
    "from torch.utils.data import DataLoader\n",
    "from collections import defaultdict\n",
    "from torchvision.utils import make_grid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "63f8dfc5",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "ad88eba4",
   "metadata": {},
   "outputs": [],
   "source": [
    "class YOLO_RESNET18(nn.Module):\n",
    "    def __init__(self, num_classes):\n",
    "        super().__init__()\n",
    "\n",
    "        self.num_classes = num_classes\n",
    "        self.num_bboxes = 2\n",
    "        self.grid_size = 7\n",
    "\n",
    "        resnet18 = torchvision.models.resnet18(pretrained = True)\n",
    "#         swin=torchvision.models.swin_v2_t(weights='IMAGENET1K_V1')\n",
    "        layers = [m for m in resnet18.children()] #Resnet에서 Yolo에서 가져올수 있을만한 layer만 선별적으로 가져오기 위해서\n",
    "\n",
    "        # 기존 Resnet18의 layer들중에서 맨 뒤에 두개만 제외하고 다 가져와서 Backbone으로 사용\n",
    "        self.backbone = nn.Sequential(*layers[:-2]) \n",
    "        self.head = nn.Sequential(\n",
    "                nn.Conv2d(in_channels=512, out_channels=1024, kernel_size=1, padding=0,bias=False),\n",
    "                nn.BatchNorm2d(1024),\n",
    "                nn.ReLU(inplace=True),\n",
    "                nn.Conv2d(in_channels=1024, out_channels=1024, kernel_size=3, padding=1,bias=False),\n",
    "                nn.BatchNorm2d(1024),\n",
    "                nn.ReLU(inplace=True),\n",
    "                nn.Conv2d(in_channels=1024, out_channels=1024, kernel_size=3, padding=1,bias=False),\n",
    "                nn.BatchNorm2d(1024),\n",
    "                nn.ReLU(inplace=True),\n",
    "                nn.Conv2d(in_channels=1024, out_channels=1024, kernel_size=3, padding=1,bias=False),\n",
    "                nn.BatchNorm2d(1024),\n",
    "                nn.ReLU(inplace=True),\n",
    "\n",
    "                nn.Conv2d(in_channels=1024, out_channels=(4+1)*self.num_bboxes+num_classes, kernel_size=1, padding=0, bias=False),\n",
    "                nn.AdaptiveAvgPool2d(output_size=(self.grid_size, self.grid_size))\n",
    "            )\n",
    "\n",
    "    def forward(self, x):\n",
    "        out = self.backbone(x)\n",
    "        # out = self.neck(out)\n",
    "        out = self.head(out) # input (batch, 3, 448, 448) -> output feature (batch, 12, 7, 7)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "64dd5b10",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_model(ckpt_path, num_classes, device):\n",
    "    checkpoint = torch.load(ckpt_path, map_location=device)\n",
    "    model = YOLO_SWIN(num_classes=num_classes)\n",
    "#     model=YOLO_RESNET18(num_classes=num_classes)\n",
    "    model.load_state_dict(checkpoint)\n",
    "    model = model.to(device)\n",
    "    model.eval()\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "4d80869e",
   "metadata": {},
   "outputs": [],
   "source": [
    "IMAGE_SIZE=448\n",
    "transformer = A.Compose([\n",
    "            A.Resize(height=IMAGE_SIZE, width=IMAGE_SIZE),\n",
    "            A.Normalize(mean=(0.485, 0.456, 0.406),std=(0.229, 0.224, 0.225)),\n",
    "            ToTensorV2(),\n",
    "        ],\n",
    "        bbox_params=A.BboxParams(format='yolo', label_fields=['class_ids']),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "76bcd114",
   "metadata": {},
   "outputs": [],
   "source": [
    "NUM_CLASSES=2\n",
    "# ckpt_path=\"./trained_model/YOLO_SWIN_T_body_LR0.0001_AUG30/model_90.pth\"\n",
    "ckpt_path=\"/workspace/Plastic_Bottle_defect_detection/experiments/trained_model/YOLO_SWIN_T_neck_LR0.0001_IP50_AUG4_radio_pretrained/model_100.pth\"\n",
    "model = load_model(ckpt_path, NUM_CLASSES, device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "0d42c594",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'PET_dataset' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[16], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m NECK_PATH \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m/home/host_data/PET_data/Neck\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m      2\u001b[0m BODY_PATH \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m/home/host_data/PET_data/Body\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[0;32m----> 3\u001b[0m test_dataset\u001b[38;5;241m=\u001b[39m\u001b[43mPET_dataset\u001b[49m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mneck\u001b[39m\u001b[38;5;124m\"\u001b[39m ,neck_dir\u001b[38;5;241m=\u001b[39mNECK_PATH,body_dir\u001b[38;5;241m=\u001b[39mBODY_PATH,phase\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtest\u001b[39m\u001b[38;5;124m'\u001b[39m, transformer\u001b[38;5;241m=\u001b[39mtransformer, aug\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m)\n\u001b[1;32m      4\u001b[0m test_dataloaders \u001b[38;5;241m=\u001b[39m DataLoader(test_dataset, batch_size\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m, shuffle\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m, collate_fn\u001b[38;5;241m=\u001b[39mcollate_fn)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'PET_dataset' is not defined"
     ]
    }
   ],
   "source": [
    "NECK_PATH = '/home/host_data/PET_data/Neck'\n",
    "BODY_PATH = '/home/host_data/PET_data/Body'\n",
    "test_dataset=PET_dataset(\"neck\" ,neck_dir=NECK_PATH,body_dir=BODY_PATH,phase='test', transformer=transformer, aug=None)\n",
    "test_dataloaders = DataLoader(test_dataset, batch_size=1, shuffle=False, collate_fn=collate_fn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "07fed11f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "25"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(test_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "3709c974",
   "metadata": {},
   "outputs": [],
   "source": [
    "@torch.no_grad()\n",
    "def model_predict(image, model, conf_thres=0.2, iou_threshold=0.1):\n",
    "    predictions = model(image)\n",
    "    prediction = predictions.detach().cpu().squeeze(dim=0)\n",
    "    f_map=prediction\n",
    "\n",
    "#     print(prediction.shape)\n",
    "    \n",
    "    grid_size = prediction.shape[-1]\n",
    "    y_grid, x_grid = torch.meshgrid(torch.arange(grid_size), torch.arange(grid_size))\n",
    "    stride_size = IMAGE_SIZE/grid_size\n",
    "\n",
    "    conf = prediction[[0,5], ...].reshape(1, -1)\n",
    "    xc = (prediction[[1,6], ...] * IMAGE_SIZE + x_grid*stride_size).reshape(1,-1)\n",
    "    yc = (prediction[[2,7], ...] * IMAGE_SIZE + y_grid*stride_size).reshape(1,-1)\n",
    "    w = (prediction[[3,8], ...] * IMAGE_SIZE).reshape(1,-1)\n",
    "    h = (prediction[[4,9], ...] * IMAGE_SIZE).reshape(1,-1)\n",
    "    cls = torch.max(prediction[10:, ...].reshape(NUM_CLASSES, -1), dim=0).indices.tile(1,2)\n",
    "    \n",
    "    x_min = xc - w/2\n",
    "    y_min = yc - h/2\n",
    "    x_max = xc + w/2\n",
    "    y_max = yc + h/2\n",
    "\n",
    "    prediction_res = torch.cat([x_min, y_min, x_max, y_max, conf, cls], dim=0)\n",
    "    prediction_res = prediction_res.transpose(0,1)\n",
    "\n",
    "    # x_min과 y_min이 음수가 되지않고, x_max와 y_max가 이미지 크기를 넘지 않게 제한\n",
    "    prediction_res[:, 2].clip(min=0, max=image.shape[1]) \n",
    "    prediction_res[:, 3].clip(min=0, max=image.shape[0])\n",
    "        \n",
    "    pred_res = prediction_res[prediction_res[:, 4] > conf_thres]\n",
    "    nms_index = torchvision.ops.nms(boxes=pred_res[:, 0:4], scores=pred_res[:, 4], iou_threshold=iou_threshold)\n",
    "    pred_res_ = pred_res[nms_index].numpy()\n",
    "    \n",
    "    n_obj = pred_res_.shape[0]\n",
    "    bboxes = np.zeros(shape=(n_obj, 4), dtype=np.float32)\n",
    "    bboxes[:, 0:2] = (pred_res_[:, 0:2] + pred_res_[:, 2:4]) / 2\n",
    "    bboxes[:, 2:4] = pred_res_[:, 2:4] - pred_res_[:, 0:2]\n",
    "    scores = pred_res_[:, 4]\n",
    "    class_ids = pred_res_[:, 5]\n",
    "    \n",
    "    # 이미지 값이 들어가면 모델을 통해서, 후처리까지 포함된 yolo 포멧의 box좌표, 그 좌표에 대한 confidence score\n",
    "    # 그리고 class id를 반환\n",
    "    return bboxes, scores, class_ids,f_map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "10dddcd9",
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_images = []\n",
    "pred_labels =[]\n",
    "feature_maps=[]\n",
    "\n",
    "for index, batch in enumerate(test_dataloaders):\n",
    "    images = batch[0].to(device)\n",
    "    bboxes, scores, class_ids, fmap = model_predict(images, model, conf_thres=0.1, iou_threshold=0.1)\n",
    "    \n",
    "    if len(bboxes) > 0:\n",
    "        prediction_yolo = np.concatenate([bboxes, scores[:, np.newaxis], class_ids[:, np.newaxis]], axis=1)\n",
    "    else:\n",
    "        prediction_yolo = np.array([])\n",
    "    \n",
    "    # 텐서형의 이미지를 다시 unnormalize를 시키고, 다시 chw를 hwc로 바꾸고 넘파이로 바꾼다.\n",
    "    np_image = make_grid(images[0], normalize=True).cpu().permute(1,2,0).numpy()\n",
    "    pred_images.append(np_image)\n",
    "    pred_labels.append(prediction_yolo)\n",
    "    feature_maps.append(fmap)\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "b07fa545",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d01d1eb96aa64ef3bc38fcdd6d592506",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "interactive(children=(IntSlider(value=0, description='index', max=24), Output()), _dom_classes=('widget-intera…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from ipywidgets import interact\n",
    "\n",
    "@interact(index=(0,len(pred_images)-1))\n",
    "def show_result(index=0):\n",
    "    print(pred_labels[index])\n",
    "    if len(pred_labels[index]) > 0:\n",
    "        result = visualize(pred_images[index], pred_labels[index][:, 0:4], pred_labels[index][:, 5])\n",
    "    else:\n",
    "        result = pred_images[index]\n",
    "        \n",
    "    plt.figure(figsize=(6,6))\n",
    "    plt.imshow(result)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "24c0544e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b41df6c32f1d4a3ebdaa5691d017a43e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "interactive(children=(IntSlider(value=0, description='index', max=24), Output()), _dom_classes=('widget-intera…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#feature map에서 0,5번쨰에 해당하는 objectness 투사\n",
    "from ipywidgets import interact\n",
    "\n",
    "@interact(index=(0,len(pred_images)-1))\n",
    "def show_result(index=0):\n",
    "    print(pred_labels[index])\n",
    "    if len(pred_labels[index]) > 0:\n",
    "        result = visualize(pred_images[index], pred_labels[index][:, 0:4], pred_labels[index][:, 5])\n",
    "    else:\n",
    "        result = pred_images[index]\n",
    "    \n",
    "    f_map=feature_maps[index]\n",
    "    zero_canvas=np.zeros((448,448))\n",
    "\n",
    "    cv_re1=cv2.resize(f_map[0,:,:].numpy(),(448,448))\n",
    "    cv_re2=cv2.resize(f_map[5,:,:].numpy(),(448,448))\n",
    "    zero_canvas=zero_canvas+cv_re1+cv_re2\n",
    "\n",
    "    \n",
    "    fig = plt.figure()\n",
    "    rows = 1\n",
    "    cols = 2\n",
    "    ax1 = fig.add_subplot(rows, cols, 1)\n",
    "    ax1.imshow(result)\n",
    "    ax1.set_title('Detection')\n",
    "    ax1.axis(\"off\")\n",
    "    \n",
    "    ax2 = fig.add_subplot(rows, cols, 2)\n",
    "    ax2.imshow(zero_canvas)\n",
    "    ax2.set_title('feature map-objectness')\n",
    "    ax2.axis(\"off\")\n",
    "\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99e7d4d8",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
