{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3c025da0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import os \n",
    "import pandas as pd\n",
    "import cv2\n",
    "import torch\n",
    "import matplotlib.pyplot as plt\n",
    "from ipywidgets import interact\n",
    "import albumentations as A\n",
    "from albumentations.pytorch import ToTensorV2\n",
    "import torchvision\n",
    "from torch import nn\n",
    "import torchsummary\n",
    "from torch.utils.data import DataLoader\n",
    "from collections import defaultdict\n",
    "from torchvision.utils import make_grid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5d503acd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cuda', index=0)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "device"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ee9eb3c",
   "metadata": {},
   "source": [
    "# Utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c7fac7d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "CLASS_NAME_TO_ID = {'BS': 0, 'SCRATCH': 1}\n",
    "CLASS_ID_TO_NAME = {0: 'BS', 1: 'SCRATCH'}\n",
    "BOX_COLOR = {'BS':(200, 0, 0), 'SCRATCH':(0, 0, 200)}\n",
    "TEXT_COLOR = (255, 255, 255)\n",
    "\n",
    "def save_model(model_state, model_name, save_dir=\"./trained_model\"):\n",
    "    os.makedirs(save_dir, exist_ok=True)\n",
    "    torch.save(model_state, os.path.join(save_dir, model_name))\n",
    "\n",
    "\n",
    "def visualize_bbox(image, bbox, class_name, color=BOX_COLOR, thickness=2):\n",
    "    x_center, y_center, w, h = bbox\n",
    "    x_min = int(x_center - w/2)\n",
    "    y_min = int(y_center - h/2)\n",
    "    x_max = int(x_center + w/2)\n",
    "    y_max = int(y_center + h/2)\n",
    "    \n",
    "    cv2.rectangle(image, (x_min, y_min), (x_max, y_max), color=color[class_name], thickness=thickness)\n",
    "    \n",
    "    ((text_width, text_height), _) = cv2.getTextSize(class_name, cv2.FONT_HERSHEY_SIMPLEX, 0.35, 1)    \n",
    "    cv2.rectangle(image, (x_min, y_min - int(1.3 * text_height)), (x_min + text_width, y_min), color[class_name], -1)\n",
    "    cv2.putText(\n",
    "        image,\n",
    "        text=class_name,\n",
    "        org=(x_min, y_min - int(0.3 * text_height)),\n",
    "        fontFace=cv2.FONT_HERSHEY_SIMPLEX,\n",
    "        fontScale=0.35, \n",
    "        color=TEXT_COLOR, \n",
    "        lineType=cv2.LINE_AA,\n",
    "    )\n",
    "    return image\n",
    "\n",
    "\n",
    "def visualize(image, bboxes, category_ids):\n",
    "    img = image.copy()\n",
    "    for bbox, category_id in zip(bboxes, category_ids):\n",
    "#         print('category_id: ',category_id)\n",
    "        class_name = CLASS_ID_TO_NAME[category_id.item()]\n",
    "        img = visualize_bbox(img, bbox, class_name)\n",
    "    return img"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62c7da98",
   "metadata": {},
   "source": [
    "# Datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ea0166e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "class PET_dataset():\n",
    "    def __init__(self,part,neck_dir,body_dir,phase, transformer=None):\n",
    "        self.neck_dir=neck_dir\n",
    "        self.body_dir=body_dir\n",
    "        self.part=part\n",
    "        self.phase=phase\n",
    "        self.transformer=transformer\n",
    "        if(self.part==\"body\"):\n",
    "            self.image_files = sorted([fn for fn in os.listdir(self.body_dir+\"/\"+self.phase+\"/image\") if fn.endswith(\"jpg\")])\n",
    "            self.label_files= sorted([lab for lab in os.listdir(self.body_dir+\"/\"+self.phase+\"/label\") if lab.endswith(\"txt\")])\n",
    "        elif(self.part==\"neck\"):\n",
    "            self.image_files = sorted([fn for fn in os.listdir(self.neck_dir+\"/\"+self.phase+\"/image\") if fn.endswith(\"jpg\")])\n",
    "            self.label_files= sorted([lab for lab in os.listdir(self.neck_dir+\"/\"+self.phase+\"/label\") if lab.endswith(\"txt\")])\n",
    "            \n",
    "        \n",
    "    def __getitem__(self,index):\n",
    "        filename, image = self.get_image(self.part, index)\n",
    "        bboxes, class_ids = self.get_label(self.part, index)\n",
    "        \n",
    "        if(self.transformer):\n",
    "            transformed_data=self.transformer(image=image, bboxes=bboxes, class_ids=class_ids)\n",
    "            image = transformed_data['image']\n",
    "            bboxes = np.array(transformed_data['bboxes'])\n",
    "            class_ids = np.array(transformed_data['class_ids'])\n",
    "            \n",
    "        \n",
    "        target = {}\n",
    "#         print(f'bboxes:{bboxes}\\nclass_ids:{class_ids}\\nlen_bboxes:{len(bboxes)}\\nlen_class_ids:{len(class_ids)}')\n",
    "#         print(f'filename: {filename}')\n",
    "        target[\"boxes\"] = torch.Tensor(bboxes).float()\n",
    "        target[\"labels\"] = torch.Tensor(class_ids).long()\n",
    "        \n",
    "        ###\n",
    "        bboxes=torch.Tensor(bboxes).float()\n",
    "        class_ids=torch.Tensor(class_ids).long()\n",
    "        target = np.concatenate((bboxes, class_ids[:, np.newaxis]), axis=1)\n",
    "        ###\n",
    "        return image, target, filename\n",
    "    \n",
    "    def __len__(self, ):\n",
    "        return len(self.image_files)\n",
    "    \n",
    "    def get_image(self, part, index): # 이미지 불러오는 함수\n",
    "        filename = self.image_files[index]\n",
    "        if(part==\"body\"):\n",
    "#             print(f\"body called!-> {self.part}\")\n",
    "            image_path = self.body_dir+\"/\"+self.phase+\"/image/\"+filename\n",
    "        elif(part==\"neck\"):\n",
    "#             print(f\"neck called!-> {self.part}\")\n",
    "            image_path = self.neck_dir+\"/\"+self.phase+\"/image/\"+filename\n",
    "        image = cv2.imread(image_path)\n",
    "        image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "        return filename, image\n",
    "    \n",
    "    def get_label(self, part, index): # label (box좌표, class_id) 불러오는 함수\n",
    "        label_filename=self.label_files[index]\n",
    "        if(part==\"body\"):\n",
    "#             print(f\"body label called!-> {self.part}\")\n",
    "            label_path = self.body_dir+\"/\"+self.phase+\"/label/\"+label_filename\n",
    "        elif(part==\"neck\"):\n",
    "#             print(f\"neck label called!-> {self.part}\")\n",
    "            label_path = self.neck_dir+\"/\"+self.phase+\"/label/\"+label_filename\n",
    "        with open(label_path, 'r') as file:\n",
    "            labels = file.readlines()\n",
    "        \n",
    "        class_ids=[]\n",
    "        bboxes=[]\n",
    "        for label in labels:\n",
    "            label=label.replace(\"\\n\", \"\")\n",
    "            obj=label.split(' ')[0]\n",
    "            coor=label.split(' ')[1:]\n",
    "            obj=int(obj)\n",
    "            coor=list(map(float, coor))\n",
    "            class_ids.append(obj)\n",
    "            bboxes.append(coor)\n",
    "            \n",
    "        return bboxes, class_ids\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "235e7cec",
   "metadata": {},
   "outputs": [],
   "source": [
    "IMAGE_SIZE = 448\n",
    "\n",
    "transformer = A.Compose([ \n",
    "        # bounding box의 변환, augmentation에서 albumentations는 Detection 학습을 할 때 굉장히 유용하다. \n",
    "        A.Resize(height=IMAGE_SIZE, width=IMAGE_SIZE),\n",
    "        A.Normalize(mean=(0.485, 0.456, 0.406),std=(0.229, 0.224, 0.225)),\n",
    "        ToTensorV2(),\n",
    "        # albumentations 라이브러리에서는 Normalization을 먼저 진행해 주고 tensor화를 진행해 주어야한다.\n",
    "    ],\n",
    "    # box 위치에 대한 transformation도 함께 진행된다. \n",
    "    bbox_params=A.BboxParams(format='yolo', label_fields=['class_ids']),\n",
    ")\n",
    "\n",
    "def collate_fn(batch):\n",
    "    image_list = []\n",
    "    target_list = []\n",
    "    filename_list = []\n",
    "    \n",
    "    for a,b,c in batch:\n",
    "        image_list.append(a)\n",
    "        target_list.append(b)\n",
    "        filename_list.append(c)\n",
    "\n",
    "    return torch.stack(image_list, dim=0), target_list, filename_list\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "0b245cf4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_dataloader(part, NECK_PATH, BODY_PATH, batch_size=2):\n",
    "    transformer = A.Compose([\n",
    "            A.Resize(height=IMAGE_SIZE, width=IMAGE_SIZE),\n",
    "            A.Normalize(mean=(0.485, 0.456, 0.406),std=(0.229, 0.224, 0.225)),\n",
    "            ToTensorV2(),\n",
    "        ],\n",
    "        bbox_params=A.BboxParams(format='yolo', label_fields=['class_ids']),\n",
    "    )\n",
    "    \n",
    "    dataloaders = {}\n",
    "#     train_dataset = Detection_dataset(data_dir=data_dir, phase=\"train\", transformer=transformer)\n",
    "    train_dataset=PET_dataset(part ,neck_dir=NECK_PATH,body_dir=BODY_PATH,phase='train', transformer=transformer)\n",
    "    dataloaders[\"train\"] = DataLoader(train_dataset, batch_size=batch_size, shuffle=True, collate_fn=collate_fn)\n",
    "\n",
    "#     val_dataset = Detection_dataset(data_dir=data_dir, phase=\"val\", transformer=transformer)\n",
    "    val_dataset=PET_dataset(part ,neck_dir=NECK_PATH,body_dir=BODY_PATH,phase='valid', transformer=transformer)\n",
    "    dataloaders[\"val\"] = DataLoader(val_dataset, batch_size=1, shuffle=False, collate_fn=collate_fn)\n",
    "    return dataloaders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a6d5c32a",
   "metadata": {},
   "outputs": [],
   "source": [
    "NECK_PATH = '/home/host_data/PET_data/Neck'\n",
    "BODY_PATH = '/home/host_data/PET_data/Body'\n",
    "trainset=PET_dataset(part='body',neck_dir=NECK_PATH,body_dir=BODY_PATH,phase='train', transformer=transformer)\n",
    "trainset_no_trans=PET_dataset(part='body',neck_dir=NECK_PATH,body_dir=BODY_PATH,phase='train', transformer=None)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d4849831",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "image.shape:torch.Size([3, 448, 448])\n",
      "target:[[0.58172178 0.55863488 0.06113537 0.04489235 1.        ]\n",
      " [0.92389268 0.30393952 0.01996257 0.01603298 0.        ]\n",
      " [0.80255771 0.09001374 0.01996257 0.01786532 0.        ]\n",
      " [0.0246413  0.60444343 0.02557704 0.09253321 1.        ]\n",
      " [0.74422956 0.08131012 0.0205864  0.01603298 0.        ]\n",
      " [0.20586401 0.51007789 0.02495321 0.05863491 1.        ]\n",
      " [0.22181535 0.16869904 0.12494074 0.03748969 1.        ]]\n"
     ]
    }
   ],
   "source": [
    "# target 모양을 (x_cen, y_cen, w, h ,class_id)로 변경\n",
    "image, target, filename = trainset[0]\n",
    "print(f\"image.shape:{image.shape}\")\n",
    "\n",
    "print(f\"target:{target}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "85b8a100",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "image.shape:(2183, 1603, 3)\n",
      "target:[[0.58172178 0.55863488 0.06113537 0.04489235 1.        ]\n",
      " [0.92389268 0.30393952 0.01996257 0.01603298 0.        ]\n",
      " [0.80255771 0.09001374 0.01996257 0.01786532 0.        ]\n",
      " [0.0246413  0.60444343 0.02557704 0.09253321 1.        ]\n",
      " [0.74422956 0.08131012 0.0205864  0.01603298 0.        ]\n",
      " [0.20586401 0.51007789 0.02495321 0.05863491 1.        ]\n",
      " [0.22181535 0.16869904 0.12494074 0.03748969 1.        ]]\n"
     ]
    }
   ],
   "source": [
    "image, target, filename = trainset_no_trans[0]\n",
    "print(f\"image.shape:{image.shape}\")\n",
    "# print(f\"image.type:{image.type}\") #numpy\n",
    "\n",
    "print(f\"target:{target}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "c0fbcd25",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "117"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(trainset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "5db4ebba",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ddfb3f28990d456491693371806a6e5e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "interactive(children=(IntSlider(value=0, description='index', max=116), Output()), _dom_classes=('widget-inter…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "@interact(index=(0, len(trainset_no_trans)-1))\n",
    "\n",
    "def show_sample(index=0):\n",
    "    image, target, filename = trainset_no_trans[index]\n",
    "#     image=image.permute(1,2,0).numpy()\n",
    "    img_H, img_W, _ = image.shape\n",
    "    print(image.shape)\n",
    "\n",
    "#     bboxes = target['boxes']\n",
    "#     class_ids = target[\"labels\"]\n",
    "    \n",
    "    ###\n",
    "    bboxes = target[:, 0:4]\n",
    "    class_ids = target[:, 4]\n",
    "    ###\n",
    "    bboxes[:, [0,2]] *= img_W\n",
    "    bboxes[:, [1,3]] *= img_H\n",
    "\n",
    "    canvas = visualize(image, bboxes, class_ids)\n",
    "    plt.figure(figsize=(6,6))\n",
    "    plt.imshow(canvas)\n",
    "    plt.axis('off')\n",
    "    plt.show()\n",
    "\n",
    "# show_sample()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "5e341d7c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a7bb9e9353a64a3dabc05b4f4f3fce6a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "interactive(children=(IntSlider(value=0, description='index', max=116), Output()), _dom_classes=('widget-inter…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "@interact(index=(0, len(trainset)-1))\n",
    "\n",
    "def show_sample(index=0):\n",
    "    image, target, filename = trainset[index]\n",
    "    image=image.permute(1,2,0).numpy()\n",
    "    img_H, img_W, _ = image.shape\n",
    "    print(image.shape)\n",
    "\n",
    "#     bboxes = target['boxes']\n",
    "#     class_ids = target[\"labels\"]\n",
    "    ###\n",
    "    bboxes = target[:, 0:4]\n",
    "    class_ids = target[:, 4]\n",
    "    ###\n",
    "    bboxes[:, [0,2]] *= img_W\n",
    "    bboxes[:, [1,3]] *= img_H\n",
    "\n",
    "    canvas = visualize(image, bboxes, class_ids)\n",
    "    plt.figure(figsize=(6,6))\n",
    "    plt.imshow(canvas)\n",
    "    plt.axis('off')\n",
    "    plt.show()\n",
    "\n",
    "# show_sample()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f151003",
   "metadata": {},
   "source": [
    "## Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "729f2964",
   "metadata": {},
   "outputs": [],
   "source": [
    "class YOLO_RESNET(nn.Module):\n",
    "    def __init__(self, num_classes):\n",
    "        super().__init__()\n",
    "\n",
    "        self.num_classes = num_classes\n",
    "        self.num_bboxes = 2\n",
    "        self.grid_size = 7\n",
    "\n",
    "        resnet18 = torchvision.models.resnet18(pretrained = True)\n",
    "        layers = [m for m in resnet18.children()] #Resnet에서 Yolo에서 가져올수 있을만한 layer만 선별적으로 가져오기 위해서\n",
    "\n",
    "        # 기존 Resnet18의 layer들중에서 맨 뒤에 두개만 제외하고 다 가져와서 Backbone으로 사용\n",
    "        self.backbone = nn.Sequential(*layers[:-2]) \n",
    "\n",
    "        # self.neck = nn.Sequential(\n",
    "        #     nn.Conv2d(in_channels=512, out_channels=1024, kernel_size=1, padding=0, bias=False), #Channel의 수만 변경\n",
    "        #     nn.BatchNorm2d(1024),\n",
    "        #     nn.ReLU(inplace=True),\n",
    "        #     nn.Conv2d(in_channels=1024, out_channels=1024, kernel_size=3, padding=1,bias=False), #spatial 손실이 없게끔 padding 설정\n",
    "        #     nn.BatchNorm2d(1024),\n",
    "        #     nn.ReLU(inplace=True),\n",
    "        #     nn.Conv2d(in_channels=1024, out_channels=1024, kernel_size=3, padding=1,bias=False),\n",
    "        #     nn.BatchNorm2d(1024),\n",
    "        #     nn.ReLU(inplace=True),\n",
    "        #     nn.Conv2d(in_channels=1024, out_channels=1024, kernel_size=3, padding=1,bias=False),\n",
    "        #     nn.BatchNorm2d(1024),\n",
    "        #     nn.ReLU(inplace=True)\n",
    "        #     # 여기 위에를 통과하는 동안에는 feature에 대한 정보만 바뀌고, resolution에 대한 정보는 바뀌지x\n",
    "        # )\n",
    "\n",
    "        # neck을 통과해서 feature map을 가져오고, head 부분에서 output depth와 grid size를 조절해서 뱉게해준다.\n",
    "\n",
    "        # self.head = nn.Sequential(\n",
    "        #     nn.Conv2d(in_channels=1024, out_channels=(4+1)*self.num_bboxes+num_classes, kernel_size=1, padding=0, bias=False),\n",
    "        #     nn.AdaptiveAvgPool2d(output_size=(self.grid_size, self.grid_size))\n",
    "        # )\n",
    "        self.head = nn.Sequential(\n",
    "                nn.Conv2d(in_channels=512, out_channels=1024, kernel_size=1, padding=0,bias=False),\n",
    "                nn.BatchNorm2d(1024),\n",
    "                nn.ReLU(inplace=True),\n",
    "                nn.Conv2d(in_channels=1024, out_channels=1024, kernel_size=3, padding=1,bias=False),\n",
    "                nn.BatchNorm2d(1024),\n",
    "                nn.ReLU(inplace=True),\n",
    "                nn.Conv2d(in_channels=1024, out_channels=1024, kernel_size=3, padding=1,bias=False),\n",
    "                nn.BatchNorm2d(1024),\n",
    "                nn.ReLU(inplace=True),\n",
    "                nn.Conv2d(in_channels=1024, out_channels=1024, kernel_size=3, padding=1,bias=False),\n",
    "                nn.BatchNorm2d(1024),\n",
    "                nn.ReLU(inplace=True),\n",
    "\n",
    "                nn.Conv2d(in_channels=1024, out_channels=(4+1)*self.num_bboxes+num_classes, kernel_size=1, padding=0, bias=False),\n",
    "                nn.AdaptiveAvgPool2d(output_size=(self.grid_size, self.grid_size))\n",
    "            )\n",
    "\n",
    "    def forward(self, x):\n",
    "        out = self.backbone(x)\n",
    "        # out = self.neck(out)\n",
    "        out = self.head(out) # input (batch, 3, 448, 448) -> output feature (batch, 12, 7, 7)\n",
    "        return out\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "b0a6eb83",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.8/dist-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.8/dist-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ResNet18_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet18_Weights.DEFAULT` to get the most up-to-date weights.\n",
      "  warnings.warn(msg)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "YOLO_RESNET(\n",
       "  (backbone): Sequential(\n",
       "    (0): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
       "    (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU(inplace=True)\n",
       "    (3): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
       "    (4): Sequential(\n",
       "      (0): BasicBlock(\n",
       "        (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (1): BasicBlock(\n",
       "        (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (5): Sequential(\n",
       "      (0): BasicBlock(\n",
       "        (conv1): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (downsample): Sequential(\n",
       "          (0): Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "          (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "      )\n",
       "      (1): BasicBlock(\n",
       "        (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (6): Sequential(\n",
       "      (0): BasicBlock(\n",
       "        (conv1): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (downsample): Sequential(\n",
       "          (0): Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "          (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "      )\n",
       "      (1): BasicBlock(\n",
       "        (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (7): Sequential(\n",
       "      (0): BasicBlock(\n",
       "        (conv1): Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (downsample): Sequential(\n",
       "          (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "          (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "      )\n",
       "      (1): BasicBlock(\n",
       "        (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (head): Sequential(\n",
       "    (0): Conv2d(512, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "    (1): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU(inplace=True)\n",
       "    (3): Conv2d(1024, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "    (4): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (5): ReLU(inplace=True)\n",
       "    (6): Conv2d(1024, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "    (7): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (8): ReLU(inplace=True)\n",
       "    (9): Conv2d(1024, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "    (10): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (11): ReLU(inplace=True)\n",
       "    (12): Conv2d(1024, 12, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "    (13): AdaptiveAvgPool2d(output_size=(7, 7))\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "NUM_CLASSES = 2\n",
    "model = YOLO_RESNET(num_classes=NUM_CLASSES)\n",
    "model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "361cde55",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------------------------------\n",
      "        Layer (type)               Output Shape         Param #\n",
      "================================================================\n",
      "            Conv2d-1         [-1, 64, 224, 224]           9,408\n",
      "       BatchNorm2d-2         [-1, 64, 224, 224]             128\n",
      "              ReLU-3         [-1, 64, 224, 224]               0\n",
      "         MaxPool2d-4         [-1, 64, 112, 112]               0\n",
      "            Conv2d-5         [-1, 64, 112, 112]          36,864\n",
      "       BatchNorm2d-6         [-1, 64, 112, 112]             128\n",
      "              ReLU-7         [-1, 64, 112, 112]               0\n",
      "            Conv2d-8         [-1, 64, 112, 112]          36,864\n",
      "       BatchNorm2d-9         [-1, 64, 112, 112]             128\n",
      "             ReLU-10         [-1, 64, 112, 112]               0\n",
      "       BasicBlock-11         [-1, 64, 112, 112]               0\n",
      "           Conv2d-12         [-1, 64, 112, 112]          36,864\n",
      "      BatchNorm2d-13         [-1, 64, 112, 112]             128\n",
      "             ReLU-14         [-1, 64, 112, 112]               0\n",
      "           Conv2d-15         [-1, 64, 112, 112]          36,864\n",
      "      BatchNorm2d-16         [-1, 64, 112, 112]             128\n",
      "             ReLU-17         [-1, 64, 112, 112]               0\n",
      "       BasicBlock-18         [-1, 64, 112, 112]               0\n",
      "           Conv2d-19          [-1, 128, 56, 56]          73,728\n",
      "      BatchNorm2d-20          [-1, 128, 56, 56]             256\n",
      "             ReLU-21          [-1, 128, 56, 56]               0\n",
      "           Conv2d-22          [-1, 128, 56, 56]         147,456\n",
      "      BatchNorm2d-23          [-1, 128, 56, 56]             256\n",
      "           Conv2d-24          [-1, 128, 56, 56]           8,192\n",
      "      BatchNorm2d-25          [-1, 128, 56, 56]             256\n",
      "             ReLU-26          [-1, 128, 56, 56]               0\n",
      "       BasicBlock-27          [-1, 128, 56, 56]               0\n",
      "           Conv2d-28          [-1, 128, 56, 56]         147,456\n",
      "      BatchNorm2d-29          [-1, 128, 56, 56]             256\n",
      "             ReLU-30          [-1, 128, 56, 56]               0\n",
      "           Conv2d-31          [-1, 128, 56, 56]         147,456\n",
      "      BatchNorm2d-32          [-1, 128, 56, 56]             256\n",
      "             ReLU-33          [-1, 128, 56, 56]               0\n",
      "       BasicBlock-34          [-1, 128, 56, 56]               0\n",
      "           Conv2d-35          [-1, 256, 28, 28]         294,912\n",
      "      BatchNorm2d-36          [-1, 256, 28, 28]             512\n",
      "             ReLU-37          [-1, 256, 28, 28]               0\n",
      "           Conv2d-38          [-1, 256, 28, 28]         589,824\n",
      "      BatchNorm2d-39          [-1, 256, 28, 28]             512\n",
      "           Conv2d-40          [-1, 256, 28, 28]          32,768\n",
      "      BatchNorm2d-41          [-1, 256, 28, 28]             512\n",
      "             ReLU-42          [-1, 256, 28, 28]               0\n",
      "       BasicBlock-43          [-1, 256, 28, 28]               0\n",
      "           Conv2d-44          [-1, 256, 28, 28]         589,824\n",
      "      BatchNorm2d-45          [-1, 256, 28, 28]             512\n",
      "             ReLU-46          [-1, 256, 28, 28]               0\n",
      "           Conv2d-47          [-1, 256, 28, 28]         589,824\n",
      "      BatchNorm2d-48          [-1, 256, 28, 28]             512\n",
      "             ReLU-49          [-1, 256, 28, 28]               0\n",
      "       BasicBlock-50          [-1, 256, 28, 28]               0\n",
      "           Conv2d-51          [-1, 512, 14, 14]       1,179,648\n",
      "      BatchNorm2d-52          [-1, 512, 14, 14]           1,024\n",
      "             ReLU-53          [-1, 512, 14, 14]               0\n",
      "           Conv2d-54          [-1, 512, 14, 14]       2,359,296\n",
      "      BatchNorm2d-55          [-1, 512, 14, 14]           1,024\n",
      "           Conv2d-56          [-1, 512, 14, 14]         131,072\n",
      "      BatchNorm2d-57          [-1, 512, 14, 14]           1,024\n",
      "             ReLU-58          [-1, 512, 14, 14]               0\n",
      "       BasicBlock-59          [-1, 512, 14, 14]               0\n",
      "           Conv2d-60          [-1, 512, 14, 14]       2,359,296\n",
      "      BatchNorm2d-61          [-1, 512, 14, 14]           1,024\n",
      "             ReLU-62          [-1, 512, 14, 14]               0\n",
      "           Conv2d-63          [-1, 512, 14, 14]       2,359,296\n",
      "      BatchNorm2d-64          [-1, 512, 14, 14]           1,024\n",
      "             ReLU-65          [-1, 512, 14, 14]               0\n",
      "       BasicBlock-66          [-1, 512, 14, 14]               0\n",
      "           Conv2d-67         [-1, 1024, 14, 14]         524,288\n",
      "      BatchNorm2d-68         [-1, 1024, 14, 14]           2,048\n",
      "             ReLU-69         [-1, 1024, 14, 14]               0\n",
      "           Conv2d-70         [-1, 1024, 14, 14]       9,437,184\n",
      "      BatchNorm2d-71         [-1, 1024, 14, 14]           2,048\n",
      "             ReLU-72         [-1, 1024, 14, 14]               0\n",
      "           Conv2d-73         [-1, 1024, 14, 14]       9,437,184\n",
      "      BatchNorm2d-74         [-1, 1024, 14, 14]           2,048\n",
      "             ReLU-75         [-1, 1024, 14, 14]               0\n",
      "           Conv2d-76         [-1, 1024, 14, 14]       9,437,184\n",
      "      BatchNorm2d-77         [-1, 1024, 14, 14]           2,048\n",
      "             ReLU-78         [-1, 1024, 14, 14]               0\n",
      "           Conv2d-79           [-1, 12, 14, 14]          12,288\n",
      "AdaptiveAvgPool2d-80             [-1, 12, 7, 7]               0\n",
      "================================================================\n",
      "Total params: 40,032,832\n",
      "Trainable params: 40,032,832\n",
      "Non-trainable params: 0\n",
      "----------------------------------------------------------------\n",
      "Input size (MB): 2.30\n",
      "Forward/backward pass size (MB): 269.52\n",
      "Params size (MB): 152.71\n",
      "Estimated Total Size (MB): 424.53\n",
      "----------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "torchsummary.summary(model, (3,448,448))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "4cf3af4c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 12, 7, 7])\n"
     ]
    }
   ],
   "source": [
    "x = torch.randn(1, 3, 448, 448).to(device)\n",
    "with torch.no_grad():\n",
    "    y = model(x)\n",
    "print(y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "5c34a239",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "filename:['shape1_10.jpg'], target:[array([[0.58172178, 0.55863488, 0.06113537, 0.04489235, 1.        ],\n",
      "       [0.92389268, 0.30393952, 0.01996257, 0.01603298, 0.        ],\n",
      "       [0.80255771, 0.09001374, 0.01996257, 0.01786532, 0.        ],\n",
      "       [0.0246413 , 0.60444343, 0.02557704, 0.09253321, 1.        ],\n",
      "       [0.74422956, 0.08131012, 0.0205864 , 0.01603298, 0.        ],\n",
      "       [0.20586401, 0.51007789, 0.02495321, 0.05863491, 1.        ],\n",
      "       [0.22181535, 0.16869904, 0.12494074, 0.03748969, 1.        ]])]\n",
      "filename:['shape1_106.jpg'], target:[array([[0.225968  , 0.51142299, 0.27690101, 0.050928  , 1.        ],\n",
      "       [0.88163602, 0.53712499, 0.067432  , 0.037601  , 1.        ],\n",
      "       [0.879484  , 0.58662498, 0.045911  , 0.019515  , 1.        ],\n",
      "       [0.21556699, 0.378867  , 0.058106  , 0.081866  , 1.        ],\n",
      "       [0.90781897, 0.17896201, 0.058106  , 0.072347  , 1.        ]])]\n",
      "filename:['shape1_113.jpg'], target:[array([[0.511078  , 0.59718901, 0.212703  , 0.144354  , 1.        ],\n",
      "       [0.67688298, 0.70748001, 0.245938  , 0.069557  , 1.        ],\n",
      "       [0.786928  , 0.78584999, 0.244461  , 0.058599  , 1.        ],\n",
      "       [0.87887698, 0.75035697, 0.017725  , 0.012387  , 0.        ],\n",
      "       [0.257386  , 0.51929498, 0.014032  , 0.010481  , 0.        ],\n",
      "       [0.697932  , 0.412101  , 0.020679  , 0.015245  , 0.        ],\n",
      "       [0.86779898, 0.851834  , 0.062038  , 0.044783  , 1.        ],\n",
      "       [0.16986699, 0.82920402, 0.038405  , 0.022392  , 1.        ],\n",
      "       [0.139956  , 0.641258  , 0.031758  , 0.097189  , 1.        ]])]\n",
      "filename:['shape1_116.jpg'], target:[array([[0.16838235, 0.4815613 , 0.0382353 , 0.03065134, 1.        ],\n",
      "       [0.52316177, 0.66259581, 0.02352941, 0.01628353, 0.        ],\n",
      "       [0.73088235, 0.60512453, 0.02279412, 0.01628353, 0.        ],\n",
      "       [0.78198528, 0.37715518, 0.02426471, 0.01724138, 0.        ],\n",
      "       [0.77573532, 0.64248085, 0.02058824, 0.01436782, 0.        ],\n",
      "       [0.03713235, 0.4315134 , 0.03088235, 0.09626437, 1.        ],\n",
      "       [0.59117645, 0.35560346, 0.02352941, 0.01676245, 0.        ]])]\n",
      "filename:['shape1_117.jpg'], target:[array([[0.87970501, 0.75570297, 0.019188  , 0.018061  , 0.        ],\n",
      "       [0.250554  , 0.52281398, 0.014022  , 0.012357  , 0.        ],\n",
      "       [0.69446498, 0.41444901, 0.020664  , 0.015209  , 0.        ],\n",
      "       [0.51365298, 0.59981   , 0.206642  , 0.143536  , 1.        ],\n",
      "       [0.65572   , 0.70983797, 0.208856  , 0.066065  , 1.        ],\n",
      "       [0.77970499, 0.78897297, 0.25461301, 0.056084  , 1.        ],\n",
      "       [0.16715901, 0.83103597, 0.037638  , 0.020437  , 1.        ],\n",
      "       [0.86383802, 0.854563  , 0.059779  , 0.042776  , 1.        ]])]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[21], line 17\u001b[0m\n\u001b[1;32m     14\u001b[0m     targets \u001b[38;5;241m=\u001b[39m batch[\u001b[38;5;241m1\u001b[39m]\n\u001b[1;32m     15\u001b[0m     filenames \u001b[38;5;241m=\u001b[39m batch[\u001b[38;5;241m2\u001b[39m]\n\u001b[0;32m---> 17\u001b[0m     predictions \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\u001b[43mimages\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     18\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfilename:\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfilenames\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m, target:\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mtargets\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     19\u001b[0m \u001b[38;5;66;03m#     print(f\"{index}--input shape:{images.shape} -> output shape: {predictions.shape}\")\u001b[39;00m\n",
      "File \u001b[0;32m/usr/local/lib/python3.8/dist-packages/torch/nn/modules/module.py:1423\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1418\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1419\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1420\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1421\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1422\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1423\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1424\u001b[0m \u001b[38;5;66;03m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1425\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[38;5;241m=\u001b[39m [], []\n",
      "Cell \u001b[0;32mIn[17], line 56\u001b[0m, in \u001b[0;36mYOLO_RESNET.forward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     55\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, x):\n\u001b[0;32m---> 56\u001b[0m     out \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackbone\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     57\u001b[0m     \u001b[38;5;66;03m# out = self.neck(out)\u001b[39;00m\n\u001b[1;32m     58\u001b[0m     out \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhead(out) \u001b[38;5;66;03m# input (batch, 3, 448, 448) -> output feature (batch, 12, 7, 7)\u001b[39;00m\n",
      "File \u001b[0;32m/usr/local/lib/python3.8/dist-packages/torch/nn/modules/module.py:1423\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1418\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1419\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1420\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1421\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1422\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1423\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1424\u001b[0m \u001b[38;5;66;03m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1425\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[38;5;241m=\u001b[39m [], []\n",
      "File \u001b[0;32m/usr/local/lib/python3.8/dist-packages/torch/nn/modules/container.py:204\u001b[0m, in \u001b[0;36mSequential.forward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    202\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m):\n\u001b[1;32m    203\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m module \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m:\n\u001b[0;32m--> 204\u001b[0m         \u001b[38;5;28minput\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[43mmodule\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m    205\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28minput\u001b[39m\n",
      "File \u001b[0;32m/usr/local/lib/python3.8/dist-packages/torch/nn/modules/module.py:1423\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1418\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1419\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1420\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1421\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1422\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1423\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1424\u001b[0m \u001b[38;5;66;03m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1425\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[38;5;241m=\u001b[39m [], []\n",
      "File \u001b[0;32m/usr/local/lib/python3.8/dist-packages/torch/nn/modules/container.py:204\u001b[0m, in \u001b[0;36mSequential.forward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    202\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m):\n\u001b[1;32m    203\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m module \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m:\n\u001b[0;32m--> 204\u001b[0m         \u001b[38;5;28minput\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[43mmodule\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m    205\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28minput\u001b[39m\n",
      "File \u001b[0;32m/usr/local/lib/python3.8/dist-packages/torch/nn/modules/module.py:1423\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1418\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1419\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1420\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1421\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1422\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1423\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1424\u001b[0m \u001b[38;5;66;03m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1425\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[38;5;241m=\u001b[39m [], []\n",
      "File \u001b[0;32m/usr/local/lib/python3.8/dist-packages/torchvision/models/resnet.py:92\u001b[0m, in \u001b[0;36mBasicBlock.forward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     89\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, x: Tensor) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tensor:\n\u001b[1;32m     90\u001b[0m     identity \u001b[38;5;241m=\u001b[39m x\n\u001b[0;32m---> 92\u001b[0m     out \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconv1\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     93\u001b[0m     out \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbn1(out)\n\u001b[1;32m     94\u001b[0m     out \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mrelu(out)\n",
      "File \u001b[0;32m/usr/local/lib/python3.8/dist-packages/torch/nn/modules/module.py:1423\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1418\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1419\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1420\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1421\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1422\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1423\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1424\u001b[0m \u001b[38;5;66;03m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1425\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[38;5;241m=\u001b[39m [], []\n",
      "File \u001b[0;32m/usr/local/lib/python3.8/dist-packages/torch/nn/modules/conv.py:463\u001b[0m, in \u001b[0;36mConv2d.forward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    462\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m: Tensor) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tensor:\n\u001b[0;32m--> 463\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_conv_forward\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbias\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/usr/local/lib/python3.8/dist-packages/torch/nn/modules/conv.py:459\u001b[0m, in \u001b[0;36mConv2d._conv_forward\u001b[0;34m(self, input, weight, bias)\u001b[0m\n\u001b[1;32m    455\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpadding_mode \u001b[38;5;241m!=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mzeros\u001b[39m\u001b[38;5;124m'\u001b[39m:\n\u001b[1;32m    456\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m F\u001b[38;5;241m.\u001b[39mconv2d(F\u001b[38;5;241m.\u001b[39mpad(\u001b[38;5;28minput\u001b[39m, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_reversed_padding_repeated_twice, mode\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpadding_mode),\n\u001b[1;32m    457\u001b[0m                     weight, bias, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstride,\n\u001b[1;32m    458\u001b[0m                     _pair(\u001b[38;5;241m0\u001b[39m), \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdilation, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mgroups)\n\u001b[0;32m--> 459\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mF\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconv2d\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbias\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstride\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    460\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpadding\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdilation\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgroups\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# data_dir = \"/content/drive/MyDrive/fastCamMedicalProj/DATASET/DATASET/Detection/\"\n",
    "BATCH_SIZE = 1\n",
    "\n",
    "# trainset = Detection_dataset(data_dir=data_dir, phase=\"train\", transformer=transformer)\n",
    "NECK_PATH = '/home/host_data/PET_data/Neck'\n",
    "BODY_PATH = '/home/host_data/PET_data/Body'\n",
    "trainset=PET_dataset(part='body',neck_dir=NECK_PATH,body_dir=BODY_PATH,phase='train', transformer=transformer)\n",
    "trainloader = DataLoader(trainset, batch_size=BATCH_SIZE, shuffle=False, collate_fn=collate_fn)\n",
    "\n",
    "model = YOLO_RESNET(num_classes=NUM_CLASSES)\n",
    "\n",
    "for index, batch in enumerate(trainloader):\n",
    "    images = batch[0]\n",
    "    targets = batch[1]\n",
    "    filenames = batch[2]\n",
    "    \n",
    "    predictions = model(images)\n",
    "    print(f\"filename:{filenames}, target:{targets}\")\n",
    "#     print(f\"{index}--input shape:{images.shape} -> output shape: {predictions.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8da970d7",
   "metadata": {},
   "source": [
    "# Loss func"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "3c66945c",
   "metadata": {},
   "outputs": [],
   "source": [
    "class YOLO_LOSS():\n",
    "    def __init__(self, num_classes, device, lambda_coord=5., lambda_noobj=0.5):\n",
    "        self.num_classes = num_classes\n",
    "        self.device = device\n",
    "        self.grid_size = 7\n",
    "        self.lambda_coord = lambda_coord\n",
    "        self.lambda_noobj = lambda_noobj\n",
    "        self.mse_loss = nn.MSELoss(reduction=\"sum\")\n",
    "\n",
    "    def __call__(self, predictions, targets):\n",
    "        self.batch_size, _, _, _ = predictions.shape\n",
    "        groundtruths = self.build_batch_target_grid(targets)\n",
    "        groundtruths = groundtruths.to(self.device)\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            iou1 = self.get_IoU(predictions[:, 1:5, ...], groundtruths[:, 1:5, ...])\n",
    "            iou2 = self.get_IoU(predictions[:, 6:10, ...], groundtruths[:, 1:5, ...])\n",
    "\n",
    "        ious = torch.stack([iou1, iou2], dim=1)\n",
    "        max_iou, best_box = ious.max(dim=1, keepdim=True)\n",
    "        max_iou = torch.cat([max_iou, max_iou], dim=1)\n",
    "        best_box = torch.cat([best_box.eq(0), best_box.eq(1)], dim=1)\n",
    "\n",
    "        predictions_ = predictions[:, :5*2, ...].reshape(self.batch_size, 2, 5, self.grid_size, self.grid_size)\n",
    "        obj_pred = predictions_[:, :, 0, ...]\n",
    "        xy_pred = predictions_[:, :, 1:3, ...]\n",
    "        wh_pred = predictions_[:, :, 3:5, ...]\n",
    "        cls_pred = predictions[:, 5*2:, ...]\n",
    "\n",
    "        groundtruths_ = groundtruths[:, :5, ...].reshape(self.batch_size, 1, 5, self.grid_size, self.grid_size)\n",
    "        obj_target = groundtruths_[:, :, 0, ...]\n",
    "        xy_target = groundtruths_[:, :, 1:3, ...]\n",
    "        wh_target= groundtruths_[:, :, 3:5, ...]\n",
    "        cls_target = groundtruths[:, 5:, ...]\n",
    "        \n",
    "        positive = obj_target * best_box\n",
    "\n",
    "        obj_loss = self.mse_loss(positive * obj_pred, positive * ious)\n",
    "        noobj_loss = self.mse_loss((1 - positive) * obj_pred, ious*0)\n",
    "        xy_loss = self.mse_loss(positive.unsqueeze(dim=2) * xy_pred, positive.unsqueeze(dim=2) * xy_target)\n",
    "        wh_loss = self.mse_loss(positive.unsqueeze(dim=2) * (wh_pred.sign() * (wh_pred.abs() + 1e-8).sqrt()),\n",
    "                           positive.unsqueeze(dim=2) * (wh_target + 1e-8).sqrt())\n",
    "        cls_loss = self.mse_loss(obj_target * cls_pred, cls_target)\n",
    "        \n",
    "        obj_loss /= self.batch_size\n",
    "        noobj_loss /= self.batch_size\n",
    "        bbox_loss = (xy_loss+wh_loss) / self.batch_size\n",
    "        cls_loss /= self.batch_size\n",
    "        \n",
    "        total_loss = obj_loss + self.lambda_noobj*noobj_loss + self.lambda_coord*bbox_loss + cls_loss\n",
    "        return total_loss, (obj_loss.item(), noobj_loss.item(), bbox_loss.item(), cls_loss.item())\n",
    "    \n",
    "    def build_target_grid(self, target):\n",
    "        target_grid = torch.zeros((1+4+self.num_classes, self.grid_size, self.grid_size), device=self.device)\n",
    "\n",
    "        for gt in target:\n",
    "            xc, yc, w, h, cls_id = gt\n",
    "            xn = (xc % (1/self.grid_size))\n",
    "            yn = (yc % (1/self.grid_size))\n",
    "            cls_id = int(cls_id)\n",
    "\n",
    "            i_grid = int(xc * self.grid_size)\n",
    "            j_grid = int(yc * self.grid_size)\n",
    "            target_grid[0, j_grid, i_grid] = 1\n",
    "            target_grid[1:5, j_grid, i_grid] = torch.Tensor([xn,yn,w,h])\n",
    "#             print(5+cls_id, j_grid, i_grid)\n",
    "            target_grid[5+cls_id, j_grid, i_grid] = 1\n",
    "\n",
    "        return target_grid\n",
    "    \n",
    "    def build_batch_target_grid(self, targets):\n",
    "        target_grid_batch = torch.stack([self.build_target_grid(target) for target in targets], dim=0)\n",
    "        return target_grid_batch\n",
    "    \n",
    "    def get_IoU(self, cbox1, cbox2):\n",
    "        box1 = self.xywh_to_xyxy(cbox1)\n",
    "        box2 = self.xywh_to_xyxy(cbox2)\n",
    "\n",
    "        x1 = torch.max(box1[:, 0, ...], box2[:, 0, ...])\n",
    "        y1 = torch.max(box1[:, 1, ...], box2[:, 1, ...])\n",
    "        x2 = torch.min(box1[:, 2, ...], box2[:, 2, ...])\n",
    "        y2 = torch.min(box1[:, 3, ...], box2[:, 3, ...])\n",
    "\n",
    "        intersection = (x2-x1).clamp(min=0) * (y2-y1).clamp(min=0)\n",
    "        union = abs(cbox1[:, 2, ...]*cbox1[:, 3, ...]) + \\\n",
    "                abs(cbox2[:, 2, ...]*cbox2[:, 3, ...]) - intersection\n",
    "\n",
    "        intersection[intersection.gt(0)] = intersection[intersection.gt(0)] / union[intersection.gt(0)]\n",
    "        return intersection\n",
    "    \n",
    "    def generate_xy_normed_grid(self):\n",
    "        y_offset, x_offset = torch.meshgrid(torch.arange(self.grid_size), torch.arange(self.grid_size))\n",
    "        xy_grid = torch.stack([x_offset, y_offset], dim=0)\n",
    "        xy_normed_grid = xy_grid / self.grid_size\n",
    "        return xy_normed_grid.to(self.device)\n",
    "\n",
    "    def xywh_to_xyxy(self, bboxes):\n",
    "        xy_normed_grid = self.generate_xy_normed_grid()\n",
    "        xcyc = bboxes[:,0:2,...] + xy_normed_grid.tile(self.batch_size, 1,1,1)\n",
    "        wh = bboxes[:,2:4,...]\n",
    "        x1y1 = xcyc - (wh/2)\n",
    "        x2y2 = xcyc + (wh/2)\n",
    "        return torch.cat([x1y1, x2y2], dim=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c46ad931",
   "metadata": {},
   "source": [
    "# Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "b1729df2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_one_epoch(dataloaders, model, criterion, optimizer, device):\n",
    "    train_loss = defaultdict(float)\n",
    "    val_loss = defaultdict(float)\n",
    "    \n",
    "    for phase in [\"train\", \"val\"]:\n",
    "        if phase == \"train\":\n",
    "            model.train()\n",
    "        else:\n",
    "            model.eval()\n",
    "        \n",
    "        running_loss = defaultdict(float)\n",
    "        for index, batch in enumerate(dataloaders[phase]):\n",
    "            images = batch[0].to(device)\n",
    "            targets = batch[1]\n",
    "            filenames = batch[2]\n",
    "            \n",
    "            with torch.set_grad_enabled(phase == \"train\"): # phase가 train 일때만 gradient 추적기능을 킨다.\n",
    "                predictions = model(images) #prediction shape=> B,12,7,7\n",
    "#             print(f\"predictions:{predictions}, \\ntargets: {targets}\\n\")\n",
    "            loss, (obj_loss, noobj_loss, bbox_loss, cls_loss) = criterion(predictions, targets)\n",
    "#             print(f\"loss:{loss}, obj_loss:{obj_loss}, noobj_loss:{noobj_loss}\\nbbox_loss:{bbox_loss}, cls_loss:{cls_loss}\\n--------------\\n\")\n",
    "            if phase == \"train\":\n",
    "                optimizer.zero_grad()\n",
    "                loss.backward()\n",
    "                optimizer.step()\n",
    "                \n",
    "                # 현재 epoch단계에서 loss가 얼마인지 running loss 가출력\n",
    "                running_loss[\"total_loss\"] += loss.item()\n",
    "                running_loss[\"obj_loss\"] += obj_loss\n",
    "                running_loss[\"noobj_loss\"] += noobj_loss\n",
    "                running_loss[\"bbox_loss\"] += bbox_loss\n",
    "                running_loss[\"cls_loss\"] += cls_loss\n",
    "                \n",
    "                train_loss[\"total_loss\"] += loss.item()\n",
    "                train_loss[\"obj_loss\"] += obj_loss\n",
    "                train_loss[\"noobj_loss\"] += noobj_loss\n",
    "                train_loss[\"bbox_loss\"] += bbox_loss\n",
    "                train_loss[\"cls_loss\"] += cls_loss\n",
    "                \n",
    "                if (index > 0) and (index % VERBOSE_FREQ) == 0:\n",
    "                    text = f\"<<<iteration:[{index}/{len(dataloaders[phase])}] - \"\n",
    "                    for k, v in running_loss.items():\n",
    "                        text += f\"{k}: {v/VERBOSE_FREQ:.4f}  \"\n",
    "                        running_loss[k] = 0.\n",
    "                    print(text)\n",
    "            else:\n",
    "                val_loss[\"total_loss\"] += loss.item()\n",
    "                val_loss[\"obj_loss\"] += obj_loss\n",
    "                val_loss[\"noobj_loss\"] += noobj_loss\n",
    "                val_loss[\"bbox_loss\"] += bbox_loss\n",
    "                val_loss[\"cls_loss\"] += cls_loss\n",
    "\n",
    "    for k in train_loss.keys():\n",
    "        train_loss[k] /= len(dataloaders[\"train\"])\n",
    "        val_loss[k] /= len(dataloaders[\"val\"])\n",
    "    return train_loss, val_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "2771b438",
   "metadata": {},
   "outputs": [],
   "source": [
    "# data_dir = \"/content/drive/MyDrive/fastCamMedicalProj/DATASET/DATASET/Detection/\"\n",
    "NECK_PATH = '/home/host_data/PET_data/Neck'\n",
    "BODY_PATH = '/home/host_data/PET_data/Body'\n",
    "is_cuda = True\n",
    "\n",
    "NUM_CLASSES = 2\n",
    "IMAGE_SIZE = 448\n",
    "BATCH_SIZE = 1\n",
    "VERBOSE_FREQ = 20\n",
    "LR=0.00001\n",
    "BACKBONE=\"YOLO_RESNET18\"\n",
    "PART=\"body\"\n",
    "# DEVICE = torch.device('cuda' if torch.cuda.is_available and is_cuda else 'cpu')\n",
    "\n",
    "dataloaders = build_dataloader(part=PART,NECK_PATH=NECK_PATH,BODY_PATH=BODY_PATH,batch_size=BATCH_SIZE)\n",
    "model = YOLO_RESNET(num_classes=NUM_CLASSES)\n",
    "model = model.to(device)\n",
    "criterion = YOLO_LOSS(num_classes=NUM_CLASSES, device=device)\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=LR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "060a24e6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "Finishing last run (ID:d766zdyz) before initializing another..."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "83f60cffe9f54bac80046da2e7159bbd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='0.003 MB of 0.003 MB uploaded (0.000 MB deduped)\\r'), FloatProgress(value=1.0, max…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>Train Loss</td><td>█▆▅▅▄▄▄▃▃▂▂▂▂▁▁▁</td></tr><tr><td>Train bbox Loss</td><td>█▇▆▅▄▄▄▄▃▃▃▂▂▁▁▁</td></tr><tr><td>Train class Loss</td><td>█▅▄▄▄▃▃▂▂▂▂▁▁▁▁▁</td></tr><tr><td>Train obj Loss</td><td>█▅▄▄▃▂▂▂▂▁▁▁▁▁▁▁</td></tr><tr><td>Val Loss</td><td>█▇▅▅▄▄▄▃▃▂▂▂▁▁▁▂</td></tr><tr><td>Val bbox Loss</td><td>█▇▅▅▄▄▃▃▃▂▂▂▁▁▁▂</td></tr><tr><td>Val class Loss</td><td>▇▁▄▅▄▄▇▄▇▄▇▃▃▃▃█</td></tr><tr><td>Val obj Loss</td><td>█▆▅▄▄▃▃▃▄▂▂▃▂▁▁▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>Train Loss</td><td>5.0485</td></tr><tr><td>Train bbox Loss</td><td>0.82442</td></tr><tr><td>Train class Loss</td><td>0.42578</td></tr><tr><td>Train obj Loss</td><td>0.0671</td></tr><tr><td>Val Loss</td><td>12.17263</td></tr><tr><td>Val bbox Loss</td><td>1.50617</td></tr><tr><td>Val class Loss</td><td>3.27785</td></tr><tr><td>Val obj Loss</td><td>0.1138</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">fragrant-feather-1</strong> at: <a href='https://wandb.ai/urp/my-awesome-project/runs/d766zdyz' target=\"_blank\">https://wandb.ai/urp/my-awesome-project/runs/d766zdyz</a><br/>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20231003_123623-d766zdyz/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Successfully finished last run (ID:d766zdyz). Initializing new run:<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9c887ab56cf344a5a5c4e1f63825e5ae",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='Waiting for wandb.init()...\\r'), FloatProgress(value=0.011113318600028935, max=1.0…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.15.11"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/workspace/yb/wandb/run-20231003_124530-6ozln9gt</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/urp/yolo_resnet/runs/6ozln9gt' target=\"_blank\">amber-frost-2</a></strong> to <a href='https://wandb.ai/urp/yolo_resnet' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/urp/yolo_resnet' target=\"_blank\">https://wandb.ai/urp/yolo_resnet</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/urp/yolo_resnet/runs/6ozln9gt' target=\"_blank\">https://wandb.ai/urp/yolo_resnet/runs/6ozln9gt</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<button onClick=\"this.nextSibling.style.display='block';this.style.display='none';\">Display W&B run</button><iframe src='https://wandb.ai/urp/yolo_resnet/runs/6ozln9gt?jupyter=true' style='border:none;width:100%;height:420px;display:none;'></iframe>"
      ],
      "text/plain": [
       "<wandb.sdk.wandb_run.Run at 0x7f8368c714f0>"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import wandb\n",
    "import random\n",
    "\n",
    "# start a new wandb run to track this script\n",
    "wandb.init(\n",
    "    # set the wandb project where this run will be logged\n",
    "    project=\"yolo_resnet\",\n",
    "    \n",
    "    # track hyperparameters and run metadata\n",
    "    config={\n",
    "    \"learning_rate\": LR,\n",
    "    \"batch_size\": BATCH_SIZE,\n",
    "    \"architecture\": BACKBONE,\n",
    "    \"dataset\": \"BODY\",\n",
    "    \"epochs\": 100,\n",
    "    }\n",
    ")\n",
    "\n",
    "# simulate training\n",
    "# epochs = 10\n",
    "# offset = random.random() / 5\n",
    "# for epoch in range(2, epochs):\n",
    "#     acc = 1 - 2 ** -epoch - random.random() / epoch - offset\n",
    "#     loss = 2 ** -epoch + random.random() / epoch + offset\n",
    "    \n",
    "#     # log metrics to wandb\n",
    "#     wandb.log({\"acc\": acc, \"loss\": loss})\n",
    "    \n",
    "# # [optional] finish the wandb run, necessary in notebooks\n",
    "# wandb.finish()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "8ebab5dc",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<<<iteration:[20/117] - total_loss: 10.0012  obj_loss: 0.0653  noobj_loss: 1.1336  bbox_loss: 1.7076  cls_loss: 0.8313  \n",
      "<<<iteration:[40/117] - total_loss: 6.1174  obj_loss: 0.0661  noobj_loss: 1.0699  bbox_loss: 1.0060  cls_loss: 0.4862  \n",
      "<<<iteration:[60/117] - total_loss: 5.3445  obj_loss: 0.0384  noobj_loss: 1.0399  bbox_loss: 0.8482  cls_loss: 0.5450  \n",
      "<<<iteration:[80/117] - total_loss: 6.1004  obj_loss: 0.0809  noobj_loss: 0.9702  bbox_loss: 0.9511  cls_loss: 0.7788  \n",
      "<<<iteration:[100/117] - total_loss: 5.7960  obj_loss: 0.0682  noobj_loss: 0.9686  bbox_loss: 0.9143  cls_loss: 0.6722  \n",
      "\n",
      "epoch:1/100 - Train Loss: 6.4320, Val Loss: 10.4970\n",
      "\n",
      "<<<iteration:[20/117] - total_loss: 4.5339  obj_loss: 0.0439  noobj_loss: 0.9305  bbox_loss: 0.7098  cls_loss: 0.4758  \n",
      "<<<iteration:[40/117] - total_loss: 5.7652  obj_loss: 0.0570  noobj_loss: 0.8886  bbox_loss: 0.9491  cls_loss: 0.5183  \n",
      "<<<iteration:[60/117] - total_loss: 5.3198  obj_loss: 0.0554  noobj_loss: 0.8942  bbox_loss: 0.8477  cls_loss: 0.5789  \n",
      "<<<iteration:[80/117] - total_loss: 4.6485  obj_loss: 0.0412  noobj_loss: 0.8654  bbox_loss: 0.7255  cls_loss: 0.5470  \n",
      "<<<iteration:[100/117] - total_loss: 5.3148  obj_loss: 0.0816  noobj_loss: 0.9011  bbox_loss: 0.8499  cls_loss: 0.5331  \n",
      "\n",
      "epoch:2/100 - Train Loss: 5.0585, Val Loss: 9.5741\n",
      "\n",
      "<<<iteration:[20/117] - total_loss: 5.1003  obj_loss: 0.0640  noobj_loss: 0.8352  bbox_loss: 0.8453  cls_loss: 0.3921  \n",
      "<<<iteration:[40/117] - total_loss: 4.8651  obj_loss: 0.0580  noobj_loss: 0.8130  bbox_loss: 0.7920  cls_loss: 0.4407  \n",
      "<<<iteration:[60/117] - total_loss: 4.0273  obj_loss: 0.0922  noobj_loss: 0.7989  bbox_loss: 0.6279  cls_loss: 0.3959  \n",
      "<<<iteration:[80/117] - total_loss: 4.0027  obj_loss: 0.0490  noobj_loss: 0.8386  bbox_loss: 0.6280  cls_loss: 0.3946  \n",
      "<<<iteration:[100/117] - total_loss: 5.1956  obj_loss: 0.0611  noobj_loss: 0.8586  bbox_loss: 0.8647  cls_loss: 0.3815  \n",
      "\n",
      "epoch:3/100 - Train Loss: 4.6280, Val Loss: 9.9416\n",
      "\n",
      "<<<iteration:[20/117] - total_loss: 3.7042  obj_loss: 0.0601  noobj_loss: 0.7918  bbox_loss: 0.5693  cls_loss: 0.4020  \n",
      "<<<iteration:[40/117] - total_loss: 4.5553  obj_loss: 0.0538  noobj_loss: 0.7244  bbox_loss: 0.7597  cls_loss: 0.3410  \n",
      "<<<iteration:[60/117] - total_loss: 4.5344  obj_loss: 0.0690  noobj_loss: 0.7998  bbox_loss: 0.7173  cls_loss: 0.4789  \n",
      "<<<iteration:[80/117] - total_loss: 3.6369  obj_loss: 0.0649  noobj_loss: 0.6748  bbox_loss: 0.5936  cls_loss: 0.2668  \n",
      "<<<iteration:[100/117] - total_loss: 4.7644  obj_loss: 0.0996  noobj_loss: 0.6899  bbox_loss: 0.7934  cls_loss: 0.3529  \n",
      "\n",
      "epoch:4/100 - Train Loss: 4.2255, Val Loss: 9.9745\n",
      "\n",
      "<<<iteration:[20/117] - total_loss: 4.3781  obj_loss: 0.0596  noobj_loss: 0.6780  bbox_loss: 0.7407  cls_loss: 0.2761  \n",
      "<<<iteration:[40/117] - total_loss: 3.6597  obj_loss: 0.0735  noobj_loss: 0.6275  bbox_loss: 0.5922  cls_loss: 0.3112  \n",
      "<<<iteration:[60/117] - total_loss: 3.5940  obj_loss: 0.1009  noobj_loss: 0.6488  bbox_loss: 0.5675  cls_loss: 0.3312  \n",
      "<<<iteration:[80/117] - total_loss: 4.5669  obj_loss: 0.0632  noobj_loss: 0.6450  bbox_loss: 0.7787  cls_loss: 0.2880  \n",
      "<<<iteration:[100/117] - total_loss: 4.5899  obj_loss: 0.0706  noobj_loss: 0.6554  bbox_loss: 0.7724  cls_loss: 0.3294  \n",
      "\n",
      "epoch:5/100 - Train Loss: 4.0939, Val Loss: 9.8854\n",
      "\n",
      "<<<iteration:[20/117] - total_loss: 2.9030  obj_loss: 0.0804  noobj_loss: 0.6315  bbox_loss: 0.4567  cls_loss: 0.2235  \n",
      "<<<iteration:[40/117] - total_loss: 4.8784  obj_loss: 0.1165  noobj_loss: 0.5908  bbox_loss: 0.8303  cls_loss: 0.3151  \n",
      "<<<iteration:[60/117] - total_loss: 3.9288  obj_loss: 0.0746  noobj_loss: 0.5979  bbox_loss: 0.6462  cls_loss: 0.3243  \n",
      "<<<iteration:[80/117] - total_loss: 3.3420  obj_loss: 0.0695  noobj_loss: 0.5603  bbox_loss: 0.5497  cls_loss: 0.2439  \n",
      "<<<iteration:[100/117] - total_loss: 3.0535  obj_loss: 0.0587  noobj_loss: 0.5733  bbox_loss: 0.4956  cls_loss: 0.2300  \n",
      "\n",
      "epoch:6/100 - Train Loss: 3.6188, Val Loss: 8.8613\n",
      "\n",
      "<<<iteration:[20/117] - total_loss: 3.3683  obj_loss: 0.0926  noobj_loss: 0.5606  bbox_loss: 0.5450  cls_loss: 0.2702  \n",
      "<<<iteration:[40/117] - total_loss: 3.1580  obj_loss: 0.0780  noobj_loss: 0.5534  bbox_loss: 0.5244  cls_loss: 0.1812  \n",
      "<<<iteration:[60/117] - total_loss: 3.4946  obj_loss: 0.0773  noobj_loss: 0.6016  bbox_loss: 0.5933  cls_loss: 0.1501  \n",
      "<<<iteration:[80/117] - total_loss: 3.0206  obj_loss: 0.0874  noobj_loss: 0.5480  bbox_loss: 0.4661  cls_loss: 0.3286  \n",
      "<<<iteration:[100/117] - total_loss: 4.4247  obj_loss: 0.0703  noobj_loss: 0.5270  bbox_loss: 0.7544  cls_loss: 0.3187  \n",
      "\n",
      "epoch:7/100 - Train Loss: 3.3888, Val Loss: 9.1062\n",
      "\n",
      "<<<iteration:[20/117] - total_loss: 3.0749  obj_loss: 0.1040  noobj_loss: 0.5286  bbox_loss: 0.5121  cls_loss: 0.1464  \n",
      "<<<iteration:[40/117] - total_loss: 2.9030  obj_loss: 0.1252  noobj_loss: 0.5077  bbox_loss: 0.4659  cls_loss: 0.1944  \n",
      "<<<iteration:[60/117] - total_loss: 3.0743  obj_loss: 0.1065  noobj_loss: 0.4946  bbox_loss: 0.5074  cls_loss: 0.1835  \n",
      "<<<iteration:[80/117] - total_loss: 3.1318  obj_loss: 0.0720  noobj_loss: 0.4879  bbox_loss: 0.5176  cls_loss: 0.2280  \n",
      "<<<iteration:[100/117] - total_loss: 2.9729  obj_loss: 0.1037  noobj_loss: 0.4825  bbox_loss: 0.4834  cls_loss: 0.2109  \n",
      "\n",
      "epoch:8/100 - Train Loss: 2.9465, Val Loss: 8.2846\n",
      "\n",
      "<<<iteration:[20/117] - total_loss: 2.7506  obj_loss: 0.0751  noobj_loss: 0.4950  bbox_loss: 0.4570  cls_loss: 0.1430  \n",
      "<<<iteration:[40/117] - total_loss: 3.2331  obj_loss: 0.1374  noobj_loss: 0.4644  bbox_loss: 0.5367  cls_loss: 0.1801  \n",
      "<<<iteration:[60/117] - total_loss: 2.7466  obj_loss: 0.1060  noobj_loss: 0.4517  bbox_loss: 0.4431  cls_loss: 0.1993  \n",
      "<<<iteration:[80/117] - total_loss: 2.3230  obj_loss: 0.0995  noobj_loss: 0.4672  bbox_loss: 0.3762  cls_loss: 0.1091  \n",
      "<<<iteration:[100/117] - total_loss: 3.1967  obj_loss: 0.0843  noobj_loss: 0.4603  bbox_loss: 0.5340  cls_loss: 0.2124  \n",
      "\n",
      "epoch:9/100 - Train Loss: 2.7883, Val Loss: 8.9956\n",
      "\n",
      "<<<iteration:[20/117] - total_loss: 2.5670  obj_loss: 0.0849  noobj_loss: 0.4484  bbox_loss: 0.4224  cls_loss: 0.1459  \n",
      "<<<iteration:[40/117] - total_loss: 2.5503  obj_loss: 0.1197  noobj_loss: 0.4365  bbox_loss: 0.4142  cls_loss: 0.1412  \n",
      "<<<iteration:[60/117] - total_loss: 2.5546  obj_loss: 0.1238  noobj_loss: 0.4520  bbox_loss: 0.4103  cls_loss: 0.1532  \n",
      "<<<iteration:[80/117] - total_loss: 2.8206  obj_loss: 0.1221  noobj_loss: 0.4543  bbox_loss: 0.4555  cls_loss: 0.1939  \n",
      "<<<iteration:[100/117] - total_loss: 3.2085  obj_loss: 0.0980  noobj_loss: 0.4399  bbox_loss: 0.5370  cls_loss: 0.2054  \n",
      "\n",
      "epoch:10/100 - Train Loss: 2.6944, Val Loss: 8.1850\n",
      "\n",
      "<<<iteration:[20/117] - total_loss: 2.3225  obj_loss: 0.1179  noobj_loss: 0.4527  bbox_loss: 0.3682  cls_loss: 0.1371  \n",
      "<<<iteration:[40/117] - total_loss: 2.8553  obj_loss: 0.0826  noobj_loss: 0.4578  bbox_loss: 0.4718  cls_loss: 0.1846  \n",
      "<<<iteration:[60/117] - total_loss: 2.4595  obj_loss: 0.0693  noobj_loss: 0.4239  bbox_loss: 0.4075  cls_loss: 0.1406  \n",
      "<<<iteration:[80/117] - total_loss: 3.0209  obj_loss: 0.0423  noobj_loss: 0.4237  bbox_loss: 0.5217  cls_loss: 0.1585  \n",
      "<<<iteration:[100/117] - total_loss: 3.2537  obj_loss: 0.0913  noobj_loss: 0.4193  bbox_loss: 0.5532  cls_loss: 0.1871  \n",
      "\n",
      "epoch:11/100 - Train Loss: 2.6984, Val Loss: 8.6173\n",
      "\n",
      "<<<iteration:[20/117] - total_loss: 3.3384  obj_loss: 0.0676  noobj_loss: 0.4103  bbox_loss: 0.5807  cls_loss: 0.1620  \n",
      "<<<iteration:[40/117] - total_loss: 3.0773  obj_loss: 0.1173  noobj_loss: 0.4126  bbox_loss: 0.5231  cls_loss: 0.1382  \n",
      "<<<iteration:[60/117] - total_loss: 3.0657  obj_loss: 0.0926  noobj_loss: 0.3850  bbox_loss: 0.5321  cls_loss: 0.1200  \n",
      "<<<iteration:[80/117] - total_loss: 2.4304  obj_loss: 0.0689  noobj_loss: 0.4244  bbox_loss: 0.3985  cls_loss: 0.1570  \n",
      "<<<iteration:[100/117] - total_loss: 2.7177  obj_loss: 0.0597  noobj_loss: 0.4194  bbox_loss: 0.4598  cls_loss: 0.1494  \n",
      "\n",
      "epoch:12/100 - Train Loss: 2.7835, Val Loss: 7.9702\n",
      "\n",
      "<<<iteration:[20/117] - total_loss: 2.6853  obj_loss: 0.0886  noobj_loss: 0.3784  bbox_loss: 0.4560  cls_loss: 0.1272  \n",
      "<<<iteration:[40/117] - total_loss: 2.4770  obj_loss: 0.1230  noobj_loss: 0.3848  bbox_loss: 0.4023  cls_loss: 0.1499  \n",
      "<<<iteration:[60/117] - total_loss: 2.6437  obj_loss: 0.0748  noobj_loss: 0.3899  bbox_loss: 0.4520  cls_loss: 0.1142  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<<<iteration:[80/117] - total_loss: 2.5573  obj_loss: 0.1268  noobj_loss: 0.3987  bbox_loss: 0.4197  cls_loss: 0.1326  \n",
      "<<<iteration:[100/117] - total_loss: 2.1451  obj_loss: 0.1155  noobj_loss: 0.3562  bbox_loss: 0.3496  cls_loss: 0.1036  \n",
      "\n",
      "epoch:13/100 - Train Loss: 2.5375, Val Loss: 8.3016\n",
      "\n",
      "<<<iteration:[20/117] - total_loss: 3.1815  obj_loss: 0.0639  noobj_loss: 0.4030  bbox_loss: 0.5538  cls_loss: 0.1472  \n",
      "<<<iteration:[40/117] - total_loss: 2.5137  obj_loss: 0.0912  noobj_loss: 0.3513  bbox_loss: 0.4303  cls_loss: 0.0953  \n",
      "<<<iteration:[60/117] - total_loss: 2.5420  obj_loss: 0.1141  noobj_loss: 0.3433  bbox_loss: 0.4255  cls_loss: 0.1289  \n",
      "<<<iteration:[80/117] - total_loss: 2.4893  obj_loss: 0.1004  noobj_loss: 0.3635  bbox_loss: 0.4135  cls_loss: 0.1395  \n",
      "<<<iteration:[100/117] - total_loss: 2.0394  obj_loss: 0.0776  noobj_loss: 0.3486  bbox_loss: 0.3400  cls_loss: 0.0873  \n",
      "\n",
      "epoch:14/100 - Train Loss: 2.5089, Val Loss: 7.3701\n",
      "\n",
      "<<<iteration:[20/117] - total_loss: 2.9869  obj_loss: 0.2114  noobj_loss: 0.3530  bbox_loss: 0.4959  cls_loss: 0.1196  \n",
      "<<<iteration:[40/117] - total_loss: 2.4606  obj_loss: 0.1166  noobj_loss: 0.3514  bbox_loss: 0.4139  cls_loss: 0.0988  \n",
      "<<<iteration:[60/117] - total_loss: 2.6222  obj_loss: 0.0908  noobj_loss: 0.3598  bbox_loss: 0.4438  cls_loss: 0.1327  \n",
      "<<<iteration:[80/117] - total_loss: 1.8925  obj_loss: 0.0866  noobj_loss: 0.3546  bbox_loss: 0.2984  cls_loss: 0.1364  \n",
      "<<<iteration:[100/117] - total_loss: 2.2151  obj_loss: 0.0655  noobj_loss: 0.3425  bbox_loss: 0.3731  cls_loss: 0.1127  \n",
      "\n",
      "epoch:15/100 - Train Loss: 2.3360, Val Loss: 7.5056\n",
      "\n",
      "<<<iteration:[20/117] - total_loss: 2.6447  obj_loss: 0.1333  noobj_loss: 0.3486  bbox_loss: 0.4385  cls_loss: 0.1447  \n",
      "<<<iteration:[40/117] - total_loss: 2.2219  obj_loss: 0.1140  noobj_loss: 0.3532  bbox_loss: 0.3674  cls_loss: 0.0945  \n",
      "<<<iteration:[60/117] - total_loss: 1.8962  obj_loss: 0.0629  noobj_loss: 0.3058  bbox_loss: 0.3209  cls_loss: 0.0760  \n",
      "<<<iteration:[80/117] - total_loss: 2.3690  obj_loss: 0.0465  noobj_loss: 0.3365  bbox_loss: 0.4132  cls_loss: 0.0881  \n",
      "<<<iteration:[100/117] - total_loss: 2.7237  obj_loss: 0.1485  noobj_loss: 0.3446  bbox_loss: 0.4554  cls_loss: 0.1259  \n",
      "\n",
      "epoch:16/100 - Train Loss: 2.2619, Val Loss: 8.0555\n",
      "\n",
      "<<<iteration:[20/117] - total_loss: 2.5778  obj_loss: 0.0973  noobj_loss: 0.3168  bbox_loss: 0.4416  cls_loss: 0.1143  \n",
      "<<<iteration:[40/117] - total_loss: 2.8062  obj_loss: 0.1041  noobj_loss: 0.3231  bbox_loss: 0.4856  cls_loss: 0.1122  \n",
      "<<<iteration:[60/117] - total_loss: 1.9823  obj_loss: 0.1754  noobj_loss: 0.3194  bbox_loss: 0.3093  cls_loss: 0.1010  \n",
      "<<<iteration:[80/117] - total_loss: 2.1885  obj_loss: 0.0953  noobj_loss: 0.3301  bbox_loss: 0.3703  cls_loss: 0.0767  \n",
      "<<<iteration:[100/117] - total_loss: 3.2126  obj_loss: 0.0848  noobj_loss: 0.3534  bbox_loss: 0.5701  cls_loss: 0.1005  \n",
      "\n",
      "epoch:17/100 - Train Loss: 2.4471, Val Loss: 7.6778\n",
      "\n",
      "<<<iteration:[20/117] - total_loss: 1.7916  obj_loss: 0.1912  noobj_loss: 0.3262  bbox_loss: 0.2705  cls_loss: 0.0849  \n",
      "<<<iteration:[40/117] - total_loss: 1.6891  obj_loss: 0.0876  noobj_loss: 0.3015  bbox_loss: 0.2760  cls_loss: 0.0706  \n",
      "<<<iteration:[60/117] - total_loss: 2.0828  obj_loss: 0.0742  noobj_loss: 0.3226  bbox_loss: 0.3481  cls_loss: 0.1068  \n",
      "<<<iteration:[80/117] - total_loss: 2.0741  obj_loss: 0.0601  noobj_loss: 0.3110  bbox_loss: 0.3511  cls_loss: 0.1033  \n",
      "<<<iteration:[100/117] - total_loss: 2.2234  obj_loss: 0.0750  noobj_loss: 0.2973  bbox_loss: 0.3821  cls_loss: 0.0895  \n",
      "\n",
      "epoch:18/100 - Train Loss: 2.0308, Val Loss: 8.3062\n",
      "\n",
      "<<<iteration:[20/117] - total_loss: 3.4476  obj_loss: 0.0435  noobj_loss: 0.4150  bbox_loss: 0.6066  cls_loss: 0.1638  \n",
      "<<<iteration:[40/117] - total_loss: 1.8236  obj_loss: 0.0390  noobj_loss: 0.3297  bbox_loss: 0.3019  cls_loss: 0.1104  \n",
      "<<<iteration:[60/117] - total_loss: 2.2974  obj_loss: 0.0759  noobj_loss: 0.3238  bbox_loss: 0.3885  cls_loss: 0.1172  \n",
      "<<<iteration:[80/117] - total_loss: 2.0343  obj_loss: 0.0848  noobj_loss: 0.3380  bbox_loss: 0.3384  cls_loss: 0.0886  \n",
      "<<<iteration:[100/117] - total_loss: 1.8153  obj_loss: 0.0650  noobj_loss: 0.3006  bbox_loss: 0.2965  cls_loss: 0.1176  \n",
      "\n",
      "epoch:19/100 - Train Loss: 2.3259, Val Loss: 6.6545\n",
      "\n",
      "<<<iteration:[20/117] - total_loss: 2.0609  obj_loss: 0.1482  noobj_loss: 0.3134  bbox_loss: 0.3326  cls_loss: 0.0927  \n",
      "<<<iteration:[40/117] - total_loss: 3.0321  obj_loss: 0.0687  noobj_loss: 0.2975  bbox_loss: 0.5376  cls_loss: 0.1265  \n",
      "<<<iteration:[60/117] - total_loss: 1.7596  obj_loss: 0.0919  noobj_loss: 0.3029  bbox_loss: 0.2828  cls_loss: 0.1024  \n",
      "<<<iteration:[80/117] - total_loss: 1.7495  obj_loss: 0.1327  noobj_loss: 0.2892  bbox_loss: 0.2729  cls_loss: 0.1078  \n",
      "<<<iteration:[100/117] - total_loss: 1.8425  obj_loss: 0.1021  noobj_loss: 0.3237  bbox_loss: 0.3010  cls_loss: 0.0735  \n",
      "\n",
      "epoch:20/100 - Train Loss: 2.5075, Val Loss: 9.7275\n",
      "\n",
      "<<<iteration:[20/117] - total_loss: 3.7961  obj_loss: 0.0620  noobj_loss: 0.4335  bbox_loss: 0.6748  cls_loss: 0.1433  \n",
      "<<<iteration:[40/117] - total_loss: 2.0792  obj_loss: 0.0779  noobj_loss: 0.3641  bbox_loss: 0.3439  cls_loss: 0.0999  \n",
      "<<<iteration:[60/117] - total_loss: 2.1962  obj_loss: 0.0808  noobj_loss: 0.3482  bbox_loss: 0.3573  cls_loss: 0.1549  \n",
      "<<<iteration:[80/117] - total_loss: 2.1958  obj_loss: 0.0717  noobj_loss: 0.3603  bbox_loss: 0.3620  cls_loss: 0.1338  \n",
      "<<<iteration:[100/117] - total_loss: 2.8896  obj_loss: 0.0533  noobj_loss: 0.3405  bbox_loss: 0.5027  cls_loss: 0.1523  \n",
      "\n",
      "epoch:21/100 - Train Loss: 2.5873, Val Loss: 7.7509\n",
      "\n",
      "<<<iteration:[20/117] - total_loss: 2.5670  obj_loss: 0.0944  noobj_loss: 0.3343  bbox_loss: 0.4368  cls_loss: 0.1216  \n",
      "<<<iteration:[40/117] - total_loss: 2.0800  obj_loss: 0.1286  noobj_loss: 0.3019  bbox_loss: 0.3371  cls_loss: 0.1150  \n",
      "<<<iteration:[60/117] - total_loss: 1.8850  obj_loss: 0.1106  noobj_loss: 0.3174  bbox_loss: 0.3072  cls_loss: 0.0798  \n",
      "<<<iteration:[80/117] - total_loss: 2.3157  obj_loss: 0.0950  noobj_loss: 0.2953  bbox_loss: 0.3952  cls_loss: 0.0973  \n",
      "<<<iteration:[100/117] - total_loss: 1.6351  obj_loss: 0.1035  noobj_loss: 0.2963  bbox_loss: 0.2581  cls_loss: 0.0928  \n",
      "\n",
      "epoch:22/100 - Train Loss: 2.0186, Val Loss: 7.3742\n",
      "\n",
      "<<<iteration:[20/117] - total_loss: 1.9993  obj_loss: 0.1631  noobj_loss: 0.3017  bbox_loss: 0.3153  cls_loss: 0.1088  \n",
      "<<<iteration:[40/117] - total_loss: 1.9231  obj_loss: 0.0898  noobj_loss: 0.2864  bbox_loss: 0.3244  cls_loss: 0.0680  \n",
      "<<<iteration:[60/117] - total_loss: 5.5454  obj_loss: 0.0455  noobj_loss: 0.3297  bbox_loss: 1.0450  cls_loss: 0.1098  \n",
      "<<<iteration:[80/117] - total_loss: 3.7464  obj_loss: 0.0709  noobj_loss: 0.3269  bbox_loss: 0.6787  cls_loss: 0.1187  \n",
      "<<<iteration:[100/117] - total_loss: 1.6875  obj_loss: 0.0806  noobj_loss: 0.3123  bbox_loss: 0.2755  cls_loss: 0.0730  \n",
      "\n",
      "epoch:23/100 - Train Loss: 2.9042, Val Loss: 7.5031\n",
      "\n",
      "<<<iteration:[20/117] - total_loss: 1.9427  obj_loss: 0.1114  noobj_loss: 0.2867  bbox_loss: 0.3238  cls_loss: 0.0690  \n",
      "<<<iteration:[40/117] - total_loss: 2.1573  obj_loss: 0.1141  noobj_loss: 0.2945  bbox_loss: 0.3655  cls_loss: 0.0682  \n",
      "<<<iteration:[60/117] - total_loss: 2.3257  obj_loss: 0.0770  noobj_loss: 0.2697  bbox_loss: 0.4045  cls_loss: 0.0915  \n",
      "<<<iteration:[80/117] - total_loss: 1.5315  obj_loss: 0.0986  noobj_loss: 0.2870  bbox_loss: 0.2409  cls_loss: 0.0847  \n",
      "<<<iteration:[100/117] - total_loss: 1.8992  obj_loss: 0.1430  noobj_loss: 0.2903  bbox_loss: 0.3057  cls_loss: 0.0825  \n",
      "\n",
      "epoch:24/100 - Train Loss: 1.8607, Val Loss: 7.3892\n",
      "\n",
      "<<<iteration:[20/117] - total_loss: 2.0614  obj_loss: 0.1321  noobj_loss: 0.2814  bbox_loss: 0.3397  cls_loss: 0.0900  \n",
      "<<<iteration:[40/117] - total_loss: 1.9950  obj_loss: 0.1025  noobj_loss: 0.2841  bbox_loss: 0.3339  cls_loss: 0.0808  \n",
      "<<<iteration:[60/117] - total_loss: 2.1971  obj_loss: 0.0717  noobj_loss: 0.3038  bbox_loss: 0.3794  cls_loss: 0.0766  \n",
      "<<<iteration:[80/117] - total_loss: 1.5289  obj_loss: 0.0632  noobj_loss: 0.2847  bbox_loss: 0.2536  cls_loss: 0.0554  \n",
      "<<<iteration:[100/117] - total_loss: 2.0679  obj_loss: 0.0924  noobj_loss: 0.2639  bbox_loss: 0.3554  cls_loss: 0.0668  \n",
      "\n",
      "epoch:25/100 - Train Loss: 1.8574, Val Loss: 6.6816\n",
      "\n",
      "<<<iteration:[20/117] - total_loss: 1.2812  obj_loss: 0.2042  noobj_loss: 0.2750  bbox_loss: 0.1791  cls_loss: 0.0441  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<<<iteration:[40/117] - total_loss: 1.4981  obj_loss: 0.0892  noobj_loss: 0.2644  bbox_loss: 0.2459  cls_loss: 0.0470  \n",
      "<<<iteration:[60/117] - total_loss: 1.9314  obj_loss: 0.1472  noobj_loss: 0.2550  bbox_loss: 0.3164  cls_loss: 0.0749  \n",
      "<<<iteration:[80/117] - total_loss: 1.6243  obj_loss: 0.1190  noobj_loss: 0.2704  bbox_loss: 0.2627  cls_loss: 0.0564  \n",
      "<<<iteration:[100/117] - total_loss: 1.5511  obj_loss: 0.0984  noobj_loss: 0.2714  bbox_loss: 0.2508  cls_loss: 0.0629  \n",
      "\n",
      "epoch:26/100 - Train Loss: 1.5567, Val Loss: 7.0433\n",
      "\n",
      "<<<iteration:[20/117] - total_loss: 1.6459  obj_loss: 0.1931  noobj_loss: 0.2786  bbox_loss: 0.2497  cls_loss: 0.0650  \n",
      "<<<iteration:[40/117] - total_loss: 1.9821  obj_loss: 0.1552  noobj_loss: 0.2492  bbox_loss: 0.3237  cls_loss: 0.0837  \n",
      "<<<iteration:[60/117] - total_loss: 2.2574  obj_loss: 0.0625  noobj_loss: 0.2514  bbox_loss: 0.3997  cls_loss: 0.0708  \n",
      "<<<iteration:[80/117] - total_loss: 1.9982  obj_loss: 0.1009  noobj_loss: 0.2821  bbox_loss: 0.3413  cls_loss: 0.0496  \n",
      "<<<iteration:[100/117] - total_loss: 1.6777  obj_loss: 0.0673  noobj_loss: 0.2489  bbox_loss: 0.2879  cls_loss: 0.0464  \n",
      "\n",
      "epoch:27/100 - Train Loss: 1.8139, Val Loss: 6.3735\n",
      "\n",
      "<<<iteration:[20/117] - total_loss: 1.3720  obj_loss: 0.1977  noobj_loss: 0.2578  bbox_loss: 0.2005  cls_loss: 0.0429  \n",
      "<<<iteration:[40/117] - total_loss: 1.5213  obj_loss: 0.1170  noobj_loss: 0.2647  bbox_loss: 0.2456  cls_loss: 0.0438  \n",
      "<<<iteration:[60/117] - total_loss: 2.0121  obj_loss: 0.1061  noobj_loss: 0.2410  bbox_loss: 0.3444  cls_loss: 0.0635  \n",
      "<<<iteration:[80/117] - total_loss: 1.5382  obj_loss: 0.1088  noobj_loss: 0.2380  bbox_loss: 0.2547  cls_loss: 0.0371  \n",
      "<<<iteration:[100/117] - total_loss: 1.4102  obj_loss: 0.0796  noobj_loss: 0.2260  bbox_loss: 0.2339  cls_loss: 0.0482  \n",
      "\n",
      "epoch:28/100 - Train Loss: 1.5527, Val Loss: 6.5735\n",
      "\n",
      "<<<iteration:[20/117] - total_loss: 1.2045  obj_loss: 0.1010  noobj_loss: 0.2405  bbox_loss: 0.1886  cls_loss: 0.0404  \n",
      "<<<iteration:[40/117] - total_loss: 1.6633  obj_loss: 0.1234  noobj_loss: 0.2339  bbox_loss: 0.2761  cls_loss: 0.0424  \n",
      "<<<iteration:[60/117] - total_loss: 1.5557  obj_loss: 0.1837  noobj_loss: 0.2208  bbox_loss: 0.2444  cls_loss: 0.0398  \n",
      "<<<iteration:[80/117] - total_loss: 1.1893  obj_loss: 0.1441  noobj_loss: 0.2297  bbox_loss: 0.1764  cls_loss: 0.0481  \n",
      "<<<iteration:[100/117] - total_loss: 1.9759  obj_loss: 0.1182  noobj_loss: 0.2349  bbox_loss: 0.3371  cls_loss: 0.0550  \n",
      "\n",
      "epoch:29/100 - Train Loss: 1.4863, Val Loss: 6.9896\n",
      "\n",
      "<<<iteration:[20/117] - total_loss: 1.9898  obj_loss: 0.1263  noobj_loss: 0.2435  bbox_loss: 0.3414  cls_loss: 0.0349  \n",
      "<<<iteration:[40/117] - total_loss: 1.6774  obj_loss: 0.1040  noobj_loss: 0.2168  bbox_loss: 0.2807  cls_loss: 0.0615  \n",
      "<<<iteration:[60/117] - total_loss: 1.3203  obj_loss: 0.1466  noobj_loss: 0.2188  bbox_loss: 0.2035  cls_loss: 0.0469  \n",
      "<<<iteration:[80/117] - total_loss: 1.0593  obj_loss: 0.0895  noobj_loss: 0.2077  bbox_loss: 0.1683  cls_loss: 0.0242  \n",
      "<<<iteration:[100/117] - total_loss: 1.3755  obj_loss: 0.0812  noobj_loss: 0.2378  bbox_loss: 0.2271  cls_loss: 0.0399  \n",
      "\n",
      "epoch:30/100 - Train Loss: 1.4429, Val Loss: 6.5494\n",
      "\n",
      "<<<iteration:[20/117] - total_loss: 1.6878  obj_loss: 0.1327  noobj_loss: 0.2160  bbox_loss: 0.2804  cls_loss: 0.0452  \n",
      "<<<iteration:[40/117] - total_loss: 1.3569  obj_loss: 0.0979  noobj_loss: 0.2199  bbox_loss: 0.2214  cls_loss: 0.0423  \n",
      "<<<iteration:[60/117] - total_loss: 1.4297  obj_loss: 0.0936  noobj_loss: 0.2082  bbox_loss: 0.2357  cls_loss: 0.0535  \n",
      "<<<iteration:[80/117] - total_loss: 1.3939  obj_loss: 0.1340  noobj_loss: 0.2200  bbox_loss: 0.2235  cls_loss: 0.0326  \n",
      "<<<iteration:[100/117] - total_loss: 1.7455  obj_loss: 0.1169  noobj_loss: 0.2331  bbox_loss: 0.2937  cls_loss: 0.0436  \n",
      "\n",
      "epoch:31/100 - Train Loss: 1.4195, Val Loss: 6.3966\n",
      "\n",
      "<<<iteration:[20/117] - total_loss: 1.4933  obj_loss: 0.2281  noobj_loss: 0.2398  bbox_loss: 0.2202  cls_loss: 0.0443  \n",
      "<<<iteration:[40/117] - total_loss: 1.0279  obj_loss: 0.1296  noobj_loss: 0.2250  bbox_loss: 0.1505  cls_loss: 0.0331  \n",
      "<<<iteration:[60/117] - total_loss: 1.8661  obj_loss: 0.1135  noobj_loss: 0.2097  bbox_loss: 0.3210  cls_loss: 0.0427  \n",
      "<<<iteration:[80/117] - total_loss: 0.9959  obj_loss: 0.0878  noobj_loss: 0.1993  bbox_loss: 0.1566  cls_loss: 0.0257  \n",
      "<<<iteration:[100/117] - total_loss: 1.2105  obj_loss: 0.1560  noobj_loss: 0.2061  bbox_loss: 0.1817  cls_loss: 0.0429  \n",
      "\n",
      "epoch:32/100 - Train Loss: 1.3156, Val Loss: 6.5914\n",
      "\n",
      "<<<iteration:[20/117] - total_loss: 1.5244  obj_loss: 0.1383  noobj_loss: 0.2065  bbox_loss: 0.2496  cls_loss: 0.0348  \n",
      "<<<iteration:[40/117] - total_loss: 0.8050  obj_loss: 0.1098  noobj_loss: 0.2045  bbox_loss: 0.1134  cls_loss: 0.0262  \n",
      "<<<iteration:[60/117] - total_loss: 1.2623  obj_loss: 0.1692  noobj_loss: 0.2179  bbox_loss: 0.1886  cls_loss: 0.0413  \n",
      "<<<iteration:[80/117] - total_loss: 1.1948  obj_loss: 0.1041  noobj_loss: 0.2015  bbox_loss: 0.1910  cls_loss: 0.0352  \n",
      "<<<iteration:[100/117] - total_loss: 1.7169  obj_loss: 0.1008  noobj_loss: 0.2070  bbox_loss: 0.2946  cls_loss: 0.0394  \n",
      "\n",
      "epoch:33/100 - Train Loss: 1.2695, Val Loss: 6.2943\n",
      "\n",
      "<<<iteration:[20/117] - total_loss: 1.1175  obj_loss: 0.1677  noobj_loss: 0.2211  bbox_loss: 0.1633  cls_loss: 0.0226  \n",
      "<<<iteration:[40/117] - total_loss: 0.7416  obj_loss: 0.1276  noobj_loss: 0.1851  bbox_loss: 0.1007  cls_loss: 0.0182  \n",
      "<<<iteration:[60/117] - total_loss: 1.2639  obj_loss: 0.1489  noobj_loss: 0.1886  bbox_loss: 0.1966  cls_loss: 0.0374  \n",
      "<<<iteration:[80/117] - total_loss: 1.2932  obj_loss: 0.1205  noobj_loss: 0.2079  bbox_loss: 0.2076  cls_loss: 0.0307  \n",
      "<<<iteration:[100/117] - total_loss: 1.5550  obj_loss: 0.2119  noobj_loss: 0.2091  bbox_loss: 0.2404  cls_loss: 0.0364  \n",
      "\n",
      "epoch:34/100 - Train Loss: 1.2073, Val Loss: 5.6990\n",
      "\n",
      "<<<iteration:[20/117] - total_loss: 1.5734  obj_loss: 0.1651  noobj_loss: 0.2190  bbox_loss: 0.2502  cls_loss: 0.0479  \n",
      "<<<iteration:[40/117] - total_loss: 1.3447  obj_loss: 0.1895  noobj_loss: 0.2152  bbox_loss: 0.2042  cls_loss: 0.0265  \n",
      "<<<iteration:[60/117] - total_loss: 0.8268  obj_loss: 0.1927  noobj_loss: 0.2223  bbox_loss: 0.0999  cls_loss: 0.0236  \n",
      "<<<iteration:[80/117] - total_loss: 0.9762  obj_loss: 0.0881  noobj_loss: 0.2118  bbox_loss: 0.1510  cls_loss: 0.0271  \n",
      "<<<iteration:[100/117] - total_loss: 1.0388  obj_loss: 0.1367  noobj_loss: 0.1922  bbox_loss: 0.1561  cls_loss: 0.0253  \n",
      "\n",
      "epoch:35/100 - Train Loss: 1.1425, Val Loss: 6.3969\n",
      "\n",
      "<<<iteration:[20/117] - total_loss: 1.2601  obj_loss: 0.1797  noobj_loss: 0.1980  bbox_loss: 0.1900  cls_loss: 0.0312  \n",
      "<<<iteration:[40/117] - total_loss: 1.2613  obj_loss: 0.1506  noobj_loss: 0.1973  bbox_loss: 0.1967  cls_loss: 0.0287  \n",
      "<<<iteration:[60/117] - total_loss: 0.9910  obj_loss: 0.1589  noobj_loss: 0.1980  bbox_loss: 0.1437  cls_loss: 0.0145  \n",
      "<<<iteration:[80/117] - total_loss: 0.9913  obj_loss: 0.1812  noobj_loss: 0.2031  bbox_loss: 0.1376  cls_loss: 0.0204  \n",
      "<<<iteration:[100/117] - total_loss: 0.9724  obj_loss: 0.1474  noobj_loss: 0.1983  bbox_loss: 0.1409  cls_loss: 0.0213  \n",
      "\n",
      "epoch:36/100 - Train Loss: 1.1342, Val Loss: 6.2994\n",
      "\n",
      "<<<iteration:[20/117] - total_loss: 1.1613  obj_loss: 0.1919  noobj_loss: 0.2054  bbox_loss: 0.1697  cls_loss: 0.0179  \n",
      "<<<iteration:[40/117] - total_loss: 1.1157  obj_loss: 0.1973  noobj_loss: 0.1890  bbox_loss: 0.1609  cls_loss: 0.0193  \n",
      "<<<iteration:[60/117] - total_loss: 1.1930  obj_loss: 0.1264  noobj_loss: 0.1878  bbox_loss: 0.1900  cls_loss: 0.0227  \n",
      "<<<iteration:[80/117] - total_loss: 1.2763  obj_loss: 0.1515  noobj_loss: 0.1934  bbox_loss: 0.1987  cls_loss: 0.0345  \n",
      "<<<iteration:[100/117] - total_loss: 1.2555  obj_loss: 0.1483  noobj_loss: 0.2068  bbox_loss: 0.1947  cls_loss: 0.0303  \n",
      "\n",
      "epoch:37/100 - Train Loss: 1.1408, Val Loss: 6.5829\n",
      "\n",
      "<<<iteration:[20/117] - total_loss: 1.3817  obj_loss: 0.1540  noobj_loss: 0.1963  bbox_loss: 0.2206  cls_loss: 0.0267  \n",
      "<<<iteration:[40/117] - total_loss: 1.4533  obj_loss: 0.1956  noobj_loss: 0.1952  bbox_loss: 0.2278  cls_loss: 0.0212  \n",
      "<<<iteration:[60/117] - total_loss: 1.1905  obj_loss: 0.1675  noobj_loss: 0.1918  bbox_loss: 0.1796  cls_loss: 0.0294  \n",
      "<<<iteration:[80/117] - total_loss: 1.1381  obj_loss: 0.1604  noobj_loss: 0.2003  bbox_loss: 0.1711  cls_loss: 0.0220  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<<<iteration:[100/117] - total_loss: 1.2296  obj_loss: 0.1446  noobj_loss: 0.2022  bbox_loss: 0.1904  cls_loss: 0.0318  \n",
      "\n",
      "epoch:38/100 - Train Loss: 1.2367, Val Loss: 6.1907\n",
      "\n",
      "<<<iteration:[20/117] - total_loss: 1.0579  obj_loss: 0.1471  noobj_loss: 0.1881  bbox_loss: 0.1596  cls_loss: 0.0189  \n",
      "<<<iteration:[40/117] - total_loss: 1.3691  obj_loss: 0.1082  noobj_loss: 0.1940  bbox_loss: 0.2271  cls_loss: 0.0281  \n",
      "<<<iteration:[60/117] - total_loss: 1.2917  obj_loss: 0.1204  noobj_loss: 0.1963  bbox_loss: 0.2094  cls_loss: 0.0260  \n",
      "<<<iteration:[80/117] - total_loss: 0.9130  obj_loss: 0.1447  noobj_loss: 0.2101  bbox_loss: 0.1273  cls_loss: 0.0266  \n",
      "<<<iteration:[100/117] - total_loss: 1.4316  obj_loss: 0.1403  noobj_loss: 0.1875  bbox_loss: 0.2327  cls_loss: 0.0339  \n",
      "\n",
      "epoch:39/100 - Train Loss: 1.1788, Val Loss: 5.7718\n",
      "\n",
      "<<<iteration:[20/117] - total_loss: 1.0196  obj_loss: 0.1972  noobj_loss: 0.1988  bbox_loss: 0.1392  cls_loss: 0.0268  \n",
      "<<<iteration:[40/117] - total_loss: 1.3537  obj_loss: 0.2279  noobj_loss: 0.2026  bbox_loss: 0.2018  cls_loss: 0.0153  \n",
      "<<<iteration:[60/117] - total_loss: 0.9930  obj_loss: 0.1561  noobj_loss: 0.2041  bbox_loss: 0.1433  cls_loss: 0.0183  \n",
      "<<<iteration:[80/117] - total_loss: 1.0406  obj_loss: 0.1848  noobj_loss: 0.1908  bbox_loss: 0.1478  cls_loss: 0.0212  \n",
      "<<<iteration:[100/117] - total_loss: 1.1567  obj_loss: 0.1258  noobj_loss: 0.1898  bbox_loss: 0.1826  cls_loss: 0.0229  \n",
      "\n",
      "epoch:40/100 - Train Loss: 1.1265, Val Loss: 5.7939\n",
      "\n",
      "<<<iteration:[20/117] - total_loss: 0.9543  obj_loss: 0.1968  noobj_loss: 0.1895  bbox_loss: 0.1292  cls_loss: 0.0165  \n",
      "<<<iteration:[40/117] - total_loss: 1.1528  obj_loss: 0.1654  noobj_loss: 0.1794  bbox_loss: 0.1766  cls_loss: 0.0146  \n",
      "<<<iteration:[60/117] - total_loss: 1.2542  obj_loss: 0.2105  noobj_loss: 0.1764  bbox_loss: 0.1865  cls_loss: 0.0230  \n",
      "<<<iteration:[80/117] - total_loss: 1.1627  obj_loss: 0.1261  noobj_loss: 0.1902  bbox_loss: 0.1841  cls_loss: 0.0208  \n",
      "<<<iteration:[100/117] - total_loss: 0.9101  obj_loss: 0.2172  noobj_loss: 0.1903  bbox_loss: 0.1151  cls_loss: 0.0222  \n",
      "\n",
      "epoch:41/100 - Train Loss: 1.0623, Val Loss: 5.8751\n",
      "\n",
      "<<<iteration:[20/117] - total_loss: 1.0025  obj_loss: 0.2745  noobj_loss: 0.2165  bbox_loss: 0.1210  cls_loss: 0.0149  \n",
      "<<<iteration:[40/117] - total_loss: 0.9089  obj_loss: 0.1725  noobj_loss: 0.1822  bbox_loss: 0.1253  cls_loss: 0.0187  \n",
      "<<<iteration:[60/117] - total_loss: 1.3419  obj_loss: 0.1401  noobj_loss: 0.1882  bbox_loss: 0.2162  cls_loss: 0.0267  \n",
      "<<<iteration:[80/117] - total_loss: 0.9286  obj_loss: 0.1956  noobj_loss: 0.1787  bbox_loss: 0.1251  cls_loss: 0.0179  \n",
      "<<<iteration:[100/117] - total_loss: 1.1888  obj_loss: 0.0884  noobj_loss: 0.1827  bbox_loss: 0.1993  cls_loss: 0.0128  \n",
      "\n",
      "epoch:42/100 - Train Loss: 1.1997, Val Loss: 6.8975\n",
      "\n",
      "<<<iteration:[20/117] - total_loss: 0.8454  obj_loss: 0.1172  noobj_loss: 0.1846  bbox_loss: 0.1233  cls_loss: 0.0192  \n",
      "<<<iteration:[40/117] - total_loss: 1.8215  obj_loss: 0.1889  noobj_loss: 0.1836  bbox_loss: 0.3030  cls_loss: 0.0259  \n",
      "<<<iteration:[60/117] - total_loss: 1.4982  obj_loss: 0.0718  noobj_loss: 0.1840  bbox_loss: 0.2600  cls_loss: 0.0341  \n",
      "<<<iteration:[80/117] - total_loss: 0.9355  obj_loss: 0.1555  noobj_loss: 0.1876  bbox_loss: 0.1325  cls_loss: 0.0240  \n",
      "<<<iteration:[100/117] - total_loss: 1.1103  obj_loss: 0.0981  noobj_loss: 0.1676  bbox_loss: 0.1806  cls_loss: 0.0255  \n",
      "\n",
      "epoch:43/100 - Train Loss: 1.2238, Val Loss: 5.8502\n",
      "\n",
      "<<<iteration:[20/117] - total_loss: 1.2081  obj_loss: 0.1625  noobj_loss: 0.1772  bbox_loss: 0.1870  cls_loss: 0.0222  \n",
      "<<<iteration:[40/117] - total_loss: 1.0516  obj_loss: 0.1072  noobj_loss: 0.1700  bbox_loss: 0.1685  cls_loss: 0.0167  \n",
      "<<<iteration:[60/117] - total_loss: 1.1056  obj_loss: 0.1355  noobj_loss: 0.1680  bbox_loss: 0.1721  cls_loss: 0.0253  \n",
      "<<<iteration:[80/117] - total_loss: 0.8987  obj_loss: 0.1702  noobj_loss: 0.1831  bbox_loss: 0.1230  cls_loss: 0.0219  \n",
      "<<<iteration:[100/117] - total_loss: 0.8916  obj_loss: 0.1894  noobj_loss: 0.1762  bbox_loss: 0.1189  cls_loss: 0.0197  \n",
      "\n",
      "epoch:44/100 - Train Loss: 1.0261, Val Loss: 5.7817\n",
      "\n",
      "<<<iteration:[20/117] - total_loss: 1.0658  obj_loss: 0.1911  noobj_loss: 0.1909  bbox_loss: 0.1522  cls_loss: 0.0182  \n",
      "<<<iteration:[40/117] - total_loss: 1.1037  obj_loss: 0.1246  noobj_loss: 0.1786  bbox_loss: 0.1743  cls_loss: 0.0181  \n",
      "<<<iteration:[60/117] - total_loss: 1.1357  obj_loss: 0.1356  noobj_loss: 0.1715  bbox_loss: 0.1786  cls_loss: 0.0213  \n",
      "<<<iteration:[80/117] - total_loss: 0.9661  obj_loss: 0.1272  noobj_loss: 0.1742  bbox_loss: 0.1478  cls_loss: 0.0126  \n",
      "<<<iteration:[100/117] - total_loss: 0.8610  obj_loss: 0.1582  noobj_loss: 0.1632  bbox_loss: 0.1206  cls_loss: 0.0181  \n",
      "\n",
      "epoch:45/100 - Train Loss: 1.0254, Val Loss: 6.2361\n",
      "\n",
      "<<<iteration:[20/117] - total_loss: 1.0687  obj_loss: 0.1798  noobj_loss: 0.1751  bbox_loss: 0.1567  cls_loss: 0.0178  \n",
      "<<<iteration:[40/117] - total_loss: 1.1475  obj_loss: 0.1683  noobj_loss: 0.1858  bbox_loss: 0.1740  cls_loss: 0.0163  \n",
      "<<<iteration:[60/117] - total_loss: 1.0325  obj_loss: 0.1412  noobj_loss: 0.1652  bbox_loss: 0.1577  cls_loss: 0.0200  \n",
      "<<<iteration:[80/117] - total_loss: 1.0538  obj_loss: 0.0720  noobj_loss: 0.1706  bbox_loss: 0.1759  cls_loss: 0.0169  \n",
      "<<<iteration:[100/117] - total_loss: 0.9332  obj_loss: 0.1573  noobj_loss: 0.1666  bbox_loss: 0.1358  cls_loss: 0.0138  \n",
      "\n",
      "epoch:46/100 - Train Loss: 1.0401, Val Loss: 5.8249\n",
      "\n",
      "<<<iteration:[20/117] - total_loss: 0.9541  obj_loss: 0.1429  noobj_loss: 0.1709  bbox_loss: 0.1429  cls_loss: 0.0111  \n",
      "<<<iteration:[40/117] - total_loss: 1.0799  obj_loss: 0.1363  noobj_loss: 0.1630  bbox_loss: 0.1701  cls_loss: 0.0113  \n",
      "<<<iteration:[60/117] - total_loss: 1.1622  obj_loss: 0.1785  noobj_loss: 0.1670  bbox_loss: 0.1752  cls_loss: 0.0242  \n",
      "<<<iteration:[80/117] - total_loss: 0.9707  obj_loss: 0.1233  noobj_loss: 0.1591  bbox_loss: 0.1505  cls_loss: 0.0153  \n",
      "<<<iteration:[100/117] - total_loss: 0.8153  obj_loss: 0.1099  noobj_loss: 0.1675  bbox_loss: 0.1215  cls_loss: 0.0142  \n",
      "\n",
      "epoch:47/100 - Train Loss: 1.0119, Val Loss: 5.7809\n",
      "\n",
      "<<<iteration:[20/117] - total_loss: 1.2106  obj_loss: 0.2501  noobj_loss: 0.1878  bbox_loss: 0.1700  cls_loss: 0.0167  \n",
      "<<<iteration:[40/117] - total_loss: 0.9846  obj_loss: 0.1366  noobj_loss: 0.1713  bbox_loss: 0.1496  cls_loss: 0.0143  \n",
      "<<<iteration:[60/117] - total_loss: 1.2735  obj_loss: 0.1588  noobj_loss: 0.1739  bbox_loss: 0.2031  cls_loss: 0.0123  \n",
      "<<<iteration:[80/117] - total_loss: 0.7730  obj_loss: 0.0958  noobj_loss: 0.1608  bbox_loss: 0.1161  cls_loss: 0.0164  \n",
      "<<<iteration:[100/117] - total_loss: 0.8769  obj_loss: 0.1624  noobj_loss: 0.1697  bbox_loss: 0.1223  cls_loss: 0.0179  \n",
      "\n",
      "epoch:48/100 - Train Loss: 1.0040, Val Loss: 5.8554\n",
      "\n",
      "<<<iteration:[20/117] - total_loss: 1.2097  obj_loss: 0.1214  noobj_loss: 0.1635  bbox_loss: 0.1974  cls_loss: 0.0198  \n",
      "<<<iteration:[40/117] - total_loss: 0.9501  obj_loss: 0.1912  noobj_loss: 0.1537  bbox_loss: 0.1341  cls_loss: 0.0117  \n",
      "<<<iteration:[60/117] - total_loss: 1.0820  obj_loss: 0.1489  noobj_loss: 0.1672  bbox_loss: 0.1663  cls_loss: 0.0179  \n",
      "<<<iteration:[80/117] - total_loss: 0.9870  obj_loss: 0.1747  noobj_loss: 0.1826  bbox_loss: 0.1416  cls_loss: 0.0133  \n",
      "<<<iteration:[100/117] - total_loss: 1.1962  obj_loss: 0.1553  noobj_loss: 0.1591  bbox_loss: 0.1894  cls_loss: 0.0145  \n",
      "\n",
      "epoch:49/100 - Train Loss: 1.0517, Val Loss: 5.8363\n",
      "\n",
      "<<<iteration:[20/117] - total_loss: 0.8625  obj_loss: 0.1572  noobj_loss: 0.1574  bbox_loss: 0.1226  cls_loss: 0.0134  \n",
      "<<<iteration:[40/117] - total_loss: 1.3172  obj_loss: 0.1204  noobj_loss: 0.1573  bbox_loss: 0.2208  cls_loss: 0.0141  \n",
      "<<<iteration:[60/117] - total_loss: 1.0798  obj_loss: 0.1557  noobj_loss: 0.1556  bbox_loss: 0.1666  cls_loss: 0.0132  \n",
      "<<<iteration:[80/117] - total_loss: 0.7459  obj_loss: 0.1852  noobj_loss: 0.1710  bbox_loss: 0.0928  cls_loss: 0.0111  \n",
      "<<<iteration:[100/117] - total_loss: 1.0534  obj_loss: 0.1952  noobj_loss: 0.1675  bbox_loss: 0.1516  cls_loss: 0.0166  \n",
      "\n",
      "epoch:50/100 - Train Loss: 0.9663, Val Loss: 6.1123\n",
      "\n",
      "<<<iteration:[20/117] - total_loss: 0.9252  obj_loss: 0.1337  noobj_loss: 0.1601  bbox_loss: 0.1392  cls_loss: 0.0155  \n",
      "<<<iteration:[40/117] - total_loss: 0.7193  obj_loss: 0.2246  noobj_loss: 0.1633  bbox_loss: 0.0807  cls_loss: 0.0097  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<<<iteration:[60/117] - total_loss: 0.8125  obj_loss: 0.2129  noobj_loss: 0.1732  bbox_loss: 0.1007  cls_loss: 0.0096  \n",
      "<<<iteration:[80/117] - total_loss: 1.1850  obj_loss: 0.1135  noobj_loss: 0.1698  bbox_loss: 0.1939  cls_loss: 0.0173  \n",
      "<<<iteration:[100/117] - total_loss: 1.4493  obj_loss: 0.1164  noobj_loss: 0.1668  bbox_loss: 0.2475  cls_loss: 0.0118  \n",
      "\n",
      "epoch:51/100 - Train Loss: 1.0428, Val Loss: 5.7554\n",
      "\n",
      "<<<iteration:[20/117] - total_loss: 0.8622  obj_loss: 0.1916  noobj_loss: 0.1549  bbox_loss: 0.1159  cls_loss: 0.0135  \n",
      "<<<iteration:[40/117] - total_loss: 0.9985  obj_loss: 0.1453  noobj_loss: 0.1542  bbox_loss: 0.1525  cls_loss: 0.0135  \n",
      "<<<iteration:[60/117] - total_loss: 0.5762  obj_loss: 0.1430  noobj_loss: 0.1516  bbox_loss: 0.0694  cls_loss: 0.0107  \n",
      "<<<iteration:[80/117] - total_loss: 1.0699  obj_loss: 0.1549  noobj_loss: 0.1594  bbox_loss: 0.1645  cls_loss: 0.0129  \n",
      "<<<iteration:[100/117] - total_loss: 0.7926  obj_loss: 0.1676  noobj_loss: 0.1624  bbox_loss: 0.1070  cls_loss: 0.0088  \n",
      "\n",
      "epoch:52/100 - Train Loss: 0.8943, Val Loss: 5.6984\n",
      "\n",
      "<<<iteration:[20/117] - total_loss: 0.8235  obj_loss: 0.1868  noobj_loss: 0.1559  bbox_loss: 0.1093  cls_loss: 0.0121  \n",
      "<<<iteration:[40/117] - total_loss: 0.9962  obj_loss: 0.1354  noobj_loss: 0.1508  bbox_loss: 0.1552  cls_loss: 0.0096  \n",
      "<<<iteration:[60/117] - total_loss: 1.1140  obj_loss: 0.1799  noobj_loss: 0.1694  bbox_loss: 0.1665  cls_loss: 0.0170  \n",
      "<<<iteration:[80/117] - total_loss: 0.7017  obj_loss: 0.1588  noobj_loss: 0.1480  bbox_loss: 0.0920  cls_loss: 0.0090  \n",
      "<<<iteration:[100/117] - total_loss: 0.7348  obj_loss: 0.1637  noobj_loss: 0.1565  bbox_loss: 0.0965  cls_loss: 0.0105  \n",
      "\n",
      "epoch:53/100 - Train Loss: 0.8383, Val Loss: 5.9373\n",
      "\n",
      "<<<iteration:[20/117] - total_loss: 0.6470  obj_loss: 0.1663  noobj_loss: 0.1673  bbox_loss: 0.0773  cls_loss: 0.0106  \n",
      "<<<iteration:[40/117] - total_loss: 0.7635  obj_loss: 0.1731  noobj_loss: 0.1641  bbox_loss: 0.0997  cls_loss: 0.0101  \n",
      "<<<iteration:[60/117] - total_loss: 0.8246  obj_loss: 0.1869  noobj_loss: 0.1643  bbox_loss: 0.1087  cls_loss: 0.0118  \n",
      "<<<iteration:[80/117] - total_loss: 0.8756  obj_loss: 0.1708  noobj_loss: 0.1603  bbox_loss: 0.1226  cls_loss: 0.0117  \n",
      "<<<iteration:[100/117] - total_loss: 0.8024  obj_loss: 0.2031  noobj_loss: 0.1849  bbox_loss: 0.0997  cls_loss: 0.0083  \n",
      "\n",
      "epoch:54/100 - Train Loss: 0.7622, Val Loss: 5.8462\n",
      "\n",
      "<<<iteration:[20/117] - total_loss: 0.7178  obj_loss: 0.2451  noobj_loss: 0.1781  bbox_loss: 0.0757  cls_loss: 0.0051  \n",
      "<<<iteration:[40/117] - total_loss: 0.8988  obj_loss: 0.1868  noobj_loss: 0.1710  bbox_loss: 0.1240  cls_loss: 0.0065  \n",
      "<<<iteration:[60/117] - total_loss: 0.9238  obj_loss: 0.2012  noobj_loss: 0.1731  bbox_loss: 0.1248  cls_loss: 0.0121  \n",
      "<<<iteration:[80/117] - total_loss: 0.6691  obj_loss: 0.2162  noobj_loss: 0.1646  bbox_loss: 0.0716  cls_loss: 0.0128  \n",
      "<<<iteration:[100/117] - total_loss: 0.6890  obj_loss: 0.1884  noobj_loss: 0.1701  bbox_loss: 0.0810  cls_loss: 0.0105  \n",
      "\n",
      "epoch:55/100 - Train Loss: 0.8068, Val Loss: 5.8699\n",
      "\n",
      "<<<iteration:[20/117] - total_loss: 0.6558  obj_loss: 0.2394  noobj_loss: 0.1862  bbox_loss: 0.0633  cls_loss: 0.0068  \n",
      "<<<iteration:[40/117] - total_loss: 0.9049  obj_loss: 0.1255  noobj_loss: 0.1675  bbox_loss: 0.1371  cls_loss: 0.0102  \n",
      "<<<iteration:[60/117] - total_loss: 0.9658  obj_loss: 0.1513  noobj_loss: 0.1409  bbox_loss: 0.1472  cls_loss: 0.0080  \n",
      "<<<iteration:[80/117] - total_loss: 0.7430  obj_loss: 0.1607  noobj_loss: 0.1524  bbox_loss: 0.0995  cls_loss: 0.0088  \n",
      "<<<iteration:[100/117] - total_loss: 0.8927  obj_loss: 0.1235  noobj_loss: 0.1405  bbox_loss: 0.1376  cls_loss: 0.0111  \n",
      "\n",
      "epoch:56/100 - Train Loss: 0.8252, Val Loss: 6.2012\n",
      "\n",
      "<<<iteration:[20/117] - total_loss: 0.7464  obj_loss: 0.2068  noobj_loss: 0.1532  bbox_loss: 0.0909  cls_loss: 0.0086  \n",
      "<<<iteration:[40/117] - total_loss: 0.7254  obj_loss: 0.1567  noobj_loss: 0.1543  bbox_loss: 0.0972  cls_loss: 0.0056  \n",
      "<<<iteration:[60/117] - total_loss: 0.7393  obj_loss: 0.1497  noobj_loss: 0.1485  bbox_loss: 0.1007  cls_loss: 0.0116  \n",
      "<<<iteration:[80/117] - total_loss: 0.9291  obj_loss: 0.2191  noobj_loss: 0.1557  bbox_loss: 0.1249  cls_loss: 0.0075  \n",
      "<<<iteration:[100/117] - total_loss: 0.7934  obj_loss: 0.2599  noobj_loss: 0.1813  bbox_loss: 0.0863  cls_loss: 0.0113  \n",
      "\n",
      "epoch:57/100 - Train Loss: 0.8170, Val Loss: 5.9929\n",
      "\n",
      "<<<iteration:[20/117] - total_loss: 0.8825  obj_loss: 0.1993  noobj_loss: 0.1547  bbox_loss: 0.1197  cls_loss: 0.0076  \n",
      "<<<iteration:[40/117] - total_loss: 0.6544  obj_loss: 0.1982  noobj_loss: 0.1642  bbox_loss: 0.0732  cls_loss: 0.0079  \n",
      "<<<iteration:[60/117] - total_loss: 0.8291  obj_loss: 0.1425  noobj_loss: 0.1530  bbox_loss: 0.1209  cls_loss: 0.0057  \n",
      "<<<iteration:[80/117] - total_loss: 0.6360  obj_loss: 0.1422  noobj_loss: 0.1547  bbox_loss: 0.0816  cls_loss: 0.0082  \n",
      "<<<iteration:[100/117] - total_loss: 0.5831  obj_loss: 0.1355  noobj_loss: 0.1575  bbox_loss: 0.0719  cls_loss: 0.0094  \n",
      "\n",
      "epoch:58/100 - Train Loss: 0.7327, Val Loss: 5.3976\n",
      "\n",
      "<<<iteration:[20/117] - total_loss: 0.8898  obj_loss: 0.2309  noobj_loss: 0.1620  bbox_loss: 0.1144  cls_loss: 0.0060  \n",
      "<<<iteration:[40/117] - total_loss: 0.7446  obj_loss: 0.1983  noobj_loss: 0.1607  bbox_loss: 0.0911  cls_loss: 0.0106  \n",
      "<<<iteration:[60/117] - total_loss: 0.6626  obj_loss: 0.1266  noobj_loss: 0.1358  bbox_loss: 0.0923  cls_loss: 0.0068  \n",
      "<<<iteration:[80/117] - total_loss: 0.5453  obj_loss: 0.2489  noobj_loss: 0.1612  bbox_loss: 0.0416  cls_loss: 0.0076  \n",
      "<<<iteration:[100/117] - total_loss: 0.6856  obj_loss: 0.2210  noobj_loss: 0.1688  bbox_loss: 0.0749  cls_loss: 0.0057  \n",
      "\n",
      "epoch:59/100 - Train Loss: 0.7167, Val Loss: 5.6801\n",
      "\n",
      "<<<iteration:[20/117] - total_loss: 1.0778  obj_loss: 0.1696  noobj_loss: 0.1748  bbox_loss: 0.1625  cls_loss: 0.0085  \n",
      "<<<iteration:[40/117] - total_loss: 0.8252  obj_loss: 0.1778  noobj_loss: 0.1629  bbox_loss: 0.1122  cls_loss: 0.0050  \n",
      "<<<iteration:[60/117] - total_loss: 0.7857  obj_loss: 0.2217  noobj_loss: 0.1643  bbox_loss: 0.0936  cls_loss: 0.0138  \n",
      "<<<iteration:[80/117] - total_loss: 0.7224  obj_loss: 0.1349  noobj_loss: 0.1457  bbox_loss: 0.1016  cls_loss: 0.0067  \n",
      "<<<iteration:[100/117] - total_loss: 0.6678  obj_loss: 0.1638  noobj_loss: 0.1495  bbox_loss: 0.0846  cls_loss: 0.0065  \n",
      "\n",
      "epoch:60/100 - Train Loss: 0.7814, Val Loss: 5.7374\n",
      "\n",
      "<<<iteration:[20/117] - total_loss: 0.7133  obj_loss: 0.2641  noobj_loss: 0.1568  bbox_loss: 0.0734  cls_loss: 0.0039  \n",
      "<<<iteration:[40/117] - total_loss: 0.7690  obj_loss: 0.2192  noobj_loss: 0.1654  bbox_loss: 0.0915  cls_loss: 0.0095  \n",
      "<<<iteration:[60/117] - total_loss: 0.7708  obj_loss: 0.1614  noobj_loss: 0.1581  bbox_loss: 0.1050  cls_loss: 0.0054  \n",
      "<<<iteration:[80/117] - total_loss: 0.8784  obj_loss: 0.2094  noobj_loss: 0.1718  bbox_loss: 0.1158  cls_loss: 0.0042  \n",
      "<<<iteration:[100/117] - total_loss: 1.0200  obj_loss: 0.2418  noobj_loss: 0.1836  bbox_loss: 0.1357  cls_loss: 0.0081  \n",
      "\n",
      "epoch:61/100 - Train Loss: 0.8836, Val Loss: 5.5890\n",
      "\n",
      "<<<iteration:[20/117] - total_loss: 0.7312  obj_loss: 0.1563  noobj_loss: 0.1483  bbox_loss: 0.0985  cls_loss: 0.0083  \n",
      "<<<iteration:[40/117] - total_loss: 0.5718  obj_loss: 0.1277  noobj_loss: 0.1298  bbox_loss: 0.0745  cls_loss: 0.0066  \n",
      "<<<iteration:[60/117] - total_loss: 0.6031  obj_loss: 0.2332  noobj_loss: 0.1464  bbox_loss: 0.0581  cls_loss: 0.0063  \n",
      "<<<iteration:[80/117] - total_loss: 0.8778  obj_loss: 0.1877  noobj_loss: 0.1522  bbox_loss: 0.1207  cls_loss: 0.0107  \n",
      "<<<iteration:[100/117] - total_loss: 0.7534  obj_loss: 0.1672  noobj_loss: 0.1552  bbox_loss: 0.1002  cls_loss: 0.0078  \n",
      "\n",
      "epoch:62/100 - Train Loss: 0.7356, Val Loss: 5.9147\n",
      "\n",
      "<<<iteration:[20/117] - total_loss: 0.9617  obj_loss: 0.1621  noobj_loss: 0.1279  bbox_loss: 0.1455  cls_loss: 0.0079  \n",
      "<<<iteration:[40/117] - total_loss: 0.9035  obj_loss: 0.1161  noobj_loss: 0.1336  bbox_loss: 0.1427  cls_loss: 0.0073  \n",
      "<<<iteration:[60/117] - total_loss: 0.4673  obj_loss: 0.1328  noobj_loss: 0.1284  bbox_loss: 0.0526  cls_loss: 0.0076  \n",
      "<<<iteration:[80/117] - total_loss: 0.5799  obj_loss: 0.1116  noobj_loss: 0.1358  bbox_loss: 0.0783  cls_loss: 0.0090  \n",
      "<<<iteration:[100/117] - total_loss: 0.5606  obj_loss: 0.2121  noobj_loss: 0.1511  bbox_loss: 0.0536  cls_loss: 0.0052  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "epoch:63/100 - Train Loss: 0.6796, Val Loss: 5.5123\n",
      "\n",
      "<<<iteration:[20/117] - total_loss: 0.7354  obj_loss: 0.2151  noobj_loss: 0.1696  bbox_loss: 0.0858  cls_loss: 0.0064  \n",
      "<<<iteration:[40/117] - total_loss: 0.4963  obj_loss: 0.1480  noobj_loss: 0.1504  bbox_loss: 0.0541  cls_loss: 0.0024  \n",
      "<<<iteration:[60/117] - total_loss: 0.7263  obj_loss: 0.1580  noobj_loss: 0.1396  bbox_loss: 0.0983  cls_loss: 0.0070  \n",
      "<<<iteration:[80/117] - total_loss: 0.7260  obj_loss: 0.1826  noobj_loss: 0.1435  bbox_loss: 0.0924  cls_loss: 0.0098  \n",
      "<<<iteration:[100/117] - total_loss: 0.7226  obj_loss: 0.1338  noobj_loss: 0.1438  bbox_loss: 0.1025  cls_loss: 0.0042  \n",
      "\n",
      "epoch:64/100 - Train Loss: 0.6918, Val Loss: 5.7459\n",
      "\n",
      "<<<iteration:[20/117] - total_loss: 0.9785  obj_loss: 0.2256  noobj_loss: 0.1630  bbox_loss: 0.1328  cls_loss: 0.0072  \n",
      "<<<iteration:[40/117] - total_loss: 0.6957  obj_loss: 0.1606  noobj_loss: 0.1399  bbox_loss: 0.0919  cls_loss: 0.0055  \n",
      "<<<iteration:[60/117] - total_loss: 0.7937  obj_loss: 0.1567  noobj_loss: 0.1550  bbox_loss: 0.1107  cls_loss: 0.0060  \n",
      "<<<iteration:[80/117] - total_loss: 0.5937  obj_loss: 0.0637  noobj_loss: 0.1400  bbox_loss: 0.0911  cls_loss: 0.0043  \n",
      "<<<iteration:[100/117] - total_loss: 0.4494  obj_loss: 0.1586  noobj_loss: 0.1185  bbox_loss: 0.0447  cls_loss: 0.0082  \n",
      "\n",
      "epoch:65/100 - Train Loss: 0.7065, Val Loss: 5.5479\n",
      "\n",
      "<<<iteration:[20/117] - total_loss: 0.8439  obj_loss: 0.2465  noobj_loss: 0.1553  bbox_loss: 0.1022  cls_loss: 0.0088  \n",
      "<<<iteration:[40/117] - total_loss: 0.6004  obj_loss: 0.2118  noobj_loss: 0.1660  bbox_loss: 0.0605  cls_loss: 0.0032  \n",
      "<<<iteration:[60/117] - total_loss: 0.5831  obj_loss: 0.1696  noobj_loss: 0.1616  bbox_loss: 0.0656  cls_loss: 0.0045  \n",
      "<<<iteration:[80/117] - total_loss: 0.7943  obj_loss: 0.1780  noobj_loss: 0.1359  bbox_loss: 0.1086  cls_loss: 0.0055  \n",
      "<<<iteration:[100/117] - total_loss: 0.5620  obj_loss: 0.1841  noobj_loss: 0.1478  bbox_loss: 0.0596  cls_loss: 0.0058  \n",
      "\n",
      "epoch:66/100 - Train Loss: 0.6600, Val Loss: 5.8715\n",
      "\n",
      "<<<iteration:[20/117] - total_loss: 0.6299  obj_loss: 0.1834  noobj_loss: 0.1368  bbox_loss: 0.0749  cls_loss: 0.0036  \n",
      "<<<iteration:[40/117] - total_loss: 0.5577  obj_loss: 0.2215  noobj_loss: 0.1678  bbox_loss: 0.0486  cls_loss: 0.0093  \n",
      "<<<iteration:[60/117] - total_loss: 0.6734  obj_loss: 0.2060  noobj_loss: 0.1622  bbox_loss: 0.0760  cls_loss: 0.0063  \n",
      "<<<iteration:[80/117] - total_loss: 0.6057  obj_loss: 0.2005  noobj_loss: 0.1748  bbox_loss: 0.0628  cls_loss: 0.0038  \n",
      "<<<iteration:[100/117] - total_loss: 0.7369  obj_loss: 0.1484  noobj_loss: 0.1468  bbox_loss: 0.1022  cls_loss: 0.0040  \n",
      "\n",
      "epoch:67/100 - Train Loss: 0.6478, Val Loss: 5.5275\n",
      "\n",
      "<<<iteration:[20/117] - total_loss: 0.6057  obj_loss: 0.1463  noobj_loss: 0.1157  bbox_loss: 0.0794  cls_loss: 0.0046  \n",
      "<<<iteration:[40/117] - total_loss: 0.7477  obj_loss: 0.1240  noobj_loss: 0.1210  bbox_loss: 0.1115  cls_loss: 0.0057  \n",
      "<<<iteration:[60/117] - total_loss: 0.8798  obj_loss: 0.1286  noobj_loss: 0.1346  bbox_loss: 0.1360  cls_loss: 0.0037  \n",
      "<<<iteration:[80/117] - total_loss: 0.5855  obj_loss: 0.1580  noobj_loss: 0.1353  bbox_loss: 0.0706  cls_loss: 0.0070  \n",
      "<<<iteration:[100/117] - total_loss: 0.6372  obj_loss: 0.1884  noobj_loss: 0.1421  bbox_loss: 0.0745  cls_loss: 0.0052  \n",
      "\n",
      "epoch:68/100 - Train Loss: 0.6654, Val Loss: 5.7229\n",
      "\n",
      "<<<iteration:[20/117] - total_loss: 0.7927  obj_loss: 0.1773  noobj_loss: 0.1392  bbox_loss: 0.1081  cls_loss: 0.0054  \n",
      "<<<iteration:[40/117] - total_loss: 0.6427  obj_loss: 0.1885  noobj_loss: 0.1322  bbox_loss: 0.0771  cls_loss: 0.0028  \n",
      "<<<iteration:[60/117] - total_loss: 0.8522  obj_loss: 0.1652  noobj_loss: 0.1372  bbox_loss: 0.1226  cls_loss: 0.0055  \n",
      "<<<iteration:[80/117] - total_loss: 0.5124  obj_loss: 0.1357  noobj_loss: 0.1262  bbox_loss: 0.0618  cls_loss: 0.0047  \n",
      "<<<iteration:[100/117] - total_loss: 0.7668  obj_loss: 0.1516  noobj_loss: 0.1407  bbox_loss: 0.1079  cls_loss: 0.0054  \n",
      "\n",
      "epoch:69/100 - Train Loss: 0.6924, Val Loss: 5.3697\n",
      "\n",
      "<<<iteration:[20/117] - total_loss: 0.7172  obj_loss: 0.1873  noobj_loss: 0.1475  bbox_loss: 0.0897  cls_loss: 0.0077  \n",
      "<<<iteration:[40/117] - total_loss: 0.5352  obj_loss: 0.1757  noobj_loss: 0.1464  bbox_loss: 0.0565  cls_loss: 0.0036  \n",
      "<<<iteration:[60/117] - total_loss: 0.5949  obj_loss: 0.1442  noobj_loss: 0.1469  bbox_loss: 0.0747  cls_loss: 0.0036  \n",
      "<<<iteration:[80/117] - total_loss: 0.6180  obj_loss: 0.2262  noobj_loss: 0.1557  bbox_loss: 0.0622  cls_loss: 0.0029  \n",
      "<<<iteration:[100/117] - total_loss: 0.5654  obj_loss: 0.2059  noobj_loss: 0.1512  bbox_loss: 0.0561  cls_loss: 0.0031  \n",
      "\n",
      "epoch:70/100 - Train Loss: 0.6305, Val Loss: 5.3747\n",
      "\n",
      "<<<iteration:[20/117] - total_loss: 0.5819  obj_loss: 0.2486  noobj_loss: 0.1703  bbox_loss: 0.0490  cls_loss: 0.0034  \n",
      "<<<iteration:[40/117] - total_loss: 0.5208  obj_loss: 0.1559  noobj_loss: 0.1366  bbox_loss: 0.0589  cls_loss: 0.0023  \n",
      "<<<iteration:[60/117] - total_loss: 0.6129  obj_loss: 0.2485  noobj_loss: 0.1612  bbox_loss: 0.0558  cls_loss: 0.0049  \n",
      "<<<iteration:[80/117] - total_loss: 0.5517  obj_loss: 0.2022  noobj_loss: 0.1544  bbox_loss: 0.0534  cls_loss: 0.0053  \n",
      "<<<iteration:[100/117] - total_loss: 0.6041  obj_loss: 0.1678  noobj_loss: 0.1515  bbox_loss: 0.0714  cls_loss: 0.0034  \n",
      "\n",
      "epoch:71/100 - Train Loss: 0.6018, Val Loss: 5.3248\n",
      "\n",
      "<<<iteration:[20/117] - total_loss: 0.7832  obj_loss: 0.1966  noobj_loss: 0.1476  bbox_loss: 0.1012  cls_loss: 0.0066  \n",
      "<<<iteration:[40/117] - total_loss: 0.7788  obj_loss: 0.1209  noobj_loss: 0.1192  bbox_loss: 0.1188  cls_loss: 0.0044  \n",
      "<<<iteration:[60/117] - total_loss: 0.4351  obj_loss: 0.1413  noobj_loss: 0.1199  bbox_loss: 0.0462  cls_loss: 0.0027  \n",
      "<<<iteration:[80/117] - total_loss: 0.7492  obj_loss: 0.1633  noobj_loss: 0.1242  bbox_loss: 0.1040  cls_loss: 0.0038  \n",
      "<<<iteration:[100/117] - total_loss: 0.5136  obj_loss: 0.2335  noobj_loss: 0.1311  bbox_loss: 0.0421  cls_loss: 0.0042  \n",
      "\n",
      "epoch:72/100 - Train Loss: 0.6498, Val Loss: 5.4441\n",
      "\n",
      "<<<iteration:[20/117] - total_loss: 0.6192  obj_loss: 0.1515  noobj_loss: 0.1402  bbox_loss: 0.0787  cls_loss: 0.0044  \n",
      "<<<iteration:[40/117] - total_loss: 0.5671  obj_loss: 0.2183  noobj_loss: 0.1440  bbox_loss: 0.0545  cls_loss: 0.0044  \n",
      "<<<iteration:[60/117] - total_loss: 0.5366  obj_loss: 0.1770  noobj_loss: 0.1536  bbox_loss: 0.0556  cls_loss: 0.0050  \n",
      "<<<iteration:[80/117] - total_loss: 0.7088  obj_loss: 0.1097  noobj_loss: 0.1290  bbox_loss: 0.1064  cls_loss: 0.0026  \n",
      "<<<iteration:[100/117] - total_loss: 0.5060  obj_loss: 0.1585  noobj_loss: 0.1376  bbox_loss: 0.0550  cls_loss: 0.0037  \n",
      "\n",
      "epoch:73/100 - Train Loss: 0.5741, Val Loss: 5.7857\n",
      "\n",
      "<<<iteration:[20/117] - total_loss: 0.6080  obj_loss: 0.1993  noobj_loss: 0.1612  bbox_loss: 0.0649  cls_loss: 0.0038  \n",
      "<<<iteration:[40/117] - total_loss: 0.5084  obj_loss: 0.1789  noobj_loss: 0.1327  bbox_loss: 0.0520  cls_loss: 0.0029  \n",
      "<<<iteration:[60/117] - total_loss: 0.7924  obj_loss: 0.1543  noobj_loss: 0.1272  bbox_loss: 0.1141  cls_loss: 0.0042  \n",
      "<<<iteration:[80/117] - total_loss: 0.5581  obj_loss: 0.1984  noobj_loss: 0.1336  bbox_loss: 0.0577  cls_loss: 0.0045  \n",
      "<<<iteration:[100/117] - total_loss: 0.6256  obj_loss: 0.1563  noobj_loss: 0.1341  bbox_loss: 0.0798  cls_loss: 0.0031  \n",
      "\n",
      "epoch:74/100 - Train Loss: 0.6033, Val Loss: 5.6728\n",
      "\n",
      "<<<iteration:[20/117] - total_loss: 0.5490  obj_loss: 0.2157  noobj_loss: 0.1457  bbox_loss: 0.0515  cls_loss: 0.0028  \n",
      "<<<iteration:[40/117] - total_loss: 0.6925  obj_loss: 0.2635  noobj_loss: 0.1641  bbox_loss: 0.0685  cls_loss: 0.0046  \n",
      "<<<iteration:[60/117] - total_loss: 0.6107  obj_loss: 0.2054  noobj_loss: 0.1719  bbox_loss: 0.0633  cls_loss: 0.0027  \n",
      "<<<iteration:[80/117] - total_loss: 0.4834  obj_loss: 0.2402  noobj_loss: 0.1419  bbox_loss: 0.0339  cls_loss: 0.0026  \n",
      "<<<iteration:[100/117] - total_loss: 0.6908  obj_loss: 0.1951  noobj_loss: 0.1682  bbox_loss: 0.0817  cls_loss: 0.0029  \n",
      "\n",
      "epoch:75/100 - Train Loss: 0.6036, Val Loss: 5.5542\n",
      "\n",
      "<<<iteration:[20/117] - total_loss: 0.4676  obj_loss: 0.1735  noobj_loss: 0.1456  bbox_loss: 0.0439  cls_loss: 0.0020  \n",
      "<<<iteration:[40/117] - total_loss: 0.5057  obj_loss: 0.2116  noobj_loss: 0.1424  bbox_loss: 0.0441  cls_loss: 0.0022  \n",
      "<<<iteration:[60/117] - total_loss: 0.5863  obj_loss: 0.2167  noobj_loss: 0.1564  bbox_loss: 0.0574  cls_loss: 0.0044  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<<<iteration:[80/117] - total_loss: 0.5756  obj_loss: 0.1611  noobj_loss: 0.1386  bbox_loss: 0.0685  cls_loss: 0.0027  \n",
      "<<<iteration:[100/117] - total_loss: 0.6822  obj_loss: 0.1850  noobj_loss: 0.1387  bbox_loss: 0.0850  cls_loss: 0.0030  \n",
      "\n",
      "epoch:76/100 - Train Loss: 0.5701, Val Loss: 5.5532\n",
      "\n",
      "<<<iteration:[20/117] - total_loss: 0.5630  obj_loss: 0.2065  noobj_loss: 0.1529  bbox_loss: 0.0553  cls_loss: 0.0033  \n",
      "<<<iteration:[40/117] - total_loss: 0.5807  obj_loss: 0.1241  noobj_loss: 0.1400  bbox_loss: 0.0768  cls_loss: 0.0028  \n",
      "<<<iteration:[60/117] - total_loss: 0.4825  obj_loss: 0.1600  noobj_loss: 0.1147  bbox_loss: 0.0525  cls_loss: 0.0025  \n",
      "<<<iteration:[80/117] - total_loss: 0.5673  obj_loss: 0.2191  noobj_loss: 0.1523  bbox_loss: 0.0533  cls_loss: 0.0054  \n",
      "<<<iteration:[100/117] - total_loss: 0.7660  obj_loss: 0.1953  noobj_loss: 0.1511  bbox_loss: 0.0984  cls_loss: 0.0032  \n",
      "\n",
      "epoch:77/100 - Train Loss: 0.5756, Val Loss: 5.7313\n",
      "\n",
      "<<<iteration:[20/117] - total_loss: 0.3971  obj_loss: 0.1754  noobj_loss: 0.1346  bbox_loss: 0.0304  cls_loss: 0.0027  \n",
      "<<<iteration:[40/117] - total_loss: 0.5656  obj_loss: 0.2210  noobj_loss: 0.1546  bbox_loss: 0.0528  cls_loss: 0.0032  \n",
      "<<<iteration:[60/117] - total_loss: 0.6067  obj_loss: 0.2112  noobj_loss: 0.1552  bbox_loss: 0.0629  cls_loss: 0.0033  \n",
      "<<<iteration:[80/117] - total_loss: 0.7467  obj_loss: 0.1367  noobj_loss: 0.1446  bbox_loss: 0.1066  cls_loss: 0.0048  \n",
      "<<<iteration:[100/117] - total_loss: 0.5947  obj_loss: 0.1172  noobj_loss: 0.1273  bbox_loss: 0.0818  cls_loss: 0.0050  \n",
      "\n",
      "epoch:78/100 - Train Loss: 0.5570, Val Loss: 5.8323\n",
      "\n",
      "<<<iteration:[20/117] - total_loss: 0.5363  obj_loss: 0.2077  noobj_loss: 0.1475  bbox_loss: 0.0505  cls_loss: 0.0024  \n",
      "<<<iteration:[40/117] - total_loss: 0.7571  obj_loss: 0.1845  noobj_loss: 0.1433  bbox_loss: 0.0992  cls_loss: 0.0047  \n",
      "<<<iteration:[60/117] - total_loss: 0.7310  obj_loss: 0.1655  noobj_loss: 0.1324  bbox_loss: 0.0992  cls_loss: 0.0030  \n",
      "<<<iteration:[80/117] - total_loss: 0.4858  obj_loss: 0.1753  noobj_loss: 0.1226  bbox_loss: 0.0491  cls_loss: 0.0035  \n",
      "<<<iteration:[100/117] - total_loss: 0.4521  obj_loss: 0.1766  noobj_loss: 0.1500  bbox_loss: 0.0395  cls_loss: 0.0028  \n",
      "\n",
      "epoch:79/100 - Train Loss: 0.5766, Val Loss: 5.4432\n",
      "\n",
      "<<<iteration:[20/117] - total_loss: 0.5748  obj_loss: 0.2072  noobj_loss: 0.1435  bbox_loss: 0.0585  cls_loss: 0.0032  \n",
      "<<<iteration:[40/117] - total_loss: 0.6032  obj_loss: 0.2672  noobj_loss: 0.1567  bbox_loss: 0.0508  cls_loss: 0.0037  \n",
      "<<<iteration:[60/117] - total_loss: 0.8012  obj_loss: 0.1664  noobj_loss: 0.1581  bbox_loss: 0.1105  cls_loss: 0.0030  \n",
      "<<<iteration:[80/117] - total_loss: 0.6816  obj_loss: 0.1259  noobj_loss: 0.1236  bbox_loss: 0.0983  cls_loss: 0.0025  \n",
      "<<<iteration:[100/117] - total_loss: 0.4454  obj_loss: 0.1455  noobj_loss: 0.1320  bbox_loss: 0.0463  cls_loss: 0.0025  \n",
      "\n",
      "epoch:80/100 - Train Loss: 0.6000, Val Loss: 5.4956\n",
      "\n",
      "<<<iteration:[20/117] - total_loss: 0.5308  obj_loss: 0.2303  noobj_loss: 0.1556  bbox_loss: 0.0439  cls_loss: 0.0030  \n",
      "<<<iteration:[40/117] - total_loss: 0.4797  obj_loss: 0.1893  noobj_loss: 0.1501  bbox_loss: 0.0425  cls_loss: 0.0027  \n",
      "<<<iteration:[60/117] - total_loss: 0.4869  obj_loss: 0.1022  noobj_loss: 0.1296  bbox_loss: 0.0634  cls_loss: 0.0028  \n",
      "<<<iteration:[80/117] - total_loss: 0.6263  obj_loss: 0.1814  noobj_loss: 0.1253  bbox_loss: 0.0758  cls_loss: 0.0032  \n",
      "<<<iteration:[100/117] - total_loss: 0.4434  obj_loss: 0.1771  noobj_loss: 0.1493  bbox_loss: 0.0380  cls_loss: 0.0018  \n",
      "\n",
      "epoch:81/100 - Train Loss: 0.4997, Val Loss: 5.6451\n",
      "\n",
      "<<<iteration:[20/117] - total_loss: 0.7131  obj_loss: 0.2109  noobj_loss: 0.1314  bbox_loss: 0.0868  cls_loss: 0.0027  \n",
      "<<<iteration:[40/117] - total_loss: 0.5673  obj_loss: 0.1280  noobj_loss: 0.1207  bbox_loss: 0.0753  cls_loss: 0.0023  \n",
      "<<<iteration:[60/117] - total_loss: 0.5630  obj_loss: 0.1790  noobj_loss: 0.1208  bbox_loss: 0.0642  cls_loss: 0.0028  \n",
      "<<<iteration:[80/117] - total_loss: 0.6753  obj_loss: 0.1190  noobj_loss: 0.1285  bbox_loss: 0.0978  cls_loss: 0.0030  \n",
      "<<<iteration:[100/117] - total_loss: 0.7690  obj_loss: 0.0570  noobj_loss: 0.1167  bbox_loss: 0.1298  cls_loss: 0.0049  \n",
      "\n",
      "epoch:82/100 - Train Loss: 0.6114, Val Loss: 5.3668\n",
      "\n",
      "<<<iteration:[20/117] - total_loss: 0.5361  obj_loss: 0.1664  noobj_loss: 0.1230  bbox_loss: 0.0612  cls_loss: 0.0022  \n",
      "<<<iteration:[40/117] - total_loss: 0.6143  obj_loss: 0.1560  noobj_loss: 0.1213  bbox_loss: 0.0788  cls_loss: 0.0038  \n",
      "<<<iteration:[60/117] - total_loss: 0.4679  obj_loss: 0.1036  noobj_loss: 0.1074  bbox_loss: 0.0616  cls_loss: 0.0028  \n",
      "<<<iteration:[80/117] - total_loss: 0.6140  obj_loss: 0.1251  noobj_loss: 0.1018  bbox_loss: 0.0867  cls_loss: 0.0047  \n",
      "<<<iteration:[100/117] - total_loss: 1.2259  obj_loss: 0.1128  noobj_loss: 0.1170  bbox_loss: 0.2100  cls_loss: 0.0046  \n",
      "\n",
      "epoch:83/100 - Train Loss: 0.7145, Val Loss: 5.5195\n",
      "\n",
      "<<<iteration:[20/117] - total_loss: 0.7202  obj_loss: 0.1556  noobj_loss: 0.0970  bbox_loss: 0.1022  cls_loss: 0.0049  \n",
      "<<<iteration:[40/117] - total_loss: 0.5132  obj_loss: 0.1039  noobj_loss: 0.0940  bbox_loss: 0.0718  cls_loss: 0.0033  \n",
      "<<<iteration:[60/117] - total_loss: 0.6907  obj_loss: 0.1289  noobj_loss: 0.1152  bbox_loss: 0.0992  cls_loss: 0.0083  \n",
      "<<<iteration:[80/117] - total_loss: 0.8182  obj_loss: 0.1057  noobj_loss: 0.1115  bbox_loss: 0.1304  cls_loss: 0.0048  \n",
      "<<<iteration:[100/117] - total_loss: 0.6847  obj_loss: 0.1595  noobj_loss: 0.1062  bbox_loss: 0.0937  cls_loss: 0.0038  \n",
      "\n",
      "epoch:84/100 - Train Loss: 0.6765, Val Loss: 5.8657\n",
      "\n",
      "<<<iteration:[20/117] - total_loss: 0.8013  obj_loss: 0.0734  noobj_loss: 0.0938  bbox_loss: 0.1355  cls_loss: 0.0035  \n",
      "<<<iteration:[40/117] - total_loss: 0.3927  obj_loss: 0.1265  noobj_loss: 0.1006  bbox_loss: 0.0424  cls_loss: 0.0039  \n",
      "<<<iteration:[60/117] - total_loss: 0.8027  obj_loss: 0.1903  noobj_loss: 0.1166  bbox_loss: 0.1101  cls_loss: 0.0037  \n",
      "<<<iteration:[80/117] - total_loss: 0.6309  obj_loss: 0.1302  noobj_loss: 0.1075  bbox_loss: 0.0884  cls_loss: 0.0051  \n",
      "<<<iteration:[100/117] - total_loss: 0.8860  obj_loss: 0.1886  noobj_loss: 0.1137  bbox_loss: 0.1270  cls_loss: 0.0057  \n",
      "\n",
      "epoch:85/100 - Train Loss: 0.6827, Val Loss: 5.4791\n",
      "\n",
      "<<<iteration:[20/117] - total_loss: 0.7453  obj_loss: 0.0920  noobj_loss: 0.0954  bbox_loss: 0.1198  cls_loss: 0.0066  \n",
      "<<<iteration:[40/117] - total_loss: 0.5122  obj_loss: 0.1145  noobj_loss: 0.0898  bbox_loss: 0.0692  cls_loss: 0.0071  \n",
      "<<<iteration:[60/117] - total_loss: 0.6729  obj_loss: 0.1193  noobj_loss: 0.0997  bbox_loss: 0.0996  cls_loss: 0.0056  \n",
      "<<<iteration:[80/117] - total_loss: 0.4257  obj_loss: 0.1550  noobj_loss: 0.1013  bbox_loss: 0.0432  cls_loss: 0.0042  \n",
      "<<<iteration:[100/117] - total_loss: 0.5531  obj_loss: 0.1349  noobj_loss: 0.0909  bbox_loss: 0.0739  cls_loss: 0.0032  \n",
      "\n",
      "epoch:86/100 - Train Loss: 0.5985, Val Loss: 5.2290\n",
      "\n",
      "<<<iteration:[20/117] - total_loss: 0.7064  obj_loss: 0.1094  noobj_loss: 0.0872  bbox_loss: 0.1100  cls_loss: 0.0034  \n",
      "<<<iteration:[40/117] - total_loss: 0.7147  obj_loss: 0.1669  noobj_loss: 0.0986  bbox_loss: 0.0985  cls_loss: 0.0062  \n",
      "<<<iteration:[60/117] - total_loss: 0.4771  obj_loss: 0.0983  noobj_loss: 0.0939  bbox_loss: 0.0657  cls_loss: 0.0032  \n",
      "<<<iteration:[80/117] - total_loss: 0.4938  obj_loss: 0.1416  noobj_loss: 0.0916  bbox_loss: 0.0603  cls_loss: 0.0047  \n",
      "<<<iteration:[100/117] - total_loss: 0.6993  obj_loss: 0.1802  noobj_loss: 0.1004  bbox_loss: 0.0929  cls_loss: 0.0045  \n",
      "\n",
      "epoch:87/100 - Train Loss: 0.6168, Val Loss: 5.3457\n",
      "\n",
      "<<<iteration:[20/117] - total_loss: 0.5821  obj_loss: 0.2064  noobj_loss: 0.1020  bbox_loss: 0.0644  cls_loss: 0.0027  \n",
      "<<<iteration:[40/117] - total_loss: 0.4834  obj_loss: 0.1536  noobj_loss: 0.1013  bbox_loss: 0.0552  cls_loss: 0.0032  \n",
      "<<<iteration:[60/117] - total_loss: 0.6080  obj_loss: 0.1362  noobj_loss: 0.1003  bbox_loss: 0.0836  cls_loss: 0.0037  \n",
      "<<<iteration:[80/117] - total_loss: 0.7511  obj_loss: 0.1384  noobj_loss: 0.1100  bbox_loss: 0.1109  cls_loss: 0.0033  \n",
      "<<<iteration:[100/117] - total_loss: 0.4140  obj_loss: 0.1449  noobj_loss: 0.0988  bbox_loss: 0.0432  cls_loss: 0.0035  \n",
      "\n",
      "epoch:88/100 - Train Loss: 0.5703, Val Loss: 5.3625\n",
      "\n",
      "<<<iteration:[20/117] - total_loss: 0.5286  obj_loss: 0.1725  noobj_loss: 0.1086  bbox_loss: 0.0598  cls_loss: 0.0029  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<<<iteration:[40/117] - total_loss: 0.7522  obj_loss: 0.1635  noobj_loss: 0.1192  bbox_loss: 0.1052  cls_loss: 0.0033  \n",
      "<<<iteration:[60/117] - total_loss: 0.4440  obj_loss: 0.1721  noobj_loss: 0.1199  bbox_loss: 0.0419  cls_loss: 0.0028  \n",
      "<<<iteration:[80/117] - total_loss: 0.5057  obj_loss: 0.1516  noobj_loss: 0.1101  bbox_loss: 0.0593  cls_loss: 0.0024  \n",
      "<<<iteration:[100/117] - total_loss: 0.5096  obj_loss: 0.1230  noobj_loss: 0.0961  bbox_loss: 0.0672  cls_loss: 0.0026  \n",
      "\n",
      "epoch:89/100 - Train Loss: 0.5206, Val Loss: 5.6462\n",
      "\n",
      "<<<iteration:[20/117] - total_loss: 0.4257  obj_loss: 0.1778  noobj_loss: 0.1154  bbox_loss: 0.0377  cls_loss: 0.0018  \n",
      "<<<iteration:[40/117] - total_loss: 0.6125  obj_loss: 0.1469  noobj_loss: 0.1185  bbox_loss: 0.0807  cls_loss: 0.0027  \n",
      "<<<iteration:[60/117] - total_loss: 0.5490  obj_loss: 0.1913  noobj_loss: 0.1212  bbox_loss: 0.0590  cls_loss: 0.0019  \n",
      "<<<iteration:[80/117] - total_loss: 0.4753  obj_loss: 0.1680  noobj_loss: 0.1275  bbox_loss: 0.0481  cls_loss: 0.0029  \n",
      "<<<iteration:[100/117] - total_loss: 0.4784  obj_loss: 0.1544  noobj_loss: 0.1064  bbox_loss: 0.0535  cls_loss: 0.0031  \n",
      "\n",
      "epoch:90/100 - Train Loss: 0.5200, Val Loss: 5.5049\n",
      "\n",
      "<<<iteration:[20/117] - total_loss: 0.7434  obj_loss: 0.2115  noobj_loss: 0.1344  bbox_loss: 0.0922  cls_loss: 0.0038  \n",
      "<<<iteration:[40/117] - total_loss: 0.5199  obj_loss: 0.1794  noobj_loss: 0.1397  bbox_loss: 0.0538  cls_loss: 0.0016  \n",
      "<<<iteration:[60/117] - total_loss: 0.4109  obj_loss: 0.1792  noobj_loss: 0.1203  bbox_loss: 0.0340  cls_loss: 0.0015  \n",
      "<<<iteration:[80/117] - total_loss: 0.5480  obj_loss: 0.1389  noobj_loss: 0.1205  bbox_loss: 0.0692  cls_loss: 0.0027  \n",
      "<<<iteration:[100/117] - total_loss: 0.4219  obj_loss: 0.1377  noobj_loss: 0.1135  bbox_loss: 0.0451  cls_loss: 0.0019  \n",
      "\n",
      "epoch:91/100 - Train Loss: 0.5761, Val Loss: 6.2482\n",
      "\n",
      "<<<iteration:[20/117] - total_loss: 0.9515  obj_loss: 0.1419  noobj_loss: 0.0968  bbox_loss: 0.1516  cls_loss: 0.0033  \n",
      "<<<iteration:[40/117] - total_loss: 0.5880  obj_loss: 0.1487  noobj_loss: 0.0977  bbox_loss: 0.0774  cls_loss: 0.0034  \n",
      "<<<iteration:[60/117] - total_loss: 0.4912  obj_loss: 0.1193  noobj_loss: 0.1035  bbox_loss: 0.0631  cls_loss: 0.0045  \n",
      "<<<iteration:[80/117] - total_loss: 0.4559  obj_loss: 0.1432  noobj_loss: 0.0988  bbox_loss: 0.0521  cls_loss: 0.0029  \n",
      "<<<iteration:[100/117] - total_loss: 0.4639  obj_loss: 0.1210  noobj_loss: 0.0837  bbox_loss: 0.0593  cls_loss: 0.0043  \n",
      "\n",
      "epoch:92/100 - Train Loss: 0.5786, Val Loss: 5.7309\n",
      "\n",
      "<<<iteration:[20/117] - total_loss: 1.7639  obj_loss: 0.1676  noobj_loss: 0.1199  bbox_loss: 0.3046  cls_loss: 0.0131  \n",
      "<<<iteration:[40/117] - total_loss: 6.3439  obj_loss: 0.1927  noobj_loss: 0.2591  bbox_loss: 1.1931  cls_loss: 0.0563  \n",
      "<<<iteration:[60/117] - total_loss: 8.9652  obj_loss: 0.1972  noobj_loss: 0.2303  bbox_loss: 1.7123  cls_loss: 0.0916  \n",
      "<<<iteration:[80/117] - total_loss: 5.3102  obj_loss: 0.2038  noobj_loss: 0.2395  bbox_loss: 0.9872  cls_loss: 0.0507  \n",
      "<<<iteration:[100/117] - total_loss: 4.3485  obj_loss: 0.1390  noobj_loss: 0.1930  bbox_loss: 0.8146  cls_loss: 0.0401  \n",
      "\n",
      "epoch:93/100 - Train Loss: 4.8525, Val Loss: 8.5133\n",
      "\n",
      "<<<iteration:[20/117] - total_loss: 2.9181  obj_loss: 0.1267  noobj_loss: 0.1664  bbox_loss: 0.5352  cls_loss: 0.0324  \n",
      "<<<iteration:[40/117] - total_loss: 2.2269  obj_loss: 0.1076  noobj_loss: 0.1665  bbox_loss: 0.4009  cls_loss: 0.0316  \n",
      "<<<iteration:[60/117] - total_loss: 2.7512  obj_loss: 0.1290  noobj_loss: 0.1855  bbox_loss: 0.4962  cls_loss: 0.0485  \n",
      "<<<iteration:[80/117] - total_loss: 2.6417  obj_loss: 0.1004  noobj_loss: 0.1748  bbox_loss: 0.4839  cls_loss: 0.0341  \n",
      "<<<iteration:[100/117] - total_loss: 1.6510  obj_loss: 0.1114  noobj_loss: 0.1621  bbox_loss: 0.2865  cls_loss: 0.0263  \n",
      "\n",
      "epoch:94/100 - Train Loss: 2.2519, Val Loss: 6.4658\n",
      "\n",
      "<<<iteration:[20/117] - total_loss: 1.2272  obj_loss: 0.1307  noobj_loss: 0.1455  bbox_loss: 0.2002  cls_loss: 0.0227  \n",
      "<<<iteration:[40/117] - total_loss: 1.2471  obj_loss: 0.0760  noobj_loss: 0.1306  bbox_loss: 0.2181  cls_loss: 0.0152  \n",
      "<<<iteration:[60/117] - total_loss: 1.7772  obj_loss: 0.1074  noobj_loss: 0.1345  bbox_loss: 0.3157  cls_loss: 0.0243  \n",
      "<<<iteration:[80/117] - total_loss: 1.2942  obj_loss: 0.0725  noobj_loss: 0.1478  bbox_loss: 0.2251  cls_loss: 0.0222  \n",
      "<<<iteration:[100/117] - total_loss: 1.2128  obj_loss: 0.0777  noobj_loss: 0.1180  bbox_loss: 0.2113  cls_loss: 0.0196  \n",
      "\n",
      "epoch:95/100 - Train Loss: 1.3000, Val Loss: 6.0505\n",
      "\n",
      "<<<iteration:[20/117] - total_loss: 1.0092  obj_loss: 0.0988  noobj_loss: 0.1158  bbox_loss: 0.1667  cls_loss: 0.0188  \n",
      "<<<iteration:[40/117] - total_loss: 0.5872  obj_loss: 0.0909  noobj_loss: 0.1133  bbox_loss: 0.0852  cls_loss: 0.0138  \n",
      "<<<iteration:[60/117] - total_loss: 1.0098  obj_loss: 0.0716  noobj_loss: 0.1114  bbox_loss: 0.1735  cls_loss: 0.0148  \n",
      "<<<iteration:[80/117] - total_loss: 0.9338  obj_loss: 0.0939  noobj_loss: 0.1109  bbox_loss: 0.1540  cls_loss: 0.0144  \n",
      "<<<iteration:[100/117] - total_loss: 1.1260  obj_loss: 0.0878  noobj_loss: 0.1176  bbox_loss: 0.1921  cls_loss: 0.0190  \n",
      "\n",
      "epoch:96/100 - Train Loss: 0.8889, Val Loss: 5.8742\n",
      "\n",
      "<<<iteration:[20/117] - total_loss: 0.5993  obj_loss: 0.1114  noobj_loss: 0.1085  bbox_loss: 0.0840  cls_loss: 0.0136  \n",
      "<<<iteration:[40/117] - total_loss: 0.9501  obj_loss: 0.1056  noobj_loss: 0.1070  bbox_loss: 0.1555  cls_loss: 0.0133  \n",
      "<<<iteration:[60/117] - total_loss: 0.9887  obj_loss: 0.0874  noobj_loss: 0.1088  bbox_loss: 0.1665  cls_loss: 0.0145  \n",
      "<<<iteration:[80/117] - total_loss: 0.6357  obj_loss: 0.0829  noobj_loss: 0.1043  bbox_loss: 0.0972  cls_loss: 0.0145  \n",
      "<<<iteration:[100/117] - total_loss: 0.5148  obj_loss: 0.1026  noobj_loss: 0.1023  bbox_loss: 0.0700  cls_loss: 0.0109  \n",
      "\n",
      "epoch:97/100 - Train Loss: 0.7325, Val Loss: 5.5486\n",
      "\n",
      "<<<iteration:[20/117] - total_loss: 0.7475  obj_loss: 0.1239  noobj_loss: 0.1089  bbox_loss: 0.1117  cls_loss: 0.0104  \n",
      "<<<iteration:[40/117] - total_loss: 0.7882  obj_loss: 0.1583  noobj_loss: 0.1037  bbox_loss: 0.1137  cls_loss: 0.0097  \n",
      "<<<iteration:[60/117] - total_loss: 1.1148  obj_loss: 0.0966  noobj_loss: 0.1013  bbox_loss: 0.1909  cls_loss: 0.0130  \n",
      "<<<iteration:[80/117] - total_loss: 0.9521  obj_loss: 0.1311  noobj_loss: 0.1054  bbox_loss: 0.1514  cls_loss: 0.0111  \n",
      "<<<iteration:[100/117] - total_loss: 0.5641  obj_loss: 0.0503  noobj_loss: 0.1082  bbox_loss: 0.0904  cls_loss: 0.0075  \n",
      "\n",
      "epoch:98/100 - Train Loss: 0.8220, Val Loss: 6.4316\n",
      "\n",
      "<<<iteration:[20/117] - total_loss: 0.8979  obj_loss: 0.0802  noobj_loss: 0.1191  bbox_loss: 0.1489  cls_loss: 0.0137  \n",
      "<<<iteration:[40/117] - total_loss: 0.8175  obj_loss: 0.0721  noobj_loss: 0.1070  bbox_loss: 0.1369  cls_loss: 0.0073  \n",
      "<<<iteration:[60/117] - total_loss: 0.5890  obj_loss: 0.1225  noobj_loss: 0.0945  bbox_loss: 0.0820  cls_loss: 0.0095  \n",
      "<<<iteration:[80/117] - total_loss: 11.5959  obj_loss: 0.1376  noobj_loss: 0.3425  bbox_loss: 2.2406  cls_loss: 0.0840  \n",
      "<<<iteration:[100/117] - total_loss: 7.5960  obj_loss: 0.1134  noobj_loss: 0.2892  bbox_loss: 1.4432  cls_loss: 0.1221  \n",
      "\n",
      "epoch:99/100 - Train Loss: 4.1498, Val Loss: 7.5408\n",
      "\n",
      "<<<iteration:[20/117] - total_loss: 2.4903  obj_loss: 0.0746  noobj_loss: 0.2371  bbox_loss: 0.4441  cls_loss: 0.0769  \n",
      "<<<iteration:[40/117] - total_loss: 2.1124  obj_loss: 0.0981  noobj_loss: 0.2039  bbox_loss: 0.3688  cls_loss: 0.0684  \n",
      "<<<iteration:[60/117] - total_loss: 1.8642  obj_loss: 0.0828  noobj_loss: 0.2211  bbox_loss: 0.3223  cls_loss: 0.0593  \n",
      "<<<iteration:[80/117] - total_loss: 1.4571  obj_loss: 0.0775  noobj_loss: 0.2419  bbox_loss: 0.2370  cls_loss: 0.0737  \n",
      "<<<iteration:[100/117] - total_loss: 1.8553  obj_loss: 0.1172  noobj_loss: 0.2143  bbox_loss: 0.3134  cls_loss: 0.0641  \n",
      "\n",
      "epoch:100/100 - Train Loss: 1.8002, Val Loss: 5.4623\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "accec016048f48aeb3a78e213aedae89",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='0.003 MB of 0.069 MB uploaded (0.000 MB deduped)\\r'), FloatProgress(value=0.036727…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>Train Loss</td><td>█▆▅▄▄▃▃▃▃▄▂▂▂▂▂▂▂▂▂▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▃▁▃</td></tr><tr><td>Train bbox Loss</td><td>█▆▅▄▄▄▃▃▄▄▂▂▂▂▂▂▂▂▂▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▃▁▃</td></tr><tr><td>Train class Loss</td><td>█▆▄▃▃▂▂▂▂▂▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▂</td></tr><tr><td>Train obj Loss</td><td>▁▁▂▃▂▃▃▃▁▂▄▄▃▅▆▄▇▆▅▅▅▆▆██▆▇▆▆▇▆▇▄▄▅▆▄▃▃▂</td></tr><tr><td>Val Loss</td><td>█▇▆▅▅▅▅▅▄▄▃▃▂▁▂▂▂▂▂▂▂▂▂▁▁▂▁▁▁▁▂▁▁▂▁▁▂▃▁▁</td></tr><tr><td>Val bbox Loss</td><td>██▆▅▆▅▅▆▅▄▄▃▃▂▃▂▂▂▂▂▂▂▃▂▂▂▁▁▁▁▂▁▁▂▁▁▁▃▁▁</td></tr><tr><td>Val class Loss</td><td>█▃▇▅▄▅▇▄▄▂▅▃▃▂▂▂▂▂▂▁▄▃▂▃▁▂▂▃▂▃▃▂▂▄▄▃▅▂▃▃</td></tr><tr><td>Val obj Loss</td><td>██▄▄▂▅▃▄▂▂▁▂▂▁▃▃▃▂▃▁▂▃▂▄▄▆▄▄▅▇▅▇▆▄▅▇▆▄▄▃</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>Train Loss</td><td>1.80016</td></tr><tr><td>Train bbox Loss</td><td>0.30807</td></tr><tr><td>Train class Loss</td><td>0.06389</td></tr><tr><td>Train obj Loss</td><td>0.08773</td></tr><tr><td>Val Loss</td><td>5.46231</td></tr><tr><td>Val bbox Loss</td><td>0.40829</td></tr><tr><td>Val class Loss</td><td>2.78857</td></tr><tr><td>Val obj Loss</td><td>0.07789</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">amber-frost-2</strong> at: <a href='https://wandb.ai/urp/yolo_resnet/runs/6ozln9gt' target=\"_blank\">https://wandb.ai/urp/yolo_resnet/runs/6ozln9gt</a><br/>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20231003_124530-6ozln9gt/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "num_epochs = 100\n",
    "\n",
    "best_epoch = 0\n",
    "best_score = float('inf')\n",
    "train_losses = []\n",
    "val_losses = []\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    train_loss, val_loss = train_one_epoch(dataloaders, model, criterion, optimizer, device)\n",
    "    train_losses.append(train_loss)\n",
    "    val_losses.append(val_loss)\n",
    "#     train_loss[\"obj_loss\"] += obj_loss\n",
    "#     train_loss[\"noobj_loss\"] += noobj_loss\n",
    "#     train_loss[\"bbox_loss\"] += bbox_loss\n",
    "#     train_loss[\"cls_loss\"] += cls_loss\n",
    "    wandb.log({\"Train Loss\": train_loss['total_loss'],\n",
    "               \"Train obj Loss\":train_loss[\"obj_loss\"],\n",
    "               \"Train bbox Loss\":train_loss[\"bbox_loss\"],\n",
    "               \"Train class Loss\":train_loss[\"cls_loss\"],\n",
    "               \"Val Loss\": val_loss['total_loss'],\n",
    "               \"Val obj Loss\":val_loss[\"obj_loss\"],\n",
    "               \"Val bbox Loss\":val_loss[\"bbox_loss\"],\n",
    "               \"Val class Loss\":val_loss[\"cls_loss\"],})\n",
    "    print(f\"\\nepoch:{epoch+1}/{num_epochs} - Train Loss: {train_loss['total_loss']:.4f}, Val Loss: {val_loss['total_loss']:.4f}\\n\")\n",
    "    \n",
    "    if (epoch+1) % 10 == 0:\n",
    "        save_model(model.state_dict(), f'model_{epoch+1}.pth', save_dir=f\"./trained_model/{BACKBONE}_{PART}_LR{LR}\")\n",
    "wandb.finish()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4de7fe95",
   "metadata": {},
   "source": [
    "# Inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "64dd5b10",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_model(ckpt_path, num_classes, device):\n",
    "    checkpoint = torch.load(ckpt_path, map_location=device)\n",
    "    model = YOLO_RESNET(num_classes=num_classes)\n",
    "    model.load_state_dict(checkpoint)\n",
    "    model = model.to(device)\n",
    "    model.eval()\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "4d80869e",
   "metadata": {},
   "outputs": [],
   "source": [
    "transformer = A.Compose([\n",
    "    A.Resize(height=IMAGE_SIZE, width=IMAGE_SIZE),\n",
    "    A.Normalize(mean=(0.485, 0.456, 0.406),std=(0.229, 0.224, 0.225)),\n",
    "    ToTensorV2()\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "76bcd114",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.8/dist-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.8/dist-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ResNet18_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet18_Weights.DEFAULT` to get the most up-to-date weights.\n",
      "  warnings.warn(msg)\n"
     ]
    }
   ],
   "source": [
    "# ckpt_path=\"./trained_model/YOLO_RESNET18_body_LR1e-05/model_80.pth\"\n",
    "ckpt_path=\"/workspace/yb/trained_model/YOLO_RESNET18_body_LR1e-05/model_100.pth\"\n",
    "model = load_model(ckpt_path, NUM_CLASSES, device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "7870d512",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x7f4b1fc0a400>"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "image=cv2.imread(\"/home/host_data/PET_data/Body/valid/image/shape1_128.jpg\")\n",
    "plt.imshow(image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "3709c974",
   "metadata": {},
   "outputs": [],
   "source": [
    "@torch.no_grad()\n",
    "def model_predict(image, model, conf_thres=0.3, iou_threshold=0.1):\n",
    "    predictions = model(image)\n",
    "    prediction = predictions.detach().cpu().squeeze(dim=0)\n",
    "    \n",
    "    grid_size = prediction.shape[-1]\n",
    "    y_grid, x_grid = torch.meshgrid(torch.arange(grid_size), torch.arange(grid_size))\n",
    "    stride_size = IMAGE_SIZE/grid_size\n",
    "\n",
    "    conf = prediction[[0,5], ...].reshape(1, -1)\n",
    "    xc = (prediction[[1,6], ...] * IMAGE_SIZE + x_grid*stride_size).reshape(1,-1)\n",
    "    yc = (prediction[[2,7], ...] * IMAGE_SIZE + y_grid*stride_size).reshape(1,-1)\n",
    "    w = (prediction[[3,8], ...] * IMAGE_SIZE).reshape(1,-1)\n",
    "    h = (prediction[[4,9], ...] * IMAGE_SIZE).reshape(1,-1)\n",
    "    cls = torch.max(prediction[10:, ...].reshape(NUM_CLASSES, -1), dim=0).indices.tile(1,2)\n",
    "    \n",
    "    x_min = xc - w/2\n",
    "    y_min = yc - h/2\n",
    "    x_max = xc + w/2\n",
    "    y_max = yc + h/2\n",
    "\n",
    "    prediction_res = torch.cat([x_min, y_min, x_max, y_max, conf, cls], dim=0)\n",
    "    prediction_res = prediction_res.transpose(0,1)\n",
    "\n",
    "    # x_min과 y_min이 음수가 되지않고, x_max와 y_max가 이미지 크기를 넘지 않게 제한\n",
    "    prediction_res[:, 2].clip(min=0, max=image.shape[1]) \n",
    "    prediction_res[:, 3].clip(min=0, max=image.shape[0])\n",
    "        \n",
    "    pred_res = prediction_res[prediction_res[:, 4] > conf_thres]\n",
    "    nms_index = torchvision.ops.nms(boxes=pred_res[:, 0:4], scores=pred_res[:, 4], iou_threshold=iou_threshold)\n",
    "    pred_res_ = pred_res[nms_index].numpy()\n",
    "    \n",
    "    n_obj = pred_res_.shape[0]\n",
    "    bboxes = np.zeros(shape=(n_obj, 4), dtype=np.float32)\n",
    "    bboxes[:, 0:2] = (pred_res_[:, 0:2] + pred_res_[:, 2:4]) / 2\n",
    "    bboxes[:, 2:4] = pred_res_[:, 2:4] - pred_res_[:, 0:2]\n",
    "    scores = pred_res_[:, 4]\n",
    "    class_ids = pred_res_[:, 5]\n",
    "    \n",
    "    # 이미지 값이 들어가면 모델을 통해서, 후처리까지 포함된 yolo 포멧의 box좌표, 그 좌표에 대한 confidence score\n",
    "    # 그리고 class id를 반환\n",
    "    return bboxes, scores, class_ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "10dddcd9",
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_images = []\n",
    "pred_labels =[]\n",
    "\n",
    "for index, batch in enumerate(dataloaders[\"val\"]):\n",
    "    images = batch[0].to(device)\n",
    "    bboxes, scores, class_ids = model_predict(images, model, conf_thres=0.2, iou_threshold=0.1)\n",
    "    \n",
    "    if len(bboxes) > 0:\n",
    "        prediction_yolo = np.concatenate([bboxes, scores[:, np.newaxis], class_ids[:, np.newaxis]], axis=1)\n",
    "    else:\n",
    "        prediction_yolo = np.array([])\n",
    "    \n",
    "    # 텐서형의 이미지를 다시 unnormalize를 시키고, 다시 chw를 hwc로 바꾸고 넘파이로 바꾼다.\n",
    "    np_image = make_grid(images[0], normalize=True).cpu().permute(1,2,0).numpy()\n",
    "    pred_images.append(np_image)\n",
    "    pred_labels.append(prediction_yolo)\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "b07fa545",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8b19637b02064e2eb7e2000239b3a4b1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "interactive(children=(IntSlider(value=0, description='index', max=19), Output()), _dom_classes=('widget-intera…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from ipywidgets import interact\n",
    "\n",
    "@interact(index=(0,len(pred_images)-1))\n",
    "def show_result(index=0):\n",
    "#     print(pred_labels[index])\n",
    "    if len(pred_labels[index]) > 0:\n",
    "        result = visualize(pred_images[index], pred_labels[index][:, 0:4], pred_labels[index][:, 5])\n",
    "    else:\n",
    "        result = pred_images[index]\n",
    "        \n",
    "    plt.figure(figsize=(6,6))\n",
    "    plt.imshow(result)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0b5bf2c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "edc7e158",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d742eb1c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "789df476",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68ba0798",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
