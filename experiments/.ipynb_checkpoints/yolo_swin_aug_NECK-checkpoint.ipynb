{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3c025da0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import os \n",
    "import pandas as pd\n",
    "import cv2\n",
    "import torch\n",
    "import matplotlib.pyplot as plt\n",
    "from ipywidgets import interact\n",
    "import albumentations as A\n",
    "from albumentations.pytorch import ToTensorV2\n",
    "import torchvision\n",
    "from torch import nn\n",
    "import torchsummary\n",
    "from torch.utils.data import DataLoader\n",
    "from collections import defaultdict\n",
    "from torchvision.utils import make_grid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5d503acd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cuda', index=0)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "device"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ee9eb3c",
   "metadata": {},
   "source": [
    "# Utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c7fac7d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "CLASS_NAME_TO_ID = {'Unformed': 0, 'Burr': 1}\n",
    "CLASS_ID_TO_NAME = {0: 'Unformed', 1: 'Burr'}\n",
    "BOX_COLOR = {'Unformed':(200, 0, 0), 'Burr':(0, 0, 200)}\n",
    "TEXT_COLOR = (255, 255, 255)\n",
    "\n",
    "def save_model(model_state, model_name, save_dir=\"./trained_model\"):\n",
    "    os.makedirs(save_dir, exist_ok=True)\n",
    "    torch.save(model_state, os.path.join(save_dir, model_name))\n",
    "\n",
    "\n",
    "def visualize_bbox(image, bbox, class_name, color=BOX_COLOR, thickness=2):\n",
    "    x_center, y_center, w, h = bbox\n",
    "    x_min = int(x_center - w/2)\n",
    "    y_min = int(y_center - h/2)\n",
    "    x_max = int(x_center + w/2)\n",
    "    y_max = int(y_center + h/2)\n",
    "    \n",
    "    cv2.rectangle(image, (x_min, y_min), (x_max, y_max), color=color[class_name], thickness=thickness)\n",
    "    \n",
    "    ((text_width, text_height), _) = cv2.getTextSize(class_name, cv2.FONT_HERSHEY_SIMPLEX, 0.35, 1)    \n",
    "    cv2.rectangle(image, (x_min, y_min - int(1.3 * text_height)), (x_min + text_width, y_min), color[class_name], -1)\n",
    "    cv2.putText(\n",
    "        image,\n",
    "        text=class_name,\n",
    "        org=(x_min, y_min - int(0.3 * text_height)),\n",
    "        fontFace=cv2.FONT_HERSHEY_SIMPLEX,\n",
    "        fontScale=0.35, \n",
    "        color=TEXT_COLOR, \n",
    "        lineType=cv2.LINE_AA,\n",
    "    )\n",
    "    return image\n",
    "\n",
    "\n",
    "def visualize(image, bboxes, category_ids):\n",
    "    img = image.copy()\n",
    "    for bbox, category_id in zip(bboxes, category_ids):\n",
    "#         print('category_id: ',category_id)\n",
    "        class_name = CLASS_ID_TO_NAME[category_id.item()]\n",
    "        img = visualize_bbox(img, bbox, class_name)\n",
    "    return img"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62c7da98",
   "metadata": {},
   "source": [
    "# Datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ea0166e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "class PET_dataset():\n",
    "    def __init__(self,part,neck_dir,body_dir,phase, transformer=None, aug=None, aug_factor=0):\n",
    "        self.neck_dir=neck_dir\n",
    "        self.body_dir=body_dir\n",
    "        self.part=part\n",
    "        self.phase=phase\n",
    "        self.transformer=transformer\n",
    "        self.aug=aug\n",
    "        self.aug_factor=aug_factor\n",
    "        if(self.part==\"body\"):\n",
    "            self.image_files = sorted([fn for fn in os.listdir(self.body_dir+\"/\"+self.phase+\"/image\") if fn.endswith(\"jpg\")])\n",
    "            self.label_files= sorted([lab for lab in os.listdir(self.body_dir+\"/\"+self.phase+\"/label\") if lab.endswith(\"txt\")])\n",
    "        elif(self.part==\"neck\"):\n",
    "            self.image_files = sorted([fn for fn in os.listdir(self.neck_dir+\"/\"+self.phase+\"/image\") if fn.endswith(\"jpg\")])\n",
    "            self.label_files= sorted([lab for lab in os.listdir(self.neck_dir+\"/\"+self.phase+\"/label\") if lab.endswith(\"txt\")])\n",
    "        \n",
    "        self.auged_img_list, self.auged_label_list=self.make_aug_list(self.image_files, self.label_files)\n",
    "        \n",
    "    def __getitem__(self,index):\n",
    "        if(self.aug==None):\n",
    "            filename, image = self.get_image(self.part, index)\n",
    "            bboxes, class_ids = self.get_label(self.part, index)\n",
    "\n",
    "            if(self.transformer):\n",
    "                transformed_data=self.transformer(image=image, bboxes=bboxes, class_ids=class_ids)\n",
    "                image = transformed_data['image']\n",
    "                bboxes = np.array(transformed_data['bboxes'])\n",
    "                class_ids = np.array(transformed_data['class_ids'])\n",
    "\n",
    "\n",
    "            target = {}\n",
    "    #         print(f'bboxes:{bboxes}\\nclass_ids:{class_ids}\\nlen_bboxes:{len(bboxes)}\\nlen_class_ids:{len(class_ids)}')\n",
    "    #         print(f'filename: {filename}')\n",
    "            target[\"boxes\"] = torch.Tensor(bboxes).float()\n",
    "            target[\"labels\"] = torch.Tensor(class_ids).long()\n",
    "\n",
    "            ###\n",
    "            bboxes=torch.Tensor(bboxes).float()\n",
    "            class_ids=torch.Tensor(class_ids).long()\n",
    "            target = np.concatenate((bboxes, class_ids[:, np.newaxis]), axis=1)\n",
    "            ###\n",
    "        else:\n",
    "            image=self.auged_img_list[index][1]\n",
    "            target=self.auged_label_list[index]\n",
    "            filename=self.auged_img_list[index][0]\n",
    "        return image, target, filename\n",
    "    \n",
    "    def __len__(self, ):\n",
    "        length=0\n",
    "        if(self.aug==None):\n",
    "            length=len(self.image_files)\n",
    "        else:\n",
    "            length=len(self.auged_img_list)\n",
    "        return length\n",
    "    \n",
    "    def make_aug_list(self,ori_image_list,ori_label_files):\n",
    "        aug_image_list=[]\n",
    "        aug_label_list=[]\n",
    "        \n",
    "        print(f\"start making augmented images-- augmented factor:{self.aug_factor}\")\n",
    "        for i in range(len(ori_image_list)):\n",
    "            filename, ori_image = self.get_image(self.part, i)\n",
    "            ori_bboxes, ori_class_ids = self.get_label(self.part, i)\n",
    "            for j in range(self.aug_factor):\n",
    "                auged_data=self.aug(image=ori_image, bboxes=ori_bboxes, class_ids=ori_class_ids)\n",
    "                image = auged_data['image']\n",
    "                bboxes = np.array(auged_data['bboxes'])\n",
    "                class_ids = np.array(auged_data['class_ids'])\n",
    "                \n",
    "                bboxes=torch.Tensor(bboxes).float()\n",
    "                class_ids=torch.Tensor(class_ids).long()\n",
    "                \n",
    "                aug_image_list.append((filename, image))\n",
    "                aug_label_list.append(np.concatenate((bboxes, class_ids[:, np.newaxis]), axis=1))\n",
    "        \n",
    "        print(f\"total length of augmented images: {len(aug_image_list)}\")\n",
    "        \n",
    "        return aug_image_list, aug_label_list\n",
    "        \n",
    "    \n",
    "    def get_image(self, part, index): # 이미지 불러오는 함수\n",
    "        filename = self.image_files[index]\n",
    "        if(part==\"body\"):\n",
    "#             print(f\"body called!-> {self.part}\")\n",
    "            image_path = self.body_dir+\"/\"+self.phase+\"/image/\"+filename\n",
    "        elif(part==\"neck\"):\n",
    "#             print(f\"neck called!-> {self.part}\")\n",
    "            image_path = self.neck_dir+\"/\"+self.phase+\"/image/\"+filename\n",
    "        image = cv2.imread(image_path)\n",
    "        image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "        return filename, image\n",
    "    \n",
    "    def get_label(self, part, index): # label (box좌표, class_id) 불러오는 함수\n",
    "        label_filename=self.label_files[index]\n",
    "        if(part==\"body\"):\n",
    "#             print(f\"body label called!-> {self.part}\")\n",
    "            label_path = self.body_dir+\"/\"+self.phase+\"/label/\"+label_filename\n",
    "        elif(part==\"neck\"):\n",
    "#             print(f\"neck label called!-> {self.part}\")\n",
    "            label_path = self.neck_dir+\"/\"+self.phase+\"/label/\"+label_filename\n",
    "        with open(label_path, 'r') as file:\n",
    "            labels = file.readlines()\n",
    "        \n",
    "        class_ids=[]\n",
    "        bboxes=[]\n",
    "        for label in labels:\n",
    "            label=label.replace(\"\\n\", \"\")\n",
    "            obj=label.split(' ')[0]\n",
    "            coor=label.split(' ')[1:]\n",
    "            obj=int(obj)\n",
    "            coor=list(map(float, coor))\n",
    "            class_ids.append(obj)\n",
    "            bboxes.append(coor)\n",
    "            \n",
    "        return bboxes, class_ids\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "235e7cec",
   "metadata": {},
   "outputs": [],
   "source": [
    "IMAGE_SIZE = 448\n",
    "\n",
    "transformer = A.Compose([ \n",
    "        # bounding box의 변환, augmentation에서 albumentations는 Detection 학습을 할 때 굉장히 유용하다. \n",
    "        A.Resize(height=IMAGE_SIZE, width=IMAGE_SIZE),\n",
    "        A.Normalize(mean=(0.485, 0.456, 0.406),std=(0.229, 0.224, 0.225)),\n",
    "        ToTensorV2(),\n",
    "        # albumentations 라이브러리에서는 Normalization을 먼저 진행해 주고 tensor화를 진행해 주어야한다.\n",
    "    ],\n",
    "    # box 위치에 대한 transformation도 함께 진행된다. \n",
    "    bbox_params=A.BboxParams(format='yolo', label_fields=['class_ids']),\n",
    ")\n",
    "\n",
    "augmentator=A.Compose([\n",
    "#     A.Resize(height=IMAGE_SIZE, width=IMAGE_SIZE),\n",
    "    A.HorizontalFlip(p=0.7),\n",
    "#     A.Sharpen(p=0.7),\n",
    "    A.BBoxSafeRandomCrop(p=0.6),\n",
    "    A.VerticalFlip (p=0.5),\n",
    "    A.HueSaturationValue(p=0.5),\n",
    "    A.Resize(height=IMAGE_SIZE, width=IMAGE_SIZE),\n",
    "    A.Normalize(mean=(0.485, 0.456, 0.406),std=(0.229, 0.224, 0.225)),\n",
    "    ToTensorV2(),\n",
    "    ],\n",
    "    bbox_params=A.BboxParams(format='yolo', label_fields=['class_ids']),\n",
    ")\n",
    "\n",
    "def collate_fn(batch):\n",
    "    image_list = []\n",
    "    target_list = []\n",
    "    filename_list = []\n",
    "    \n",
    "    for a,b,c in batch:\n",
    "        image_list.append(a)\n",
    "        target_list.append(b)\n",
    "        filename_list.append(c)\n",
    "\n",
    "    return torch.stack(image_list, dim=0), target_list, filename_list\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a6d5c32a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "start making augmented images-- augmented factor:0\n",
      "total length of augmented images: 0\n"
     ]
    }
   ],
   "source": [
    "# NECK_PATH = '/home/host_data/PET_data/Neck'\n",
    "# BODY_PATH = '/home/host_data/PET_data/Body'\n",
    "\n",
    "NECK_PATH = '/home/host_data/PET_data_IP_AUG/aug_patched_Neck/'\n",
    "BODY_PATH = '/home/host_data/PET_data_image_patching/Body'\n",
    "# trainset_yes_aug=PET_dataset(part='neck',neck_dir=NECK_PATH,body_dir=BODY_PATH,phase='train', transformer=transformer, aug=augmentator, aug_factor=5)\n",
    "trainset_no_aug=PET_dataset(part='neck',neck_dir=NECK_PATH,body_dir=BODY_PATH,phase='valid', transformer=transformer, aug=None)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "c0fbcd25",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7200"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(trainset_no_aug)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "5db4ebba",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "486ff0d293384a8bab842d33df5e154f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "interactive(children=(IntSlider(value=0, description='index', max=7199), Output()), _dom_classes=('widget-inte…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "@interact(index=(0, len(trainset_no_aug)-1))\n",
    "\n",
    "def show_sample(index=0):\n",
    "    image, target, filename = trainset_no_aug[index]\n",
    "    image=image.permute(1,2,0).numpy()\n",
    "    img_H, img_W, _ = image.shape\n",
    "    print(filename)\n",
    "    print(image.shape)\n",
    "#     print(image)\n",
    "\n",
    "#     bboxes = target['boxes']\n",
    "#     class_ids = target[\"labels\"]\n",
    "    \n",
    "    ###\n",
    "    bboxes = target[:, 0:4]\n",
    "    class_ids = target[:, 4]\n",
    "    ###\n",
    "    bboxes[:, [0,2]] *= img_W\n",
    "    bboxes[:, [1,3]] *= img_H\n",
    "\n",
    "    canvas = visualize(image, bboxes, class_ids)\n",
    "    plt.figure(figsize=(6,6))\n",
    "    plt.imshow(canvas)\n",
    "    plt.axis('off')\n",
    "    plt.show()\n",
    "\n",
    "# show_sample()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "5e341d7c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "dc2f0f8545384fc497e75c2df386cf40",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "interactive(children=(IntSlider(value=0, description='index', max=1049), Output()), _dom_classes=('widget-inte…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "@interact(index=(0, len(trainset_yes_aug)-1))\n",
    "\n",
    "def show_sample(index=0):\n",
    "    image, target, filename = trainset_yes_aug[index]\n",
    "    image=image.permute(1,2,0).numpy()\n",
    "    img_H, img_W, _ = image.shape\n",
    "    print(filename)\n",
    "    print(image.shape)\n",
    "#     print(image)\n",
    "\n",
    "#     bboxes = target['boxes']\n",
    "#     class_ids = target[\"labels\"]\n",
    "    ###\n",
    "    bboxes = target[:, 0:4]\n",
    "    class_ids = target[:, 4]\n",
    "    ###\n",
    "    bboxes[:, [0,2]] *= img_W\n",
    "    bboxes[:, [1,3]] *= img_H\n",
    "    print(bboxes)\n",
    "\n",
    "    canvas = visualize(image, bboxes, class_ids)\n",
    "    plt.figure(figsize=(6,6))\n",
    "    plt.imshow(canvas)\n",
    "    plt.axis('off')\n",
    "    plt.show()\n",
    "\n",
    "# show_sample()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f151003",
   "metadata": {},
   "source": [
    "## Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "729f2964",
   "metadata": {},
   "outputs": [],
   "source": [
    "class YOLO_SWIN(nn.Module):\n",
    "    def __init__(self, num_classes):\n",
    "        super().__init__()\n",
    "\n",
    "        self.num_classes = num_classes\n",
    "        self.num_bboxes = 2\n",
    "        self.grid_size = 7\n",
    "\n",
    "#         resnet18 = torchvision.models.resnet18(pretrained = True)\n",
    "        swin=torchvision.models.swin_v2_t(weights='IMAGENET1K_V1')\n",
    "        layers = [m for m in swin.children()] #Resnet에서 Yolo에서 가져올수 있을만한 layer만 선별적으로 가져오기 위해서\n",
    "\n",
    "        # 기존 Resnet18의 layer들중에서 맨 뒤에 두개만 제외하고 다 가져와서 Backbone으로 사용\n",
    "        self.backbone = nn.Sequential(*layers[:-3]) \n",
    "        self.head = nn.Sequential(\n",
    "                nn.Conv2d(in_channels=768, out_channels=1024, kernel_size=1, padding=0,bias=False),\n",
    "                nn.BatchNorm2d(1024),\n",
    "                nn.ReLU(inplace=True),\n",
    "                nn.Conv2d(in_channels=1024, out_channels=1024, kernel_size=3, padding=1,bias=False),\n",
    "                nn.BatchNorm2d(1024),\n",
    "                nn.ReLU(inplace=True),\n",
    "                nn.Conv2d(in_channels=1024, out_channels=1024, kernel_size=3, padding=1,bias=False),\n",
    "                nn.BatchNorm2d(1024),\n",
    "                nn.ReLU(inplace=True),\n",
    "                nn.Conv2d(in_channels=1024, out_channels=1024, kernel_size=3, padding=1,bias=False),\n",
    "                nn.BatchNorm2d(1024),\n",
    "                nn.ReLU(inplace=True),\n",
    "\n",
    "                nn.Conv2d(in_channels=1024, out_channels=(4+1)*self.num_bboxes+num_classes, kernel_size=1, padding=0, bias=False),\n",
    "                nn.AdaptiveAvgPool2d(output_size=(self.grid_size, self.grid_size))\n",
    "            )\n",
    "\n",
    "    def forward(self, x):\n",
    "        out = self.backbone(x)\n",
    "        # out = self.neck(out)\n",
    "        out = self.head(out) # input (batch, 3, 448, 448) -> output feature (batch, 12, 7, 7)\n",
    "        return out\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "b0a6eb83",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "YOLO_SWIN(\n",
       "  (backbone): Sequential(\n",
       "    (0): Sequential(\n",
       "      (0): Sequential(\n",
       "        (0): Conv2d(3, 96, kernel_size=(4, 4), stride=(4, 4))\n",
       "        (1): Permute()\n",
       "        (2): LayerNorm((96,), eps=1e-05, elementwise_affine=True)\n",
       "      )\n",
       "      (1): Sequential(\n",
       "        (0): SwinTransformerBlockV2(\n",
       "          (norm1): LayerNorm((96,), eps=1e-05, elementwise_affine=True)\n",
       "          (attn): ShiftedWindowAttentionV2(\n",
       "            (qkv): Linear(in_features=96, out_features=288, bias=True)\n",
       "            (proj): Linear(in_features=96, out_features=96, bias=True)\n",
       "            (cpb_mlp): Sequential(\n",
       "              (0): Linear(in_features=2, out_features=512, bias=True)\n",
       "              (1): ReLU(inplace=True)\n",
       "              (2): Linear(in_features=512, out_features=3, bias=False)\n",
       "            )\n",
       "          )\n",
       "          (stochastic_depth): StochasticDepth(p=0.0, mode=row)\n",
       "          (norm2): LayerNorm((96,), eps=1e-05, elementwise_affine=True)\n",
       "          (mlp): MLP(\n",
       "            (0): Linear(in_features=96, out_features=384, bias=True)\n",
       "            (1): GELU(approximate='none')\n",
       "            (2): Dropout(p=0.0, inplace=False)\n",
       "            (3): Linear(in_features=384, out_features=96, bias=True)\n",
       "            (4): Dropout(p=0.0, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (1): SwinTransformerBlockV2(\n",
       "          (norm1): LayerNorm((96,), eps=1e-05, elementwise_affine=True)\n",
       "          (attn): ShiftedWindowAttentionV2(\n",
       "            (qkv): Linear(in_features=96, out_features=288, bias=True)\n",
       "            (proj): Linear(in_features=96, out_features=96, bias=True)\n",
       "            (cpb_mlp): Sequential(\n",
       "              (0): Linear(in_features=2, out_features=512, bias=True)\n",
       "              (1): ReLU(inplace=True)\n",
       "              (2): Linear(in_features=512, out_features=3, bias=False)\n",
       "            )\n",
       "          )\n",
       "          (stochastic_depth): StochasticDepth(p=0.018181818181818184, mode=row)\n",
       "          (norm2): LayerNorm((96,), eps=1e-05, elementwise_affine=True)\n",
       "          (mlp): MLP(\n",
       "            (0): Linear(in_features=96, out_features=384, bias=True)\n",
       "            (1): GELU(approximate='none')\n",
       "            (2): Dropout(p=0.0, inplace=False)\n",
       "            (3): Linear(in_features=384, out_features=96, bias=True)\n",
       "            (4): Dropout(p=0.0, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (2): PatchMergingV2(\n",
       "        (reduction): Linear(in_features=384, out_features=192, bias=False)\n",
       "        (norm): LayerNorm((192,), eps=1e-05, elementwise_affine=True)\n",
       "      )\n",
       "      (3): Sequential(\n",
       "        (0): SwinTransformerBlockV2(\n",
       "          (norm1): LayerNorm((192,), eps=1e-05, elementwise_affine=True)\n",
       "          (attn): ShiftedWindowAttentionV2(\n",
       "            (qkv): Linear(in_features=192, out_features=576, bias=True)\n",
       "            (proj): Linear(in_features=192, out_features=192, bias=True)\n",
       "            (cpb_mlp): Sequential(\n",
       "              (0): Linear(in_features=2, out_features=512, bias=True)\n",
       "              (1): ReLU(inplace=True)\n",
       "              (2): Linear(in_features=512, out_features=6, bias=False)\n",
       "            )\n",
       "          )\n",
       "          (stochastic_depth): StochasticDepth(p=0.03636363636363637, mode=row)\n",
       "          (norm2): LayerNorm((192,), eps=1e-05, elementwise_affine=True)\n",
       "          (mlp): MLP(\n",
       "            (0): Linear(in_features=192, out_features=768, bias=True)\n",
       "            (1): GELU(approximate='none')\n",
       "            (2): Dropout(p=0.0, inplace=False)\n",
       "            (3): Linear(in_features=768, out_features=192, bias=True)\n",
       "            (4): Dropout(p=0.0, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (1): SwinTransformerBlockV2(\n",
       "          (norm1): LayerNorm((192,), eps=1e-05, elementwise_affine=True)\n",
       "          (attn): ShiftedWindowAttentionV2(\n",
       "            (qkv): Linear(in_features=192, out_features=576, bias=True)\n",
       "            (proj): Linear(in_features=192, out_features=192, bias=True)\n",
       "            (cpb_mlp): Sequential(\n",
       "              (0): Linear(in_features=2, out_features=512, bias=True)\n",
       "              (1): ReLU(inplace=True)\n",
       "              (2): Linear(in_features=512, out_features=6, bias=False)\n",
       "            )\n",
       "          )\n",
       "          (stochastic_depth): StochasticDepth(p=0.05454545454545456, mode=row)\n",
       "          (norm2): LayerNorm((192,), eps=1e-05, elementwise_affine=True)\n",
       "          (mlp): MLP(\n",
       "            (0): Linear(in_features=192, out_features=768, bias=True)\n",
       "            (1): GELU(approximate='none')\n",
       "            (2): Dropout(p=0.0, inplace=False)\n",
       "            (3): Linear(in_features=768, out_features=192, bias=True)\n",
       "            (4): Dropout(p=0.0, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (4): PatchMergingV2(\n",
       "        (reduction): Linear(in_features=768, out_features=384, bias=False)\n",
       "        (norm): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n",
       "      )\n",
       "      (5): Sequential(\n",
       "        (0): SwinTransformerBlockV2(\n",
       "          (norm1): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n",
       "          (attn): ShiftedWindowAttentionV2(\n",
       "            (qkv): Linear(in_features=384, out_features=1152, bias=True)\n",
       "            (proj): Linear(in_features=384, out_features=384, bias=True)\n",
       "            (cpb_mlp): Sequential(\n",
       "              (0): Linear(in_features=2, out_features=512, bias=True)\n",
       "              (1): ReLU(inplace=True)\n",
       "              (2): Linear(in_features=512, out_features=12, bias=False)\n",
       "            )\n",
       "          )\n",
       "          (stochastic_depth): StochasticDepth(p=0.07272727272727274, mode=row)\n",
       "          (norm2): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n",
       "          (mlp): MLP(\n",
       "            (0): Linear(in_features=384, out_features=1536, bias=True)\n",
       "            (1): GELU(approximate='none')\n",
       "            (2): Dropout(p=0.0, inplace=False)\n",
       "            (3): Linear(in_features=1536, out_features=384, bias=True)\n",
       "            (4): Dropout(p=0.0, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (1): SwinTransformerBlockV2(\n",
       "          (norm1): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n",
       "          (attn): ShiftedWindowAttentionV2(\n",
       "            (qkv): Linear(in_features=384, out_features=1152, bias=True)\n",
       "            (proj): Linear(in_features=384, out_features=384, bias=True)\n",
       "            (cpb_mlp): Sequential(\n",
       "              (0): Linear(in_features=2, out_features=512, bias=True)\n",
       "              (1): ReLU(inplace=True)\n",
       "              (2): Linear(in_features=512, out_features=12, bias=False)\n",
       "            )\n",
       "          )\n",
       "          (stochastic_depth): StochasticDepth(p=0.09090909090909091, mode=row)\n",
       "          (norm2): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n",
       "          (mlp): MLP(\n",
       "            (0): Linear(in_features=384, out_features=1536, bias=True)\n",
       "            (1): GELU(approximate='none')\n",
       "            (2): Dropout(p=0.0, inplace=False)\n",
       "            (3): Linear(in_features=1536, out_features=384, bias=True)\n",
       "            (4): Dropout(p=0.0, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (2): SwinTransformerBlockV2(\n",
       "          (norm1): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n",
       "          (attn): ShiftedWindowAttentionV2(\n",
       "            (qkv): Linear(in_features=384, out_features=1152, bias=True)\n",
       "            (proj): Linear(in_features=384, out_features=384, bias=True)\n",
       "            (cpb_mlp): Sequential(\n",
       "              (0): Linear(in_features=2, out_features=512, bias=True)\n",
       "              (1): ReLU(inplace=True)\n",
       "              (2): Linear(in_features=512, out_features=12, bias=False)\n",
       "            )\n",
       "          )\n",
       "          (stochastic_depth): StochasticDepth(p=0.10909090909090911, mode=row)\n",
       "          (norm2): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n",
       "          (mlp): MLP(\n",
       "            (0): Linear(in_features=384, out_features=1536, bias=True)\n",
       "            (1): GELU(approximate='none')\n",
       "            (2): Dropout(p=0.0, inplace=False)\n",
       "            (3): Linear(in_features=1536, out_features=384, bias=True)\n",
       "            (4): Dropout(p=0.0, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (3): SwinTransformerBlockV2(\n",
       "          (norm1): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n",
       "          (attn): ShiftedWindowAttentionV2(\n",
       "            (qkv): Linear(in_features=384, out_features=1152, bias=True)\n",
       "            (proj): Linear(in_features=384, out_features=384, bias=True)\n",
       "            (cpb_mlp): Sequential(\n",
       "              (0): Linear(in_features=2, out_features=512, bias=True)\n",
       "              (1): ReLU(inplace=True)\n",
       "              (2): Linear(in_features=512, out_features=12, bias=False)\n",
       "            )\n",
       "          )\n",
       "          (stochastic_depth): StochasticDepth(p=0.1272727272727273, mode=row)\n",
       "          (norm2): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n",
       "          (mlp): MLP(\n",
       "            (0): Linear(in_features=384, out_features=1536, bias=True)\n",
       "            (1): GELU(approximate='none')\n",
       "            (2): Dropout(p=0.0, inplace=False)\n",
       "            (3): Linear(in_features=1536, out_features=384, bias=True)\n",
       "            (4): Dropout(p=0.0, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (4): SwinTransformerBlockV2(\n",
       "          (norm1): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n",
       "          (attn): ShiftedWindowAttentionV2(\n",
       "            (qkv): Linear(in_features=384, out_features=1152, bias=True)\n",
       "            (proj): Linear(in_features=384, out_features=384, bias=True)\n",
       "            (cpb_mlp): Sequential(\n",
       "              (0): Linear(in_features=2, out_features=512, bias=True)\n",
       "              (1): ReLU(inplace=True)\n",
       "              (2): Linear(in_features=512, out_features=12, bias=False)\n",
       "            )\n",
       "          )\n",
       "          (stochastic_depth): StochasticDepth(p=0.14545454545454548, mode=row)\n",
       "          (norm2): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n",
       "          (mlp): MLP(\n",
       "            (0): Linear(in_features=384, out_features=1536, bias=True)\n",
       "            (1): GELU(approximate='none')\n",
       "            (2): Dropout(p=0.0, inplace=False)\n",
       "            (3): Linear(in_features=1536, out_features=384, bias=True)\n",
       "            (4): Dropout(p=0.0, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (5): SwinTransformerBlockV2(\n",
       "          (norm1): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n",
       "          (attn): ShiftedWindowAttentionV2(\n",
       "            (qkv): Linear(in_features=384, out_features=1152, bias=True)\n",
       "            (proj): Linear(in_features=384, out_features=384, bias=True)\n",
       "            (cpb_mlp): Sequential(\n",
       "              (0): Linear(in_features=2, out_features=512, bias=True)\n",
       "              (1): ReLU(inplace=True)\n",
       "              (2): Linear(in_features=512, out_features=12, bias=False)\n",
       "            )\n",
       "          )\n",
       "          (stochastic_depth): StochasticDepth(p=0.16363636363636364, mode=row)\n",
       "          (norm2): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n",
       "          (mlp): MLP(\n",
       "            (0): Linear(in_features=384, out_features=1536, bias=True)\n",
       "            (1): GELU(approximate='none')\n",
       "            (2): Dropout(p=0.0, inplace=False)\n",
       "            (3): Linear(in_features=1536, out_features=384, bias=True)\n",
       "            (4): Dropout(p=0.0, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (6): PatchMergingV2(\n",
       "        (reduction): Linear(in_features=1536, out_features=768, bias=False)\n",
       "        (norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "      )\n",
       "      (7): Sequential(\n",
       "        (0): SwinTransformerBlockV2(\n",
       "          (norm1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "          (attn): ShiftedWindowAttentionV2(\n",
       "            (qkv): Linear(in_features=768, out_features=2304, bias=True)\n",
       "            (proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (cpb_mlp): Sequential(\n",
       "              (0): Linear(in_features=2, out_features=512, bias=True)\n",
       "              (1): ReLU(inplace=True)\n",
       "              (2): Linear(in_features=512, out_features=24, bias=False)\n",
       "            )\n",
       "          )\n",
       "          (stochastic_depth): StochasticDepth(p=0.18181818181818182, mode=row)\n",
       "          (norm2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "          (mlp): MLP(\n",
       "            (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (1): GELU(approximate='none')\n",
       "            (2): Dropout(p=0.0, inplace=False)\n",
       "            (3): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (4): Dropout(p=0.0, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (1): SwinTransformerBlockV2(\n",
       "          (norm1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "          (attn): ShiftedWindowAttentionV2(\n",
       "            (qkv): Linear(in_features=768, out_features=2304, bias=True)\n",
       "            (proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (cpb_mlp): Sequential(\n",
       "              (0): Linear(in_features=2, out_features=512, bias=True)\n",
       "              (1): ReLU(inplace=True)\n",
       "              (2): Linear(in_features=512, out_features=24, bias=False)\n",
       "            )\n",
       "          )\n",
       "          (stochastic_depth): StochasticDepth(p=0.2, mode=row)\n",
       "          (norm2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "          (mlp): MLP(\n",
       "            (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (1): GELU(approximate='none')\n",
       "            (2): Dropout(p=0.0, inplace=False)\n",
       "            (3): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (4): Dropout(p=0.0, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "    (2): Permute()\n",
       "  )\n",
       "  (head): Sequential(\n",
       "    (0): Conv2d(768, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "    (1): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU(inplace=True)\n",
       "    (3): Conv2d(1024, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "    (4): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (5): ReLU(inplace=True)\n",
       "    (6): Conv2d(1024, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "    (7): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (8): ReLU(inplace=True)\n",
       "    (9): Conv2d(1024, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "    (10): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (11): ReLU(inplace=True)\n",
       "    (12): Conv2d(1024, 12, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "    (13): AdaptiveAvgPool2d(output_size=(7, 7))\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "NUM_CLASSES = 2\n",
    "model = YOLO_SWIN(num_classes=NUM_CLASSES)\n",
    "model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "361cde55",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------------------------------\n",
      "        Layer (type)               Output Shape         Param #\n",
      "================================================================\n",
      "            Conv2d-1         [-1, 96, 112, 112]           4,704\n",
      "           Permute-2         [-1, 112, 112, 96]               0\n",
      "         LayerNorm-3         [-1, 112, 112, 96]             192\n",
      "            Linear-4          [-1, 15, 15, 512]           1,536\n",
      "              ReLU-5          [-1, 15, 15, 512]               0\n",
      "            Linear-6            [-1, 15, 15, 3]           1,536\n",
      "ShiftedWindowAttentionV2-7         [-1, 112, 112, 96]               0\n",
      "         LayerNorm-8         [-1, 112, 112, 96]             192\n",
      "   StochasticDepth-9         [-1, 112, 112, 96]               0\n",
      "           Linear-10        [-1, 112, 112, 384]          37,248\n",
      "             GELU-11        [-1, 112, 112, 384]               0\n",
      "          Dropout-12        [-1, 112, 112, 384]               0\n",
      "           Linear-13         [-1, 112, 112, 96]          36,960\n",
      "          Dropout-14         [-1, 112, 112, 96]               0\n",
      "        LayerNorm-15         [-1, 112, 112, 96]             192\n",
      "  StochasticDepth-16         [-1, 112, 112, 96]               0\n",
      "SwinTransformerBlockV2-17         [-1, 112, 112, 96]               0\n",
      "           Linear-18          [-1, 15, 15, 512]           1,536\n",
      "             ReLU-19          [-1, 15, 15, 512]               0\n",
      "           Linear-20            [-1, 15, 15, 3]           1,536\n",
      "ShiftedWindowAttentionV2-21         [-1, 112, 112, 96]               0\n",
      "        LayerNorm-22         [-1, 112, 112, 96]             192\n",
      "  StochasticDepth-23         [-1, 112, 112, 96]               0\n",
      "           Linear-24        [-1, 112, 112, 384]          37,248\n",
      "             GELU-25        [-1, 112, 112, 384]               0\n",
      "          Dropout-26        [-1, 112, 112, 384]               0\n",
      "           Linear-27         [-1, 112, 112, 96]          36,960\n",
      "          Dropout-28         [-1, 112, 112, 96]               0\n",
      "        LayerNorm-29         [-1, 112, 112, 96]             192\n",
      "  StochasticDepth-30         [-1, 112, 112, 96]               0\n",
      "SwinTransformerBlockV2-31         [-1, 112, 112, 96]               0\n",
      "           Linear-32          [-1, 56, 56, 192]          73,728\n",
      "        LayerNorm-33          [-1, 56, 56, 192]             384\n",
      "   PatchMergingV2-34          [-1, 56, 56, 192]               0\n",
      "           Linear-35          [-1, 15, 15, 512]           1,536\n",
      "             ReLU-36          [-1, 15, 15, 512]               0\n",
      "           Linear-37            [-1, 15, 15, 6]           3,072\n",
      "ShiftedWindowAttentionV2-38          [-1, 56, 56, 192]               0\n",
      "        LayerNorm-39          [-1, 56, 56, 192]             384\n",
      "  StochasticDepth-40          [-1, 56, 56, 192]               0\n",
      "           Linear-41          [-1, 56, 56, 768]         148,224\n",
      "             GELU-42          [-1, 56, 56, 768]               0\n",
      "          Dropout-43          [-1, 56, 56, 768]               0\n",
      "           Linear-44          [-1, 56, 56, 192]         147,648\n",
      "          Dropout-45          [-1, 56, 56, 192]               0\n",
      "        LayerNorm-46          [-1, 56, 56, 192]             384\n",
      "  StochasticDepth-47          [-1, 56, 56, 192]               0\n",
      "SwinTransformerBlockV2-48          [-1, 56, 56, 192]               0\n",
      "           Linear-49          [-1, 15, 15, 512]           1,536\n",
      "             ReLU-50          [-1, 15, 15, 512]               0\n",
      "           Linear-51            [-1, 15, 15, 6]           3,072\n",
      "ShiftedWindowAttentionV2-52          [-1, 56, 56, 192]               0\n",
      "        LayerNorm-53          [-1, 56, 56, 192]             384\n",
      "  StochasticDepth-54          [-1, 56, 56, 192]               0\n",
      "           Linear-55          [-1, 56, 56, 768]         148,224\n",
      "             GELU-56          [-1, 56, 56, 768]               0\n",
      "          Dropout-57          [-1, 56, 56, 768]               0\n",
      "           Linear-58          [-1, 56, 56, 192]         147,648\n",
      "          Dropout-59          [-1, 56, 56, 192]               0\n",
      "        LayerNorm-60          [-1, 56, 56, 192]             384\n",
      "  StochasticDepth-61          [-1, 56, 56, 192]               0\n",
      "SwinTransformerBlockV2-62          [-1, 56, 56, 192]               0\n",
      "           Linear-63          [-1, 28, 28, 384]         294,912\n",
      "        LayerNorm-64          [-1, 28, 28, 384]             768\n",
      "   PatchMergingV2-65          [-1, 28, 28, 384]               0\n",
      "           Linear-66          [-1, 15, 15, 512]           1,536\n",
      "             ReLU-67          [-1, 15, 15, 512]               0\n",
      "           Linear-68           [-1, 15, 15, 12]           6,144\n",
      "ShiftedWindowAttentionV2-69          [-1, 28, 28, 384]               0\n",
      "        LayerNorm-70          [-1, 28, 28, 384]             768\n",
      "  StochasticDepth-71          [-1, 28, 28, 384]               0\n",
      "           Linear-72         [-1, 28, 28, 1536]         591,360\n",
      "             GELU-73         [-1, 28, 28, 1536]               0\n",
      "          Dropout-74         [-1, 28, 28, 1536]               0\n",
      "           Linear-75          [-1, 28, 28, 384]         590,208\n",
      "          Dropout-76          [-1, 28, 28, 384]               0\n",
      "        LayerNorm-77          [-1, 28, 28, 384]             768\n",
      "  StochasticDepth-78          [-1, 28, 28, 384]               0\n",
      "SwinTransformerBlockV2-79          [-1, 28, 28, 384]               0\n",
      "           Linear-80          [-1, 15, 15, 512]           1,536\n",
      "             ReLU-81          [-1, 15, 15, 512]               0\n",
      "           Linear-82           [-1, 15, 15, 12]           6,144\n",
      "ShiftedWindowAttentionV2-83          [-1, 28, 28, 384]               0\n",
      "        LayerNorm-84          [-1, 28, 28, 384]             768\n",
      "  StochasticDepth-85          [-1, 28, 28, 384]               0\n",
      "           Linear-86         [-1, 28, 28, 1536]         591,360\n",
      "             GELU-87         [-1, 28, 28, 1536]               0\n",
      "          Dropout-88         [-1, 28, 28, 1536]               0\n",
      "           Linear-89          [-1, 28, 28, 384]         590,208\n",
      "          Dropout-90          [-1, 28, 28, 384]               0\n",
      "        LayerNorm-91          [-1, 28, 28, 384]             768\n",
      "  StochasticDepth-92          [-1, 28, 28, 384]               0\n",
      "SwinTransformerBlockV2-93          [-1, 28, 28, 384]               0\n",
      "           Linear-94          [-1, 15, 15, 512]           1,536\n",
      "             ReLU-95          [-1, 15, 15, 512]               0\n",
      "           Linear-96           [-1, 15, 15, 12]           6,144\n",
      "ShiftedWindowAttentionV2-97          [-1, 28, 28, 384]               0\n",
      "        LayerNorm-98          [-1, 28, 28, 384]             768\n",
      "  StochasticDepth-99          [-1, 28, 28, 384]               0\n",
      "          Linear-100         [-1, 28, 28, 1536]         591,360\n",
      "            GELU-101         [-1, 28, 28, 1536]               0\n",
      "         Dropout-102         [-1, 28, 28, 1536]               0\n",
      "          Linear-103          [-1, 28, 28, 384]         590,208\n",
      "         Dropout-104          [-1, 28, 28, 384]               0\n",
      "       LayerNorm-105          [-1, 28, 28, 384]             768\n",
      " StochasticDepth-106          [-1, 28, 28, 384]               0\n",
      "SwinTransformerBlockV2-107          [-1, 28, 28, 384]               0\n",
      "          Linear-108          [-1, 15, 15, 512]           1,536\n",
      "            ReLU-109          [-1, 15, 15, 512]               0\n",
      "          Linear-110           [-1, 15, 15, 12]           6,144\n",
      "ShiftedWindowAttentionV2-111          [-1, 28, 28, 384]               0\n",
      "       LayerNorm-112          [-1, 28, 28, 384]             768\n",
      " StochasticDepth-113          [-1, 28, 28, 384]               0\n",
      "          Linear-114         [-1, 28, 28, 1536]         591,360\n",
      "            GELU-115         [-1, 28, 28, 1536]               0\n",
      "         Dropout-116         [-1, 28, 28, 1536]               0\n",
      "          Linear-117          [-1, 28, 28, 384]         590,208\n",
      "         Dropout-118          [-1, 28, 28, 384]               0\n",
      "       LayerNorm-119          [-1, 28, 28, 384]             768\n",
      " StochasticDepth-120          [-1, 28, 28, 384]               0\n",
      "SwinTransformerBlockV2-121          [-1, 28, 28, 384]               0\n",
      "          Linear-122          [-1, 15, 15, 512]           1,536\n",
      "            ReLU-123          [-1, 15, 15, 512]               0\n",
      "          Linear-124           [-1, 15, 15, 12]           6,144\n",
      "ShiftedWindowAttentionV2-125          [-1, 28, 28, 384]               0\n",
      "       LayerNorm-126          [-1, 28, 28, 384]             768\n",
      " StochasticDepth-127          [-1, 28, 28, 384]               0\n",
      "          Linear-128         [-1, 28, 28, 1536]         591,360\n",
      "            GELU-129         [-1, 28, 28, 1536]               0\n",
      "         Dropout-130         [-1, 28, 28, 1536]               0\n",
      "          Linear-131          [-1, 28, 28, 384]         590,208\n",
      "         Dropout-132          [-1, 28, 28, 384]               0\n",
      "       LayerNorm-133          [-1, 28, 28, 384]             768\n",
      " StochasticDepth-134          [-1, 28, 28, 384]               0\n",
      "SwinTransformerBlockV2-135          [-1, 28, 28, 384]               0\n",
      "          Linear-136          [-1, 15, 15, 512]           1,536\n",
      "            ReLU-137          [-1, 15, 15, 512]               0\n",
      "          Linear-138           [-1, 15, 15, 12]           6,144\n",
      "ShiftedWindowAttentionV2-139          [-1, 28, 28, 384]               0\n",
      "       LayerNorm-140          [-1, 28, 28, 384]             768\n",
      " StochasticDepth-141          [-1, 28, 28, 384]               0\n",
      "          Linear-142         [-1, 28, 28, 1536]         591,360\n",
      "            GELU-143         [-1, 28, 28, 1536]               0\n",
      "         Dropout-144         [-1, 28, 28, 1536]               0\n",
      "          Linear-145          [-1, 28, 28, 384]         590,208\n",
      "         Dropout-146          [-1, 28, 28, 384]               0\n",
      "       LayerNorm-147          [-1, 28, 28, 384]             768\n",
      " StochasticDepth-148          [-1, 28, 28, 384]               0\n",
      "SwinTransformerBlockV2-149          [-1, 28, 28, 384]               0\n",
      "          Linear-150          [-1, 14, 14, 768]       1,179,648\n",
      "       LayerNorm-151          [-1, 14, 14, 768]           1,536\n",
      "  PatchMergingV2-152          [-1, 14, 14, 768]               0\n",
      "          Linear-153          [-1, 15, 15, 512]           1,536\n",
      "            ReLU-154          [-1, 15, 15, 512]               0\n",
      "          Linear-155           [-1, 15, 15, 24]          12,288\n",
      "ShiftedWindowAttentionV2-156          [-1, 14, 14, 768]               0\n",
      "       LayerNorm-157          [-1, 14, 14, 768]           1,536\n",
      " StochasticDepth-158          [-1, 14, 14, 768]               0\n",
      "          Linear-159         [-1, 14, 14, 3072]       2,362,368\n",
      "            GELU-160         [-1, 14, 14, 3072]               0\n",
      "         Dropout-161         [-1, 14, 14, 3072]               0\n",
      "          Linear-162          [-1, 14, 14, 768]       2,360,064\n",
      "         Dropout-163          [-1, 14, 14, 768]               0\n",
      "       LayerNorm-164          [-1, 14, 14, 768]           1,536\n",
      " StochasticDepth-165          [-1, 14, 14, 768]               0\n",
      "SwinTransformerBlockV2-166          [-1, 14, 14, 768]               0\n",
      "          Linear-167          [-1, 15, 15, 512]           1,536\n",
      "            ReLU-168          [-1, 15, 15, 512]               0\n",
      "          Linear-169           [-1, 15, 15, 24]          12,288\n",
      "ShiftedWindowAttentionV2-170          [-1, 14, 14, 768]               0\n",
      "       LayerNorm-171          [-1, 14, 14, 768]           1,536\n",
      " StochasticDepth-172          [-1, 14, 14, 768]               0\n",
      "          Linear-173         [-1, 14, 14, 3072]       2,362,368\n",
      "            GELU-174         [-1, 14, 14, 3072]               0\n",
      "         Dropout-175         [-1, 14, 14, 3072]               0\n",
      "          Linear-176          [-1, 14, 14, 768]       2,360,064\n",
      "         Dropout-177          [-1, 14, 14, 768]               0\n",
      "       LayerNorm-178          [-1, 14, 14, 768]           1,536\n",
      " StochasticDepth-179          [-1, 14, 14, 768]               0\n",
      "SwinTransformerBlockV2-180          [-1, 14, 14, 768]               0\n",
      "       LayerNorm-181          [-1, 14, 14, 768]           1,536\n",
      "         Permute-182          [-1, 768, 14, 14]               0\n",
      "          Conv2d-183         [-1, 1024, 14, 14]         786,432\n",
      "     BatchNorm2d-184         [-1, 1024, 14, 14]           2,048\n",
      "            ReLU-185         [-1, 1024, 14, 14]               0\n",
      "          Conv2d-186         [-1, 1024, 14, 14]       9,437,184\n",
      "     BatchNorm2d-187         [-1, 1024, 14, 14]           2,048\n",
      "            ReLU-188         [-1, 1024, 14, 14]               0\n",
      "          Conv2d-189         [-1, 1024, 14, 14]       9,437,184\n",
      "     BatchNorm2d-190         [-1, 1024, 14, 14]           2,048\n",
      "            ReLU-191         [-1, 1024, 14, 14]               0\n",
      "          Conv2d-192         [-1, 1024, 14, 14]       9,437,184\n",
      "     BatchNorm2d-193         [-1, 1024, 14, 14]           2,048\n",
      "            ReLU-194         [-1, 1024, 14, 14]               0\n",
      "          Conv2d-195           [-1, 12, 14, 14]          12,288\n",
      "AdaptiveAvgPool2d-196             [-1, 12, 7, 7]               0\n",
      "================================================================\n",
      "Total params: 48,057,056\n",
      "Trainable params: 48,057,056\n",
      "Non-trainable params: 0\n",
      "----------------------------------------------------------------\n",
      "Input size (MB): 2.30\n",
      "Forward/backward pass size (MB): 966.52\n",
      "Params size (MB): 183.32\n",
      "Estimated Total Size (MB): 1152.14\n",
      "----------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "torchsummary.summary(model, (3,448,448))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "4cf3af4c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 12, 7, 7])\n"
     ]
    }
   ],
   "source": [
    "x = torch.randn(1, 3, 448, 448).to(device)\n",
    "with torch.no_grad():\n",
    "    y = model(x)\n",
    "print(y.shape)"
   ]
  },
  {
   "cell_type": "raw",
   "id": "f4c05720",
   "metadata": {
    "scrolled": true
   },
   "source": [
    "# data_dir = \"/content/drive/MyDrive/fastCamMedicalProj/DATASET/DATASET/Detection/\"\n",
    "BATCH_SIZE = 1\n",
    "\n",
    "# trainset = Detection_dataset(data_dir=data_dir, phase=\"train\", transformer=transformer)\n",
    "NECK_PATH = '/home/host_data/PET_data/Neck'\n",
    "BODY_PATH = '/home/host_data/PET_data/Body'\n",
    "trainset=PET_dataset(part='body',neck_dir=NECK_PATH,body_dir=BODY_PATH,phase='train', transformer=transformer)\n",
    "trainloader = DataLoader(trainset, batch_size=BATCH_SIZE, shuffle=False, collate_fn=collate_fn)\n",
    "\n",
    "model = YOLO_SWIN(num_classes=NUM_CLASSES)\n",
    "\n",
    "for index, batch in enumerate(trainloader):\n",
    "    images = batch[0]\n",
    "    targets = batch[1]\n",
    "    filenames = batch[2]\n",
    "    \n",
    "    predictions = model(images)\n",
    "    print(f\"filename:{filenames}, target:{targets}\")\n",
    "#     print(f\"{index}--input shape:{images.shape} -> output shape: {predictions.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8da970d7",
   "metadata": {},
   "source": [
    "# Loss func"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "3c66945c",
   "metadata": {},
   "outputs": [],
   "source": [
    "class YOLO_LOSS():\n",
    "    def __init__(self, num_classes, device, lambda_coord=5., lambda_noobj=0.5):\n",
    "        self.num_classes = num_classes\n",
    "        self.device = device\n",
    "        self.grid_size = 7\n",
    "        self.lambda_coord = lambda_coord\n",
    "        self.lambda_noobj = lambda_noobj\n",
    "        self.mse_loss = nn.MSELoss(reduction=\"sum\")\n",
    "\n",
    "    def __call__(self, predictions, targets):\n",
    "        self.batch_size, _, _, _ = predictions.shape\n",
    "        groundtruths = self.build_batch_target_grid(targets)\n",
    "        groundtruths = groundtruths.to(self.device)\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            iou1 = self.get_IoU(predictions[:, 1:5, ...], groundtruths[:, 1:5, ...])\n",
    "            iou2 = self.get_IoU(predictions[:, 6:10, ...], groundtruths[:, 1:5, ...])\n",
    "\n",
    "        ious = torch.stack([iou1, iou2], dim=1)\n",
    "        max_iou, best_box = ious.max(dim=1, keepdim=True)\n",
    "        max_iou = torch.cat([max_iou, max_iou], dim=1)\n",
    "        best_box = torch.cat([best_box.eq(0), best_box.eq(1)], dim=1)\n",
    "\n",
    "        predictions_ = predictions[:, :5*2, ...].reshape(self.batch_size, 2, 5, self.grid_size, self.grid_size)\n",
    "        obj_pred = predictions_[:, :, 0, ...]\n",
    "        xy_pred = predictions_[:, :, 1:3, ...]\n",
    "        wh_pred = predictions_[:, :, 3:5, ...]\n",
    "        cls_pred = predictions[:, 5*2:, ...]\n",
    "\n",
    "        groundtruths_ = groundtruths[:, :5, ...].reshape(self.batch_size, 1, 5, self.grid_size, self.grid_size)\n",
    "        obj_target = groundtruths_[:, :, 0, ...]\n",
    "        xy_target = groundtruths_[:, :, 1:3, ...]\n",
    "        wh_target= groundtruths_[:, :, 3:5, ...]\n",
    "        cls_target = groundtruths[:, 5:, ...]\n",
    "        \n",
    "        positive = obj_target * best_box\n",
    "\n",
    "        obj_loss = self.mse_loss(positive * obj_pred, positive * ious)\n",
    "        noobj_loss = self.mse_loss((1 - positive) * obj_pred, ious*0)\n",
    "        xy_loss = self.mse_loss(positive.unsqueeze(dim=2) * xy_pred, positive.unsqueeze(dim=2) * xy_target)\n",
    "        wh_loss = self.mse_loss(positive.unsqueeze(dim=2) * (wh_pred.sign() * (wh_pred.abs() + 1e-8).sqrt()),\n",
    "                           positive.unsqueeze(dim=2) * (wh_target + 1e-8).sqrt())\n",
    "        cls_loss = self.mse_loss(obj_target * cls_pred, cls_target)\n",
    "        \n",
    "        obj_loss /= self.batch_size\n",
    "        noobj_loss /= self.batch_size\n",
    "        bbox_loss = (xy_loss+wh_loss) / self.batch_size\n",
    "        cls_loss /= self.batch_size\n",
    "        \n",
    "        total_loss = obj_loss + self.lambda_noobj*noobj_loss + self.lambda_coord*bbox_loss + cls_loss\n",
    "        return total_loss, (obj_loss.item(), noobj_loss.item(), bbox_loss.item(), cls_loss.item())\n",
    "    \n",
    "    def build_target_grid(self, target):\n",
    "        target_grid = torch.zeros((1+4+self.num_classes, self.grid_size, self.grid_size), device=self.device)\n",
    "\n",
    "        for gt in target:\n",
    "            xc, yc, w, h, cls_id = gt\n",
    "            xn = (xc % (1/self.grid_size))\n",
    "            yn = (yc % (1/self.grid_size))\n",
    "            cls_id = int(cls_id)\n",
    "\n",
    "            i_grid = int(xc * self.grid_size)\n",
    "            j_grid = int(yc * self.grid_size)\n",
    "            target_grid[0, j_grid, i_grid] = 1\n",
    "            target_grid[1:5, j_grid, i_grid] = torch.Tensor([xn,yn,w,h])\n",
    "#             print(5+cls_id, j_grid, i_grid)\n",
    "            target_grid[5+cls_id, j_grid, i_grid] = 1\n",
    "\n",
    "        return target_grid\n",
    "    \n",
    "    def build_batch_target_grid(self, targets):\n",
    "        target_grid_batch = torch.stack([self.build_target_grid(target) for target in targets], dim=0)\n",
    "        return target_grid_batch\n",
    "    \n",
    "    def get_IoU(self, cbox1, cbox2):\n",
    "        box1 = self.xywh_to_xyxy(cbox1)\n",
    "        box2 = self.xywh_to_xyxy(cbox2)\n",
    "\n",
    "        x1 = torch.max(box1[:, 0, ...], box2[:, 0, ...])\n",
    "        y1 = torch.max(box1[:, 1, ...], box2[:, 1, ...])\n",
    "        x2 = torch.min(box1[:, 2, ...], box2[:, 2, ...])\n",
    "        y2 = torch.min(box1[:, 3, ...], box2[:, 3, ...])\n",
    "\n",
    "        intersection = (x2-x1).clamp(min=0) * (y2-y1).clamp(min=0)\n",
    "        union = abs(cbox1[:, 2, ...]*cbox1[:, 3, ...]) + \\\n",
    "                abs(cbox2[:, 2, ...]*cbox2[:, 3, ...]) - intersection\n",
    "\n",
    "        intersection[intersection.gt(0)] = intersection[intersection.gt(0)] / union[intersection.gt(0)]\n",
    "        return intersection\n",
    "    \n",
    "    def generate_xy_normed_grid(self):\n",
    "        y_offset, x_offset = torch.meshgrid(torch.arange(self.grid_size), torch.arange(self.grid_size))\n",
    "        xy_grid = torch.stack([x_offset, y_offset], dim=0)\n",
    "        xy_normed_grid = xy_grid / self.grid_size\n",
    "        return xy_normed_grid.to(self.device)\n",
    "\n",
    "    def xywh_to_xyxy(self, bboxes):\n",
    "        xy_normed_grid = self.generate_xy_normed_grid()\n",
    "        xcyc = bboxes[:,0:2,...] + xy_normed_grid.tile(self.batch_size, 1,1,1)\n",
    "        wh = bboxes[:,2:4,...]\n",
    "        x1y1 = xcyc - (wh/2)\n",
    "        x2y2 = xcyc + (wh/2)\n",
    "        return torch.cat([x1y1, x2y2], dim=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c46ad931",
   "metadata": {},
   "source": [
    "# Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "b1729df2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_one_epoch(dataloaders, model, criterion, optimizer, device):\n",
    "    train_loss = defaultdict(float)\n",
    "    val_loss = defaultdict(float)\n",
    "    \n",
    "    for phase in [\"train\", \"val\"]:\n",
    "        if phase == \"train\":\n",
    "            model.train()\n",
    "        else:\n",
    "            model.eval()\n",
    "        \n",
    "        running_loss = defaultdict(float)\n",
    "        for index, batch in enumerate(dataloaders[phase]):\n",
    "            images = batch[0].to(device)\n",
    "            targets = batch[1]\n",
    "            filenames = batch[2]\n",
    "            \n",
    "            with torch.set_grad_enabled(phase == \"train\"): # phase가 train 일때만 gradient 추적기능을 킨다.\n",
    "                predictions = model(images) #prediction shape=> B,12,7,7\n",
    "#             print(f\"predictions:{predictions}, \\ntargets: {targets}\\n\")\n",
    "            loss, (obj_loss, noobj_loss, bbox_loss, cls_loss) = criterion(predictions, targets)\n",
    "#             print(f\"loss:{loss}, obj_loss:{obj_loss}, noobj_loss:{noobj_loss}\\nbbox_loss:{bbox_loss}, cls_loss:{cls_loss}\\n--------------\\n\")\n",
    "            if phase == \"train\":\n",
    "                optimizer.zero_grad()\n",
    "                loss.backward()\n",
    "                optimizer.step()\n",
    "                \n",
    "                # 현재 epoch단계에서 loss가 얼마인지 running loss 가출력\n",
    "                running_loss[\"total_loss\"] += loss.item()\n",
    "                running_loss[\"obj_loss\"] += obj_loss\n",
    "                running_loss[\"noobj_loss\"] += noobj_loss\n",
    "                running_loss[\"bbox_loss\"] += bbox_loss\n",
    "                running_loss[\"cls_loss\"] += cls_loss\n",
    "                \n",
    "                train_loss[\"total_loss\"] += loss.item()\n",
    "                train_loss[\"obj_loss\"] += obj_loss\n",
    "                train_loss[\"noobj_loss\"] += noobj_loss\n",
    "                train_loss[\"bbox_loss\"] += bbox_loss\n",
    "                train_loss[\"cls_loss\"] += cls_loss\n",
    "                \n",
    "                if (index > 0) and (index % VERBOSE_FREQ) == 0:\n",
    "                    text = f\"<<<iteration:[{index}/{len(dataloaders[phase])}] - \"\n",
    "                    for k, v in running_loss.items():\n",
    "                        text += f\"{k}: {v/VERBOSE_FREQ:.4f}  \"\n",
    "                        running_loss[k] = 0.\n",
    "                    print(text)\n",
    "            else:\n",
    "                val_loss[\"total_loss\"] += loss.item()\n",
    "                val_loss[\"obj_loss\"] += obj_loss\n",
    "                val_loss[\"noobj_loss\"] += noobj_loss\n",
    "                val_loss[\"bbox_loss\"] += bbox_loss\n",
    "                val_loss[\"cls_loss\"] += cls_loss\n",
    "\n",
    "    for k in train_loss.keys():\n",
    "        train_loss[k] /= len(dataloaders[\"train\"])\n",
    "        val_loss[k] /= len(dataloaders[\"val\"])\n",
    "    return train_loss, val_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "cc20c145",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_dataloader(part, NECK_PATH, BODY_PATH, batch_size=2, aug_factor=0):\n",
    "    IMAGE_SIZE = 448\n",
    "    transformer = A.Compose([\n",
    "            A.Resize(height=IMAGE_SIZE, width=IMAGE_SIZE),\n",
    "            A.Normalize(mean=(0.485, 0.456, 0.406),std=(0.229, 0.224, 0.225)),\n",
    "            ToTensorV2(),\n",
    "        ],\n",
    "        bbox_params=A.BboxParams(format='yolo', label_fields=['class_ids']),\n",
    "    )\n",
    "    augmentator=A.Compose([\n",
    "    #     A.Resize(height=IMAGE_SIZE, width=IMAGE_SIZE),\n",
    "        A.HorizontalFlip(p=0.7),\n",
    "    #     A.Sharpen(p=0.7),\n",
    "        A.BBoxSafeRandomCrop(p=0.6),\n",
    "        A.VerticalFlip (p=0.6),\n",
    "        A.HueSaturationValue(p=0.6),\n",
    "        A.Resize(height=IMAGE_SIZE, width=IMAGE_SIZE),\n",
    "        A.Normalize(mean=(0.485, 0.456, 0.406),std=(0.229, 0.224, 0.225)),\n",
    "        ToTensorV2(),\n",
    "        ],\n",
    "        bbox_params=A.BboxParams(format='yolo', label_fields=['class_ids']),\n",
    "    )\n",
    "    \n",
    "    dataloaders = {}\n",
    "#     train_dataset = Detection_dataset(data_dir=data_dir, phase=\"train\", transformer=transformer)\n",
    "#     train_dataset=PET_dataset(part ,neck_dir=NECK_PATH,body_dir=BODY_PATH,phase='train', transformer=transformer, aug=augmentator, aug_factor=aug_factor)\n",
    "    train_dataset=PET_dataset(part ,neck_dir=NECK_PATH,body_dir=BODY_PATH,phase='train', transformer=transformer, aug=None)\n",
    "    dataloaders[\"train\"] = DataLoader(train_dataset, batch_size=batch_size, shuffle=True, collate_fn=collate_fn)\n",
    "\n",
    "#     val_dataset = Detection_dataset(data_dir=data_dir, phase=\"val\", transformer=transformer)\n",
    "    val_dataset=PET_dataset(part ,neck_dir=NECK_PATH,body_dir=BODY_PATH,phase='valid', transformer=transformer, aug=None)\n",
    "    dataloaders[\"val\"] = DataLoader(val_dataset, batch_size=batch_size, shuffle=False, collate_fn=collate_fn)\n",
    "    print(f\"trainset:{len(train_dataset)} validset:{len(val_dataset)}\")\n",
    "    return dataloaders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "2771b438",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "start making augmented images-- augmented factor:0\n",
      "total length of augmented images: 0\n",
      "start making augmented images-- augmented factor:0\n",
      "total length of augmented images: 0\n",
      "trainset:42000 validset:7200\n"
     ]
    }
   ],
   "source": [
    "# data_dir = \"/content/drive/MyDrive/fastCamMedicalProj/DATASET/DATASET/Detection/\"\n",
    "# NECK_PATH = '/home/host_data/PET_data/Neck'\n",
    "# BODY_PATH = '/home/host_data/PET_data/Body'\n",
    "NECK_PATH = '/home/host_data/PET_data_IP_AUG/aug_patched_Neck'\n",
    "BODY_PATH = '/home/host_data/PET_data_IP_AUG/Body'\n",
    "is_cuda = True\n",
    "\n",
    "NUM_CLASSES = 2\n",
    "IMAGE_SIZE = 448\n",
    "BATCH_SIZE = 16\n",
    "VERBOSE_FREQ = 20\n",
    "LR=0.0001\n",
    "AUG_FACTOR=4\n",
    "PATCH_FACTOR=50\n",
    "BACKBONE=\"YOLO_SWIN_T\"\n",
    "PART=\"neck\"\n",
    "num_epochs = 100\n",
    "# DEVICE = torch.device('cuda' if torch.cuda.is_available and is_cuda else 'cpu')\n",
    "\n",
    "dataloaders = build_dataloader(part=PART,NECK_PATH=NECK_PATH,BODY_PATH=BODY_PATH,batch_size=BATCH_SIZE, aug_factor=AUG_FACTOR)\n",
    "model = YOLO_SWIN(num_classes=NUM_CLASSES)\n",
    "model = model.to(device)\n",
    "criterion = YOLO_LOSS(num_classes=NUM_CLASSES, device=device)\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=LR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "060a24e6",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mgomduribo\u001b[0m (\u001b[33murp\u001b[0m). Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.15.12 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.15.11"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/workspace/Plastic_Bottle_defect_detection/experiments/wandb/run-20231019_091400-elvxwgth</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/urp/yolo_swin_neck_IMAGE_PATCH/runs/elvxwgth' target=\"_blank\">still-serenity-1</a></strong> to <a href='https://wandb.ai/urp/yolo_swin_neck_IMAGE_PATCH' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/urp/yolo_swin_neck_IMAGE_PATCH' target=\"_blank\">https://wandb.ai/urp/yolo_swin_neck_IMAGE_PATCH</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/urp/yolo_swin_neck_IMAGE_PATCH/runs/elvxwgth' target=\"_blank\">https://wandb.ai/urp/yolo_swin_neck_IMAGE_PATCH/runs/elvxwgth</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<button onClick=\"this.nextSibling.style.display='block';this.style.display='none';\">Display W&B run</button><iframe src='https://wandb.ai/urp/yolo_swin_neck_IMAGE_PATCH/runs/elvxwgth?jupyter=true' style='border:none;width:100%;height:420px;display:none;'></iframe>"
      ],
      "text/plain": [
       "<wandb.sdk.wandb_run.Run at 0x7fa5f1cca7c0>"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import wandb\n",
    "import random\n",
    "\n",
    "# start a new wandb run to track this script\n",
    "wandb.init(\n",
    "    # set the wandb project where this run will be logged\n",
    "    project=\"yolo_swin_neck_IMAGE_PATCH\",\n",
    "    \n",
    "    # track hyperparameters and run metadata\n",
    "    config={\n",
    "    \"learning_rate\": LR,\n",
    "    \"batch_size\": BATCH_SIZE,\n",
    "    \"architecture\": BACKBONE,\n",
    "    \"dataset\": PART,\n",
    "    \"epochs\": num_epochs,\n",
    "    \"patch factor\":PATCH_FACTOR,\n",
    "    \"aug factor\":AUG_FACTOR.\n",
    "    }\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "8ebab5dc",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.8/dist-packages/torch/functional.py:504: UserWarning: torch.meshgrid: in an upcoming release, it will be required to pass the indexing argument. (Triggered internally at /opt/pytorch/pytorch/aten/src/ATen/native/TensorShape.cpp:3423.)\n",
      "  return _VF.meshgrid(tensors, **kwargs)  # type: ignore[attr-defined]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<<<iteration:[20/657] - total_loss: 5.1420  obj_loss: 0.0719  noobj_loss: 3.3286  bbox_loss: 0.5320  cls_loss: 0.7457  \n",
      "<<<iteration:[40/657] - total_loss: 3.6397  obj_loss: 0.0520  noobj_loss: 2.6219  bbox_loss: 0.3610  cls_loss: 0.4715  \n",
      "<<<iteration:[60/657] - total_loss: 3.1291  obj_loss: 0.0571  noobj_loss: 2.3949  bbox_loss: 0.3018  cls_loss: 0.3654  \n",
      "<<<iteration:[80/657] - total_loss: 2.7706  obj_loss: 0.0430  noobj_loss: 2.1838  bbox_loss: 0.2613  cls_loss: 0.3293  \n",
      "<<<iteration:[100/657] - total_loss: 2.8573  obj_loss: 0.0473  noobj_loss: 2.0604  bbox_loss: 0.2957  cls_loss: 0.3011  \n",
      "<<<iteration:[120/657] - total_loss: 2.8664  obj_loss: 0.0427  noobj_loss: 1.9434  bbox_loss: 0.3095  cls_loss: 0.3044  \n",
      "<<<iteration:[140/657] - total_loss: 2.4828  obj_loss: 0.0468  noobj_loss: 1.8353  bbox_loss: 0.2524  cls_loss: 0.2561  \n",
      "<<<iteration:[160/657] - total_loss: 4.7442  obj_loss: 0.0398  noobj_loss: 2.0205  bbox_loss: 0.6776  cls_loss: 0.3062  \n",
      "<<<iteration:[180/657] - total_loss: 3.4136  obj_loss: 0.0369  noobj_loss: 1.9107  bbox_loss: 0.4298  cls_loss: 0.2723  \n",
      "<<<iteration:[200/657] - total_loss: 3.3978  obj_loss: 0.0364  noobj_loss: 1.8544  bbox_loss: 0.4247  cls_loss: 0.3108  \n",
      "<<<iteration:[220/657] - total_loss: 3.0685  obj_loss: 0.0409  noobj_loss: 1.8065  bbox_loss: 0.3664  cls_loss: 0.2925  \n",
      "<<<iteration:[240/657] - total_loss: 2.5087  obj_loss: 0.0403  noobj_loss: 1.6901  bbox_loss: 0.2680  cls_loss: 0.2832  \n",
      "<<<iteration:[260/657] - total_loss: 2.2614  obj_loss: 0.0463  noobj_loss: 1.6021  bbox_loss: 0.2305  cls_loss: 0.2614  \n",
      "<<<iteration:[280/657] - total_loss: 2.1131  obj_loss: 0.0427  noobj_loss: 1.5213  bbox_loss: 0.2084  cls_loss: 0.2675  \n",
      "<<<iteration:[300/657] - total_loss: 1.9473  obj_loss: 0.0444  noobj_loss: 1.4214  bbox_loss: 0.1898  cls_loss: 0.2433  \n",
      "<<<iteration:[320/657] - total_loss: 1.8667  obj_loss: 0.0450  noobj_loss: 1.3986  bbox_loss: 0.1773  cls_loss: 0.2360  \n",
      "<<<iteration:[340/657] - total_loss: 1.7455  obj_loss: 0.0426  noobj_loss: 1.3174  bbox_loss: 0.1631  cls_loss: 0.2289  \n",
      "<<<iteration:[360/657] - total_loss: 1.6608  obj_loss: 0.0454  noobj_loss: 1.2636  bbox_loss: 0.1528  cls_loss: 0.2196  \n",
      "<<<iteration:[380/657] - total_loss: 1.6139  obj_loss: 0.0415  noobj_loss: 1.2169  bbox_loss: 0.1490  cls_loss: 0.2192  \n",
      "<<<iteration:[400/657] - total_loss: 1.7813  obj_loss: 0.0383  noobj_loss: 1.2537  bbox_loss: 0.1776  cls_loss: 0.2284  \n",
      "<<<iteration:[420/657] - total_loss: 1.9690  obj_loss: 0.0471  noobj_loss: 1.2918  bbox_loss: 0.2097  cls_loss: 0.2273  \n",
      "<<<iteration:[440/657] - total_loss: 1.6357  obj_loss: 0.0384  noobj_loss: 1.1481  bbox_loss: 0.1618  cls_loss: 0.2142  \n",
      "<<<iteration:[460/657] - total_loss: 1.5373  obj_loss: 0.0439  noobj_loss: 1.0769  bbox_loss: 0.1503  cls_loss: 0.2033  \n",
      "<<<iteration:[480/657] - total_loss: 1.4510  obj_loss: 0.0470  noobj_loss: 1.0118  bbox_loss: 0.1403  cls_loss: 0.1968  \n",
      "<<<iteration:[500/657] - total_loss: 1.3864  obj_loss: 0.0508  noobj_loss: 0.9906  bbox_loss: 0.1310  cls_loss: 0.1856  \n",
      "<<<iteration:[520/657] - total_loss: 1.3831  obj_loss: 0.0514  noobj_loss: 0.9640  bbox_loss: 0.1345  cls_loss: 0.1770  \n",
      "<<<iteration:[540/657] - total_loss: 1.3113  obj_loss: 0.0459  noobj_loss: 0.9302  bbox_loss: 0.1258  cls_loss: 0.1713  \n",
      "<<<iteration:[560/657] - total_loss: 1.2432  obj_loss: 0.0492  noobj_loss: 0.8933  bbox_loss: 0.1174  cls_loss: 0.1607  \n",
      "<<<iteration:[580/657] - total_loss: 1.2478  obj_loss: 0.0443  noobj_loss: 0.8515  bbox_loss: 0.1204  cls_loss: 0.1755  \n",
      "<<<iteration:[600/657] - total_loss: 1.2243  obj_loss: 0.0537  noobj_loss: 0.8339  bbox_loss: 0.1164  cls_loss: 0.1717  \n",
      "<<<iteration:[620/657] - total_loss: 1.1400  obj_loss: 0.0498  noobj_loss: 0.8340  bbox_loss: 0.1003  cls_loss: 0.1717  \n",
      "<<<iteration:[640/657] - total_loss: 1.1702  obj_loss: 0.0475  noobj_loss: 0.8573  bbox_loss: 0.1056  cls_loss: 0.1662  \n",
      "\n",
      "epoch:1/100 - Train Loss: 2.2125, Val Loss: 1.1080\n",
      "\n",
      "<<<iteration:[20/657] - total_loss: 1.2545  obj_loss: 0.0499  noobj_loss: 0.8655  bbox_loss: 0.1217  cls_loss: 0.1631  \n",
      "<<<iteration:[40/657] - total_loss: 1.0774  obj_loss: 0.0574  noobj_loss: 0.7916  bbox_loss: 0.0951  cls_loss: 0.1485  \n",
      "<<<iteration:[60/657] - total_loss: 1.0721  obj_loss: 0.0599  noobj_loss: 0.7632  bbox_loss: 0.0947  cls_loss: 0.1569  \n",
      "<<<iteration:[80/657] - total_loss: 1.0410  obj_loss: 0.0521  noobj_loss: 0.7201  bbox_loss: 0.0960  cls_loss: 0.1487  \n",
      "<<<iteration:[100/657] - total_loss: 0.9962  obj_loss: 0.0610  noobj_loss: 0.6803  bbox_loss: 0.0899  cls_loss: 0.1456  \n",
      "<<<iteration:[120/657] - total_loss: 1.0383  obj_loss: 0.0628  noobj_loss: 0.6666  bbox_loss: 0.0985  cls_loss: 0.1495  \n",
      "<<<iteration:[140/657] - total_loss: 1.0120  obj_loss: 0.0709  noobj_loss: 0.6685  bbox_loss: 0.0927  cls_loss: 0.1434  \n",
      "<<<iteration:[160/657] - total_loss: 0.9672  obj_loss: 0.0668  noobj_loss: 0.6645  bbox_loss: 0.0914  cls_loss: 0.1109  \n",
      "<<<iteration:[180/657] - total_loss: 0.9677  obj_loss: 0.0595  noobj_loss: 0.6329  bbox_loss: 0.0920  cls_loss: 0.1316  \n",
      "<<<iteration:[200/657] - total_loss: 0.9248  obj_loss: 0.0631  noobj_loss: 0.6159  bbox_loss: 0.0839  cls_loss: 0.1341  \n",
      "<<<iteration:[220/657] - total_loss: 0.8152  obj_loss: 0.0753  noobj_loss: 0.5719  bbox_loss: 0.0670  cls_loss: 0.1188  \n",
      "<<<iteration:[240/657] - total_loss: 0.8305  obj_loss: 0.0788  noobj_loss: 0.5737  bbox_loss: 0.0639  cls_loss: 0.1454  \n",
      "<<<iteration:[260/657] - total_loss: 0.8696  obj_loss: 0.0588  noobj_loss: 0.5646  bbox_loss: 0.0799  cls_loss: 0.1290  \n",
      "<<<iteration:[280/657] - total_loss: 0.8155  obj_loss: 0.0646  noobj_loss: 0.5483  bbox_loss: 0.0702  cls_loss: 0.1255  \n",
      "<<<iteration:[300/657] - total_loss: 0.7806  obj_loss: 0.0698  noobj_loss: 0.5356  bbox_loss: 0.0659  cls_loss: 0.1136  \n",
      "<<<iteration:[320/657] - total_loss: 0.7750  obj_loss: 0.0749  noobj_loss: 0.5083  bbox_loss: 0.0646  cls_loss: 0.1228  \n",
      "<<<iteration:[340/657] - total_loss: 0.7618  obj_loss: 0.0748  noobj_loss: 0.4985  bbox_loss: 0.0642  cls_loss: 0.1169  \n",
      "<<<iteration:[360/657] - total_loss: 0.7520  obj_loss: 0.0771  noobj_loss: 0.5054  bbox_loss: 0.0631  cls_loss: 0.1065  \n",
      "<<<iteration:[380/657] - total_loss: 0.8193  obj_loss: 0.0837  noobj_loss: 0.5093  bbox_loss: 0.0690  cls_loss: 0.1359  \n",
      "<<<iteration:[400/657] - total_loss: 0.7336  obj_loss: 0.0790  noobj_loss: 0.4749  bbox_loss: 0.0592  cls_loss: 0.1210  \n",
      "<<<iteration:[420/657] - total_loss: 0.7525  obj_loss: 0.0842  noobj_loss: 0.4640  bbox_loss: 0.0647  cls_loss: 0.1127  \n",
      "<<<iteration:[440/657] - total_loss: 0.7464  obj_loss: 0.0763  noobj_loss: 0.4540  bbox_loss: 0.0652  cls_loss: 0.1172  \n",
      "<<<iteration:[460/657] - total_loss: 0.7328  obj_loss: 0.0826  noobj_loss: 0.4387  bbox_loss: 0.0608  cls_loss: 0.1268  \n",
      "<<<iteration:[480/657] - total_loss: 0.7174  obj_loss: 0.0757  noobj_loss: 0.4258  bbox_loss: 0.0610  cls_loss: 0.1238  \n",
      "<<<iteration:[500/657] - total_loss: 0.6995  obj_loss: 0.0786  noobj_loss: 0.4160  bbox_loss: 0.0592  cls_loss: 0.1170  \n",
      "<<<iteration:[520/657] - total_loss: 0.6879  obj_loss: 0.0916  noobj_loss: 0.4085  bbox_loss: 0.0557  cls_loss: 0.1136  \n",
      "<<<iteration:[540/657] - total_loss: 0.6565  obj_loss: 0.0867  noobj_loss: 0.3969  bbox_loss: 0.0526  cls_loss: 0.1086  \n",
      "<<<iteration:[560/657] - total_loss: 0.6424  obj_loss: 0.0876  noobj_loss: 0.3862  bbox_loss: 0.0449  cls_loss: 0.1372  \n",
      "<<<iteration:[580/657] - total_loss: 0.6277  obj_loss: 0.0829  noobj_loss: 0.3877  bbox_loss: 0.0501  cls_loss: 0.1005  \n",
      "<<<iteration:[600/657] - total_loss: 0.6481  obj_loss: 0.0756  noobj_loss: 0.3744  bbox_loss: 0.0556  cls_loss: 0.1075  \n",
      "<<<iteration:[620/657] - total_loss: 0.6124  obj_loss: 0.0892  noobj_loss: 0.3648  bbox_loss: 0.0483  cls_loss: 0.0993  \n",
      "<<<iteration:[640/657] - total_loss: 0.6536  obj_loss: 0.0861  noobj_loss: 0.3630  bbox_loss: 0.0545  cls_loss: 0.1135  \n",
      "\n",
      "epoch:2/100 - Train Loss: 0.8206, Val Loss: 0.5686\n",
      "\n",
      "<<<iteration:[20/657] - total_loss: 0.6074  obj_loss: 0.0997  noobj_loss: 0.3510  bbox_loss: 0.0452  cls_loss: 0.1062  \n",
      "<<<iteration:[40/657] - total_loss: 0.6050  obj_loss: 0.0974  noobj_loss: 0.3323  bbox_loss: 0.0472  cls_loss: 0.1055  \n",
      "<<<iteration:[60/657] - total_loss: 0.6442  obj_loss: 0.0917  noobj_loss: 0.3294  bbox_loss: 0.0557  cls_loss: 0.1092  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<<<iteration:[80/657] - total_loss: 0.6301  obj_loss: 0.0968  noobj_loss: 0.3127  bbox_loss: 0.0492  cls_loss: 0.1310  \n",
      "<<<iteration:[100/657] - total_loss: 0.6030  obj_loss: 0.0992  noobj_loss: 0.3161  bbox_loss: 0.0436  cls_loss: 0.1276  \n",
      "<<<iteration:[120/657] - total_loss: 0.5505  obj_loss: 0.1011  noobj_loss: 0.3086  bbox_loss: 0.0394  cls_loss: 0.0978  \n",
      "<<<iteration:[140/657] - total_loss: 0.5758  obj_loss: 0.0944  noobj_loss: 0.3204  bbox_loss: 0.0446  cls_loss: 0.0980  \n",
      "<<<iteration:[160/657] - total_loss: 0.5682  obj_loss: 0.0923  noobj_loss: 0.3039  bbox_loss: 0.0433  cls_loss: 0.1076  \n",
      "<<<iteration:[180/657] - total_loss: 0.5669  obj_loss: 0.1009  noobj_loss: 0.2870  bbox_loss: 0.0469  cls_loss: 0.0880  \n",
      "<<<iteration:[200/657] - total_loss: 0.5691  obj_loss: 0.1067  noobj_loss: 0.2885  bbox_loss: 0.0439  cls_loss: 0.0988  \n",
      "<<<iteration:[220/657] - total_loss: 0.5439  obj_loss: 0.1090  noobj_loss: 0.2812  bbox_loss: 0.0416  cls_loss: 0.0862  \n",
      "<<<iteration:[240/657] - total_loss: 0.5315  obj_loss: 0.1171  noobj_loss: 0.2780  bbox_loss: 0.0380  cls_loss: 0.0856  \n",
      "<<<iteration:[260/657] - total_loss: 0.5340  obj_loss: 0.1043  noobj_loss: 0.2812  bbox_loss: 0.0399  cls_loss: 0.0896  \n",
      "<<<iteration:[280/657] - total_loss: 0.5439  obj_loss: 0.1022  noobj_loss: 0.2701  bbox_loss: 0.0439  cls_loss: 0.0871  \n",
      "<<<iteration:[300/657] - total_loss: 0.5458  obj_loss: 0.1089  noobj_loss: 0.2678  bbox_loss: 0.0417  cls_loss: 0.0943  \n",
      "<<<iteration:[320/657] - total_loss: 0.4943  obj_loss: 0.1108  noobj_loss: 0.2574  bbox_loss: 0.0348  cls_loss: 0.0806  \n",
      "<<<iteration:[340/657] - total_loss: 0.5210  obj_loss: 0.1211  noobj_loss: 0.2661  bbox_loss: 0.0361  cls_loss: 0.0863  \n",
      "<<<iteration:[360/657] - total_loss: 0.5612  obj_loss: 0.1031  noobj_loss: 0.2519  bbox_loss: 0.0453  cls_loss: 0.1054  \n",
      "<<<iteration:[380/657] - total_loss: 0.5414  obj_loss: 0.1097  noobj_loss: 0.2501  bbox_loss: 0.0408  cls_loss: 0.1025  \n",
      "<<<iteration:[400/657] - total_loss: 0.5360  obj_loss: 0.1135  noobj_loss: 0.2517  bbox_loss: 0.0435  cls_loss: 0.0792  \n",
      "<<<iteration:[420/657] - total_loss: 0.4933  obj_loss: 0.1024  noobj_loss: 0.2469  bbox_loss: 0.0368  cls_loss: 0.0834  \n",
      "<<<iteration:[440/657] - total_loss: 0.5045  obj_loss: 0.1194  noobj_loss: 0.2380  bbox_loss: 0.0360  cls_loss: 0.0859  \n",
      "<<<iteration:[460/657] - total_loss: 0.5348  obj_loss: 0.1106  noobj_loss: 0.2453  bbox_loss: 0.0434  cls_loss: 0.0848  \n",
      "<<<iteration:[480/657] - total_loss: 0.5376  obj_loss: 0.1017  noobj_loss: 0.2308  bbox_loss: 0.0425  cls_loss: 0.1082  \n",
      "<<<iteration:[500/657] - total_loss: 0.9873  obj_loss: 0.0796  noobj_loss: 0.2718  bbox_loss: 0.1331  cls_loss: 0.1061  \n",
      "<<<iteration:[520/657] - total_loss: 0.6713  obj_loss: 0.0878  noobj_loss: 0.2405  bbox_loss: 0.0756  cls_loss: 0.0854  \n",
      "<<<iteration:[540/657] - total_loss: 0.6747  obj_loss: 0.1004  noobj_loss: 0.2471  bbox_loss: 0.0713  cls_loss: 0.0941  \n",
      "<<<iteration:[560/657] - total_loss: 0.5302  obj_loss: 0.1073  noobj_loss: 0.2366  bbox_loss: 0.0445  cls_loss: 0.0821  \n",
      "<<<iteration:[580/657] - total_loss: 0.5302  obj_loss: 0.1209  noobj_loss: 0.2209  bbox_loss: 0.0423  cls_loss: 0.0876  \n",
      "<<<iteration:[600/657] - total_loss: 0.5252  obj_loss: 0.1246  noobj_loss: 0.2217  bbox_loss: 0.0404  cls_loss: 0.0880  \n",
      "<<<iteration:[620/657] - total_loss: 0.5120  obj_loss: 0.1235  noobj_loss: 0.2225  bbox_loss: 0.0379  cls_loss: 0.0876  \n",
      "<<<iteration:[640/657] - total_loss: 0.5501  obj_loss: 0.1151  noobj_loss: 0.2209  bbox_loss: 0.0470  cls_loss: 0.0894  \n",
      "\n",
      "epoch:3/100 - Train Loss: 0.5701, Val Loss: 0.4308\n",
      "\n",
      "<<<iteration:[20/657] - total_loss: 0.5057  obj_loss: 0.1275  noobj_loss: 0.2239  bbox_loss: 0.0377  cls_loss: 0.0778  \n",
      "<<<iteration:[40/657] - total_loss: 0.4838  obj_loss: 0.1227  noobj_loss: 0.2005  bbox_loss: 0.0338  cls_loss: 0.0917  \n",
      "<<<iteration:[60/657] - total_loss: 0.4788  obj_loss: 0.1271  noobj_loss: 0.2020  bbox_loss: 0.0332  cls_loss: 0.0845  \n",
      "<<<iteration:[80/657] - total_loss: 0.5006  obj_loss: 0.1185  noobj_loss: 0.2033  bbox_loss: 0.0365  cls_loss: 0.0979  \n",
      "<<<iteration:[100/657] - total_loss: 0.4536  obj_loss: 0.1361  noobj_loss: 0.1945  bbox_loss: 0.0327  cls_loss: 0.0568  \n",
      "<<<iteration:[120/657] - total_loss: 0.4761  obj_loss: 0.1282  noobj_loss: 0.1958  bbox_loss: 0.0325  cls_loss: 0.0877  \n",
      "<<<iteration:[140/657] - total_loss: 0.4726  obj_loss: 0.1275  noobj_loss: 0.1907  bbox_loss: 0.0353  cls_loss: 0.0730  \n",
      "<<<iteration:[160/657] - total_loss: 0.4499  obj_loss: 0.1293  noobj_loss: 0.1852  bbox_loss: 0.0316  cls_loss: 0.0700  \n",
      "<<<iteration:[180/657] - total_loss: 0.4716  obj_loss: 0.1332  noobj_loss: 0.1858  bbox_loss: 0.0329  cls_loss: 0.0808  \n",
      "<<<iteration:[200/657] - total_loss: 0.4500  obj_loss: 0.1370  noobj_loss: 0.1743  bbox_loss: 0.0310  cls_loss: 0.0707  \n",
      "<<<iteration:[220/657] - total_loss: 0.4468  obj_loss: 0.1297  noobj_loss: 0.1815  bbox_loss: 0.0293  cls_loss: 0.0799  \n",
      "<<<iteration:[240/657] - total_loss: 0.4423  obj_loss: 0.1297  noobj_loss: 0.1762  bbox_loss: 0.0294  cls_loss: 0.0777  \n",
      "<<<iteration:[260/657] - total_loss: 0.4776  obj_loss: 0.1358  noobj_loss: 0.1763  bbox_loss: 0.0301  cls_loss: 0.1031  \n",
      "<<<iteration:[280/657] - total_loss: 0.4506  obj_loss: 0.1412  noobj_loss: 0.1803  bbox_loss: 0.0289  cls_loss: 0.0749  \n",
      "<<<iteration:[300/657] - total_loss: 0.4792  obj_loss: 0.1371  noobj_loss: 0.1786  bbox_loss: 0.0321  cls_loss: 0.0921  \n",
      "<<<iteration:[320/657] - total_loss: 0.4512  obj_loss: 0.1325  noobj_loss: 0.1726  bbox_loss: 0.0311  cls_loss: 0.0771  \n",
      "<<<iteration:[340/657] - total_loss: 0.4207  obj_loss: 0.1301  noobj_loss: 0.1706  bbox_loss: 0.0265  cls_loss: 0.0731  \n",
      "<<<iteration:[360/657] - total_loss: 0.4496  obj_loss: 0.1379  noobj_loss: 0.1745  bbox_loss: 0.0295  cls_loss: 0.0767  \n",
      "<<<iteration:[380/657] - total_loss: 0.4529  obj_loss: 0.1250  noobj_loss: 0.1603  bbox_loss: 0.0315  cls_loss: 0.0901  \n",
      "<<<iteration:[400/657] - total_loss: 0.4574  obj_loss: 0.1351  noobj_loss: 0.1730  bbox_loss: 0.0316  cls_loss: 0.0777  \n",
      "<<<iteration:[420/657] - total_loss: 0.4443  obj_loss: 0.1322  noobj_loss: 0.1617  bbox_loss: 0.0298  cls_loss: 0.0824  \n",
      "<<<iteration:[440/657] - total_loss: 0.4393  obj_loss: 0.1510  noobj_loss: 0.1640  bbox_loss: 0.0266  cls_loss: 0.0732  \n",
      "<<<iteration:[460/657] - total_loss: 0.4409  obj_loss: 0.1503  noobj_loss: 0.1532  bbox_loss: 0.0260  cls_loss: 0.0837  \n",
      "<<<iteration:[480/657] - total_loss: 0.4682  obj_loss: 0.1349  noobj_loss: 0.1561  bbox_loss: 0.0304  cls_loss: 0.1030  \n",
      "<<<iteration:[500/657] - total_loss: 0.4174  obj_loss: 0.1355  noobj_loss: 0.1595  bbox_loss: 0.0269  cls_loss: 0.0678  \n",
      "<<<iteration:[520/657] - total_loss: 0.4224  obj_loss: 0.1422  noobj_loss: 0.1544  bbox_loss: 0.0273  cls_loss: 0.0665  \n",
      "<<<iteration:[540/657] - total_loss: 0.4588  obj_loss: 0.1367  noobj_loss: 0.1626  bbox_loss: 0.0301  cls_loss: 0.0903  \n",
      "<<<iteration:[560/657] - total_loss: 0.4143  obj_loss: 0.1262  noobj_loss: 0.1591  bbox_loss: 0.0265  cls_loss: 0.0763  \n",
      "<<<iteration:[580/657] - total_loss: 0.4239  obj_loss: 0.1425  noobj_loss: 0.1509  bbox_loss: 0.0255  cls_loss: 0.0786  \n",
      "<<<iteration:[600/657] - total_loss: 0.4447  obj_loss: 0.1477  noobj_loss: 0.1499  bbox_loss: 0.0278  cls_loss: 0.0830  \n",
      "<<<iteration:[620/657] - total_loss: 0.4494  obj_loss: 0.1325  noobj_loss: 0.1510  bbox_loss: 0.0317  cls_loss: 0.0828  \n",
      "<<<iteration:[640/657] - total_loss: 0.4209  obj_loss: 0.1395  noobj_loss: 0.1531  bbox_loss: 0.0261  cls_loss: 0.0744  \n",
      "\n",
      "epoch:4/100 - Train Loss: 0.4525, Val Loss: 0.3907\n",
      "\n",
      "<<<iteration:[20/657] - total_loss: 0.4587  obj_loss: 0.1470  noobj_loss: 0.1639  bbox_loss: 0.0292  cls_loss: 0.0836  \n",
      "<<<iteration:[40/657] - total_loss: 0.4363  obj_loss: 0.1392  noobj_loss: 0.1433  bbox_loss: 0.0290  cls_loss: 0.0805  \n",
      "<<<iteration:[60/657] - total_loss: 0.4048  obj_loss: 0.1378  noobj_loss: 0.1460  bbox_loss: 0.0242  cls_loss: 0.0732  \n",
      "<<<iteration:[80/657] - total_loss: 0.4303  obj_loss: 0.1352  noobj_loss: 0.1522  bbox_loss: 0.0289  cls_loss: 0.0743  \n",
      "<<<iteration:[100/657] - total_loss: 0.3999  obj_loss: 0.1281  noobj_loss: 0.1438  bbox_loss: 0.0263  cls_loss: 0.0686  \n",
      "<<<iteration:[120/657] - total_loss: 0.3899  obj_loss: 0.1585  noobj_loss: 0.1388  bbox_loss: 0.0202  cls_loss: 0.0612  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<<<iteration:[140/657] - total_loss: 0.4287  obj_loss: 0.1494  noobj_loss: 0.1426  bbox_loss: 0.0272  cls_loss: 0.0717  \n",
      "<<<iteration:[160/657] - total_loss: 0.4518  obj_loss: 0.1370  noobj_loss: 0.1499  bbox_loss: 0.0311  cls_loss: 0.0844  \n",
      "<<<iteration:[180/657] - total_loss: 0.4214  obj_loss: 0.1496  noobj_loss: 0.1413  bbox_loss: 0.0264  cls_loss: 0.0692  \n",
      "<<<iteration:[200/657] - total_loss: 0.3994  obj_loss: 0.1421  noobj_loss: 0.1393  bbox_loss: 0.0246  cls_loss: 0.0647  \n",
      "<<<iteration:[220/657] - total_loss: 0.4121  obj_loss: 0.1566  noobj_loss: 0.1417  bbox_loss: 0.0243  cls_loss: 0.0629  \n",
      "<<<iteration:[240/657] - total_loss: 0.4056  obj_loss: 0.1424  noobj_loss: 0.1412  bbox_loss: 0.0264  cls_loss: 0.0607  \n",
      "<<<iteration:[260/657] - total_loss: 0.4176  obj_loss: 0.1451  noobj_loss: 0.1337  bbox_loss: 0.0250  cls_loss: 0.0808  \n",
      "<<<iteration:[280/657] - total_loss: 0.4204  obj_loss: 0.1511  noobj_loss: 0.1381  bbox_loss: 0.0264  cls_loss: 0.0682  \n",
      "<<<iteration:[300/657] - total_loss: 0.4355  obj_loss: 0.1398  noobj_loss: 0.1333  bbox_loss: 0.0292  cls_loss: 0.0831  \n",
      "<<<iteration:[320/657] - total_loss: 0.4052  obj_loss: 0.1530  noobj_loss: 0.1365  bbox_loss: 0.0229  cls_loss: 0.0696  \n",
      "<<<iteration:[340/657] - total_loss: 0.4031  obj_loss: 0.1544  noobj_loss: 0.1379  bbox_loss: 0.0243  cls_loss: 0.0581  \n",
      "<<<iteration:[360/657] - total_loss: 0.3912  obj_loss: 0.1497  noobj_loss: 0.1315  bbox_loss: 0.0228  cls_loss: 0.0616  \n",
      "<<<iteration:[380/657] - total_loss: 0.4094  obj_loss: 0.1512  noobj_loss: 0.1341  bbox_loss: 0.0240  cls_loss: 0.0709  \n",
      "<<<iteration:[400/657] - total_loss: 0.4193  obj_loss: 0.1501  noobj_loss: 0.1371  bbox_loss: 0.0242  cls_loss: 0.0795  \n",
      "<<<iteration:[420/657] - total_loss: 0.4096  obj_loss: 0.1472  noobj_loss: 0.1328  bbox_loss: 0.0253  cls_loss: 0.0695  \n",
      "<<<iteration:[440/657] - total_loss: 0.3924  obj_loss: 0.1497  noobj_loss: 0.1263  bbox_loss: 0.0244  cls_loss: 0.0578  \n",
      "<<<iteration:[460/657] - total_loss: 0.4115  obj_loss: 0.1544  noobj_loss: 0.1288  bbox_loss: 0.0247  cls_loss: 0.0689  \n",
      "<<<iteration:[480/657] - total_loss: 0.4033  obj_loss: 0.1560  noobj_loss: 0.1311  bbox_loss: 0.0233  cls_loss: 0.0653  \n",
      "<<<iteration:[500/657] - total_loss: 0.4277  obj_loss: 0.1433  noobj_loss: 0.1285  bbox_loss: 0.0255  cls_loss: 0.0925  \n",
      "<<<iteration:[520/657] - total_loss: 0.4041  obj_loss: 0.1646  noobj_loss: 0.1212  bbox_loss: 0.0220  cls_loss: 0.0689  \n",
      "<<<iteration:[540/657] - total_loss: 0.3904  obj_loss: 0.1645  noobj_loss: 0.1327  bbox_loss: 0.0223  cls_loss: 0.0481  \n",
      "<<<iteration:[560/657] - total_loss: 0.4021  obj_loss: 0.1508  noobj_loss: 0.1208  bbox_loss: 0.0236  cls_loss: 0.0732  \n",
      "<<<iteration:[580/657] - total_loss: 0.3911  obj_loss: 0.1345  noobj_loss: 0.1259  bbox_loss: 0.0248  cls_loss: 0.0697  \n",
      "<<<iteration:[600/657] - total_loss: 0.4116  obj_loss: 0.1546  noobj_loss: 0.1251  bbox_loss: 0.0235  cls_loss: 0.0769  \n",
      "<<<iteration:[620/657] - total_loss: 0.3950  obj_loss: 0.1459  noobj_loss: 0.1226  bbox_loss: 0.0235  cls_loss: 0.0705  \n",
      "<<<iteration:[640/657] - total_loss: 0.3860  obj_loss: 0.1574  noobj_loss: 0.1233  bbox_loss: 0.0218  cls_loss: 0.0577  \n",
      "\n",
      "epoch:5/100 - Train Loss: 0.4108, Val Loss: 0.3903\n",
      "\n",
      "<<<iteration:[20/657] - total_loss: 0.3975  obj_loss: 0.1543  noobj_loss: 0.1333  bbox_loss: 0.0227  cls_loss: 0.0631  \n",
      "<<<iteration:[40/657] - total_loss: 0.3908  obj_loss: 0.1532  noobj_loss: 0.1244  bbox_loss: 0.0229  cls_loss: 0.0608  \n",
      "<<<iteration:[60/657] - total_loss: 0.3701  obj_loss: 0.1606  noobj_loss: 0.1198  bbox_loss: 0.0199  cls_loss: 0.0502  \n",
      "<<<iteration:[80/657] - total_loss: 0.3952  obj_loss: 0.1615  noobj_loss: 0.1230  bbox_loss: 0.0211  cls_loss: 0.0667  \n",
      "<<<iteration:[100/657] - total_loss: 0.3856  obj_loss: 0.1505  noobj_loss: 0.1179  bbox_loss: 0.0217  cls_loss: 0.0678  \n",
      "<<<iteration:[120/657] - total_loss: 0.4059  obj_loss: 0.1584  noobj_loss: 0.1202  bbox_loss: 0.0238  cls_loss: 0.0686  \n",
      "<<<iteration:[140/657] - total_loss: 0.3903  obj_loss: 0.1469  noobj_loss: 0.1204  bbox_loss: 0.0231  cls_loss: 0.0677  \n",
      "<<<iteration:[160/657] - total_loss: 0.3915  obj_loss: 0.1660  noobj_loss: 0.1147  bbox_loss: 0.0224  cls_loss: 0.0564  \n",
      "<<<iteration:[180/657] - total_loss: 0.3965  obj_loss: 0.1711  noobj_loss: 0.1231  bbox_loss: 0.0198  cls_loss: 0.0647  \n",
      "<<<iteration:[200/657] - total_loss: 0.4071  obj_loss: 0.1546  noobj_loss: 0.1258  bbox_loss: 0.0241  cls_loss: 0.0690  \n",
      "<<<iteration:[220/657] - total_loss: 0.3954  obj_loss: 0.1510  noobj_loss: 0.1166  bbox_loss: 0.0221  cls_loss: 0.0756  \n",
      "<<<iteration:[240/657] - total_loss: 0.3656  obj_loss: 0.1590  noobj_loss: 0.1103  bbox_loss: 0.0203  cls_loss: 0.0498  \n",
      "<<<iteration:[260/657] - total_loss: 0.4117  obj_loss: 0.1675  noobj_loss: 0.1245  bbox_loss: 0.0228  cls_loss: 0.0681  \n",
      "<<<iteration:[280/657] - total_loss: 0.3866  obj_loss: 0.1662  noobj_loss: 0.1140  bbox_loss: 0.0211  cls_loss: 0.0579  \n",
      "<<<iteration:[300/657] - total_loss: 0.4017  obj_loss: 0.1520  noobj_loss: 0.1078  bbox_loss: 0.0234  cls_loss: 0.0787  \n",
      "<<<iteration:[320/657] - total_loss: 0.3738  obj_loss: 0.1577  noobj_loss: 0.1122  bbox_loss: 0.0191  cls_loss: 0.0643  \n",
      "<<<iteration:[340/657] - total_loss: 0.3709  obj_loss: 0.1768  noobj_loss: 0.1092  bbox_loss: 0.0183  cls_loss: 0.0480  \n",
      "<<<iteration:[360/657] - total_loss: 0.3842  obj_loss: 0.1685  noobj_loss: 0.1150  bbox_loss: 0.0193  cls_loss: 0.0617  \n",
      "<<<iteration:[380/657] - total_loss: 0.3857  obj_loss: 0.1571  noobj_loss: 0.1176  bbox_loss: 0.0198  cls_loss: 0.0710  \n",
      "<<<iteration:[400/657] - total_loss: 0.3746  obj_loss: 0.1573  noobj_loss: 0.1125  bbox_loss: 0.0203  cls_loss: 0.0594  \n",
      "<<<iteration:[420/657] - total_loss: 0.4076  obj_loss: 0.1579  noobj_loss: 0.1122  bbox_loss: 0.0217  cls_loss: 0.0849  \n",
      "<<<iteration:[440/657] - total_loss: 0.3828  obj_loss: 0.1661  noobj_loss: 0.1143  bbox_loss: 0.0196  cls_loss: 0.0616  \n",
      "<<<iteration:[460/657] - total_loss: 0.4495  obj_loss: 0.1281  noobj_loss: 0.1146  bbox_loss: 0.0405  cls_loss: 0.0618  \n",
      "<<<iteration:[480/657] - total_loss: 0.3857  obj_loss: 0.1538  noobj_loss: 0.1138  bbox_loss: 0.0238  cls_loss: 0.0562  \n",
      "<<<iteration:[500/657] - total_loss: 0.3929  obj_loss: 0.1601  noobj_loss: 0.1139  bbox_loss: 0.0223  cls_loss: 0.0644  \n",
      "<<<iteration:[520/657] - total_loss: 0.3862  obj_loss: 0.1589  noobj_loss: 0.1126  bbox_loss: 0.0213  cls_loss: 0.0644  \n",
      "<<<iteration:[540/657] - total_loss: 0.3900  obj_loss: 0.1568  noobj_loss: 0.1115  bbox_loss: 0.0223  cls_loss: 0.0661  \n",
      "<<<iteration:[560/657] - total_loss: 0.3947  obj_loss: 0.1640  noobj_loss: 0.1126  bbox_loss: 0.0219  cls_loss: 0.0648  \n",
      "<<<iteration:[580/657] - total_loss: 0.3877  obj_loss: 0.1706  noobj_loss: 0.1142  bbox_loss: 0.0201  cls_loss: 0.0598  \n",
      "<<<iteration:[600/657] - total_loss: 0.3819  obj_loss: 0.1593  noobj_loss: 0.1106  bbox_loss: 0.0216  cls_loss: 0.0595  \n",
      "<<<iteration:[620/657] - total_loss: 0.4090  obj_loss: 0.1613  noobj_loss: 0.1125  bbox_loss: 0.0232  cls_loss: 0.0753  \n",
      "<<<iteration:[640/657] - total_loss: 0.3828  obj_loss: 0.1473  noobj_loss: 0.1134  bbox_loss: 0.0210  cls_loss: 0.0739  \n",
      "\n",
      "epoch:6/100 - Train Loss: 0.3909, Val Loss: 0.3607\n",
      "\n",
      "<<<iteration:[20/657] - total_loss: 0.4046  obj_loss: 0.1698  noobj_loss: 0.1197  bbox_loss: 0.0238  cls_loss: 0.0560  \n",
      "<<<iteration:[40/657] - total_loss: 0.3703  obj_loss: 0.1585  noobj_loss: 0.1077  bbox_loss: 0.0199  cls_loss: 0.0586  \n",
      "<<<iteration:[60/657] - total_loss: 0.3926  obj_loss: 0.1767  noobj_loss: 0.1087  bbox_loss: 0.0195  cls_loss: 0.0639  \n",
      "<<<iteration:[80/657] - total_loss: 0.4097  obj_loss: 0.1688  noobj_loss: 0.1102  bbox_loss: 0.0227  cls_loss: 0.0723  \n",
      "<<<iteration:[100/657] - total_loss: 0.3998  obj_loss: 0.1686  noobj_loss: 0.1167  bbox_loss: 0.0220  cls_loss: 0.0629  \n",
      "<<<iteration:[120/657] - total_loss: 0.3796  obj_loss: 0.1608  noobj_loss: 0.0999  bbox_loss: 0.0214  cls_loss: 0.0618  \n",
      "<<<iteration:[140/657] - total_loss: 0.3772  obj_loss: 0.1588  noobj_loss: 0.1097  bbox_loss: 0.0193  cls_loss: 0.0671  \n",
      "<<<iteration:[160/657] - total_loss: 0.3857  obj_loss: 0.1777  noobj_loss: 0.1115  bbox_loss: 0.0199  cls_loss: 0.0526  \n",
      "<<<iteration:[180/657] - total_loss: 0.3680  obj_loss: 0.1698  noobj_loss: 0.1084  bbox_loss: 0.0180  cls_loss: 0.0538  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<<<iteration:[200/657] - total_loss: 0.3855  obj_loss: 0.1733  noobj_loss: 0.1091  bbox_loss: 0.0195  cls_loss: 0.0600  \n",
      "<<<iteration:[220/657] - total_loss: 0.3811  obj_loss: 0.1573  noobj_loss: 0.1051  bbox_loss: 0.0218  cls_loss: 0.0622  \n",
      "<<<iteration:[240/657] - total_loss: 0.3756  obj_loss: 0.1682  noobj_loss: 0.1104  bbox_loss: 0.0190  cls_loss: 0.0573  \n",
      "<<<iteration:[260/657] - total_loss: 0.3954  obj_loss: 0.1622  noobj_loss: 0.1091  bbox_loss: 0.0210  cls_loss: 0.0737  \n",
      "<<<iteration:[280/657] - total_loss: 0.4008  obj_loss: 0.1684  noobj_loss: 0.1023  bbox_loss: 0.0230  cls_loss: 0.0664  \n",
      "<<<iteration:[300/657] - total_loss: 0.3668  obj_loss: 0.1804  noobj_loss: 0.1054  bbox_loss: 0.0180  cls_loss: 0.0435  \n",
      "<<<iteration:[320/657] - total_loss: 0.3627  obj_loss: 0.1628  noobj_loss: 0.1042  bbox_loss: 0.0187  cls_loss: 0.0545  \n",
      "<<<iteration:[340/657] - total_loss: 0.3477  obj_loss: 0.1515  noobj_loss: 0.1062  bbox_loss: 0.0192  cls_loss: 0.0470  \n",
      "<<<iteration:[360/657] - total_loss: 0.3722  obj_loss: 0.1765  noobj_loss: 0.1027  bbox_loss: 0.0178  cls_loss: 0.0552  \n",
      "<<<iteration:[380/657] - total_loss: 0.3540  obj_loss: 0.1664  noobj_loss: 0.1045  bbox_loss: 0.0180  cls_loss: 0.0454  \n",
      "<<<iteration:[400/657] - total_loss: 0.3835  obj_loss: 0.1810  noobj_loss: 0.1070  bbox_loss: 0.0180  cls_loss: 0.0590  \n",
      "<<<iteration:[420/657] - total_loss: 0.3801  obj_loss: 0.1730  noobj_loss: 0.1082  bbox_loss: 0.0177  cls_loss: 0.0644  \n",
      "<<<iteration:[440/657] - total_loss: 0.3552  obj_loss: 0.1592  noobj_loss: 0.1010  bbox_loss: 0.0169  cls_loss: 0.0609  \n",
      "<<<iteration:[460/657] - total_loss: 0.3639  obj_loss: 0.1729  noobj_loss: 0.1073  bbox_loss: 0.0175  cls_loss: 0.0496  \n",
      "<<<iteration:[480/657] - total_loss: 0.3801  obj_loss: 0.1760  noobj_loss: 0.1082  bbox_loss: 0.0185  cls_loss: 0.0575  \n",
      "<<<iteration:[500/657] - total_loss: 0.3802  obj_loss: 0.1652  noobj_loss: 0.1023  bbox_loss: 0.0207  cls_loss: 0.0603  \n",
      "<<<iteration:[520/657] - total_loss: 0.3613  obj_loss: 0.1560  noobj_loss: 0.1035  bbox_loss: 0.0215  cls_loss: 0.0459  \n",
      "<<<iteration:[540/657] - total_loss: 0.3774  obj_loss: 0.1660  noobj_loss: 0.1111  bbox_loss: 0.0195  cls_loss: 0.0585  \n",
      "<<<iteration:[560/657] - total_loss: 0.3731  obj_loss: 0.1633  noobj_loss: 0.1027  bbox_loss: 0.0205  cls_loss: 0.0560  \n",
      "<<<iteration:[580/657] - total_loss: 0.3811  obj_loss: 0.1718  noobj_loss: 0.1064  bbox_loss: 0.0200  cls_loss: 0.0561  \n",
      "<<<iteration:[600/657] - total_loss: 0.3632  obj_loss: 0.1736  noobj_loss: 0.1041  bbox_loss: 0.0187  cls_loss: 0.0442  \n",
      "<<<iteration:[620/657] - total_loss: 0.3744  obj_loss: 0.1703  noobj_loss: 0.1072  bbox_loss: 0.0181  cls_loss: 0.0598  \n",
      "<<<iteration:[640/657] - total_loss: 0.3637  obj_loss: 0.1494  noobj_loss: 0.1053  bbox_loss: 0.0184  cls_loss: 0.0694  \n",
      "\n",
      "epoch:7/100 - Train Loss: 0.3769, Val Loss: 0.3824\n",
      "\n",
      "<<<iteration:[20/657] - total_loss: 0.3806  obj_loss: 0.1829  noobj_loss: 0.1110  bbox_loss: 0.0179  cls_loss: 0.0527  \n",
      "<<<iteration:[40/657] - total_loss: 0.3723  obj_loss: 0.1742  noobj_loss: 0.1049  bbox_loss: 0.0172  cls_loss: 0.0599  \n",
      "<<<iteration:[60/657] - total_loss: 0.3618  obj_loss: 0.1745  noobj_loss: 0.1031  bbox_loss: 0.0177  cls_loss: 0.0471  \n",
      "<<<iteration:[80/657] - total_loss: 0.3643  obj_loss: 0.1591  noobj_loss: 0.1014  bbox_loss: 0.0201  cls_loss: 0.0540  \n",
      "<<<iteration:[100/657] - total_loss: 0.3605  obj_loss: 0.1721  noobj_loss: 0.0988  bbox_loss: 0.0180  cls_loss: 0.0488  \n",
      "<<<iteration:[120/657] - total_loss: 0.3622  obj_loss: 0.1478  noobj_loss: 0.0972  bbox_loss: 0.0205  cls_loss: 0.0631  \n",
      "<<<iteration:[140/657] - total_loss: 0.3536  obj_loss: 0.1795  noobj_loss: 0.0999  bbox_loss: 0.0160  cls_loss: 0.0444  \n",
      "<<<iteration:[160/657] - total_loss: 0.3705  obj_loss: 0.1717  noobj_loss: 0.0967  bbox_loss: 0.0187  cls_loss: 0.0569  \n",
      "<<<iteration:[180/657] - total_loss: 0.3692  obj_loss: 0.1603  noobj_loss: 0.1054  bbox_loss: 0.0195  cls_loss: 0.0586  \n",
      "<<<iteration:[200/657] - total_loss: 0.3623  obj_loss: 0.1765  noobj_loss: 0.1026  bbox_loss: 0.0169  cls_loss: 0.0498  \n",
      "<<<iteration:[220/657] - total_loss: 0.3697  obj_loss: 0.1736  noobj_loss: 0.0968  bbox_loss: 0.0186  cls_loss: 0.0546  \n",
      "<<<iteration:[240/657] - total_loss: 0.3663  obj_loss: 0.1722  noobj_loss: 0.1015  bbox_loss: 0.0180  cls_loss: 0.0534  \n",
      "<<<iteration:[260/657] - total_loss: 0.3736  obj_loss: 0.1675  noobj_loss: 0.1022  bbox_loss: 0.0189  cls_loss: 0.0604  \n",
      "<<<iteration:[280/657] - total_loss: 0.3716  obj_loss: 0.1759  noobj_loss: 0.1029  bbox_loss: 0.0179  cls_loss: 0.0547  \n",
      "<<<iteration:[300/657] - total_loss: 0.3633  obj_loss: 0.1723  noobj_loss: 0.0990  bbox_loss: 0.0174  cls_loss: 0.0546  \n",
      "<<<iteration:[320/657] - total_loss: 0.3709  obj_loss: 0.1754  noobj_loss: 0.1045  bbox_loss: 0.0168  cls_loss: 0.0595  \n",
      "<<<iteration:[340/657] - total_loss: 0.3650  obj_loss: 0.1735  noobj_loss: 0.1066  bbox_loss: 0.0177  cls_loss: 0.0499  \n",
      "<<<iteration:[360/657] - total_loss: 0.3756  obj_loss: 0.1725  noobj_loss: 0.1067  bbox_loss: 0.0191  cls_loss: 0.0544  \n",
      "<<<iteration:[380/657] - total_loss: 0.3461  obj_loss: 0.1682  noobj_loss: 0.0977  bbox_loss: 0.0155  cls_loss: 0.0514  \n",
      "<<<iteration:[400/657] - total_loss: 0.3589  obj_loss: 0.1701  noobj_loss: 0.1019  bbox_loss: 0.0167  cls_loss: 0.0544  \n",
      "<<<iteration:[420/657] - total_loss: 0.3724  obj_loss: 0.1762  noobj_loss: 0.1011  bbox_loss: 0.0178  cls_loss: 0.0568  \n",
      "<<<iteration:[440/657] - total_loss: 0.3554  obj_loss: 0.1811  noobj_loss: 0.0986  bbox_loss: 0.0147  cls_loss: 0.0514  \n",
      "<<<iteration:[460/657] - total_loss: 0.3607  obj_loss: 0.1493  noobj_loss: 0.1013  bbox_loss: 0.0198  cls_loss: 0.0618  \n",
      "<<<iteration:[480/657] - total_loss: 0.3557  obj_loss: 0.1781  noobj_loss: 0.1024  bbox_loss: 0.0158  cls_loss: 0.0473  \n",
      "<<<iteration:[500/657] - total_loss: 0.3757  obj_loss: 0.1696  noobj_loss: 0.1030  bbox_loss: 0.0186  cls_loss: 0.0618  \n",
      "<<<iteration:[520/657] - total_loss: 0.3627  obj_loss: 0.1637  noobj_loss: 0.1006  bbox_loss: 0.0174  cls_loss: 0.0616  \n",
      "<<<iteration:[540/657] - total_loss: 0.3466  obj_loss: 0.1751  noobj_loss: 0.1022  bbox_loss: 0.0168  cls_loss: 0.0364  \n",
      "<<<iteration:[560/657] - total_loss: 0.3477  obj_loss: 0.1688  noobj_loss: 0.1045  bbox_loss: 0.0160  cls_loss: 0.0465  \n",
      "<<<iteration:[580/657] - total_loss: 0.3909  obj_loss: 0.1859  noobj_loss: 0.1025  bbox_loss: 0.0171  cls_loss: 0.0681  \n",
      "<<<iteration:[600/657] - total_loss: 0.3700  obj_loss: 0.1742  noobj_loss: 0.0982  bbox_loss: 0.0182  cls_loss: 0.0557  \n",
      "<<<iteration:[620/657] - total_loss: 0.3745  obj_loss: 0.1755  noobj_loss: 0.0986  bbox_loss: 0.0178  cls_loss: 0.0609  \n",
      "<<<iteration:[640/657] - total_loss: 0.3775  obj_loss: 0.1751  noobj_loss: 0.1071  bbox_loss: 0.0187  cls_loss: 0.0556  \n",
      "\n",
      "epoch:8/100 - Train Loss: 0.3651, Val Loss: 0.3574\n",
      "\n",
      "<<<iteration:[20/657] - total_loss: 0.3655  obj_loss: 0.1854  noobj_loss: 0.1036  bbox_loss: 0.0164  cls_loss: 0.0464  \n",
      "<<<iteration:[40/657] - total_loss: 0.3696  obj_loss: 0.1805  noobj_loss: 0.1053  bbox_loss: 0.0168  cls_loss: 0.0525  \n",
      "<<<iteration:[60/657] - total_loss: 0.3726  obj_loss: 0.1690  noobj_loss: 0.1116  bbox_loss: 0.0184  cls_loss: 0.0560  \n",
      "<<<iteration:[80/657] - total_loss: 0.3593  obj_loss: 0.1849  noobj_loss: 0.0952  bbox_loss: 0.0151  cls_loss: 0.0513  \n",
      "<<<iteration:[100/657] - total_loss: 0.3427  obj_loss: 0.1695  noobj_loss: 0.0960  bbox_loss: 0.0163  cls_loss: 0.0438  \n",
      "<<<iteration:[120/657] - total_loss: 0.3528  obj_loss: 0.1731  noobj_loss: 0.0995  bbox_loss: 0.0165  cls_loss: 0.0476  \n",
      "<<<iteration:[140/657] - total_loss: 0.3681  obj_loss: 0.1795  noobj_loss: 0.1024  bbox_loss: 0.0163  cls_loss: 0.0562  \n",
      "<<<iteration:[160/657] - total_loss: 0.3531  obj_loss: 0.1814  noobj_loss: 0.0987  bbox_loss: 0.0158  cls_loss: 0.0431  \n",
      "<<<iteration:[180/657] - total_loss: 0.3630  obj_loss: 0.1752  noobj_loss: 0.0998  bbox_loss: 0.0165  cls_loss: 0.0556  \n",
      "<<<iteration:[200/657] - total_loss: 0.3652  obj_loss: 0.1683  noobj_loss: 0.1030  bbox_loss: 0.0194  cls_loss: 0.0486  \n",
      "<<<iteration:[220/657] - total_loss: 0.3539  obj_loss: 0.1698  noobj_loss: 0.0960  bbox_loss: 0.0175  cls_loss: 0.0486  \n",
      "<<<iteration:[240/657] - total_loss: 0.3495  obj_loss: 0.1793  noobj_loss: 0.0973  bbox_loss: 0.0157  cls_loss: 0.0429  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<<<iteration:[260/657] - total_loss: 0.3810  obj_loss: 0.1795  noobj_loss: 0.0989  bbox_loss: 0.0189  cls_loss: 0.0577  \n",
      "<<<iteration:[280/657] - total_loss: 0.3580  obj_loss: 0.1639  noobj_loss: 0.1071  bbox_loss: 0.0168  cls_loss: 0.0564  \n",
      "<<<iteration:[300/657] - total_loss: 0.3530  obj_loss: 0.1712  noobj_loss: 0.1003  bbox_loss: 0.0159  cls_loss: 0.0521  \n",
      "<<<iteration:[320/657] - total_loss: 0.3468  obj_loss: 0.1638  noobj_loss: 0.1001  bbox_loss: 0.0180  cls_loss: 0.0428  \n",
      "<<<iteration:[340/657] - total_loss: 0.3404  obj_loss: 0.1643  noobj_loss: 0.0981  bbox_loss: 0.0157  cls_loss: 0.0484  \n",
      "<<<iteration:[360/657] - total_loss: 0.3432  obj_loss: 0.1752  noobj_loss: 0.1000  bbox_loss: 0.0153  cls_loss: 0.0415  \n",
      "<<<iteration:[380/657] - total_loss: 0.3775  obj_loss: 0.1786  noobj_loss: 0.0999  bbox_loss: 0.0183  cls_loss: 0.0573  \n",
      "<<<iteration:[400/657] - total_loss: 0.3493  obj_loss: 0.1809  noobj_loss: 0.0969  bbox_loss: 0.0152  cls_loss: 0.0440  \n",
      "<<<iteration:[420/657] - total_loss: 0.3623  obj_loss: 0.1888  noobj_loss: 0.0991  bbox_loss: 0.0159  cls_loss: 0.0447  \n",
      "<<<iteration:[440/657] - total_loss: 0.3553  obj_loss: 0.1827  noobj_loss: 0.1014  bbox_loss: 0.0154  cls_loss: 0.0449  \n",
      "<<<iteration:[460/657] - total_loss: 0.3790  obj_loss: 0.1925  noobj_loss: 0.1023  bbox_loss: 0.0162  cls_loss: 0.0544  \n",
      "<<<iteration:[480/657] - total_loss: 0.3572  obj_loss: 0.1751  noobj_loss: 0.0988  bbox_loss: 0.0161  cls_loss: 0.0524  \n",
      "<<<iteration:[500/657] - total_loss: 0.3556  obj_loss: 0.1776  noobj_loss: 0.1024  bbox_loss: 0.0150  cls_loss: 0.0517  \n",
      "<<<iteration:[520/657] - total_loss: 0.3582  obj_loss: 0.1736  noobj_loss: 0.1019  bbox_loss: 0.0180  cls_loss: 0.0434  \n",
      "<<<iteration:[540/657] - total_loss: 0.3697  obj_loss: 0.1807  noobj_loss: 0.1012  bbox_loss: 0.0175  cls_loss: 0.0510  \n",
      "<<<iteration:[560/657] - total_loss: 0.3397  obj_loss: 0.1645  noobj_loss: 0.1022  bbox_loss: 0.0153  cls_loss: 0.0478  \n",
      "<<<iteration:[580/657] - total_loss: 0.3529  obj_loss: 0.1803  noobj_loss: 0.1015  bbox_loss: 0.0158  cls_loss: 0.0427  \n",
      "<<<iteration:[600/657] - total_loss: 0.3646  obj_loss: 0.1857  noobj_loss: 0.1050  bbox_loss: 0.0153  cls_loss: 0.0499  \n",
      "<<<iteration:[620/657] - total_loss: 0.3575  obj_loss: 0.1695  noobj_loss: 0.1038  bbox_loss: 0.0164  cls_loss: 0.0542  \n",
      "<<<iteration:[640/657] - total_loss: 0.3709  obj_loss: 0.1763  noobj_loss: 0.0948  bbox_loss: 0.0185  cls_loss: 0.0547  \n",
      "\n",
      "epoch:9/100 - Train Loss: 0.3583, Val Loss: 0.3532\n",
      "\n",
      "<<<iteration:[20/657] - total_loss: 0.3806  obj_loss: 0.1885  noobj_loss: 0.1050  bbox_loss: 0.0169  cls_loss: 0.0552  \n",
      "<<<iteration:[40/657] - total_loss: 0.3360  obj_loss: 0.1726  noobj_loss: 0.1031  bbox_loss: 0.0159  cls_loss: 0.0326  \n",
      "<<<iteration:[60/657] - total_loss: 0.3573  obj_loss: 0.1801  noobj_loss: 0.1025  bbox_loss: 0.0154  cls_loss: 0.0487  \n",
      "<<<iteration:[80/657] - total_loss: 0.3508  obj_loss: 0.1798  noobj_loss: 0.1001  bbox_loss: 0.0154  cls_loss: 0.0440  \n",
      "<<<iteration:[100/657] - total_loss: 0.3884  obj_loss: 0.1771  noobj_loss: 0.1059  bbox_loss: 0.0194  cls_loss: 0.0613  \n",
      "<<<iteration:[120/657] - total_loss: 0.3370  obj_loss: 0.1673  noobj_loss: 0.1033  bbox_loss: 0.0164  cls_loss: 0.0360  \n",
      "<<<iteration:[140/657] - total_loss: 0.3421  obj_loss: 0.1687  noobj_loss: 0.0992  bbox_loss: 0.0158  cls_loss: 0.0447  \n",
      "<<<iteration:[160/657] - total_loss: 0.3472  obj_loss: 0.1758  noobj_loss: 0.1033  bbox_loss: 0.0152  cls_loss: 0.0435  \n",
      "<<<iteration:[180/657] - total_loss: 0.3526  obj_loss: 0.1807  noobj_loss: 0.1039  bbox_loss: 0.0155  cls_loss: 0.0422  \n",
      "<<<iteration:[200/657] - total_loss: 0.3455  obj_loss: 0.1785  noobj_loss: 0.0966  bbox_loss: 0.0151  cls_loss: 0.0434  \n",
      "<<<iteration:[220/657] - total_loss: 0.3639  obj_loss: 0.1734  noobj_loss: 0.1036  bbox_loss: 0.0172  cls_loss: 0.0527  \n",
      "<<<iteration:[240/657] - total_loss: 0.3507  obj_loss: 0.1799  noobj_loss: 0.1006  bbox_loss: 0.0146  cls_loss: 0.0473  \n",
      "<<<iteration:[260/657] - total_loss: 0.3513  obj_loss: 0.1760  noobj_loss: 0.1000  bbox_loss: 0.0154  cls_loss: 0.0481  \n",
      "<<<iteration:[280/657] - total_loss: 0.3528  obj_loss: 0.1781  noobj_loss: 0.1028  bbox_loss: 0.0164  cls_loss: 0.0411  \n",
      "<<<iteration:[300/657] - total_loss: 0.3529  obj_loss: 0.1756  noobj_loss: 0.1034  bbox_loss: 0.0160  cls_loss: 0.0457  \n",
      "<<<iteration:[320/657] - total_loss: 0.3376  obj_loss: 0.1711  noobj_loss: 0.0969  bbox_loss: 0.0153  cls_loss: 0.0416  \n",
      "<<<iteration:[340/657] - total_loss: 0.3439  obj_loss: 0.1625  noobj_loss: 0.1004  bbox_loss: 0.0161  cls_loss: 0.0506  \n",
      "<<<iteration:[360/657] - total_loss: 0.3364  obj_loss: 0.1697  noobj_loss: 0.0996  bbox_loss: 0.0162  cls_loss: 0.0360  \n",
      "<<<iteration:[380/657] - total_loss: 0.3560  obj_loss: 0.1683  noobj_loss: 0.1023  bbox_loss: 0.0174  cls_loss: 0.0494  \n",
      "<<<iteration:[400/657] - total_loss: 0.3492  obj_loss: 0.1642  noobj_loss: 0.0985  bbox_loss: 0.0162  cls_loss: 0.0545  \n",
      "<<<iteration:[420/657] - total_loss: 0.3346  obj_loss: 0.1790  noobj_loss: 0.0949  bbox_loss: 0.0139  cls_loss: 0.0387  \n",
      "<<<iteration:[440/657] - total_loss: 0.3689  obj_loss: 0.1977  noobj_loss: 0.1018  bbox_loss: 0.0155  cls_loss: 0.0428  \n",
      "<<<iteration:[460/657] - total_loss: 0.3492  obj_loss: 0.1773  noobj_loss: 0.1007  bbox_loss: 0.0151  cls_loss: 0.0463  \n",
      "<<<iteration:[480/657] - total_loss: 0.3571  obj_loss: 0.1820  noobj_loss: 0.1050  bbox_loss: 0.0158  cls_loss: 0.0438  \n",
      "<<<iteration:[500/657] - total_loss: 0.3388  obj_loss: 0.1815  noobj_loss: 0.0935  bbox_loss: 0.0146  cls_loss: 0.0378  \n",
      "<<<iteration:[520/657] - total_loss: 0.3486  obj_loss: 0.1701  noobj_loss: 0.1007  bbox_loss: 0.0159  cls_loss: 0.0485  \n",
      "<<<iteration:[540/657] - total_loss: 0.3638  obj_loss: 0.1810  noobj_loss: 0.1008  bbox_loss: 0.0160  cls_loss: 0.0526  \n",
      "<<<iteration:[560/657] - total_loss: 0.3562  obj_loss: 0.1800  noobj_loss: 0.1037  bbox_loss: 0.0146  cls_loss: 0.0515  \n",
      "<<<iteration:[580/657] - total_loss: 0.3671  obj_loss: 0.1795  noobj_loss: 0.1015  bbox_loss: 0.0176  cls_loss: 0.0487  \n",
      "<<<iteration:[600/657] - total_loss: 0.3532  obj_loss: 0.1781  noobj_loss: 0.0990  bbox_loss: 0.0151  cls_loss: 0.0499  \n",
      "<<<iteration:[620/657] - total_loss: 0.3537  obj_loss: 0.1747  noobj_loss: 0.1012  bbox_loss: 0.0158  cls_loss: 0.0496  \n",
      "<<<iteration:[640/657] - total_loss: 0.3727  obj_loss: 0.1929  noobj_loss: 0.1013  bbox_loss: 0.0159  cls_loss: 0.0495  \n",
      "\n",
      "epoch:10/100 - Train Loss: 0.3522, Val Loss: 0.3453\n",
      "\n",
      "<<<iteration:[20/657] - total_loss: 0.3502  obj_loss: 0.1780  noobj_loss: 0.1019  bbox_loss: 0.0152  cls_loss: 0.0453  \n",
      "<<<iteration:[40/657] - total_loss: 0.3562  obj_loss: 0.1666  noobj_loss: 0.0977  bbox_loss: 0.0160  cls_loss: 0.0606  \n",
      "<<<iteration:[60/657] - total_loss: 0.3515  obj_loss: 0.1751  noobj_loss: 0.0994  bbox_loss: 0.0172  cls_loss: 0.0408  \n",
      "<<<iteration:[80/657] - total_loss: 0.3454  obj_loss: 0.1751  noobj_loss: 0.0989  bbox_loss: 0.0149  cls_loss: 0.0464  \n",
      "<<<iteration:[100/657] - total_loss: 0.3313  obj_loss: 0.1587  noobj_loss: 0.1004  bbox_loss: 0.0159  cls_loss: 0.0428  \n",
      "<<<iteration:[120/657] - total_loss: 0.3452  obj_loss: 0.1760  noobj_loss: 0.0972  bbox_loss: 0.0137  cls_loss: 0.0521  \n",
      "<<<iteration:[140/657] - total_loss: 0.3471  obj_loss: 0.1726  noobj_loss: 0.1033  bbox_loss: 0.0154  cls_loss: 0.0458  \n",
      "<<<iteration:[160/657] - total_loss: 0.3396  obj_loss: 0.1682  noobj_loss: 0.1012  bbox_loss: 0.0148  cls_loss: 0.0468  \n",
      "<<<iteration:[180/657] - total_loss: 0.3757  obj_loss: 0.1759  noobj_loss: 0.1013  bbox_loss: 0.0168  cls_loss: 0.0652  \n",
      "<<<iteration:[200/657] - total_loss: 0.3396  obj_loss: 0.1856  noobj_loss: 0.0942  bbox_loss: 0.0147  cls_loss: 0.0335  \n",
      "<<<iteration:[220/657] - total_loss: 0.3333  obj_loss: 0.1760  noobj_loss: 0.0953  bbox_loss: 0.0138  cls_loss: 0.0409  \n",
      "<<<iteration:[240/657] - total_loss: 0.3412  obj_loss: 0.1723  noobj_loss: 0.0972  bbox_loss: 0.0156  cls_loss: 0.0422  \n",
      "<<<iteration:[260/657] - total_loss: 0.3633  obj_loss: 0.1929  noobj_loss: 0.1009  bbox_loss: 0.0148  cls_loss: 0.0461  \n",
      "<<<iteration:[280/657] - total_loss: 0.3467  obj_loss: 0.1749  noobj_loss: 0.1015  bbox_loss: 0.0157  cls_loss: 0.0426  \n",
      "<<<iteration:[300/657] - total_loss: 0.3708  obj_loss: 0.1863  noobj_loss: 0.1036  bbox_loss: 0.0160  cls_loss: 0.0528  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<<<iteration:[320/657] - total_loss: 0.3470  obj_loss: 0.1815  noobj_loss: 0.1013  bbox_loss: 0.0157  cls_loss: 0.0365  \n",
      "<<<iteration:[340/657] - total_loss: 0.3478  obj_loss: 0.1806  noobj_loss: 0.0942  bbox_loss: 0.0154  cls_loss: 0.0432  \n",
      "<<<iteration:[360/657] - total_loss: 0.3549  obj_loss: 0.1783  noobj_loss: 0.1004  bbox_loss: 0.0157  cls_loss: 0.0477  \n",
      "<<<iteration:[380/657] - total_loss: 0.3458  obj_loss: 0.1894  noobj_loss: 0.1003  bbox_loss: 0.0139  cls_loss: 0.0366  \n",
      "<<<iteration:[400/657] - total_loss: 0.3414  obj_loss: 0.1698  noobj_loss: 0.1034  bbox_loss: 0.0153  cls_loss: 0.0436  \n",
      "<<<iteration:[420/657] - total_loss: 0.3658  obj_loss: 0.1923  noobj_loss: 0.1010  bbox_loss: 0.0157  cls_loss: 0.0442  \n",
      "<<<iteration:[440/657] - total_loss: 0.3476  obj_loss: 0.1719  noobj_loss: 0.0983  bbox_loss: 0.0153  cls_loss: 0.0502  \n",
      "<<<iteration:[460/657] - total_loss: 0.3436  obj_loss: 0.1816  noobj_loss: 0.1007  bbox_loss: 0.0141  cls_loss: 0.0414  \n",
      "<<<iteration:[480/657] - total_loss: 0.3557  obj_loss: 0.1973  noobj_loss: 0.1001  bbox_loss: 0.0136  cls_loss: 0.0405  \n",
      "<<<iteration:[500/657] - total_loss: 0.3873  obj_loss: 0.1722  noobj_loss: 0.1022  bbox_loss: 0.0239  cls_loss: 0.0446  \n",
      "<<<iteration:[520/657] - total_loss: 0.3645  obj_loss: 0.1803  noobj_loss: 0.1045  bbox_loss: 0.0183  cls_loss: 0.0404  \n",
      "<<<iteration:[540/657] - total_loss: 0.3488  obj_loss: 0.1713  noobj_loss: 0.0952  bbox_loss: 0.0178  cls_loss: 0.0410  \n",
      "<<<iteration:[560/657] - total_loss: 0.3366  obj_loss: 0.1684  noobj_loss: 0.0980  bbox_loss: 0.0152  cls_loss: 0.0435  \n",
      "<<<iteration:[580/657] - total_loss: 0.3418  obj_loss: 0.1733  noobj_loss: 0.0978  bbox_loss: 0.0149  cls_loss: 0.0450  \n",
      "<<<iteration:[600/657] - total_loss: 0.3426  obj_loss: 0.1808  noobj_loss: 0.0977  bbox_loss: 0.0152  cls_loss: 0.0372  \n",
      "<<<iteration:[620/657] - total_loss: 0.3516  obj_loss: 0.1725  noobj_loss: 0.1026  bbox_loss: 0.0165  cls_loss: 0.0453  \n",
      "<<<iteration:[640/657] - total_loss: 0.3699  obj_loss: 0.1920  noobj_loss: 0.1001  bbox_loss: 0.0168  cls_loss: 0.0438  \n",
      "\n",
      "epoch:11/100 - Train Loss: 0.3507, Val Loss: 0.3530\n",
      "\n",
      "<<<iteration:[20/657] - total_loss: 0.3637  obj_loss: 0.1813  noobj_loss: 0.1047  bbox_loss: 0.0167  cls_loss: 0.0467  \n",
      "<<<iteration:[40/657] - total_loss: 0.3704  obj_loss: 0.1837  noobj_loss: 0.1020  bbox_loss: 0.0175  cls_loss: 0.0483  \n",
      "<<<iteration:[60/657] - total_loss: 0.3517  obj_loss: 0.1752  noobj_loss: 0.1015  bbox_loss: 0.0156  cls_loss: 0.0480  \n",
      "<<<iteration:[80/657] - total_loss: 0.3618  obj_loss: 0.1832  noobj_loss: 0.1036  bbox_loss: 0.0169  cls_loss: 0.0421  \n",
      "<<<iteration:[100/657] - total_loss: 0.3609  obj_loss: 0.1835  noobj_loss: 0.0988  bbox_loss: 0.0156  cls_loss: 0.0499  \n",
      "<<<iteration:[120/657] - total_loss: 0.3474  obj_loss: 0.1851  noobj_loss: 0.1042  bbox_loss: 0.0143  cls_loss: 0.0385  \n",
      "<<<iteration:[140/657] - total_loss: 0.3491  obj_loss: 0.1654  noobj_loss: 0.0994  bbox_loss: 0.0184  cls_loss: 0.0421  \n",
      "<<<iteration:[160/657] - total_loss: 0.3487  obj_loss: 0.1885  noobj_loss: 0.0971  bbox_loss: 0.0144  cls_loss: 0.0394  \n",
      "<<<iteration:[180/657] - total_loss: 0.3438  obj_loss: 0.1785  noobj_loss: 0.1040  bbox_loss: 0.0132  cls_loss: 0.0470  \n",
      "<<<iteration:[200/657] - total_loss: 0.3440  obj_loss: 0.1815  noobj_loss: 0.0970  bbox_loss: 0.0147  cls_loss: 0.0408  \n",
      "<<<iteration:[220/657] - total_loss: 0.3377  obj_loss: 0.1788  noobj_loss: 0.0991  bbox_loss: 0.0129  cls_loss: 0.0447  \n",
      "<<<iteration:[240/657] - total_loss: 0.3429  obj_loss: 0.1913  noobj_loss: 0.0953  bbox_loss: 0.0139  cls_loss: 0.0345  \n",
      "<<<iteration:[260/657] - total_loss: 0.3427  obj_loss: 0.1775  noobj_loss: 0.1010  bbox_loss: 0.0144  cls_loss: 0.0429  \n",
      "<<<iteration:[280/657] - total_loss: 0.3562  obj_loss: 0.1773  noobj_loss: 0.0982  bbox_loss: 0.0169  cls_loss: 0.0454  \n",
      "<<<iteration:[300/657] - total_loss: 0.3467  obj_loss: 0.1779  noobj_loss: 0.1029  bbox_loss: 0.0155  cls_loss: 0.0397  \n",
      "<<<iteration:[320/657] - total_loss: 0.3350  obj_loss: 0.1680  noobj_loss: 0.1029  bbox_loss: 0.0154  cls_loss: 0.0385  \n",
      "<<<iteration:[340/657] - total_loss: 0.3489  obj_loss: 0.1864  noobj_loss: 0.1024  bbox_loss: 0.0133  cls_loss: 0.0446  \n",
      "<<<iteration:[360/657] - total_loss: 0.3284  obj_loss: 0.1658  noobj_loss: 0.0995  bbox_loss: 0.0144  cls_loss: 0.0409  \n",
      "<<<iteration:[380/657] - total_loss: 0.3367  obj_loss: 0.1850  noobj_loss: 0.0964  bbox_loss: 0.0123  cls_loss: 0.0417  \n",
      "<<<iteration:[400/657] - total_loss: 0.3540  obj_loss: 0.1915  noobj_loss: 0.1024  bbox_loss: 0.0133  cls_loss: 0.0447  \n",
      "<<<iteration:[420/657] - total_loss: 0.3355  obj_loss: 0.1703  noobj_loss: 0.0962  bbox_loss: 0.0151  cls_loss: 0.0414  \n",
      "<<<iteration:[440/657] - total_loss: 0.3254  obj_loss: 0.1827  noobj_loss: 0.0995  bbox_loss: 0.0131  cls_loss: 0.0272  \n",
      "<<<iteration:[460/657] - total_loss: 0.3396  obj_loss: 0.1695  noobj_loss: 0.1015  bbox_loss: 0.0139  cls_loss: 0.0499  \n",
      "<<<iteration:[480/657] - total_loss: 0.3475  obj_loss: 0.1820  noobj_loss: 0.1033  bbox_loss: 0.0130  cls_loss: 0.0490  \n",
      "<<<iteration:[500/657] - total_loss: 0.3264  obj_loss: 0.1652  noobj_loss: 0.1014  bbox_loss: 0.0145  cls_loss: 0.0378  \n",
      "<<<iteration:[520/657] - total_loss: 0.3542  obj_loss: 0.1879  noobj_loss: 0.0914  bbox_loss: 0.0136  cls_loss: 0.0525  \n",
      "<<<iteration:[540/657] - total_loss: 0.3459  obj_loss: 0.1819  noobj_loss: 0.0989  bbox_loss: 0.0148  cls_loss: 0.0403  \n",
      "<<<iteration:[560/657] - total_loss: 0.3360  obj_loss: 0.1867  noobj_loss: 0.1015  bbox_loss: 0.0128  cls_loss: 0.0345  \n",
      "<<<iteration:[580/657] - total_loss: 0.3264  obj_loss: 0.1723  noobj_loss: 0.1029  bbox_loss: 0.0135  cls_loss: 0.0351  \n",
      "<<<iteration:[600/657] - total_loss: 0.3311  obj_loss: 0.1771  noobj_loss: 0.0982  bbox_loss: 0.0139  cls_loss: 0.0355  \n",
      "<<<iteration:[620/657] - total_loss: 0.3309  obj_loss: 0.1786  noobj_loss: 0.0977  bbox_loss: 0.0138  cls_loss: 0.0344  \n",
      "<<<iteration:[640/657] - total_loss: 0.3425  obj_loss: 0.1861  noobj_loss: 0.1025  bbox_loss: 0.0131  cls_loss: 0.0398  \n",
      "\n",
      "epoch:12/100 - Train Loss: 0.3430, Val Loss: 0.3378\n",
      "\n",
      "<<<iteration:[20/657] - total_loss: 0.3472  obj_loss: 0.1933  noobj_loss: 0.1049  bbox_loss: 0.0131  cls_loss: 0.0358  \n",
      "<<<iteration:[40/657] - total_loss: 0.3485  obj_loss: 0.1815  noobj_loss: 0.0996  bbox_loss: 0.0154  cls_loss: 0.0401  \n",
      "<<<iteration:[60/657] - total_loss: 0.3615  obj_loss: 0.1945  noobj_loss: 0.1019  bbox_loss: 0.0144  cls_loss: 0.0440  \n",
      "<<<iteration:[80/657] - total_loss: 0.3464  obj_loss: 0.1927  noobj_loss: 0.0980  bbox_loss: 0.0133  cls_loss: 0.0383  \n",
      "<<<iteration:[100/657] - total_loss: 0.3359  obj_loss: 0.1876  noobj_loss: 0.0993  bbox_loss: 0.0130  cls_loss: 0.0337  \n",
      "<<<iteration:[120/657] - total_loss: 0.3274  obj_loss: 0.1671  noobj_loss: 0.0962  bbox_loss: 0.0151  cls_loss: 0.0367  \n",
      "<<<iteration:[140/657] - total_loss: 0.3423  obj_loss: 0.1906  noobj_loss: 0.0967  bbox_loss: 0.0118  cls_loss: 0.0445  \n",
      "<<<iteration:[160/657] - total_loss: 0.3379  obj_loss: 0.1873  noobj_loss: 0.0981  bbox_loss: 0.0126  cls_loss: 0.0383  \n",
      "<<<iteration:[180/657] - total_loss: 0.3643  obj_loss: 0.2064  noobj_loss: 0.1060  bbox_loss: 0.0132  cls_loss: 0.0390  \n",
      "<<<iteration:[200/657] - total_loss: 0.3357  obj_loss: 0.1807  noobj_loss: 0.0959  bbox_loss: 0.0124  cls_loss: 0.0449  \n",
      "<<<iteration:[220/657] - total_loss: 0.3428  obj_loss: 0.1917  noobj_loss: 0.1043  bbox_loss: 0.0125  cls_loss: 0.0364  \n",
      "<<<iteration:[240/657] - total_loss: 0.3547  obj_loss: 0.1948  noobj_loss: 0.0975  bbox_loss: 0.0140  cls_loss: 0.0410  \n",
      "<<<iteration:[260/657] - total_loss: 0.3451  obj_loss: 0.1896  noobj_loss: 0.1014  bbox_loss: 0.0131  cls_loss: 0.0392  \n",
      "<<<iteration:[280/657] - total_loss: 0.3449  obj_loss: 0.1775  noobj_loss: 0.1018  bbox_loss: 0.0150  cls_loss: 0.0416  \n",
      "<<<iteration:[300/657] - total_loss: 0.3501  obj_loss: 0.1688  noobj_loss: 0.1024  bbox_loss: 0.0153  cls_loss: 0.0537  \n",
      "<<<iteration:[320/657] - total_loss: 0.3256  obj_loss: 0.1660  noobj_loss: 0.1017  bbox_loss: 0.0141  cls_loss: 0.0382  \n",
      "<<<iteration:[340/657] - total_loss: 0.3315  obj_loss: 0.1753  noobj_loss: 0.1004  bbox_loss: 0.0140  cls_loss: 0.0361  \n",
      "<<<iteration:[360/657] - total_loss: 0.3326  obj_loss: 0.1874  noobj_loss: 0.0978  bbox_loss: 0.0132  cls_loss: 0.0300  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<<<iteration:[380/657] - total_loss: 0.3347  obj_loss: 0.1721  noobj_loss: 0.1000  bbox_loss: 0.0134  cls_loss: 0.0456  \n",
      "<<<iteration:[400/657] - total_loss: 0.3357  obj_loss: 0.1759  noobj_loss: 0.0984  bbox_loss: 0.0144  cls_loss: 0.0387  \n",
      "<<<iteration:[420/657] - total_loss: 0.3243  obj_loss: 0.1836  noobj_loss: 0.1003  bbox_loss: 0.0119  cls_loss: 0.0312  \n",
      "<<<iteration:[440/657] - total_loss: 0.3551  obj_loss: 0.1849  noobj_loss: 0.1027  bbox_loss: 0.0147  cls_loss: 0.0455  \n",
      "<<<iteration:[460/657] - total_loss: 0.3230  obj_loss: 0.1718  noobj_loss: 0.1005  bbox_loss: 0.0126  cls_loss: 0.0380  \n",
      "<<<iteration:[480/657] - total_loss: 0.3451  obj_loss: 0.1899  noobj_loss: 0.0994  bbox_loss: 0.0135  cls_loss: 0.0381  \n",
      "<<<iteration:[500/657] - total_loss: 0.3398  obj_loss: 0.1915  noobj_loss: 0.0955  bbox_loss: 0.0126  cls_loss: 0.0377  \n",
      "<<<iteration:[520/657] - total_loss: 0.3248  obj_loss: 0.1836  noobj_loss: 0.1018  bbox_loss: 0.0123  cls_loss: 0.0288  \n",
      "<<<iteration:[540/657] - total_loss: 0.3484  obj_loss: 0.1875  noobj_loss: 0.1038  bbox_loss: 0.0132  cls_loss: 0.0429  \n",
      "<<<iteration:[560/657] - total_loss: 0.3540  obj_loss: 0.1872  noobj_loss: 0.0954  bbox_loss: 0.0152  cls_loss: 0.0431  \n",
      "<<<iteration:[580/657] - total_loss: 0.3461  obj_loss: 0.1500  noobj_loss: 0.0993  bbox_loss: 0.0208  cls_loss: 0.0423  \n",
      "<<<iteration:[600/657] - total_loss: 0.3663  obj_loss: 0.1750  noobj_loss: 0.0976  bbox_loss: 0.0198  cls_loss: 0.0435  \n",
      "<<<iteration:[620/657] - total_loss: 0.3415  obj_loss: 0.1660  noobj_loss: 0.0974  bbox_loss: 0.0166  cls_loss: 0.0440  \n",
      "<<<iteration:[640/657] - total_loss: 0.3435  obj_loss: 0.1787  noobj_loss: 0.1010  bbox_loss: 0.0154  cls_loss: 0.0370  \n",
      "\n",
      "epoch:13/100 - Train Loss: 0.3422, Val Loss: 0.3400\n",
      "\n",
      "<<<iteration:[20/657] - total_loss: 0.3698  obj_loss: 0.1704  noobj_loss: 0.1066  bbox_loss: 0.0199  cls_loss: 0.0466  \n",
      "<<<iteration:[40/657] - total_loss: 0.3397  obj_loss: 0.1868  noobj_loss: 0.0978  bbox_loss: 0.0142  cls_loss: 0.0329  \n",
      "<<<iteration:[60/657] - total_loss: 0.3410  obj_loss: 0.1741  noobj_loss: 0.1003  bbox_loss: 0.0145  cls_loss: 0.0443  \n",
      "<<<iteration:[80/657] - total_loss: 0.3345  obj_loss: 0.1711  noobj_loss: 0.1026  bbox_loss: 0.0139  cls_loss: 0.0427  \n",
      "<<<iteration:[100/657] - total_loss: 0.3386  obj_loss: 0.1736  noobj_loss: 0.0980  bbox_loss: 0.0151  cls_loss: 0.0404  \n",
      "<<<iteration:[120/657] - total_loss: 0.3372  obj_loss: 0.1801  noobj_loss: 0.1010  bbox_loss: 0.0137  cls_loss: 0.0381  \n",
      "<<<iteration:[140/657] - total_loss: 0.3354  obj_loss: 0.1756  noobj_loss: 0.0952  bbox_loss: 0.0146  cls_loss: 0.0394  \n",
      "<<<iteration:[160/657] - total_loss: 0.3341  obj_loss: 0.1917  noobj_loss: 0.1023  bbox_loss: 0.0128  cls_loss: 0.0274  \n",
      "<<<iteration:[180/657] - total_loss: 0.3301  obj_loss: 0.1791  noobj_loss: 0.1050  bbox_loss: 0.0128  cls_loss: 0.0344  \n",
      "<<<iteration:[200/657] - total_loss: 0.3470  obj_loss: 0.2027  noobj_loss: 0.0990  bbox_loss: 0.0127  cls_loss: 0.0316  \n",
      "<<<iteration:[220/657] - total_loss: 0.3438  obj_loss: 0.1858  noobj_loss: 0.1083  bbox_loss: 0.0131  cls_loss: 0.0382  \n",
      "<<<iteration:[240/657] - total_loss: 0.3567  obj_loss: 0.1926  noobj_loss: 0.1019  bbox_loss: 0.0127  cls_loss: 0.0495  \n",
      "<<<iteration:[260/657] - total_loss: 0.3470  obj_loss: 0.1811  noobj_loss: 0.1034  bbox_loss: 0.0143  cls_loss: 0.0426  \n",
      "<<<iteration:[280/657] - total_loss: 0.3461  obj_loss: 0.1724  noobj_loss: 0.1090  bbox_loss: 0.0140  cls_loss: 0.0492  \n",
      "<<<iteration:[300/657] - total_loss: 0.3352  obj_loss: 0.1836  noobj_loss: 0.0940  bbox_loss: 0.0124  cls_loss: 0.0428  \n",
      "<<<iteration:[320/657] - total_loss: 0.3503  obj_loss: 0.1969  noobj_loss: 0.1034  bbox_loss: 0.0121  cls_loss: 0.0414  \n",
      "<<<iteration:[340/657] - total_loss: 0.3315  obj_loss: 0.1876  noobj_loss: 0.1023  bbox_loss: 0.0120  cls_loss: 0.0329  \n",
      "<<<iteration:[360/657] - total_loss: 0.3324  obj_loss: 0.1778  noobj_loss: 0.1071  bbox_loss: 0.0125  cls_loss: 0.0384  \n",
      "<<<iteration:[380/657] - total_loss: 0.3337  obj_loss: 0.1885  noobj_loss: 0.1019  bbox_loss: 0.0122  cls_loss: 0.0334  \n",
      "<<<iteration:[400/657] - total_loss: 0.3693  obj_loss: 0.1844  noobj_loss: 0.1073  bbox_loss: 0.0153  cls_loss: 0.0550  \n",
      "<<<iteration:[420/657] - total_loss: 0.3244  obj_loss: 0.1760  noobj_loss: 0.1019  bbox_loss: 0.0123  cls_loss: 0.0358  \n",
      "<<<iteration:[440/657] - total_loss: 0.3353  obj_loss: 0.1770  noobj_loss: 0.1062  bbox_loss: 0.0129  cls_loss: 0.0408  \n",
      "<<<iteration:[460/657] - total_loss: 0.3443  obj_loss: 0.1827  noobj_loss: 0.1038  bbox_loss: 0.0143  cls_loss: 0.0384  \n",
      "<<<iteration:[480/657] - total_loss: 0.3381  obj_loss: 0.1803  noobj_loss: 0.0980  bbox_loss: 0.0129  cls_loss: 0.0444  \n",
      "<<<iteration:[500/657] - total_loss: 0.3324  obj_loss: 0.1785  noobj_loss: 0.1045  bbox_loss: 0.0122  cls_loss: 0.0404  \n",
      "<<<iteration:[520/657] - total_loss: 0.3355  obj_loss: 0.1848  noobj_loss: 0.1049  bbox_loss: 0.0127  cls_loss: 0.0351  \n",
      "<<<iteration:[540/657] - total_loss: 0.3152  obj_loss: 0.1743  noobj_loss: 0.1020  bbox_loss: 0.0125  cls_loss: 0.0274  \n",
      "<<<iteration:[560/657] - total_loss: 0.3197  obj_loss: 0.1613  noobj_loss: 0.1001  bbox_loss: 0.0135  cls_loss: 0.0408  \n",
      "<<<iteration:[580/657] - total_loss: 0.3318  obj_loss: 0.1730  noobj_loss: 0.1031  bbox_loss: 0.0136  cls_loss: 0.0395  \n",
      "<<<iteration:[600/657] - total_loss: 0.3332  obj_loss: 0.1733  noobj_loss: 0.1084  bbox_loss: 0.0125  cls_loss: 0.0430  \n",
      "<<<iteration:[620/657] - total_loss: 0.3254  obj_loss: 0.1736  noobj_loss: 0.0966  bbox_loss: 0.0136  cls_loss: 0.0353  \n",
      "<<<iteration:[640/657] - total_loss: 0.3229  obj_loss: 0.1741  noobj_loss: 0.1045  bbox_loss: 0.0127  cls_loss: 0.0329  \n",
      "\n",
      "epoch:14/100 - Train Loss: 0.3373, Val Loss: 0.3423\n",
      "\n",
      "<<<iteration:[20/657] - total_loss: 0.3338  obj_loss: 0.1781  noobj_loss: 0.1053  bbox_loss: 0.0141  cls_loss: 0.0326  \n",
      "<<<iteration:[40/657] - total_loss: 0.3150  obj_loss: 0.1858  noobj_loss: 0.0967  bbox_loss: 0.0113  cls_loss: 0.0244  \n",
      "<<<iteration:[60/657] - total_loss: 0.3309  obj_loss: 0.1873  noobj_loss: 0.1035  bbox_loss: 0.0126  cls_loss: 0.0287  \n",
      "<<<iteration:[80/657] - total_loss: 0.3407  obj_loss: 0.1814  noobj_loss: 0.1059  bbox_loss: 0.0142  cls_loss: 0.0352  \n",
      "<<<iteration:[100/657] - total_loss: 0.3614  obj_loss: 0.1894  noobj_loss: 0.1057  bbox_loss: 0.0131  cls_loss: 0.0536  \n",
      "<<<iteration:[120/657] - total_loss: 0.3283  obj_loss: 0.1839  noobj_loss: 0.1000  bbox_loss: 0.0134  cls_loss: 0.0273  \n",
      "<<<iteration:[140/657] - total_loss: 0.3286  obj_loss: 0.1760  noobj_loss: 0.1012  bbox_loss: 0.0136  cls_loss: 0.0341  \n",
      "<<<iteration:[160/657] - total_loss: 0.3417  obj_loss: 0.1820  noobj_loss: 0.1046  bbox_loss: 0.0130  cls_loss: 0.0424  \n",
      "<<<iteration:[180/657] - total_loss: 0.3387  obj_loss: 0.1804  noobj_loss: 0.1005  bbox_loss: 0.0141  cls_loss: 0.0373  \n",
      "<<<iteration:[200/657] - total_loss: 0.3271  obj_loss: 0.1705  noobj_loss: 0.1106  bbox_loss: 0.0136  cls_loss: 0.0334  \n",
      "<<<iteration:[220/657] - total_loss: 0.3167  obj_loss: 0.1789  noobj_loss: 0.1041  bbox_loss: 0.0117  cls_loss: 0.0274  \n",
      "<<<iteration:[240/657] - total_loss: 0.3408  obj_loss: 0.1845  noobj_loss: 0.1022  bbox_loss: 0.0129  cls_loss: 0.0409  \n",
      "<<<iteration:[260/657] - total_loss: 0.3195  obj_loss: 0.1690  noobj_loss: 0.1076  bbox_loss: 0.0135  cls_loss: 0.0294  \n",
      "<<<iteration:[280/657] - total_loss: 0.3235  obj_loss: 0.1758  noobj_loss: 0.1040  bbox_loss: 0.0126  cls_loss: 0.0329  \n",
      "<<<iteration:[300/657] - total_loss: 0.3496  obj_loss: 0.2015  noobj_loss: 0.1043  bbox_loss: 0.0123  cls_loss: 0.0344  \n",
      "<<<iteration:[320/657] - total_loss: 0.3386  obj_loss: 0.1808  noobj_loss: 0.1064  bbox_loss: 0.0129  cls_loss: 0.0401  \n",
      "<<<iteration:[340/657] - total_loss: 0.3410  obj_loss: 0.1867  noobj_loss: 0.1030  bbox_loss: 0.0128  cls_loss: 0.0388  \n",
      "<<<iteration:[360/657] - total_loss: 0.3298  obj_loss: 0.1825  noobj_loss: 0.1016  bbox_loss: 0.0120  cls_loss: 0.0365  \n",
      "<<<iteration:[380/657] - total_loss: 0.3273  obj_loss: 0.1910  noobj_loss: 0.1014  bbox_loss: 0.0112  cls_loss: 0.0297  \n",
      "<<<iteration:[400/657] - total_loss: 0.3210  obj_loss: 0.1631  noobj_loss: 0.1122  bbox_loss: 0.0125  cls_loss: 0.0393  \n",
      "<<<iteration:[420/657] - total_loss: 0.3371  obj_loss: 0.1871  noobj_loss: 0.1004  bbox_loss: 0.0118  cls_loss: 0.0407  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<<<iteration:[440/657] - total_loss: 0.3263  obj_loss: 0.1746  noobj_loss: 0.1037  bbox_loss: 0.0122  cls_loss: 0.0386  \n",
      "<<<iteration:[460/657] - total_loss: 0.3294  obj_loss: 0.1825  noobj_loss: 0.1034  bbox_loss: 0.0119  cls_loss: 0.0357  \n",
      "<<<iteration:[480/657] - total_loss: 0.3358  obj_loss: 0.1870  noobj_loss: 0.1048  bbox_loss: 0.0122  cls_loss: 0.0355  \n",
      "<<<iteration:[500/657] - total_loss: 0.3408  obj_loss: 0.1895  noobj_loss: 0.1005  bbox_loss: 0.0118  cls_loss: 0.0420  \n",
      "<<<iteration:[520/657] - total_loss: 0.3199  obj_loss: 0.1803  noobj_loss: 0.1050  bbox_loss: 0.0114  cls_loss: 0.0299  \n",
      "<<<iteration:[540/657] - total_loss: 0.3441  obj_loss: 0.1838  noobj_loss: 0.1080  bbox_loss: 0.0122  cls_loss: 0.0453  \n",
      "<<<iteration:[560/657] - total_loss: 0.3381  obj_loss: 0.1806  noobj_loss: 0.1006  bbox_loss: 0.0137  cls_loss: 0.0386  \n",
      "<<<iteration:[580/657] - total_loss: 0.3302  obj_loss: 0.1812  noobj_loss: 0.1062  bbox_loss: 0.0123  cls_loss: 0.0345  \n",
      "<<<iteration:[600/657] - total_loss: 0.3248  obj_loss: 0.1725  noobj_loss: 0.1023  bbox_loss: 0.0131  cls_loss: 0.0356  \n",
      "<<<iteration:[620/657] - total_loss: 0.3250  obj_loss: 0.1826  noobj_loss: 0.1055  bbox_loss: 0.0116  cls_loss: 0.0318  \n",
      "<<<iteration:[640/657] - total_loss: 0.3264  obj_loss: 0.1912  noobj_loss: 0.1058  bbox_loss: 0.0110  cls_loss: 0.0271  \n",
      "\n",
      "epoch:15/100 - Train Loss: 0.3319, Val Loss: 0.3221\n",
      "\n",
      "<<<iteration:[20/657] - total_loss: 0.3361  obj_loss: 0.1822  noobj_loss: 0.1074  bbox_loss: 0.0131  cls_loss: 0.0348  \n",
      "<<<iteration:[40/657] - total_loss: 0.3363  obj_loss: 0.1808  noobj_loss: 0.0999  bbox_loss: 0.0146  cls_loss: 0.0325  \n",
      "<<<iteration:[60/657] - total_loss: 0.3265  obj_loss: 0.1755  noobj_loss: 0.1021  bbox_loss: 0.0131  cls_loss: 0.0344  \n",
      "<<<iteration:[80/657] - total_loss: 0.3385  obj_loss: 0.1744  noobj_loss: 0.1030  bbox_loss: 0.0142  cls_loss: 0.0415  \n",
      "<<<iteration:[100/657] - total_loss: 0.3428  obj_loss: 0.1909  noobj_loss: 0.1016  bbox_loss: 0.0128  cls_loss: 0.0372  \n",
      "<<<iteration:[120/657] - total_loss: 0.3370  obj_loss: 0.1868  noobj_loss: 0.1048  bbox_loss: 0.0122  cls_loss: 0.0367  \n",
      "<<<iteration:[140/657] - total_loss: 0.3337  obj_loss: 0.1908  noobj_loss: 0.1055  bbox_loss: 0.0117  cls_loss: 0.0316  \n",
      "<<<iteration:[160/657] - total_loss: 0.3110  obj_loss: 0.1767  noobj_loss: 0.1029  bbox_loss: 0.0117  cls_loss: 0.0243  \n",
      "<<<iteration:[180/657] - total_loss: 0.3426  obj_loss: 0.1824  noobj_loss: 0.1000  bbox_loss: 0.0129  cls_loss: 0.0456  \n",
      "<<<iteration:[200/657] - total_loss: 0.3308  obj_loss: 0.1809  noobj_loss: 0.1057  bbox_loss: 0.0129  cls_loss: 0.0326  \n",
      "<<<iteration:[220/657] - total_loss: 0.3299  obj_loss: 0.1703  noobj_loss: 0.1023  bbox_loss: 0.0142  cls_loss: 0.0377  \n",
      "<<<iteration:[240/657] - total_loss: 0.3160  obj_loss: 0.1663  noobj_loss: 0.1071  bbox_loss: 0.0124  cls_loss: 0.0339  \n",
      "<<<iteration:[260/657] - total_loss: 0.3226  obj_loss: 0.1792  noobj_loss: 0.1023  bbox_loss: 0.0123  cls_loss: 0.0307  \n",
      "<<<iteration:[280/657] - total_loss: 0.3254  obj_loss: 0.1838  noobj_loss: 0.0996  bbox_loss: 0.0123  cls_loss: 0.0304  \n",
      "<<<iteration:[300/657] - total_loss: 0.3171  obj_loss: 0.1817  noobj_loss: 0.1066  bbox_loss: 0.0110  cls_loss: 0.0273  \n",
      "<<<iteration:[320/657] - total_loss: 0.3336  obj_loss: 0.1832  noobj_loss: 0.1106  bbox_loss: 0.0117  cls_loss: 0.0365  \n",
      "<<<iteration:[340/657] - total_loss: 0.3203  obj_loss: 0.1787  noobj_loss: 0.1055  bbox_loss: 0.0117  cls_loss: 0.0304  \n",
      "<<<iteration:[360/657] - total_loss: 0.3227  obj_loss: 0.1663  noobj_loss: 0.1087  bbox_loss: 0.0138  cls_loss: 0.0330  \n",
      "<<<iteration:[380/657] - total_loss: 0.3344  obj_loss: 0.1821  noobj_loss: 0.1097  bbox_loss: 0.0110  cls_loss: 0.0423  \n",
      "<<<iteration:[400/657] - total_loss: 0.3382  obj_loss: 0.1941  noobj_loss: 0.1075  bbox_loss: 0.0114  cls_loss: 0.0331  \n",
      "<<<iteration:[420/657] - total_loss: 0.3377  obj_loss: 0.1852  noobj_loss: 0.1070  bbox_loss: 0.0117  cls_loss: 0.0405  \n",
      "<<<iteration:[440/657] - total_loss: 0.3274  obj_loss: 0.1935  noobj_loss: 0.1069  bbox_loss: 0.0107  cls_loss: 0.0268  \n",
      "<<<iteration:[460/657] - total_loss: 0.3143  obj_loss: 0.1705  noobj_loss: 0.1024  bbox_loss: 0.0123  cls_loss: 0.0310  \n",
      "<<<iteration:[480/657] - total_loss: 0.3265  obj_loss: 0.1772  noobj_loss: 0.1115  bbox_loss: 0.0122  cls_loss: 0.0326  \n",
      "<<<iteration:[500/657] - total_loss: 0.3485  obj_loss: 0.1748  noobj_loss: 0.1033  bbox_loss: 0.0147  cls_loss: 0.0485  \n",
      "<<<iteration:[520/657] - total_loss: 0.3367  obj_loss: 0.1921  noobj_loss: 0.1044  bbox_loss: 0.0132  cls_loss: 0.0266  \n",
      "<<<iteration:[540/657] - total_loss: 0.3393  obj_loss: 0.1877  noobj_loss: 0.1086  bbox_loss: 0.0131  cls_loss: 0.0316  \n",
      "<<<iteration:[560/657] - total_loss: 0.3285  obj_loss: 0.1828  noobj_loss: 0.1038  bbox_loss: 0.0121  cls_loss: 0.0330  \n",
      "<<<iteration:[580/657] - total_loss: 0.3197  obj_loss: 0.1712  noobj_loss: 0.1060  bbox_loss: 0.0134  cls_loss: 0.0286  \n",
      "<<<iteration:[600/657] - total_loss: 0.3216  obj_loss: 0.1806  noobj_loss: 0.1028  bbox_loss: 0.0118  cls_loss: 0.0306  \n",
      "<<<iteration:[620/657] - total_loss: 0.3443  obj_loss: 0.1973  noobj_loss: 0.1000  bbox_loss: 0.0122  cls_loss: 0.0363  \n",
      "<<<iteration:[640/657] - total_loss: 0.3217  obj_loss: 0.1721  noobj_loss: 0.1065  bbox_loss: 0.0122  cls_loss: 0.0352  \n",
      "\n",
      "epoch:16/100 - Train Loss: 0.3302, Val Loss: 0.3303\n",
      "\n",
      "<<<iteration:[20/657] - total_loss: 0.3301  obj_loss: 0.1843  noobj_loss: 0.1084  bbox_loss: 0.0125  cls_loss: 0.0290  \n",
      "<<<iteration:[40/657] - total_loss: 0.3242  obj_loss: 0.1825  noobj_loss: 0.1050  bbox_loss: 0.0106  cls_loss: 0.0362  \n",
      "<<<iteration:[60/657] - total_loss: 0.3227  obj_loss: 0.1844  noobj_loss: 0.1006  bbox_loss: 0.0112  cls_loss: 0.0322  \n",
      "<<<iteration:[80/657] - total_loss: 0.3368  obj_loss: 0.1852  noobj_loss: 0.1062  bbox_loss: 0.0123  cls_loss: 0.0369  \n",
      "<<<iteration:[100/657] - total_loss: 0.3343  obj_loss: 0.2009  noobj_loss: 0.1040  bbox_loss: 0.0112  cls_loss: 0.0255  \n",
      "<<<iteration:[120/657] - total_loss: 0.3285  obj_loss: 0.1788  noobj_loss: 0.1068  bbox_loss: 0.0113  cls_loss: 0.0398  \n",
      "<<<iteration:[140/657] - total_loss: 0.3357  obj_loss: 0.1776  noobj_loss: 0.1065  bbox_loss: 0.0132  cls_loss: 0.0389  \n",
      "<<<iteration:[160/657] - total_loss: 0.3186  obj_loss: 0.1699  noobj_loss: 0.1086  bbox_loss: 0.0116  cls_loss: 0.0364  \n",
      "<<<iteration:[180/657] - total_loss: 0.3310  obj_loss: 0.1865  noobj_loss: 0.1047  bbox_loss: 0.0128  cls_loss: 0.0283  \n",
      "<<<iteration:[200/657] - total_loss: 0.3220  obj_loss: 0.1831  noobj_loss: 0.1085  bbox_loss: 0.0108  cls_loss: 0.0308  \n",
      "<<<iteration:[220/657] - total_loss: 0.3120  obj_loss: 0.1699  noobj_loss: 0.1010  bbox_loss: 0.0114  cls_loss: 0.0344  \n",
      "<<<iteration:[240/657] - total_loss: 0.3349  obj_loss: 0.1806  noobj_loss: 0.1131  bbox_loss: 0.0126  cls_loss: 0.0349  \n",
      "<<<iteration:[260/657] - total_loss: 0.3164  obj_loss: 0.1725  noobj_loss: 0.1049  bbox_loss: 0.0130  cls_loss: 0.0266  \n",
      "<<<iteration:[280/657] - total_loss: 0.3192  obj_loss: 0.1660  noobj_loss: 0.1044  bbox_loss: 0.0137  cls_loss: 0.0327  \n",
      "<<<iteration:[300/657] - total_loss: 0.3274  obj_loss: 0.1805  noobj_loss: 0.1119  bbox_loss: 0.0112  cls_loss: 0.0349  \n",
      "<<<iteration:[320/657] - total_loss: 0.3180  obj_loss: 0.1792  noobj_loss: 0.1054  bbox_loss: 0.0116  cls_loss: 0.0282  \n",
      "<<<iteration:[340/657] - total_loss: 0.3190  obj_loss: 0.1898  noobj_loss: 0.1018  bbox_loss: 0.0101  cls_loss: 0.0277  \n",
      "<<<iteration:[360/657] - total_loss: 0.3412  obj_loss: 0.1987  noobj_loss: 0.1089  bbox_loss: 0.0113  cls_loss: 0.0315  \n",
      "<<<iteration:[380/657] - total_loss: 0.3412  obj_loss: 0.1816  noobj_loss: 0.1027  bbox_loss: 0.0143  cls_loss: 0.0367  \n",
      "<<<iteration:[400/657] - total_loss: 0.3213  obj_loss: 0.1862  noobj_loss: 0.1100  bbox_loss: 0.0101  cls_loss: 0.0296  \n",
      "<<<iteration:[420/657] - total_loss: 0.3477  obj_loss: 0.1982  noobj_loss: 0.1106  bbox_loss: 0.0125  cls_loss: 0.0318  \n",
      "<<<iteration:[440/657] - total_loss: 0.3219  obj_loss: 0.1748  noobj_loss: 0.1042  bbox_loss: 0.0129  cls_loss: 0.0307  \n",
      "<<<iteration:[460/657] - total_loss: 0.3258  obj_loss: 0.1806  noobj_loss: 0.1033  bbox_loss: 0.0122  cls_loss: 0.0325  \n",
      "<<<iteration:[480/657] - total_loss: 0.3201  obj_loss: 0.1737  noobj_loss: 0.1020  bbox_loss: 0.0117  cls_loss: 0.0371  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<<<iteration:[500/657] - total_loss: 0.3307  obj_loss: 0.1854  noobj_loss: 0.1078  bbox_loss: 0.0117  cls_loss: 0.0327  \n",
      "<<<iteration:[520/657] - total_loss: 0.3297  obj_loss: 0.1709  noobj_loss: 0.1078  bbox_loss: 0.0127  cls_loss: 0.0414  \n",
      "<<<iteration:[540/657] - total_loss: 0.3404  obj_loss: 0.1964  noobj_loss: 0.1106  bbox_loss: 0.0114  cls_loss: 0.0320  \n",
      "<<<iteration:[560/657] - total_loss: 0.3174  obj_loss: 0.1744  noobj_loss: 0.1071  bbox_loss: 0.0122  cls_loss: 0.0282  \n",
      "<<<iteration:[580/657] - total_loss: 0.3251  obj_loss: 0.1580  noobj_loss: 0.1098  bbox_loss: 0.0145  cls_loss: 0.0398  \n",
      "<<<iteration:[600/657] - total_loss: 0.3290  obj_loss: 0.1858  noobj_loss: 0.1045  bbox_loss: 0.0113  cls_loss: 0.0346  \n",
      "<<<iteration:[620/657] - total_loss: 0.3420  obj_loss: 0.1865  noobj_loss: 0.1086  bbox_loss: 0.0123  cls_loss: 0.0398  \n",
      "<<<iteration:[640/657] - total_loss: 0.3267  obj_loss: 0.1798  noobj_loss: 0.1036  bbox_loss: 0.0121  cls_loss: 0.0347  \n",
      "\n",
      "epoch:17/100 - Train Loss: 0.3277, Val Loss: 0.3165\n",
      "\n",
      "<<<iteration:[20/657] - total_loss: 0.3276  obj_loss: 0.1728  noobj_loss: 0.1138  bbox_loss: 0.0127  cls_loss: 0.0346  \n",
      "<<<iteration:[40/657] - total_loss: 0.3166  obj_loss: 0.1828  noobj_loss: 0.1068  bbox_loss: 0.0112  cls_loss: 0.0242  \n",
      "<<<iteration:[60/657] - total_loss: 0.3277  obj_loss: 0.1859  noobj_loss: 0.1046  bbox_loss: 0.0120  cls_loss: 0.0297  \n",
      "<<<iteration:[80/657] - total_loss: 0.3353  obj_loss: 0.1825  noobj_loss: 0.1050  bbox_loss: 0.0124  cls_loss: 0.0380  \n",
      "<<<iteration:[100/657] - total_loss: 0.3425  obj_loss: 0.1829  noobj_loss: 0.1119  bbox_loss: 0.0124  cls_loss: 0.0419  \n",
      "<<<iteration:[120/657] - total_loss: 0.3328  obj_loss: 0.1875  noobj_loss: 0.1058  bbox_loss: 0.0118  cls_loss: 0.0334  \n",
      "<<<iteration:[140/657] - total_loss: 0.3268  obj_loss: 0.1846  noobj_loss: 0.1116  bbox_loss: 0.0118  cls_loss: 0.0276  \n",
      "<<<iteration:[160/657] - total_loss: 0.3314  obj_loss: 0.1814  noobj_loss: 0.1118  bbox_loss: 0.0115  cls_loss: 0.0365  \n",
      "<<<iteration:[180/657] - total_loss: 0.3043  obj_loss: 0.1726  noobj_loss: 0.1099  bbox_loss: 0.0113  cls_loss: 0.0204  \n",
      "<<<iteration:[200/657] - total_loss: 0.3253  obj_loss: 0.1832  noobj_loss: 0.1043  bbox_loss: 0.0118  cls_loss: 0.0311  \n",
      "<<<iteration:[220/657] - total_loss: 0.3222  obj_loss: 0.1833  noobj_loss: 0.1071  bbox_loss: 0.0105  cls_loss: 0.0328  \n",
      "<<<iteration:[240/657] - total_loss: 0.3257  obj_loss: 0.1812  noobj_loss: 0.1032  bbox_loss: 0.0122  cls_loss: 0.0318  \n",
      "<<<iteration:[260/657] - total_loss: 0.3214  obj_loss: 0.1820  noobj_loss: 0.1052  bbox_loss: 0.0107  cls_loss: 0.0334  \n",
      "<<<iteration:[280/657] - total_loss: 0.3172  obj_loss: 0.1822  noobj_loss: 0.1068  bbox_loss: 0.0110  cls_loss: 0.0268  \n",
      "<<<iteration:[300/657] - total_loss: 0.3269  obj_loss: 0.1896  noobj_loss: 0.1123  bbox_loss: 0.0100  cls_loss: 0.0312  \n",
      "<<<iteration:[320/657] - total_loss: 0.3199  obj_loss: 0.1852  noobj_loss: 0.1106  bbox_loss: 0.0104  cls_loss: 0.0275  \n",
      "<<<iteration:[340/657] - total_loss: 0.3470  obj_loss: 0.1820  noobj_loss: 0.1090  bbox_loss: 0.0122  cls_loss: 0.0493  \n",
      "<<<iteration:[360/657] - total_loss: 0.3263  obj_loss: 0.1822  noobj_loss: 0.1110  bbox_loss: 0.0118  cls_loss: 0.0297  \n",
      "<<<iteration:[380/657] - total_loss: 0.3139  obj_loss: 0.1756  noobj_loss: 0.1072  bbox_loss: 0.0107  cls_loss: 0.0312  \n",
      "<<<iteration:[400/657] - total_loss: 0.3095  obj_loss: 0.1730  noobj_loss: 0.1092  bbox_loss: 0.0117  cls_loss: 0.0236  \n",
      "<<<iteration:[420/657] - total_loss: 0.3206  obj_loss: 0.1886  noobj_loss: 0.1155  bbox_loss: 0.0098  cls_loss: 0.0253  \n",
      "<<<iteration:[440/657] - total_loss: 0.3111  obj_loss: 0.1690  noobj_loss: 0.1102  bbox_loss: 0.0123  cls_loss: 0.0256  \n",
      "<<<iteration:[460/657] - total_loss: 0.3308  obj_loss: 0.1795  noobj_loss: 0.1058  bbox_loss: 0.0112  cls_loss: 0.0423  \n",
      "<<<iteration:[480/657] - total_loss: 0.3335  obj_loss: 0.1843  noobj_loss: 0.1100  bbox_loss: 0.0121  cls_loss: 0.0335  \n",
      "<<<iteration:[500/657] - total_loss: 0.3313  obj_loss: 0.1843  noobj_loss: 0.1031  bbox_loss: 0.0126  cls_loss: 0.0325  \n",
      "<<<iteration:[520/657] - total_loss: 0.3355  obj_loss: 0.1872  noobj_loss: 0.1075  bbox_loss: 0.0110  cls_loss: 0.0396  \n",
      "<<<iteration:[540/657] - total_loss: 0.3281  obj_loss: 0.1929  noobj_loss: 0.1095  bbox_loss: 0.0108  cls_loss: 0.0267  \n",
      "<<<iteration:[560/657] - total_loss: 0.3209  obj_loss: 0.1779  noobj_loss: 0.1098  bbox_loss: 0.0121  cls_loss: 0.0273  \n",
      "<<<iteration:[580/657] - total_loss: 0.3301  obj_loss: 0.1889  noobj_loss: 0.1086  bbox_loss: 0.0108  cls_loss: 0.0330  \n",
      "<<<iteration:[600/657] - total_loss: 0.3290  obj_loss: 0.1852  noobj_loss: 0.1093  bbox_loss: 0.0109  cls_loss: 0.0345  \n",
      "<<<iteration:[620/657] - total_loss: 0.3084  obj_loss: 0.1797  noobj_loss: 0.1057  bbox_loss: 0.0101  cls_loss: 0.0251  \n",
      "<<<iteration:[640/657] - total_loss: 0.3250  obj_loss: 0.1811  noobj_loss: 0.1153  bbox_loss: 0.0112  cls_loss: 0.0300  \n",
      "\n",
      "epoch:18/100 - Train Loss: 0.3244, Val Loss: 0.3331\n",
      "\n",
      "<<<iteration:[20/657] - total_loss: 0.3555  obj_loss: 0.2109  noobj_loss: 0.1185  bbox_loss: 0.0108  cls_loss: 0.0316  \n",
      "<<<iteration:[40/657] - total_loss: 0.3147  obj_loss: 0.1678  noobj_loss: 0.1090  bbox_loss: 0.0117  cls_loss: 0.0339  \n",
      "<<<iteration:[60/657] - total_loss: 0.3177  obj_loss: 0.1820  noobj_loss: 0.1148  bbox_loss: 0.0104  cls_loss: 0.0262  \n",
      "<<<iteration:[80/657] - total_loss: 0.3336  obj_loss: 0.1890  noobj_loss: 0.1121  bbox_loss: 0.0106  cls_loss: 0.0355  \n",
      "<<<iteration:[100/657] - total_loss: 0.3269  obj_loss: 0.1928  noobj_loss: 0.1047  bbox_loss: 0.0105  cls_loss: 0.0293  \n",
      "<<<iteration:[120/657] - total_loss: 0.3240  obj_loss: 0.1890  noobj_loss: 0.1072  bbox_loss: 0.0105  cls_loss: 0.0288  \n",
      "<<<iteration:[140/657] - total_loss: 0.3306  obj_loss: 0.1913  noobj_loss: 0.1055  bbox_loss: 0.0105  cls_loss: 0.0338  \n",
      "<<<iteration:[160/657] - total_loss: 0.3155  obj_loss: 0.1684  noobj_loss: 0.1101  bbox_loss: 0.0115  cls_loss: 0.0348  \n",
      "<<<iteration:[180/657] - total_loss: 0.3320  obj_loss: 0.1793  noobj_loss: 0.1100  bbox_loss: 0.0127  cls_loss: 0.0344  \n",
      "<<<iteration:[200/657] - total_loss: 0.3140  obj_loss: 0.1826  noobj_loss: 0.1138  bbox_loss: 0.0104  cls_loss: 0.0225  \n",
      "<<<iteration:[220/657] - total_loss: 0.3209  obj_loss: 0.1850  noobj_loss: 0.1105  bbox_loss: 0.0109  cls_loss: 0.0260  \n",
      "<<<iteration:[240/657] - total_loss: 0.3196  obj_loss: 0.1856  noobj_loss: 0.1073  bbox_loss: 0.0102  cls_loss: 0.0293  \n",
      "<<<iteration:[260/657] - total_loss: 0.3215  obj_loss: 0.1794  noobj_loss: 0.1091  bbox_loss: 0.0109  cls_loss: 0.0330  \n",
      "<<<iteration:[280/657] - total_loss: 0.3222  obj_loss: 0.1774  noobj_loss: 0.1104  bbox_loss: 0.0120  cls_loss: 0.0296  \n",
      "<<<iteration:[300/657] - total_loss: 0.3266  obj_loss: 0.1846  noobj_loss: 0.1162  bbox_loss: 0.0108  cls_loss: 0.0300  \n",
      "<<<iteration:[320/657] - total_loss: 0.3185  obj_loss: 0.1782  noobj_loss: 0.1062  bbox_loss: 0.0117  cls_loss: 0.0286  \n",
      "<<<iteration:[340/657] - total_loss: 0.3362  obj_loss: 0.1858  noobj_loss: 0.1104  bbox_loss: 0.0127  cls_loss: 0.0318  \n",
      "<<<iteration:[360/657] - total_loss: 0.3273  obj_loss: 0.1867  noobj_loss: 0.1096  bbox_loss: 0.0115  cls_loss: 0.0285  \n",
      "<<<iteration:[380/657] - total_loss: 0.3268  obj_loss: 0.1911  noobj_loss: 0.1078  bbox_loss: 0.0107  cls_loss: 0.0282  \n",
      "<<<iteration:[400/657] - total_loss: 0.3232  obj_loss: 0.1774  noobj_loss: 0.1105  bbox_loss: 0.0124  cls_loss: 0.0288  \n",
      "<<<iteration:[420/657] - total_loss: 0.3212  obj_loss: 0.1836  noobj_loss: 0.1132  bbox_loss: 0.0107  cls_loss: 0.0275  \n",
      "<<<iteration:[440/657] - total_loss: 0.3275  obj_loss: 0.1827  noobj_loss: 0.1120  bbox_loss: 0.0112  cls_loss: 0.0328  \n",
      "<<<iteration:[460/657] - total_loss: 0.3128  obj_loss: 0.1814  noobj_loss: 0.1065  bbox_loss: 0.0104  cls_loss: 0.0259  \n",
      "<<<iteration:[480/657] - total_loss: 0.3245  obj_loss: 0.1780  noobj_loss: 0.1106  bbox_loss: 0.0118  cls_loss: 0.0320  \n",
      "<<<iteration:[500/657] - total_loss: 0.3180  obj_loss: 0.1882  noobj_loss: 0.1087  bbox_loss: 0.0109  cls_loss: 0.0208  \n",
      "<<<iteration:[520/657] - total_loss: 0.3341  obj_loss: 0.1968  noobj_loss: 0.1114  bbox_loss: 0.0101  cls_loss: 0.0314  \n",
      "<<<iteration:[540/657] - total_loss: 0.3166  obj_loss: 0.1778  noobj_loss: 0.1154  bbox_loss: 0.0109  cls_loss: 0.0265  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<<<iteration:[560/657] - total_loss: 0.3108  obj_loss: 0.1695  noobj_loss: 0.1101  bbox_loss: 0.0108  cls_loss: 0.0322  \n",
      "<<<iteration:[580/657] - total_loss: 0.3356  obj_loss: 0.1930  noobj_loss: 0.1096  bbox_loss: 0.0107  cls_loss: 0.0345  \n",
      "<<<iteration:[600/657] - total_loss: 0.3281  obj_loss: 0.1895  noobj_loss: 0.1190  bbox_loss: 0.0105  cls_loss: 0.0264  \n",
      "<<<iteration:[620/657] - total_loss: 0.3159  obj_loss: 0.1695  noobj_loss: 0.1208  bbox_loss: 0.0112  cls_loss: 0.0302  \n",
      "<<<iteration:[640/657] - total_loss: 0.3230  obj_loss: 0.1818  noobj_loss: 0.1110  bbox_loss: 0.0119  cls_loss: 0.0262  \n",
      "\n",
      "epoch:19/100 - Train Loss: 0.3234, Val Loss: 0.3322\n",
      "\n",
      "<<<iteration:[20/657] - total_loss: 0.3345  obj_loss: 0.1846  noobj_loss: 0.1150  bbox_loss: 0.0120  cls_loss: 0.0325  \n",
      "<<<iteration:[40/657] - total_loss: 0.3431  obj_loss: 0.2027  noobj_loss: 0.1124  bbox_loss: 0.0109  cls_loss: 0.0298  \n",
      "<<<iteration:[60/657] - total_loss: 0.3268  obj_loss: 0.1869  noobj_loss: 0.1165  bbox_loss: 0.0101  cls_loss: 0.0312  \n",
      "<<<iteration:[80/657] - total_loss: 0.3207  obj_loss: 0.1765  noobj_loss: 0.1128  bbox_loss: 0.0120  cls_loss: 0.0280  \n",
      "<<<iteration:[100/657] - total_loss: 0.3203  obj_loss: 0.1811  noobj_loss: 0.1104  bbox_loss: 0.0117  cls_loss: 0.0255  \n",
      "<<<iteration:[120/657] - total_loss: 0.3080  obj_loss: 0.1835  noobj_loss: 0.1133  bbox_loss: 0.0091  cls_loss: 0.0221  \n",
      "<<<iteration:[140/657] - total_loss: 0.3221  obj_loss: 0.1900  noobj_loss: 0.1114  bbox_loss: 0.0095  cls_loss: 0.0292  \n",
      "<<<iteration:[160/657] - total_loss: 0.3132  obj_loss: 0.1706  noobj_loss: 0.1101  bbox_loss: 0.0120  cls_loss: 0.0275  \n",
      "<<<iteration:[180/657] - total_loss: 0.3139  obj_loss: 0.1630  noobj_loss: 0.1106  bbox_loss: 0.0136  cls_loss: 0.0278  \n",
      "<<<iteration:[200/657] - total_loss: 0.3191  obj_loss: 0.1805  noobj_loss: 0.1119  bbox_loss: 0.0109  cls_loss: 0.0280  \n",
      "<<<iteration:[220/657] - total_loss: 0.3310  obj_loss: 0.1930  noobj_loss: 0.1107  bbox_loss: 0.0112  cls_loss: 0.0268  \n",
      "<<<iteration:[240/657] - total_loss: 0.3194  obj_loss: 0.1769  noobj_loss: 0.1095  bbox_loss: 0.0116  cls_loss: 0.0299  \n",
      "<<<iteration:[260/657] - total_loss: 0.3024  obj_loss: 0.1736  noobj_loss: 0.1068  bbox_loss: 0.0102  cls_loss: 0.0244  \n",
      "<<<iteration:[280/657] - total_loss: 0.3179  obj_loss: 0.1735  noobj_loss: 0.1182  bbox_loss: 0.0111  cls_loss: 0.0296  \n",
      "<<<iteration:[300/657] - total_loss: 0.3314  obj_loss: 0.1854  noobj_loss: 0.1132  bbox_loss: 0.0108  cls_loss: 0.0353  \n",
      "<<<iteration:[320/657] - total_loss: 0.3106  obj_loss: 0.1844  noobj_loss: 0.1083  bbox_loss: 0.0097  cls_loss: 0.0237  \n",
      "<<<iteration:[340/657] - total_loss: 0.3233  obj_loss: 0.1900  noobj_loss: 0.1214  bbox_loss: 0.0098  cls_loss: 0.0233  \n",
      "<<<iteration:[360/657] - total_loss: 0.3366  obj_loss: 0.1827  noobj_loss: 0.1079  bbox_loss: 0.0106  cls_loss: 0.0471  \n",
      "<<<iteration:[380/657] - total_loss: 0.3188  obj_loss: 0.1799  noobj_loss: 0.1125  bbox_loss: 0.0104  cls_loss: 0.0309  \n",
      "<<<iteration:[400/657] - total_loss: 0.3177  obj_loss: 0.1773  noobj_loss: 0.1135  bbox_loss: 0.0114  cls_loss: 0.0269  \n",
      "<<<iteration:[420/657] - total_loss: 0.3228  obj_loss: 0.1888  noobj_loss: 0.1132  bbox_loss: 0.0099  cls_loss: 0.0276  \n",
      "<<<iteration:[440/657] - total_loss: 0.3144  obj_loss: 0.1844  noobj_loss: 0.1133  bbox_loss: 0.0095  cls_loss: 0.0258  \n",
      "<<<iteration:[460/657] - total_loss: 0.3408  obj_loss: 0.2074  noobj_loss: 0.1146  bbox_loss: 0.0088  cls_loss: 0.0322  \n",
      "<<<iteration:[480/657] - total_loss: 0.3258  obj_loss: 0.1907  noobj_loss: 0.1098  bbox_loss: 0.0107  cls_loss: 0.0265  \n",
      "<<<iteration:[500/657] - total_loss: 0.3237  obj_loss: 0.1794  noobj_loss: 0.1164  bbox_loss: 0.0111  cls_loss: 0.0304  \n",
      "<<<iteration:[520/657] - total_loss: 0.3140  obj_loss: 0.1768  noobj_loss: 0.1045  bbox_loss: 0.0108  cls_loss: 0.0311  \n",
      "<<<iteration:[540/657] - total_loss: 0.3277  obj_loss: 0.1837  noobj_loss: 0.1193  bbox_loss: 0.0106  cls_loss: 0.0312  \n",
      "<<<iteration:[560/657] - total_loss: 0.3257  obj_loss: 0.1811  noobj_loss: 0.1157  bbox_loss: 0.0110  cls_loss: 0.0319  \n",
      "<<<iteration:[580/657] - total_loss: 0.3234  obj_loss: 0.1831  noobj_loss: 0.1152  bbox_loss: 0.0098  cls_loss: 0.0335  \n",
      "<<<iteration:[600/657] - total_loss: 0.3070  obj_loss: 0.1713  noobj_loss: 0.1185  bbox_loss: 0.0109  cls_loss: 0.0218  \n",
      "<<<iteration:[620/657] - total_loss: 0.3314  obj_loss: 0.1801  noobj_loss: 0.1109  bbox_loss: 0.0112  cls_loss: 0.0398  \n",
      "<<<iteration:[640/657] - total_loss: 0.3294  obj_loss: 0.1870  noobj_loss: 0.1112  bbox_loss: 0.0108  cls_loss: 0.0330  \n",
      "\n",
      "epoch:20/100 - Train Loss: 0.3214, Val Loss: 0.3258\n",
      "\n",
      "<<<iteration:[20/657] - total_loss: 0.3343  obj_loss: 0.1839  noobj_loss: 0.1211  bbox_loss: 0.0116  cls_loss: 0.0320  \n",
      "<<<iteration:[40/657] - total_loss: 0.3215  obj_loss: 0.1824  noobj_loss: 0.1104  bbox_loss: 0.0113  cls_loss: 0.0274  \n",
      "<<<iteration:[60/657] - total_loss: 0.3189  obj_loss: 0.1855  noobj_loss: 0.1132  bbox_loss: 0.0098  cls_loss: 0.0279  \n",
      "<<<iteration:[80/657] - total_loss: 0.3207  obj_loss: 0.1872  noobj_loss: 0.1170  bbox_loss: 0.0097  cls_loss: 0.0267  \n",
      "<<<iteration:[100/657] - total_loss: 0.3116  obj_loss: 0.1737  noobj_loss: 0.1153  bbox_loss: 0.0101  cls_loss: 0.0298  \n",
      "<<<iteration:[120/657] - total_loss: 0.3156  obj_loss: 0.1813  noobj_loss: 0.1144  bbox_loss: 0.0099  cls_loss: 0.0277  \n",
      "<<<iteration:[140/657] - total_loss: 0.3233  obj_loss: 0.1850  noobj_loss: 0.1174  bbox_loss: 0.0106  cls_loss: 0.0264  \n",
      "<<<iteration:[160/657] - total_loss: 0.3130  obj_loss: 0.1744  noobj_loss: 0.1146  bbox_loss: 0.0111  cls_loss: 0.0258  \n",
      "<<<iteration:[180/657] - total_loss: 0.3365  obj_loss: 0.2033  noobj_loss: 0.1129  bbox_loss: 0.0099  cls_loss: 0.0271  \n",
      "<<<iteration:[200/657] - total_loss: 0.3120  obj_loss: 0.1809  noobj_loss: 0.1185  bbox_loss: 0.0102  cls_loss: 0.0209  \n",
      "<<<iteration:[220/657] - total_loss: 0.3305  obj_loss: 0.1934  noobj_loss: 0.1103  bbox_loss: 0.0112  cls_loss: 0.0258  \n",
      "<<<iteration:[240/657] - total_loss: 0.3324  obj_loss: 0.1953  noobj_loss: 0.1140  bbox_loss: 0.0107  cls_loss: 0.0267  \n",
      "<<<iteration:[260/657] - total_loss: 0.3263  obj_loss: 0.1845  noobj_loss: 0.1202  bbox_loss: 0.0109  cls_loss: 0.0274  \n",
      "<<<iteration:[280/657] - total_loss: 0.3169  obj_loss: 0.1852  noobj_loss: 0.1146  bbox_loss: 0.0094  cls_loss: 0.0271  \n",
      "<<<iteration:[300/657] - total_loss: 0.3230  obj_loss: 0.1804  noobj_loss: 0.1128  bbox_loss: 0.0107  cls_loss: 0.0325  \n",
      "<<<iteration:[320/657] - total_loss: 0.3162  obj_loss: 0.1695  noobj_loss: 0.1104  bbox_loss: 0.0119  cls_loss: 0.0320  \n",
      "<<<iteration:[340/657] - total_loss: 0.3202  obj_loss: 0.1904  noobj_loss: 0.1152  bbox_loss: 0.0101  cls_loss: 0.0217  \n",
      "<<<iteration:[360/657] - total_loss: 0.3248  obj_loss: 0.1910  noobj_loss: 0.1135  bbox_loss: 0.0101  cls_loss: 0.0268  \n",
      "<<<iteration:[380/657] - total_loss: 0.3188  obj_loss: 0.1837  noobj_loss: 0.1203  bbox_loss: 0.0102  cls_loss: 0.0239  \n",
      "<<<iteration:[400/657] - total_loss: 0.3283  obj_loss: 0.1955  noobj_loss: 0.1138  bbox_loss: 0.0093  cls_loss: 0.0292  \n",
      "<<<iteration:[420/657] - total_loss: 0.3151  obj_loss: 0.1843  noobj_loss: 0.1080  bbox_loss: 0.0102  cls_loss: 0.0259  \n",
      "<<<iteration:[440/657] - total_loss: 0.3171  obj_loss: 0.1828  noobj_loss: 0.1195  bbox_loss: 0.0101  cls_loss: 0.0242  \n",
      "<<<iteration:[460/657] - total_loss: 0.3104  obj_loss: 0.1732  noobj_loss: 0.1170  bbox_loss: 0.0100  cls_loss: 0.0289  \n",
      "<<<iteration:[480/657] - total_loss: 0.3197  obj_loss: 0.1732  noobj_loss: 0.1131  bbox_loss: 0.0112  cls_loss: 0.0340  \n",
      "<<<iteration:[500/657] - total_loss: 0.3126  obj_loss: 0.1801  noobj_loss: 0.1132  bbox_loss: 0.0105  cls_loss: 0.0232  \n",
      "<<<iteration:[520/657] - total_loss: 0.3124  obj_loss: 0.1844  noobj_loss: 0.1112  bbox_loss: 0.0092  cls_loss: 0.0263  \n",
      "<<<iteration:[540/657] - total_loss: 0.3303  obj_loss: 0.1892  noobj_loss: 0.1193  bbox_loss: 0.0111  cls_loss: 0.0260  \n",
      "<<<iteration:[560/657] - total_loss: 0.3266  obj_loss: 0.1894  noobj_loss: 0.1122  bbox_loss: 0.0109  cls_loss: 0.0267  \n",
      "<<<iteration:[580/657] - total_loss: 0.3148  obj_loss: 0.1754  noobj_loss: 0.1097  bbox_loss: 0.0110  cls_loss: 0.0296  \n",
      "<<<iteration:[600/657] - total_loss: 0.3264  obj_loss: 0.1906  noobj_loss: 0.1136  bbox_loss: 0.0102  cls_loss: 0.0281  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<<<iteration:[620/657] - total_loss: 0.3319  obj_loss: 0.1922  noobj_loss: 0.1132  bbox_loss: 0.0100  cls_loss: 0.0330  \n",
      "<<<iteration:[640/657] - total_loss: 0.3287  obj_loss: 0.1901  noobj_loss: 0.1168  bbox_loss: 0.0107  cls_loss: 0.0265  \n",
      "\n",
      "epoch:21/100 - Train Loss: 0.3217, Val Loss: 0.3345\n",
      "\n",
      "<<<iteration:[20/657] - total_loss: 0.3391  obj_loss: 0.1967  noobj_loss: 0.1206  bbox_loss: 0.0109  cls_loss: 0.0275  \n",
      "<<<iteration:[40/657] - total_loss: 0.3055  obj_loss: 0.1688  noobj_loss: 0.1166  bbox_loss: 0.0104  cls_loss: 0.0266  \n",
      "<<<iteration:[60/657] - total_loss: 0.3271  obj_loss: 0.1871  noobj_loss: 0.1123  bbox_loss: 0.0110  cls_loss: 0.0289  \n",
      "<<<iteration:[80/657] - total_loss: 0.3086  obj_loss: 0.1696  noobj_loss: 0.1163  bbox_loss: 0.0100  cls_loss: 0.0307  \n",
      "<<<iteration:[100/657] - total_loss: 0.3107  obj_loss: 0.1789  noobj_loss: 0.1135  bbox_loss: 0.0101  cls_loss: 0.0248  \n",
      "<<<iteration:[120/657] - total_loss: 0.3194  obj_loss: 0.1840  noobj_loss: 0.1139  bbox_loss: 0.0095  cls_loss: 0.0308  \n",
      "<<<iteration:[140/657] - total_loss: 0.3140  obj_loss: 0.1791  noobj_loss: 0.1142  bbox_loss: 0.0097  cls_loss: 0.0294  \n",
      "<<<iteration:[160/657] - total_loss: 0.3225  obj_loss: 0.1767  noobj_loss: 0.1167  bbox_loss: 0.0105  cls_loss: 0.0349  \n",
      "<<<iteration:[180/657] - total_loss: 0.3187  obj_loss: 0.1728  noobj_loss: 0.1260  bbox_loss: 0.0102  cls_loss: 0.0318  \n",
      "<<<iteration:[200/657] - total_loss: 0.3212  obj_loss: 0.1800  noobj_loss: 0.1189  bbox_loss: 0.0109  cls_loss: 0.0273  \n",
      "<<<iteration:[220/657] - total_loss: 0.3146  obj_loss: 0.1810  noobj_loss: 0.1182  bbox_loss: 0.0097  cls_loss: 0.0260  \n",
      "<<<iteration:[240/657] - total_loss: 0.3328  obj_loss: 0.1795  noobj_loss: 0.1168  bbox_loss: 0.0125  cls_loss: 0.0326  \n",
      "<<<iteration:[260/657] - total_loss: 0.3127  obj_loss: 0.1779  noobj_loss: 0.1163  bbox_loss: 0.0102  cls_loss: 0.0255  \n",
      "<<<iteration:[280/657] - total_loss: 0.3164  obj_loss: 0.1832  noobj_loss: 0.1131  bbox_loss: 0.0101  cls_loss: 0.0258  \n",
      "<<<iteration:[300/657] - total_loss: 0.3180  obj_loss: 0.1752  noobj_loss: 0.1157  bbox_loss: 0.0108  cls_loss: 0.0312  \n",
      "<<<iteration:[320/657] - total_loss: 0.3158  obj_loss: 0.1842  noobj_loss: 0.1150  bbox_loss: 0.0104  cls_loss: 0.0223  \n",
      "<<<iteration:[340/657] - total_loss: 0.3115  obj_loss: 0.1773  noobj_loss: 0.1127  bbox_loss: 0.0097  cls_loss: 0.0294  \n",
      "<<<iteration:[360/657] - total_loss: 0.3149  obj_loss: 0.1777  noobj_loss: 0.1190  bbox_loss: 0.0098  cls_loss: 0.0289  \n",
      "<<<iteration:[380/657] - total_loss: 0.3153  obj_loss: 0.1743  noobj_loss: 0.1198  bbox_loss: 0.0106  cls_loss: 0.0280  \n",
      "<<<iteration:[400/657] - total_loss: 0.3189  obj_loss: 0.1889  noobj_loss: 0.1130  bbox_loss: 0.0087  cls_loss: 0.0301  \n",
      "<<<iteration:[420/657] - total_loss: 0.3158  obj_loss: 0.1792  noobj_loss: 0.1130  bbox_loss: 0.0107  cls_loss: 0.0264  \n",
      "<<<iteration:[440/657] - total_loss: 0.3308  obj_loss: 0.1921  noobj_loss: 0.1223  bbox_loss: 0.0093  cls_loss: 0.0309  \n",
      "<<<iteration:[460/657] - total_loss: 0.3243  obj_loss: 0.1888  noobj_loss: 0.1176  bbox_loss: 0.0099  cls_loss: 0.0272  \n",
      "<<<iteration:[480/657] - total_loss: 0.3169  obj_loss: 0.1873  noobj_loss: 0.1129  bbox_loss: 0.0096  cls_loss: 0.0250  \n",
      "<<<iteration:[500/657] - total_loss: 0.3101  obj_loss: 0.1770  noobj_loss: 0.1171  bbox_loss: 0.0102  cls_loss: 0.0238  \n",
      "<<<iteration:[520/657] - total_loss: 0.3119  obj_loss: 0.1750  noobj_loss: 0.1181  bbox_loss: 0.0104  cls_loss: 0.0257  \n",
      "<<<iteration:[540/657] - total_loss: 0.3206  obj_loss: 0.1805  noobj_loss: 0.1152  bbox_loss: 0.0104  cls_loss: 0.0303  \n",
      "<<<iteration:[560/657] - total_loss: 0.3273  obj_loss: 0.1968  noobj_loss: 0.1159  bbox_loss: 0.0097  cls_loss: 0.0242  \n",
      "<<<iteration:[580/657] - total_loss: 0.3154  obj_loss: 0.1912  noobj_loss: 0.1159  bbox_loss: 0.0088  cls_loss: 0.0226  \n",
      "<<<iteration:[600/657] - total_loss: 0.3108  obj_loss: 0.1845  noobj_loss: 0.1144  bbox_loss: 0.0094  cls_loss: 0.0223  \n",
      "<<<iteration:[620/657] - total_loss: 0.3154  obj_loss: 0.1928  noobj_loss: 0.1119  bbox_loss: 0.0098  cls_loss: 0.0178  \n",
      "<<<iteration:[640/657] - total_loss: 0.3153  obj_loss: 0.1910  noobj_loss: 0.1101  bbox_loss: 0.0092  cls_loss: 0.0235  \n",
      "\n",
      "epoch:22/100 - Train Loss: 0.3178, Val Loss: 0.3304\n",
      "\n",
      "<<<iteration:[20/657] - total_loss: 0.3319  obj_loss: 0.1851  noobj_loss: 0.1222  bbox_loss: 0.0108  cls_loss: 0.0318  \n",
      "<<<iteration:[40/657] - total_loss: 0.3181  obj_loss: 0.1939  noobj_loss: 0.1156  bbox_loss: 0.0085  cls_loss: 0.0239  \n",
      "<<<iteration:[60/657] - total_loss: 0.3019  obj_loss: 0.1647  noobj_loss: 0.1216  bbox_loss: 0.0104  cls_loss: 0.0243  \n",
      "<<<iteration:[80/657] - total_loss: 0.3131  obj_loss: 0.1709  noobj_loss: 0.1248  bbox_loss: 0.0106  cls_loss: 0.0270  \n",
      "<<<iteration:[100/657] - total_loss: 0.3149  obj_loss: 0.1855  noobj_loss: 0.1205  bbox_loss: 0.0089  cls_loss: 0.0248  \n",
      "<<<iteration:[120/657] - total_loss: 0.3150  obj_loss: 0.1826  noobj_loss: 0.1174  bbox_loss: 0.0095  cls_loss: 0.0261  \n",
      "<<<iteration:[140/657] - total_loss: 0.3175  obj_loss: 0.1870  noobj_loss: 0.1132  bbox_loss: 0.0096  cls_loss: 0.0259  \n",
      "<<<iteration:[160/657] - total_loss: 0.3351  obj_loss: 0.1965  noobj_loss: 0.1182  bbox_loss: 0.0105  cls_loss: 0.0270  \n",
      "<<<iteration:[180/657] - total_loss: 0.3171  obj_loss: 0.1807  noobj_loss: 0.1165  bbox_loss: 0.0105  cls_loss: 0.0256  \n",
      "<<<iteration:[200/657] - total_loss: 0.3157  obj_loss: 0.1829  noobj_loss: 0.1168  bbox_loss: 0.0096  cls_loss: 0.0263  \n",
      "<<<iteration:[220/657] - total_loss: 0.3165  obj_loss: 0.1902  noobj_loss: 0.1144  bbox_loss: 0.0094  cls_loss: 0.0223  \n",
      "<<<iteration:[240/657] - total_loss: 0.3221  obj_loss: 0.1833  noobj_loss: 0.1148  bbox_loss: 0.0101  cls_loss: 0.0308  \n",
      "<<<iteration:[260/657] - total_loss: 0.3199  obj_loss: 0.1765  noobj_loss: 0.1188  bbox_loss: 0.0102  cls_loss: 0.0331  \n",
      "<<<iteration:[280/657] - total_loss: 0.3195  obj_loss: 0.1888  noobj_loss: 0.1191  bbox_loss: 0.0097  cls_loss: 0.0229  \n",
      "<<<iteration:[300/657] - total_loss: 0.3298  obj_loss: 0.1970  noobj_loss: 0.1167  bbox_loss: 0.0099  cls_loss: 0.0248  \n",
      "<<<iteration:[320/657] - total_loss: 0.3147  obj_loss: 0.1779  noobj_loss: 0.1189  bbox_loss: 0.0101  cls_loss: 0.0266  \n",
      "<<<iteration:[340/657] - total_loss: 0.3190  obj_loss: 0.1778  noobj_loss: 0.1141  bbox_loss: 0.0113  cls_loss: 0.0277  \n",
      "<<<iteration:[360/657] - total_loss: 0.3088  obj_loss: 0.1809  noobj_loss: 0.1138  bbox_loss: 0.0091  cls_loss: 0.0257  \n",
      "<<<iteration:[380/657] - total_loss: 0.3247  obj_loss: 0.1919  noobj_loss: 0.1196  bbox_loss: 0.0098  cls_loss: 0.0238  \n",
      "<<<iteration:[400/657] - total_loss: 0.3183  obj_loss: 0.1797  noobj_loss: 0.1163  bbox_loss: 0.0101  cls_loss: 0.0301  \n",
      "<<<iteration:[420/657] - total_loss: 0.3051  obj_loss: 0.1713  noobj_loss: 0.1227  bbox_loss: 0.0093  cls_loss: 0.0260  \n",
      "<<<iteration:[440/657] - total_loss: 0.3201  obj_loss: 0.1870  noobj_loss: 0.1186  bbox_loss: 0.0105  cls_loss: 0.0212  \n",
      "<<<iteration:[460/657] - total_loss: 0.3205  obj_loss: 0.1917  noobj_loss: 0.1193  bbox_loss: 0.0093  cls_loss: 0.0225  \n",
      "<<<iteration:[480/657] - total_loss: 0.3215  obj_loss: 0.1852  noobj_loss: 0.1209  bbox_loss: 0.0100  cls_loss: 0.0260  \n",
      "<<<iteration:[500/657] - total_loss: 0.3370  obj_loss: 0.1920  noobj_loss: 0.1259  bbox_loss: 0.0112  cls_loss: 0.0262  \n",
      "<<<iteration:[520/657] - total_loss: 0.3174  obj_loss: 0.1734  noobj_loss: 0.1212  bbox_loss: 0.0100  cls_loss: 0.0333  \n",
      "<<<iteration:[540/657] - total_loss: 0.3172  obj_loss: 0.1869  noobj_loss: 0.1203  bbox_loss: 0.0094  cls_loss: 0.0229  \n",
      "<<<iteration:[560/657] - total_loss: 0.3305  obj_loss: 0.1974  noobj_loss: 0.1204  bbox_loss: 0.0092  cls_loss: 0.0268  \n",
      "<<<iteration:[580/657] - total_loss: 0.3265  obj_loss: 0.1980  noobj_loss: 0.1184  bbox_loss: 0.0090  cls_loss: 0.0244  \n",
      "<<<iteration:[600/657] - total_loss: 0.3010  obj_loss: 0.1738  noobj_loss: 0.1198  bbox_loss: 0.0090  cls_loss: 0.0226  \n",
      "<<<iteration:[620/657] - total_loss: 0.3249  obj_loss: 0.1849  noobj_loss: 0.1197  bbox_loss: 0.0102  cls_loss: 0.0293  \n",
      "<<<iteration:[640/657] - total_loss: 0.3228  obj_loss: 0.1972  noobj_loss: 0.1189  bbox_loss: 0.0087  cls_loss: 0.0229  \n",
      "\n",
      "epoch:23/100 - Train Loss: 0.3193, Val Loss: 0.3232\n",
      "\n",
      "<<<iteration:[20/657] - total_loss: 0.3379  obj_loss: 0.1991  noobj_loss: 0.1275  bbox_loss: 0.0100  cls_loss: 0.0252  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<<<iteration:[40/657] - total_loss: 0.3008  obj_loss: 0.1623  noobj_loss: 0.1184  bbox_loss: 0.0095  cls_loss: 0.0319  \n",
      "<<<iteration:[60/657] - total_loss: 0.3130  obj_loss: 0.1850  noobj_loss: 0.1160  bbox_loss: 0.0095  cls_loss: 0.0225  \n",
      "<<<iteration:[80/657] - total_loss: 0.3149  obj_loss: 0.1846  noobj_loss: 0.1248  bbox_loss: 0.0087  cls_loss: 0.0244  \n",
      "<<<iteration:[100/657] - total_loss: 0.3178  obj_loss: 0.1785  noobj_loss: 0.1227  bbox_loss: 0.0102  cls_loss: 0.0269  \n",
      "<<<iteration:[120/657] - total_loss: 0.3315  obj_loss: 0.1966  noobj_loss: 0.1168  bbox_loss: 0.0095  cls_loss: 0.0289  \n",
      "<<<iteration:[140/657] - total_loss: 0.3199  obj_loss: 0.1834  noobj_loss: 0.1202  bbox_loss: 0.0095  cls_loss: 0.0288  \n",
      "<<<iteration:[160/657] - total_loss: 0.3222  obj_loss: 0.1865  noobj_loss: 0.1226  bbox_loss: 0.0100  cls_loss: 0.0244  \n",
      "<<<iteration:[180/657] - total_loss: 0.3224  obj_loss: 0.1823  noobj_loss: 0.1227  bbox_loss: 0.0103  cls_loss: 0.0270  \n",
      "<<<iteration:[200/657] - total_loss: 0.3195  obj_loss: 0.1798  noobj_loss: 0.1176  bbox_loss: 0.0113  cls_loss: 0.0244  \n",
      "<<<iteration:[220/657] - total_loss: 0.3032  obj_loss: 0.1754  noobj_loss: 0.1140  bbox_loss: 0.0097  cls_loss: 0.0223  \n",
      "<<<iteration:[240/657] - total_loss: 0.3093  obj_loss: 0.1853  noobj_loss: 0.1180  bbox_loss: 0.0090  cls_loss: 0.0202  \n",
      "<<<iteration:[260/657] - total_loss: 0.3220  obj_loss: 0.1860  noobj_loss: 0.1170  bbox_loss: 0.0105  cls_loss: 0.0251  \n",
      "<<<iteration:[280/657] - total_loss: 0.3210  obj_loss: 0.1883  noobj_loss: 0.1263  bbox_loss: 0.0093  cls_loss: 0.0231  \n",
      "<<<iteration:[300/657] - total_loss: 0.3362  obj_loss: 0.1949  noobj_loss: 0.1223  bbox_loss: 0.0102  cls_loss: 0.0288  \n",
      "<<<iteration:[320/657] - total_loss: 0.3093  obj_loss: 0.1794  noobj_loss: 0.1249  bbox_loss: 0.0085  cls_loss: 0.0251  \n",
      "<<<iteration:[340/657] - total_loss: 0.3039  obj_loss: 0.1808  noobj_loss: 0.1129  bbox_loss: 0.0087  cls_loss: 0.0232  \n",
      "<<<iteration:[360/657] - total_loss: 0.3282  obj_loss: 0.2013  noobj_loss: 0.1213  bbox_loss: 0.0089  cls_loss: 0.0220  \n",
      "<<<iteration:[380/657] - total_loss: 0.3175  obj_loss: 0.1868  noobj_loss: 0.1318  bbox_loss: 0.0091  cls_loss: 0.0193  \n",
      "<<<iteration:[400/657] - total_loss: 0.3105  obj_loss: 0.1837  noobj_loss: 0.1128  bbox_loss: 0.0092  cls_loss: 0.0242  \n",
      "<<<iteration:[420/657] - total_loss: 0.3105  obj_loss: 0.1735  noobj_loss: 0.1259  bbox_loss: 0.0102  cls_loss: 0.0228  \n",
      "<<<iteration:[440/657] - total_loss: 0.3221  obj_loss: 0.1788  noobj_loss: 0.1255  bbox_loss: 0.0103  cls_loss: 0.0293  \n",
      "<<<iteration:[460/657] - total_loss: 0.3188  obj_loss: 0.1828  noobj_loss: 0.1181  bbox_loss: 0.0102  cls_loss: 0.0260  \n",
      "<<<iteration:[480/657] - total_loss: 0.3233  obj_loss: 0.1885  noobj_loss: 0.1188  bbox_loss: 0.0100  cls_loss: 0.0256  \n",
      "<<<iteration:[500/657] - total_loss: 0.3099  obj_loss: 0.1826  noobj_loss: 0.1168  bbox_loss: 0.0086  cls_loss: 0.0261  \n",
      "<<<iteration:[520/657] - total_loss: 0.3142  obj_loss: 0.1749  noobj_loss: 0.1255  bbox_loss: 0.0094  cls_loss: 0.0298  \n",
      "<<<iteration:[540/657] - total_loss: 0.3136  obj_loss: 0.1733  noobj_loss: 0.1251  bbox_loss: 0.0102  cls_loss: 0.0268  \n",
      "<<<iteration:[560/657] - total_loss: 0.3180  obj_loss: 0.1913  noobj_loss: 0.1177  bbox_loss: 0.0086  cls_loss: 0.0249  \n",
      "<<<iteration:[580/657] - total_loss: 0.3305  obj_loss: 0.1947  noobj_loss: 0.1190  bbox_loss: 0.0099  cls_loss: 0.0270  \n",
      "<<<iteration:[600/657] - total_loss: 0.2928  obj_loss: 0.1583  noobj_loss: 0.1201  bbox_loss: 0.0099  cls_loss: 0.0247  \n",
      "<<<iteration:[620/657] - total_loss: 0.3186  obj_loss: 0.1880  noobj_loss: 0.1233  bbox_loss: 0.0090  cls_loss: 0.0241  \n",
      "<<<iteration:[640/657] - total_loss: 0.3054  obj_loss: 0.1758  noobj_loss: 0.1203  bbox_loss: 0.0097  cls_loss: 0.0210  \n",
      "\n",
      "epoch:24/100 - Train Loss: 0.3161, Val Loss: 0.3356\n",
      "\n",
      "<<<iteration:[20/657] - total_loss: 0.3372  obj_loss: 0.2000  noobj_loss: 0.1305  bbox_loss: 0.0096  cls_loss: 0.0240  \n",
      "<<<iteration:[40/657] - total_loss: 0.3131  obj_loss: 0.1753  noobj_loss: 0.1276  bbox_loss: 0.0100  cls_loss: 0.0240  \n",
      "<<<iteration:[60/657] - total_loss: 0.3169  obj_loss: 0.1879  noobj_loss: 0.1168  bbox_loss: 0.0099  cls_loss: 0.0210  \n",
      "<<<iteration:[80/657] - total_loss: 0.3005  obj_loss: 0.1750  noobj_loss: 0.1175  bbox_loss: 0.0090  cls_loss: 0.0216  \n",
      "<<<iteration:[100/657] - total_loss: 0.3169  obj_loss: 0.1910  noobj_loss: 0.1175  bbox_loss: 0.0091  cls_loss: 0.0216  \n",
      "<<<iteration:[120/657] - total_loss: 0.3188  obj_loss: 0.1840  noobj_loss: 0.1205  bbox_loss: 0.0099  cls_loss: 0.0251  \n",
      "<<<iteration:[140/657] - total_loss: 0.3096  obj_loss: 0.1765  noobj_loss: 0.1240  bbox_loss: 0.0090  cls_loss: 0.0262  \n",
      "<<<iteration:[160/657] - total_loss: 0.3162  obj_loss: 0.1815  noobj_loss: 0.1275  bbox_loss: 0.0088  cls_loss: 0.0270  \n",
      "<<<iteration:[180/657] - total_loss: 0.3042  obj_loss: 0.1785  noobj_loss: 0.1184  bbox_loss: 0.0084  cls_loss: 0.0246  \n",
      "<<<iteration:[200/657] - total_loss: 0.3075  obj_loss: 0.1859  noobj_loss: 0.1182  bbox_loss: 0.0090  cls_loss: 0.0175  \n",
      "<<<iteration:[220/657] - total_loss: 0.3126  obj_loss: 0.1680  noobj_loss: 0.1263  bbox_loss: 0.0105  cls_loss: 0.0291  \n",
      "<<<iteration:[240/657] - total_loss: 0.3326  obj_loss: 0.1908  noobj_loss: 0.1214  bbox_loss: 0.0106  cls_loss: 0.0280  \n",
      "<<<iteration:[260/657] - total_loss: 0.2930  obj_loss: 0.1699  noobj_loss: 0.1224  bbox_loss: 0.0089  cls_loss: 0.0176  \n",
      "<<<iteration:[280/657] - total_loss: 0.3122  obj_loss: 0.1783  noobj_loss: 0.1155  bbox_loss: 0.0097  cls_loss: 0.0278  \n",
      "<<<iteration:[300/657] - total_loss: 0.3054  obj_loss: 0.1786  noobj_loss: 0.1231  bbox_loss: 0.0090  cls_loss: 0.0202  \n",
      "<<<iteration:[320/657] - total_loss: 0.3034  obj_loss: 0.1748  noobj_loss: 0.1171  bbox_loss: 0.0097  cls_loss: 0.0218  \n",
      "<<<iteration:[340/657] - total_loss: 0.3196  obj_loss: 0.1905  noobj_loss: 0.1205  bbox_loss: 0.0094  cls_loss: 0.0220  \n",
      "<<<iteration:[360/657] - total_loss: 0.3141  obj_loss: 0.1829  noobj_loss: 0.1277  bbox_loss: 0.0089  cls_loss: 0.0227  \n",
      "<<<iteration:[380/657] - total_loss: 0.3111  obj_loss: 0.1838  noobj_loss: 0.1200  bbox_loss: 0.0085  cls_loss: 0.0250  \n",
      "<<<iteration:[400/657] - total_loss: 0.3250  obj_loss: 0.1884  noobj_loss: 0.1228  bbox_loss: 0.0096  cls_loss: 0.0270  \n",
      "<<<iteration:[420/657] - total_loss: 0.3113  obj_loss: 0.1640  noobj_loss: 0.1272  bbox_loss: 0.0103  cls_loss: 0.0324  \n",
      "<<<iteration:[440/657] - total_loss: 0.3237  obj_loss: 0.1915  noobj_loss: 0.1194  bbox_loss: 0.0097  cls_loss: 0.0241  \n",
      "<<<iteration:[460/657] - total_loss: 0.3156  obj_loss: 0.1809  noobj_loss: 0.1238  bbox_loss: 0.0097  cls_loss: 0.0240  \n",
      "<<<iteration:[480/657] - total_loss: 0.3084  obj_loss: 0.1772  noobj_loss: 0.1202  bbox_loss: 0.0093  cls_loss: 0.0246  \n",
      "<<<iteration:[500/657] - total_loss: 0.3143  obj_loss: 0.1795  noobj_loss: 0.1217  bbox_loss: 0.0087  cls_loss: 0.0304  \n",
      "<<<iteration:[520/657] - total_loss: 0.3332  obj_loss: 0.1968  noobj_loss: 0.1245  bbox_loss: 0.0093  cls_loss: 0.0275  \n",
      "<<<iteration:[540/657] - total_loss: 0.3282  obj_loss: 0.1959  noobj_loss: 0.1216  bbox_loss: 0.0094  cls_loss: 0.0243  \n",
      "<<<iteration:[560/657] - total_loss: 0.3096  obj_loss: 0.1807  noobj_loss: 0.1257  bbox_loss: 0.0089  cls_loss: 0.0215  \n",
      "<<<iteration:[580/657] - total_loss: 0.3086  obj_loss: 0.1803  noobj_loss: 0.1185  bbox_loss: 0.0094  cls_loss: 0.0221  \n",
      "<<<iteration:[600/657] - total_loss: 0.3168  obj_loss: 0.1893  noobj_loss: 0.1262  bbox_loss: 0.0085  cls_loss: 0.0220  \n",
      "<<<iteration:[620/657] - total_loss: 0.3020  obj_loss: 0.1718  noobj_loss: 0.1297  bbox_loss: 0.0087  cls_loss: 0.0220  \n",
      "<<<iteration:[640/657] - total_loss: 0.3065  obj_loss: 0.1886  noobj_loss: 0.1172  bbox_loss: 0.0087  cls_loss: 0.0158  \n",
      "\n",
      "epoch:25/100 - Train Loss: 0.3136, Val Loss: 0.3218\n",
      "\n",
      "<<<iteration:[20/657] - total_loss: 0.3246  obj_loss: 0.1904  noobj_loss: 0.1249  bbox_loss: 0.0098  cls_loss: 0.0226  \n",
      "<<<iteration:[40/657] - total_loss: 0.3229  obj_loss: 0.1898  noobj_loss: 0.1219  bbox_loss: 0.0091  cls_loss: 0.0267  \n",
      "<<<iteration:[60/657] - total_loss: 0.3061  obj_loss: 0.1734  noobj_loss: 0.1205  bbox_loss: 0.0096  cls_loss: 0.0246  \n",
      "<<<iteration:[80/657] - total_loss: 0.3101  obj_loss: 0.1775  noobj_loss: 0.1216  bbox_loss: 0.0092  cls_loss: 0.0258  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<<<iteration:[100/657] - total_loss: 0.2992  obj_loss: 0.1789  noobj_loss: 0.1155  bbox_loss: 0.0085  cls_loss: 0.0203  \n",
      "<<<iteration:[120/657] - total_loss: 0.3120  obj_loss: 0.1866  noobj_loss: 0.1226  bbox_loss: 0.0084  cls_loss: 0.0222  \n",
      "<<<iteration:[140/657] - total_loss: 0.3205  obj_loss: 0.1840  noobj_loss: 0.1283  bbox_loss: 0.0098  cls_loss: 0.0234  \n",
      "<<<iteration:[160/657] - total_loss: 0.3183  obj_loss: 0.1879  noobj_loss: 0.1221  bbox_loss: 0.0090  cls_loss: 0.0246  \n",
      "<<<iteration:[180/657] - total_loss: 0.3115  obj_loss: 0.1863  noobj_loss: 0.1274  bbox_loss: 0.0086  cls_loss: 0.0185  \n",
      "<<<iteration:[200/657] - total_loss: 0.3161  obj_loss: 0.1825  noobj_loss: 0.1214  bbox_loss: 0.0100  cls_loss: 0.0227  \n",
      "<<<iteration:[220/657] - total_loss: 0.3073  obj_loss: 0.1718  noobj_loss: 0.1230  bbox_loss: 0.0090  cls_loss: 0.0292  \n",
      "<<<iteration:[240/657] - total_loss: 0.3363  obj_loss: 0.2078  noobj_loss: 0.1191  bbox_loss: 0.0093  cls_loss: 0.0227  \n",
      "<<<iteration:[260/657] - total_loss: 0.3295  obj_loss: 0.1822  noobj_loss: 0.1327  bbox_loss: 0.0098  cls_loss: 0.0319  \n",
      "<<<iteration:[280/657] - total_loss: 0.3257  obj_loss: 0.1925  noobj_loss: 0.1195  bbox_loss: 0.0087  cls_loss: 0.0299  \n",
      "<<<iteration:[300/657] - total_loss: 0.3091  obj_loss: 0.1739  noobj_loss: 0.1240  bbox_loss: 0.0099  cls_loss: 0.0239  \n",
      "<<<iteration:[320/657] - total_loss: 0.3128  obj_loss: 0.1850  noobj_loss: 0.1215  bbox_loss: 0.0081  cls_loss: 0.0267  \n",
      "<<<iteration:[340/657] - total_loss: 0.3128  obj_loss: 0.1762  noobj_loss: 0.1218  bbox_loss: 0.0096  cls_loss: 0.0279  \n",
      "<<<iteration:[360/657] - total_loss: 0.3092  obj_loss: 0.1827  noobj_loss: 0.1210  bbox_loss: 0.0090  cls_loss: 0.0212  \n",
      "<<<iteration:[380/657] - total_loss: 0.3084  obj_loss: 0.1790  noobj_loss: 0.1258  bbox_loss: 0.0092  cls_loss: 0.0203  \n",
      "<<<iteration:[400/657] - total_loss: 0.3182  obj_loss: 0.1888  noobj_loss: 0.1255  bbox_loss: 0.0088  cls_loss: 0.0226  \n",
      "<<<iteration:[420/657] - total_loss: 0.3120  obj_loss: 0.1783  noobj_loss: 0.1246  bbox_loss: 0.0097  cls_loss: 0.0230  \n",
      "<<<iteration:[440/657] - total_loss: 0.3062  obj_loss: 0.1756  noobj_loss: 0.1296  bbox_loss: 0.0093  cls_loss: 0.0195  \n",
      "<<<iteration:[460/657] - total_loss: 0.3115  obj_loss: 0.1763  noobj_loss: 0.1272  bbox_loss: 0.0094  cls_loss: 0.0246  \n",
      "<<<iteration:[480/657] - total_loss: 0.3207  obj_loss: 0.1888  noobj_loss: 0.1225  bbox_loss: 0.0092  cls_loss: 0.0245  \n",
      "<<<iteration:[500/657] - total_loss: 0.3162  obj_loss: 0.1823  noobj_loss: 0.1219  bbox_loss: 0.0089  cls_loss: 0.0284  \n",
      "<<<iteration:[520/657] - total_loss: 0.3111  obj_loss: 0.1857  noobj_loss: 0.1224  bbox_loss: 0.0084  cls_loss: 0.0220  \n",
      "<<<iteration:[540/657] - total_loss: 0.3090  obj_loss: 0.1793  noobj_loss: 0.1216  bbox_loss: 0.0088  cls_loss: 0.0249  \n",
      "<<<iteration:[560/657] - total_loss: 0.3047  obj_loss: 0.1791  noobj_loss: 0.1231  bbox_loss: 0.0089  cls_loss: 0.0197  \n",
      "<<<iteration:[580/657] - total_loss: 0.3093  obj_loss: 0.1837  noobj_loss: 0.1211  bbox_loss: 0.0090  cls_loss: 0.0199  \n",
      "<<<iteration:[600/657] - total_loss: 0.3095  obj_loss: 0.1770  noobj_loss: 0.1245  bbox_loss: 0.0095  cls_loss: 0.0227  \n",
      "<<<iteration:[620/657] - total_loss: 0.3274  obj_loss: 0.1944  noobj_loss: 0.1233  bbox_loss: 0.0103  cls_loss: 0.0199  \n",
      "<<<iteration:[640/657] - total_loss: 0.2971  obj_loss: 0.1736  noobj_loss: 0.1221  bbox_loss: 0.0092  cls_loss: 0.0166  \n",
      "\n",
      "epoch:26/100 - Train Loss: 0.3139, Val Loss: 0.3207\n",
      "\n",
      "<<<iteration:[20/657] - total_loss: 0.3363  obj_loss: 0.1932  noobj_loss: 0.1309  bbox_loss: 0.0098  cls_loss: 0.0285  \n",
      "<<<iteration:[40/657] - total_loss: 0.3290  obj_loss: 0.1895  noobj_loss: 0.1242  bbox_loss: 0.0103  cls_loss: 0.0259  \n",
      "<<<iteration:[60/657] - total_loss: 0.3159  obj_loss: 0.1844  noobj_loss: 0.1199  bbox_loss: 0.0091  cls_loss: 0.0262  \n",
      "<<<iteration:[80/657] - total_loss: 0.3171  obj_loss: 0.1923  noobj_loss: 0.1202  bbox_loss: 0.0083  cls_loss: 0.0234  \n",
      "<<<iteration:[100/657] - total_loss: 0.3275  obj_loss: 0.1885  noobj_loss: 0.1262  bbox_loss: 0.0090  cls_loss: 0.0308  \n",
      "<<<iteration:[120/657] - total_loss: 0.3034  obj_loss: 0.1728  noobj_loss: 0.1237  bbox_loss: 0.0091  cls_loss: 0.0230  \n",
      "<<<iteration:[140/657] - total_loss: 0.3111  obj_loss: 0.1806  noobj_loss: 0.1219  bbox_loss: 0.0096  cls_loss: 0.0214  \n",
      "<<<iteration:[160/657] - total_loss: 0.3103  obj_loss: 0.1796  noobj_loss: 0.1234  bbox_loss: 0.0092  cls_loss: 0.0231  \n",
      "<<<iteration:[180/657] - total_loss: 0.3006  obj_loss: 0.1655  noobj_loss: 0.1269  bbox_loss: 0.0100  cls_loss: 0.0217  \n",
      "<<<iteration:[200/657] - total_loss: 0.3171  obj_loss: 0.1829  noobj_loss: 0.1203  bbox_loss: 0.0097  cls_loss: 0.0252  \n",
      "<<<iteration:[220/657] - total_loss: 0.3257  obj_loss: 0.1952  noobj_loss: 0.1238  bbox_loss: 0.0095  cls_loss: 0.0213  \n",
      "<<<iteration:[240/657] - total_loss: 0.3178  obj_loss: 0.1815  noobj_loss: 0.1288  bbox_loss: 0.0084  cls_loss: 0.0300  \n",
      "<<<iteration:[260/657] - total_loss: 0.3072  obj_loss: 0.1812  noobj_loss: 0.1252  bbox_loss: 0.0085  cls_loss: 0.0208  \n",
      "<<<iteration:[280/657] - total_loss: 0.3044  obj_loss: 0.1833  noobj_loss: 0.1155  bbox_loss: 0.0085  cls_loss: 0.0208  \n",
      "<<<iteration:[300/657] - total_loss: 0.3253  obj_loss: 0.1848  noobj_loss: 0.1339  bbox_loss: 0.0094  cls_loss: 0.0265  \n",
      "<<<iteration:[320/657] - total_loss: 0.3072  obj_loss: 0.1802  noobj_loss: 0.1228  bbox_loss: 0.0087  cls_loss: 0.0222  \n",
      "<<<iteration:[340/657] - total_loss: 0.3098  obj_loss: 0.1780  noobj_loss: 0.1255  bbox_loss: 0.0093  cls_loss: 0.0223  \n",
      "<<<iteration:[360/657] - total_loss: 0.3121  obj_loss: 0.1860  noobj_loss: 0.1263  bbox_loss: 0.0086  cls_loss: 0.0201  \n",
      "<<<iteration:[380/657] - total_loss: 0.3045  obj_loss: 0.1797  noobj_loss: 0.1210  bbox_loss: 0.0087  cls_loss: 0.0209  \n",
      "<<<iteration:[400/657] - total_loss: 0.3103  obj_loss: 0.1829  noobj_loss: 0.1279  bbox_loss: 0.0085  cls_loss: 0.0210  \n",
      "<<<iteration:[420/657] - total_loss: 0.3255  obj_loss: 0.1972  noobj_loss: 0.1326  bbox_loss: 0.0082  cls_loss: 0.0210  \n",
      "<<<iteration:[440/657] - total_loss: 0.3073  obj_loss: 0.1741  noobj_loss: 0.1301  bbox_loss: 0.0093  cls_loss: 0.0218  \n",
      "<<<iteration:[460/657] - total_loss: 0.3123  obj_loss: 0.1827  noobj_loss: 0.1270  bbox_loss: 0.0083  cls_loss: 0.0245  \n",
      "<<<iteration:[480/657] - total_loss: 0.3083  obj_loss: 0.1844  noobj_loss: 0.1242  bbox_loss: 0.0085  cls_loss: 0.0194  \n",
      "<<<iteration:[500/657] - total_loss: 0.3181  obj_loss: 0.1835  noobj_loss: 0.1248  bbox_loss: 0.0097  cls_loss: 0.0236  \n",
      "<<<iteration:[520/657] - total_loss: 0.3140  obj_loss: 0.1827  noobj_loss: 0.1225  bbox_loss: 0.0098  cls_loss: 0.0209  \n",
      "<<<iteration:[540/657] - total_loss: 0.3010  obj_loss: 0.1719  noobj_loss: 0.1260  bbox_loss: 0.0082  cls_loss: 0.0250  \n",
      "<<<iteration:[560/657] - total_loss: 0.2953  obj_loss: 0.1716  noobj_loss: 0.1198  bbox_loss: 0.0089  cls_loss: 0.0194  \n",
      "<<<iteration:[580/657] - total_loss: 0.3093  obj_loss: 0.1711  noobj_loss: 0.1289  bbox_loss: 0.0099  cls_loss: 0.0242  \n",
      "<<<iteration:[600/657] - total_loss: 0.3249  obj_loss: 0.1995  noobj_loss: 0.1256  bbox_loss: 0.0085  cls_loss: 0.0202  \n",
      "<<<iteration:[620/657] - total_loss: 0.3124  obj_loss: 0.1854  noobj_loss: 0.1282  bbox_loss: 0.0080  cls_loss: 0.0226  \n",
      "<<<iteration:[640/657] - total_loss: 0.3226  obj_loss: 0.1861  noobj_loss: 0.1269  bbox_loss: 0.0099  cls_loss: 0.0236  \n",
      "\n",
      "epoch:27/100 - Train Loss: 0.3136, Val Loss: 0.3254\n",
      "\n",
      "<<<iteration:[20/657] - total_loss: 0.3211  obj_loss: 0.1911  noobj_loss: 0.1311  bbox_loss: 0.0089  cls_loss: 0.0198  \n",
      "<<<iteration:[40/657] - total_loss: 0.3159  obj_loss: 0.1801  noobj_loss: 0.1270  bbox_loss: 0.0093  cls_loss: 0.0257  \n",
      "<<<iteration:[60/657] - total_loss: 0.3125  obj_loss: 0.1805  noobj_loss: 0.1268  bbox_loss: 0.0093  cls_loss: 0.0219  \n",
      "<<<iteration:[80/657] - total_loss: 0.3216  obj_loss: 0.1929  noobj_loss: 0.1214  bbox_loss: 0.0090  cls_loss: 0.0230  \n",
      "<<<iteration:[100/657] - total_loss: 0.3095  obj_loss: 0.1789  noobj_loss: 0.1294  bbox_loss: 0.0082  cls_loss: 0.0249  \n",
      "<<<iteration:[120/657] - total_loss: 0.3219  obj_loss: 0.1849  noobj_loss: 0.1218  bbox_loss: 0.0101  cls_loss: 0.0255  \n",
      "<<<iteration:[140/657] - total_loss: 0.3186  obj_loss: 0.1861  noobj_loss: 0.1320  bbox_loss: 0.0096  cls_loss: 0.0187  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<<<iteration:[160/657] - total_loss: 0.3216  obj_loss: 0.1905  noobj_loss: 0.1287  bbox_loss: 0.0092  cls_loss: 0.0206  \n",
      "<<<iteration:[180/657] - total_loss: 0.3058  obj_loss: 0.1824  noobj_loss: 0.1242  bbox_loss: 0.0086  cls_loss: 0.0185  \n",
      "<<<iteration:[200/657] - total_loss: 0.3249  obj_loss: 0.1982  noobj_loss: 0.1283  bbox_loss: 0.0089  cls_loss: 0.0182  \n",
      "<<<iteration:[220/657] - total_loss: 0.3064  obj_loss: 0.1735  noobj_loss: 0.1332  bbox_loss: 0.0087  cls_loss: 0.0229  \n",
      "<<<iteration:[240/657] - total_loss: 0.3235  obj_loss: 0.1936  noobj_loss: 0.1256  bbox_loss: 0.0091  cls_loss: 0.0214  \n",
      "<<<iteration:[260/657] - total_loss: 0.3075  obj_loss: 0.1706  noobj_loss: 0.1272  bbox_loss: 0.0097  cls_loss: 0.0248  \n",
      "<<<iteration:[280/657] - total_loss: 0.3023  obj_loss: 0.1731  noobj_loss: 0.1298  bbox_loss: 0.0087  cls_loss: 0.0208  \n",
      "<<<iteration:[300/657] - total_loss: 0.3257  obj_loss: 0.1879  noobj_loss: 0.1350  bbox_loss: 0.0084  cls_loss: 0.0284  \n",
      "<<<iteration:[320/657] - total_loss: 0.3301  obj_loss: 0.1956  noobj_loss: 0.1291  bbox_loss: 0.0087  cls_loss: 0.0265  \n",
      "<<<iteration:[340/657] - total_loss: 0.3102  obj_loss: 0.1832  noobj_loss: 0.1311  bbox_loss: 0.0082  cls_loss: 0.0203  \n",
      "<<<iteration:[360/657] - total_loss: 0.3111  obj_loss: 0.1681  noobj_loss: 0.1318  bbox_loss: 0.0109  cls_loss: 0.0226  \n",
      "<<<iteration:[380/657] - total_loss: 0.3123  obj_loss: 0.1808  noobj_loss: 0.1288  bbox_loss: 0.0094  cls_loss: 0.0203  \n",
      "<<<iteration:[400/657] - total_loss: 0.3023  obj_loss: 0.1808  noobj_loss: 0.1237  bbox_loss: 0.0084  cls_loss: 0.0177  \n",
      "<<<iteration:[420/657] - total_loss: 0.3077  obj_loss: 0.1738  noobj_loss: 0.1283  bbox_loss: 0.0088  cls_loss: 0.0255  \n",
      "<<<iteration:[440/657] - total_loss: 0.3311  obj_loss: 0.1912  noobj_loss: 0.1259  bbox_loss: 0.0098  cls_loss: 0.0278  \n",
      "<<<iteration:[460/657] - total_loss: 0.3193  obj_loss: 0.1859  noobj_loss: 0.1312  bbox_loss: 0.0088  cls_loss: 0.0239  \n",
      "<<<iteration:[480/657] - total_loss: 0.3043  obj_loss: 0.1780  noobj_loss: 0.1298  bbox_loss: 0.0086  cls_loss: 0.0184  \n",
      "<<<iteration:[500/657] - total_loss: 0.3100  obj_loss: 0.1867  noobj_loss: 0.1297  bbox_loss: 0.0080  cls_loss: 0.0186  \n",
      "<<<iteration:[520/657] - total_loss: 0.3073  obj_loss: 0.1816  noobj_loss: 0.1225  bbox_loss: 0.0097  cls_loss: 0.0159  \n",
      "<<<iteration:[540/657] - total_loss: 0.2970  obj_loss: 0.1678  noobj_loss: 0.1231  bbox_loss: 0.0093  cls_loss: 0.0211  \n",
      "<<<iteration:[560/657] - total_loss: 0.2964  obj_loss: 0.1693  noobj_loss: 0.1258  bbox_loss: 0.0092  cls_loss: 0.0182  \n",
      "<<<iteration:[580/657] - total_loss: 0.3080  obj_loss: 0.1760  noobj_loss: 0.1169  bbox_loss: 0.0099  cls_loss: 0.0241  \n",
      "<<<iteration:[600/657] - total_loss: 0.3318  obj_loss: 0.2013  noobj_loss: 0.1272  bbox_loss: 0.0088  cls_loss: 0.0229  \n",
      "<<<iteration:[620/657] - total_loss: 0.3156  obj_loss: 0.1765  noobj_loss: 0.1286  bbox_loss: 0.0090  cls_loss: 0.0298  \n",
      "<<<iteration:[640/657] - total_loss: 0.2987  obj_loss: 0.1738  noobj_loss: 0.1254  bbox_loss: 0.0086  cls_loss: 0.0195  \n",
      "\n",
      "epoch:28/100 - Train Loss: 0.3132, Val Loss: 0.3216\n",
      "\n",
      "<<<iteration:[20/657] - total_loss: 0.3291  obj_loss: 0.1881  noobj_loss: 0.1276  bbox_loss: 0.0100  cls_loss: 0.0272  \n",
      "<<<iteration:[40/657] - total_loss: 0.3175  obj_loss: 0.1776  noobj_loss: 0.1262  bbox_loss: 0.0121  cls_loss: 0.0162  \n",
      "<<<iteration:[60/657] - total_loss: 0.3148  obj_loss: 0.1915  noobj_loss: 0.1288  bbox_loss: 0.0080  cls_loss: 0.0189  \n",
      "<<<iteration:[80/657] - total_loss: 0.3007  obj_loss: 0.1745  noobj_loss: 0.1301  bbox_loss: 0.0084  cls_loss: 0.0190  \n",
      "<<<iteration:[100/657] - total_loss: 0.3144  obj_loss: 0.1762  noobj_loss: 0.1259  bbox_loss: 0.0097  cls_loss: 0.0267  \n",
      "<<<iteration:[120/657] - total_loss: 0.3136  obj_loss: 0.1846  noobj_loss: 0.1290  bbox_loss: 0.0087  cls_loss: 0.0211  \n",
      "<<<iteration:[140/657] - total_loss: 0.2924  obj_loss: 0.1663  noobj_loss: 0.1262  bbox_loss: 0.0082  cls_loss: 0.0218  \n",
      "<<<iteration:[160/657] - total_loss: 0.3023  obj_loss: 0.1758  noobj_loss: 0.1300  bbox_loss: 0.0094  cls_loss: 0.0147  \n",
      "<<<iteration:[180/657] - total_loss: 0.3111  obj_loss: 0.1858  noobj_loss: 0.1243  bbox_loss: 0.0085  cls_loss: 0.0208  \n",
      "<<<iteration:[200/657] - total_loss: 0.2877  obj_loss: 0.1671  noobj_loss: 0.1260  bbox_loss: 0.0082  cls_loss: 0.0166  \n",
      "<<<iteration:[220/657] - total_loss: 0.3043  obj_loss: 0.1768  noobj_loss: 0.1228  bbox_loss: 0.0090  cls_loss: 0.0211  \n",
      "<<<iteration:[240/657] - total_loss: 0.3279  obj_loss: 0.1889  noobj_loss: 0.1346  bbox_loss: 0.0095  cls_loss: 0.0244  \n",
      "<<<iteration:[260/657] - total_loss: 0.3249  obj_loss: 0.1813  noobj_loss: 0.1370  bbox_loss: 0.0098  cls_loss: 0.0261  \n",
      "<<<iteration:[280/657] - total_loss: 0.3094  obj_loss: 0.1824  noobj_loss: 0.1325  bbox_loss: 0.0085  cls_loss: 0.0179  \n",
      "<<<iteration:[300/657] - total_loss: 0.3061  obj_loss: 0.1791  noobj_loss: 0.1204  bbox_loss: 0.0087  cls_loss: 0.0233  \n",
      "<<<iteration:[320/657] - total_loss: 0.3072  obj_loss: 0.1770  noobj_loss: 0.1340  bbox_loss: 0.0087  cls_loss: 0.0197  \n",
      "<<<iteration:[340/657] - total_loss: 0.3013  obj_loss: 0.1759  noobj_loss: 0.1336  bbox_loss: 0.0079  cls_loss: 0.0190  \n",
      "<<<iteration:[360/657] - total_loss: 0.3052  obj_loss: 0.1787  noobj_loss: 0.1312  bbox_loss: 0.0083  cls_loss: 0.0194  \n",
      "<<<iteration:[380/657] - total_loss: 0.2966  obj_loss: 0.1627  noobj_loss: 0.1230  bbox_loss: 0.0091  cls_loss: 0.0271  \n",
      "<<<iteration:[400/657] - total_loss: 0.3034  obj_loss: 0.1768  noobj_loss: 0.1247  bbox_loss: 0.0091  cls_loss: 0.0185  \n",
      "<<<iteration:[420/657] - total_loss: 0.3039  obj_loss: 0.1768  noobj_loss: 0.1302  bbox_loss: 0.0083  cls_loss: 0.0204  \n",
      "<<<iteration:[440/657] - total_loss: 0.3316  obj_loss: 0.1946  noobj_loss: 0.1297  bbox_loss: 0.0096  cls_loss: 0.0239  \n",
      "<<<iteration:[460/657] - total_loss: 0.3223  obj_loss: 0.1912  noobj_loss: 0.1280  bbox_loss: 0.0080  cls_loss: 0.0273  \n",
      "<<<iteration:[480/657] - total_loss: 0.3034  obj_loss: 0.1754  noobj_loss: 0.1281  bbox_loss: 0.0084  cls_loss: 0.0219  \n",
      "<<<iteration:[500/657] - total_loss: 0.3041  obj_loss: 0.1819  noobj_loss: 0.1238  bbox_loss: 0.0087  cls_loss: 0.0169  \n",
      "<<<iteration:[520/657] - total_loss: 0.3022  obj_loss: 0.1713  noobj_loss: 0.1323  bbox_loss: 0.0092  cls_loss: 0.0185  \n",
      "<<<iteration:[540/657] - total_loss: 0.3027  obj_loss: 0.1749  noobj_loss: 0.1300  bbox_loss: 0.0086  cls_loss: 0.0199  \n",
      "<<<iteration:[560/657] - total_loss: 0.3210  obj_loss: 0.1848  noobj_loss: 0.1291  bbox_loss: 0.0093  cls_loss: 0.0252  \n",
      "<<<iteration:[580/657] - total_loss: 0.3106  obj_loss: 0.1860  noobj_loss: 0.1295  bbox_loss: 0.0076  cls_loss: 0.0218  \n",
      "<<<iteration:[600/657] - total_loss: 0.3095  obj_loss: 0.1824  noobj_loss: 0.1308  bbox_loss: 0.0085  cls_loss: 0.0191  \n",
      "<<<iteration:[620/657] - total_loss: 0.3295  obj_loss: 0.1870  noobj_loss: 0.1283  bbox_loss: 0.0113  cls_loss: 0.0220  \n",
      "<<<iteration:[640/657] - total_loss: 0.3263  obj_loss: 0.1959  noobj_loss: 0.1282  bbox_loss: 0.0087  cls_loss: 0.0225  \n",
      "\n",
      "epoch:29/100 - Train Loss: 0.3103, Val Loss: 0.3204\n",
      "\n",
      "<<<iteration:[20/657] - total_loss: 0.3391  obj_loss: 0.2028  noobj_loss: 0.1371  bbox_loss: 0.0086  cls_loss: 0.0245  \n",
      "<<<iteration:[40/657] - total_loss: 0.3189  obj_loss: 0.1923  noobj_loss: 0.1348  bbox_loss: 0.0082  cls_loss: 0.0180  \n",
      "<<<iteration:[60/657] - total_loss: 0.3198  obj_loss: 0.2005  noobj_loss: 0.1247  bbox_loss: 0.0078  cls_loss: 0.0177  \n",
      "<<<iteration:[80/657] - total_loss: 0.3060  obj_loss: 0.1777  noobj_loss: 0.1300  bbox_loss: 0.0085  cls_loss: 0.0206  \n",
      "<<<iteration:[100/657] - total_loss: 0.3066  obj_loss: 0.1747  noobj_loss: 0.1371  bbox_loss: 0.0089  cls_loss: 0.0190  \n",
      "<<<iteration:[120/657] - total_loss: 0.3043  obj_loss: 0.1853  noobj_loss: 0.1235  bbox_loss: 0.0083  cls_loss: 0.0159  \n",
      "<<<iteration:[140/657] - total_loss: 0.3024  obj_loss: 0.1770  noobj_loss: 0.1321  bbox_loss: 0.0083  cls_loss: 0.0181  \n",
      "<<<iteration:[160/657] - total_loss: 0.3149  obj_loss: 0.1922  noobj_loss: 0.1326  bbox_loss: 0.0079  cls_loss: 0.0169  \n",
      "<<<iteration:[180/657] - total_loss: 0.3232  obj_loss: 0.1809  noobj_loss: 0.1349  bbox_loss: 0.0100  cls_loss: 0.0250  \n",
      "<<<iteration:[200/657] - total_loss: 0.3148  obj_loss: 0.1953  noobj_loss: 0.1285  bbox_loss: 0.0078  cls_loss: 0.0160  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<<<iteration:[220/657] - total_loss: 0.3132  obj_loss: 0.1815  noobj_loss: 0.1312  bbox_loss: 0.0084  cls_loss: 0.0240  \n",
      "<<<iteration:[240/657] - total_loss: 0.3171  obj_loss: 0.1940  noobj_loss: 0.1309  bbox_loss: 0.0082  cls_loss: 0.0166  \n",
      "<<<iteration:[260/657] - total_loss: 0.3084  obj_loss: 0.1848  noobj_loss: 0.1312  bbox_loss: 0.0075  cls_loss: 0.0203  \n",
      "<<<iteration:[280/657] - total_loss: 0.3206  obj_loss: 0.1858  noobj_loss: 0.1330  bbox_loss: 0.0092  cls_loss: 0.0221  \n",
      "<<<iteration:[300/657] - total_loss: 0.3090  obj_loss: 0.1834  noobj_loss: 0.1266  bbox_loss: 0.0086  cls_loss: 0.0193  \n",
      "<<<iteration:[320/657] - total_loss: 0.3259  obj_loss: 0.2023  noobj_loss: 0.1320  bbox_loss: 0.0078  cls_loss: 0.0188  \n",
      "<<<iteration:[340/657] - total_loss: 0.3141  obj_loss: 0.1728  noobj_loss: 0.1321  bbox_loss: 0.0114  cls_loss: 0.0185  \n",
      "<<<iteration:[360/657] - total_loss: 0.3118  obj_loss: 0.1798  noobj_loss: 0.1305  bbox_loss: 0.0086  cls_loss: 0.0238  \n",
      "<<<iteration:[380/657] - total_loss: 0.3250  obj_loss: 0.1922  noobj_loss: 0.1315  bbox_loss: 0.0077  cls_loss: 0.0284  \n",
      "<<<iteration:[400/657] - total_loss: 0.3118  obj_loss: 0.1831  noobj_loss: 0.1334  bbox_loss: 0.0085  cls_loss: 0.0194  \n",
      "<<<iteration:[420/657] - total_loss: 0.3131  obj_loss: 0.1848  noobj_loss: 0.1308  bbox_loss: 0.0088  cls_loss: 0.0187  \n",
      "<<<iteration:[440/657] - total_loss: 0.3173  obj_loss: 0.1944  noobj_loss: 0.1317  bbox_loss: 0.0073  cls_loss: 0.0207  \n",
      "<<<iteration:[460/657] - total_loss: 0.2997  obj_loss: 0.1729  noobj_loss: 0.1321  bbox_loss: 0.0087  cls_loss: 0.0171  \n",
      "<<<iteration:[480/657] - total_loss: 0.2997  obj_loss: 0.1690  noobj_loss: 0.1338  bbox_loss: 0.0093  cls_loss: 0.0172  \n",
      "<<<iteration:[500/657] - total_loss: 0.3248  obj_loss: 0.1902  noobj_loss: 0.1324  bbox_loss: 0.0084  cls_loss: 0.0263  \n",
      "<<<iteration:[520/657] - total_loss: 0.3134  obj_loss: 0.1771  noobj_loss: 0.1290  bbox_loss: 0.0091  cls_loss: 0.0263  \n",
      "<<<iteration:[540/657] - total_loss: 0.3095  obj_loss: 0.1777  noobj_loss: 0.1349  bbox_loss: 0.0095  cls_loss: 0.0172  \n",
      "<<<iteration:[560/657] - total_loss: 0.3128  obj_loss: 0.1860  noobj_loss: 0.1292  bbox_loss: 0.0088  cls_loss: 0.0181  \n",
      "<<<iteration:[580/657] - total_loss: 0.2932  obj_loss: 0.1599  noobj_loss: 0.1321  bbox_loss: 0.0082  cls_loss: 0.0261  \n",
      "<<<iteration:[600/657] - total_loss: 0.3115  obj_loss: 0.1809  noobj_loss: 0.1332  bbox_loss: 0.0091  cls_loss: 0.0183  \n",
      "<<<iteration:[620/657] - total_loss: 0.3166  obj_loss: 0.1862  noobj_loss: 0.1320  bbox_loss: 0.0094  cls_loss: 0.0176  \n",
      "<<<iteration:[640/657] - total_loss: 0.3315  obj_loss: 0.1999  noobj_loss: 0.1366  bbox_loss: 0.0088  cls_loss: 0.0191  \n",
      "\n",
      "epoch:30/100 - Train Loss: 0.3132, Val Loss: 0.3226\n",
      "\n",
      "<<<iteration:[20/657] - total_loss: 0.3249  obj_loss: 0.1935  noobj_loss: 0.1338  bbox_loss: 0.0083  cls_loss: 0.0230  \n",
      "<<<iteration:[40/657] - total_loss: 0.3209  obj_loss: 0.1914  noobj_loss: 0.1364  bbox_loss: 0.0086  cls_loss: 0.0184  \n",
      "<<<iteration:[60/657] - total_loss: 0.2981  obj_loss: 0.1634  noobj_loss: 0.1363  bbox_loss: 0.0092  cls_loss: 0.0203  \n",
      "<<<iteration:[80/657] - total_loss: 0.3122  obj_loss: 0.1848  noobj_loss: 0.1340  bbox_loss: 0.0075  cls_loss: 0.0227  \n",
      "<<<iteration:[100/657] - total_loss: 0.3175  obj_loss: 0.1854  noobj_loss: 0.1307  bbox_loss: 0.0092  cls_loss: 0.0206  \n",
      "<<<iteration:[120/657] - total_loss: 0.3101  obj_loss: 0.1819  noobj_loss: 0.1374  bbox_loss: 0.0074  cls_loss: 0.0226  \n",
      "<<<iteration:[140/657] - total_loss: 0.3133  obj_loss: 0.1912  noobj_loss: 0.1301  bbox_loss: 0.0078  cls_loss: 0.0180  \n",
      "<<<iteration:[160/657] - total_loss: 0.3163  obj_loss: 0.1801  noobj_loss: 0.1287  bbox_loss: 0.0094  cls_loss: 0.0248  \n",
      "<<<iteration:[180/657] - total_loss: 0.3121  obj_loss: 0.1881  noobj_loss: 0.1333  bbox_loss: 0.0076  cls_loss: 0.0194  \n",
      "<<<iteration:[200/657] - total_loss: 0.3104  obj_loss: 0.1825  noobj_loss: 0.1295  bbox_loss: 0.0082  cls_loss: 0.0220  \n",
      "<<<iteration:[220/657] - total_loss: 0.3197  obj_loss: 0.1873  noobj_loss: 0.1323  bbox_loss: 0.0093  cls_loss: 0.0197  \n",
      "<<<iteration:[240/657] - total_loss: 0.2911  obj_loss: 0.1632  noobj_loss: 0.1277  bbox_loss: 0.0082  cls_loss: 0.0231  \n",
      "<<<iteration:[260/657] - total_loss: 0.3072  obj_loss: 0.1850  noobj_loss: 0.1283  bbox_loss: 0.0083  cls_loss: 0.0164  \n",
      "<<<iteration:[280/657] - total_loss: 0.3002  obj_loss: 0.1743  noobj_loss: 0.1306  bbox_loss: 0.0089  cls_loss: 0.0164  \n",
      "<<<iteration:[300/657] - total_loss: 0.3012  obj_loss: 0.1743  noobj_loss: 0.1309  bbox_loss: 0.0080  cls_loss: 0.0215  \n",
      "<<<iteration:[320/657] - total_loss: 0.2851  obj_loss: 0.1661  noobj_loss: 0.1266  bbox_loss: 0.0073  cls_loss: 0.0189  \n",
      "<<<iteration:[340/657] - total_loss: 0.3307  obj_loss: 0.1935  noobj_loss: 0.1355  bbox_loss: 0.0086  cls_loss: 0.0262  \n",
      "<<<iteration:[360/657] - total_loss: 0.3290  obj_loss: 0.1956  noobj_loss: 0.1352  bbox_loss: 0.0084  cls_loss: 0.0236  \n",
      "<<<iteration:[380/657] - total_loss: 0.3095  obj_loss: 0.1812  noobj_loss: 0.1295  bbox_loss: 0.0086  cls_loss: 0.0205  \n",
      "<<<iteration:[400/657] - total_loss: 0.3128  obj_loss: 0.1855  noobj_loss: 0.1347  bbox_loss: 0.0081  cls_loss: 0.0194  \n",
      "<<<iteration:[420/657] - total_loss: 0.3231  obj_loss: 0.1842  noobj_loss: 0.1381  bbox_loss: 0.0101  cls_loss: 0.0195  \n",
      "<<<iteration:[440/657] - total_loss: 0.3154  obj_loss: 0.1832  noobj_loss: 0.1332  bbox_loss: 0.0084  cls_loss: 0.0233  \n",
      "<<<iteration:[460/657] - total_loss: 0.3170  obj_loss: 0.1871  noobj_loss: 0.1332  bbox_loss: 0.0083  cls_loss: 0.0220  \n",
      "<<<iteration:[480/657] - total_loss: 0.3061  obj_loss: 0.1841  noobj_loss: 0.1329  bbox_loss: 0.0082  cls_loss: 0.0144  \n",
      "<<<iteration:[500/657] - total_loss: 0.3038  obj_loss: 0.1760  noobj_loss: 0.1351  bbox_loss: 0.0083  cls_loss: 0.0189  \n",
      "<<<iteration:[520/657] - total_loss: 0.3224  obj_loss: 0.1948  noobj_loss: 0.1270  bbox_loss: 0.0080  cls_loss: 0.0243  \n",
      "<<<iteration:[540/657] - total_loss: 0.3077  obj_loss: 0.1749  noobj_loss: 0.1313  bbox_loss: 0.0093  cls_loss: 0.0207  \n",
      "<<<iteration:[560/657] - total_loss: 0.3143  obj_loss: 0.1802  noobj_loss: 0.1329  bbox_loss: 0.0086  cls_loss: 0.0244  \n",
      "<<<iteration:[580/657] - total_loss: 0.3134  obj_loss: 0.1837  noobj_loss: 0.1356  bbox_loss: 0.0087  cls_loss: 0.0185  \n",
      "<<<iteration:[600/657] - total_loss: 0.3089  obj_loss: 0.1830  noobj_loss: 0.1313  bbox_loss: 0.0085  cls_loss: 0.0179  \n",
      "<<<iteration:[620/657] - total_loss: 0.3192  obj_loss: 0.1901  noobj_loss: 0.1335  bbox_loss: 0.0082  cls_loss: 0.0214  \n",
      "<<<iteration:[640/657] - total_loss: 0.3058  obj_loss: 0.1847  noobj_loss: 0.1337  bbox_loss: 0.0075  cls_loss: 0.0168  \n",
      "\n",
      "epoch:31/100 - Train Loss: 0.3113, Val Loss: 0.3233\n",
      "\n",
      "<<<iteration:[20/657] - total_loss: 0.3317  obj_loss: 0.1927  noobj_loss: 0.1430  bbox_loss: 0.0094  cls_loss: 0.0205  \n",
      "<<<iteration:[40/657] - total_loss: 0.3102  obj_loss: 0.1856  noobj_loss: 0.1276  bbox_loss: 0.0079  cls_loss: 0.0210  \n",
      "<<<iteration:[60/657] - total_loss: 0.3162  obj_loss: 0.1882  noobj_loss: 0.1389  bbox_loss: 0.0080  cls_loss: 0.0186  \n",
      "<<<iteration:[80/657] - total_loss: 0.3122  obj_loss: 0.1837  noobj_loss: 0.1393  bbox_loss: 0.0079  cls_loss: 0.0195  \n",
      "<<<iteration:[100/657] - total_loss: 0.3135  obj_loss: 0.1870  noobj_loss: 0.1342  bbox_loss: 0.0083  cls_loss: 0.0181  \n",
      "<<<iteration:[120/657] - total_loss: 0.3010  obj_loss: 0.1700  noobj_loss: 0.1377  bbox_loss: 0.0089  cls_loss: 0.0179  \n",
      "<<<iteration:[140/657] - total_loss: 0.2964  obj_loss: 0.1680  noobj_loss: 0.1316  bbox_loss: 0.0083  cls_loss: 0.0212  \n",
      "<<<iteration:[160/657] - total_loss: 0.3111  obj_loss: 0.1872  noobj_loss: 0.1365  bbox_loss: 0.0074  cls_loss: 0.0186  \n",
      "<<<iteration:[180/657] - total_loss: 0.3238  obj_loss: 0.1832  noobj_loss: 0.1384  bbox_loss: 0.0109  cls_loss: 0.0170  \n",
      "<<<iteration:[200/657] - total_loss: 0.3095  obj_loss: 0.1782  noobj_loss: 0.1334  bbox_loss: 0.0084  cls_loss: 0.0223  \n",
      "<<<iteration:[220/657] - total_loss: 0.3092  obj_loss: 0.1775  noobj_loss: 0.1420  bbox_loss: 0.0081  cls_loss: 0.0204  \n",
      "<<<iteration:[240/657] - total_loss: 0.3185  obj_loss: 0.1831  noobj_loss: 0.1280  bbox_loss: 0.0091  cls_loss: 0.0261  \n",
      "<<<iteration:[260/657] - total_loss: 0.3002  obj_loss: 0.1793  noobj_loss: 0.1320  bbox_loss: 0.0078  cls_loss: 0.0159  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<<<iteration:[280/657] - total_loss: 0.3085  obj_loss: 0.1895  noobj_loss: 0.1366  bbox_loss: 0.0070  cls_loss: 0.0156  \n",
      "<<<iteration:[300/657] - total_loss: 0.3173  obj_loss: 0.1813  noobj_loss: 0.1394  bbox_loss: 0.0085  cls_loss: 0.0240  \n",
      "<<<iteration:[320/657] - total_loss: 0.3194  obj_loss: 0.2025  noobj_loss: 0.1290  bbox_loss: 0.0081  cls_loss: 0.0119  \n",
      "<<<iteration:[340/657] - total_loss: 0.3287  obj_loss: 0.1954  noobj_loss: 0.1381  bbox_loss: 0.0084  cls_loss: 0.0225  \n",
      "<<<iteration:[360/657] - total_loss: 0.3108  obj_loss: 0.1749  noobj_loss: 0.1420  bbox_loss: 0.0091  cls_loss: 0.0195  \n",
      "<<<iteration:[380/657] - total_loss: 0.3105  obj_loss: 0.1764  noobj_loss: 0.1357  bbox_loss: 0.0085  cls_loss: 0.0235  \n",
      "<<<iteration:[400/657] - total_loss: 0.3114  obj_loss: 0.1877  noobj_loss: 0.1303  bbox_loss: 0.0077  cls_loss: 0.0199  \n",
      "<<<iteration:[420/657] - total_loss: 0.3021  obj_loss: 0.1801  noobj_loss: 0.1313  bbox_loss: 0.0082  cls_loss: 0.0155  \n",
      "<<<iteration:[440/657] - total_loss: 0.3160  obj_loss: 0.1879  noobj_loss: 0.1301  bbox_loss: 0.0087  cls_loss: 0.0196  \n",
      "<<<iteration:[460/657] - total_loss: 0.3071  obj_loss: 0.1804  noobj_loss: 0.1318  bbox_loss: 0.0080  cls_loss: 0.0207  \n",
      "<<<iteration:[480/657] - total_loss: 0.2914  obj_loss: 0.1640  noobj_loss: 0.1308  bbox_loss: 0.0089  cls_loss: 0.0176  \n",
      "<<<iteration:[500/657] - total_loss: 0.2975  obj_loss: 0.1689  noobj_loss: 0.1346  bbox_loss: 0.0084  cls_loss: 0.0194  \n",
      "<<<iteration:[520/657] - total_loss: 0.3047  obj_loss: 0.1700  noobj_loss: 0.1341  bbox_loss: 0.0085  cls_loss: 0.0252  \n",
      "<<<iteration:[540/657] - total_loss: 0.3219  obj_loss: 0.1854  noobj_loss: 0.1390  bbox_loss: 0.0089  cls_loss: 0.0225  \n",
      "<<<iteration:[560/657] - total_loss: 0.2992  obj_loss: 0.1812  noobj_loss: 0.1312  bbox_loss: 0.0070  cls_loss: 0.0172  \n",
      "<<<iteration:[580/657] - total_loss: 0.3089  obj_loss: 0.1912  noobj_loss: 0.1302  bbox_loss: 0.0074  cls_loss: 0.0154  \n",
      "<<<iteration:[600/657] - total_loss: 0.3142  obj_loss: 0.1919  noobj_loss: 0.1444  bbox_loss: 0.0071  cls_loss: 0.0149  \n",
      "<<<iteration:[620/657] - total_loss: 0.3086  obj_loss: 0.1774  noobj_loss: 0.1356  bbox_loss: 0.0088  cls_loss: 0.0193  \n",
      "<<<iteration:[640/657] - total_loss: 0.3074  obj_loss: 0.1792  noobj_loss: 0.1290  bbox_loss: 0.0076  cls_loss: 0.0256  \n",
      "\n",
      "epoch:32/100 - Train Loss: 0.3104, Val Loss: 0.3195\n",
      "\n",
      "<<<iteration:[20/657] - total_loss: 0.3256  obj_loss: 0.1882  noobj_loss: 0.1411  bbox_loss: 0.0091  cls_loss: 0.0214  \n",
      "<<<iteration:[40/657] - total_loss: 0.3109  obj_loss: 0.1740  noobj_loss: 0.1407  bbox_loss: 0.0088  cls_loss: 0.0225  \n",
      "<<<iteration:[60/657] - total_loss: 0.3210  obj_loss: 0.1882  noobj_loss: 0.1425  bbox_loss: 0.0082  cls_loss: 0.0204  \n",
      "<<<iteration:[80/657] - total_loss: 0.2971  obj_loss: 0.1787  noobj_loss: 0.1337  bbox_loss: 0.0076  cls_loss: 0.0137  \n",
      "<<<iteration:[100/657] - total_loss: 0.3268  obj_loss: 0.1886  noobj_loss: 0.1335  bbox_loss: 0.0085  cls_loss: 0.0290  \n",
      "<<<iteration:[120/657] - total_loss: 0.3201  obj_loss: 0.1912  noobj_loss: 0.1393  bbox_loss: 0.0079  cls_loss: 0.0196  \n",
      "<<<iteration:[140/657] - total_loss: 0.3163  obj_loss: 0.1813  noobj_loss: 0.1447  bbox_loss: 0.0074  cls_loss: 0.0255  \n",
      "<<<iteration:[160/657] - total_loss: 0.3017  obj_loss: 0.1827  noobj_loss: 0.1396  bbox_loss: 0.0071  cls_loss: 0.0135  \n",
      "<<<iteration:[180/657] - total_loss: 0.3022  obj_loss: 0.1709  noobj_loss: 0.1361  bbox_loss: 0.0085  cls_loss: 0.0206  \n",
      "<<<iteration:[200/657] - total_loss: 0.3067  obj_loss: 0.1832  noobj_loss: 0.1412  bbox_loss: 0.0074  cls_loss: 0.0158  \n",
      "<<<iteration:[220/657] - total_loss: 0.3156  obj_loss: 0.1925  noobj_loss: 0.1334  bbox_loss: 0.0076  cls_loss: 0.0185  \n",
      "<<<iteration:[240/657] - total_loss: 0.3102  obj_loss: 0.1809  noobj_loss: 0.1423  bbox_loss: 0.0083  cls_loss: 0.0166  \n",
      "<<<iteration:[260/657] - total_loss: 0.3212  obj_loss: 0.1869  noobj_loss: 0.1378  bbox_loss: 0.0082  cls_loss: 0.0245  \n",
      "<<<iteration:[280/657] - total_loss: 0.3086  obj_loss: 0.1776  noobj_loss: 0.1351  bbox_loss: 0.0084  cls_loss: 0.0213  \n",
      "<<<iteration:[300/657] - total_loss: 0.3112  obj_loss: 0.1858  noobj_loss: 0.1362  bbox_loss: 0.0076  cls_loss: 0.0193  \n",
      "<<<iteration:[320/657] - total_loss: 0.3027  obj_loss: 0.1762  noobj_loss: 0.1353  bbox_loss: 0.0082  cls_loss: 0.0178  \n",
      "<<<iteration:[340/657] - total_loss: 0.2903  obj_loss: 0.1647  noobj_loss: 0.1353  bbox_loss: 0.0075  cls_loss: 0.0203  \n",
      "<<<iteration:[360/657] - total_loss: 0.3067  obj_loss: 0.1772  noobj_loss: 0.1325  bbox_loss: 0.0091  cls_loss: 0.0176  \n",
      "<<<iteration:[380/657] - total_loss: 0.3089  obj_loss: 0.1796  noobj_loss: 0.1333  bbox_loss: 0.0086  cls_loss: 0.0195  \n",
      "<<<iteration:[400/657] - total_loss: 0.3085  obj_loss: 0.1789  noobj_loss: 0.1363  bbox_loss: 0.0084  cls_loss: 0.0197  \n",
      "<<<iteration:[420/657] - total_loss: 0.2994  obj_loss: 0.1736  noobj_loss: 0.1334  bbox_loss: 0.0077  cls_loss: 0.0207  \n",
      "<<<iteration:[440/657] - total_loss: 0.3056  obj_loss: 0.1667  noobj_loss: 0.1346  bbox_loss: 0.0093  cls_loss: 0.0251  \n",
      "<<<iteration:[460/657] - total_loss: 0.3131  obj_loss: 0.1897  noobj_loss: 0.1343  bbox_loss: 0.0074  cls_loss: 0.0193  \n",
      "<<<iteration:[480/657] - total_loss: 0.3215  obj_loss: 0.1988  noobj_loss: 0.1371  bbox_loss: 0.0080  cls_loss: 0.0142  \n",
      "<<<iteration:[500/657] - total_loss: 0.3043  obj_loss: 0.1810  noobj_loss: 0.1352  bbox_loss: 0.0078  cls_loss: 0.0169  \n",
      "<<<iteration:[520/657] - total_loss: 0.3013  obj_loss: 0.1799  noobj_loss: 0.1327  bbox_loss: 0.0073  cls_loss: 0.0186  \n",
      "<<<iteration:[540/657] - total_loss: 0.2993  obj_loss: 0.1668  noobj_loss: 0.1318  bbox_loss: 0.0090  cls_loss: 0.0215  \n",
      "<<<iteration:[560/657] - total_loss: 0.3116  obj_loss: 0.1776  noobj_loss: 0.1393  bbox_loss: 0.0086  cls_loss: 0.0215  \n",
      "<<<iteration:[580/657] - total_loss: 0.3058  obj_loss: 0.1798  noobj_loss: 0.1347  bbox_loss: 0.0079  cls_loss: 0.0193  \n",
      "<<<iteration:[600/657] - total_loss: 0.3086  obj_loss: 0.1908  noobj_loss: 0.1319  bbox_loss: 0.0069  cls_loss: 0.0175  \n",
      "<<<iteration:[620/657] - total_loss: 0.2978  obj_loss: 0.1794  noobj_loss: 0.1326  bbox_loss: 0.0074  cls_loss: 0.0150  \n",
      "<<<iteration:[640/657] - total_loss: 0.3154  obj_loss: 0.1877  noobj_loss: 0.1384  bbox_loss: 0.0084  cls_loss: 0.0164  \n",
      "\n",
      "epoch:33/100 - Train Loss: 0.3089, Val Loss: 0.3222\n",
      "\n",
      "<<<iteration:[20/657] - total_loss: 0.3242  obj_loss: 0.1907  noobj_loss: 0.1366  bbox_loss: 0.0083  cls_loss: 0.0239  \n",
      "<<<iteration:[40/657] - total_loss: 0.3092  obj_loss: 0.1780  noobj_loss: 0.1409  bbox_loss: 0.0083  cls_loss: 0.0194  \n",
      "<<<iteration:[60/657] - total_loss: 0.3193  obj_loss: 0.1890  noobj_loss: 0.1274  bbox_loss: 0.0082  cls_loss: 0.0254  \n",
      "<<<iteration:[80/657] - total_loss: 0.3095  obj_loss: 0.1799  noobj_loss: 0.1398  bbox_loss: 0.0080  cls_loss: 0.0198  \n",
      "<<<iteration:[100/657] - total_loss: 0.3140  obj_loss: 0.1832  noobj_loss: 0.1392  bbox_loss: 0.0080  cls_loss: 0.0212  \n",
      "<<<iteration:[120/657] - total_loss: 0.3092  obj_loss: 0.1850  noobj_loss: 0.1360  bbox_loss: 0.0081  cls_loss: 0.0159  \n",
      "<<<iteration:[140/657] - total_loss: 0.3058  obj_loss: 0.1820  noobj_loss: 0.1338  bbox_loss: 0.0080  cls_loss: 0.0168  \n",
      "<<<iteration:[160/657] - total_loss: 0.3122  obj_loss: 0.1953  noobj_loss: 0.1283  bbox_loss: 0.0075  cls_loss: 0.0152  \n",
      "<<<iteration:[180/657] - total_loss: 0.3292  obj_loss: 0.1923  noobj_loss: 0.1390  bbox_loss: 0.0094  cls_loss: 0.0206  \n",
      "<<<iteration:[200/657] - total_loss: 0.3123  obj_loss: 0.1850  noobj_loss: 0.1381  bbox_loss: 0.0078  cls_loss: 0.0191  \n",
      "<<<iteration:[220/657] - total_loss: 0.3131  obj_loss: 0.1854  noobj_loss: 0.1395  bbox_loss: 0.0079  cls_loss: 0.0184  \n",
      "<<<iteration:[240/657] - total_loss: 0.2977  obj_loss: 0.1710  noobj_loss: 0.1357  bbox_loss: 0.0086  cls_loss: 0.0160  \n",
      "<<<iteration:[260/657] - total_loss: 0.3023  obj_loss: 0.1725  noobj_loss: 0.1364  bbox_loss: 0.0092  cls_loss: 0.0156  \n",
      "<<<iteration:[280/657] - total_loss: 0.3026  obj_loss: 0.1721  noobj_loss: 0.1451  bbox_loss: 0.0075  cls_loss: 0.0205  \n",
      "<<<iteration:[300/657] - total_loss: 0.3092  obj_loss: 0.1810  noobj_loss: 0.1358  bbox_loss: 0.0081  cls_loss: 0.0200  \n",
      "<<<iteration:[320/657] - total_loss: 0.3030  obj_loss: 0.1775  noobj_loss: 0.1354  bbox_loss: 0.0082  cls_loss: 0.0168  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<<<iteration:[340/657] - total_loss: 0.3099  obj_loss: 0.1821  noobj_loss: 0.1382  bbox_loss: 0.0078  cls_loss: 0.0197  \n",
      "<<<iteration:[360/657] - total_loss: 0.2994  obj_loss: 0.1787  noobj_loss: 0.1329  bbox_loss: 0.0080  cls_loss: 0.0144  \n",
      "<<<iteration:[380/657] - total_loss: 0.3088  obj_loss: 0.1841  noobj_loss: 0.1328  bbox_loss: 0.0082  cls_loss: 0.0174  \n",
      "<<<iteration:[400/657] - total_loss: 0.3263  obj_loss: 0.1732  noobj_loss: 0.1431  bbox_loss: 0.0118  cls_loss: 0.0227  \n",
      "<<<iteration:[420/657] - total_loss: 0.3105  obj_loss: 0.1468  noobj_loss: 0.1359  bbox_loss: 0.0154  cls_loss: 0.0189  \n",
      "<<<iteration:[440/657] - total_loss: 0.2947  obj_loss: 0.1591  noobj_loss: 0.1220  bbox_loss: 0.0120  cls_loss: 0.0144  \n",
      "<<<iteration:[460/657] - total_loss: 0.3041  obj_loss: 0.1663  noobj_loss: 0.1234  bbox_loss: 0.0111  cls_loss: 0.0204  \n",
      "<<<iteration:[480/657] - total_loss: 0.3044  obj_loss: 0.1773  noobj_loss: 0.1248  bbox_loss: 0.0097  cls_loss: 0.0161  \n",
      "<<<iteration:[500/657] - total_loss: 0.3098  obj_loss: 0.1822  noobj_loss: 0.1314  bbox_loss: 0.0092  cls_loss: 0.0157  \n",
      "<<<iteration:[520/657] - total_loss: 0.3076  obj_loss: 0.1743  noobj_loss: 0.1390  bbox_loss: 0.0091  cls_loss: 0.0183  \n",
      "<<<iteration:[540/657] - total_loss: 0.3154  obj_loss: 0.1820  noobj_loss: 0.1331  bbox_loss: 0.0098  cls_loss: 0.0179  \n",
      "<<<iteration:[560/657] - total_loss: 0.3064  obj_loss: 0.1767  noobj_loss: 0.1349  bbox_loss: 0.0088  cls_loss: 0.0182  \n",
      "<<<iteration:[580/657] - total_loss: 0.3055  obj_loss: 0.1795  noobj_loss: 0.1314  bbox_loss: 0.0086  cls_loss: 0.0174  \n",
      "<<<iteration:[600/657] - total_loss: 0.2997  obj_loss: 0.1684  noobj_loss: 0.1391  bbox_loss: 0.0097  cls_loss: 0.0131  \n",
      "<<<iteration:[620/657] - total_loss: 0.3029  obj_loss: 0.1733  noobj_loss: 0.1296  bbox_loss: 0.0098  cls_loss: 0.0161  \n",
      "<<<iteration:[640/657] - total_loss: 0.3057  obj_loss: 0.1659  noobj_loss: 0.1302  bbox_loss: 0.0090  cls_loss: 0.0299  \n",
      "\n",
      "epoch:34/100 - Train Loss: 0.3083, Val Loss: 0.3201\n",
      "\n",
      "<<<iteration:[20/657] - total_loss: 0.3116  obj_loss: 0.1780  noobj_loss: 0.1407  bbox_loss: 0.0087  cls_loss: 0.0196  \n",
      "<<<iteration:[40/657] - total_loss: 0.3189  obj_loss: 0.1869  noobj_loss: 0.1320  bbox_loss: 0.0088  cls_loss: 0.0219  \n",
      "<<<iteration:[60/657] - total_loss: 0.2982  obj_loss: 0.1802  noobj_loss: 0.1284  bbox_loss: 0.0079  cls_loss: 0.0141  \n",
      "<<<iteration:[80/657] - total_loss: 0.2948  obj_loss: 0.1736  noobj_loss: 0.1342  bbox_loss: 0.0077  cls_loss: 0.0155  \n",
      "<<<iteration:[100/657] - total_loss: 0.3109  obj_loss: 0.1718  noobj_loss: 0.1389  bbox_loss: 0.0091  cls_loss: 0.0241  \n",
      "<<<iteration:[120/657] - total_loss: 0.3033  obj_loss: 0.1766  noobj_loss: 0.1341  bbox_loss: 0.0080  cls_loss: 0.0193  \n",
      "<<<iteration:[140/657] - total_loss: 0.3042  obj_loss: 0.1746  noobj_loss: 0.1400  bbox_loss: 0.0078  cls_loss: 0.0205  \n",
      "<<<iteration:[160/657] - total_loss: 0.3053  obj_loss: 0.1805  noobj_loss: 0.1388  bbox_loss: 0.0079  cls_loss: 0.0159  \n",
      "<<<iteration:[180/657] - total_loss: 0.3011  obj_loss: 0.1787  noobj_loss: 0.1318  bbox_loss: 0.0078  cls_loss: 0.0173  \n",
      "<<<iteration:[200/657] - total_loss: 0.3077  obj_loss: 0.1816  noobj_loss: 0.1345  bbox_loss: 0.0076  cls_loss: 0.0211  \n",
      "<<<iteration:[220/657] - total_loss: 0.3136  obj_loss: 0.1970  noobj_loss: 0.1337  bbox_loss: 0.0072  cls_loss: 0.0138  \n",
      "<<<iteration:[240/657] - total_loss: 0.3099  obj_loss: 0.1769  noobj_loss: 0.1424  bbox_loss: 0.0085  cls_loss: 0.0191  \n",
      "<<<iteration:[260/657] - total_loss: 0.3195  obj_loss: 0.1883  noobj_loss: 0.1360  bbox_loss: 0.0086  cls_loss: 0.0203  \n",
      "<<<iteration:[280/657] - total_loss: 0.3073  obj_loss: 0.1786  noobj_loss: 0.1417  bbox_loss: 0.0076  cls_loss: 0.0198  \n",
      "<<<iteration:[300/657] - total_loss: 0.3151  obj_loss: 0.1815  noobj_loss: 0.1354  bbox_loss: 0.0086  cls_loss: 0.0227  \n",
      "<<<iteration:[320/657] - total_loss: 0.3209  obj_loss: 0.1918  noobj_loss: 0.1376  bbox_loss: 0.0075  cls_loss: 0.0226  \n",
      "<<<iteration:[340/657] - total_loss: 0.3116  obj_loss: 0.1843  noobj_loss: 0.1403  bbox_loss: 0.0079  cls_loss: 0.0175  \n",
      "<<<iteration:[360/657] - total_loss: 0.3074  obj_loss: 0.1800  noobj_loss: 0.1345  bbox_loss: 0.0080  cls_loss: 0.0199  \n",
      "<<<iteration:[380/657] - total_loss: 0.3109  obj_loss: 0.1763  noobj_loss: 0.1377  bbox_loss: 0.0098  cls_loss: 0.0167  \n",
      "<<<iteration:[400/657] - total_loss: 0.3215  obj_loss: 0.1884  noobj_loss: 0.1415  bbox_loss: 0.0088  cls_loss: 0.0181  \n",
      "<<<iteration:[420/657] - total_loss: 0.3057  obj_loss: 0.1799  noobj_loss: 0.1401  bbox_loss: 0.0078  cls_loss: 0.0167  \n",
      "<<<iteration:[440/657] - total_loss: 0.3094  obj_loss: 0.1913  noobj_loss: 0.1392  bbox_loss: 0.0071  cls_loss: 0.0132  \n",
      "<<<iteration:[460/657] - total_loss: 0.2988  obj_loss: 0.1695  noobj_loss: 0.1424  bbox_loss: 0.0081  cls_loss: 0.0175  \n",
      "<<<iteration:[480/657] - total_loss: 0.3180  obj_loss: 0.1896  noobj_loss: 0.1366  bbox_loss: 0.0079  cls_loss: 0.0205  \n",
      "<<<iteration:[500/657] - total_loss: 0.2998  obj_loss: 0.1670  noobj_loss: 0.1414  bbox_loss: 0.0088  cls_loss: 0.0178  \n",
      "<<<iteration:[520/657] - total_loss: 0.2995  obj_loss: 0.1748  noobj_loss: 0.1372  bbox_loss: 0.0078  cls_loss: 0.0173  \n",
      "<<<iteration:[540/657] - total_loss: 0.3151  obj_loss: 0.1891  noobj_loss: 0.1406  bbox_loss: 0.0086  cls_loss: 0.0128  \n",
      "<<<iteration:[560/657] - total_loss: 0.3190  obj_loss: 0.1920  noobj_loss: 0.1400  bbox_loss: 0.0078  cls_loss: 0.0180  \n",
      "<<<iteration:[580/657] - total_loss: 0.2974  obj_loss: 0.1739  noobj_loss: 0.1367  bbox_loss: 0.0077  cls_loss: 0.0165  \n",
      "<<<iteration:[600/657] - total_loss: 0.2995  obj_loss: 0.1739  noobj_loss: 0.1424  bbox_loss: 0.0074  cls_loss: 0.0173  \n",
      "<<<iteration:[620/657] - total_loss: 0.2932  obj_loss: 0.1700  noobj_loss: 0.1365  bbox_loss: 0.0075  cls_loss: 0.0172  \n",
      "<<<iteration:[640/657] - total_loss: 0.3171  obj_loss: 0.1916  noobj_loss: 0.1382  bbox_loss: 0.0079  cls_loss: 0.0172  \n",
      "\n",
      "epoch:35/100 - Train Loss: 0.3078, Val Loss: 0.3164\n",
      "\n",
      "<<<iteration:[20/657] - total_loss: 0.3203  obj_loss: 0.1849  noobj_loss: 0.1495  bbox_loss: 0.0080  cls_loss: 0.0204  \n",
      "<<<iteration:[40/657] - total_loss: 0.3029  obj_loss: 0.1846  noobj_loss: 0.1306  bbox_loss: 0.0071  cls_loss: 0.0178  \n",
      "<<<iteration:[60/657] - total_loss: 0.3279  obj_loss: 0.2009  noobj_loss: 0.1351  bbox_loss: 0.0084  cls_loss: 0.0174  \n",
      "<<<iteration:[80/657] - total_loss: 0.3060  obj_loss: 0.1820  noobj_loss: 0.1421  bbox_loss: 0.0073  cls_loss: 0.0166  \n",
      "<<<iteration:[100/657] - total_loss: 0.3136  obj_loss: 0.1861  noobj_loss: 0.1419  bbox_loss: 0.0077  cls_loss: 0.0180  \n",
      "<<<iteration:[120/657] - total_loss: 0.3114  obj_loss: 0.1842  noobj_loss: 0.1398  bbox_loss: 0.0076  cls_loss: 0.0194  \n",
      "<<<iteration:[140/657] - total_loss: 0.2953  obj_loss: 0.1714  noobj_loss: 0.1374  bbox_loss: 0.0077  cls_loss: 0.0166  \n",
      "<<<iteration:[160/657] - total_loss: 0.3023  obj_loss: 0.1752  noobj_loss: 0.1411  bbox_loss: 0.0078  cls_loss: 0.0175  \n",
      "<<<iteration:[180/657] - total_loss: 0.3021  obj_loss: 0.1752  noobj_loss: 0.1353  bbox_loss: 0.0078  cls_loss: 0.0200  \n",
      "<<<iteration:[200/657] - total_loss: 0.3116  obj_loss: 0.1750  noobj_loss: 0.1409  bbox_loss: 0.0087  cls_loss: 0.0226  \n",
      "<<<iteration:[220/657] - total_loss: 0.3125  obj_loss: 0.1847  noobj_loss: 0.1335  bbox_loss: 0.0086  cls_loss: 0.0182  \n",
      "<<<iteration:[240/657] - total_loss: 0.2986  obj_loss: 0.1741  noobj_loss: 0.1363  bbox_loss: 0.0074  cls_loss: 0.0193  \n",
      "<<<iteration:[260/657] - total_loss: 0.3024  obj_loss: 0.1758  noobj_loss: 0.1321  bbox_loss: 0.0080  cls_loss: 0.0204  \n",
      "<<<iteration:[280/657] - total_loss: 0.3113  obj_loss: 0.1717  noobj_loss: 0.1421  bbox_loss: 0.0092  cls_loss: 0.0228  \n",
      "<<<iteration:[300/657] - total_loss: 0.3182  obj_loss: 0.1935  noobj_loss: 0.1412  bbox_loss: 0.0073  cls_loss: 0.0176  \n",
      "<<<iteration:[320/657] - total_loss: 0.3029  obj_loss: 0.1827  noobj_loss: 0.1399  bbox_loss: 0.0070  cls_loss: 0.0151  \n",
      "<<<iteration:[340/657] - total_loss: 0.3192  obj_loss: 0.1919  noobj_loss: 0.1442  bbox_loss: 0.0074  cls_loss: 0.0181  \n",
      "<<<iteration:[360/657] - total_loss: 0.2990  obj_loss: 0.1720  noobj_loss: 0.1472  bbox_loss: 0.0080  cls_loss: 0.0136  \n",
      "<<<iteration:[380/657] - total_loss: 0.3042  obj_loss: 0.1742  noobj_loss: 0.1355  bbox_loss: 0.0079  cls_loss: 0.0226  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<<<iteration:[400/657] - total_loss: 0.3082  obj_loss: 0.1800  noobj_loss: 0.1433  bbox_loss: 0.0073  cls_loss: 0.0201  \n",
      "<<<iteration:[420/657] - total_loss: 0.3061  obj_loss: 0.1882  noobj_loss: 0.1365  bbox_loss: 0.0070  cls_loss: 0.0147  \n",
      "<<<iteration:[440/657] - total_loss: 0.3080  obj_loss: 0.1844  noobj_loss: 0.1454  bbox_loss: 0.0067  cls_loss: 0.0173  \n",
      "<<<iteration:[460/657] - total_loss: 0.3107  obj_loss: 0.1843  noobj_loss: 0.1467  bbox_loss: 0.0071  cls_loss: 0.0176  \n",
      "<<<iteration:[480/657] - total_loss: 0.2991  obj_loss: 0.1823  noobj_loss: 0.1426  bbox_loss: 0.0069  cls_loss: 0.0110  \n",
      "<<<iteration:[500/657] - total_loss: 0.3043  obj_loss: 0.1779  noobj_loss: 0.1351  bbox_loss: 0.0084  cls_loss: 0.0168  \n",
      "<<<iteration:[520/657] - total_loss: 0.2954  obj_loss: 0.1692  noobj_loss: 0.1418  bbox_loss: 0.0079  cls_loss: 0.0160  \n",
      "<<<iteration:[540/657] - total_loss: 0.3098  obj_loss: 0.1825  noobj_loss: 0.1387  bbox_loss: 0.0086  cls_loss: 0.0152  \n",
      "<<<iteration:[560/657] - total_loss: 0.2981  obj_loss: 0.1755  noobj_loss: 0.1396  bbox_loss: 0.0078  cls_loss: 0.0140  \n",
      "<<<iteration:[580/657] - total_loss: 0.3044  obj_loss: 0.1806  noobj_loss: 0.1426  bbox_loss: 0.0079  cls_loss: 0.0127  \n",
      "<<<iteration:[600/657] - total_loss: 0.3022  obj_loss: 0.1818  noobj_loss: 0.1372  bbox_loss: 0.0070  cls_loss: 0.0169  \n",
      "<<<iteration:[620/657] - total_loss: 0.3097  obj_loss: 0.1781  noobj_loss: 0.1356  bbox_loss: 0.0081  cls_loss: 0.0232  \n",
      "<<<iteration:[640/657] - total_loss: 0.3124  obj_loss: 0.1870  noobj_loss: 0.1371  bbox_loss: 0.0081  cls_loss: 0.0163  \n",
      "\n",
      "epoch:36/100 - Train Loss: 0.3069, Val Loss: 0.3165\n",
      "\n",
      "<<<iteration:[20/657] - total_loss: 0.3217  obj_loss: 0.1843  noobj_loss: 0.1484  bbox_loss: 0.0087  cls_loss: 0.0200  \n",
      "<<<iteration:[40/657] - total_loss: 0.3223  obj_loss: 0.1969  noobj_loss: 0.1406  bbox_loss: 0.0077  cls_loss: 0.0167  \n",
      "<<<iteration:[60/657] - total_loss: 0.3065  obj_loss: 0.1810  noobj_loss: 0.1486  bbox_loss: 0.0074  cls_loss: 0.0140  \n",
      "<<<iteration:[80/657] - total_loss: 0.3116  obj_loss: 0.1895  noobj_loss: 0.1426  bbox_loss: 0.0071  cls_loss: 0.0154  \n",
      "<<<iteration:[100/657] - total_loss: 0.3039  obj_loss: 0.1775  noobj_loss: 0.1368  bbox_loss: 0.0078  cls_loss: 0.0188  \n",
      "<<<iteration:[120/657] - total_loss: 0.3118  obj_loss: 0.1840  noobj_loss: 0.1359  bbox_loss: 0.0083  cls_loss: 0.0183  \n",
      "<<<iteration:[140/657] - total_loss: 0.3006  obj_loss: 0.1796  noobj_loss: 0.1400  bbox_loss: 0.0073  cls_loss: 0.0148  \n",
      "<<<iteration:[160/657] - total_loss: 0.3164  obj_loss: 0.1852  noobj_loss: 0.1402  bbox_loss: 0.0078  cls_loss: 0.0218  \n",
      "<<<iteration:[180/657] - total_loss: 0.3085  obj_loss: 0.1767  noobj_loss: 0.1423  bbox_loss: 0.0082  cls_loss: 0.0197  \n",
      "<<<iteration:[200/657] - total_loss: 0.3067  obj_loss: 0.1811  noobj_loss: 0.1453  bbox_loss: 0.0074  cls_loss: 0.0158  \n",
      "<<<iteration:[220/657] - total_loss: 0.3313  obj_loss: 0.1943  noobj_loss: 0.1510  bbox_loss: 0.0079  cls_loss: 0.0219  \n",
      "<<<iteration:[240/657] - total_loss: 0.2983  obj_loss: 0.1712  noobj_loss: 0.1493  bbox_loss: 0.0074  cls_loss: 0.0153  \n",
      "<<<iteration:[260/657] - total_loss: 0.3070  obj_loss: 0.1831  noobj_loss: 0.1432  bbox_loss: 0.0071  cls_loss: 0.0168  \n",
      "<<<iteration:[280/657] - total_loss: 0.2891  obj_loss: 0.1704  noobj_loss: 0.1352  bbox_loss: 0.0072  cls_loss: 0.0150  \n",
      "<<<iteration:[300/657] - total_loss: 0.3033  obj_loss: 0.1804  noobj_loss: 0.1426  bbox_loss: 0.0071  cls_loss: 0.0163  \n",
      "<<<iteration:[320/657] - total_loss: 0.3263  obj_loss: 0.1851  noobj_loss: 0.1455  bbox_loss: 0.0099  cls_loss: 0.0191  \n",
      "<<<iteration:[340/657] - total_loss: 0.3038  obj_loss: 0.1839  noobj_loss: 0.1397  bbox_loss: 0.0074  cls_loss: 0.0130  \n",
      "<<<iteration:[360/657] - total_loss: 0.3017  obj_loss: 0.1780  noobj_loss: 0.1411  bbox_loss: 0.0066  cls_loss: 0.0201  \n",
      "<<<iteration:[380/657] - total_loss: 0.2979  obj_loss: 0.1800  noobj_loss: 0.1398  bbox_loss: 0.0070  cls_loss: 0.0131  \n",
      "<<<iteration:[400/657] - total_loss: 0.2938  obj_loss: 0.1668  noobj_loss: 0.1439  bbox_loss: 0.0073  cls_loss: 0.0188  \n",
      "<<<iteration:[420/657] - total_loss: 0.3135  obj_loss: 0.1891  noobj_loss: 0.1385  bbox_loss: 0.0076  cls_loss: 0.0171  \n",
      "<<<iteration:[440/657] - total_loss: 0.3194  obj_loss: 0.1899  noobj_loss: 0.1399  bbox_loss: 0.0080  cls_loss: 0.0195  \n",
      "<<<iteration:[460/657] - total_loss: 0.3204  obj_loss: 0.1948  noobj_loss: 0.1492  bbox_loss: 0.0069  cls_loss: 0.0164  \n",
      "<<<iteration:[480/657] - total_loss: 0.2959  obj_loss: 0.1626  noobj_loss: 0.1481  bbox_loss: 0.0081  cls_loss: 0.0187  \n",
      "<<<iteration:[500/657] - total_loss: 0.2997  obj_loss: 0.1736  noobj_loss: 0.1341  bbox_loss: 0.0081  cls_loss: 0.0187  \n",
      "<<<iteration:[520/657] - total_loss: 0.3203  obj_loss: 0.1816  noobj_loss: 0.1392  bbox_loss: 0.0089  cls_loss: 0.0244  \n",
      "<<<iteration:[540/657] - total_loss: 0.2911  obj_loss: 0.1720  noobj_loss: 0.1392  bbox_loss: 0.0069  cls_loss: 0.0150  \n",
      "<<<iteration:[560/657] - total_loss: 0.2956  obj_loss: 0.1745  noobj_loss: 0.1376  bbox_loss: 0.0073  cls_loss: 0.0158  \n",
      "<<<iteration:[580/657] - total_loss: 0.3134  obj_loss: 0.1806  noobj_loss: 0.1429  bbox_loss: 0.0080  cls_loss: 0.0211  \n",
      "<<<iteration:[600/657] - total_loss: 0.2965  obj_loss: 0.1747  noobj_loss: 0.1423  bbox_loss: 0.0073  cls_loss: 0.0139  \n",
      "<<<iteration:[620/657] - total_loss: 0.3177  obj_loss: 0.1861  noobj_loss: 0.1494  bbox_loss: 0.0081  cls_loss: 0.0165  \n",
      "<<<iteration:[640/657] - total_loss: 0.3107  obj_loss: 0.1805  noobj_loss: 0.1443  bbox_loss: 0.0077  cls_loss: 0.0194  \n",
      "\n",
      "epoch:37/100 - Train Loss: 0.3074, Val Loss: 0.3165\n",
      "\n",
      "<<<iteration:[20/657] - total_loss: 0.3336  obj_loss: 0.1886  noobj_loss: 0.1482  bbox_loss: 0.0082  cls_loss: 0.0299  \n",
      "<<<iteration:[40/657] - total_loss: 0.3011  obj_loss: 0.1798  noobj_loss: 0.1356  bbox_loss: 0.0077  cls_loss: 0.0149  \n",
      "<<<iteration:[60/657] - total_loss: 0.3093  obj_loss: 0.1826  noobj_loss: 0.1424  bbox_loss: 0.0082  cls_loss: 0.0146  \n",
      "<<<iteration:[80/657] - total_loss: 0.3115  obj_loss: 0.1841  noobj_loss: 0.1410  bbox_loss: 0.0081  cls_loss: 0.0165  \n",
      "<<<iteration:[100/657] - total_loss: 0.3050  obj_loss: 0.1797  noobj_loss: 0.1384  bbox_loss: 0.0078  cls_loss: 0.0173  \n",
      "<<<iteration:[120/657] - total_loss: 0.3043  obj_loss: 0.1769  noobj_loss: 0.1394  bbox_loss: 0.0073  cls_loss: 0.0211  \n",
      "<<<iteration:[140/657] - total_loss: 0.3090  obj_loss: 0.1878  noobj_loss: 0.1436  bbox_loss: 0.0069  cls_loss: 0.0151  \n",
      "<<<iteration:[160/657] - total_loss: 0.2959  obj_loss: 0.1692  noobj_loss: 0.1505  bbox_loss: 0.0070  cls_loss: 0.0163  \n",
      "<<<iteration:[180/657] - total_loss: 0.3193  obj_loss: 0.1864  noobj_loss: 0.1426  bbox_loss: 0.0082  cls_loss: 0.0209  \n",
      "<<<iteration:[200/657] - total_loss: 0.3069  obj_loss: 0.1849  noobj_loss: 0.1413  bbox_loss: 0.0070  cls_loss: 0.0161  \n",
      "<<<iteration:[220/657] - total_loss: 0.2998  obj_loss: 0.1807  noobj_loss: 0.1484  bbox_loss: 0.0066  cls_loss: 0.0119  \n",
      "<<<iteration:[240/657] - total_loss: 0.3020  obj_loss: 0.1779  noobj_loss: 0.1486  bbox_loss: 0.0068  cls_loss: 0.0159  \n",
      "<<<iteration:[260/657] - total_loss: 0.3091  obj_loss: 0.1833  noobj_loss: 0.1374  bbox_loss: 0.0075  cls_loss: 0.0195  \n",
      "<<<iteration:[280/657] - total_loss: 0.3102  obj_loss: 0.1861  noobj_loss: 0.1463  bbox_loss: 0.0070  cls_loss: 0.0158  \n",
      "<<<iteration:[300/657] - total_loss: 0.2991  obj_loss: 0.1741  noobj_loss: 0.1458  bbox_loss: 0.0075  cls_loss: 0.0146  \n",
      "<<<iteration:[320/657] - total_loss: 0.3248  obj_loss: 0.1998  noobj_loss: 0.1373  bbox_loss: 0.0081  cls_loss: 0.0160  \n",
      "<<<iteration:[340/657] - total_loss: 0.3124  obj_loss: 0.1873  noobj_loss: 0.1462  bbox_loss: 0.0077  cls_loss: 0.0135  \n",
      "<<<iteration:[360/657] - total_loss: 0.3088  obj_loss: 0.1795  noobj_loss: 0.1505  bbox_loss: 0.0071  cls_loss: 0.0189  \n",
      "<<<iteration:[380/657] - total_loss: 0.2972  obj_loss: 0.1705  noobj_loss: 0.1514  bbox_loss: 0.0074  cls_loss: 0.0142  \n",
      "<<<iteration:[400/657] - total_loss: 0.2972  obj_loss: 0.1752  noobj_loss: 0.1436  bbox_loss: 0.0069  cls_loss: 0.0156  \n",
      "<<<iteration:[420/657] - total_loss: 0.2848  obj_loss: 0.1643  noobj_loss: 0.1460  bbox_loss: 0.0068  cls_loss: 0.0137  \n",
      "<<<iteration:[440/657] - total_loss: 0.3044  obj_loss: 0.1781  noobj_loss: 0.1431  bbox_loss: 0.0079  cls_loss: 0.0152  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<<<iteration:[460/657] - total_loss: 0.3039  obj_loss: 0.1810  noobj_loss: 0.1412  bbox_loss: 0.0075  cls_loss: 0.0147  \n",
      "<<<iteration:[480/657] - total_loss: 0.3074  obj_loss: 0.1743  noobj_loss: 0.1439  bbox_loss: 0.0081  cls_loss: 0.0205  \n",
      "<<<iteration:[500/657] - total_loss: 0.2993  obj_loss: 0.1796  noobj_loss: 0.1424  bbox_loss: 0.0069  cls_loss: 0.0140  \n",
      "<<<iteration:[520/657] - total_loss: 0.3001  obj_loss: 0.1848  noobj_loss: 0.1394  bbox_loss: 0.0069  cls_loss: 0.0112  \n",
      "<<<iteration:[540/657] - total_loss: 0.3117  obj_loss: 0.1865  noobj_loss: 0.1481  bbox_loss: 0.0071  cls_loss: 0.0157  \n",
      "<<<iteration:[560/657] - total_loss: 0.3130  obj_loss: 0.1893  noobj_loss: 0.1383  bbox_loss: 0.0077  cls_loss: 0.0161  \n",
      "<<<iteration:[580/657] - total_loss: 0.3050  obj_loss: 0.1768  noobj_loss: 0.1475  bbox_loss: 0.0072  cls_loss: 0.0183  \n",
      "<<<iteration:[600/657] - total_loss: 0.3088  obj_loss: 0.1823  noobj_loss: 0.1413  bbox_loss: 0.0073  cls_loss: 0.0195  \n",
      "<<<iteration:[620/657] - total_loss: 0.3054  obj_loss: 0.1748  noobj_loss: 0.1447  bbox_loss: 0.0083  cls_loss: 0.0167  \n",
      "<<<iteration:[640/657] - total_loss: 0.3185  obj_loss: 0.1936  noobj_loss: 0.1400  bbox_loss: 0.0076  cls_loss: 0.0171  \n",
      "\n",
      "epoch:38/100 - Train Loss: 0.3063, Val Loss: 0.3185\n",
      "\n",
      "<<<iteration:[20/657] - total_loss: 0.3089  obj_loss: 0.1810  noobj_loss: 0.1586  bbox_loss: 0.0070  cls_loss: 0.0134  \n",
      "<<<iteration:[40/657] - total_loss: 0.3053  obj_loss: 0.1830  noobj_loss: 0.1421  bbox_loss: 0.0072  cls_loss: 0.0154  \n",
      "<<<iteration:[60/657] - total_loss: 0.3173  obj_loss: 0.1858  noobj_loss: 0.1428  bbox_loss: 0.0079  cls_loss: 0.0203  \n",
      "<<<iteration:[80/657] - total_loss: 0.2941  obj_loss: 0.1692  noobj_loss: 0.1417  bbox_loss: 0.0070  cls_loss: 0.0189  \n",
      "<<<iteration:[100/657] - total_loss: 0.2950  obj_loss: 0.1722  noobj_loss: 0.1484  bbox_loss: 0.0069  cls_loss: 0.0141  \n",
      "<<<iteration:[120/657] - total_loss: 0.3097  obj_loss: 0.1826  noobj_loss: 0.1378  bbox_loss: 0.0087  cls_loss: 0.0148  \n",
      "<<<iteration:[140/657] - total_loss: 0.3096  obj_loss: 0.1880  noobj_loss: 0.1414  bbox_loss: 0.0070  cls_loss: 0.0157  \n",
      "<<<iteration:[160/657] - total_loss: 0.3094  obj_loss: 0.1800  noobj_loss: 0.1452  bbox_loss: 0.0071  cls_loss: 0.0211  \n",
      "<<<iteration:[180/657] - total_loss: 0.3029  obj_loss: 0.1794  noobj_loss: 0.1489  bbox_loss: 0.0070  cls_loss: 0.0141  \n",
      "<<<iteration:[200/657] - total_loss: 0.2975  obj_loss: 0.1736  noobj_loss: 0.1407  bbox_loss: 0.0075  cls_loss: 0.0160  \n",
      "<<<iteration:[220/657] - total_loss: 0.3062  obj_loss: 0.1846  noobj_loss: 0.1421  bbox_loss: 0.0070  cls_loss: 0.0153  \n",
      "<<<iteration:[240/657] - total_loss: 0.2999  obj_loss: 0.1755  noobj_loss: 0.1414  bbox_loss: 0.0076  cls_loss: 0.0156  \n",
      "<<<iteration:[260/657] - total_loss: 0.3116  obj_loss: 0.1924  noobj_loss: 0.1407  bbox_loss: 0.0073  cls_loss: 0.0124  \n",
      "<<<iteration:[280/657] - total_loss: 0.2930  obj_loss: 0.1713  noobj_loss: 0.1525  bbox_loss: 0.0063  cls_loss: 0.0139  \n",
      "<<<iteration:[300/657] - total_loss: 0.3108  obj_loss: 0.1822  noobj_loss: 0.1524  bbox_loss: 0.0073  cls_loss: 0.0156  \n",
      "<<<iteration:[320/657] - total_loss: 0.3043  obj_loss: 0.1814  noobj_loss: 0.1455  bbox_loss: 0.0073  cls_loss: 0.0135  \n",
      "<<<iteration:[340/657] - total_loss: 0.3047  obj_loss: 0.1865  noobj_loss: 0.1366  bbox_loss: 0.0070  cls_loss: 0.0151  \n",
      "<<<iteration:[360/657] - total_loss: 0.2968  obj_loss: 0.1730  noobj_loss: 0.1451  bbox_loss: 0.0073  cls_loss: 0.0146  \n",
      "<<<iteration:[380/657] - total_loss: 0.2924  obj_loss: 0.1681  noobj_loss: 0.1444  bbox_loss: 0.0074  cls_loss: 0.0150  \n",
      "<<<iteration:[400/657] - total_loss: 0.3085  obj_loss: 0.1761  noobj_loss: 0.1524  bbox_loss: 0.0072  cls_loss: 0.0200  \n",
      "<<<iteration:[420/657] - total_loss: 0.3052  obj_loss: 0.1790  noobj_loss: 0.1427  bbox_loss: 0.0073  cls_loss: 0.0181  \n",
      "<<<iteration:[440/657] - total_loss: 0.3017  obj_loss: 0.1823  noobj_loss: 0.1324  bbox_loss: 0.0077  cls_loss: 0.0148  \n",
      "<<<iteration:[460/657] - total_loss: 0.3042  obj_loss: 0.1756  noobj_loss: 0.1519  bbox_loss: 0.0076  cls_loss: 0.0148  \n",
      "<<<iteration:[480/657] - total_loss: 0.2938  obj_loss: 0.1707  noobj_loss: 0.1461  bbox_loss: 0.0073  cls_loss: 0.0133  \n",
      "<<<iteration:[500/657] - total_loss: 0.2976  obj_loss: 0.1749  noobj_loss: 0.1436  bbox_loss: 0.0072  cls_loss: 0.0148  \n",
      "<<<iteration:[520/657] - total_loss: 0.3023  obj_loss: 0.1781  noobj_loss: 0.1434  bbox_loss: 0.0069  cls_loss: 0.0181  \n",
      "<<<iteration:[540/657] - total_loss: 0.3143  obj_loss: 0.1913  noobj_loss: 0.1515  bbox_loss: 0.0063  cls_loss: 0.0159  \n",
      "<<<iteration:[560/657] - total_loss: 0.3053  obj_loss: 0.1773  noobj_loss: 0.1394  bbox_loss: 0.0077  cls_loss: 0.0196  \n",
      "<<<iteration:[580/657] - total_loss: 0.3197  obj_loss: 0.1801  noobj_loss: 0.1539  bbox_loss: 0.0094  cls_loss: 0.0155  \n",
      "<<<iteration:[600/657] - total_loss: 0.3160  obj_loss: 0.1839  noobj_loss: 0.1390  bbox_loss: 0.0096  cls_loss: 0.0147  \n",
      "<<<iteration:[620/657] - total_loss: 0.3092  obj_loss: 0.1593  noobj_loss: 0.1448  bbox_loss: 0.0114  cls_loss: 0.0203  \n",
      "<<<iteration:[640/657] - total_loss: 0.2951  obj_loss: 0.1639  noobj_loss: 0.1434  bbox_loss: 0.0079  cls_loss: 0.0200  \n",
      "\n",
      "epoch:39/100 - Train Loss: 0.3042, Val Loss: 0.3189\n",
      "\n",
      "<<<iteration:[20/657] - total_loss: 0.3221  obj_loss: 0.1804  noobj_loss: 0.1444  bbox_loss: 0.0093  cls_loss: 0.0232  \n",
      "<<<iteration:[40/657] - total_loss: 0.2986  obj_loss: 0.1795  noobj_loss: 0.1443  bbox_loss: 0.0072  cls_loss: 0.0109  \n",
      "<<<iteration:[60/657] - total_loss: 0.3169  obj_loss: 0.1997  noobj_loss: 0.1425  bbox_loss: 0.0064  cls_loss: 0.0137  \n",
      "<<<iteration:[80/657] - total_loss: 0.2967  obj_loss: 0.1673  noobj_loss: 0.1404  bbox_loss: 0.0084  cls_loss: 0.0173  \n",
      "<<<iteration:[100/657] - total_loss: 0.3093  obj_loss: 0.1840  noobj_loss: 0.1507  bbox_loss: 0.0065  cls_loss: 0.0175  \n",
      "<<<iteration:[120/657] - total_loss: 0.3042  obj_loss: 0.1721  noobj_loss: 0.1439  bbox_loss: 0.0085  cls_loss: 0.0178  \n",
      "<<<iteration:[140/657] - total_loss: 0.3171  obj_loss: 0.1867  noobj_loss: 0.1482  bbox_loss: 0.0083  cls_loss: 0.0147  \n",
      "<<<iteration:[160/657] - total_loss: 0.3053  obj_loss: 0.1761  noobj_loss: 0.1408  bbox_loss: 0.0083  cls_loss: 0.0173  \n",
      "<<<iteration:[180/657] - total_loss: 0.3024  obj_loss: 0.1774  noobj_loss: 0.1460  bbox_loss: 0.0074  cls_loss: 0.0149  \n",
      "<<<iteration:[200/657] - total_loss: 0.2987  obj_loss: 0.1681  noobj_loss: 0.1411  bbox_loss: 0.0086  cls_loss: 0.0170  \n",
      "<<<iteration:[220/657] - total_loss: 0.3217  obj_loss: 0.1907  noobj_loss: 0.1490  bbox_loss: 0.0077  cls_loss: 0.0179  \n",
      "<<<iteration:[240/657] - total_loss: 0.3028  obj_loss: 0.1799  noobj_loss: 0.1440  bbox_loss: 0.0076  cls_loss: 0.0127  \n",
      "<<<iteration:[260/657] - total_loss: 0.3059  obj_loss: 0.1784  noobj_loss: 0.1493  bbox_loss: 0.0075  cls_loss: 0.0153  \n",
      "<<<iteration:[280/657] - total_loss: 0.3034  obj_loss: 0.1807  noobj_loss: 0.1513  bbox_loss: 0.0062  cls_loss: 0.0161  \n",
      "<<<iteration:[300/657] - total_loss: 0.3108  obj_loss: 0.1744  noobj_loss: 0.1512  bbox_loss: 0.0084  cls_loss: 0.0186  \n",
      "<<<iteration:[320/657] - total_loss: 0.3050  obj_loss: 0.1770  noobj_loss: 0.1403  bbox_loss: 0.0085  cls_loss: 0.0152  \n",
      "<<<iteration:[340/657] - total_loss: 0.3038  obj_loss: 0.1756  noobj_loss: 0.1425  bbox_loss: 0.0086  cls_loss: 0.0139  \n",
      "<<<iteration:[360/657] - total_loss: 0.3024  obj_loss: 0.1786  noobj_loss: 0.1493  bbox_loss: 0.0074  cls_loss: 0.0122  \n",
      "<<<iteration:[380/657] - total_loss: 0.3150  obj_loss: 0.1848  noobj_loss: 0.1465  bbox_loss: 0.0079  cls_loss: 0.0176  \n",
      "<<<iteration:[400/657] - total_loss: 0.3199  obj_loss: 0.1811  noobj_loss: 0.1519  bbox_loss: 0.0084  cls_loss: 0.0210  \n",
      "<<<iteration:[420/657] - total_loss: 0.2962  obj_loss: 0.1730  noobj_loss: 0.1392  bbox_loss: 0.0070  cls_loss: 0.0187  \n",
      "<<<iteration:[440/657] - total_loss: 0.3076  obj_loss: 0.1875  noobj_loss: 0.1363  bbox_loss: 0.0071  cls_loss: 0.0163  \n",
      "<<<iteration:[460/657] - total_loss: 0.2977  obj_loss: 0.1723  noobj_loss: 0.1529  bbox_loss: 0.0071  cls_loss: 0.0132  \n",
      "<<<iteration:[480/657] - total_loss: 0.2917  obj_loss: 0.1697  noobj_loss: 0.1509  bbox_loss: 0.0070  cls_loss: 0.0113  \n",
      "<<<iteration:[500/657] - total_loss: 0.2985  obj_loss: 0.1763  noobj_loss: 0.1457  bbox_loss: 0.0075  cls_loss: 0.0117  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<<<iteration:[520/657] - total_loss: 0.3087  obj_loss: 0.1861  noobj_loss: 0.1419  bbox_loss: 0.0075  cls_loss: 0.0143  \n",
      "<<<iteration:[540/657] - total_loss: 0.2907  obj_loss: 0.1674  noobj_loss: 0.1418  bbox_loss: 0.0070  cls_loss: 0.0173  \n",
      "<<<iteration:[560/657] - total_loss: 0.3164  obj_loss: 0.1892  noobj_loss: 0.1390  bbox_loss: 0.0081  cls_loss: 0.0173  \n",
      "<<<iteration:[580/657] - total_loss: 0.3129  obj_loss: 0.1906  noobj_loss: 0.1410  bbox_loss: 0.0076  cls_loss: 0.0135  \n",
      "<<<iteration:[600/657] - total_loss: 0.2972  obj_loss: 0.1719  noobj_loss: 0.1411  bbox_loss: 0.0074  cls_loss: 0.0176  \n",
      "<<<iteration:[620/657] - total_loss: 0.2921  obj_loss: 0.1632  noobj_loss: 0.1442  bbox_loss: 0.0074  cls_loss: 0.0198  \n",
      "<<<iteration:[640/657] - total_loss: 0.3075  obj_loss: 0.1801  noobj_loss: 0.1392  bbox_loss: 0.0075  cls_loss: 0.0201  \n",
      "\n",
      "epoch:40/100 - Train Loss: 0.3051, Val Loss: 0.3149\n",
      "\n",
      "<<<iteration:[20/657] - total_loss: 0.3283  obj_loss: 0.2018  noobj_loss: 0.1542  bbox_loss: 0.0070  cls_loss: 0.0143  \n",
      "<<<iteration:[40/657] - total_loss: 0.2929  obj_loss: 0.1691  noobj_loss: 0.1452  bbox_loss: 0.0071  cls_loss: 0.0156  \n",
      "<<<iteration:[60/657] - total_loss: 0.3076  obj_loss: 0.1813  noobj_loss: 0.1443  bbox_loss: 0.0074  cls_loss: 0.0172  \n",
      "<<<iteration:[80/657] - total_loss: 0.3036  obj_loss: 0.1771  noobj_loss: 0.1475  bbox_loss: 0.0073  cls_loss: 0.0161  \n",
      "<<<iteration:[100/657] - total_loss: 0.3152  obj_loss: 0.1802  noobj_loss: 0.1553  bbox_loss: 0.0072  cls_loss: 0.0212  \n",
      "<<<iteration:[120/657] - total_loss: 0.3148  obj_loss: 0.1855  noobj_loss: 0.1466  bbox_loss: 0.0072  cls_loss: 0.0202  \n",
      "<<<iteration:[140/657] - total_loss: 0.2888  obj_loss: 0.1658  noobj_loss: 0.1448  bbox_loss: 0.0075  cls_loss: 0.0131  \n",
      "<<<iteration:[160/657] - total_loss: 0.3003  obj_loss: 0.1711  noobj_loss: 0.1411  bbox_loss: 0.0079  cls_loss: 0.0190  \n",
      "<<<iteration:[180/657] - total_loss: 0.3139  obj_loss: 0.1858  noobj_loss: 0.1468  bbox_loss: 0.0075  cls_loss: 0.0172  \n",
      "<<<iteration:[200/657] - total_loss: 0.2968  obj_loss: 0.1740  noobj_loss: 0.1432  bbox_loss: 0.0070  cls_loss: 0.0160  \n",
      "<<<iteration:[220/657] - total_loss: 0.2973  obj_loss: 0.1782  noobj_loss: 0.1468  bbox_loss: 0.0069  cls_loss: 0.0113  \n",
      "<<<iteration:[240/657] - total_loss: 0.2947  obj_loss: 0.1700  noobj_loss: 0.1512  bbox_loss: 0.0071  cls_loss: 0.0135  \n",
      "<<<iteration:[260/657] - total_loss: 0.3171  obj_loss: 0.1860  noobj_loss: 0.1492  bbox_loss: 0.0079  cls_loss: 0.0168  \n",
      "<<<iteration:[280/657] - total_loss: 0.3111  obj_loss: 0.1836  noobj_loss: 0.1512  bbox_loss: 0.0069  cls_loss: 0.0175  \n",
      "<<<iteration:[300/657] - total_loss: 0.3152  obj_loss: 0.1895  noobj_loss: 0.1468  bbox_loss: 0.0069  cls_loss: 0.0178  \n",
      "<<<iteration:[320/657] - total_loss: 0.3178  obj_loss: 0.1753  noobj_loss: 0.1471  bbox_loss: 0.0085  cls_loss: 0.0265  \n",
      "<<<iteration:[340/657] - total_loss: 0.3017  obj_loss: 0.1800  noobj_loss: 0.1533  bbox_loss: 0.0066  cls_loss: 0.0122  \n",
      "<<<iteration:[360/657] - total_loss: 0.3040  obj_loss: 0.1809  noobj_loss: 0.1384  bbox_loss: 0.0075  cls_loss: 0.0164  \n",
      "<<<iteration:[380/657] - total_loss: 0.3024  obj_loss: 0.1792  noobj_loss: 0.1471  bbox_loss: 0.0072  cls_loss: 0.0134  \n",
      "<<<iteration:[400/657] - total_loss: 0.3012  obj_loss: 0.1848  noobj_loss: 0.1425  bbox_loss: 0.0062  cls_loss: 0.0140  \n",
      "<<<iteration:[420/657] - total_loss: 0.3167  obj_loss: 0.1998  noobj_loss: 0.1451  bbox_loss: 0.0065  cls_loss: 0.0118  \n",
      "<<<iteration:[440/657] - total_loss: 0.3057  obj_loss: 0.1721  noobj_loss: 0.1581  bbox_loss: 0.0075  cls_loss: 0.0170  \n",
      "<<<iteration:[460/657] - total_loss: 0.3099  obj_loss: 0.1790  noobj_loss: 0.1548  bbox_loss: 0.0071  cls_loss: 0.0181  \n",
      "<<<iteration:[480/657] - total_loss: 0.2975  obj_loss: 0.1787  noobj_loss: 0.1517  bbox_loss: 0.0061  cls_loss: 0.0126  \n",
      "<<<iteration:[500/657] - total_loss: 0.2959  obj_loss: 0.1738  noobj_loss: 0.1461  bbox_loss: 0.0069  cls_loss: 0.0147  \n",
      "<<<iteration:[520/657] - total_loss: 0.3168  obj_loss: 0.1887  noobj_loss: 0.1498  bbox_loss: 0.0078  cls_loss: 0.0140  \n",
      "<<<iteration:[540/657] - total_loss: 0.2892  obj_loss: 0.1655  noobj_loss: 0.1469  bbox_loss: 0.0067  cls_loss: 0.0166  \n",
      "<<<iteration:[560/657] - total_loss: 0.3102  obj_loss: 0.1903  noobj_loss: 0.1513  bbox_loss: 0.0063  cls_loss: 0.0130  \n",
      "<<<iteration:[580/657] - total_loss: 0.3131  obj_loss: 0.1945  noobj_loss: 0.1477  bbox_loss: 0.0063  cls_loss: 0.0132  \n",
      "<<<iteration:[600/657] - total_loss: 0.3036  obj_loss: 0.1794  noobj_loss: 0.1443  bbox_loss: 0.0068  cls_loss: 0.0180  \n",
      "<<<iteration:[620/657] - total_loss: 0.3023  obj_loss: 0.1780  noobj_loss: 0.1451  bbox_loss: 0.0070  cls_loss: 0.0169  \n",
      "<<<iteration:[640/657] - total_loss: 0.3010  obj_loss: 0.1783  noobj_loss: 0.1476  bbox_loss: 0.0069  cls_loss: 0.0145  \n",
      "\n",
      "epoch:41/100 - Train Loss: 0.3047, Val Loss: 0.3123\n",
      "\n",
      "<<<iteration:[20/657] - total_loss: 0.3128  obj_loss: 0.1842  noobj_loss: 0.1546  bbox_loss: 0.0073  cls_loss: 0.0147  \n",
      "<<<iteration:[40/657] - total_loss: 0.2944  obj_loss: 0.1630  noobj_loss: 0.1512  bbox_loss: 0.0077  cls_loss: 0.0172  \n",
      "<<<iteration:[60/657] - total_loss: 0.2910  obj_loss: 0.1795  noobj_loss: 0.1417  bbox_loss: 0.0055  cls_loss: 0.0129  \n",
      "<<<iteration:[80/657] - total_loss: 0.2983  obj_loss: 0.1764  noobj_loss: 0.1409  bbox_loss: 0.0074  cls_loss: 0.0146  \n",
      "<<<iteration:[100/657] - total_loss: 0.2997  obj_loss: 0.1769  noobj_loss: 0.1457  bbox_loss: 0.0069  cls_loss: 0.0155  \n",
      "<<<iteration:[120/657] - total_loss: 0.3072  obj_loss: 0.1859  noobj_loss: 0.1488  bbox_loss: 0.0070  cls_loss: 0.0121  \n",
      "<<<iteration:[140/657] - total_loss: 0.3202  obj_loss: 0.1879  noobj_loss: 0.1486  bbox_loss: 0.0075  cls_loss: 0.0204  \n",
      "<<<iteration:[160/657] - total_loss: 0.3016  obj_loss: 0.1720  noobj_loss: 0.1480  bbox_loss: 0.0077  cls_loss: 0.0172  \n",
      "<<<iteration:[180/657] - total_loss: 0.2965  obj_loss: 0.1787  noobj_loss: 0.1377  bbox_loss: 0.0068  cls_loss: 0.0152  \n",
      "<<<iteration:[200/657] - total_loss: 0.2886  obj_loss: 0.1668  noobj_loss: 0.1435  bbox_loss: 0.0074  cls_loss: 0.0128  \n",
      "<<<iteration:[220/657] - total_loss: 0.2968  obj_loss: 0.1713  noobj_loss: 0.1464  bbox_loss: 0.0074  cls_loss: 0.0155  \n",
      "<<<iteration:[240/657] - total_loss: 0.3037  obj_loss: 0.1864  noobj_loss: 0.1392  bbox_loss: 0.0071  cls_loss: 0.0121  \n",
      "<<<iteration:[260/657] - total_loss: 0.3099  obj_loss: 0.1849  noobj_loss: 0.1470  bbox_loss: 0.0067  cls_loss: 0.0178  \n",
      "<<<iteration:[280/657] - total_loss: 0.3087  obj_loss: 0.1830  noobj_loss: 0.1496  bbox_loss: 0.0074  cls_loss: 0.0139  \n",
      "<<<iteration:[300/657] - total_loss: 0.3055  obj_loss: 0.1770  noobj_loss: 0.1499  bbox_loss: 0.0078  cls_loss: 0.0146  \n",
      "<<<iteration:[320/657] - total_loss: 0.2973  obj_loss: 0.1731  noobj_loss: 0.1547  bbox_loss: 0.0067  cls_loss: 0.0132  \n",
      "<<<iteration:[340/657] - total_loss: 0.3081  obj_loss: 0.1837  noobj_loss: 0.1504  bbox_loss: 0.0073  cls_loss: 0.0130  \n",
      "<<<iteration:[360/657] - total_loss: 0.3055  obj_loss: 0.1745  noobj_loss: 0.1455  bbox_loss: 0.0074  cls_loss: 0.0213  \n",
      "<<<iteration:[380/657] - total_loss: 0.2968  obj_loss: 0.1763  noobj_loss: 0.1410  bbox_loss: 0.0072  cls_loss: 0.0143  \n",
      "<<<iteration:[400/657] - total_loss: 0.2968  obj_loss: 0.1746  noobj_loss: 0.1459  bbox_loss: 0.0069  cls_loss: 0.0148  \n",
      "<<<iteration:[420/657] - total_loss: 0.2983  obj_loss: 0.1675  noobj_loss: 0.1537  bbox_loss: 0.0073  cls_loss: 0.0176  \n",
      "<<<iteration:[440/657] - total_loss: 0.3117  obj_loss: 0.1825  noobj_loss: 0.1529  bbox_loss: 0.0074  cls_loss: 0.0156  \n",
      "<<<iteration:[460/657] - total_loss: 0.3044  obj_loss: 0.1789  noobj_loss: 0.1511  bbox_loss: 0.0068  cls_loss: 0.0159  \n",
      "<<<iteration:[480/657] - total_loss: 0.3022  obj_loss: 0.1741  noobj_loss: 0.1526  bbox_loss: 0.0073  cls_loss: 0.0151  \n",
      "<<<iteration:[500/657] - total_loss: 0.2933  obj_loss: 0.1771  noobj_loss: 0.1456  bbox_loss: 0.0062  cls_loss: 0.0126  \n",
      "<<<iteration:[520/657] - total_loss: 0.2947  obj_loss: 0.1745  noobj_loss: 0.1526  bbox_loss: 0.0065  cls_loss: 0.0113  \n",
      "<<<iteration:[540/657] - total_loss: 0.2990  obj_loss: 0.1725  noobj_loss: 0.1507  bbox_loss: 0.0069  cls_loss: 0.0166  \n",
      "<<<iteration:[560/657] - total_loss: 0.3244  obj_loss: 0.1879  noobj_loss: 0.1449  bbox_loss: 0.0075  cls_loss: 0.0268  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<<<iteration:[580/657] - total_loss: 0.3051  obj_loss: 0.1861  noobj_loss: 0.1439  bbox_loss: 0.0069  cls_loss: 0.0123  \n",
      "<<<iteration:[600/657] - total_loss: 0.3104  obj_loss: 0.1856  noobj_loss: 0.1507  bbox_loss: 0.0068  cls_loss: 0.0155  \n",
      "<<<iteration:[620/657] - total_loss: 0.3001  obj_loss: 0.1690  noobj_loss: 0.1540  bbox_loss: 0.0075  cls_loss: 0.0166  \n",
      "<<<iteration:[640/657] - total_loss: 0.3056  obj_loss: 0.1829  noobj_loss: 0.1468  bbox_loss: 0.0070  cls_loss: 0.0142  \n",
      "\n",
      "epoch:42/100 - Train Loss: 0.3022, Val Loss: 0.3124\n",
      "\n",
      "<<<iteration:[20/657] - total_loss: 0.3236  obj_loss: 0.1912  noobj_loss: 0.1531  bbox_loss: 0.0076  cls_loss: 0.0177  \n",
      "<<<iteration:[40/657] - total_loss: 0.3040  obj_loss: 0.1732  noobj_loss: 0.1487  bbox_loss: 0.0077  cls_loss: 0.0181  \n",
      "<<<iteration:[60/657] - total_loss: 0.2964  obj_loss: 0.1775  noobj_loss: 0.1487  bbox_loss: 0.0062  cls_loss: 0.0135  \n",
      "<<<iteration:[80/657] - total_loss: 0.2994  obj_loss: 0.1770  noobj_loss: 0.1495  bbox_loss: 0.0068  cls_loss: 0.0138  \n",
      "<<<iteration:[100/657] - total_loss: 0.2987  obj_loss: 0.1720  noobj_loss: 0.1476  bbox_loss: 0.0073  cls_loss: 0.0166  \n",
      "<<<iteration:[120/657] - total_loss: 0.2969  obj_loss: 0.1717  noobj_loss: 0.1443  bbox_loss: 0.0078  cls_loss: 0.0140  \n",
      "<<<iteration:[140/657] - total_loss: 0.2948  obj_loss: 0.1678  noobj_loss: 0.1551  bbox_loss: 0.0069  cls_loss: 0.0149  \n",
      "<<<iteration:[160/657] - total_loss: 0.2928  obj_loss: 0.1728  noobj_loss: 0.1445  bbox_loss: 0.0071  cls_loss: 0.0123  \n",
      "<<<iteration:[180/657] - total_loss: 0.3206  obj_loss: 0.1978  noobj_loss: 0.1447  bbox_loss: 0.0074  cls_loss: 0.0135  \n",
      "<<<iteration:[200/657] - total_loss: 0.2883  obj_loss: 0.1637  noobj_loss: 0.1495  bbox_loss: 0.0071  cls_loss: 0.0146  \n",
      "<<<iteration:[220/657] - total_loss: 0.3083  obj_loss: 0.1850  noobj_loss: 0.1457  bbox_loss: 0.0074  cls_loss: 0.0132  \n",
      "<<<iteration:[240/657] - total_loss: 0.3138  obj_loss: 0.1865  noobj_loss: 0.1516  bbox_loss: 0.0074  cls_loss: 0.0144  \n",
      "<<<iteration:[260/657] - total_loss: 0.3114  obj_loss: 0.1854  noobj_loss: 0.1530  bbox_loss: 0.0067  cls_loss: 0.0161  \n",
      "<<<iteration:[280/657] - total_loss: 0.2978  obj_loss: 0.1694  noobj_loss: 0.1470  bbox_loss: 0.0079  cls_loss: 0.0154  \n",
      "<<<iteration:[300/657] - total_loss: 0.2963  obj_loss: 0.1731  noobj_loss: 0.1483  bbox_loss: 0.0065  cls_loss: 0.0164  \n",
      "<<<iteration:[320/657] - total_loss: 0.3085  obj_loss: 0.1759  noobj_loss: 0.1576  bbox_loss: 0.0077  cls_loss: 0.0154  \n",
      "<<<iteration:[340/657] - total_loss: 0.3032  obj_loss: 0.1738  noobj_loss: 0.1535  bbox_loss: 0.0071  cls_loss: 0.0171  \n",
      "<<<iteration:[360/657] - total_loss: 0.2879  obj_loss: 0.1717  noobj_loss: 0.1413  bbox_loss: 0.0067  cls_loss: 0.0120  \n",
      "<<<iteration:[380/657] - total_loss: 0.2901  obj_loss: 0.1721  noobj_loss: 0.1481  bbox_loss: 0.0066  cls_loss: 0.0108  \n",
      "<<<iteration:[400/657] - total_loss: 0.2996  obj_loss: 0.1778  noobj_loss: 0.1477  bbox_loss: 0.0071  cls_loss: 0.0124  \n",
      "<<<iteration:[420/657] - total_loss: 0.2999  obj_loss: 0.1657  noobj_loss: 0.1529  bbox_loss: 0.0075  cls_loss: 0.0205  \n",
      "<<<iteration:[440/657] - total_loss: 0.3076  obj_loss: 0.1864  noobj_loss: 0.1475  bbox_loss: 0.0069  cls_loss: 0.0132  \n",
      "<<<iteration:[460/657] - total_loss: 0.3017  obj_loss: 0.1788  noobj_loss: 0.1480  bbox_loss: 0.0073  cls_loss: 0.0122  \n",
      "<<<iteration:[480/657] - total_loss: 0.2926  obj_loss: 0.1660  noobj_loss: 0.1524  bbox_loss: 0.0074  cls_loss: 0.0134  \n",
      "<<<iteration:[500/657] - total_loss: 0.3081  obj_loss: 0.1836  noobj_loss: 0.1454  bbox_loss: 0.0073  cls_loss: 0.0152  \n",
      "<<<iteration:[520/657] - total_loss: 0.3074  obj_loss: 0.1829  noobj_loss: 0.1495  bbox_loss: 0.0065  cls_loss: 0.0173  \n",
      "<<<iteration:[540/657] - total_loss: 0.3027  obj_loss: 0.1755  noobj_loss: 0.1473  bbox_loss: 0.0076  cls_loss: 0.0158  \n",
      "<<<iteration:[560/657] - total_loss: 0.3013  obj_loss: 0.1737  noobj_loss: 0.1526  bbox_loss: 0.0075  cls_loss: 0.0140  \n",
      "<<<iteration:[580/657] - total_loss: 0.2913  obj_loss: 0.1664  noobj_loss: 0.1458  bbox_loss: 0.0074  cls_loss: 0.0152  \n",
      "<<<iteration:[600/657] - total_loss: 0.2986  obj_loss: 0.1675  noobj_loss: 0.1467  bbox_loss: 0.0082  cls_loss: 0.0169  \n",
      "<<<iteration:[620/657] - total_loss: 0.3074  obj_loss: 0.1828  noobj_loss: 0.1543  bbox_loss: 0.0065  cls_loss: 0.0152  \n",
      "<<<iteration:[640/657] - total_loss: 0.2964  obj_loss: 0.1759  noobj_loss: 0.1571  bbox_loss: 0.0060  cls_loss: 0.0119  \n",
      "\n",
      "epoch:43/100 - Train Loss: 0.3012, Val Loss: 0.3096\n",
      "\n",
      "<<<iteration:[20/657] - total_loss: 0.3256  obj_loss: 0.1954  noobj_loss: 0.1536  bbox_loss: 0.0073  cls_loss: 0.0169  \n",
      "<<<iteration:[40/657] - total_loss: 0.3025  obj_loss: 0.1781  noobj_loss: 0.1573  bbox_loss: 0.0063  cls_loss: 0.0142  \n",
      "<<<iteration:[60/657] - total_loss: 0.3073  obj_loss: 0.1783  noobj_loss: 0.1477  bbox_loss: 0.0074  cls_loss: 0.0179  \n",
      "<<<iteration:[80/657] - total_loss: 0.3035  obj_loss: 0.1795  noobj_loss: 0.1429  bbox_loss: 0.0065  cls_loss: 0.0201  \n",
      "<<<iteration:[100/657] - total_loss: 0.2982  obj_loss: 0.1791  noobj_loss: 0.1525  bbox_loss: 0.0059  cls_loss: 0.0131  \n",
      "<<<iteration:[120/657] - total_loss: 0.3019  obj_loss: 0.1812  noobj_loss: 0.1527  bbox_loss: 0.0058  cls_loss: 0.0152  \n",
      "<<<iteration:[140/657] - total_loss: 0.3012  obj_loss: 0.1729  noobj_loss: 0.1543  bbox_loss: 0.0068  cls_loss: 0.0170  \n",
      "<<<iteration:[160/657] - total_loss: 0.2999  obj_loss: 0.1792  noobj_loss: 0.1500  bbox_loss: 0.0067  cls_loss: 0.0120  \n",
      "<<<iteration:[180/657] - total_loss: 0.3088  obj_loss: 0.1891  noobj_loss: 0.1489  bbox_loss: 0.0065  cls_loss: 0.0130  \n",
      "<<<iteration:[200/657] - total_loss: 0.3074  obj_loss: 0.1795  noobj_loss: 0.1507  bbox_loss: 0.0070  cls_loss: 0.0176  \n",
      "<<<iteration:[220/657] - total_loss: 0.2961  obj_loss: 0.1745  noobj_loss: 0.1459  bbox_loss: 0.0068  cls_loss: 0.0145  \n",
      "<<<iteration:[240/657] - total_loss: 0.3109  obj_loss: 0.1890  noobj_loss: 0.1471  bbox_loss: 0.0065  cls_loss: 0.0158  \n",
      "<<<iteration:[260/657] - total_loss: 0.3137  obj_loss: 0.1863  noobj_loss: 0.1462  bbox_loss: 0.0075  cls_loss: 0.0167  \n",
      "<<<iteration:[280/657] - total_loss: 0.3067  obj_loss: 0.1754  noobj_loss: 0.1530  bbox_loss: 0.0084  cls_loss: 0.0129  \n",
      "<<<iteration:[300/657] - total_loss: 0.3033  obj_loss: 0.1772  noobj_loss: 0.1536  bbox_loss: 0.0066  cls_loss: 0.0162  \n",
      "<<<iteration:[320/657] - total_loss: 0.2963  obj_loss: 0.1618  noobj_loss: 0.1513  bbox_loss: 0.0076  cls_loss: 0.0208  \n",
      "<<<iteration:[340/657] - total_loss: 0.2997  obj_loss: 0.1684  noobj_loss: 0.1560  bbox_loss: 0.0077  cls_loss: 0.0147  \n",
      "<<<iteration:[360/657] - total_loss: 0.3135  obj_loss: 0.1926  noobj_loss: 0.1495  bbox_loss: 0.0066  cls_loss: 0.0132  \n",
      "<<<iteration:[380/657] - total_loss: 0.3099  obj_loss: 0.1758  noobj_loss: 0.1590  bbox_loss: 0.0071  cls_loss: 0.0191  \n",
      "<<<iteration:[400/657] - total_loss: 0.3078  obj_loss: 0.1807  noobj_loss: 0.1504  bbox_loss: 0.0073  cls_loss: 0.0154  \n",
      "<<<iteration:[420/657] - total_loss: 0.3050  obj_loss: 0.1827  noobj_loss: 0.1557  bbox_loss: 0.0065  cls_loss: 0.0121  \n",
      "<<<iteration:[440/657] - total_loss: 0.2975  obj_loss: 0.1718  noobj_loss: 0.1480  bbox_loss: 0.0069  cls_loss: 0.0170  \n",
      "<<<iteration:[460/657] - total_loss: 0.2936  obj_loss: 0.1666  noobj_loss: 0.1507  bbox_loss: 0.0070  cls_loss: 0.0165  \n",
      "<<<iteration:[480/657] - total_loss: 0.3058  obj_loss: 0.1827  noobj_loss: 0.1466  bbox_loss: 0.0071  cls_loss: 0.0142  \n",
      "<<<iteration:[500/657] - total_loss: 0.2923  obj_loss: 0.1754  noobj_loss: 0.1457  bbox_loss: 0.0062  cls_loss: 0.0129  \n",
      "<<<iteration:[520/657] - total_loss: 0.2873  obj_loss: 0.1626  noobj_loss: 0.1473  bbox_loss: 0.0069  cls_loss: 0.0168  \n",
      "<<<iteration:[540/657] - total_loss: 0.3171  obj_loss: 0.1920  noobj_loss: 0.1421  bbox_loss: 0.0066  cls_loss: 0.0212  \n",
      "<<<iteration:[560/657] - total_loss: 0.3052  obj_loss: 0.1769  noobj_loss: 0.1511  bbox_loss: 0.0076  cls_loss: 0.0146  \n",
      "<<<iteration:[580/657] - total_loss: 0.3062  obj_loss: 0.1810  noobj_loss: 0.1458  bbox_loss: 0.0074  cls_loss: 0.0154  \n",
      "<<<iteration:[600/657] - total_loss: 0.3018  obj_loss: 0.1752  noobj_loss: 0.1499  bbox_loss: 0.0074  cls_loss: 0.0146  \n",
      "<<<iteration:[620/657] - total_loss: 0.2989  obj_loss: 0.1640  noobj_loss: 0.1597  bbox_loss: 0.0075  cls_loss: 0.0173  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<<<iteration:[640/657] - total_loss: 0.2874  obj_loss: 0.1666  noobj_loss: 0.1506  bbox_loss: 0.0066  cls_loss: 0.0127  \n",
      "\n",
      "epoch:44/100 - Train Loss: 0.3026, Val Loss: 0.3087\n",
      "\n",
      "<<<iteration:[20/657] - total_loss: 0.3071  obj_loss: 0.1800  noobj_loss: 0.1505  bbox_loss: 0.0072  cls_loss: 0.0158  \n",
      "<<<iteration:[40/657] - total_loss: 0.2975  obj_loss: 0.1749  noobj_loss: 0.1488  bbox_loss: 0.0072  cls_loss: 0.0120  \n",
      "<<<iteration:[60/657] - total_loss: 0.3114  obj_loss: 0.1783  noobj_loss: 0.1551  bbox_loss: 0.0071  cls_loss: 0.0201  \n",
      "<<<iteration:[80/657] - total_loss: 0.2961  obj_loss: 0.1691  noobj_loss: 0.1500  bbox_loss: 0.0070  cls_loss: 0.0170  \n",
      "<<<iteration:[100/657] - total_loss: 0.3041  obj_loss: 0.1767  noobj_loss: 0.1548  bbox_loss: 0.0069  cls_loss: 0.0155  \n",
      "<<<iteration:[120/657] - total_loss: 0.2978  obj_loss: 0.1730  noobj_loss: 0.1471  bbox_loss: 0.0072  cls_loss: 0.0151  \n",
      "<<<iteration:[140/657] - total_loss: 0.2965  obj_loss: 0.1761  noobj_loss: 0.1534  bbox_loss: 0.0066  cls_loss: 0.0105  \n",
      "<<<iteration:[160/657] - total_loss: 0.3108  obj_loss: 0.1892  noobj_loss: 0.1505  bbox_loss: 0.0066  cls_loss: 0.0135  \n",
      "<<<iteration:[180/657] - total_loss: 0.3078  obj_loss: 0.1853  noobj_loss: 0.1540  bbox_loss: 0.0068  cls_loss: 0.0116  \n",
      "<<<iteration:[200/657] - total_loss: 0.2870  obj_loss: 0.1639  noobj_loss: 0.1481  bbox_loss: 0.0071  cls_loss: 0.0137  \n",
      "<<<iteration:[220/657] - total_loss: 0.3054  obj_loss: 0.1820  noobj_loss: 0.1533  bbox_loss: 0.0060  cls_loss: 0.0166  \n",
      "<<<iteration:[240/657] - total_loss: 0.2895  obj_loss: 0.1607  noobj_loss: 0.1548  bbox_loss: 0.0071  cls_loss: 0.0160  \n",
      "<<<iteration:[260/657] - total_loss: 0.3001  obj_loss: 0.1762  noobj_loss: 0.1542  bbox_loss: 0.0067  cls_loss: 0.0133  \n",
      "<<<iteration:[280/657] - total_loss: 0.3007  obj_loss: 0.1774  noobj_loss: 0.1541  bbox_loss: 0.0066  cls_loss: 0.0133  \n",
      "<<<iteration:[300/657] - total_loss: 0.3051  obj_loss: 0.1799  noobj_loss: 0.1584  bbox_loss: 0.0067  cls_loss: 0.0124  \n",
      "<<<iteration:[320/657] - total_loss: 0.2950  obj_loss: 0.1726  noobj_loss: 0.1485  bbox_loss: 0.0065  cls_loss: 0.0157  \n",
      "<<<iteration:[340/657] - total_loss: 0.3003  obj_loss: 0.1762  noobj_loss: 0.1473  bbox_loss: 0.0070  cls_loss: 0.0153  \n",
      "<<<iteration:[360/657] - total_loss: 0.2984  obj_loss: 0.1757  noobj_loss: 0.1471  bbox_loss: 0.0068  cls_loss: 0.0151  \n",
      "<<<iteration:[380/657] - total_loss: 0.3079  obj_loss: 0.1804  noobj_loss: 0.1581  bbox_loss: 0.0070  cls_loss: 0.0133  \n",
      "<<<iteration:[400/657] - total_loss: 0.2997  obj_loss: 0.1769  noobj_loss: 0.1525  bbox_loss: 0.0068  cls_loss: 0.0124  \n",
      "<<<iteration:[420/657] - total_loss: 0.2849  obj_loss: 0.1611  noobj_loss: 0.1502  bbox_loss: 0.0066  cls_loss: 0.0157  \n",
      "<<<iteration:[440/657] - total_loss: 0.3018  obj_loss: 0.1757  noobj_loss: 0.1499  bbox_loss: 0.0073  cls_loss: 0.0148  \n",
      "<<<iteration:[460/657] - total_loss: 0.3037  obj_loss: 0.1803  noobj_loss: 0.1586  bbox_loss: 0.0065  cls_loss: 0.0115  \n",
      "<<<iteration:[480/657] - total_loss: 0.2873  obj_loss: 0.1632  noobj_loss: 0.1524  bbox_loss: 0.0070  cls_loss: 0.0132  \n",
      "<<<iteration:[500/657] - total_loss: 0.2943  obj_loss: 0.1741  noobj_loss: 0.1479  bbox_loss: 0.0067  cls_loss: 0.0127  \n",
      "<<<iteration:[520/657] - total_loss: 0.2988  obj_loss: 0.1804  noobj_loss: 0.1520  bbox_loss: 0.0060  cls_loss: 0.0126  \n",
      "<<<iteration:[540/657] - total_loss: 0.3092  obj_loss: 0.1837  noobj_loss: 0.1516  bbox_loss: 0.0062  cls_loss: 0.0188  \n",
      "<<<iteration:[560/657] - total_loss: 0.3078  obj_loss: 0.1826  noobj_loss: 0.1544  bbox_loss: 0.0062  cls_loss: 0.0171  \n",
      "<<<iteration:[580/657] - total_loss: 0.2935  obj_loss: 0.1690  noobj_loss: 0.1440  bbox_loss: 0.0075  cls_loss: 0.0148  \n",
      "<<<iteration:[600/657] - total_loss: 0.2927  obj_loss: 0.1762  noobj_loss: 0.1448  bbox_loss: 0.0061  cls_loss: 0.0136  \n",
      "<<<iteration:[620/657] - total_loss: 0.3013  obj_loss: 0.1770  noobj_loss: 0.1533  bbox_loss: 0.0070  cls_loss: 0.0125  \n",
      "<<<iteration:[640/657] - total_loss: 0.3062  obj_loss: 0.1842  noobj_loss: 0.1524  bbox_loss: 0.0067  cls_loss: 0.0123  \n",
      "\n",
      "epoch:45/100 - Train Loss: 0.2993, Val Loss: 0.3141\n",
      "\n",
      "<<<iteration:[20/657] - total_loss: 0.3147  obj_loss: 0.1913  noobj_loss: 0.1526  bbox_loss: 0.0069  cls_loss: 0.0127  \n",
      "<<<iteration:[40/657] - total_loss: 0.3084  obj_loss: 0.1848  noobj_loss: 0.1566  bbox_loss: 0.0066  cls_loss: 0.0123  \n",
      "<<<iteration:[60/657] - total_loss: 0.2943  obj_loss: 0.1684  noobj_loss: 0.1516  bbox_loss: 0.0069  cls_loss: 0.0156  \n",
      "<<<iteration:[80/657] - total_loss: 0.2997  obj_loss: 0.1723  noobj_loss: 0.1451  bbox_loss: 0.0074  cls_loss: 0.0179  \n",
      "<<<iteration:[100/657] - total_loss: 0.3080  obj_loss: 0.1840  noobj_loss: 0.1531  bbox_loss: 0.0066  cls_loss: 0.0146  \n",
      "<<<iteration:[120/657] - total_loss: 0.3028  obj_loss: 0.1759  noobj_loss: 0.1525  bbox_loss: 0.0071  cls_loss: 0.0152  \n",
      "<<<iteration:[140/657] - total_loss: 0.2955  obj_loss: 0.1797  noobj_loss: 0.1493  bbox_loss: 0.0063  cls_loss: 0.0096  \n",
      "<<<iteration:[160/657] - total_loss: 0.2999  obj_loss: 0.1742  noobj_loss: 0.1500  bbox_loss: 0.0074  cls_loss: 0.0136  \n",
      "<<<iteration:[180/657] - total_loss: 0.3069  obj_loss: 0.1839  noobj_loss: 0.1556  bbox_loss: 0.0067  cls_loss: 0.0119  \n",
      "<<<iteration:[200/657] - total_loss: 0.2979  obj_loss: 0.1740  noobj_loss: 0.1527  bbox_loss: 0.0068  cls_loss: 0.0137  \n",
      "<<<iteration:[220/657] - total_loss: 0.2976  obj_loss: 0.1700  noobj_loss: 0.1461  bbox_loss: 0.0081  cls_loss: 0.0139  \n",
      "<<<iteration:[240/657] - total_loss: 0.3011  obj_loss: 0.1737  noobj_loss: 0.1587  bbox_loss: 0.0068  cls_loss: 0.0141  \n",
      "<<<iteration:[260/657] - total_loss: 0.2962  obj_loss: 0.1708  noobj_loss: 0.1526  bbox_loss: 0.0070  cls_loss: 0.0139  \n",
      "<<<iteration:[280/657] - total_loss: 0.2929  obj_loss: 0.1717  noobj_loss: 0.1508  bbox_loss: 0.0060  cls_loss: 0.0157  \n",
      "<<<iteration:[300/657] - total_loss: 0.2924  obj_loss: 0.1677  noobj_loss: 0.1497  bbox_loss: 0.0073  cls_loss: 0.0135  \n",
      "<<<iteration:[320/657] - total_loss: 0.2945  obj_loss: 0.1760  noobj_loss: 0.1460  bbox_loss: 0.0065  cls_loss: 0.0130  \n",
      "<<<iteration:[340/657] - total_loss: 0.3048  obj_loss: 0.1807  noobj_loss: 0.1577  bbox_loss: 0.0063  cls_loss: 0.0139  \n",
      "<<<iteration:[360/657] - total_loss: 0.2940  obj_loss: 0.1723  noobj_loss: 0.1491  bbox_loss: 0.0065  cls_loss: 0.0148  \n",
      "<<<iteration:[380/657] - total_loss: 0.3050  obj_loss: 0.1794  noobj_loss: 0.1647  bbox_loss: 0.0060  cls_loss: 0.0131  \n",
      "<<<iteration:[400/657] - total_loss: 0.2952  obj_loss: 0.1767  noobj_loss: 0.1456  bbox_loss: 0.0066  cls_loss: 0.0129  \n",
      "<<<iteration:[420/657] - total_loss: 0.2925  obj_loss: 0.1731  noobj_loss: 0.1542  bbox_loss: 0.0063  cls_loss: 0.0108  \n",
      "<<<iteration:[440/657] - total_loss: 0.3073  obj_loss: 0.1780  noobj_loss: 0.1594  bbox_loss: 0.0069  cls_loss: 0.0149  \n",
      "<<<iteration:[460/657] - total_loss: 0.2993  obj_loss: 0.1766  noobj_loss: 0.1543  bbox_loss: 0.0065  cls_loss: 0.0132  \n",
      "<<<iteration:[480/657] - total_loss: 0.3004  obj_loss: 0.1806  noobj_loss: 0.1512  bbox_loss: 0.0062  cls_loss: 0.0134  \n",
      "<<<iteration:[500/657] - total_loss: 0.2946  obj_loss: 0.1759  noobj_loss: 0.1549  bbox_loss: 0.0060  cls_loss: 0.0112  \n",
      "<<<iteration:[520/657] - total_loss: 0.3062  obj_loss: 0.1725  noobj_loss: 0.1470  bbox_loss: 0.0075  cls_loss: 0.0226  \n",
      "<<<iteration:[540/657] - total_loss: 0.3079  obj_loss: 0.1773  noobj_loss: 0.1528  bbox_loss: 0.0073  cls_loss: 0.0177  \n",
      "<<<iteration:[560/657] - total_loss: 0.3050  obj_loss: 0.1797  noobj_loss: 0.1453  bbox_loss: 0.0070  cls_loss: 0.0177  \n",
      "<<<iteration:[580/657] - total_loss: 0.3066  obj_loss: 0.1833  noobj_loss: 0.1559  bbox_loss: 0.0068  cls_loss: 0.0114  \n",
      "<<<iteration:[600/657] - total_loss: 0.3010  obj_loss: 0.1773  noobj_loss: 0.1665  bbox_loss: 0.0058  cls_loss: 0.0112  \n",
      "<<<iteration:[620/657] - total_loss: 0.2894  obj_loss: 0.1689  noobj_loss: 0.1491  bbox_loss: 0.0067  cls_loss: 0.0126  \n",
      "<<<iteration:[640/657] - total_loss: 0.3051  obj_loss: 0.1788  noobj_loss: 0.1527  bbox_loss: 0.0075  cls_loss: 0.0123  \n",
      "\n",
      "epoch:46/100 - Train Loss: 0.3002, Val Loss: 0.3152\n",
      "\n",
      "<<<iteration:[20/657] - total_loss: 0.3284  obj_loss: 0.1912  noobj_loss: 0.1522  bbox_loss: 0.0090  cls_loss: 0.0160  \n",
      "<<<iteration:[40/657] - total_loss: 0.3056  obj_loss: 0.1792  noobj_loss: 0.1484  bbox_loss: 0.0077  cls_loss: 0.0138  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<<<iteration:[60/657] - total_loss: 0.2986  obj_loss: 0.1807  noobj_loss: 0.1503  bbox_loss: 0.0061  cls_loss: 0.0122  \n",
      "<<<iteration:[80/657] - total_loss: 0.3128  obj_loss: 0.1749  noobj_loss: 0.1588  bbox_loss: 0.0075  cls_loss: 0.0212  \n",
      "<<<iteration:[100/657] - total_loss: 0.2949  obj_loss: 0.1725  noobj_loss: 0.1516  bbox_loss: 0.0066  cls_loss: 0.0134  \n",
      "<<<iteration:[120/657] - total_loss: 0.3010  obj_loss: 0.1764  noobj_loss: 0.1486  bbox_loss: 0.0070  cls_loss: 0.0152  \n",
      "<<<iteration:[140/657] - total_loss: 0.2980  obj_loss: 0.1723  noobj_loss: 0.1515  bbox_loss: 0.0070  cls_loss: 0.0149  \n",
      "<<<iteration:[160/657] - total_loss: 0.3121  obj_loss: 0.1857  noobj_loss: 0.1574  bbox_loss: 0.0062  cls_loss: 0.0165  \n",
      "<<<iteration:[180/657] - total_loss: 0.3011  obj_loss: 0.1810  noobj_loss: 0.1524  bbox_loss: 0.0063  cls_loss: 0.0122  \n",
      "<<<iteration:[200/657] - total_loss: 0.3076  obj_loss: 0.1816  noobj_loss: 0.1538  bbox_loss: 0.0069  cls_loss: 0.0145  \n",
      "<<<iteration:[220/657] - total_loss: 0.3009  obj_loss: 0.1765  noobj_loss: 0.1570  bbox_loss: 0.0065  cls_loss: 0.0136  \n",
      "<<<iteration:[240/657] - total_loss: 0.3023  obj_loss: 0.1722  noobj_loss: 0.1526  bbox_loss: 0.0071  cls_loss: 0.0185  \n",
      "<<<iteration:[260/657] - total_loss: 0.2940  obj_loss: 0.1693  noobj_loss: 0.1524  bbox_loss: 0.0068  cls_loss: 0.0144  \n",
      "<<<iteration:[280/657] - total_loss: 0.3055  obj_loss: 0.1813  noobj_loss: 0.1508  bbox_loss: 0.0073  cls_loss: 0.0125  \n",
      "<<<iteration:[300/657] - total_loss: 0.2961  obj_loss: 0.1766  noobj_loss: 0.1481  bbox_loss: 0.0065  cls_loss: 0.0130  \n",
      "<<<iteration:[320/657] - total_loss: 0.3093  obj_loss: 0.1819  noobj_loss: 0.1549  bbox_loss: 0.0063  cls_loss: 0.0182  \n",
      "<<<iteration:[340/657] - total_loss: 0.3153  obj_loss: 0.1915  noobj_loss: 0.1562  bbox_loss: 0.0064  cls_loss: 0.0134  \n",
      "<<<iteration:[360/657] - total_loss: 0.3037  obj_loss: 0.1792  noobj_loss: 0.1593  bbox_loss: 0.0061  cls_loss: 0.0145  \n",
      "<<<iteration:[380/657] - total_loss: 0.2923  obj_loss: 0.1727  noobj_loss: 0.1566  bbox_loss: 0.0061  cls_loss: 0.0110  \n",
      "<<<iteration:[400/657] - total_loss: 0.3062  obj_loss: 0.1802  noobj_loss: 0.1580  bbox_loss: 0.0062  cls_loss: 0.0159  \n",
      "<<<iteration:[420/657] - total_loss: 0.3064  obj_loss: 0.1823  noobj_loss: 0.1572  bbox_loss: 0.0064  cls_loss: 0.0136  \n",
      "<<<iteration:[440/657] - total_loss: 0.2927  obj_loss: 0.1692  noobj_loss: 0.1522  bbox_loss: 0.0072  cls_loss: 0.0115  \n",
      "<<<iteration:[460/657] - total_loss: 0.2813  obj_loss: 0.1595  noobj_loss: 0.1573  bbox_loss: 0.0062  cls_loss: 0.0122  \n",
      "<<<iteration:[480/657] - total_loss: 0.2972  obj_loss: 0.1765  noobj_loss: 0.1604  bbox_loss: 0.0061  cls_loss: 0.0103  \n",
      "<<<iteration:[500/657] - total_loss: 0.3068  obj_loss: 0.1775  noobj_loss: 0.1590  bbox_loss: 0.0074  cls_loss: 0.0127  \n",
      "<<<iteration:[520/657] - total_loss: 0.3108  obj_loss: 0.1790  noobj_loss: 0.1513  bbox_loss: 0.0075  cls_loss: 0.0187  \n",
      "<<<iteration:[540/657] - total_loss: 0.2963  obj_loss: 0.1753  noobj_loss: 0.1529  bbox_loss: 0.0064  cls_loss: 0.0126  \n",
      "<<<iteration:[560/657] - total_loss: 0.3064  obj_loss: 0.1846  noobj_loss: 0.1550  bbox_loss: 0.0057  cls_loss: 0.0159  \n",
      "<<<iteration:[580/657] - total_loss: 0.2953  obj_loss: 0.1735  noobj_loss: 0.1498  bbox_loss: 0.0064  cls_loss: 0.0151  \n",
      "<<<iteration:[600/657] - total_loss: 0.2925  obj_loss: 0.1627  noobj_loss: 0.1611  bbox_loss: 0.0064  cls_loss: 0.0174  \n",
      "<<<iteration:[620/657] - total_loss: 0.3042  obj_loss: 0.1833  noobj_loss: 0.1561  bbox_loss: 0.0059  cls_loss: 0.0133  \n",
      "<<<iteration:[640/657] - total_loss: 0.3057  obj_loss: 0.1824  noobj_loss: 0.1562  bbox_loss: 0.0066  cls_loss: 0.0123  \n",
      "\n",
      "epoch:47/100 - Train Loss: 0.3019, Val Loss: 0.3111\n",
      "\n",
      "<<<iteration:[20/657] - total_loss: 0.3165  obj_loss: 0.1896  noobj_loss: 0.1580  bbox_loss: 0.0071  cls_loss: 0.0123  \n",
      "<<<iteration:[40/657] - total_loss: 0.3008  obj_loss: 0.1747  noobj_loss: 0.1561  bbox_loss: 0.0067  cls_loss: 0.0145  \n",
      "<<<iteration:[60/657] - total_loss: 0.3077  obj_loss: 0.1835  noobj_loss: 0.1527  bbox_loss: 0.0067  cls_loss: 0.0142  \n",
      "<<<iteration:[80/657] - total_loss: 0.3040  obj_loss: 0.1752  noobj_loss: 0.1638  bbox_loss: 0.0065  cls_loss: 0.0145  \n",
      "<<<iteration:[100/657] - total_loss: 0.2962  obj_loss: 0.1672  noobj_loss: 0.1558  bbox_loss: 0.0072  cls_loss: 0.0152  \n",
      "<<<iteration:[120/657] - total_loss: 0.2977  obj_loss: 0.1719  noobj_loss: 0.1527  bbox_loss: 0.0068  cls_loss: 0.0155  \n",
      "<<<iteration:[140/657] - total_loss: 0.3081  obj_loss: 0.1844  noobj_loss: 0.1549  bbox_loss: 0.0064  cls_loss: 0.0141  \n",
      "<<<iteration:[160/657] - total_loss: 0.2943  obj_loss: 0.1703  noobj_loss: 0.1528  bbox_loss: 0.0069  cls_loss: 0.0128  \n",
      "<<<iteration:[180/657] - total_loss: 0.2816  obj_loss: 0.1644  noobj_loss: 0.1530  bbox_loss: 0.0061  cls_loss: 0.0101  \n",
      "<<<iteration:[200/657] - total_loss: 0.3045  obj_loss: 0.1809  noobj_loss: 0.1533  bbox_loss: 0.0065  cls_loss: 0.0144  \n",
      "<<<iteration:[220/657] - total_loss: 0.3045  obj_loss: 0.1824  noobj_loss: 0.1515  bbox_loss: 0.0071  cls_loss: 0.0109  \n",
      "<<<iteration:[240/657] - total_loss: 0.2978  obj_loss: 0.1767  noobj_loss: 0.1520  bbox_loss: 0.0065  cls_loss: 0.0124  \n",
      "<<<iteration:[260/657] - total_loss: 0.2999  obj_loss: 0.1751  noobj_loss: 0.1589  bbox_loss: 0.0065  cls_loss: 0.0126  \n",
      "<<<iteration:[280/657] - total_loss: 0.3033  obj_loss: 0.1788  noobj_loss: 0.1449  bbox_loss: 0.0073  cls_loss: 0.0156  \n",
      "<<<iteration:[300/657] - total_loss: 0.3021  obj_loss: 0.1785  noobj_loss: 0.1528  bbox_loss: 0.0069  cls_loss: 0.0128  \n",
      "<<<iteration:[320/657] - total_loss: 0.3095  obj_loss: 0.1867  noobj_loss: 0.1685  bbox_loss: 0.0056  cls_loss: 0.0104  \n",
      "<<<iteration:[340/657] - total_loss: 0.2996  obj_loss: 0.1794  noobj_loss: 0.1498  bbox_loss: 0.0069  cls_loss: 0.0106  \n",
      "<<<iteration:[360/657] - total_loss: 0.2810  obj_loss: 0.1646  noobj_loss: 0.1496  bbox_loss: 0.0065  cls_loss: 0.0091  \n",
      "<<<iteration:[380/657] - total_loss: 0.2993  obj_loss: 0.1735  noobj_loss: 0.1541  bbox_loss: 0.0066  cls_loss: 0.0158  \n",
      "<<<iteration:[400/657] - total_loss: 0.2813  obj_loss: 0.1606  noobj_loss: 0.1573  bbox_loss: 0.0063  cls_loss: 0.0108  \n",
      "<<<iteration:[420/657] - total_loss: 0.2984  obj_loss: 0.1764  noobj_loss: 0.1538  bbox_loss: 0.0063  cls_loss: 0.0135  \n",
      "<<<iteration:[440/657] - total_loss: 0.3149  obj_loss: 0.1888  noobj_loss: 0.1546  bbox_loss: 0.0067  cls_loss: 0.0153  \n",
      "<<<iteration:[460/657] - total_loss: 0.2949  obj_loss: 0.1742  noobj_loss: 0.1595  bbox_loss: 0.0062  cls_loss: 0.0100  \n",
      "<<<iteration:[480/657] - total_loss: 0.2818  obj_loss: 0.1568  noobj_loss: 0.1586  bbox_loss: 0.0066  cls_loss: 0.0129  \n",
      "<<<iteration:[500/657] - total_loss: 0.3014  obj_loss: 0.1718  noobj_loss: 0.1526  bbox_loss: 0.0065  cls_loss: 0.0209  \n",
      "<<<iteration:[520/657] - total_loss: 0.3045  obj_loss: 0.1777  noobj_loss: 0.1484  bbox_loss: 0.0073  cls_loss: 0.0162  \n",
      "<<<iteration:[540/657] - total_loss: 0.2981  obj_loss: 0.1779  noobj_loss: 0.1543  bbox_loss: 0.0063  cls_loss: 0.0115  \n",
      "<<<iteration:[560/657] - total_loss: 0.2935  obj_loss: 0.1756  noobj_loss: 0.1535  bbox_loss: 0.0060  cls_loss: 0.0112  \n",
      "<<<iteration:[580/657] - total_loss: 0.3059  obj_loss: 0.1875  noobj_loss: 0.1534  bbox_loss: 0.0059  cls_loss: 0.0122  \n",
      "<<<iteration:[600/657] - total_loss: 0.3010  obj_loss: 0.1755  noobj_loss: 0.1555  bbox_loss: 0.0068  cls_loss: 0.0136  \n",
      "<<<iteration:[620/657] - total_loss: 0.3036  obj_loss: 0.1748  noobj_loss: 0.1637  bbox_loss: 0.0068  cls_loss: 0.0127  \n",
      "<<<iteration:[640/657] - total_loss: 0.3022  obj_loss: 0.1749  noobj_loss: 0.1556  bbox_loss: 0.0065  cls_loss: 0.0172  \n",
      "\n",
      "epoch:48/100 - Train Loss: 0.2992, Val Loss: 0.3108\n",
      "\n",
      "<<<iteration:[20/657] - total_loss: 0.3307  obj_loss: 0.1997  noobj_loss: 0.1686  bbox_loss: 0.0070  cls_loss: 0.0115  \n",
      "<<<iteration:[40/657] - total_loss: 0.3076  obj_loss: 0.1755  noobj_loss: 0.1570  bbox_loss: 0.0073  cls_loss: 0.0171  \n",
      "<<<iteration:[60/657] - total_loss: 0.3124  obj_loss: 0.1885  noobj_loss: 0.1588  bbox_loss: 0.0063  cls_loss: 0.0128  \n",
      "<<<iteration:[80/657] - total_loss: 0.2942  obj_loss: 0.1701  noobj_loss: 0.1533  bbox_loss: 0.0069  cls_loss: 0.0127  \n",
      "<<<iteration:[100/657] - total_loss: 0.3121  obj_loss: 0.1907  noobj_loss: 0.1567  bbox_loss: 0.0062  cls_loss: 0.0121  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<<<iteration:[120/657] - total_loss: 0.3021  obj_loss: 0.1759  noobj_loss: 0.1500  bbox_loss: 0.0071  cls_loss: 0.0159  \n",
      "<<<iteration:[140/657] - total_loss: 0.2843  obj_loss: 0.1644  noobj_loss: 0.1568  bbox_loss: 0.0061  cls_loss: 0.0109  \n",
      "<<<iteration:[160/657] - total_loss: 0.3024  obj_loss: 0.1803  noobj_loss: 0.1514  bbox_loss: 0.0066  cls_loss: 0.0131  \n",
      "<<<iteration:[180/657] - total_loss: 0.3047  obj_loss: 0.1810  noobj_loss: 0.1558  bbox_loss: 0.0068  cls_loss: 0.0120  \n",
      "<<<iteration:[200/657] - total_loss: 0.2901  obj_loss: 0.1715  noobj_loss: 0.1514  bbox_loss: 0.0065  cls_loss: 0.0103  \n",
      "<<<iteration:[220/657] - total_loss: 0.2956  obj_loss: 0.1720  noobj_loss: 0.1547  bbox_loss: 0.0069  cls_loss: 0.0117  \n",
      "<<<iteration:[240/657] - total_loss: 0.3028  obj_loss: 0.1769  noobj_loss: 0.1555  bbox_loss: 0.0067  cls_loss: 0.0145  \n",
      "<<<iteration:[260/657] - total_loss: 0.2962  obj_loss: 0.1717  noobj_loss: 0.1578  bbox_loss: 0.0063  cls_loss: 0.0143  \n",
      "<<<iteration:[280/657] - total_loss: 0.3020  obj_loss: 0.1753  noobj_loss: 0.1582  bbox_loss: 0.0063  cls_loss: 0.0160  \n",
      "<<<iteration:[300/657] - total_loss: 0.2943  obj_loss: 0.1638  noobj_loss: 0.1483  bbox_loss: 0.0078  cls_loss: 0.0172  \n",
      "<<<iteration:[320/657] - total_loss: 0.3080  obj_loss: 0.1847  noobj_loss: 0.1550  bbox_loss: 0.0068  cls_loss: 0.0117  \n",
      "<<<iteration:[340/657] - total_loss: 0.3026  obj_loss: 0.1819  noobj_loss: 0.1584  bbox_loss: 0.0059  cls_loss: 0.0119  \n",
      "<<<iteration:[360/657] - total_loss: 0.3019  obj_loss: 0.1826  noobj_loss: 0.1524  bbox_loss: 0.0062  cls_loss: 0.0121  \n",
      "<<<iteration:[380/657] - total_loss: 0.3076  obj_loss: 0.1874  noobj_loss: 0.1484  bbox_loss: 0.0063  cls_loss: 0.0143  \n",
      "<<<iteration:[400/657] - total_loss: 0.3011  obj_loss: 0.1780  noobj_loss: 0.1585  bbox_loss: 0.0061  cls_loss: 0.0132  \n",
      "<<<iteration:[420/657] - total_loss: 0.2856  obj_loss: 0.1562  noobj_loss: 0.1549  bbox_loss: 0.0072  cls_loss: 0.0160  \n",
      "<<<iteration:[440/657] - total_loss: 0.2923  obj_loss: 0.1662  noobj_loss: 0.1599  bbox_loss: 0.0065  cls_loss: 0.0138  \n",
      "<<<iteration:[460/657] - total_loss: 0.3018  obj_loss: 0.1825  noobj_loss: 0.1548  bbox_loss: 0.0062  cls_loss: 0.0110  \n",
      "<<<iteration:[480/657] - total_loss: 0.3044  obj_loss: 0.1779  noobj_loss: 0.1613  bbox_loss: 0.0059  cls_loss: 0.0161  \n",
      "<<<iteration:[500/657] - total_loss: 0.3004  obj_loss: 0.1633  noobj_loss: 0.1589  bbox_loss: 0.0077  cls_loss: 0.0194  \n",
      "<<<iteration:[520/657] - total_loss: 0.2978  obj_loss: 0.1726  noobj_loss: 0.1593  bbox_loss: 0.0066  cls_loss: 0.0123  \n",
      "<<<iteration:[540/657] - total_loss: 0.2940  obj_loss: 0.1730  noobj_loss: 0.1491  bbox_loss: 0.0066  cls_loss: 0.0135  \n",
      "<<<iteration:[560/657] - total_loss: 0.3069  obj_loss: 0.1880  noobj_loss: 0.1492  bbox_loss: 0.0061  cls_loss: 0.0137  \n",
      "<<<iteration:[580/657] - total_loss: 0.2948  obj_loss: 0.1729  noobj_loss: 0.1587  bbox_loss: 0.0064  cls_loss: 0.0105  \n",
      "<<<iteration:[600/657] - total_loss: 0.2971  obj_loss: 0.1772  noobj_loss: 0.1616  bbox_loss: 0.0058  cls_loss: 0.0102  \n",
      "<<<iteration:[620/657] - total_loss: 0.3016  obj_loss: 0.1734  noobj_loss: 0.1628  bbox_loss: 0.0064  cls_loss: 0.0146  \n",
      "<<<iteration:[640/657] - total_loss: 0.2982  obj_loss: 0.1697  noobj_loss: 0.1618  bbox_loss: 0.0069  cls_loss: 0.0132  \n",
      "\n",
      "epoch:49/100 - Train Loss: 0.3003, Val Loss: 0.3137\n",
      "\n",
      "<<<iteration:[20/657] - total_loss: 0.3126  obj_loss: 0.1771  noobj_loss: 0.1712  bbox_loss: 0.0066  cls_loss: 0.0170  \n",
      "<<<iteration:[40/657] - total_loss: 0.2995  obj_loss: 0.1756  noobj_loss: 0.1607  bbox_loss: 0.0061  cls_loss: 0.0133  \n",
      "<<<iteration:[60/657] - total_loss: 0.2977  obj_loss: 0.1682  noobj_loss: 0.1610  bbox_loss: 0.0071  cls_loss: 0.0134  \n",
      "<<<iteration:[80/657] - total_loss: 0.2912  obj_loss: 0.1748  noobj_loss: 0.1518  bbox_loss: 0.0060  cls_loss: 0.0105  \n",
      "<<<iteration:[100/657] - total_loss: 0.3007  obj_loss: 0.1667  noobj_loss: 0.1633  bbox_loss: 0.0067  cls_loss: 0.0189  \n",
      "<<<iteration:[120/657] - total_loss: 0.2981  obj_loss: 0.1751  noobj_loss: 0.1597  bbox_loss: 0.0065  cls_loss: 0.0106  \n",
      "<<<iteration:[140/657] - total_loss: 0.2924  obj_loss: 0.1749  noobj_loss: 0.1484  bbox_loss: 0.0061  cls_loss: 0.0125  \n",
      "<<<iteration:[160/657] - total_loss: 0.3132  obj_loss: 0.1933  noobj_loss: 0.1656  bbox_loss: 0.0052  cls_loss: 0.0113  \n",
      "<<<iteration:[180/657] - total_loss: 0.2984  obj_loss: 0.1743  noobj_loss: 0.1566  bbox_loss: 0.0068  cls_loss: 0.0119  \n",
      "<<<iteration:[200/657] - total_loss: 0.2929  obj_loss: 0.1733  noobj_loss: 0.1558  bbox_loss: 0.0061  cls_loss: 0.0111  \n",
      "<<<iteration:[220/657] - total_loss: 0.3049  obj_loss: 0.1843  noobj_loss: 0.1646  bbox_loss: 0.0057  cls_loss: 0.0099  \n",
      "<<<iteration:[240/657] - total_loss: 0.2849  obj_loss: 0.1623  noobj_loss: 0.1546  bbox_loss: 0.0067  cls_loss: 0.0117  \n",
      "<<<iteration:[260/657] - total_loss: 0.3068  obj_loss: 0.1816  noobj_loss: 0.1561  bbox_loss: 0.0065  cls_loss: 0.0144  \n",
      "<<<iteration:[280/657] - total_loss: 0.3042  obj_loss: 0.1769  noobj_loss: 0.1626  bbox_loss: 0.0067  cls_loss: 0.0124  \n",
      "<<<iteration:[300/657] - total_loss: 0.3005  obj_loss: 0.1702  noobj_loss: 0.1601  bbox_loss: 0.0067  cls_loss: 0.0167  \n",
      "<<<iteration:[320/657] - total_loss: 0.3031  obj_loss: 0.1792  noobj_loss: 0.1570  bbox_loss: 0.0070  cls_loss: 0.0105  \n",
      "<<<iteration:[340/657] - total_loss: 0.3004  obj_loss: 0.1723  noobj_loss: 0.1570  bbox_loss: 0.0072  cls_loss: 0.0138  \n",
      "<<<iteration:[360/657] - total_loss: 0.3045  obj_loss: 0.1828  noobj_loss: 0.1565  bbox_loss: 0.0065  cls_loss: 0.0112  \n",
      "<<<iteration:[380/657] - total_loss: 0.3011  obj_loss: 0.1849  noobj_loss: 0.1536  bbox_loss: 0.0055  cls_loss: 0.0121  \n",
      "<<<iteration:[400/657] - total_loss: 0.2904  obj_loss: 0.1684  noobj_loss: 0.1559  bbox_loss: 0.0065  cls_loss: 0.0116  \n",
      "<<<iteration:[420/657] - total_loss: 0.3058  obj_loss: 0.1832  noobj_loss: 0.1598  bbox_loss: 0.0059  cls_loss: 0.0131  \n",
      "<<<iteration:[440/657] - total_loss: 0.2912  obj_loss: 0.1708  noobj_loss: 0.1553  bbox_loss: 0.0063  cls_loss: 0.0113  \n",
      "<<<iteration:[460/657] - total_loss: 0.3006  obj_loss: 0.1758  noobj_loss: 0.1566  bbox_loss: 0.0063  cls_loss: 0.0150  \n",
      "<<<iteration:[480/657] - total_loss: 0.3073  obj_loss: 0.1835  noobj_loss: 0.1539  bbox_loss: 0.0064  cls_loss: 0.0146  \n",
      "<<<iteration:[500/657] - total_loss: 0.2969  obj_loss: 0.1691  noobj_loss: 0.1552  bbox_loss: 0.0066  cls_loss: 0.0172  \n",
      "<<<iteration:[520/657] - total_loss: 0.3009  obj_loss: 0.1792  noobj_loss: 0.1604  bbox_loss: 0.0059  cls_loss: 0.0118  \n",
      "<<<iteration:[540/657] - total_loss: 0.3032  obj_loss: 0.1793  noobj_loss: 0.1569  bbox_loss: 0.0064  cls_loss: 0.0133  \n",
      "<<<iteration:[560/657] - total_loss: 0.3115  obj_loss: 0.1868  noobj_loss: 0.1553  bbox_loss: 0.0064  cls_loss: 0.0150  \n",
      "<<<iteration:[580/657] - total_loss: 0.2959  obj_loss: 0.1705  noobj_loss: 0.1625  bbox_loss: 0.0063  cls_loss: 0.0127  \n",
      "<<<iteration:[600/657] - total_loss: 0.2890  obj_loss: 0.1654  noobj_loss: 0.1604  bbox_loss: 0.0063  cls_loss: 0.0117  \n",
      "<<<iteration:[620/657] - total_loss: 0.2972  obj_loss: 0.1734  noobj_loss: 0.1630  bbox_loss: 0.0062  cls_loss: 0.0115  \n",
      "<<<iteration:[640/657] - total_loss: 0.2985  obj_loss: 0.1786  noobj_loss: 0.1560  bbox_loss: 0.0060  cls_loss: 0.0117  \n",
      "\n",
      "epoch:50/100 - Train Loss: 0.2996, Val Loss: 0.3112\n",
      "\n",
      "<<<iteration:[20/657] - total_loss: 0.3114  obj_loss: 0.1870  noobj_loss: 0.1659  bbox_loss: 0.0059  cls_loss: 0.0118  \n",
      "<<<iteration:[40/657] - total_loss: 0.2966  obj_loss: 0.1764  noobj_loss: 0.1579  bbox_loss: 0.0060  cls_loss: 0.0111  \n",
      "<<<iteration:[60/657] - total_loss: 0.3024  obj_loss: 0.1797  noobj_loss: 0.1522  bbox_loss: 0.0065  cls_loss: 0.0139  \n",
      "<<<iteration:[80/657] - total_loss: 0.2913  obj_loss: 0.1721  noobj_loss: 0.1528  bbox_loss: 0.0058  cls_loss: 0.0140  \n",
      "<<<iteration:[100/657] - total_loss: 0.2843  obj_loss: 0.1644  noobj_loss: 0.1584  bbox_loss: 0.0062  cls_loss: 0.0100  \n",
      "<<<iteration:[120/657] - total_loss: 0.2986  obj_loss: 0.1762  noobj_loss: 0.1585  bbox_loss: 0.0063  cls_loss: 0.0116  \n",
      "<<<iteration:[140/657] - total_loss: 0.2816  obj_loss: 0.1612  noobj_loss: 0.1569  bbox_loss: 0.0062  cls_loss: 0.0110  \n",
      "<<<iteration:[160/657] - total_loss: 0.3121  obj_loss: 0.1814  noobj_loss: 0.1552  bbox_loss: 0.0069  cls_loss: 0.0185  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<<<iteration:[180/657] - total_loss: 0.3017  obj_loss: 0.1755  noobj_loss: 0.1626  bbox_loss: 0.0065  cls_loss: 0.0124  \n",
      "<<<iteration:[200/657] - total_loss: 0.2865  obj_loss: 0.1633  noobj_loss: 0.1558  bbox_loss: 0.0060  cls_loss: 0.0153  \n",
      "<<<iteration:[220/657] - total_loss: 0.3018  obj_loss: 0.1728  noobj_loss: 0.1570  bbox_loss: 0.0070  cls_loss: 0.0157  \n",
      "<<<iteration:[240/657] - total_loss: 0.3024  obj_loss: 0.1790  noobj_loss: 0.1556  bbox_loss: 0.0066  cls_loss: 0.0128  \n",
      "<<<iteration:[260/657] - total_loss: 0.3025  obj_loss: 0.1779  noobj_loss: 0.1646  bbox_loss: 0.0060  cls_loss: 0.0124  \n",
      "<<<iteration:[280/657] - total_loss: 0.3047  obj_loss: 0.1784  noobj_loss: 0.1557  bbox_loss: 0.0062  cls_loss: 0.0175  \n",
      "<<<iteration:[300/657] - total_loss: 0.3023  obj_loss: 0.1767  noobj_loss: 0.1574  bbox_loss: 0.0067  cls_loss: 0.0134  \n",
      "<<<iteration:[320/657] - total_loss: 0.3014  obj_loss: 0.1717  noobj_loss: 0.1607  bbox_loss: 0.0068  cls_loss: 0.0155  \n",
      "<<<iteration:[340/657] - total_loss: 0.2956  obj_loss: 0.1709  noobj_loss: 0.1561  bbox_loss: 0.0066  cls_loss: 0.0134  \n",
      "<<<iteration:[360/657] - total_loss: 0.3133  obj_loss: 0.1874  noobj_loss: 0.1561  bbox_loss: 0.0068  cls_loss: 0.0141  \n",
      "<<<iteration:[380/657] - total_loss: 0.2877  obj_loss: 0.1658  noobj_loss: 0.1602  bbox_loss: 0.0058  cls_loss: 0.0128  \n",
      "<<<iteration:[400/657] - total_loss: 0.2973  obj_loss: 0.1736  noobj_loss: 0.1628  bbox_loss: 0.0061  cls_loss: 0.0120  \n",
      "<<<iteration:[420/657] - total_loss: 0.3142  obj_loss: 0.1823  noobj_loss: 0.1648  bbox_loss: 0.0068  cls_loss: 0.0156  \n",
      "<<<iteration:[440/657] - total_loss: 0.2940  obj_loss: 0.1694  noobj_loss: 0.1567  bbox_loss: 0.0064  cls_loss: 0.0144  \n",
      "<<<iteration:[460/657] - total_loss: 0.2953  obj_loss: 0.1706  noobj_loss: 0.1620  bbox_loss: 0.0064  cls_loss: 0.0118  \n",
      "<<<iteration:[480/657] - total_loss: 0.2953  obj_loss: 0.1719  noobj_loss: 0.1586  bbox_loss: 0.0058  cls_loss: 0.0151  \n",
      "<<<iteration:[500/657] - total_loss: 0.2885  obj_loss: 0.1695  noobj_loss: 0.1580  bbox_loss: 0.0060  cls_loss: 0.0101  \n",
      "<<<iteration:[520/657] - total_loss: 0.2995  obj_loss: 0.1783  noobj_loss: 0.1536  bbox_loss: 0.0067  cls_loss: 0.0109  \n",
      "<<<iteration:[540/657] - total_loss: 0.3084  obj_loss: 0.1848  noobj_loss: 0.1637  bbox_loss: 0.0061  cls_loss: 0.0112  \n",
      "<<<iteration:[560/657] - total_loss: 0.3084  obj_loss: 0.1833  noobj_loss: 0.1607  bbox_loss: 0.0059  cls_loss: 0.0151  \n",
      "<<<iteration:[580/657] - total_loss: 0.3153  obj_loss: 0.1881  noobj_loss: 0.1635  bbox_loss: 0.0070  cls_loss: 0.0107  \n",
      "<<<iteration:[600/657] - total_loss: 0.2992  obj_loss: 0.1722  noobj_loss: 0.1663  bbox_loss: 0.0068  cls_loss: 0.0099  \n",
      "<<<iteration:[620/657] - total_loss: 0.2878  obj_loss: 0.1704  noobj_loss: 0.1568  bbox_loss: 0.0060  cls_loss: 0.0091  \n",
      "<<<iteration:[640/657] - total_loss: 0.2931  obj_loss: 0.1690  noobj_loss: 0.1600  bbox_loss: 0.0066  cls_loss: 0.0113  \n",
      "\n",
      "epoch:51/100 - Train Loss: 0.2991, Val Loss: 0.3109\n",
      "\n",
      "<<<iteration:[20/657] - total_loss: 0.3163  obj_loss: 0.1927  noobj_loss: 0.1618  bbox_loss: 0.0060  cls_loss: 0.0127  \n",
      "<<<iteration:[40/657] - total_loss: 0.2920  obj_loss: 0.1715  noobj_loss: 0.1548  bbox_loss: 0.0062  cls_loss: 0.0121  \n",
      "<<<iteration:[60/657] - total_loss: 0.2874  obj_loss: 0.1656  noobj_loss: 0.1529  bbox_loss: 0.0068  cls_loss: 0.0114  \n",
      "<<<iteration:[80/657] - total_loss: 0.3038  obj_loss: 0.1782  noobj_loss: 0.1539  bbox_loss: 0.0061  cls_loss: 0.0180  \n",
      "<<<iteration:[100/657] - total_loss: 0.2960  obj_loss: 0.1736  noobj_loss: 0.1603  bbox_loss: 0.0058  cls_loss: 0.0134  \n",
      "<<<iteration:[120/657] - total_loss: 0.2956  obj_loss: 0.1763  noobj_loss: 0.1599  bbox_loss: 0.0058  cls_loss: 0.0105  \n",
      "<<<iteration:[140/657] - total_loss: 0.2998  obj_loss: 0.1733  noobj_loss: 0.1630  bbox_loss: 0.0064  cls_loss: 0.0129  \n",
      "<<<iteration:[160/657] - total_loss: 0.3109  obj_loss: 0.1800  noobj_loss: 0.1657  bbox_loss: 0.0062  cls_loss: 0.0173  \n",
      "<<<iteration:[180/657] - total_loss: 0.2847  obj_loss: 0.1648  noobj_loss: 0.1574  bbox_loss: 0.0062  cls_loss: 0.0104  \n",
      "<<<iteration:[200/657] - total_loss: 0.3087  obj_loss: 0.1801  noobj_loss: 0.1617  bbox_loss: 0.0072  cls_loss: 0.0120  \n",
      "<<<iteration:[220/657] - total_loss: 0.2796  obj_loss: 0.1551  noobj_loss: 0.1561  bbox_loss: 0.0068  cls_loss: 0.0123  \n",
      "<<<iteration:[240/657] - total_loss: 0.3105  obj_loss: 0.1852  noobj_loss: 0.1641  bbox_loss: 0.0058  cls_loss: 0.0141  \n",
      "<<<iteration:[260/657] - total_loss: 0.2961  obj_loss: 0.1735  noobj_loss: 0.1564  bbox_loss: 0.0062  cls_loss: 0.0132  \n",
      "<<<iteration:[280/657] - total_loss: 0.3088  obj_loss: 0.1827  noobj_loss: 0.1633  bbox_loss: 0.0064  cls_loss: 0.0126  \n",
      "<<<iteration:[300/657] - total_loss: 0.2922  obj_loss: 0.1679  noobj_loss: 0.1580  bbox_loss: 0.0064  cls_loss: 0.0133  \n",
      "<<<iteration:[320/657] - total_loss: 0.3025  obj_loss: 0.1741  noobj_loss: 0.1584  bbox_loss: 0.0066  cls_loss: 0.0161  \n",
      "<<<iteration:[340/657] - total_loss: 0.2966  obj_loss: 0.1669  noobj_loss: 0.1692  bbox_loss: 0.0061  cls_loss: 0.0145  \n",
      "<<<iteration:[360/657] - total_loss: 0.3087  obj_loss: 0.1836  noobj_loss: 0.1618  bbox_loss: 0.0062  cls_loss: 0.0130  \n",
      "<<<iteration:[380/657] - total_loss: 0.2911  obj_loss: 0.1655  noobj_loss: 0.1535  bbox_loss: 0.0075  cls_loss: 0.0116  \n",
      "<<<iteration:[400/657] - total_loss: 0.3017  obj_loss: 0.1820  noobj_loss: 0.1538  bbox_loss: 0.0063  cls_loss: 0.0113  \n",
      "<<<iteration:[420/657] - total_loss: 0.3015  obj_loss: 0.1781  noobj_loss: 0.1596  bbox_loss: 0.0061  cls_loss: 0.0131  \n",
      "<<<iteration:[440/657] - total_loss: 0.3106  obj_loss: 0.1847  noobj_loss: 0.1627  bbox_loss: 0.0060  cls_loss: 0.0144  \n",
      "<<<iteration:[460/657] - total_loss: 0.2997  obj_loss: 0.1860  noobj_loss: 0.1559  bbox_loss: 0.0051  cls_loss: 0.0101  \n",
      "<<<iteration:[480/657] - total_loss: 0.3112  obj_loss: 0.1809  noobj_loss: 0.1499  bbox_loss: 0.0075  cls_loss: 0.0179  \n",
      "<<<iteration:[500/657] - total_loss: 0.2990  obj_loss: 0.1685  noobj_loss: 0.1693  bbox_loss: 0.0063  cls_loss: 0.0144  \n",
      "<<<iteration:[520/657] - total_loss: 0.3062  obj_loss: 0.1842  noobj_loss: 0.1608  bbox_loss: 0.0056  cls_loss: 0.0138  \n",
      "<<<iteration:[540/657] - total_loss: 0.2936  obj_loss: 0.1663  noobj_loss: 0.1626  bbox_loss: 0.0067  cls_loss: 0.0125  \n",
      "<<<iteration:[560/657] - total_loss: 0.3003  obj_loss: 0.1795  noobj_loss: 0.1627  bbox_loss: 0.0060  cls_loss: 0.0093  \n",
      "<<<iteration:[580/657] - total_loss: 0.2991  obj_loss: 0.1718  noobj_loss: 0.1586  bbox_loss: 0.0070  cls_loss: 0.0127  \n",
      "<<<iteration:[600/657] - total_loss: 0.2847  obj_loss: 0.1655  noobj_loss: 0.1544  bbox_loss: 0.0062  cls_loss: 0.0109  \n",
      "<<<iteration:[620/657] - total_loss: 0.3086  obj_loss: 0.1796  noobj_loss: 0.1646  bbox_loss: 0.0064  cls_loss: 0.0146  \n",
      "<<<iteration:[640/657] - total_loss: 0.2986  obj_loss: 0.1717  noobj_loss: 0.1674  bbox_loss: 0.0065  cls_loss: 0.0106  \n",
      "\n",
      "epoch:52/100 - Train Loss: 0.2990, Val Loss: 0.3135\n",
      "\n",
      "<<<iteration:[20/657] - total_loss: 0.3052  obj_loss: 0.1801  noobj_loss: 0.1640  bbox_loss: 0.0060  cls_loss: 0.0128  \n",
      "<<<iteration:[40/657] - total_loss: 0.3150  obj_loss: 0.1907  noobj_loss: 0.1554  bbox_loss: 0.0060  cls_loss: 0.0164  \n",
      "<<<iteration:[60/657] - total_loss: 0.2937  obj_loss: 0.1743  noobj_loss: 0.1488  bbox_loss: 0.0066  cls_loss: 0.0122  \n",
      "<<<iteration:[80/657] - total_loss: 0.2994  obj_loss: 0.1734  noobj_loss: 0.1632  bbox_loss: 0.0061  cls_loss: 0.0137  \n",
      "<<<iteration:[100/657] - total_loss: 0.2978  obj_loss: 0.1786  noobj_loss: 0.1640  bbox_loss: 0.0053  cls_loss: 0.0104  \n",
      "<<<iteration:[120/657] - total_loss: 0.2923  obj_loss: 0.1638  noobj_loss: 0.1601  bbox_loss: 0.0071  cls_loss: 0.0128  \n",
      "<<<iteration:[140/657] - total_loss: 0.3045  obj_loss: 0.1752  noobj_loss: 0.1642  bbox_loss: 0.0060  cls_loss: 0.0170  \n",
      "<<<iteration:[160/657] - total_loss: 0.3043  obj_loss: 0.1822  noobj_loss: 0.1522  bbox_loss: 0.0065  cls_loss: 0.0136  \n",
      "<<<iteration:[180/657] - total_loss: 0.2961  obj_loss: 0.1806  noobj_loss: 0.1519  bbox_loss: 0.0062  cls_loss: 0.0085  \n",
      "<<<iteration:[200/657] - total_loss: 0.2968  obj_loss: 0.1727  noobj_loss: 0.1652  bbox_loss: 0.0060  cls_loss: 0.0116  \n",
      "<<<iteration:[220/657] - total_loss: 0.2885  obj_loss: 0.1627  noobj_loss: 0.1584  bbox_loss: 0.0068  cls_loss: 0.0128  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<<<iteration:[240/657] - total_loss: 0.2949  obj_loss: 0.1705  noobj_loss: 0.1526  bbox_loss: 0.0073  cls_loss: 0.0114  \n",
      "<<<iteration:[260/657] - total_loss: 0.2894  obj_loss: 0.1711  noobj_loss: 0.1589  bbox_loss: 0.0063  cls_loss: 0.0075  \n",
      "<<<iteration:[280/657] - total_loss: 0.2960  obj_loss: 0.1727  noobj_loss: 0.1609  bbox_loss: 0.0062  cls_loss: 0.0116  \n",
      "<<<iteration:[300/657] - total_loss: 0.2854  obj_loss: 0.1644  noobj_loss: 0.1615  bbox_loss: 0.0062  cls_loss: 0.0093  \n",
      "<<<iteration:[320/657] - total_loss: 0.2977  obj_loss: 0.1760  noobj_loss: 0.1563  bbox_loss: 0.0063  cls_loss: 0.0119  \n",
      "<<<iteration:[340/657] - total_loss: 0.3005  obj_loss: 0.1757  noobj_loss: 0.1578  bbox_loss: 0.0063  cls_loss: 0.0146  \n",
      "<<<iteration:[360/657] - total_loss: 0.2941  obj_loss: 0.1734  noobj_loss: 0.1582  bbox_loss: 0.0062  cls_loss: 0.0108  \n",
      "<<<iteration:[380/657] - total_loss: 0.3044  obj_loss: 0.1827  noobj_loss: 0.1608  bbox_loss: 0.0062  cls_loss: 0.0101  \n",
      "<<<iteration:[400/657] - total_loss: 0.3073  obj_loss: 0.1853  noobj_loss: 0.1613  bbox_loss: 0.0060  cls_loss: 0.0112  \n",
      "<<<iteration:[420/657] - total_loss: 0.2991  obj_loss: 0.1744  noobj_loss: 0.1672  bbox_loss: 0.0062  cls_loss: 0.0103  \n",
      "<<<iteration:[440/657] - total_loss: 0.2921  obj_loss: 0.1737  noobj_loss: 0.1607  bbox_loss: 0.0055  cls_loss: 0.0109  \n",
      "<<<iteration:[460/657] - total_loss: 0.2934  obj_loss: 0.1613  noobj_loss: 0.1575  bbox_loss: 0.0075  cls_loss: 0.0160  \n",
      "<<<iteration:[480/657] - total_loss: 0.2954  obj_loss: 0.1709  noobj_loss: 0.1661  bbox_loss: 0.0056  cls_loss: 0.0132  \n",
      "<<<iteration:[500/657] - total_loss: 0.2886  obj_loss: 0.1645  noobj_loss: 0.1548  bbox_loss: 0.0065  cls_loss: 0.0140  \n",
      "<<<iteration:[520/657] - total_loss: 0.3001  obj_loss: 0.1776  noobj_loss: 0.1594  bbox_loss: 0.0060  cls_loss: 0.0127  \n",
      "<<<iteration:[540/657] - total_loss: 0.2920  obj_loss: 0.1639  noobj_loss: 0.1671  bbox_loss: 0.0060  cls_loss: 0.0147  \n",
      "<<<iteration:[560/657] - total_loss: 0.3020  obj_loss: 0.1841  noobj_loss: 0.1580  bbox_loss: 0.0062  cls_loss: 0.0080  \n",
      "<<<iteration:[580/657] - total_loss: 0.2852  obj_loss: 0.1587  noobj_loss: 0.1584  bbox_loss: 0.0066  cls_loss: 0.0141  \n",
      "<<<iteration:[600/657] - total_loss: 0.3001  obj_loss: 0.1775  noobj_loss: 0.1570  bbox_loss: 0.0062  cls_loss: 0.0131  \n",
      "<<<iteration:[620/657] - total_loss: 0.3029  obj_loss: 0.1736  noobj_loss: 0.1536  bbox_loss: 0.0072  cls_loss: 0.0165  \n",
      "<<<iteration:[640/657] - total_loss: 0.2935  obj_loss: 0.1732  noobj_loss: 0.1586  bbox_loss: 0.0061  cls_loss: 0.0106  \n",
      "\n",
      "epoch:53/100 - Train Loss: 0.2968, Val Loss: 0.3120\n",
      "\n",
      "<<<iteration:[20/657] - total_loss: 0.3219  obj_loss: 0.1846  noobj_loss: 0.1667  bbox_loss: 0.0073  cls_loss: 0.0177  \n",
      "<<<iteration:[40/657] - total_loss: 0.2918  obj_loss: 0.1703  noobj_loss: 0.1605  bbox_loss: 0.0057  cls_loss: 0.0126  \n",
      "<<<iteration:[60/657] - total_loss: 0.3120  obj_loss: 0.1814  noobj_loss: 0.1620  bbox_loss: 0.0067  cls_loss: 0.0161  \n",
      "<<<iteration:[80/657] - total_loss: 0.2954  obj_loss: 0.1747  noobj_loss: 0.1527  bbox_loss: 0.0064  cls_loss: 0.0121  \n",
      "<<<iteration:[100/657] - total_loss: 0.3083  obj_loss: 0.1790  noobj_loss: 0.1641  bbox_loss: 0.0068  cls_loss: 0.0135  \n",
      "<<<iteration:[120/657] - total_loss: 0.2959  obj_loss: 0.1704  noobj_loss: 0.1597  bbox_loss: 0.0064  cls_loss: 0.0139  \n",
      "<<<iteration:[140/657] - total_loss: 0.3069  obj_loss: 0.1857  noobj_loss: 0.1546  bbox_loss: 0.0063  cls_loss: 0.0124  \n",
      "<<<iteration:[160/657] - total_loss: 0.2850  obj_loss: 0.1675  noobj_loss: 0.1595  bbox_loss: 0.0057  cls_loss: 0.0092  \n",
      "<<<iteration:[180/657] - total_loss: 0.3057  obj_loss: 0.1865  noobj_loss: 0.1598  bbox_loss: 0.0056  cls_loss: 0.0114  \n",
      "<<<iteration:[200/657] - total_loss: 0.2950  obj_loss: 0.1773  noobj_loss: 0.1600  bbox_loss: 0.0053  cls_loss: 0.0110  \n",
      "<<<iteration:[220/657] - total_loss: 0.3052  obj_loss: 0.1811  noobj_loss: 0.1586  bbox_loss: 0.0063  cls_loss: 0.0134  \n",
      "<<<iteration:[240/657] - total_loss: 0.2985  obj_loss: 0.1802  noobj_loss: 0.1608  bbox_loss: 0.0053  cls_loss: 0.0115  \n",
      "<<<iteration:[260/657] - total_loss: 0.3014  obj_loss: 0.1725  noobj_loss: 0.1639  bbox_loss: 0.0070  cls_loss: 0.0120  \n",
      "<<<iteration:[280/657] - total_loss: 0.3042  obj_loss: 0.1803  noobj_loss: 0.1531  bbox_loss: 0.0067  cls_loss: 0.0136  \n",
      "<<<iteration:[300/657] - total_loss: 0.2822  obj_loss: 0.1624  noobj_loss: 0.1627  bbox_loss: 0.0060  cls_loss: 0.0086  \n",
      "<<<iteration:[320/657] - total_loss: 0.2889  obj_loss: 0.1633  noobj_loss: 0.1557  bbox_loss: 0.0071  cls_loss: 0.0121  \n",
      "<<<iteration:[340/657] - total_loss: 0.2991  obj_loss: 0.1784  noobj_loss: 0.1633  bbox_loss: 0.0058  cls_loss: 0.0102  \n",
      "<<<iteration:[360/657] - total_loss: 0.2935  obj_loss: 0.1726  noobj_loss: 0.1602  bbox_loss: 0.0059  cls_loss: 0.0113  \n",
      "<<<iteration:[380/657] - total_loss: 0.2816  obj_loss: 0.1573  noobj_loss: 0.1621  bbox_loss: 0.0067  cls_loss: 0.0096  \n",
      "<<<iteration:[400/657] - total_loss: 0.2988  obj_loss: 0.1666  noobj_loss: 0.1573  bbox_loss: 0.0067  cls_loss: 0.0202  \n",
      "<<<iteration:[420/657] - total_loss: 0.2959  obj_loss: 0.1775  noobj_loss: 0.1576  bbox_loss: 0.0058  cls_loss: 0.0105  \n",
      "<<<iteration:[440/657] - total_loss: 0.2991  obj_loss: 0.1715  noobj_loss: 0.1675  bbox_loss: 0.0065  cls_loss: 0.0115  \n",
      "<<<iteration:[460/657] - total_loss: 0.2827  obj_loss: 0.1628  noobj_loss: 0.1620  bbox_loss: 0.0056  cls_loss: 0.0107  \n",
      "<<<iteration:[480/657] - total_loss: 0.2922  obj_loss: 0.1719  noobj_loss: 0.1651  bbox_loss: 0.0056  cls_loss: 0.0097  \n",
      "<<<iteration:[500/657] - total_loss: 0.2988  obj_loss: 0.1757  noobj_loss: 0.1648  bbox_loss: 0.0057  cls_loss: 0.0120  \n",
      "<<<iteration:[520/657] - total_loss: 0.3027  obj_loss: 0.1842  noobj_loss: 0.1658  bbox_loss: 0.0055  cls_loss: 0.0082  \n",
      "<<<iteration:[540/657] - total_loss: 0.2858  obj_loss: 0.1650  noobj_loss: 0.1545  bbox_loss: 0.0068  cls_loss: 0.0093  \n",
      "<<<iteration:[560/657] - total_loss: 0.2878  obj_loss: 0.1699  noobj_loss: 0.1559  bbox_loss: 0.0059  cls_loss: 0.0105  \n",
      "<<<iteration:[580/657] - total_loss: 0.2989  obj_loss: 0.1810  noobj_loss: 0.1577  bbox_loss: 0.0057  cls_loss: 0.0106  \n",
      "<<<iteration:[600/657] - total_loss: 0.2752  obj_loss: 0.1555  noobj_loss: 0.1606  bbox_loss: 0.0061  cls_loss: 0.0090  \n",
      "<<<iteration:[620/657] - total_loss: 0.3085  obj_loss: 0.1835  noobj_loss: 0.1627  bbox_loss: 0.0061  cls_loss: 0.0132  \n",
      "<<<iteration:[640/657] - total_loss: 0.2935  obj_loss: 0.1704  noobj_loss: 0.1664  bbox_loss: 0.0058  cls_loss: 0.0107  \n",
      "\n",
      "epoch:54/100 - Train Loss: 0.2964, Val Loss: 0.3026\n",
      "\n",
      "<<<iteration:[20/657] - total_loss: 0.3098  obj_loss: 0.1812  noobj_loss: 0.1695  bbox_loss: 0.0063  cls_loss: 0.0124  \n",
      "<<<iteration:[40/657] - total_loss: 0.3093  obj_loss: 0.1830  noobj_loss: 0.1645  bbox_loss: 0.0057  cls_loss: 0.0157  \n",
      "<<<iteration:[60/657] - total_loss: 0.2964  obj_loss: 0.1659  noobj_loss: 0.1647  bbox_loss: 0.0057  cls_loss: 0.0198  \n",
      "<<<iteration:[80/657] - total_loss: 0.3029  obj_loss: 0.1825  noobj_loss: 0.1511  bbox_loss: 0.0064  cls_loss: 0.0127  \n",
      "<<<iteration:[100/657] - total_loss: 0.2704  obj_loss: 0.1508  noobj_loss: 0.1629  bbox_loss: 0.0054  cls_loss: 0.0111  \n",
      "<<<iteration:[120/657] - total_loss: 0.3036  obj_loss: 0.1789  noobj_loss: 0.1575  bbox_loss: 0.0067  cls_loss: 0.0124  \n",
      "<<<iteration:[140/657] - total_loss: 0.2903  obj_loss: 0.1689  noobj_loss: 0.1660  bbox_loss: 0.0059  cls_loss: 0.0088  \n",
      "<<<iteration:[160/657] - total_loss: 0.3143  obj_loss: 0.1875  noobj_loss: 0.1634  bbox_loss: 0.0063  cls_loss: 0.0135  \n",
      "<<<iteration:[180/657] - total_loss: 0.3052  obj_loss: 0.1826  noobj_loss: 0.1618  bbox_loss: 0.0057  cls_loss: 0.0130  \n",
      "<<<iteration:[200/657] - total_loss: 0.2912  obj_loss: 0.1652  noobj_loss: 0.1638  bbox_loss: 0.0063  cls_loss: 0.0127  \n",
      "<<<iteration:[220/657] - total_loss: 0.3008  obj_loss: 0.1801  noobj_loss: 0.1626  bbox_loss: 0.0060  cls_loss: 0.0096  \n",
      "<<<iteration:[240/657] - total_loss: 0.2906  obj_loss: 0.1724  noobj_loss: 0.1638  bbox_loss: 0.0055  cls_loss: 0.0087  \n",
      "<<<iteration:[260/657] - total_loss: 0.2991  obj_loss: 0.1796  noobj_loss: 0.1627  bbox_loss: 0.0056  cls_loss: 0.0103  \n",
      "<<<iteration:[280/657] - total_loss: 0.2893  obj_loss: 0.1690  noobj_loss: 0.1591  bbox_loss: 0.0057  cls_loss: 0.0121  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<<<iteration:[300/657] - total_loss: 0.2904  obj_loss: 0.1629  noobj_loss: 0.1597  bbox_loss: 0.0068  cls_loss: 0.0135  \n",
      "<<<iteration:[320/657] - total_loss: 0.2930  obj_loss: 0.1714  noobj_loss: 0.1524  bbox_loss: 0.0066  cls_loss: 0.0125  \n",
      "<<<iteration:[340/657] - total_loss: 0.3013  obj_loss: 0.1839  noobj_loss: 0.1607  bbox_loss: 0.0055  cls_loss: 0.0095  \n",
      "<<<iteration:[360/657] - total_loss: 0.2920  obj_loss: 0.1680  noobj_loss: 0.1640  bbox_loss: 0.0061  cls_loss: 0.0118  \n",
      "<<<iteration:[380/657] - total_loss: 0.2968  obj_loss: 0.1711  noobj_loss: 0.1667  bbox_loss: 0.0061  cls_loss: 0.0116  \n",
      "<<<iteration:[400/657] - total_loss: 0.3034  obj_loss: 0.1725  noobj_loss: 0.1694  bbox_loss: 0.0062  cls_loss: 0.0152  \n",
      "<<<iteration:[420/657] - total_loss: 0.2953  obj_loss: 0.1755  noobj_loss: 0.1616  bbox_loss: 0.0056  cls_loss: 0.0111  \n",
      "<<<iteration:[440/657] - total_loss: 0.3047  obj_loss: 0.1775  noobj_loss: 0.1647  bbox_loss: 0.0061  cls_loss: 0.0145  \n",
      "<<<iteration:[460/657] - total_loss: 0.3050  obj_loss: 0.1701  noobj_loss: 0.1685  bbox_loss: 0.0071  cls_loss: 0.0153  \n",
      "<<<iteration:[480/657] - total_loss: 0.2936  obj_loss: 0.1677  noobj_loss: 0.1635  bbox_loss: 0.0061  cls_loss: 0.0134  \n",
      "<<<iteration:[500/657] - total_loss: 0.2912  obj_loss: 0.1687  noobj_loss: 0.1623  bbox_loss: 0.0059  cls_loss: 0.0117  \n",
      "<<<iteration:[520/657] - total_loss: 0.3044  obj_loss: 0.1860  noobj_loss: 0.1643  bbox_loss: 0.0053  cls_loss: 0.0097  \n",
      "<<<iteration:[540/657] - total_loss: 0.3004  obj_loss: 0.1679  noobj_loss: 0.1652  bbox_loss: 0.0067  cls_loss: 0.0166  \n",
      "<<<iteration:[560/657] - total_loss: 0.3072  obj_loss: 0.1803  noobj_loss: 0.1636  bbox_loss: 0.0063  cls_loss: 0.0135  \n",
      "<<<iteration:[580/657] - total_loss: 0.3002  obj_loss: 0.1757  noobj_loss: 0.1537  bbox_loss: 0.0066  cls_loss: 0.0145  \n",
      "<<<iteration:[600/657] - total_loss: 0.3063  obj_loss: 0.1808  noobj_loss: 0.1619  bbox_loss: 0.0068  cls_loss: 0.0107  \n",
      "<<<iteration:[620/657] - total_loss: 0.2905  obj_loss: 0.1719  noobj_loss: 0.1625  bbox_loss: 0.0056  cls_loss: 0.0092  \n",
      "<<<iteration:[640/657] - total_loss: 0.2893  obj_loss: 0.1678  noobj_loss: 0.1594  bbox_loss: 0.0057  cls_loss: 0.0133  \n",
      "\n",
      "epoch:55/100 - Train Loss: 0.2975, Val Loss: 0.3153\n",
      "\n",
      "<<<iteration:[20/657] - total_loss: 0.3038  obj_loss: 0.1777  noobj_loss: 0.1678  bbox_loss: 0.0061  cls_loss: 0.0116  \n",
      "<<<iteration:[40/657] - total_loss: 0.3038  obj_loss: 0.1747  noobj_loss: 0.1684  bbox_loss: 0.0059  cls_loss: 0.0156  \n",
      "<<<iteration:[60/657] - total_loss: 0.2904  obj_loss: 0.1647  noobj_loss: 0.1648  bbox_loss: 0.0062  cls_loss: 0.0123  \n",
      "<<<iteration:[80/657] - total_loss: 0.2841  obj_loss: 0.1635  noobj_loss: 0.1639  bbox_loss: 0.0059  cls_loss: 0.0093  \n",
      "<<<iteration:[100/657] - total_loss: 0.3010  obj_loss: 0.1798  noobj_loss: 0.1687  bbox_loss: 0.0057  cls_loss: 0.0081  \n",
      "<<<iteration:[120/657] - total_loss: 0.2921  obj_loss: 0.1687  noobj_loss: 0.1674  bbox_loss: 0.0060  cls_loss: 0.0097  \n",
      "<<<iteration:[140/657] - total_loss: 0.2898  obj_loss: 0.1726  noobj_loss: 0.1628  bbox_loss: 0.0055  cls_loss: 0.0081  \n",
      "<<<iteration:[160/657] - total_loss: 0.2932  obj_loss: 0.1709  noobj_loss: 0.1599  bbox_loss: 0.0063  cls_loss: 0.0108  \n",
      "<<<iteration:[180/657] - total_loss: 0.2976  obj_loss: 0.1714  noobj_loss: 0.1625  bbox_loss: 0.0070  cls_loss: 0.0101  \n",
      "<<<iteration:[200/657] - total_loss: 0.3012  obj_loss: 0.1729  noobj_loss: 0.1638  bbox_loss: 0.0062  cls_loss: 0.0155  \n",
      "<<<iteration:[220/657] - total_loss: 0.2860  obj_loss: 0.1698  noobj_loss: 0.1563  bbox_loss: 0.0053  cls_loss: 0.0117  \n",
      "<<<iteration:[240/657] - total_loss: 0.2938  obj_loss: 0.1685  noobj_loss: 0.1622  bbox_loss: 0.0060  cls_loss: 0.0144  \n",
      "<<<iteration:[260/657] - total_loss: 0.3011  obj_loss: 0.1776  noobj_loss: 0.1629  bbox_loss: 0.0060  cls_loss: 0.0123  \n",
      "<<<iteration:[280/657] - total_loss: 0.2897  obj_loss: 0.1690  noobj_loss: 0.1652  bbox_loss: 0.0056  cls_loss: 0.0099  \n",
      "<<<iteration:[300/657] - total_loss: 0.3063  obj_loss: 0.1898  noobj_loss: 0.1538  bbox_loss: 0.0055  cls_loss: 0.0124  \n",
      "<<<iteration:[320/657] - total_loss: 0.3029  obj_loss: 0.1803  noobj_loss: 0.1566  bbox_loss: 0.0060  cls_loss: 0.0141  \n",
      "<<<iteration:[340/657] - total_loss: 0.3156  obj_loss: 0.1851  noobj_loss: 0.1664  bbox_loss: 0.0060  cls_loss: 0.0174  \n",
      "<<<iteration:[360/657] - total_loss: 0.3073  obj_loss: 0.1826  noobj_loss: 0.1736  bbox_loss: 0.0055  cls_loss: 0.0104  \n",
      "<<<iteration:[380/657] - total_loss: 0.2938  obj_loss: 0.1721  noobj_loss: 0.1693  bbox_loss: 0.0056  cls_loss: 0.0092  \n",
      "<<<iteration:[400/657] - total_loss: 0.3027  obj_loss: 0.1773  noobj_loss: 0.1636  bbox_loss: 0.0064  cls_loss: 0.0115  \n",
      "<<<iteration:[420/657] - total_loss: 0.2988  obj_loss: 0.1806  noobj_loss: 0.1634  bbox_loss: 0.0055  cls_loss: 0.0089  \n",
      "<<<iteration:[440/657] - total_loss: 0.3058  obj_loss: 0.1801  noobj_loss: 0.1704  bbox_loss: 0.0058  cls_loss: 0.0116  \n",
      "<<<iteration:[460/657] - total_loss: 0.2886  obj_loss: 0.1673  noobj_loss: 0.1625  bbox_loss: 0.0056  cls_loss: 0.0120  \n",
      "<<<iteration:[480/657] - total_loss: 0.3035  obj_loss: 0.1803  noobj_loss: 0.1662  bbox_loss: 0.0057  cls_loss: 0.0115  \n",
      "<<<iteration:[500/657] - total_loss: 0.2888  obj_loss: 0.1715  noobj_loss: 0.1578  bbox_loss: 0.0062  cls_loss: 0.0075  \n",
      "<<<iteration:[520/657] - total_loss: 0.2865  obj_loss: 0.1672  noobj_loss: 0.1520  bbox_loss: 0.0063  cls_loss: 0.0119  \n",
      "<<<iteration:[540/657] - total_loss: 0.3002  obj_loss: 0.1810  noobj_loss: 0.1566  bbox_loss: 0.0056  cls_loss: 0.0130  \n",
      "<<<iteration:[560/657] - total_loss: 0.3005  obj_loss: 0.1775  noobj_loss: 0.1548  bbox_loss: 0.0065  cls_loss: 0.0129  \n",
      "<<<iteration:[580/657] - total_loss: 0.3011  obj_loss: 0.1839  noobj_loss: 0.1604  bbox_loss: 0.0056  cls_loss: 0.0090  \n",
      "<<<iteration:[600/657] - total_loss: 0.2875  obj_loss: 0.1646  noobj_loss: 0.1677  bbox_loss: 0.0057  cls_loss: 0.0105  \n",
      "<<<iteration:[620/657] - total_loss: 0.2944  obj_loss: 0.1671  noobj_loss: 0.1597  bbox_loss: 0.0067  cls_loss: 0.0140  \n",
      "<<<iteration:[640/657] - total_loss: 0.3026  obj_loss: 0.1769  noobj_loss: 0.1621  bbox_loss: 0.0064  cls_loss: 0.0126  \n",
      "\n",
      "epoch:56/100 - Train Loss: 0.2973, Val Loss: 0.3116\n",
      "\n",
      "<<<iteration:[20/657] - total_loss: 0.3108  obj_loss: 0.1766  noobj_loss: 0.1669  bbox_loss: 0.0074  cls_loss: 0.0137  \n",
      "<<<iteration:[40/657] - total_loss: 0.2781  obj_loss: 0.1574  noobj_loss: 0.1673  bbox_loss: 0.0056  cls_loss: 0.0090  \n",
      "<<<iteration:[60/657] - total_loss: 0.3069  obj_loss: 0.1840  noobj_loss: 0.1609  bbox_loss: 0.0059  cls_loss: 0.0127  \n",
      "<<<iteration:[80/657] - total_loss: 0.2946  obj_loss: 0.1728  noobj_loss: 0.1572  bbox_loss: 0.0060  cls_loss: 0.0132  \n",
      "<<<iteration:[100/657] - total_loss: 0.3054  obj_loss: 0.1806  noobj_loss: 0.1678  bbox_loss: 0.0061  cls_loss: 0.0104  \n",
      "<<<iteration:[120/657] - total_loss: 0.2934  obj_loss: 0.1719  noobj_loss: 0.1656  bbox_loss: 0.0054  cls_loss: 0.0115  \n",
      "<<<iteration:[140/657] - total_loss: 0.2985  obj_loss: 0.1704  noobj_loss: 0.1687  bbox_loss: 0.0066  cls_loss: 0.0107  \n",
      "<<<iteration:[160/657] - total_loss: 0.2926  obj_loss: 0.1673  noobj_loss: 0.1671  bbox_loss: 0.0061  cls_loss: 0.0114  \n",
      "<<<iteration:[180/657] - total_loss: 0.3076  obj_loss: 0.1856  noobj_loss: 0.1594  bbox_loss: 0.0060  cls_loss: 0.0124  \n",
      "<<<iteration:[200/657] - total_loss: 0.3070  obj_loss: 0.1831  noobj_loss: 0.1730  bbox_loss: 0.0054  cls_loss: 0.0103  \n",
      "<<<iteration:[220/657] - total_loss: 0.2974  obj_loss: 0.1766  noobj_loss: 0.1631  bbox_loss: 0.0057  cls_loss: 0.0106  \n",
      "<<<iteration:[240/657] - total_loss: 0.2936  obj_loss: 0.1691  noobj_loss: 0.1675  bbox_loss: 0.0059  cls_loss: 0.0112  \n",
      "<<<iteration:[260/657] - total_loss: 0.2816  obj_loss: 0.1648  noobj_loss: 0.1578  bbox_loss: 0.0059  cls_loss: 0.0083  \n",
      "<<<iteration:[280/657] - total_loss: 0.2935  obj_loss: 0.1734  noobj_loss: 0.1585  bbox_loss: 0.0064  cls_loss: 0.0087  \n",
      "<<<iteration:[300/657] - total_loss: 0.3002  obj_loss: 0.1786  noobj_loss: 0.1694  bbox_loss: 0.0055  cls_loss: 0.0095  \n",
      "<<<iteration:[320/657] - total_loss: 0.2922  obj_loss: 0.1718  noobj_loss: 0.1638  bbox_loss: 0.0061  cls_loss: 0.0081  \n",
      "<<<iteration:[340/657] - total_loss: 0.2938  obj_loss: 0.1677  noobj_loss: 0.1623  bbox_loss: 0.0065  cls_loss: 0.0123  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<<<iteration:[360/657] - total_loss: 0.2859  obj_loss: 0.1665  noobj_loss: 0.1580  bbox_loss: 0.0061  cls_loss: 0.0097  \n",
      "<<<iteration:[380/657] - total_loss: 0.2861  obj_loss: 0.1695  noobj_loss: 0.1556  bbox_loss: 0.0058  cls_loss: 0.0099  \n",
      "<<<iteration:[400/657] - total_loss: 0.2900  obj_loss: 0.1666  noobj_loss: 0.1624  bbox_loss: 0.0064  cls_loss: 0.0102  \n",
      "<<<iteration:[420/657] - total_loss: 0.2836  obj_loss: 0.1651  noobj_loss: 0.1624  bbox_loss: 0.0053  cls_loss: 0.0109  \n",
      "<<<iteration:[440/657] - total_loss: 0.3027  obj_loss: 0.1838  noobj_loss: 0.1634  bbox_loss: 0.0050  cls_loss: 0.0122  \n",
      "<<<iteration:[460/657] - total_loss: 0.2837  obj_loss: 0.1633  noobj_loss: 0.1625  bbox_loss: 0.0056  cls_loss: 0.0112  \n",
      "<<<iteration:[480/657] - total_loss: 0.2798  obj_loss: 0.1526  noobj_loss: 0.1634  bbox_loss: 0.0064  cls_loss: 0.0138  \n",
      "<<<iteration:[500/657] - total_loss: 0.3173  obj_loss: 0.1870  noobj_loss: 0.1706  bbox_loss: 0.0060  cls_loss: 0.0150  \n",
      "<<<iteration:[520/657] - total_loss: 0.2894  obj_loss: 0.1648  noobj_loss: 0.1629  bbox_loss: 0.0062  cls_loss: 0.0121  \n",
      "<<<iteration:[540/657] - total_loss: 0.2988  obj_loss: 0.1775  noobj_loss: 0.1577  bbox_loss: 0.0060  cls_loss: 0.0126  \n",
      "<<<iteration:[560/657] - total_loss: 0.2846  obj_loss: 0.1629  noobj_loss: 0.1645  bbox_loss: 0.0059  cls_loss: 0.0097  \n",
      "<<<iteration:[580/657] - total_loss: 0.3008  obj_loss: 0.1813  noobj_loss: 0.1622  bbox_loss: 0.0059  cls_loss: 0.0090  \n",
      "<<<iteration:[600/657] - total_loss: 0.2991  obj_loss: 0.1793  noobj_loss: 0.1660  bbox_loss: 0.0053  cls_loss: 0.0102  \n",
      "<<<iteration:[620/657] - total_loss: 0.3018  obj_loss: 0.1784  noobj_loss: 0.1655  bbox_loss: 0.0056  cls_loss: 0.0126  \n",
      "<<<iteration:[640/657] - total_loss: 0.2993  obj_loss: 0.1710  noobj_loss: 0.1668  bbox_loss: 0.0067  cls_loss: 0.0113  \n",
      "\n",
      "epoch:57/100 - Train Loss: 0.2953, Val Loss: 0.3196\n",
      "\n",
      "<<<iteration:[20/657] - total_loss: 0.3177  obj_loss: 0.1912  noobj_loss: 0.1762  bbox_loss: 0.0056  cls_loss: 0.0106  \n",
      "<<<iteration:[40/657] - total_loss: 0.2929  obj_loss: 0.1709  noobj_loss: 0.1702  bbox_loss: 0.0053  cls_loss: 0.0102  \n",
      "<<<iteration:[60/657] - total_loss: 0.2955  obj_loss: 0.1650  noobj_loss: 0.1672  bbox_loss: 0.0072  cls_loss: 0.0108  \n",
      "<<<iteration:[80/657] - total_loss: 0.2945  obj_loss: 0.1669  noobj_loss: 0.1606  bbox_loss: 0.0065  cls_loss: 0.0147  \n",
      "<<<iteration:[100/657] - total_loss: 0.2977  obj_loss: 0.1765  noobj_loss: 0.1621  bbox_loss: 0.0057  cls_loss: 0.0114  \n",
      "<<<iteration:[120/657] - total_loss: 0.2979  obj_loss: 0.1746  noobj_loss: 0.1661  bbox_loss: 0.0057  cls_loss: 0.0118  \n",
      "<<<iteration:[140/657] - total_loss: 0.2941  obj_loss: 0.1686  noobj_loss: 0.1664  bbox_loss: 0.0061  cls_loss: 0.0116  \n",
      "<<<iteration:[160/657] - total_loss: 0.2968  obj_loss: 0.1709  noobj_loss: 0.1733  bbox_loss: 0.0061  cls_loss: 0.0088  \n",
      "<<<iteration:[180/657] - total_loss: 0.2866  obj_loss: 0.1610  noobj_loss: 0.1705  bbox_loss: 0.0063  cls_loss: 0.0090  \n",
      "<<<iteration:[200/657] - total_loss: 0.2987  obj_loss: 0.1779  noobj_loss: 0.1662  bbox_loss: 0.0056  cls_loss: 0.0097  \n",
      "<<<iteration:[220/657] - total_loss: 0.3061  obj_loss: 0.1705  noobj_loss: 0.1663  bbox_loss: 0.0070  cls_loss: 0.0176  \n",
      "<<<iteration:[240/657] - total_loss: 0.2993  obj_loss: 0.1772  noobj_loss: 0.1602  bbox_loss: 0.0061  cls_loss: 0.0115  \n",
      "<<<iteration:[260/657] - total_loss: 0.2915  obj_loss: 0.1694  noobj_loss: 0.1592  bbox_loss: 0.0064  cls_loss: 0.0107  \n",
      "<<<iteration:[280/657] - total_loss: 0.2982  obj_loss: 0.1727  noobj_loss: 0.1648  bbox_loss: 0.0062  cls_loss: 0.0119  \n",
      "<<<iteration:[300/657] - total_loss: 0.2888  obj_loss: 0.1645  noobj_loss: 0.1598  bbox_loss: 0.0059  cls_loss: 0.0148  \n",
      "<<<iteration:[320/657] - total_loss: 0.2970  obj_loss: 0.1739  noobj_loss: 0.1625  bbox_loss: 0.0058  cls_loss: 0.0130  \n",
      "<<<iteration:[340/657] - total_loss: 0.2932  obj_loss: 0.1699  noobj_loss: 0.1644  bbox_loss: 0.0055  cls_loss: 0.0137  \n",
      "<<<iteration:[360/657] - total_loss: 0.2923  obj_loss: 0.1690  noobj_loss: 0.1637  bbox_loss: 0.0057  cls_loss: 0.0129  \n",
      "<<<iteration:[380/657] - total_loss: 0.2980  obj_loss: 0.1765  noobj_loss: 0.1685  bbox_loss: 0.0056  cls_loss: 0.0094  \n",
      "<<<iteration:[400/657] - total_loss: 0.2984  obj_loss: 0.1759  noobj_loss: 0.1710  bbox_loss: 0.0057  cls_loss: 0.0084  \n",
      "<<<iteration:[420/657] - total_loss: 0.2923  obj_loss: 0.1668  noobj_loss: 0.1646  bbox_loss: 0.0063  cls_loss: 0.0118  \n",
      "<<<iteration:[440/657] - total_loss: 0.2941  obj_loss: 0.1669  noobj_loss: 0.1654  bbox_loss: 0.0063  cls_loss: 0.0130  \n",
      "<<<iteration:[460/657] - total_loss: 0.2935  obj_loss: 0.1732  noobj_loss: 0.1622  bbox_loss: 0.0056  cls_loss: 0.0113  \n",
      "<<<iteration:[480/657] - total_loss: 0.2887  obj_loss: 0.1683  noobj_loss: 0.1593  bbox_loss: 0.0061  cls_loss: 0.0102  \n",
      "<<<iteration:[500/657] - total_loss: 0.2908  obj_loss: 0.1639  noobj_loss: 0.1584  bbox_loss: 0.0065  cls_loss: 0.0153  \n",
      "<<<iteration:[520/657] - total_loss: 0.3038  obj_loss: 0.1793  noobj_loss: 0.1693  bbox_loss: 0.0063  cls_loss: 0.0086  \n",
      "<<<iteration:[540/657] - total_loss: 0.3065  obj_loss: 0.1857  noobj_loss: 0.1558  bbox_loss: 0.0063  cls_loss: 0.0115  \n",
      "<<<iteration:[560/657] - total_loss: 0.3144  obj_loss: 0.1814  noobj_loss: 0.1624  bbox_loss: 0.0067  cls_loss: 0.0182  \n",
      "<<<iteration:[580/657] - total_loss: 0.3150  obj_loss: 0.1862  noobj_loss: 0.1695  bbox_loss: 0.0062  cls_loss: 0.0128  \n",
      "<<<iteration:[600/657] - total_loss: 0.2841  obj_loss: 0.1602  noobj_loss: 0.1610  bbox_loss: 0.0060  cls_loss: 0.0132  \n",
      "<<<iteration:[620/657] - total_loss: 0.2920  obj_loss: 0.1675  noobj_loss: 0.1625  bbox_loss: 0.0059  cls_loss: 0.0136  \n",
      "<<<iteration:[640/657] - total_loss: 0.3018  obj_loss: 0.1803  noobj_loss: 0.1664  bbox_loss: 0.0056  cls_loss: 0.0101  \n",
      "\n",
      "epoch:58/100 - Train Loss: 0.2971, Val Loss: 0.3083\n",
      "\n",
      "<<<iteration:[20/657] - total_loss: 0.2995  obj_loss: 0.1746  noobj_loss: 0.1662  bbox_loss: 0.0060  cls_loss: 0.0119  \n",
      "<<<iteration:[40/657] - total_loss: 0.3023  obj_loss: 0.1734  noobj_loss: 0.1707  bbox_loss: 0.0060  cls_loss: 0.0136  \n",
      "<<<iteration:[60/657] - total_loss: 0.2996  obj_loss: 0.1746  noobj_loss: 0.1678  bbox_loss: 0.0063  cls_loss: 0.0096  \n",
      "<<<iteration:[80/657] - total_loss: 0.2978  obj_loss: 0.1732  noobj_loss: 0.1689  bbox_loss: 0.0062  cls_loss: 0.0094  \n",
      "<<<iteration:[100/657] - total_loss: 0.3066  obj_loss: 0.1823  noobj_loss: 0.1661  bbox_loss: 0.0064  cls_loss: 0.0094  \n",
      "<<<iteration:[120/657] - total_loss: 0.3069  obj_loss: 0.1880  noobj_loss: 0.1684  bbox_loss: 0.0051  cls_loss: 0.0092  \n",
      "<<<iteration:[140/657] - total_loss: 0.2984  obj_loss: 0.1774  noobj_loss: 0.1640  bbox_loss: 0.0056  cls_loss: 0.0112  \n",
      "<<<iteration:[160/657] - total_loss: 0.2935  obj_loss: 0.1740  noobj_loss: 0.1649  bbox_loss: 0.0054  cls_loss: 0.0103  \n",
      "<<<iteration:[180/657] - total_loss: 0.2968  obj_loss: 0.1729  noobj_loss: 0.1660  bbox_loss: 0.0061  cls_loss: 0.0105  \n",
      "<<<iteration:[200/657] - total_loss: 0.2891  obj_loss: 0.1666  noobj_loss: 0.1617  bbox_loss: 0.0062  cls_loss: 0.0105  \n",
      "<<<iteration:[220/657] - total_loss: 0.3012  obj_loss: 0.1762  noobj_loss: 0.1719  bbox_loss: 0.0059  cls_loss: 0.0097  \n",
      "<<<iteration:[240/657] - total_loss: 0.3031  obj_loss: 0.1834  noobj_loss: 0.1616  bbox_loss: 0.0055  cls_loss: 0.0114  \n",
      "<<<iteration:[260/657] - total_loss: 0.3018  obj_loss: 0.1803  noobj_loss: 0.1660  bbox_loss: 0.0054  cls_loss: 0.0117  \n",
      "<<<iteration:[280/657] - total_loss: 0.2920  obj_loss: 0.1699  noobj_loss: 0.1601  bbox_loss: 0.0061  cls_loss: 0.0117  \n",
      "<<<iteration:[300/657] - total_loss: 0.2884  obj_loss: 0.1660  noobj_loss: 0.1625  bbox_loss: 0.0062  cls_loss: 0.0100  \n",
      "<<<iteration:[320/657] - total_loss: 0.3002  obj_loss: 0.1711  noobj_loss: 0.1658  bbox_loss: 0.0069  cls_loss: 0.0117  \n",
      "<<<iteration:[340/657] - total_loss: 0.2868  obj_loss: 0.1681  noobj_loss: 0.1609  bbox_loss: 0.0056  cls_loss: 0.0105  \n",
      "<<<iteration:[360/657] - total_loss: 0.3066  obj_loss: 0.1806  noobj_loss: 0.1691  bbox_loss: 0.0060  cls_loss: 0.0115  \n",
      "<<<iteration:[380/657] - total_loss: 0.2940  obj_loss: 0.1674  noobj_loss: 0.1718  bbox_loss: 0.0060  cls_loss: 0.0108  \n",
      "<<<iteration:[400/657] - total_loss: 0.2986  obj_loss: 0.1760  noobj_loss: 0.1686  bbox_loss: 0.0055  cls_loss: 0.0107  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<<<iteration:[420/657] - total_loss: 0.2955  obj_loss: 0.1733  noobj_loss: 0.1661  bbox_loss: 0.0055  cls_loss: 0.0115  \n",
      "<<<iteration:[440/657] - total_loss: 0.2964  obj_loss: 0.1721  noobj_loss: 0.1693  bbox_loss: 0.0061  cls_loss: 0.0094  \n",
      "<<<iteration:[460/657] - total_loss: 0.2947  obj_loss: 0.1764  noobj_loss: 0.1672  bbox_loss: 0.0055  cls_loss: 0.0073  \n",
      "<<<iteration:[480/657] - total_loss: 0.2784  obj_loss: 0.1595  noobj_loss: 0.1625  bbox_loss: 0.0059  cls_loss: 0.0079  \n",
      "<<<iteration:[500/657] - total_loss: 0.2954  obj_loss: 0.1690  noobj_loss: 0.1678  bbox_loss: 0.0059  cls_loss: 0.0133  \n",
      "<<<iteration:[520/657] - total_loss: 0.2924  obj_loss: 0.1725  noobj_loss: 0.1622  bbox_loss: 0.0057  cls_loss: 0.0101  \n",
      "<<<iteration:[540/657] - total_loss: 0.2995  obj_loss: 0.1769  noobj_loss: 0.1706  bbox_loss: 0.0057  cls_loss: 0.0090  \n",
      "<<<iteration:[560/657] - total_loss: 0.2944  obj_loss: 0.1645  noobj_loss: 0.1663  bbox_loss: 0.0068  cls_loss: 0.0130  \n",
      "<<<iteration:[580/657] - total_loss: 0.2970  obj_loss: 0.1696  noobj_loss: 0.1704  bbox_loss: 0.0058  cls_loss: 0.0129  \n",
      "<<<iteration:[600/657] - total_loss: 0.2987  obj_loss: 0.1776  noobj_loss: 0.1656  bbox_loss: 0.0058  cls_loss: 0.0095  \n",
      "<<<iteration:[620/657] - total_loss: 0.2978  obj_loss: 0.1689  noobj_loss: 0.1740  bbox_loss: 0.0061  cls_loss: 0.0114  \n",
      "<<<iteration:[640/657] - total_loss: 0.3070  obj_loss: 0.1725  noobj_loss: 0.1690  bbox_loss: 0.0064  cls_loss: 0.0181  \n",
      "\n",
      "epoch:59/100 - Train Loss: 0.2965, Val Loss: 0.3058\n",
      "\n",
      "<<<iteration:[20/657] - total_loss: 0.3169  obj_loss: 0.1912  noobj_loss: 0.1736  bbox_loss: 0.0060  cls_loss: 0.0091  \n",
      "<<<iteration:[40/657] - total_loss: 0.2864  obj_loss: 0.1625  noobj_loss: 0.1671  bbox_loss: 0.0058  cls_loss: 0.0113  \n",
      "<<<iteration:[60/657] - total_loss: 0.2902  obj_loss: 0.1663  noobj_loss: 0.1670  bbox_loss: 0.0057  cls_loss: 0.0118  \n",
      "<<<iteration:[80/657] - total_loss: 0.2877  obj_loss: 0.1627  noobj_loss: 0.1597  bbox_loss: 0.0064  cls_loss: 0.0131  \n",
      "<<<iteration:[100/657] - total_loss: 0.3003  obj_loss: 0.1751  noobj_loss: 0.1759  bbox_loss: 0.0054  cls_loss: 0.0101  \n",
      "<<<iteration:[120/657] - total_loss: 0.2910  obj_loss: 0.1665  noobj_loss: 0.1731  bbox_loss: 0.0054  cls_loss: 0.0109  \n",
      "<<<iteration:[140/657] - total_loss: 0.3064  obj_loss: 0.1812  noobj_loss: 0.1623  bbox_loss: 0.0056  cls_loss: 0.0158  \n",
      "<<<iteration:[160/657] - total_loss: 0.2963  obj_loss: 0.1667  noobj_loss: 0.1689  bbox_loss: 0.0067  cls_loss: 0.0115  \n",
      "<<<iteration:[180/657] - total_loss: 0.2854  obj_loss: 0.1609  noobj_loss: 0.1677  bbox_loss: 0.0062  cls_loss: 0.0097  \n",
      "<<<iteration:[200/657] - total_loss: 0.2895  obj_loss: 0.1652  noobj_loss: 0.1681  bbox_loss: 0.0063  cls_loss: 0.0088  \n",
      "<<<iteration:[220/657] - total_loss: 0.3084  obj_loss: 0.1923  noobj_loss: 0.1654  bbox_loss: 0.0048  cls_loss: 0.0093  \n",
      "<<<iteration:[240/657] - total_loss: 0.2963  obj_loss: 0.1746  noobj_loss: 0.1678  bbox_loss: 0.0056  cls_loss: 0.0096  \n",
      "<<<iteration:[260/657] - total_loss: 0.2943  obj_loss: 0.1741  noobj_loss: 0.1655  bbox_loss: 0.0055  cls_loss: 0.0098  \n",
      "<<<iteration:[280/657] - total_loss: 0.2889  obj_loss: 0.1624  noobj_loss: 0.1699  bbox_loss: 0.0063  cls_loss: 0.0099  \n",
      "<<<iteration:[300/657] - total_loss: 0.2833  obj_loss: 0.1630  noobj_loss: 0.1704  bbox_loss: 0.0052  cls_loss: 0.0090  \n",
      "<<<iteration:[320/657] - total_loss: 0.3020  obj_loss: 0.1772  noobj_loss: 0.1757  bbox_loss: 0.0053  cls_loss: 0.0102  \n",
      "<<<iteration:[340/657] - total_loss: 0.2954  obj_loss: 0.1714  noobj_loss: 0.1687  bbox_loss: 0.0062  cls_loss: 0.0084  \n",
      "<<<iteration:[360/657] - total_loss: 0.3024  obj_loss: 0.1814  noobj_loss: 0.1694  bbox_loss: 0.0054  cls_loss: 0.0093  \n",
      "<<<iteration:[380/657] - total_loss: 0.2850  obj_loss: 0.1649  noobj_loss: 0.1625  bbox_loss: 0.0056  cls_loss: 0.0109  \n",
      "<<<iteration:[400/657] - total_loss: 0.2933  obj_loss: 0.1690  noobj_loss: 0.1635  bbox_loss: 0.0057  cls_loss: 0.0139  \n",
      "<<<iteration:[420/657] - total_loss: 0.2926  obj_loss: 0.1739  noobj_loss: 0.1561  bbox_loss: 0.0062  cls_loss: 0.0097  \n",
      "<<<iteration:[440/657] - total_loss: 0.2993  obj_loss: 0.1714  noobj_loss: 0.1681  bbox_loss: 0.0066  cls_loss: 0.0111  \n",
      "<<<iteration:[460/657] - total_loss: 0.3060  obj_loss: 0.1768  noobj_loss: 0.1704  bbox_loss: 0.0060  cls_loss: 0.0140  \n",
      "<<<iteration:[480/657] - total_loss: 0.3048  obj_loss: 0.1803  noobj_loss: 0.1663  bbox_loss: 0.0061  cls_loss: 0.0108  \n",
      "<<<iteration:[500/657] - total_loss: 0.2809  obj_loss: 0.1569  noobj_loss: 0.1658  bbox_loss: 0.0061  cls_loss: 0.0106  \n",
      "<<<iteration:[520/657] - total_loss: 0.3109  obj_loss: 0.1868  noobj_loss: 0.1643  bbox_loss: 0.0062  cls_loss: 0.0112  \n",
      "<<<iteration:[540/657] - total_loss: 0.2956  obj_loss: 0.1755  noobj_loss: 0.1563  bbox_loss: 0.0063  cls_loss: 0.0102  \n",
      "<<<iteration:[560/657] - total_loss: 0.3007  obj_loss: 0.1813  noobj_loss: 0.1627  bbox_loss: 0.0060  cls_loss: 0.0081  \n",
      "<<<iteration:[580/657] - total_loss: 0.2987  obj_loss: 0.1683  noobj_loss: 0.1706  bbox_loss: 0.0062  cls_loss: 0.0139  \n",
      "<<<iteration:[600/657] - total_loss: 0.2978  obj_loss: 0.1751  noobj_loss: 0.1656  bbox_loss: 0.0053  cls_loss: 0.0134  \n",
      "<<<iteration:[620/657] - total_loss: 0.2979  obj_loss: 0.1810  noobj_loss: 0.1560  bbox_loss: 0.0059  cls_loss: 0.0095  \n",
      "<<<iteration:[640/657] - total_loss: 0.2906  obj_loss: 0.1711  noobj_loss: 0.1602  bbox_loss: 0.0059  cls_loss: 0.0097  \n",
      "\n",
      "epoch:60/100 - Train Loss: 0.2953, Val Loss: 0.3114\n",
      "\n",
      "<<<iteration:[20/657] - total_loss: 0.3015  obj_loss: 0.1769  noobj_loss: 0.1659  bbox_loss: 0.0063  cls_loss: 0.0104  \n",
      "<<<iteration:[40/657] - total_loss: 0.2947  obj_loss: 0.1764  noobj_loss: 0.1658  bbox_loss: 0.0051  cls_loss: 0.0098  \n",
      "<<<iteration:[60/657] - total_loss: 0.2876  obj_loss: 0.1668  noobj_loss: 0.1668  bbox_loss: 0.0056  cls_loss: 0.0096  \n",
      "<<<iteration:[80/657] - total_loss: 0.2980  obj_loss: 0.1817  noobj_loss: 0.1612  bbox_loss: 0.0052  cls_loss: 0.0096  \n",
      "<<<iteration:[100/657] - total_loss: 0.2962  obj_loss: 0.1780  noobj_loss: 0.1618  bbox_loss: 0.0052  cls_loss: 0.0112  \n",
      "<<<iteration:[120/657] - total_loss: 0.2821  obj_loss: 0.1621  noobj_loss: 0.1627  bbox_loss: 0.0058  cls_loss: 0.0095  \n",
      "<<<iteration:[140/657] - total_loss: 0.2914  obj_loss: 0.1745  noobj_loss: 0.1584  bbox_loss: 0.0055  cls_loss: 0.0102  \n",
      "<<<iteration:[160/657] - total_loss: 0.2713  obj_loss: 0.1467  noobj_loss: 0.1663  bbox_loss: 0.0062  cls_loss: 0.0104  \n",
      "<<<iteration:[180/657] - total_loss: 0.2920  obj_loss: 0.1704  noobj_loss: 0.1617  bbox_loss: 0.0060  cls_loss: 0.0107  \n",
      "<<<iteration:[200/657] - total_loss: 0.2844  obj_loss: 0.1621  noobj_loss: 0.1660  bbox_loss: 0.0059  cls_loss: 0.0098  \n",
      "<<<iteration:[220/657] - total_loss: 0.2953  obj_loss: 0.1754  noobj_loss: 0.1686  bbox_loss: 0.0052  cls_loss: 0.0096  \n",
      "<<<iteration:[240/657] - total_loss: 0.2845  obj_loss: 0.1618  noobj_loss: 0.1702  bbox_loss: 0.0057  cls_loss: 0.0092  \n",
      "<<<iteration:[260/657] - total_loss: 0.2904  obj_loss: 0.1709  noobj_loss: 0.1654  bbox_loss: 0.0053  cls_loss: 0.0103  \n",
      "<<<iteration:[280/657] - total_loss: 0.2998  obj_loss: 0.1759  noobj_loss: 0.1677  bbox_loss: 0.0056  cls_loss: 0.0118  \n",
      "<<<iteration:[300/657] - total_loss: 0.3088  obj_loss: 0.1853  noobj_loss: 0.1640  bbox_loss: 0.0060  cls_loss: 0.0116  \n",
      "<<<iteration:[320/657] - total_loss: 0.2928  obj_loss: 0.1683  noobj_loss: 0.1715  bbox_loss: 0.0058  cls_loss: 0.0095  \n",
      "<<<iteration:[340/657] - total_loss: 0.3071  obj_loss: 0.1832  noobj_loss: 0.1711  bbox_loss: 0.0054  cls_loss: 0.0111  \n",
      "<<<iteration:[360/657] - total_loss: 0.3010  obj_loss: 0.1761  noobj_loss: 0.1679  bbox_loss: 0.0060  cls_loss: 0.0109  \n",
      "<<<iteration:[380/657] - total_loss: 0.3095  obj_loss: 0.1820  noobj_loss: 0.1759  bbox_loss: 0.0059  cls_loss: 0.0100  \n",
      "<<<iteration:[400/657] - total_loss: 0.2969  obj_loss: 0.1646  noobj_loss: 0.1740  bbox_loss: 0.0067  cls_loss: 0.0116  \n",
      "<<<iteration:[420/657] - total_loss: 0.2943  obj_loss: 0.1749  noobj_loss: 0.1670  bbox_loss: 0.0053  cls_loss: 0.0094  \n",
      "<<<iteration:[440/657] - total_loss: 0.2932  obj_loss: 0.1753  noobj_loss: 0.1705  bbox_loss: 0.0051  cls_loss: 0.0071  \n",
      "<<<iteration:[460/657] - total_loss: 0.2896  obj_loss: 0.1702  noobj_loss: 0.1727  bbox_loss: 0.0052  cls_loss: 0.0069  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<<<iteration:[480/657] - total_loss: 0.3007  obj_loss: 0.1701  noobj_loss: 0.1679  bbox_loss: 0.0059  cls_loss: 0.0170  \n",
      "<<<iteration:[500/657] - total_loss: 0.3014  obj_loss: 0.1722  noobj_loss: 0.1724  bbox_loss: 0.0060  cls_loss: 0.0132  \n",
      "<<<iteration:[520/657] - total_loss: 0.3095  obj_loss: 0.1780  noobj_loss: 0.1700  bbox_loss: 0.0067  cls_loss: 0.0130  \n",
      "<<<iteration:[540/657] - total_loss: 0.2972  obj_loss: 0.1757  noobj_loss: 0.1634  bbox_loss: 0.0063  cls_loss: 0.0085  \n",
      "<<<iteration:[560/657] - total_loss: 0.3027  obj_loss: 0.1788  noobj_loss: 0.1633  bbox_loss: 0.0058  cls_loss: 0.0133  \n",
      "<<<iteration:[580/657] - total_loss: 0.2955  obj_loss: 0.1695  noobj_loss: 0.1624  bbox_loss: 0.0063  cls_loss: 0.0136  \n",
      "<<<iteration:[600/657] - total_loss: 0.3043  obj_loss: 0.1768  noobj_loss: 0.1663  bbox_loss: 0.0060  cls_loss: 0.0143  \n",
      "<<<iteration:[620/657] - total_loss: 0.2970  obj_loss: 0.1776  noobj_loss: 0.1666  bbox_loss: 0.0054  cls_loss: 0.0093  \n",
      "<<<iteration:[640/657] - total_loss: 0.3050  obj_loss: 0.1797  noobj_loss: 0.1709  bbox_loss: 0.0057  cls_loss: 0.0112  \n",
      "\n",
      "epoch:61/100 - Train Loss: 0.2959, Val Loss: 0.3137\n",
      "\n",
      "<<<iteration:[20/657] - total_loss: 0.3143  obj_loss: 0.1800  noobj_loss: 0.1905  bbox_loss: 0.0057  cls_loss: 0.0108  \n",
      "<<<iteration:[40/657] - total_loss: 0.2955  obj_loss: 0.1695  noobj_loss: 0.1723  bbox_loss: 0.0056  cls_loss: 0.0119  \n",
      "<<<iteration:[60/657] - total_loss: 0.2991  obj_loss: 0.1751  noobj_loss: 0.1679  bbox_loss: 0.0061  cls_loss: 0.0096  \n",
      "<<<iteration:[80/657] - total_loss: 0.2886  obj_loss: 0.1686  noobj_loss: 0.1712  bbox_loss: 0.0052  cls_loss: 0.0083  \n",
      "<<<iteration:[100/657] - total_loss: 0.3038  obj_loss: 0.1761  noobj_loss: 0.1636  bbox_loss: 0.0065  cls_loss: 0.0132  \n",
      "<<<iteration:[120/657] - total_loss: 0.2854  obj_loss: 0.1643  noobj_loss: 0.1672  bbox_loss: 0.0058  cls_loss: 0.0084  \n",
      "<<<iteration:[140/657] - total_loss: 0.2815  obj_loss: 0.1581  noobj_loss: 0.1679  bbox_loss: 0.0054  cls_loss: 0.0123  \n",
      "<<<iteration:[160/657] - total_loss: 0.2873  obj_loss: 0.1669  noobj_loss: 0.1679  bbox_loss: 0.0054  cls_loss: 0.0097  \n",
      "<<<iteration:[180/657] - total_loss: 0.3093  obj_loss: 0.1818  noobj_loss: 0.1690  bbox_loss: 0.0055  cls_loss: 0.0154  \n",
      "<<<iteration:[200/657] - total_loss: 0.3151  obj_loss: 0.1851  noobj_loss: 0.1773  bbox_loss: 0.0062  cls_loss: 0.0102  \n",
      "<<<iteration:[220/657] - total_loss: 0.2964  obj_loss: 0.1724  noobj_loss: 0.1734  bbox_loss: 0.0055  cls_loss: 0.0097  \n",
      "<<<iteration:[240/657] - total_loss: 0.3007  obj_loss: 0.1813  noobj_loss: 0.1671  bbox_loss: 0.0052  cls_loss: 0.0099  \n",
      "<<<iteration:[260/657] - total_loss: 0.3016  obj_loss: 0.1783  noobj_loss: 0.1671  bbox_loss: 0.0052  cls_loss: 0.0138  \n",
      "<<<iteration:[280/657] - total_loss: 0.2958  obj_loss: 0.1683  noobj_loss: 0.1711  bbox_loss: 0.0057  cls_loss: 0.0134  \n",
      "<<<iteration:[300/657] - total_loss: 0.3021  obj_loss: 0.1780  noobj_loss: 0.1670  bbox_loss: 0.0056  cls_loss: 0.0126  \n",
      "<<<iteration:[320/657] - total_loss: 0.2924  obj_loss: 0.1709  noobj_loss: 0.1712  bbox_loss: 0.0056  cls_loss: 0.0079  \n",
      "<<<iteration:[340/657] - total_loss: 0.2991  obj_loss: 0.1766  noobj_loss: 0.1695  bbox_loss: 0.0059  cls_loss: 0.0083  \n",
      "<<<iteration:[360/657] - total_loss: 0.3014  obj_loss: 0.1734  noobj_loss: 0.1725  bbox_loss: 0.0060  cls_loss: 0.0116  \n",
      "<<<iteration:[380/657] - total_loss: 0.2996  obj_loss: 0.1776  noobj_loss: 0.1719  bbox_loss: 0.0054  cls_loss: 0.0091  \n",
      "<<<iteration:[400/657] - total_loss: 0.2881  obj_loss: 0.1670  noobj_loss: 0.1597  bbox_loss: 0.0061  cls_loss: 0.0105  \n",
      "<<<iteration:[420/657] - total_loss: 0.2971  obj_loss: 0.1665  noobj_loss: 0.1748  bbox_loss: 0.0062  cls_loss: 0.0121  \n",
      "<<<iteration:[440/657] - total_loss: 0.3000  obj_loss: 0.1736  noobj_loss: 0.1640  bbox_loss: 0.0066  cls_loss: 0.0113  \n",
      "<<<iteration:[460/657] - total_loss: 0.2938  obj_loss: 0.1729  noobj_loss: 0.1695  bbox_loss: 0.0054  cls_loss: 0.0090  \n",
      "<<<iteration:[480/657] - total_loss: 0.3062  obj_loss: 0.1853  noobj_loss: 0.1774  bbox_loss: 0.0048  cls_loss: 0.0079  \n",
      "<<<iteration:[500/657] - total_loss: 0.2830  obj_loss: 0.1564  noobj_loss: 0.1689  bbox_loss: 0.0060  cls_loss: 0.0123  \n",
      "<<<iteration:[520/657] - total_loss: 0.2968  obj_loss: 0.1745  noobj_loss: 0.1664  bbox_loss: 0.0050  cls_loss: 0.0143  \n",
      "<<<iteration:[540/657] - total_loss: 0.3011  obj_loss: 0.1793  noobj_loss: 0.1672  bbox_loss: 0.0053  cls_loss: 0.0114  \n",
      "<<<iteration:[560/657] - total_loss: 0.3067  obj_loss: 0.1784  noobj_loss: 0.1770  bbox_loss: 0.0059  cls_loss: 0.0101  \n",
      "<<<iteration:[580/657] - total_loss: 0.2989  obj_loss: 0.1732  noobj_loss: 0.1688  bbox_loss: 0.0056  cls_loss: 0.0131  \n",
      "<<<iteration:[600/657] - total_loss: 0.2990  obj_loss: 0.1788  noobj_loss: 0.1640  bbox_loss: 0.0054  cls_loss: 0.0113  \n",
      "<<<iteration:[620/657] - total_loss: 0.3015  obj_loss: 0.1742  noobj_loss: 0.1724  bbox_loss: 0.0058  cls_loss: 0.0118  \n",
      "<<<iteration:[640/657] - total_loss: 0.2774  obj_loss: 0.1609  noobj_loss: 0.1613  bbox_loss: 0.0055  cls_loss: 0.0084  \n",
      "\n",
      "epoch:62/100 - Train Loss: 0.2968, Val Loss: 0.3070\n",
      "\n",
      "<<<iteration:[20/657] - total_loss: 0.3156  obj_loss: 0.1868  noobj_loss: 0.1784  bbox_loss: 0.0054  cls_loss: 0.0125  \n",
      "<<<iteration:[40/657] - total_loss: 0.2980  obj_loss: 0.1795  noobj_loss: 0.1593  bbox_loss: 0.0059  cls_loss: 0.0093  \n",
      "<<<iteration:[60/657] - total_loss: 0.2949  obj_loss: 0.1730  noobj_loss: 0.1720  bbox_loss: 0.0056  cls_loss: 0.0078  \n",
      "<<<iteration:[80/657] - total_loss: 0.3034  obj_loss: 0.1812  noobj_loss: 0.1709  bbox_loss: 0.0053  cls_loss: 0.0104  \n",
      "<<<iteration:[100/657] - total_loss: 0.3024  obj_loss: 0.1820  noobj_loss: 0.1711  bbox_loss: 0.0055  cls_loss: 0.0074  \n",
      "<<<iteration:[120/657] - total_loss: 0.2981  obj_loss: 0.1714  noobj_loss: 0.1773  bbox_loss: 0.0059  cls_loss: 0.0087  \n",
      "<<<iteration:[140/657] - total_loss: 0.2982  obj_loss: 0.1770  noobj_loss: 0.1640  bbox_loss: 0.0058  cls_loss: 0.0103  \n",
      "<<<iteration:[160/657] - total_loss: 0.2813  obj_loss: 0.1613  noobj_loss: 0.1600  bbox_loss: 0.0057  cls_loss: 0.0115  \n",
      "<<<iteration:[180/657] - total_loss: 0.3016  obj_loss: 0.1791  noobj_loss: 0.1681  bbox_loss: 0.0056  cls_loss: 0.0104  \n",
      "<<<iteration:[200/657] - total_loss: 0.3007  obj_loss: 0.1707  noobj_loss: 0.1754  bbox_loss: 0.0063  cls_loss: 0.0109  \n",
      "<<<iteration:[220/657] - total_loss: 0.2896  obj_loss: 0.1692  noobj_loss: 0.1623  bbox_loss: 0.0059  cls_loss: 0.0097  \n",
      "<<<iteration:[240/657] - total_loss: 0.3013  obj_loss: 0.1765  noobj_loss: 0.1634  bbox_loss: 0.0057  cls_loss: 0.0147  \n",
      "<<<iteration:[260/657] - total_loss: 0.2949  obj_loss: 0.1715  noobj_loss: 0.1773  bbox_loss: 0.0052  cls_loss: 0.0087  \n",
      "<<<iteration:[280/657] - total_loss: 0.2834  obj_loss: 0.1654  noobj_loss: 0.1659  bbox_loss: 0.0054  cls_loss: 0.0082  \n",
      "<<<iteration:[300/657] - total_loss: 0.3038  obj_loss: 0.1834  noobj_loss: 0.1721  bbox_loss: 0.0049  cls_loss: 0.0098  \n",
      "<<<iteration:[320/657] - total_loss: 0.2869  obj_loss: 0.1706  noobj_loss: 0.1681  bbox_loss: 0.0049  cls_loss: 0.0078  \n",
      "<<<iteration:[340/657] - total_loss: 0.2891  obj_loss: 0.1640  noobj_loss: 0.1708  bbox_loss: 0.0059  cls_loss: 0.0104  \n",
      "<<<iteration:[360/657] - total_loss: 0.2899  obj_loss: 0.1685  noobj_loss: 0.1668  bbox_loss: 0.0052  cls_loss: 0.0118  \n",
      "<<<iteration:[380/657] - total_loss: 0.2902  obj_loss: 0.1665  noobj_loss: 0.1697  bbox_loss: 0.0057  cls_loss: 0.0106  \n",
      "<<<iteration:[400/657] - total_loss: 0.2823  obj_loss: 0.1623  noobj_loss: 0.1688  bbox_loss: 0.0052  cls_loss: 0.0097  \n",
      "<<<iteration:[420/657] - total_loss: 0.2856  obj_loss: 0.1603  noobj_loss: 0.1706  bbox_loss: 0.0059  cls_loss: 0.0107  \n",
      "<<<iteration:[440/657] - total_loss: 0.2846  obj_loss: 0.1671  noobj_loss: 0.1642  bbox_loss: 0.0053  cls_loss: 0.0090  \n",
      "<<<iteration:[460/657] - total_loss: 0.3021  obj_loss: 0.1672  noobj_loss: 0.1760  bbox_loss: 0.0060  cls_loss: 0.0167  \n",
      "<<<iteration:[480/657] - total_loss: 0.2893  obj_loss: 0.1691  noobj_loss: 0.1667  bbox_loss: 0.0058  cls_loss: 0.0081  \n",
      "<<<iteration:[500/657] - total_loss: 0.2885  obj_loss: 0.1671  noobj_loss: 0.1642  bbox_loss: 0.0059  cls_loss: 0.0096  \n",
      "<<<iteration:[520/657] - total_loss: 0.3038  obj_loss: 0.1792  noobj_loss: 0.1749  bbox_loss: 0.0051  cls_loss: 0.0118  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<<<iteration:[540/657] - total_loss: 0.2900  obj_loss: 0.1695  noobj_loss: 0.1685  bbox_loss: 0.0057  cls_loss: 0.0075  \n",
      "<<<iteration:[560/657] - total_loss: 0.3002  obj_loss: 0.1758  noobj_loss: 0.1672  bbox_loss: 0.0063  cls_loss: 0.0093  \n",
      "<<<iteration:[580/657] - total_loss: 0.2922  obj_loss: 0.1679  noobj_loss: 0.1677  bbox_loss: 0.0060  cls_loss: 0.0105  \n",
      "<<<iteration:[600/657] - total_loss: 0.3095  obj_loss: 0.1822  noobj_loss: 0.1745  bbox_loss: 0.0056  cls_loss: 0.0118  \n",
      "<<<iteration:[620/657] - total_loss: 0.2988  obj_loss: 0.1773  noobj_loss: 0.1677  bbox_loss: 0.0056  cls_loss: 0.0096  \n",
      "<<<iteration:[640/657] - total_loss: 0.2839  obj_loss: 0.1592  noobj_loss: 0.1665  bbox_loss: 0.0057  cls_loss: 0.0128  \n",
      "\n",
      "epoch:63/100 - Train Loss: 0.2940, Val Loss: 0.3131\n",
      "\n",
      "<<<iteration:[20/657] - total_loss: 0.3176  obj_loss: 0.1822  noobj_loss: 0.1880  bbox_loss: 0.0061  cls_loss: 0.0110  \n",
      "<<<iteration:[40/657] - total_loss: 0.2949  obj_loss: 0.1724  noobj_loss: 0.1681  bbox_loss: 0.0059  cls_loss: 0.0090  \n",
      "<<<iteration:[60/657] - total_loss: 0.2936  obj_loss: 0.1712  noobj_loss: 0.1720  bbox_loss: 0.0053  cls_loss: 0.0100  \n",
      "<<<iteration:[80/657] - total_loss: 0.3139  obj_loss: 0.1847  noobj_loss: 0.1801  bbox_loss: 0.0053  cls_loss: 0.0125  \n",
      "<<<iteration:[100/657] - total_loss: 0.2906  obj_loss: 0.1710  noobj_loss: 0.1619  bbox_loss: 0.0061  cls_loss: 0.0080  \n",
      "<<<iteration:[120/657] - total_loss: 0.2974  obj_loss: 0.1725  noobj_loss: 0.1716  bbox_loss: 0.0056  cls_loss: 0.0112  \n",
      "<<<iteration:[140/657] - total_loss: 0.3052  obj_loss: 0.1769  noobj_loss: 0.1818  bbox_loss: 0.0055  cls_loss: 0.0099  \n",
      "<<<iteration:[160/657] - total_loss: 0.2830  obj_loss: 0.1636  noobj_loss: 0.1674  bbox_loss: 0.0054  cls_loss: 0.0088  \n",
      "<<<iteration:[180/657] - total_loss: 0.2831  obj_loss: 0.1652  noobj_loss: 0.1593  bbox_loss: 0.0056  cls_loss: 0.0102  \n",
      "<<<iteration:[200/657] - total_loss: 0.2878  obj_loss: 0.1677  noobj_loss: 0.1607  bbox_loss: 0.0061  cls_loss: 0.0091  \n",
      "<<<iteration:[220/657] - total_loss: 0.2921  obj_loss: 0.1667  noobj_loss: 0.1705  bbox_loss: 0.0058  cls_loss: 0.0112  \n",
      "<<<iteration:[240/657] - total_loss: 0.2817  obj_loss: 0.1656  noobj_loss: 0.1652  bbox_loss: 0.0049  cls_loss: 0.0089  \n",
      "<<<iteration:[260/657] - total_loss: 0.2821  obj_loss: 0.1628  noobj_loss: 0.1599  bbox_loss: 0.0059  cls_loss: 0.0098  \n",
      "<<<iteration:[280/657] - total_loss: 0.2939  obj_loss: 0.1736  noobj_loss: 0.1636  bbox_loss: 0.0054  cls_loss: 0.0113  \n",
      "<<<iteration:[300/657] - total_loss: 0.2926  obj_loss: 0.1749  noobj_loss: 0.1610  bbox_loss: 0.0054  cls_loss: 0.0102  \n",
      "<<<iteration:[320/657] - total_loss: 0.2921  obj_loss: 0.1711  noobj_loss: 0.1723  bbox_loss: 0.0051  cls_loss: 0.0096  \n",
      "<<<iteration:[340/657] - total_loss: 0.2922  obj_loss: 0.1685  noobj_loss: 0.1706  bbox_loss: 0.0056  cls_loss: 0.0104  \n",
      "<<<iteration:[360/657] - total_loss: 0.2937  obj_loss: 0.1682  noobj_loss: 0.1755  bbox_loss: 0.0056  cls_loss: 0.0097  \n",
      "<<<iteration:[380/657] - total_loss: 0.2994  obj_loss: 0.1739  noobj_loss: 0.1636  bbox_loss: 0.0058  cls_loss: 0.0147  \n",
      "<<<iteration:[400/657] - total_loss: 0.3074  obj_loss: 0.1822  noobj_loss: 0.1773  bbox_loss: 0.0056  cls_loss: 0.0084  \n",
      "<<<iteration:[420/657] - total_loss: 0.2883  obj_loss: 0.1694  noobj_loss: 0.1655  bbox_loss: 0.0053  cls_loss: 0.0094  \n",
      "<<<iteration:[440/657] - total_loss: 0.2981  obj_loss: 0.1766  noobj_loss: 0.1668  bbox_loss: 0.0056  cls_loss: 0.0099  \n",
      "<<<iteration:[460/657] - total_loss: 0.3044  obj_loss: 0.1796  noobj_loss: 0.1782  bbox_loss: 0.0051  cls_loss: 0.0101  \n",
      "<<<iteration:[480/657] - total_loss: 0.3079  obj_loss: 0.1786  noobj_loss: 0.1785  bbox_loss: 0.0059  cls_loss: 0.0107  \n",
      "<<<iteration:[500/657] - total_loss: 0.2883  obj_loss: 0.1564  noobj_loss: 0.1671  bbox_loss: 0.0063  cls_loss: 0.0166  \n",
      "<<<iteration:[520/657] - total_loss: 0.2838  obj_loss: 0.1583  noobj_loss: 0.1730  bbox_loss: 0.0058  cls_loss: 0.0099  \n",
      "<<<iteration:[540/657] - total_loss: 0.2964  obj_loss: 0.1764  noobj_loss: 0.1674  bbox_loss: 0.0054  cls_loss: 0.0093  \n",
      "<<<iteration:[560/657] - total_loss: 0.2866  obj_loss: 0.1639  noobj_loss: 0.1720  bbox_loss: 0.0056  cls_loss: 0.0084  \n",
      "<<<iteration:[580/657] - total_loss: 0.2864  obj_loss: 0.1635  noobj_loss: 0.1754  bbox_loss: 0.0054  cls_loss: 0.0080  \n",
      "<<<iteration:[600/657] - total_loss: 0.2888  obj_loss: 0.1710  noobj_loss: 0.1641  bbox_loss: 0.0050  cls_loss: 0.0107  \n",
      "<<<iteration:[620/657] - total_loss: 0.2959  obj_loss: 0.1689  noobj_loss: 0.1698  bbox_loss: 0.0060  cls_loss: 0.0121  \n",
      "<<<iteration:[640/657] - total_loss: 0.2958  obj_loss: 0.1755  noobj_loss: 0.1720  bbox_loss: 0.0050  cls_loss: 0.0092  \n",
      "\n",
      "epoch:64/100 - Train Loss: 0.2935, Val Loss: 0.3098\n",
      "\n",
      "<<<iteration:[20/657] - total_loss: 0.3195  obj_loss: 0.1904  noobj_loss: 0.1797  bbox_loss: 0.0058  cls_loss: 0.0101  \n",
      "<<<iteration:[40/657] - total_loss: 0.2942  obj_loss: 0.1710  noobj_loss: 0.1660  bbox_loss: 0.0056  cls_loss: 0.0120  \n",
      "<<<iteration:[60/657] - total_loss: 0.2922  obj_loss: 0.1694  noobj_loss: 0.1678  bbox_loss: 0.0059  cls_loss: 0.0097  \n",
      "<<<iteration:[80/657] - total_loss: 0.2962  obj_loss: 0.1727  noobj_loss: 0.1668  bbox_loss: 0.0058  cls_loss: 0.0113  \n",
      "<<<iteration:[100/657] - total_loss: 0.2964  obj_loss: 0.1724  noobj_loss: 0.1738  bbox_loss: 0.0054  cls_loss: 0.0098  \n",
      "<<<iteration:[120/657] - total_loss: 0.2984  obj_loss: 0.1814  noobj_loss: 0.1637  bbox_loss: 0.0051  cls_loss: 0.0098  \n",
      "<<<iteration:[140/657] - total_loss: 0.2929  obj_loss: 0.1685  noobj_loss: 0.1722  bbox_loss: 0.0056  cls_loss: 0.0102  \n",
      "<<<iteration:[160/657] - total_loss: 0.2970  obj_loss: 0.1730  noobj_loss: 0.1703  bbox_loss: 0.0053  cls_loss: 0.0125  \n",
      "<<<iteration:[180/657] - total_loss: 0.2841  obj_loss: 0.1632  noobj_loss: 0.1694  bbox_loss: 0.0052  cls_loss: 0.0101  \n",
      "<<<iteration:[200/657] - total_loss: 0.2986  obj_loss: 0.1678  noobj_loss: 0.1789  bbox_loss: 0.0058  cls_loss: 0.0124  \n",
      "<<<iteration:[220/657] - total_loss: 0.3044  obj_loss: 0.1798  noobj_loss: 0.1733  bbox_loss: 0.0054  cls_loss: 0.0110  \n",
      "<<<iteration:[240/657] - total_loss: 0.2875  obj_loss: 0.1631  noobj_loss: 0.1647  bbox_loss: 0.0057  cls_loss: 0.0135  \n",
      "<<<iteration:[260/657] - total_loss: 0.2872  obj_loss: 0.1595  noobj_loss: 0.1666  bbox_loss: 0.0060  cls_loss: 0.0144  \n",
      "<<<iteration:[280/657] - total_loss: 0.2957  obj_loss: 0.1795  noobj_loss: 0.1689  bbox_loss: 0.0047  cls_loss: 0.0081  \n",
      "<<<iteration:[300/657] - total_loss: 0.3109  obj_loss: 0.1827  noobj_loss: 0.1688  bbox_loss: 0.0061  cls_loss: 0.0130  \n",
      "<<<iteration:[320/657] - total_loss: 0.2989  obj_loss: 0.1742  noobj_loss: 0.1770  bbox_loss: 0.0053  cls_loss: 0.0099  \n",
      "<<<iteration:[340/657] - total_loss: 0.2810  obj_loss: 0.1552  noobj_loss: 0.1763  bbox_loss: 0.0058  cls_loss: 0.0088  \n",
      "<<<iteration:[360/657] - total_loss: 0.2997  obj_loss: 0.1690  noobj_loss: 0.1777  bbox_loss: 0.0062  cls_loss: 0.0111  \n",
      "<<<iteration:[380/657] - total_loss: 0.2927  obj_loss: 0.1708  noobj_loss: 0.1733  bbox_loss: 0.0052  cls_loss: 0.0092  \n",
      "<<<iteration:[400/657] - total_loss: 0.2970  obj_loss: 0.1696  noobj_loss: 0.1652  bbox_loss: 0.0067  cls_loss: 0.0111  \n",
      "<<<iteration:[420/657] - total_loss: 0.2749  obj_loss: 0.1551  noobj_loss: 0.1635  bbox_loss: 0.0061  cls_loss: 0.0077  \n",
      "<<<iteration:[440/657] - total_loss: 0.3030  obj_loss: 0.1846  noobj_loss: 0.1606  bbox_loss: 0.0052  cls_loss: 0.0119  \n",
      "<<<iteration:[460/657] - total_loss: 0.2879  obj_loss: 0.1685  noobj_loss: 0.1727  bbox_loss: 0.0051  cls_loss: 0.0075  \n",
      "<<<iteration:[480/657] - total_loss: 0.3024  obj_loss: 0.1811  noobj_loss: 0.1685  bbox_loss: 0.0049  cls_loss: 0.0126  \n",
      "<<<iteration:[500/657] - total_loss: 0.2917  obj_loss: 0.1651  noobj_loss: 0.1718  bbox_loss: 0.0060  cls_loss: 0.0106  \n",
      "<<<iteration:[520/657] - total_loss: 0.2916  obj_loss: 0.1750  noobj_loss: 0.1624  bbox_loss: 0.0049  cls_loss: 0.0108  \n",
      "<<<iteration:[540/657] - total_loss: 0.2942  obj_loss: 0.1619  noobj_loss: 0.1740  bbox_loss: 0.0064  cls_loss: 0.0131  \n",
      "<<<iteration:[560/657] - total_loss: 0.2970  obj_loss: 0.1681  noobj_loss: 0.1724  bbox_loss: 0.0064  cls_loss: 0.0108  \n",
      "<<<iteration:[580/657] - total_loss: 0.2858  obj_loss: 0.1674  noobj_loss: 0.1632  bbox_loss: 0.0053  cls_loss: 0.0104  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<<<iteration:[600/657] - total_loss: 0.2830  obj_loss: 0.1624  noobj_loss: 0.1681  bbox_loss: 0.0055  cls_loss: 0.0092  \n",
      "<<<iteration:[620/657] - total_loss: 0.2796  obj_loss: 0.1602  noobj_loss: 0.1671  bbox_loss: 0.0056  cls_loss: 0.0077  \n",
      "<<<iteration:[640/657] - total_loss: 0.2990  obj_loss: 0.1754  noobj_loss: 0.1667  bbox_loss: 0.0062  cls_loss: 0.0091  \n",
      "\n",
      "epoch:65/100 - Train Loss: 0.2953, Val Loss: 0.3130\n",
      "\n",
      "<<<iteration:[20/657] - total_loss: 0.3016  obj_loss: 0.1578  noobj_loss: 0.1616  bbox_loss: 0.0082  cls_loss: 0.0219  \n",
      "<<<iteration:[40/657] - total_loss: 0.2880  obj_loss: 0.1619  noobj_loss: 0.1607  bbox_loss: 0.0069  cls_loss: 0.0113  \n",
      "<<<iteration:[60/657] - total_loss: 0.2819  obj_loss: 0.1578  noobj_loss: 0.1547  bbox_loss: 0.0067  cls_loss: 0.0133  \n",
      "<<<iteration:[80/657] - total_loss: 0.2916  obj_loss: 0.1711  noobj_loss: 0.1702  bbox_loss: 0.0055  cls_loss: 0.0080  \n",
      "<<<iteration:[100/657] - total_loss: 0.2935  obj_loss: 0.1691  noobj_loss: 0.1686  bbox_loss: 0.0056  cls_loss: 0.0119  \n",
      "<<<iteration:[120/657] - total_loss: 0.2955  obj_loss: 0.1753  noobj_loss: 0.1637  bbox_loss: 0.0056  cls_loss: 0.0102  \n",
      "<<<iteration:[140/657] - total_loss: 0.2905  obj_loss: 0.1710  noobj_loss: 0.1665  bbox_loss: 0.0054  cls_loss: 0.0091  \n",
      "<<<iteration:[160/657] - total_loss: 0.2924  obj_loss: 0.1680  noobj_loss: 0.1667  bbox_loss: 0.0061  cls_loss: 0.0107  \n",
      "<<<iteration:[180/657] - total_loss: 0.3052  obj_loss: 0.1776  noobj_loss: 0.1714  bbox_loss: 0.0054  cls_loss: 0.0150  \n",
      "<<<iteration:[200/657] - total_loss: 0.3071  obj_loss: 0.1774  noobj_loss: 0.1743  bbox_loss: 0.0065  cls_loss: 0.0101  \n",
      "<<<iteration:[220/657] - total_loss: 0.3007  obj_loss: 0.1707  noobj_loss: 0.1719  bbox_loss: 0.0061  cls_loss: 0.0138  \n",
      "<<<iteration:[240/657] - total_loss: 0.2975  obj_loss: 0.1782  noobj_loss: 0.1720  bbox_loss: 0.0050  cls_loss: 0.0084  \n",
      "<<<iteration:[260/657] - total_loss: 0.2948  obj_loss: 0.1727  noobj_loss: 0.1688  bbox_loss: 0.0060  cls_loss: 0.0074  \n",
      "<<<iteration:[280/657] - total_loss: 0.2940  obj_loss: 0.1724  noobj_loss: 0.1739  bbox_loss: 0.0052  cls_loss: 0.0084  \n",
      "<<<iteration:[300/657] - total_loss: 0.2948  obj_loss: 0.1702  noobj_loss: 0.1705  bbox_loss: 0.0055  cls_loss: 0.0119  \n",
      "<<<iteration:[320/657] - total_loss: 0.2890  obj_loss: 0.1629  noobj_loss: 0.1796  bbox_loss: 0.0056  cls_loss: 0.0083  \n",
      "<<<iteration:[340/657] - total_loss: 0.2946  obj_loss: 0.1725  noobj_loss: 0.1654  bbox_loss: 0.0058  cls_loss: 0.0106  \n",
      "<<<iteration:[360/657] - total_loss: 0.2872  obj_loss: 0.1613  noobj_loss: 0.1675  bbox_loss: 0.0062  cls_loss: 0.0112  \n",
      "<<<iteration:[380/657] - total_loss: 0.2982  obj_loss: 0.1733  noobj_loss: 0.1727  bbox_loss: 0.0058  cls_loss: 0.0096  \n",
      "<<<iteration:[400/657] - total_loss: 0.3033  obj_loss: 0.1803  noobj_loss: 0.1703  bbox_loss: 0.0054  cls_loss: 0.0108  \n",
      "<<<iteration:[420/657] - total_loss: 0.2887  obj_loss: 0.1564  noobj_loss: 0.1751  bbox_loss: 0.0061  cls_loss: 0.0145  \n",
      "<<<iteration:[440/657] - total_loss: 0.2972  obj_loss: 0.1748  noobj_loss: 0.1780  bbox_loss: 0.0051  cls_loss: 0.0081  \n",
      "<<<iteration:[460/657] - total_loss: 0.2926  obj_loss: 0.1691  noobj_loss: 0.1718  bbox_loss: 0.0054  cls_loss: 0.0108  \n",
      "<<<iteration:[480/657] - total_loss: 0.3044  obj_loss: 0.1784  noobj_loss: 0.1724  bbox_loss: 0.0060  cls_loss: 0.0100  \n",
      "<<<iteration:[500/657] - total_loss: 0.2894  obj_loss: 0.1693  noobj_loss: 0.1627  bbox_loss: 0.0056  cls_loss: 0.0109  \n",
      "<<<iteration:[520/657] - total_loss: 0.2940  obj_loss: 0.1670  noobj_loss: 0.1764  bbox_loss: 0.0055  cls_loss: 0.0111  \n",
      "<<<iteration:[540/657] - total_loss: 0.2773  obj_loss: 0.1605  noobj_loss: 0.1655  bbox_loss: 0.0052  cls_loss: 0.0081  \n",
      "<<<iteration:[560/657] - total_loss: 0.2872  obj_loss: 0.1670  noobj_loss: 0.1717  bbox_loss: 0.0052  cls_loss: 0.0083  \n",
      "<<<iteration:[580/657] - total_loss: 0.2918  obj_loss: 0.1665  noobj_loss: 0.1697  bbox_loss: 0.0056  cls_loss: 0.0126  \n",
      "<<<iteration:[600/657] - total_loss: 0.2953  obj_loss: 0.1771  noobj_loss: 0.1711  bbox_loss: 0.0049  cls_loss: 0.0079  \n",
      "<<<iteration:[620/657] - total_loss: 0.2817  obj_loss: 0.1666  noobj_loss: 0.1587  bbox_loss: 0.0054  cls_loss: 0.0087  \n",
      "<<<iteration:[640/657] - total_loss: 0.3031  obj_loss: 0.1816  noobj_loss: 0.1770  bbox_loss: 0.0049  cls_loss: 0.0085  \n",
      "\n",
      "epoch:66/100 - Train Loss: 0.2934, Val Loss: 0.3090\n",
      "\n",
      "<<<iteration:[20/657] - total_loss: 0.3036  obj_loss: 0.1694  noobj_loss: 0.1841  bbox_loss: 0.0064  cls_loss: 0.0100  \n",
      "<<<iteration:[40/657] - total_loss: 0.2902  obj_loss: 0.1628  noobj_loss: 0.1755  bbox_loss: 0.0055  cls_loss: 0.0122  \n",
      "<<<iteration:[60/657] - total_loss: 0.2894  obj_loss: 0.1693  noobj_loss: 0.1685  bbox_loss: 0.0054  cls_loss: 0.0088  \n",
      "<<<iteration:[80/657] - total_loss: 0.2975  obj_loss: 0.1727  noobj_loss: 0.1702  bbox_loss: 0.0060  cls_loss: 0.0096  \n",
      "<<<iteration:[100/657] - total_loss: 0.2919  obj_loss: 0.1739  noobj_loss: 0.1703  bbox_loss: 0.0050  cls_loss: 0.0076  \n",
      "<<<iteration:[120/657] - total_loss: 0.2922  obj_loss: 0.1673  noobj_loss: 0.1705  bbox_loss: 0.0061  cls_loss: 0.0093  \n",
      "<<<iteration:[140/657] - total_loss: 0.2809  obj_loss: 0.1563  noobj_loss: 0.1778  bbox_loss: 0.0052  cls_loss: 0.0095  \n",
      "<<<iteration:[160/657] - total_loss: 0.2970  obj_loss: 0.1763  noobj_loss: 0.1675  bbox_loss: 0.0056  cls_loss: 0.0091  \n",
      "<<<iteration:[180/657] - total_loss: 0.2822  obj_loss: 0.1609  noobj_loss: 0.1733  bbox_loss: 0.0055  cls_loss: 0.0071  \n",
      "<<<iteration:[200/657] - total_loss: 0.2934  obj_loss: 0.1690  noobj_loss: 0.1766  bbox_loss: 0.0050  cls_loss: 0.0110  \n",
      "<<<iteration:[220/657] - total_loss: 0.2894  obj_loss: 0.1595  noobj_loss: 0.1763  bbox_loss: 0.0065  cls_loss: 0.0093  \n",
      "<<<iteration:[240/657] - total_loss: 0.2954  obj_loss: 0.1787  noobj_loss: 0.1709  bbox_loss: 0.0048  cls_loss: 0.0073  \n",
      "<<<iteration:[260/657] - total_loss: 0.3003  obj_loss: 0.1793  noobj_loss: 0.1752  bbox_loss: 0.0049  cls_loss: 0.0089  \n",
      "<<<iteration:[280/657] - total_loss: 0.2976  obj_loss: 0.1745  noobj_loss: 0.1662  bbox_loss: 0.0058  cls_loss: 0.0108  \n",
      "<<<iteration:[300/657] - total_loss: 0.2991  obj_loss: 0.1746  noobj_loss: 0.1710  bbox_loss: 0.0057  cls_loss: 0.0107  \n",
      "<<<iteration:[320/657] - total_loss: 0.2905  obj_loss: 0.1686  noobj_loss: 0.1707  bbox_loss: 0.0050  cls_loss: 0.0116  \n",
      "<<<iteration:[340/657] - total_loss: 0.2816  obj_loss: 0.1616  noobj_loss: 0.1707  bbox_loss: 0.0053  cls_loss: 0.0081  \n",
      "<<<iteration:[360/657] - total_loss: 0.2944  obj_loss: 0.1692  noobj_loss: 0.1810  bbox_loss: 0.0050  cls_loss: 0.0097  \n",
      "<<<iteration:[380/657] - total_loss: 0.2906  obj_loss: 0.1596  noobj_loss: 0.1813  bbox_loss: 0.0058  cls_loss: 0.0116  \n",
      "<<<iteration:[400/657] - total_loss: 0.2926  obj_loss: 0.1705  noobj_loss: 0.1673  bbox_loss: 0.0056  cls_loss: 0.0105  \n",
      "<<<iteration:[420/657] - total_loss: 0.3011  obj_loss: 0.1794  noobj_loss: 0.1720  bbox_loss: 0.0055  cls_loss: 0.0081  \n",
      "<<<iteration:[440/657] - total_loss: 0.3190  obj_loss: 0.1837  noobj_loss: 0.1764  bbox_loss: 0.0057  cls_loss: 0.0184  \n",
      "<<<iteration:[460/657] - total_loss: 0.2930  obj_loss: 0.1750  noobj_loss: 0.1729  bbox_loss: 0.0049  cls_loss: 0.0069  \n",
      "<<<iteration:[480/657] - total_loss: 0.2946  obj_loss: 0.1707  noobj_loss: 0.1748  bbox_loss: 0.0056  cls_loss: 0.0085  \n",
      "<<<iteration:[500/657] - total_loss: 0.2976  obj_loss: 0.1716  noobj_loss: 0.1785  bbox_loss: 0.0053  cls_loss: 0.0100  \n",
      "<<<iteration:[520/657] - total_loss: 0.2971  obj_loss: 0.1765  noobj_loss: 0.1668  bbox_loss: 0.0052  cls_loss: 0.0111  \n",
      "<<<iteration:[540/657] - total_loss: 0.2954  obj_loss: 0.1698  noobj_loss: 0.1724  bbox_loss: 0.0062  cls_loss: 0.0083  \n",
      "<<<iteration:[560/657] - total_loss: 0.2786  obj_loss: 0.1581  noobj_loss: 0.1685  bbox_loss: 0.0057  cls_loss: 0.0078  \n",
      "<<<iteration:[580/657] - total_loss: 0.2925  obj_loss: 0.1703  noobj_loss: 0.1691  bbox_loss: 0.0054  cls_loss: 0.0106  \n",
      "<<<iteration:[600/657] - total_loss: 0.2966  obj_loss: 0.1704  noobj_loss: 0.1770  bbox_loss: 0.0057  cls_loss: 0.0092  \n",
      "<<<iteration:[620/657] - total_loss: 0.2923  obj_loss: 0.1710  noobj_loss: 0.1758  bbox_loss: 0.0050  cls_loss: 0.0082  \n",
      "<<<iteration:[640/657] - total_loss: 0.2880  obj_loss: 0.1660  noobj_loss: 0.1786  bbox_loss: 0.0050  cls_loss: 0.0077  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "epoch:67/100 - Train Loss: 0.2930, Val Loss: 0.3100\n",
      "\n",
      "<<<iteration:[20/657] - total_loss: 0.3260  obj_loss: 0.1994  noobj_loss: 0.1790  bbox_loss: 0.0052  cls_loss: 0.0108  \n",
      "<<<iteration:[40/657] - total_loss: 0.2906  obj_loss: 0.1651  noobj_loss: 0.1756  bbox_loss: 0.0054  cls_loss: 0.0107  \n",
      "<<<iteration:[60/657] - total_loss: 0.2924  obj_loss: 0.1662  noobj_loss: 0.1734  bbox_loss: 0.0052  cls_loss: 0.0134  \n",
      "<<<iteration:[80/657] - total_loss: 0.2721  obj_loss: 0.1597  noobj_loss: 0.1673  bbox_loss: 0.0045  cls_loss: 0.0062  \n",
      "<<<iteration:[100/657] - total_loss: 0.2769  obj_loss: 0.1570  noobj_loss: 0.1709  bbox_loss: 0.0050  cls_loss: 0.0095  \n",
      "<<<iteration:[120/657] - total_loss: 0.3006  obj_loss: 0.1805  noobj_loss: 0.1646  bbox_loss: 0.0057  cls_loss: 0.0092  \n",
      "<<<iteration:[140/657] - total_loss: 0.2846  obj_loss: 0.1672  noobj_loss: 0.1717  bbox_loss: 0.0050  cls_loss: 0.0067  \n",
      "<<<iteration:[160/657] - total_loss: 0.2872  obj_loss: 0.1628  noobj_loss: 0.1763  bbox_loss: 0.0055  cls_loss: 0.0088  \n",
      "<<<iteration:[180/657] - total_loss: 0.2863  obj_loss: 0.1695  noobj_loss: 0.1680  bbox_loss: 0.0050  cls_loss: 0.0080  \n",
      "<<<iteration:[200/657] - total_loss: 0.2895  obj_loss: 0.1642  noobj_loss: 0.1709  bbox_loss: 0.0060  cls_loss: 0.0099  \n",
      "<<<iteration:[220/657] - total_loss: 0.2938  obj_loss: 0.1730  noobj_loss: 0.1729  bbox_loss: 0.0052  cls_loss: 0.0082  \n",
      "<<<iteration:[240/657] - total_loss: 0.2971  obj_loss: 0.1744  noobj_loss: 0.1746  bbox_loss: 0.0054  cls_loss: 0.0082  \n",
      "<<<iteration:[260/657] - total_loss: 0.2983  obj_loss: 0.1695  noobj_loss: 0.1793  bbox_loss: 0.0054  cls_loss: 0.0121  \n",
      "<<<iteration:[280/657] - total_loss: 0.3033  obj_loss: 0.1782  noobj_loss: 0.1713  bbox_loss: 0.0057  cls_loss: 0.0108  \n",
      "<<<iteration:[300/657] - total_loss: 0.2976  obj_loss: 0.1727  noobj_loss: 0.1820  bbox_loss: 0.0052  cls_loss: 0.0077  \n",
      "<<<iteration:[320/657] - total_loss: 0.3025  obj_loss: 0.1791  noobj_loss: 0.1754  bbox_loss: 0.0051  cls_loss: 0.0104  \n",
      "<<<iteration:[340/657] - total_loss: 0.2854  obj_loss: 0.1585  noobj_loss: 0.1764  bbox_loss: 0.0053  cls_loss: 0.0123  \n",
      "<<<iteration:[360/657] - total_loss: 0.3076  obj_loss: 0.1816  noobj_loss: 0.1725  bbox_loss: 0.0057  cls_loss: 0.0114  \n",
      "<<<iteration:[380/657] - total_loss: 0.2944  obj_loss: 0.1691  noobj_loss: 0.1792  bbox_loss: 0.0052  cls_loss: 0.0098  \n",
      "<<<iteration:[400/657] - total_loss: 0.2883  obj_loss: 0.1657  noobj_loss: 0.1714  bbox_loss: 0.0053  cls_loss: 0.0105  \n",
      "<<<iteration:[420/657] - total_loss: 0.3007  obj_loss: 0.1760  noobj_loss: 0.1743  bbox_loss: 0.0055  cls_loss: 0.0100  \n",
      "<<<iteration:[440/657] - total_loss: 0.2921  obj_loss: 0.1676  noobj_loss: 0.1656  bbox_loss: 0.0060  cls_loss: 0.0117  \n",
      "<<<iteration:[460/657] - total_loss: 0.2934  obj_loss: 0.1623  noobj_loss: 0.1737  bbox_loss: 0.0068  cls_loss: 0.0104  \n",
      "<<<iteration:[480/657] - total_loss: 0.3126  obj_loss: 0.1872  noobj_loss: 0.1771  bbox_loss: 0.0055  cls_loss: 0.0093  \n",
      "<<<iteration:[500/657] - total_loss: 0.2919  obj_loss: 0.1612  noobj_loss: 0.1778  bbox_loss: 0.0058  cls_loss: 0.0127  \n",
      "<<<iteration:[520/657] - total_loss: 0.2800  obj_loss: 0.1634  noobj_loss: 0.1704  bbox_loss: 0.0048  cls_loss: 0.0072  \n",
      "<<<iteration:[540/657] - total_loss: 0.3104  obj_loss: 0.1828  noobj_loss: 0.1812  bbox_loss: 0.0053  cls_loss: 0.0105  \n",
      "<<<iteration:[560/657] - total_loss: 0.2920  obj_loss: 0.1694  noobj_loss: 0.1750  bbox_loss: 0.0056  cls_loss: 0.0071  \n",
      "<<<iteration:[580/657] - total_loss: 0.2847  obj_loss: 0.1526  noobj_loss: 0.1762  bbox_loss: 0.0059  cls_loss: 0.0144  \n",
      "<<<iteration:[600/657] - total_loss: 0.2972  obj_loss: 0.1715  noobj_loss: 0.1814  bbox_loss: 0.0056  cls_loss: 0.0071  \n",
      "<<<iteration:[620/657] - total_loss: 0.2911  obj_loss: 0.1709  noobj_loss: 0.1643  bbox_loss: 0.0056  cls_loss: 0.0101  \n",
      "<<<iteration:[640/657] - total_loss: 0.2835  obj_loss: 0.1603  noobj_loss: 0.1663  bbox_loss: 0.0061  cls_loss: 0.0097  \n",
      "\n",
      "epoch:68/100 - Train Loss: 0.2932, Val Loss: 0.3096\n",
      "\n",
      "<<<iteration:[20/657] - total_loss: 0.3125  obj_loss: 0.1835  noobj_loss: 0.1798  bbox_loss: 0.0059  cls_loss: 0.0095  \n",
      "<<<iteration:[40/657] - total_loss: 0.2915  obj_loss: 0.1741  noobj_loss: 0.1721  bbox_loss: 0.0047  cls_loss: 0.0079  \n",
      "<<<iteration:[60/657] - total_loss: 0.2930  obj_loss: 0.1679  noobj_loss: 0.1704  bbox_loss: 0.0055  cls_loss: 0.0127  \n",
      "<<<iteration:[80/657] - total_loss: 0.2904  obj_loss: 0.1679  noobj_loss: 0.1703  bbox_loss: 0.0056  cls_loss: 0.0095  \n",
      "<<<iteration:[100/657] - total_loss: 0.2992  obj_loss: 0.1765  noobj_loss: 0.1806  bbox_loss: 0.0049  cls_loss: 0.0079  \n",
      "<<<iteration:[120/657] - total_loss: 0.2666  obj_loss: 0.1487  noobj_loss: 0.1665  bbox_loss: 0.0053  cls_loss: 0.0081  \n",
      "<<<iteration:[140/657] - total_loss: 0.2969  obj_loss: 0.1715  noobj_loss: 0.1695  bbox_loss: 0.0053  cls_loss: 0.0143  \n",
      "<<<iteration:[160/657] - total_loss: 0.2904  obj_loss: 0.1656  noobj_loss: 0.1763  bbox_loss: 0.0054  cls_loss: 0.0099  \n",
      "<<<iteration:[180/657] - total_loss: 0.2982  obj_loss: 0.1718  noobj_loss: 0.1702  bbox_loss: 0.0056  cls_loss: 0.0131  \n",
      "<<<iteration:[200/657] - total_loss: 0.2855  obj_loss: 0.1650  noobj_loss: 0.1770  bbox_loss: 0.0050  cls_loss: 0.0071  \n",
      "<<<iteration:[220/657] - total_loss: 0.2978  obj_loss: 0.1752  noobj_loss: 0.1705  bbox_loss: 0.0057  cls_loss: 0.0091  \n",
      "<<<iteration:[240/657] - total_loss: 0.2837  obj_loss: 0.1659  noobj_loss: 0.1678  bbox_loss: 0.0054  cls_loss: 0.0072  \n",
      "<<<iteration:[260/657] - total_loss: 0.2883  obj_loss: 0.1646  noobj_loss: 0.1796  bbox_loss: 0.0053  cls_loss: 0.0075  \n",
      "<<<iteration:[280/657] - total_loss: 0.3037  obj_loss: 0.1827  noobj_loss: 0.1773  bbox_loss: 0.0048  cls_loss: 0.0084  \n",
      "<<<iteration:[300/657] - total_loss: 0.2821  obj_loss: 0.1624  noobj_loss: 0.1685  bbox_loss: 0.0051  cls_loss: 0.0103  \n",
      "<<<iteration:[320/657] - total_loss: 0.3125  obj_loss: 0.1871  noobj_loss: 0.1791  bbox_loss: 0.0053  cls_loss: 0.0095  \n",
      "<<<iteration:[340/657] - total_loss: 0.2931  obj_loss: 0.1654  noobj_loss: 0.1763  bbox_loss: 0.0056  cls_loss: 0.0113  \n",
      "<<<iteration:[360/657] - total_loss: 0.2890  obj_loss: 0.1666  noobj_loss: 0.1740  bbox_loss: 0.0056  cls_loss: 0.0073  \n",
      "<<<iteration:[380/657] - total_loss: 0.2955  obj_loss: 0.1681  noobj_loss: 0.1795  bbox_loss: 0.0058  cls_loss: 0.0087  \n",
      "<<<iteration:[400/657] - total_loss: 0.2881  obj_loss: 0.1685  noobj_loss: 0.1734  bbox_loss: 0.0051  cls_loss: 0.0073  \n",
      "<<<iteration:[420/657] - total_loss: 0.2980  obj_loss: 0.1739  noobj_loss: 0.1787  bbox_loss: 0.0053  cls_loss: 0.0083  \n",
      "<<<iteration:[440/657] - total_loss: 0.2899  obj_loss: 0.1663  noobj_loss: 0.1779  bbox_loss: 0.0054  cls_loss: 0.0078  \n",
      "<<<iteration:[460/657] - total_loss: 0.2933  obj_loss: 0.1699  noobj_loss: 0.1741  bbox_loss: 0.0057  cls_loss: 0.0080  \n",
      "<<<iteration:[480/657] - total_loss: 0.2965  obj_loss: 0.1755  noobj_loss: 0.1774  bbox_loss: 0.0051  cls_loss: 0.0070  \n",
      "<<<iteration:[500/657] - total_loss: 0.2996  obj_loss: 0.1762  noobj_loss: 0.1752  bbox_loss: 0.0057  cls_loss: 0.0072  \n",
      "<<<iteration:[520/657] - total_loss: 0.2949  obj_loss: 0.1702  noobj_loss: 0.1711  bbox_loss: 0.0060  cls_loss: 0.0092  \n",
      "<<<iteration:[540/657] - total_loss: 0.2859  obj_loss: 0.1631  noobj_loss: 0.1721  bbox_loss: 0.0052  cls_loss: 0.0107  \n",
      "<<<iteration:[560/657] - total_loss: 0.2923  obj_loss: 0.1716  noobj_loss: 0.1723  bbox_loss: 0.0051  cls_loss: 0.0092  \n",
      "<<<iteration:[580/657] - total_loss: 0.3000  obj_loss: 0.1734  noobj_loss: 0.1766  bbox_loss: 0.0055  cls_loss: 0.0108  \n",
      "<<<iteration:[600/657] - total_loss: 0.2915  obj_loss: 0.1696  noobj_loss: 0.1775  bbox_loss: 0.0049  cls_loss: 0.0087  \n",
      "<<<iteration:[620/657] - total_loss: 0.2961  obj_loss: 0.1729  noobj_loss: 0.1719  bbox_loss: 0.0051  cls_loss: 0.0117  \n",
      "<<<iteration:[640/657] - total_loss: 0.3011  obj_loss: 0.1766  noobj_loss: 0.1752  bbox_loss: 0.0053  cls_loss: 0.0102  \n",
      "\n",
      "epoch:69/100 - Train Loss: 0.2930, Val Loss: 0.3084\n",
      "\n",
      "<<<iteration:[20/657] - total_loss: 0.3017  obj_loss: 0.1710  noobj_loss: 0.1848  bbox_loss: 0.0060  cls_loss: 0.0086  \n",
      "<<<iteration:[40/657] - total_loss: 0.2973  obj_loss: 0.1785  noobj_loss: 0.1752  bbox_loss: 0.0050  cls_loss: 0.0062  \n",
      "<<<iteration:[60/657] - total_loss: 0.2849  obj_loss: 0.1583  noobj_loss: 0.1698  bbox_loss: 0.0056  cls_loss: 0.0135  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<<<iteration:[80/657] - total_loss: 0.2833  obj_loss: 0.1579  noobj_loss: 0.1791  bbox_loss: 0.0054  cls_loss: 0.0088  \n",
      "<<<iteration:[100/657] - total_loss: 0.2952  obj_loss: 0.1748  noobj_loss: 0.1774  bbox_loss: 0.0048  cls_loss: 0.0079  \n",
      "<<<iteration:[120/657] - total_loss: 0.2865  obj_loss: 0.1650  noobj_loss: 0.1652  bbox_loss: 0.0051  cls_loss: 0.0132  \n",
      "<<<iteration:[140/657] - total_loss: 0.2857  obj_loss: 0.1646  noobj_loss: 0.1751  bbox_loss: 0.0050  cls_loss: 0.0087  \n",
      "<<<iteration:[160/657] - total_loss: 0.3019  obj_loss: 0.1760  noobj_loss: 0.1716  bbox_loss: 0.0054  cls_loss: 0.0133  \n",
      "<<<iteration:[180/657] - total_loss: 0.2970  obj_loss: 0.1719  noobj_loss: 0.1721  bbox_loss: 0.0055  cls_loss: 0.0117  \n",
      "<<<iteration:[200/657] - total_loss: 0.3009  obj_loss: 0.1743  noobj_loss: 0.1800  bbox_loss: 0.0054  cls_loss: 0.0097  \n",
      "<<<iteration:[220/657] - total_loss: 0.2917  obj_loss: 0.1698  noobj_loss: 0.1695  bbox_loss: 0.0053  cls_loss: 0.0105  \n",
      "<<<iteration:[240/657] - total_loss: 0.3049  obj_loss: 0.1767  noobj_loss: 0.1849  bbox_loss: 0.0051  cls_loss: 0.0101  \n",
      "<<<iteration:[260/657] - total_loss: 0.2978  obj_loss: 0.1748  noobj_loss: 0.1767  bbox_loss: 0.0051  cls_loss: 0.0094  \n",
      "<<<iteration:[280/657] - total_loss: 0.2855  obj_loss: 0.1603  noobj_loss: 0.1772  bbox_loss: 0.0054  cls_loss: 0.0098  \n",
      "<<<iteration:[300/657] - total_loss: 0.2832  obj_loss: 0.1664  noobj_loss: 0.1670  bbox_loss: 0.0051  cls_loss: 0.0079  \n",
      "<<<iteration:[320/657] - total_loss: 0.2969  obj_loss: 0.1773  noobj_loss: 0.1763  bbox_loss: 0.0052  cls_loss: 0.0056  \n",
      "<<<iteration:[340/657] - total_loss: 0.2900  obj_loss: 0.1688  noobj_loss: 0.1753  bbox_loss: 0.0049  cls_loss: 0.0091  \n",
      "<<<iteration:[360/657] - total_loss: 0.2834  obj_loss: 0.1537  noobj_loss: 0.1790  bbox_loss: 0.0060  cls_loss: 0.0100  \n",
      "<<<iteration:[380/657] - total_loss: 0.2949  obj_loss: 0.1690  noobj_loss: 0.1770  bbox_loss: 0.0054  cls_loss: 0.0105  \n",
      "<<<iteration:[400/657] - total_loss: 0.2896  obj_loss: 0.1680  noobj_loss: 0.1699  bbox_loss: 0.0051  cls_loss: 0.0109  \n",
      "<<<iteration:[420/657] - total_loss: 0.3004  obj_loss: 0.1795  noobj_loss: 0.1707  bbox_loss: 0.0054  cls_loss: 0.0086  \n",
      "<<<iteration:[440/657] - total_loss: 0.2901  obj_loss: 0.1634  noobj_loss: 0.1761  bbox_loss: 0.0054  cls_loss: 0.0119  \n",
      "<<<iteration:[460/657] - total_loss: 0.2977  obj_loss: 0.1714  noobj_loss: 0.1708  bbox_loss: 0.0059  cls_loss: 0.0112  \n",
      "<<<iteration:[480/657] - total_loss: 0.2878  obj_loss: 0.1651  noobj_loss: 0.1767  bbox_loss: 0.0049  cls_loss: 0.0096  \n",
      "<<<iteration:[500/657] - total_loss: 0.2859  obj_loss: 0.1669  noobj_loss: 0.1681  bbox_loss: 0.0056  cls_loss: 0.0071  \n",
      "<<<iteration:[520/657] - total_loss: 0.2947  obj_loss: 0.1711  noobj_loss: 0.1699  bbox_loss: 0.0054  cls_loss: 0.0115  \n",
      "<<<iteration:[540/657] - total_loss: 0.2968  obj_loss: 0.1693  noobj_loss: 0.1775  bbox_loss: 0.0056  cls_loss: 0.0107  \n",
      "<<<iteration:[560/657] - total_loss: 0.2915  obj_loss: 0.1686  noobj_loss: 0.1688  bbox_loss: 0.0057  cls_loss: 0.0098  \n",
      "<<<iteration:[580/657] - total_loss: 0.2753  obj_loss: 0.1529  noobj_loss: 0.1673  bbox_loss: 0.0057  cls_loss: 0.0104  \n",
      "<<<iteration:[600/657] - total_loss: 0.2877  obj_loss: 0.1658  noobj_loss: 0.1746  bbox_loss: 0.0056  cls_loss: 0.0065  \n",
      "<<<iteration:[620/657] - total_loss: 0.2899  obj_loss: 0.1714  noobj_loss: 0.1731  bbox_loss: 0.0050  cls_loss: 0.0071  \n",
      "<<<iteration:[640/657] - total_loss: 0.2937  obj_loss: 0.1647  noobj_loss: 0.1819  bbox_loss: 0.0054  cls_loss: 0.0113  \n",
      "\n",
      "epoch:70/100 - Train Loss: 0.2915, Val Loss: 0.3129\n",
      "\n",
      "<<<iteration:[20/657] - total_loss: 0.3008  obj_loss: 0.1795  noobj_loss: 0.1774  bbox_loss: 0.0048  cls_loss: 0.0087  \n",
      "<<<iteration:[40/657] - total_loss: 0.2863  obj_loss: 0.1624  noobj_loss: 0.1735  bbox_loss: 0.0057  cls_loss: 0.0087  \n",
      "<<<iteration:[60/657] - total_loss: 0.2843  obj_loss: 0.1588  noobj_loss: 0.1764  bbox_loss: 0.0057  cls_loss: 0.0087  \n",
      "<<<iteration:[80/657] - total_loss: 0.2938  obj_loss: 0.1683  noobj_loss: 0.1694  bbox_loss: 0.0056  cls_loss: 0.0128  \n",
      "<<<iteration:[100/657] - total_loss: 0.2854  obj_loss: 0.1680  noobj_loss: 0.1688  bbox_loss: 0.0051  cls_loss: 0.0076  \n",
      "<<<iteration:[120/657] - total_loss: 0.2885  obj_loss: 0.1686  noobj_loss: 0.1725  bbox_loss: 0.0050  cls_loss: 0.0084  \n",
      "<<<iteration:[140/657] - total_loss: 0.3055  obj_loss: 0.1780  noobj_loss: 0.1798  bbox_loss: 0.0057  cls_loss: 0.0089  \n",
      "<<<iteration:[160/657] - total_loss: 0.2977  obj_loss: 0.1727  noobj_loss: 0.1807  bbox_loss: 0.0055  cls_loss: 0.0070  \n",
      "<<<iteration:[180/657] - total_loss: 0.2902  obj_loss: 0.1716  noobj_loss: 0.1761  bbox_loss: 0.0050  cls_loss: 0.0057  \n",
      "<<<iteration:[200/657] - total_loss: 0.2894  obj_loss: 0.1645  noobj_loss: 0.1810  bbox_loss: 0.0053  cls_loss: 0.0080  \n",
      "<<<iteration:[220/657] - total_loss: 0.2900  obj_loss: 0.1674  noobj_loss: 0.1682  bbox_loss: 0.0054  cls_loss: 0.0113  \n",
      "<<<iteration:[240/657] - total_loss: 0.2842  obj_loss: 0.1583  noobj_loss: 0.1715  bbox_loss: 0.0062  cls_loss: 0.0090  \n",
      "<<<iteration:[260/657] - total_loss: 0.2826  obj_loss: 0.1662  noobj_loss: 0.1685  bbox_loss: 0.0049  cls_loss: 0.0075  \n",
      "<<<iteration:[280/657] - total_loss: 0.3116  obj_loss: 0.1843  noobj_loss: 0.1840  bbox_loss: 0.0053  cls_loss: 0.0089  \n",
      "<<<iteration:[300/657] - total_loss: 0.2955  obj_loss: 0.1713  noobj_loss: 0.1794  bbox_loss: 0.0052  cls_loss: 0.0083  \n",
      "<<<iteration:[320/657] - total_loss: 0.2948  obj_loss: 0.1702  noobj_loss: 0.1790  bbox_loss: 0.0051  cls_loss: 0.0097  \n",
      "<<<iteration:[340/657] - total_loss: 0.2885  obj_loss: 0.1595  noobj_loss: 0.1789  bbox_loss: 0.0059  cls_loss: 0.0101  \n",
      "<<<iteration:[360/657] - total_loss: 0.2855  obj_loss: 0.1712  noobj_loss: 0.1660  bbox_loss: 0.0048  cls_loss: 0.0076  \n",
      "<<<iteration:[380/657] - total_loss: 0.2896  obj_loss: 0.1696  noobj_loss: 0.1666  bbox_loss: 0.0051  cls_loss: 0.0112  \n",
      "<<<iteration:[400/657] - total_loss: 0.2777  obj_loss: 0.1571  noobj_loss: 0.1735  bbox_loss: 0.0053  cls_loss: 0.0075  \n",
      "<<<iteration:[420/657] - total_loss: 0.2939  obj_loss: 0.1741  noobj_loss: 0.1680  bbox_loss: 0.0052  cls_loss: 0.0099  \n",
      "<<<iteration:[440/657] - total_loss: 0.2850  obj_loss: 0.1650  noobj_loss: 0.1682  bbox_loss: 0.0054  cls_loss: 0.0091  \n",
      "<<<iteration:[460/657] - total_loss: 0.2914  obj_loss: 0.1656  noobj_loss: 0.1667  bbox_loss: 0.0059  cls_loss: 0.0128  \n",
      "<<<iteration:[480/657] - total_loss: 0.2890  obj_loss: 0.1711  noobj_loss: 0.1650  bbox_loss: 0.0050  cls_loss: 0.0107  \n",
      "<<<iteration:[500/657] - total_loss: 0.2942  obj_loss: 0.1682  noobj_loss: 0.1846  bbox_loss: 0.0049  cls_loss: 0.0091  \n",
      "<<<iteration:[520/657] - total_loss: 0.3130  obj_loss: 0.1807  noobj_loss: 0.1868  bbox_loss: 0.0055  cls_loss: 0.0113  \n",
      "<<<iteration:[540/657] - total_loss: 0.2990  obj_loss: 0.1725  noobj_loss: 0.1838  bbox_loss: 0.0055  cls_loss: 0.0073  \n",
      "<<<iteration:[560/657] - total_loss: 0.2827  obj_loss: 0.1589  noobj_loss: 0.1771  bbox_loss: 0.0051  cls_loss: 0.0096  \n",
      "<<<iteration:[580/657] - total_loss: 0.2879  obj_loss: 0.1674  noobj_loss: 0.1738  bbox_loss: 0.0050  cls_loss: 0.0088  \n",
      "<<<iteration:[600/657] - total_loss: 0.2918  obj_loss: 0.1714  noobj_loss: 0.1753  bbox_loss: 0.0050  cls_loss: 0.0079  \n",
      "<<<iteration:[620/657] - total_loss: 0.2901  obj_loss: 0.1639  noobj_loss: 0.1837  bbox_loss: 0.0049  cls_loss: 0.0101  \n",
      "<<<iteration:[640/657] - total_loss: 0.3002  obj_loss: 0.1743  noobj_loss: 0.1782  bbox_loss: 0.0054  cls_loss: 0.0098  \n",
      "\n",
      "epoch:71/100 - Train Loss: 0.2917, Val Loss: 0.3091\n",
      "\n",
      "<<<iteration:[20/657] - total_loss: 0.3099  obj_loss: 0.1767  noobj_loss: 0.1808  bbox_loss: 0.0065  cls_loss: 0.0101  \n",
      "<<<iteration:[40/657] - total_loss: 0.2845  obj_loss: 0.1644  noobj_loss: 0.1750  bbox_loss: 0.0052  cls_loss: 0.0065  \n",
      "<<<iteration:[60/657] - total_loss: 0.2969  obj_loss: 0.1731  noobj_loss: 0.1771  bbox_loss: 0.0051  cls_loss: 0.0097  \n",
      "<<<iteration:[80/657] - total_loss: 0.2948  obj_loss: 0.1697  noobj_loss: 0.1693  bbox_loss: 0.0054  cls_loss: 0.0132  \n",
      "<<<iteration:[100/657] - total_loss: 0.2853  obj_loss: 0.1701  noobj_loss: 0.1643  bbox_loss: 0.0052  cls_loss: 0.0072  \n",
      "<<<iteration:[120/657] - total_loss: 0.2852  obj_loss: 0.1647  noobj_loss: 0.1679  bbox_loss: 0.0053  cls_loss: 0.0101  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<<<iteration:[140/657] - total_loss: 0.2909  obj_loss: 0.1710  noobj_loss: 0.1764  bbox_loss: 0.0044  cls_loss: 0.0095  \n",
      "<<<iteration:[160/657] - total_loss: 0.2773  obj_loss: 0.1564  noobj_loss: 0.1684  bbox_loss: 0.0056  cls_loss: 0.0087  \n",
      "<<<iteration:[180/657] - total_loss: 0.2948  obj_loss: 0.1741  noobj_loss: 0.1703  bbox_loss: 0.0053  cls_loss: 0.0088  \n",
      "<<<iteration:[200/657] - total_loss: 0.2865  obj_loss: 0.1610  noobj_loss: 0.1745  bbox_loss: 0.0057  cls_loss: 0.0095  \n",
      "<<<iteration:[220/657] - total_loss: 0.2777  obj_loss: 0.1558  noobj_loss: 0.1750  bbox_loss: 0.0055  cls_loss: 0.0070  \n",
      "<<<iteration:[240/657] - total_loss: 0.2951  obj_loss: 0.1789  noobj_loss: 0.1696  bbox_loss: 0.0049  cls_loss: 0.0067  \n",
      "<<<iteration:[260/657] - total_loss: 0.2833  obj_loss: 0.1604  noobj_loss: 0.1776  bbox_loss: 0.0051  cls_loss: 0.0087  \n",
      "<<<iteration:[280/657] - total_loss: 0.3042  obj_loss: 0.1793  noobj_loss: 0.1815  bbox_loss: 0.0053  cls_loss: 0.0079  \n",
      "<<<iteration:[300/657] - total_loss: 0.2849  obj_loss: 0.1617  noobj_loss: 0.1783  bbox_loss: 0.0053  cls_loss: 0.0073  \n",
      "<<<iteration:[320/657] - total_loss: 0.3010  obj_loss: 0.1782  noobj_loss: 0.1798  bbox_loss: 0.0047  cls_loss: 0.0093  \n",
      "<<<iteration:[340/657] - total_loss: 0.2883  obj_loss: 0.1664  noobj_loss: 0.1716  bbox_loss: 0.0055  cls_loss: 0.0086  \n",
      "<<<iteration:[360/657] - total_loss: 0.3069  obj_loss: 0.1803  noobj_loss: 0.1805  bbox_loss: 0.0054  cls_loss: 0.0092  \n",
      "<<<iteration:[380/657] - total_loss: 0.2875  obj_loss: 0.1685  noobj_loss: 0.1752  bbox_loss: 0.0047  cls_loss: 0.0080  \n",
      "<<<iteration:[400/657] - total_loss: 0.2766  obj_loss: 0.1556  noobj_loss: 0.1722  bbox_loss: 0.0052  cls_loss: 0.0089  \n",
      "<<<iteration:[420/657] - total_loss: 0.3154  obj_loss: 0.1905  noobj_loss: 0.1741  bbox_loss: 0.0055  cls_loss: 0.0103  \n",
      "<<<iteration:[440/657] - total_loss: 0.3047  obj_loss: 0.1822  noobj_loss: 0.1791  bbox_loss: 0.0051  cls_loss: 0.0073  \n",
      "<<<iteration:[460/657] - total_loss: 0.2837  obj_loss: 0.1637  noobj_loss: 0.1756  bbox_loss: 0.0046  cls_loss: 0.0094  \n",
      "<<<iteration:[480/657] - total_loss: 0.3055  obj_loss: 0.1814  noobj_loss: 0.1764  bbox_loss: 0.0054  cls_loss: 0.0089  \n",
      "<<<iteration:[500/657] - total_loss: 0.2780  obj_loss: 0.1541  noobj_loss: 0.1764  bbox_loss: 0.0054  cls_loss: 0.0085  \n",
      "<<<iteration:[520/657] - total_loss: 0.2962  obj_loss: 0.1661  noobj_loss: 0.1780  bbox_loss: 0.0059  cls_loss: 0.0117  \n",
      "<<<iteration:[540/657] - total_loss: 0.2661  obj_loss: 0.1467  noobj_loss: 0.1721  bbox_loss: 0.0052  cls_loss: 0.0074  \n",
      "<<<iteration:[560/657] - total_loss: 0.2884  obj_loss: 0.1713  noobj_loss: 0.1726  bbox_loss: 0.0049  cls_loss: 0.0065  \n",
      "<<<iteration:[580/657] - total_loss: 0.2796  obj_loss: 0.1607  noobj_loss: 0.1736  bbox_loss: 0.0050  cls_loss: 0.0070  \n",
      "<<<iteration:[600/657] - total_loss: 0.2935  obj_loss: 0.1651  noobj_loss: 0.1825  bbox_loss: 0.0053  cls_loss: 0.0106  \n",
      "<<<iteration:[620/657] - total_loss: 0.2955  obj_loss: 0.1693  noobj_loss: 0.1840  bbox_loss: 0.0053  cls_loss: 0.0079  \n",
      "<<<iteration:[640/657] - total_loss: 0.2830  obj_loss: 0.1609  noobj_loss: 0.1821  bbox_loss: 0.0044  cls_loss: 0.0088  \n",
      "\n",
      "epoch:72/100 - Train Loss: 0.2904, Val Loss: 0.2971\n",
      "\n",
      "<<<iteration:[20/657] - total_loss: 0.2950  obj_loss: 0.1650  noobj_loss: 0.1755  bbox_loss: 0.0062  cls_loss: 0.0114  \n",
      "<<<iteration:[40/657] - total_loss: 0.2889  obj_loss: 0.1667  noobj_loss: 0.1761  bbox_loss: 0.0055  cls_loss: 0.0068  \n",
      "<<<iteration:[60/657] - total_loss: 0.2951  obj_loss: 0.1698  noobj_loss: 0.1793  bbox_loss: 0.0053  cls_loss: 0.0090  \n",
      "<<<iteration:[80/657] - total_loss: 0.2984  obj_loss: 0.1706  noobj_loss: 0.1797  bbox_loss: 0.0057  cls_loss: 0.0092  \n",
      "<<<iteration:[100/657] - total_loss: 0.2830  obj_loss: 0.1648  noobj_loss: 0.1684  bbox_loss: 0.0050  cls_loss: 0.0088  \n",
      "<<<iteration:[120/657] - total_loss: 0.3067  obj_loss: 0.1886  noobj_loss: 0.1696  bbox_loss: 0.0051  cls_loss: 0.0076  \n",
      "<<<iteration:[140/657] - total_loss: 0.2922  obj_loss: 0.1686  noobj_loss: 0.1789  bbox_loss: 0.0050  cls_loss: 0.0091  \n",
      "<<<iteration:[160/657] - total_loss: 0.2871  obj_loss: 0.1602  noobj_loss: 0.1819  bbox_loss: 0.0056  cls_loss: 0.0082  \n",
      "<<<iteration:[180/657] - total_loss: 0.2918  obj_loss: 0.1689  noobj_loss: 0.1802  bbox_loss: 0.0051  cls_loss: 0.0073  \n",
      "<<<iteration:[200/657] - total_loss: 0.2917  obj_loss: 0.1611  noobj_loss: 0.1824  bbox_loss: 0.0060  cls_loss: 0.0094  \n",
      "<<<iteration:[220/657] - total_loss: 0.2885  obj_loss: 0.1669  noobj_loss: 0.1792  bbox_loss: 0.0047  cls_loss: 0.0086  \n",
      "<<<iteration:[240/657] - total_loss: 0.2919  obj_loss: 0.1696  noobj_loss: 0.1755  bbox_loss: 0.0053  cls_loss: 0.0081  \n",
      "<<<iteration:[260/657] - total_loss: 0.2929  obj_loss: 0.1685  noobj_loss: 0.1755  bbox_loss: 0.0052  cls_loss: 0.0105  \n",
      "<<<iteration:[280/657] - total_loss: 0.2939  obj_loss: 0.1676  noobj_loss: 0.1790  bbox_loss: 0.0057  cls_loss: 0.0080  \n",
      "<<<iteration:[300/657] - total_loss: 0.2814  obj_loss: 0.1575  noobj_loss: 0.1767  bbox_loss: 0.0057  cls_loss: 0.0072  \n",
      "<<<iteration:[320/657] - total_loss: 0.2914  obj_loss: 0.1698  noobj_loss: 0.1726  bbox_loss: 0.0056  cls_loss: 0.0075  \n",
      "<<<iteration:[340/657] - total_loss: 0.3072  obj_loss: 0.1827  noobj_loss: 0.1807  bbox_loss: 0.0048  cls_loss: 0.0100  \n",
      "<<<iteration:[360/657] - total_loss: 0.2876  obj_loss: 0.1544  noobj_loss: 0.1844  bbox_loss: 0.0054  cls_loss: 0.0140  \n",
      "<<<iteration:[380/657] - total_loss: 0.2956  obj_loss: 0.1739  noobj_loss: 0.1739  bbox_loss: 0.0055  cls_loss: 0.0074  \n",
      "<<<iteration:[400/657] - total_loss: 0.2889  obj_loss: 0.1653  noobj_loss: 0.1739  bbox_loss: 0.0054  cls_loss: 0.0098  \n",
      "<<<iteration:[420/657] - total_loss: 0.2942  obj_loss: 0.1721  noobj_loss: 0.1753  bbox_loss: 0.0055  cls_loss: 0.0070  \n",
      "<<<iteration:[440/657] - total_loss: 0.2812  obj_loss: 0.1618  noobj_loss: 0.1749  bbox_loss: 0.0049  cls_loss: 0.0076  \n",
      "<<<iteration:[460/657] - total_loss: 0.2909  obj_loss: 0.1668  noobj_loss: 0.1795  bbox_loss: 0.0052  cls_loss: 0.0084  \n",
      "<<<iteration:[480/657] - total_loss: 0.2959  obj_loss: 0.1744  noobj_loss: 0.1777  bbox_loss: 0.0049  cls_loss: 0.0083  \n",
      "<<<iteration:[500/657] - total_loss: 0.2799  obj_loss: 0.1597  noobj_loss: 0.1685  bbox_loss: 0.0052  cls_loss: 0.0100  \n",
      "<<<iteration:[520/657] - total_loss: 0.3002  obj_loss: 0.1790  noobj_loss: 0.1806  bbox_loss: 0.0047  cls_loss: 0.0072  \n",
      "<<<iteration:[540/657] - total_loss: 0.2963  obj_loss: 0.1737  noobj_loss: 0.1766  bbox_loss: 0.0053  cls_loss: 0.0078  \n",
      "<<<iteration:[560/657] - total_loss: 0.2934  obj_loss: 0.1700  noobj_loss: 0.1823  bbox_loss: 0.0049  cls_loss: 0.0077  \n",
      "<<<iteration:[580/657] - total_loss: 0.2825  obj_loss: 0.1612  noobj_loss: 0.1741  bbox_loss: 0.0053  cls_loss: 0.0079  \n",
      "<<<iteration:[600/657] - total_loss: 0.2850  obj_loss: 0.1604  noobj_loss: 0.1763  bbox_loss: 0.0056  cls_loss: 0.0085  \n",
      "<<<iteration:[620/657] - total_loss: 0.2795  obj_loss: 0.1591  noobj_loss: 0.1744  bbox_loss: 0.0049  cls_loss: 0.0086  \n",
      "<<<iteration:[640/657] - total_loss: 0.2965  obj_loss: 0.1684  noobj_loss: 0.1789  bbox_loss: 0.0055  cls_loss: 0.0114  \n",
      "\n",
      "epoch:73/100 - Train Loss: 0.2908, Val Loss: 0.3042\n",
      "\n",
      "<<<iteration:[20/657] - total_loss: 0.3081  obj_loss: 0.1816  noobj_loss: 0.1788  bbox_loss: 0.0055  cls_loss: 0.0098  \n",
      "<<<iteration:[40/657] - total_loss: 0.2895  obj_loss: 0.1683  noobj_loss: 0.1781  bbox_loss: 0.0050  cls_loss: 0.0070  \n",
      "<<<iteration:[60/657] - total_loss: 0.3026  obj_loss: 0.1765  noobj_loss: 0.1787  bbox_loss: 0.0054  cls_loss: 0.0097  \n",
      "<<<iteration:[80/657] - total_loss: 0.2931  obj_loss: 0.1728  noobj_loss: 0.1706  bbox_loss: 0.0053  cls_loss: 0.0085  \n",
      "<<<iteration:[100/657] - total_loss: 0.2942  obj_loss: 0.1733  noobj_loss: 0.1713  bbox_loss: 0.0050  cls_loss: 0.0101  \n",
      "<<<iteration:[120/657] - total_loss: 0.2974  obj_loss: 0.1660  noobj_loss: 0.1904  bbox_loss: 0.0057  cls_loss: 0.0077  \n",
      "<<<iteration:[140/657] - total_loss: 0.2908  obj_loss: 0.1684  noobj_loss: 0.1783  bbox_loss: 0.0052  cls_loss: 0.0071  \n",
      "<<<iteration:[160/657] - total_loss: 0.2966  obj_loss: 0.1668  noobj_loss: 0.1714  bbox_loss: 0.0066  cls_loss: 0.0109  \n",
      "<<<iteration:[180/657] - total_loss: 0.2868  obj_loss: 0.1604  noobj_loss: 0.1806  bbox_loss: 0.0054  cls_loss: 0.0091  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<<<iteration:[200/657] - total_loss: 0.2912  obj_loss: 0.1683  noobj_loss: 0.1753  bbox_loss: 0.0054  cls_loss: 0.0080  \n",
      "<<<iteration:[220/657] - total_loss: 0.2780  obj_loss: 0.1538  noobj_loss: 0.1746  bbox_loss: 0.0058  cls_loss: 0.0078  \n",
      "<<<iteration:[240/657] - total_loss: 0.2869  obj_loss: 0.1661  noobj_loss: 0.1740  bbox_loss: 0.0051  cls_loss: 0.0083  \n",
      "<<<iteration:[260/657] - total_loss: 0.3062  obj_loss: 0.1745  noobj_loss: 0.1747  bbox_loss: 0.0060  cls_loss: 0.0141  \n",
      "<<<iteration:[280/657] - total_loss: 0.2854  obj_loss: 0.1620  noobj_loss: 0.1744  bbox_loss: 0.0052  cls_loss: 0.0103  \n",
      "<<<iteration:[300/657] - total_loss: 0.2949  obj_loss: 0.1724  noobj_loss: 0.1832  bbox_loss: 0.0047  cls_loss: 0.0075  \n",
      "<<<iteration:[320/657] - total_loss: 0.3024  obj_loss: 0.1806  noobj_loss: 0.1790  bbox_loss: 0.0046  cls_loss: 0.0092  \n",
      "<<<iteration:[340/657] - total_loss: 0.2949  obj_loss: 0.1692  noobj_loss: 0.1836  bbox_loss: 0.0048  cls_loss: 0.0098  \n",
      "<<<iteration:[360/657] - total_loss: 0.2893  obj_loss: 0.1615  noobj_loss: 0.1809  bbox_loss: 0.0059  cls_loss: 0.0081  \n",
      "<<<iteration:[380/657] - total_loss: 0.2845  obj_loss: 0.1672  noobj_loss: 0.1791  bbox_loss: 0.0043  cls_loss: 0.0062  \n",
      "<<<iteration:[400/657] - total_loss: 0.2890  obj_loss: 0.1657  noobj_loss: 0.1790  bbox_loss: 0.0051  cls_loss: 0.0085  \n",
      "<<<iteration:[420/657] - total_loss: 0.2893  obj_loss: 0.1632  noobj_loss: 0.1828  bbox_loss: 0.0052  cls_loss: 0.0084  \n",
      "<<<iteration:[440/657] - total_loss: 0.2833  obj_loss: 0.1604  noobj_loss: 0.1806  bbox_loss: 0.0050  cls_loss: 0.0077  \n",
      "<<<iteration:[460/657] - total_loss: 0.2925  obj_loss: 0.1708  noobj_loss: 0.1831  bbox_loss: 0.0046  cls_loss: 0.0071  \n",
      "<<<iteration:[480/657] - total_loss: 0.3008  obj_loss: 0.1717  noobj_loss: 0.1796  bbox_loss: 0.0060  cls_loss: 0.0095  \n",
      "<<<iteration:[500/657] - total_loss: 0.2937  obj_loss: 0.1733  noobj_loss: 0.1792  bbox_loss: 0.0048  cls_loss: 0.0066  \n",
      "<<<iteration:[520/657] - total_loss: 0.2846  obj_loss: 0.1627  noobj_loss: 0.1702  bbox_loss: 0.0053  cls_loss: 0.0103  \n",
      "<<<iteration:[540/657] - total_loss: 0.3010  obj_loss: 0.1802  noobj_loss: 0.1749  bbox_loss: 0.0052  cls_loss: 0.0072  \n",
      "<<<iteration:[560/657] - total_loss: 0.2921  obj_loss: 0.1713  noobj_loss: 0.1801  bbox_loss: 0.0047  cls_loss: 0.0073  \n",
      "<<<iteration:[580/657] - total_loss: 0.2752  obj_loss: 0.1497  noobj_loss: 0.1723  bbox_loss: 0.0055  cls_loss: 0.0118  \n",
      "<<<iteration:[600/657] - total_loss: 0.2981  obj_loss: 0.1757  noobj_loss: 0.1761  bbox_loss: 0.0053  cls_loss: 0.0080  \n",
      "<<<iteration:[620/657] - total_loss: 0.2882  obj_loss: 0.1682  noobj_loss: 0.1755  bbox_loss: 0.0050  cls_loss: 0.0075  \n",
      "<<<iteration:[640/657] - total_loss: 0.2981  obj_loss: 0.1732  noobj_loss: 0.1909  bbox_loss: 0.0045  cls_loss: 0.0069  \n",
      "\n",
      "epoch:74/100 - Train Loss: 0.2917, Val Loss: 0.3096\n",
      "\n",
      "<<<iteration:[20/657] - total_loss: 0.3220  obj_loss: 0.1865  noobj_loss: 0.1932  bbox_loss: 0.0058  cls_loss: 0.0098  \n",
      "<<<iteration:[40/657] - total_loss: 0.2950  obj_loss: 0.1704  noobj_loss: 0.1781  bbox_loss: 0.0051  cls_loss: 0.0098  \n",
      "<<<iteration:[60/657] - total_loss: 0.2836  obj_loss: 0.1627  noobj_loss: 0.1775  bbox_loss: 0.0049  cls_loss: 0.0077  \n",
      "<<<iteration:[80/657] - total_loss: 0.2942  obj_loss: 0.1752  noobj_loss: 0.1792  bbox_loss: 0.0044  cls_loss: 0.0071  \n",
      "<<<iteration:[100/657] - total_loss: 0.2849  obj_loss: 0.1620  noobj_loss: 0.1829  bbox_loss: 0.0050  cls_loss: 0.0066  \n",
      "<<<iteration:[120/657] - total_loss: 0.2712  obj_loss: 0.1515  noobj_loss: 0.1751  bbox_loss: 0.0052  cls_loss: 0.0063  \n",
      "<<<iteration:[140/657] - total_loss: 0.2836  obj_loss: 0.1621  noobj_loss: 0.1805  bbox_loss: 0.0050  cls_loss: 0.0064  \n",
      "<<<iteration:[160/657] - total_loss: 0.2903  obj_loss: 0.1656  noobj_loss: 0.1829  bbox_loss: 0.0050  cls_loss: 0.0083  \n",
      "<<<iteration:[180/657] - total_loss: 0.2938  obj_loss: 0.1706  noobj_loss: 0.1807  bbox_loss: 0.0049  cls_loss: 0.0085  \n",
      "<<<iteration:[200/657] - total_loss: 0.2862  obj_loss: 0.1617  noobj_loss: 0.1850  bbox_loss: 0.0051  cls_loss: 0.0066  \n",
      "<<<iteration:[220/657] - total_loss: 0.2952  obj_loss: 0.1755  noobj_loss: 0.1795  bbox_loss: 0.0045  cls_loss: 0.0073  \n",
      "<<<iteration:[240/657] - total_loss: 0.2977  obj_loss: 0.1695  noobj_loss: 0.1849  bbox_loss: 0.0053  cls_loss: 0.0093  \n",
      "<<<iteration:[260/657] - total_loss: 0.2947  obj_loss: 0.1706  noobj_loss: 0.1785  bbox_loss: 0.0051  cls_loss: 0.0095  \n",
      "<<<iteration:[280/657] - total_loss: 0.2886  obj_loss: 0.1607  noobj_loss: 0.1817  bbox_loss: 0.0053  cls_loss: 0.0106  \n",
      "<<<iteration:[300/657] - total_loss: 0.2879  obj_loss: 0.1668  noobj_loss: 0.1741  bbox_loss: 0.0053  cls_loss: 0.0076  \n",
      "<<<iteration:[320/657] - total_loss: 0.3073  obj_loss: 0.1811  noobj_loss: 0.1813  bbox_loss: 0.0053  cls_loss: 0.0090  \n",
      "<<<iteration:[340/657] - total_loss: 0.2941  obj_loss: 0.1615  noobj_loss: 0.1880  bbox_loss: 0.0052  cls_loss: 0.0127  \n",
      "<<<iteration:[360/657] - total_loss: 0.2869  obj_loss: 0.1594  noobj_loss: 0.1795  bbox_loss: 0.0054  cls_loss: 0.0109  \n",
      "<<<iteration:[380/657] - total_loss: 0.2837  obj_loss: 0.1626  noobj_loss: 0.1847  bbox_loss: 0.0045  cls_loss: 0.0064  \n",
      "<<<iteration:[400/657] - total_loss: 0.3122  obj_loss: 0.1874  noobj_loss: 0.1835  bbox_loss: 0.0050  cls_loss: 0.0080  \n",
      "<<<iteration:[420/657] - total_loss: 0.2955  obj_loss: 0.1700  noobj_loss: 0.1803  bbox_loss: 0.0050  cls_loss: 0.0105  \n",
      "<<<iteration:[440/657] - total_loss: 0.2890  obj_loss: 0.1620  noobj_loss: 0.1806  bbox_loss: 0.0057  cls_loss: 0.0084  \n",
      "<<<iteration:[460/657] - total_loss: 0.2912  obj_loss: 0.1656  noobj_loss: 0.1751  bbox_loss: 0.0056  cls_loss: 0.0098  \n",
      "<<<iteration:[480/657] - total_loss: 0.2941  obj_loss: 0.1702  noobj_loss: 0.1749  bbox_loss: 0.0056  cls_loss: 0.0084  \n",
      "<<<iteration:[500/657] - total_loss: 0.2899  obj_loss: 0.1644  noobj_loss: 0.1784  bbox_loss: 0.0053  cls_loss: 0.0100  \n",
      "<<<iteration:[520/657] - total_loss: 0.2926  obj_loss: 0.1641  noobj_loss: 0.1778  bbox_loss: 0.0056  cls_loss: 0.0118  \n",
      "<<<iteration:[540/657] - total_loss: 0.2946  obj_loss: 0.1741  noobj_loss: 0.1765  bbox_loss: 0.0049  cls_loss: 0.0077  \n",
      "<<<iteration:[560/657] - total_loss: 0.2889  obj_loss: 0.1672  noobj_loss: 0.1783  bbox_loss: 0.0050  cls_loss: 0.0075  \n",
      "<<<iteration:[580/657] - total_loss: 0.2810  obj_loss: 0.1576  noobj_loss: 0.1672  bbox_loss: 0.0057  cls_loss: 0.0115  \n",
      "<<<iteration:[600/657] - total_loss: 0.2879  obj_loss: 0.1621  noobj_loss: 0.1875  bbox_loss: 0.0049  cls_loss: 0.0073  \n",
      "<<<iteration:[620/657] - total_loss: 0.2935  obj_loss: 0.1720  noobj_loss: 0.1740  bbox_loss: 0.0052  cls_loss: 0.0082  \n",
      "<<<iteration:[640/657] - total_loss: 0.2887  obj_loss: 0.1644  noobj_loss: 0.1711  bbox_loss: 0.0054  cls_loss: 0.0116  \n",
      "\n",
      "epoch:75/100 - Train Loss: 0.2915, Val Loss: 0.3089\n",
      "\n",
      "<<<iteration:[20/657] - total_loss: 0.3129  obj_loss: 0.1833  noobj_loss: 0.1894  bbox_loss: 0.0054  cls_loss: 0.0079  \n",
      "<<<iteration:[40/657] - total_loss: 0.2978  obj_loss: 0.1730  noobj_loss: 0.1821  bbox_loss: 0.0047  cls_loss: 0.0102  \n",
      "<<<iteration:[60/657] - total_loss: 0.2779  obj_loss: 0.1616  noobj_loss: 0.1724  bbox_loss: 0.0045  cls_loss: 0.0077  \n",
      "<<<iteration:[80/657] - total_loss: 0.2849  obj_loss: 0.1650  noobj_loss: 0.1729  bbox_loss: 0.0052  cls_loss: 0.0072  \n",
      "<<<iteration:[100/657] - total_loss: 0.2751  obj_loss: 0.1557  noobj_loss: 0.1794  bbox_loss: 0.0046  cls_loss: 0.0065  \n",
      "<<<iteration:[120/657] - total_loss: 0.2862  obj_loss: 0.1640  noobj_loss: 0.1782  bbox_loss: 0.0050  cls_loss: 0.0080  \n",
      "<<<iteration:[140/657] - total_loss: 0.2823  obj_loss: 0.1643  noobj_loss: 0.1735  bbox_loss: 0.0045  cls_loss: 0.0087  \n",
      "<<<iteration:[160/657] - total_loss: 0.2979  obj_loss: 0.1780  noobj_loss: 0.1756  bbox_loss: 0.0047  cls_loss: 0.0084  \n",
      "<<<iteration:[180/657] - total_loss: 0.2910  obj_loss: 0.1662  noobj_loss: 0.1853  bbox_loss: 0.0052  cls_loss: 0.0059  \n",
      "<<<iteration:[200/657] - total_loss: 0.2977  obj_loss: 0.1733  noobj_loss: 0.1875  bbox_loss: 0.0045  cls_loss: 0.0082  \n",
      "<<<iteration:[220/657] - total_loss: 0.2945  obj_loss: 0.1751  noobj_loss: 0.1693  bbox_loss: 0.0055  cls_loss: 0.0070  \n",
      "<<<iteration:[240/657] - total_loss: 0.2971  obj_loss: 0.1735  noobj_loss: 0.1900  bbox_loss: 0.0045  cls_loss: 0.0058  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<<<iteration:[260/657] - total_loss: 0.3013  obj_loss: 0.1798  noobj_loss: 0.1787  bbox_loss: 0.0047  cls_loss: 0.0084  \n",
      "<<<iteration:[280/657] - total_loss: 0.2937  obj_loss: 0.1720  noobj_loss: 0.1761  bbox_loss: 0.0050  cls_loss: 0.0085  \n",
      "<<<iteration:[300/657] - total_loss: 0.2955  obj_loss: 0.1715  noobj_loss: 0.1828  bbox_loss: 0.0050  cls_loss: 0.0076  \n",
      "<<<iteration:[320/657] - total_loss: 0.3064  obj_loss: 0.1759  noobj_loss: 0.1834  bbox_loss: 0.0054  cls_loss: 0.0116  \n",
      "<<<iteration:[340/657] - total_loss: 0.2858  obj_loss: 0.1659  noobj_loss: 0.1790  bbox_loss: 0.0046  cls_loss: 0.0074  \n",
      "<<<iteration:[360/657] - total_loss: 0.3109  obj_loss: 0.1823  noobj_loss: 0.1833  bbox_loss: 0.0054  cls_loss: 0.0099  \n",
      "<<<iteration:[380/657] - total_loss: 0.2913  obj_loss: 0.1688  noobj_loss: 0.1812  bbox_loss: 0.0046  cls_loss: 0.0087  \n",
      "<<<iteration:[400/657] - total_loss: 0.2821  obj_loss: 0.1628  noobj_loss: 0.1776  bbox_loss: 0.0046  cls_loss: 0.0074  \n",
      "<<<iteration:[420/657] - total_loss: 0.2785  obj_loss: 0.1543  noobj_loss: 0.1806  bbox_loss: 0.0054  cls_loss: 0.0070  \n",
      "<<<iteration:[440/657] - total_loss: 0.2834  obj_loss: 0.1606  noobj_loss: 0.1781  bbox_loss: 0.0050  cls_loss: 0.0086  \n",
      "<<<iteration:[460/657] - total_loss: 0.2940  obj_loss: 0.1617  noobj_loss: 0.1881  bbox_loss: 0.0055  cls_loss: 0.0106  \n",
      "<<<iteration:[480/657] - total_loss: 0.2896  obj_loss: 0.1694  noobj_loss: 0.1747  bbox_loss: 0.0051  cls_loss: 0.0072  \n",
      "<<<iteration:[500/657] - total_loss: 0.2835  obj_loss: 0.1623  noobj_loss: 0.1716  bbox_loss: 0.0055  cls_loss: 0.0081  \n",
      "<<<iteration:[520/657] - total_loss: 0.2829  obj_loss: 0.1590  noobj_loss: 0.1793  bbox_loss: 0.0048  cls_loss: 0.0103  \n",
      "<<<iteration:[540/657] - total_loss: 0.2798  obj_loss: 0.1603  noobj_loss: 0.1714  bbox_loss: 0.0053  cls_loss: 0.0071  \n",
      "<<<iteration:[560/657] - total_loss: 0.2982  obj_loss: 0.1693  noobj_loss: 0.1873  bbox_loss: 0.0051  cls_loss: 0.0096  \n",
      "<<<iteration:[580/657] - total_loss: 0.2761  obj_loss: 0.1630  noobj_loss: 0.1709  bbox_loss: 0.0043  cls_loss: 0.0063  \n",
      "<<<iteration:[600/657] - total_loss: 0.2943  obj_loss: 0.1694  noobj_loss: 0.1859  bbox_loss: 0.0048  cls_loss: 0.0078  \n",
      "<<<iteration:[620/657] - total_loss: 0.2916  obj_loss: 0.1664  noobj_loss: 0.1712  bbox_loss: 0.0058  cls_loss: 0.0106  \n",
      "<<<iteration:[640/657] - total_loss: 0.2850  obj_loss: 0.1625  noobj_loss: 0.1751  bbox_loss: 0.0047  cls_loss: 0.0116  \n",
      "\n",
      "epoch:76/100 - Train Loss: 0.2899, Val Loss: 0.3066\n",
      "\n",
      "<<<iteration:[20/657] - total_loss: 0.3116  obj_loss: 0.1813  noobj_loss: 0.1911  bbox_loss: 0.0054  cls_loss: 0.0079  \n",
      "<<<iteration:[40/657] - total_loss: 0.2931  obj_loss: 0.1679  noobj_loss: 0.1762  bbox_loss: 0.0053  cls_loss: 0.0108  \n",
      "<<<iteration:[60/657] - total_loss: 0.3112  obj_loss: 0.1840  noobj_loss: 0.1890  bbox_loss: 0.0048  cls_loss: 0.0087  \n",
      "<<<iteration:[80/657] - total_loss: 0.2975  obj_loss: 0.1735  noobj_loss: 0.1754  bbox_loss: 0.0051  cls_loss: 0.0109  \n",
      "<<<iteration:[100/657] - total_loss: 0.2920  obj_loss: 0.1673  noobj_loss: 0.1825  bbox_loss: 0.0047  cls_loss: 0.0099  \n",
      "<<<iteration:[120/657] - total_loss: 0.2945  obj_loss: 0.1694  noobj_loss: 0.1814  bbox_loss: 0.0052  cls_loss: 0.0086  \n",
      "<<<iteration:[140/657] - total_loss: 0.3055  obj_loss: 0.1796  noobj_loss: 0.1855  bbox_loss: 0.0048  cls_loss: 0.0091  \n",
      "<<<iteration:[160/657] - total_loss: 0.2812  obj_loss: 0.1560  noobj_loss: 0.1819  bbox_loss: 0.0049  cls_loss: 0.0099  \n",
      "<<<iteration:[180/657] - total_loss: 0.2925  obj_loss: 0.1677  noobj_loss: 0.1736  bbox_loss: 0.0056  cls_loss: 0.0103  \n",
      "<<<iteration:[200/657] - total_loss: 0.2937  obj_loss: 0.1663  noobj_loss: 0.1763  bbox_loss: 0.0056  cls_loss: 0.0114  \n",
      "<<<iteration:[220/657] - total_loss: 0.2867  obj_loss: 0.1632  noobj_loss: 0.1718  bbox_loss: 0.0053  cls_loss: 0.0111  \n",
      "<<<iteration:[240/657] - total_loss: 0.2860  obj_loss: 0.1621  noobj_loss: 0.1861  bbox_loss: 0.0047  cls_loss: 0.0074  \n",
      "<<<iteration:[260/657] - total_loss: 0.2899  obj_loss: 0.1686  noobj_loss: 0.1789  bbox_loss: 0.0046  cls_loss: 0.0090  \n",
      "<<<iteration:[280/657] - total_loss: 0.2896  obj_loss: 0.1634  noobj_loss: 0.1776  bbox_loss: 0.0056  cls_loss: 0.0093  \n",
      "<<<iteration:[300/657] - total_loss: 0.2988  obj_loss: 0.1695  noobj_loss: 0.1878  bbox_loss: 0.0049  cls_loss: 0.0108  \n",
      "<<<iteration:[320/657] - total_loss: 0.2946  obj_loss: 0.1689  noobj_loss: 0.1797  bbox_loss: 0.0054  cls_loss: 0.0090  \n",
      "<<<iteration:[340/657] - total_loss: 0.3032  obj_loss: 0.1698  noobj_loss: 0.1894  bbox_loss: 0.0052  cls_loss: 0.0129  \n",
      "<<<iteration:[360/657] - total_loss: 0.2904  obj_loss: 0.1660  noobj_loss: 0.1856  bbox_loss: 0.0050  cls_loss: 0.0066  \n",
      "<<<iteration:[380/657] - total_loss: 0.2903  obj_loss: 0.1622  noobj_loss: 0.1790  bbox_loss: 0.0051  cls_loss: 0.0130  \n",
      "<<<iteration:[400/657] - total_loss: 0.2865  obj_loss: 0.1668  noobj_loss: 0.1815  bbox_loss: 0.0045  cls_loss: 0.0062  \n",
      "<<<iteration:[420/657] - total_loss: 0.3093  obj_loss: 0.1747  noobj_loss: 0.1828  bbox_loss: 0.0057  cls_loss: 0.0145  \n",
      "<<<iteration:[440/657] - total_loss: 0.3011  obj_loss: 0.1798  noobj_loss: 0.1776  bbox_loss: 0.0048  cls_loss: 0.0084  \n",
      "<<<iteration:[460/657] - total_loss: 0.2870  obj_loss: 0.1604  noobj_loss: 0.1815  bbox_loss: 0.0053  cls_loss: 0.0093  \n",
      "<<<iteration:[480/657] - total_loss: 0.2776  obj_loss: 0.1538  noobj_loss: 0.1795  bbox_loss: 0.0051  cls_loss: 0.0085  \n",
      "<<<iteration:[500/657] - total_loss: 0.2865  obj_loss: 0.1619  noobj_loss: 0.1812  bbox_loss: 0.0056  cls_loss: 0.0060  \n",
      "<<<iteration:[520/657] - total_loss: 0.2825  obj_loss: 0.1644  noobj_loss: 0.1806  bbox_loss: 0.0045  cls_loss: 0.0052  \n",
      "<<<iteration:[540/657] - total_loss: 0.2918  obj_loss: 0.1710  noobj_loss: 0.1821  bbox_loss: 0.0046  cls_loss: 0.0066  \n",
      "<<<iteration:[560/657] - total_loss: 0.2992  obj_loss: 0.1766  noobj_loss: 0.1818  bbox_loss: 0.0050  cls_loss: 0.0067  \n",
      "<<<iteration:[580/657] - total_loss: 0.2719  obj_loss: 0.1484  noobj_loss: 0.1819  bbox_loss: 0.0050  cls_loss: 0.0075  \n",
      "<<<iteration:[600/657] - total_loss: 0.2903  obj_loss: 0.1679  noobj_loss: 0.1812  bbox_loss: 0.0050  cls_loss: 0.0068  \n",
      "<<<iteration:[620/657] - total_loss: 0.2856  obj_loss: 0.1643  noobj_loss: 0.1728  bbox_loss: 0.0053  cls_loss: 0.0083  \n",
      "<<<iteration:[640/657] - total_loss: 0.2948  obj_loss: 0.1664  noobj_loss: 0.1722  bbox_loss: 0.0059  cls_loss: 0.0129  \n",
      "\n",
      "epoch:77/100 - Train Loss: 0.2919, Val Loss: 0.3093\n",
      "\n",
      "<<<iteration:[20/657] - total_loss: 0.3052  obj_loss: 0.1769  noobj_loss: 0.1851  bbox_loss: 0.0054  cls_loss: 0.0088  \n",
      "<<<iteration:[40/657] - total_loss: 0.2884  obj_loss: 0.1635  noobj_loss: 0.1789  bbox_loss: 0.0054  cls_loss: 0.0083  \n",
      "<<<iteration:[60/657] - total_loss: 0.2945  obj_loss: 0.1734  noobj_loss: 0.1734  bbox_loss: 0.0052  cls_loss: 0.0084  \n",
      "<<<iteration:[80/657] - total_loss: 0.2956  obj_loss: 0.1675  noobj_loss: 0.1848  bbox_loss: 0.0049  cls_loss: 0.0112  \n",
      "<<<iteration:[100/657] - total_loss: 0.2795  obj_loss: 0.1570  noobj_loss: 0.1815  bbox_loss: 0.0049  cls_loss: 0.0074  \n",
      "<<<iteration:[120/657] - total_loss: 0.3001  obj_loss: 0.1782  noobj_loss: 0.1836  bbox_loss: 0.0046  cls_loss: 0.0073  \n",
      "<<<iteration:[140/657] - total_loss: 0.2859  obj_loss: 0.1687  noobj_loss: 0.1778  bbox_loss: 0.0042  cls_loss: 0.0071  \n",
      "<<<iteration:[160/657] - total_loss: 0.2798  obj_loss: 0.1588  noobj_loss: 0.1784  bbox_loss: 0.0050  cls_loss: 0.0071  \n",
      "<<<iteration:[180/657] - total_loss: 0.2930  obj_loss: 0.1644  noobj_loss: 0.1836  bbox_loss: 0.0053  cls_loss: 0.0105  \n",
      "<<<iteration:[200/657] - total_loss: 0.2787  obj_loss: 0.1593  noobj_loss: 0.1791  bbox_loss: 0.0048  cls_loss: 0.0061  \n",
      "<<<iteration:[220/657] - total_loss: 0.2860  obj_loss: 0.1654  noobj_loss: 0.1758  bbox_loss: 0.0049  cls_loss: 0.0081  \n",
      "<<<iteration:[240/657] - total_loss: 0.2896  obj_loss: 0.1644  noobj_loss: 0.1800  bbox_loss: 0.0052  cls_loss: 0.0091  \n",
      "<<<iteration:[260/657] - total_loss: 0.2910  obj_loss: 0.1688  noobj_loss: 0.1769  bbox_loss: 0.0052  cls_loss: 0.0078  \n",
      "<<<iteration:[280/657] - total_loss: 0.2888  obj_loss: 0.1596  noobj_loss: 0.1840  bbox_loss: 0.0052  cls_loss: 0.0109  \n",
      "<<<iteration:[300/657] - total_loss: 0.2910  obj_loss: 0.1695  noobj_loss: 0.1756  bbox_loss: 0.0051  cls_loss: 0.0085  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<<<iteration:[320/657] - total_loss: 0.2887  obj_loss: 0.1631  noobj_loss: 0.1817  bbox_loss: 0.0053  cls_loss: 0.0084  \n",
      "<<<iteration:[340/657] - total_loss: 0.2846  obj_loss: 0.1600  noobj_loss: 0.1773  bbox_loss: 0.0053  cls_loss: 0.0093  \n",
      "<<<iteration:[360/657] - total_loss: 0.2986  obj_loss: 0.1771  noobj_loss: 0.1781  bbox_loss: 0.0051  cls_loss: 0.0070  \n",
      "<<<iteration:[380/657] - total_loss: 0.2791  obj_loss: 0.1562  noobj_loss: 0.1789  bbox_loss: 0.0051  cls_loss: 0.0077  \n",
      "<<<iteration:[400/657] - total_loss: 0.2839  obj_loss: 0.1645  noobj_loss: 0.1791  bbox_loss: 0.0049  cls_loss: 0.0052  \n",
      "<<<iteration:[420/657] - total_loss: 0.2827  obj_loss: 0.1629  noobj_loss: 0.1773  bbox_loss: 0.0047  cls_loss: 0.0079  \n",
      "<<<iteration:[440/657] - total_loss: 0.2955  obj_loss: 0.1701  noobj_loss: 0.1810  bbox_loss: 0.0052  cls_loss: 0.0089  \n",
      "<<<iteration:[460/657] - total_loss: 0.2811  obj_loss: 0.1541  noobj_loss: 0.1818  bbox_loss: 0.0053  cls_loss: 0.0097  \n",
      "<<<iteration:[480/657] - total_loss: 0.2714  obj_loss: 0.1553  noobj_loss: 0.1726  bbox_loss: 0.0045  cls_loss: 0.0074  \n",
      "<<<iteration:[500/657] - total_loss: 0.2885  obj_loss: 0.1703  noobj_loss: 0.1735  bbox_loss: 0.0047  cls_loss: 0.0077  \n",
      "<<<iteration:[520/657] - total_loss: 0.2857  obj_loss: 0.1593  noobj_loss: 0.1796  bbox_loss: 0.0058  cls_loss: 0.0075  \n",
      "<<<iteration:[540/657] - total_loss: 0.2907  obj_loss: 0.1653  noobj_loss: 0.1836  bbox_loss: 0.0049  cls_loss: 0.0092  \n",
      "<<<iteration:[560/657] - total_loss: 0.3061  obj_loss: 0.1747  noobj_loss: 0.1831  bbox_loss: 0.0055  cls_loss: 0.0123  \n",
      "<<<iteration:[580/657] - total_loss: 0.2816  obj_loss: 0.1569  noobj_loss: 0.1767  bbox_loss: 0.0057  cls_loss: 0.0079  \n",
      "<<<iteration:[600/657] - total_loss: 0.2914  obj_loss: 0.1636  noobj_loss: 0.1867  bbox_loss: 0.0050  cls_loss: 0.0095  \n",
      "<<<iteration:[620/657] - total_loss: 0.2984  obj_loss: 0.1775  noobj_loss: 0.1800  bbox_loss: 0.0049  cls_loss: 0.0064  \n",
      "<<<iteration:[640/657] - total_loss: 0.2912  obj_loss: 0.1695  noobj_loss: 0.1791  bbox_loss: 0.0048  cls_loss: 0.0082  \n",
      "\n",
      "epoch:78/100 - Train Loss: 0.2884, Val Loss: 0.3058\n",
      "\n",
      "<<<iteration:[20/657] - total_loss: 0.2986  obj_loss: 0.1715  noobj_loss: 0.1820  bbox_loss: 0.0053  cls_loss: 0.0096  \n",
      "<<<iteration:[40/657] - total_loss: 0.2835  obj_loss: 0.1578  noobj_loss: 0.1864  bbox_loss: 0.0049  cls_loss: 0.0083  \n",
      "<<<iteration:[60/657] - total_loss: 0.2981  obj_loss: 0.1755  noobj_loss: 0.1848  bbox_loss: 0.0046  cls_loss: 0.0071  \n",
      "<<<iteration:[80/657] - total_loss: 0.2952  obj_loss: 0.1684  noobj_loss: 0.1749  bbox_loss: 0.0056  cls_loss: 0.0111  \n",
      "<<<iteration:[100/657] - total_loss: 0.2848  obj_loss: 0.1669  noobj_loss: 0.1788  bbox_loss: 0.0046  cls_loss: 0.0055  \n",
      "<<<iteration:[120/657] - total_loss: 0.2971  obj_loss: 0.1751  noobj_loss: 0.1790  bbox_loss: 0.0050  cls_loss: 0.0074  \n",
      "<<<iteration:[140/657] - total_loss: 0.2689  obj_loss: 0.1485  noobj_loss: 0.1765  bbox_loss: 0.0051  cls_loss: 0.0068  \n",
      "<<<iteration:[160/657] - total_loss: 0.2924  obj_loss: 0.1730  noobj_loss: 0.1808  bbox_loss: 0.0046  cls_loss: 0.0063  \n",
      "<<<iteration:[180/657] - total_loss: 0.2861  obj_loss: 0.1643  noobj_loss: 0.1798  bbox_loss: 0.0051  cls_loss: 0.0063  \n",
      "<<<iteration:[200/657] - total_loss: 0.2887  obj_loss: 0.1664  noobj_loss: 0.1834  bbox_loss: 0.0048  cls_loss: 0.0066  \n",
      "<<<iteration:[220/657] - total_loss: 0.2852  obj_loss: 0.1619  noobj_loss: 0.1781  bbox_loss: 0.0051  cls_loss: 0.0085  \n",
      "<<<iteration:[240/657] - total_loss: 0.2965  obj_loss: 0.1691  noobj_loss: 0.1795  bbox_loss: 0.0052  cls_loss: 0.0118  \n",
      "<<<iteration:[260/657] - total_loss: 0.2982  obj_loss: 0.1720  noobj_loss: 0.1834  bbox_loss: 0.0053  cls_loss: 0.0078  \n",
      "<<<iteration:[280/657] - total_loss: 0.2987  obj_loss: 0.1695  noobj_loss: 0.1816  bbox_loss: 0.0059  cls_loss: 0.0092  \n",
      "<<<iteration:[300/657] - total_loss: 0.3018  obj_loss: 0.1765  noobj_loss: 0.1865  bbox_loss: 0.0047  cls_loss: 0.0087  \n",
      "<<<iteration:[320/657] - total_loss: 0.3066  obj_loss: 0.1836  noobj_loss: 0.1874  bbox_loss: 0.0046  cls_loss: 0.0064  \n",
      "<<<iteration:[340/657] - total_loss: 0.2822  obj_loss: 0.1599  noobj_loss: 0.1789  bbox_loss: 0.0052  cls_loss: 0.0069  \n",
      "<<<iteration:[360/657] - total_loss: 0.2988  obj_loss: 0.1744  noobj_loss: 0.1792  bbox_loss: 0.0055  cls_loss: 0.0075  \n",
      "<<<iteration:[380/657] - total_loss: 0.2943  obj_loss: 0.1634  noobj_loss: 0.1909  bbox_loss: 0.0050  cls_loss: 0.0106  \n",
      "<<<iteration:[400/657] - total_loss: 0.2970  obj_loss: 0.1758  noobj_loss: 0.1757  bbox_loss: 0.0054  cls_loss: 0.0063  \n",
      "<<<iteration:[420/657] - total_loss: 0.2909  obj_loss: 0.1618  noobj_loss: 0.1766  bbox_loss: 0.0066  cls_loss: 0.0080  \n",
      "<<<iteration:[440/657] - total_loss: 0.2908  obj_loss: 0.1659  noobj_loss: 0.1822  bbox_loss: 0.0050  cls_loss: 0.0089  \n",
      "<<<iteration:[460/657] - total_loss: 0.3088  obj_loss: 0.1800  noobj_loss: 0.1855  bbox_loss: 0.0051  cls_loss: 0.0105  \n",
      "<<<iteration:[480/657] - total_loss: 0.2778  obj_loss: 0.1532  noobj_loss: 0.1815  bbox_loss: 0.0051  cls_loss: 0.0083  \n",
      "<<<iteration:[500/657] - total_loss: 0.2830  obj_loss: 0.1626  noobj_loss: 0.1768  bbox_loss: 0.0051  cls_loss: 0.0066  \n",
      "<<<iteration:[520/657] - total_loss: 0.2787  obj_loss: 0.1592  noobj_loss: 0.1772  bbox_loss: 0.0047  cls_loss: 0.0073  \n",
      "<<<iteration:[540/657] - total_loss: 0.2887  obj_loss: 0.1613  noobj_loss: 0.1868  bbox_loss: 0.0054  cls_loss: 0.0071  \n",
      "<<<iteration:[560/657] - total_loss: 0.2860  obj_loss: 0.1625  noobj_loss: 0.1852  bbox_loss: 0.0046  cls_loss: 0.0080  \n",
      "<<<iteration:[580/657] - total_loss: 0.2929  obj_loss: 0.1675  noobj_loss: 0.1818  bbox_loss: 0.0052  cls_loss: 0.0087  \n",
      "<<<iteration:[600/657] - total_loss: 0.2931  obj_loss: 0.1672  noobj_loss: 0.1747  bbox_loss: 0.0054  cls_loss: 0.0114  \n",
      "<<<iteration:[620/657] - total_loss: 0.2833  obj_loss: 0.1596  noobj_loss: 0.1829  bbox_loss: 0.0048  cls_loss: 0.0082  \n",
      "<<<iteration:[640/657] - total_loss: 0.2815  obj_loss: 0.1577  noobj_loss: 0.1794  bbox_loss: 0.0048  cls_loss: 0.0099  \n",
      "\n",
      "epoch:79/100 - Train Loss: 0.2905, Val Loss: 0.3083\n",
      "\n",
      "<<<iteration:[20/657] - total_loss: 0.3004  obj_loss: 0.1695  noobj_loss: 0.1927  bbox_loss: 0.0051  cls_loss: 0.0089  \n",
      "<<<iteration:[40/657] - total_loss: 0.2890  obj_loss: 0.1624  noobj_loss: 0.1958  bbox_loss: 0.0043  cls_loss: 0.0074  \n",
      "<<<iteration:[60/657] - total_loss: 0.2995  obj_loss: 0.1727  noobj_loss: 0.1803  bbox_loss: 0.0051  cls_loss: 0.0114  \n",
      "<<<iteration:[80/657] - total_loss: 0.2816  obj_loss: 0.1608  noobj_loss: 0.1832  bbox_loss: 0.0045  cls_loss: 0.0067  \n",
      "<<<iteration:[100/657] - total_loss: 0.2735  obj_loss: 0.1490  noobj_loss: 0.1787  bbox_loss: 0.0053  cls_loss: 0.0085  \n",
      "<<<iteration:[120/657] - total_loss: 0.2969  obj_loss: 0.1746  noobj_loss: 0.1837  bbox_loss: 0.0048  cls_loss: 0.0065  \n",
      "<<<iteration:[140/657] - total_loss: 0.2846  obj_loss: 0.1619  noobj_loss: 0.1773  bbox_loss: 0.0052  cls_loss: 0.0079  \n",
      "<<<iteration:[160/657] - total_loss: 0.2959  obj_loss: 0.1699  noobj_loss: 0.1833  bbox_loss: 0.0051  cls_loss: 0.0087  \n",
      "<<<iteration:[180/657] - total_loss: 0.2788  obj_loss: 0.1573  noobj_loss: 0.1846  bbox_loss: 0.0044  cls_loss: 0.0073  \n",
      "<<<iteration:[200/657] - total_loss: 0.2926  obj_loss: 0.1733  noobj_loss: 0.1803  bbox_loss: 0.0046  cls_loss: 0.0060  \n",
      "<<<iteration:[220/657] - total_loss: 0.2858  obj_loss: 0.1570  noobj_loss: 0.1865  bbox_loss: 0.0055  cls_loss: 0.0083  \n",
      "<<<iteration:[240/657] - total_loss: 0.2943  obj_loss: 0.1641  noobj_loss: 0.1888  bbox_loss: 0.0053  cls_loss: 0.0092  \n",
      "<<<iteration:[260/657] - total_loss: 0.3152  obj_loss: 0.1799  noobj_loss: 0.1888  bbox_loss: 0.0054  cls_loss: 0.0140  \n",
      "<<<iteration:[280/657] - total_loss: 0.2852  obj_loss: 0.1593  noobj_loss: 0.1847  bbox_loss: 0.0051  cls_loss: 0.0078  \n",
      "<<<iteration:[300/657] - total_loss: 0.2901  obj_loss: 0.1676  noobj_loss: 0.1777  bbox_loss: 0.0053  cls_loss: 0.0072  \n",
      "<<<iteration:[320/657] - total_loss: 0.2863  obj_loss: 0.1558  noobj_loss: 0.1885  bbox_loss: 0.0052  cls_loss: 0.0104  \n",
      "<<<iteration:[340/657] - total_loss: 0.2955  obj_loss: 0.1738  noobj_loss: 0.1835  bbox_loss: 0.0046  cls_loss: 0.0068  \n",
      "<<<iteration:[360/657] - total_loss: 0.2911  obj_loss: 0.1711  noobj_loss: 0.1795  bbox_loss: 0.0045  cls_loss: 0.0075  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<<<iteration:[380/657] - total_loss: 0.3029  obj_loss: 0.1733  noobj_loss: 0.1883  bbox_loss: 0.0050  cls_loss: 0.0103  \n",
      "<<<iteration:[400/657] - total_loss: 0.2876  obj_loss: 0.1667  noobj_loss: 0.1796  bbox_loss: 0.0047  cls_loss: 0.0075  \n",
      "<<<iteration:[420/657] - total_loss: 0.2986  obj_loss: 0.1750  noobj_loss: 0.1872  bbox_loss: 0.0045  cls_loss: 0.0077  \n",
      "<<<iteration:[440/657] - total_loss: 0.2801  obj_loss: 0.1612  noobj_loss: 0.1837  bbox_loss: 0.0045  cls_loss: 0.0044  \n",
      "<<<iteration:[460/657] - total_loss: 0.3041  obj_loss: 0.1781  noobj_loss: 0.1837  bbox_loss: 0.0049  cls_loss: 0.0094  \n",
      "<<<iteration:[480/657] - total_loss: 0.2948  obj_loss: 0.1673  noobj_loss: 0.1817  bbox_loss: 0.0050  cls_loss: 0.0118  \n",
      "<<<iteration:[500/657] - total_loss: 0.2819  obj_loss: 0.1602  noobj_loss: 0.1745  bbox_loss: 0.0052  cls_loss: 0.0083  \n",
      "<<<iteration:[520/657] - total_loss: 0.2803  obj_loss: 0.1608  noobj_loss: 0.1747  bbox_loss: 0.0048  cls_loss: 0.0080  \n",
      "<<<iteration:[540/657] - total_loss: 0.2835  obj_loss: 0.1595  noobj_loss: 0.1854  bbox_loss: 0.0050  cls_loss: 0.0063  \n",
      "<<<iteration:[560/657] - total_loss: 0.2803  obj_loss: 0.1619  noobj_loss: 0.1698  bbox_loss: 0.0052  cls_loss: 0.0075  \n",
      "<<<iteration:[580/657] - total_loss: 0.2864  obj_loss: 0.1670  noobj_loss: 0.1751  bbox_loss: 0.0048  cls_loss: 0.0077  \n",
      "<<<iteration:[600/657] - total_loss: 0.2739  obj_loss: 0.1514  noobj_loss: 0.1837  bbox_loss: 0.0047  cls_loss: 0.0074  \n",
      "<<<iteration:[620/657] - total_loss: 0.2870  obj_loss: 0.1599  noobj_loss: 0.1918  bbox_loss: 0.0047  cls_loss: 0.0077  \n",
      "<<<iteration:[640/657] - total_loss: 0.2937  obj_loss: 0.1737  noobj_loss: 0.1719  bbox_loss: 0.0055  cls_loss: 0.0067  \n",
      "\n",
      "epoch:80/100 - Train Loss: 0.2891, Val Loss: 0.3118\n",
      "\n",
      "<<<iteration:[20/657] - total_loss: 0.3135  obj_loss: 0.1863  noobj_loss: 0.1835  bbox_loss: 0.0054  cls_loss: 0.0084  \n",
      "<<<iteration:[40/657] - total_loss: 0.2953  obj_loss: 0.1704  noobj_loss: 0.1875  bbox_loss: 0.0047  cls_loss: 0.0074  \n",
      "<<<iteration:[60/657] - total_loss: 0.3018  obj_loss: 0.1752  noobj_loss: 0.1857  bbox_loss: 0.0047  cls_loss: 0.0105  \n",
      "<<<iteration:[80/657] - total_loss: 0.2891  obj_loss: 0.1660  noobj_loss: 0.1785  bbox_loss: 0.0046  cls_loss: 0.0108  \n",
      "<<<iteration:[100/657] - total_loss: 0.2783  obj_loss: 0.1578  noobj_loss: 0.1719  bbox_loss: 0.0055  cls_loss: 0.0073  \n",
      "<<<iteration:[120/657] - total_loss: 0.2919  obj_loss: 0.1700  noobj_loss: 0.1778  bbox_loss: 0.0050  cls_loss: 0.0078  \n",
      "<<<iteration:[140/657] - total_loss: 0.2875  obj_loss: 0.1637  noobj_loss: 0.1771  bbox_loss: 0.0052  cls_loss: 0.0090  \n",
      "<<<iteration:[160/657] - total_loss: 0.2776  obj_loss: 0.1602  noobj_loss: 0.1740  bbox_loss: 0.0047  cls_loss: 0.0070  \n",
      "<<<iteration:[180/657] - total_loss: 0.2961  obj_loss: 0.1750  noobj_loss: 0.1774  bbox_loss: 0.0047  cls_loss: 0.0089  \n",
      "<<<iteration:[200/657] - total_loss: 0.2841  obj_loss: 0.1548  noobj_loss: 0.1903  bbox_loss: 0.0048  cls_loss: 0.0101  \n",
      "<<<iteration:[220/657] - total_loss: 0.2820  obj_loss: 0.1611  noobj_loss: 0.1807  bbox_loss: 0.0048  cls_loss: 0.0067  \n",
      "<<<iteration:[240/657] - total_loss: 0.2979  obj_loss: 0.1727  noobj_loss: 0.1809  bbox_loss: 0.0050  cls_loss: 0.0097  \n",
      "<<<iteration:[260/657] - total_loss: 0.2949  obj_loss: 0.1688  noobj_loss: 0.1807  bbox_loss: 0.0051  cls_loss: 0.0101  \n",
      "<<<iteration:[280/657] - total_loss: 0.2954  obj_loss: 0.1736  noobj_loss: 0.1832  bbox_loss: 0.0049  cls_loss: 0.0059  \n",
      "<<<iteration:[300/657] - total_loss: 0.2828  obj_loss: 0.1580  noobj_loss: 0.1848  bbox_loss: 0.0048  cls_loss: 0.0085  \n",
      "<<<iteration:[320/657] - total_loss: 0.2929  obj_loss: 0.1708  noobj_loss: 0.1793  bbox_loss: 0.0047  cls_loss: 0.0091  \n",
      "<<<iteration:[340/657] - total_loss: 0.2761  obj_loss: 0.1538  noobj_loss: 0.1823  bbox_loss: 0.0049  cls_loss: 0.0065  \n",
      "<<<iteration:[360/657] - total_loss: 0.2973  obj_loss: 0.1745  noobj_loss: 0.1828  bbox_loss: 0.0049  cls_loss: 0.0068  \n",
      "<<<iteration:[380/657] - total_loss: 0.2849  obj_loss: 0.1634  noobj_loss: 0.1781  bbox_loss: 0.0048  cls_loss: 0.0085  \n",
      "<<<iteration:[400/657] - total_loss: 0.2886  obj_loss: 0.1617  noobj_loss: 0.1812  bbox_loss: 0.0051  cls_loss: 0.0109  \n",
      "<<<iteration:[420/657] - total_loss: 0.2784  obj_loss: 0.1551  noobj_loss: 0.1829  bbox_loss: 0.0050  cls_loss: 0.0067  \n",
      "<<<iteration:[440/657] - total_loss: 0.2897  obj_loss: 0.1624  noobj_loss: 0.1874  bbox_loss: 0.0051  cls_loss: 0.0083  \n",
      "<<<iteration:[460/657] - total_loss: 0.2886  obj_loss: 0.1625  noobj_loss: 0.1816  bbox_loss: 0.0056  cls_loss: 0.0071  \n",
      "<<<iteration:[480/657] - total_loss: 0.2775  obj_loss: 0.1577  noobj_loss: 0.1789  bbox_loss: 0.0047  cls_loss: 0.0067  \n",
      "<<<iteration:[500/657] - total_loss: 0.2839  obj_loss: 0.1620  noobj_loss: 0.1689  bbox_loss: 0.0058  cls_loss: 0.0085  \n",
      "<<<iteration:[520/657] - total_loss: 0.2931  obj_loss: 0.1653  noobj_loss: 0.1882  bbox_loss: 0.0051  cls_loss: 0.0084  \n",
      "<<<iteration:[540/657] - total_loss: 0.2852  obj_loss: 0.1620  noobj_loss: 0.1790  bbox_loss: 0.0053  cls_loss: 0.0073  \n",
      "<<<iteration:[560/657] - total_loss: 0.2918  obj_loss: 0.1678  noobj_loss: 0.1757  bbox_loss: 0.0052  cls_loss: 0.0104  \n",
      "<<<iteration:[580/657] - total_loss: 0.2901  obj_loss: 0.1641  noobj_loss: 0.1823  bbox_loss: 0.0053  cls_loss: 0.0085  \n",
      "<<<iteration:[600/657] - total_loss: 0.2815  obj_loss: 0.1606  noobj_loss: 0.1806  bbox_loss: 0.0049  cls_loss: 0.0062  \n",
      "<<<iteration:[620/657] - total_loss: 0.2862  obj_loss: 0.1568  noobj_loss: 0.1828  bbox_loss: 0.0055  cls_loss: 0.0103  \n",
      "<<<iteration:[640/657] - total_loss: 0.2782  obj_loss: 0.1480  noobj_loss: 0.1851  bbox_loss: 0.0058  cls_loss: 0.0084  \n",
      "\n",
      "epoch:81/100 - Train Loss: 0.2880, Val Loss: 0.3119\n",
      "\n",
      "<<<iteration:[20/657] - total_loss: 0.3007  obj_loss: 0.1701  noobj_loss: 0.1850  bbox_loss: 0.0058  cls_loss: 0.0089  \n",
      "<<<iteration:[40/657] - total_loss: 0.2937  obj_loss: 0.1639  noobj_loss: 0.1892  bbox_loss: 0.0054  cls_loss: 0.0083  \n",
      "<<<iteration:[60/657] - total_loss: 0.3080  obj_loss: 0.1856  noobj_loss: 0.1794  bbox_loss: 0.0046  cls_loss: 0.0095  \n",
      "<<<iteration:[80/657] - total_loss: 0.2966  obj_loss: 0.1696  noobj_loss: 0.1896  bbox_loss: 0.0052  cls_loss: 0.0065  \n",
      "<<<iteration:[100/657] - total_loss: 0.2810  obj_loss: 0.1621  noobj_loss: 0.1795  bbox_loss: 0.0048  cls_loss: 0.0053  \n",
      "<<<iteration:[120/657] - total_loss: 0.2923  obj_loss: 0.1712  noobj_loss: 0.1757  bbox_loss: 0.0050  cls_loss: 0.0083  \n",
      "<<<iteration:[140/657] - total_loss: 0.2932  obj_loss: 0.1655  noobj_loss: 0.1824  bbox_loss: 0.0056  cls_loss: 0.0083  \n",
      "<<<iteration:[160/657] - total_loss: 0.2867  obj_loss: 0.1650  noobj_loss: 0.1772  bbox_loss: 0.0052  cls_loss: 0.0072  \n",
      "<<<iteration:[180/657] - total_loss: 0.2895  obj_loss: 0.1647  noobj_loss: 0.1847  bbox_loss: 0.0050  cls_loss: 0.0077  \n",
      "<<<iteration:[200/657] - total_loss: 0.2871  obj_loss: 0.1628  noobj_loss: 0.1801  bbox_loss: 0.0052  cls_loss: 0.0081  \n",
      "<<<iteration:[220/657] - total_loss: 0.2969  obj_loss: 0.1710  noobj_loss: 0.1849  bbox_loss: 0.0048  cls_loss: 0.0096  \n",
      "<<<iteration:[240/657] - total_loss: 0.2908  obj_loss: 0.1574  noobj_loss: 0.1838  bbox_loss: 0.0054  cls_loss: 0.0145  \n",
      "<<<iteration:[260/657] - total_loss: 0.2728  obj_loss: 0.1544  noobj_loss: 0.1786  bbox_loss: 0.0045  cls_loss: 0.0067  \n",
      "<<<iteration:[280/657] - total_loss: 0.2834  obj_loss: 0.1576  noobj_loss: 0.1830  bbox_loss: 0.0052  cls_loss: 0.0081  \n",
      "<<<iteration:[300/657] - total_loss: 0.2833  obj_loss: 0.1618  noobj_loss: 0.1827  bbox_loss: 0.0046  cls_loss: 0.0071  \n",
      "<<<iteration:[320/657] - total_loss: 0.2938  obj_loss: 0.1712  noobj_loss: 0.1837  bbox_loss: 0.0049  cls_loss: 0.0065  \n",
      "<<<iteration:[340/657] - total_loss: 0.2826  obj_loss: 0.1600  noobj_loss: 0.1839  bbox_loss: 0.0048  cls_loss: 0.0066  \n",
      "<<<iteration:[360/657] - total_loss: 0.2871  obj_loss: 0.1617  noobj_loss: 0.1843  bbox_loss: 0.0051  cls_loss: 0.0080  \n",
      "<<<iteration:[380/657] - total_loss: 0.2776  obj_loss: 0.1514  noobj_loss: 0.1815  bbox_loss: 0.0052  cls_loss: 0.0092  \n",
      "<<<iteration:[400/657] - total_loss: 0.2908  obj_loss: 0.1690  noobj_loss: 0.1833  bbox_loss: 0.0045  cls_loss: 0.0077  \n",
      "<<<iteration:[420/657] - total_loss: 0.2877  obj_loss: 0.1636  noobj_loss: 0.1825  bbox_loss: 0.0051  cls_loss: 0.0072  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<<<iteration:[440/657] - total_loss: 0.2885  obj_loss: 0.1656  noobj_loss: 0.1851  bbox_loss: 0.0047  cls_loss: 0.0071  \n",
      "<<<iteration:[460/657] - total_loss: 0.2753  obj_loss: 0.1532  noobj_loss: 0.1829  bbox_loss: 0.0049  cls_loss: 0.0064  \n",
      "<<<iteration:[480/657] - total_loss: 0.3043  obj_loss: 0.1773  noobj_loss: 0.1835  bbox_loss: 0.0051  cls_loss: 0.0095  \n",
      "<<<iteration:[500/657] - total_loss: 0.3015  obj_loss: 0.1739  noobj_loss: 0.1916  bbox_loss: 0.0047  cls_loss: 0.0085  \n",
      "<<<iteration:[520/657] - total_loss: 0.3002  obj_loss: 0.1762  noobj_loss: 0.1861  bbox_loss: 0.0048  cls_loss: 0.0067  \n",
      "<<<iteration:[540/657] - total_loss: 0.2895  obj_loss: 0.1631  noobj_loss: 0.1827  bbox_loss: 0.0054  cls_loss: 0.0079  \n",
      "<<<iteration:[560/657] - total_loss: 0.2794  obj_loss: 0.1573  noobj_loss: 0.1795  bbox_loss: 0.0049  cls_loss: 0.0076  \n",
      "<<<iteration:[580/657] - total_loss: 0.2830  obj_loss: 0.1603  noobj_loss: 0.1785  bbox_loss: 0.0051  cls_loss: 0.0082  \n",
      "<<<iteration:[600/657] - total_loss: 0.3057  obj_loss: 0.1819  noobj_loss: 0.1832  bbox_loss: 0.0048  cls_loss: 0.0082  \n",
      "<<<iteration:[620/657] - total_loss: 0.2902  obj_loss: 0.1653  noobj_loss: 0.1844  bbox_loss: 0.0048  cls_loss: 0.0087  \n",
      "<<<iteration:[640/657] - total_loss: 0.2814  obj_loss: 0.1517  noobj_loss: 0.1843  bbox_loss: 0.0051  cls_loss: 0.0120  \n",
      "\n",
      "epoch:82/100 - Train Loss: 0.2893, Val Loss: 0.3051\n",
      "\n",
      "<<<iteration:[20/657] - total_loss: 0.2940  obj_loss: 0.1628  noobj_loss: 0.1907  bbox_loss: 0.0053  cls_loss: 0.0094  \n",
      "<<<iteration:[40/657] - total_loss: 0.2915  obj_loss: 0.1711  noobj_loss: 0.1856  bbox_loss: 0.0042  cls_loss: 0.0065  \n",
      "<<<iteration:[60/657] - total_loss: 0.2827  obj_loss: 0.1558  noobj_loss: 0.1843  bbox_loss: 0.0050  cls_loss: 0.0100  \n",
      "<<<iteration:[80/657] - total_loss: 0.2838  obj_loss: 0.1627  noobj_loss: 0.1777  bbox_loss: 0.0049  cls_loss: 0.0079  \n",
      "<<<iteration:[100/657] - total_loss: 0.2857  obj_loss: 0.1653  noobj_loss: 0.1775  bbox_loss: 0.0050  cls_loss: 0.0067  \n",
      "<<<iteration:[120/657] - total_loss: 0.2816  obj_loss: 0.1574  noobj_loss: 0.1836  bbox_loss: 0.0050  cls_loss: 0.0072  \n",
      "<<<iteration:[140/657] - total_loss: 0.2936  obj_loss: 0.1763  noobj_loss: 0.1809  bbox_loss: 0.0042  cls_loss: 0.0061  \n",
      "<<<iteration:[160/657] - total_loss: 0.2968  obj_loss: 0.1729  noobj_loss: 0.1834  bbox_loss: 0.0047  cls_loss: 0.0086  \n",
      "<<<iteration:[180/657] - total_loss: 0.2911  obj_loss: 0.1683  noobj_loss: 0.1845  bbox_loss: 0.0049  cls_loss: 0.0061  \n",
      "<<<iteration:[200/657] - total_loss: 0.2866  obj_loss: 0.1665  noobj_loss: 0.1826  bbox_loss: 0.0043  cls_loss: 0.0071  \n",
      "<<<iteration:[220/657] - total_loss: 0.2762  obj_loss: 0.1492  noobj_loss: 0.1761  bbox_loss: 0.0052  cls_loss: 0.0128  \n",
      "<<<iteration:[240/657] - total_loss: 0.2893  obj_loss: 0.1629  noobj_loss: 0.1882  bbox_loss: 0.0049  cls_loss: 0.0078  \n",
      "<<<iteration:[260/657] - total_loss: 0.2747  obj_loss: 0.1558  noobj_loss: 0.1808  bbox_loss: 0.0043  cls_loss: 0.0068  \n",
      "<<<iteration:[280/657] - total_loss: 0.2854  obj_loss: 0.1653  noobj_loss: 0.1747  bbox_loss: 0.0049  cls_loss: 0.0081  \n",
      "<<<iteration:[300/657] - total_loss: 0.2901  obj_loss: 0.1661  noobj_loss: 0.1909  bbox_loss: 0.0046  cls_loss: 0.0057  \n",
      "<<<iteration:[320/657] - total_loss: 0.2944  obj_loss: 0.1715  noobj_loss: 0.1812  bbox_loss: 0.0047  cls_loss: 0.0088  \n",
      "<<<iteration:[340/657] - total_loss: 0.2862  obj_loss: 0.1650  noobj_loss: 0.1751  bbox_loss: 0.0052  cls_loss: 0.0078  \n",
      "<<<iteration:[360/657] - total_loss: 0.2888  obj_loss: 0.1664  noobj_loss: 0.1765  bbox_loss: 0.0050  cls_loss: 0.0092  \n",
      "<<<iteration:[380/657] - total_loss: 0.2951  obj_loss: 0.1712  noobj_loss: 0.1837  bbox_loss: 0.0048  cls_loss: 0.0083  \n",
      "<<<iteration:[400/657] - total_loss: 0.2909  obj_loss: 0.1669  noobj_loss: 0.1838  bbox_loss: 0.0051  cls_loss: 0.0068  \n",
      "<<<iteration:[420/657] - total_loss: 0.2907  obj_loss: 0.1675  noobj_loss: 0.1801  bbox_loss: 0.0050  cls_loss: 0.0083  \n",
      "<<<iteration:[440/657] - total_loss: 0.2921  obj_loss: 0.1708  noobj_loss: 0.1853  bbox_loss: 0.0043  cls_loss: 0.0070  \n",
      "<<<iteration:[460/657] - total_loss: 0.2784  obj_loss: 0.1519  noobj_loss: 0.1816  bbox_loss: 0.0052  cls_loss: 0.0097  \n",
      "<<<iteration:[480/657] - total_loss: 0.2902  obj_loss: 0.1658  noobj_loss: 0.1898  bbox_loss: 0.0044  cls_loss: 0.0072  \n",
      "<<<iteration:[500/657] - total_loss: 0.2791  obj_loss: 0.1508  noobj_loss: 0.1837  bbox_loss: 0.0056  cls_loss: 0.0082  \n",
      "<<<iteration:[520/657] - total_loss: 0.2935  obj_loss: 0.1700  noobj_loss: 0.1841  bbox_loss: 0.0049  cls_loss: 0.0072  \n",
      "<<<iteration:[540/657] - total_loss: 0.2988  obj_loss: 0.1727  noobj_loss: 0.1861  bbox_loss: 0.0050  cls_loss: 0.0081  \n",
      "<<<iteration:[560/657] - total_loss: 0.2930  obj_loss: 0.1685  noobj_loss: 0.1894  bbox_loss: 0.0047  cls_loss: 0.0066  \n",
      "<<<iteration:[580/657] - total_loss: 0.2937  obj_loss: 0.1693  noobj_loss: 0.1871  bbox_loss: 0.0045  cls_loss: 0.0082  \n",
      "<<<iteration:[600/657] - total_loss: 0.2855  obj_loss: 0.1631  noobj_loss: 0.1888  bbox_loss: 0.0045  cls_loss: 0.0053  \n",
      "<<<iteration:[620/657] - total_loss: 0.3012  obj_loss: 0.1770  noobj_loss: 0.1761  bbox_loss: 0.0050  cls_loss: 0.0110  \n",
      "<<<iteration:[640/657] - total_loss: 0.2805  obj_loss: 0.1563  noobj_loss: 0.1898  bbox_loss: 0.0043  cls_loss: 0.0075  \n",
      "\n",
      "epoch:83/100 - Train Loss: 0.2880, Val Loss: 0.3088\n",
      "\n",
      "<<<iteration:[20/657] - total_loss: 0.3035  obj_loss: 0.1709  noobj_loss: 0.1940  bbox_loss: 0.0054  cls_loss: 0.0087  \n",
      "<<<iteration:[40/657] - total_loss: 0.2867  obj_loss: 0.1612  noobj_loss: 0.1824  bbox_loss: 0.0049  cls_loss: 0.0100  \n",
      "<<<iteration:[60/657] - total_loss: 0.2827  obj_loss: 0.1617  noobj_loss: 0.1797  bbox_loss: 0.0050  cls_loss: 0.0061  \n",
      "<<<iteration:[80/657] - total_loss: 0.2841  obj_loss: 0.1615  noobj_loss: 0.1811  bbox_loss: 0.0048  cls_loss: 0.0079  \n",
      "<<<iteration:[100/657] - total_loss: 0.2882  obj_loss: 0.1622  noobj_loss: 0.1876  bbox_loss: 0.0046  cls_loss: 0.0090  \n",
      "<<<iteration:[120/657] - total_loss: 0.3025  obj_loss: 0.1782  noobj_loss: 0.1826  bbox_loss: 0.0048  cls_loss: 0.0090  \n",
      "<<<iteration:[140/657] - total_loss: 0.2902  obj_loss: 0.1579  noobj_loss: 0.1879  bbox_loss: 0.0056  cls_loss: 0.0106  \n",
      "<<<iteration:[160/657] - total_loss: 0.2890  obj_loss: 0.1641  noobj_loss: 0.1833  bbox_loss: 0.0048  cls_loss: 0.0091  \n",
      "<<<iteration:[180/657] - total_loss: 0.2913  obj_loss: 0.1637  noobj_loss: 0.1928  bbox_loss: 0.0052  cls_loss: 0.0052  \n",
      "<<<iteration:[200/657] - total_loss: 0.2881  obj_loss: 0.1644  noobj_loss: 0.1827  bbox_loss: 0.0044  cls_loss: 0.0103  \n",
      "<<<iteration:[220/657] - total_loss: 0.3056  obj_loss: 0.1828  noobj_loss: 0.1882  bbox_loss: 0.0042  cls_loss: 0.0074  \n",
      "<<<iteration:[240/657] - total_loss: 0.2901  obj_loss: 0.1584  noobj_loss: 0.1978  bbox_loss: 0.0049  cls_loss: 0.0084  \n",
      "<<<iteration:[260/657] - total_loss: 0.2914  obj_loss: 0.1677  noobj_loss: 0.1840  bbox_loss: 0.0050  cls_loss: 0.0069  \n",
      "<<<iteration:[280/657] - total_loss: 0.2997  obj_loss: 0.1737  noobj_loss: 0.1847  bbox_loss: 0.0050  cls_loss: 0.0089  \n",
      "<<<iteration:[300/657] - total_loss: 0.2796  obj_loss: 0.1561  noobj_loss: 0.1844  bbox_loss: 0.0049  cls_loss: 0.0069  \n",
      "<<<iteration:[320/657] - total_loss: 0.3000  obj_loss: 0.1710  noobj_loss: 0.1820  bbox_loss: 0.0054  cls_loss: 0.0112  \n",
      "<<<iteration:[340/657] - total_loss: 0.2838  obj_loss: 0.1650  noobj_loss: 0.1795  bbox_loss: 0.0044  cls_loss: 0.0070  \n",
      "<<<iteration:[360/657] - total_loss: 0.2955  obj_loss: 0.1645  noobj_loss: 0.1901  bbox_loss: 0.0051  cls_loss: 0.0106  \n",
      "<<<iteration:[380/657] - total_loss: 0.2990  obj_loss: 0.1746  noobj_loss: 0.1809  bbox_loss: 0.0050  cls_loss: 0.0087  \n",
      "<<<iteration:[400/657] - total_loss: 0.2889  obj_loss: 0.1643  noobj_loss: 0.1916  bbox_loss: 0.0046  cls_loss: 0.0057  \n",
      "<<<iteration:[420/657] - total_loss: 0.3009  obj_loss: 0.1740  noobj_loss: 0.1916  bbox_loss: 0.0047  cls_loss: 0.0077  \n",
      "<<<iteration:[440/657] - total_loss: 0.2840  obj_loss: 0.1618  noobj_loss: 0.1782  bbox_loss: 0.0051  cls_loss: 0.0076  \n",
      "<<<iteration:[460/657] - total_loss: 0.3004  obj_loss: 0.1798  noobj_loss: 0.1838  bbox_loss: 0.0045  cls_loss: 0.0061  \n",
      "<<<iteration:[480/657] - total_loss: 0.2896  obj_loss: 0.1665  noobj_loss: 0.1855  bbox_loss: 0.0045  cls_loss: 0.0077  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<<<iteration:[500/657] - total_loss: 0.2911  obj_loss: 0.1637  noobj_loss: 0.1956  bbox_loss: 0.0042  cls_loss: 0.0087  \n",
      "<<<iteration:[520/657] - total_loss: 0.2861  obj_loss: 0.1656  noobj_loss: 0.1877  bbox_loss: 0.0040  cls_loss: 0.0067  \n",
      "<<<iteration:[540/657] - total_loss: 0.2830  obj_loss: 0.1601  noobj_loss: 0.1827  bbox_loss: 0.0048  cls_loss: 0.0075  \n",
      "<<<iteration:[560/657] - total_loss: 0.2812  obj_loss: 0.1586  noobj_loss: 0.1799  bbox_loss: 0.0047  cls_loss: 0.0091  \n",
      "<<<iteration:[580/657] - total_loss: 0.2719  obj_loss: 0.1521  noobj_loss: 0.1799  bbox_loss: 0.0047  cls_loss: 0.0062  \n",
      "<<<iteration:[600/657] - total_loss: 0.2742  obj_loss: 0.1520  noobj_loss: 0.1822  bbox_loss: 0.0045  cls_loss: 0.0087  \n",
      "<<<iteration:[620/657] - total_loss: 0.2956  obj_loss: 0.1720  noobj_loss: 0.1837  bbox_loss: 0.0048  cls_loss: 0.0078  \n",
      "<<<iteration:[640/657] - total_loss: 0.2932  obj_loss: 0.1710  noobj_loss: 0.1778  bbox_loss: 0.0050  cls_loss: 0.0081  \n",
      "\n",
      "epoch:84/100 - Train Loss: 0.2898, Val Loss: 0.3073\n",
      "\n",
      "<<<iteration:[20/657] - total_loss: 0.3037  obj_loss: 0.1711  noobj_loss: 0.1915  bbox_loss: 0.0051  cls_loss: 0.0114  \n",
      "<<<iteration:[40/657] - total_loss: 0.3021  obj_loss: 0.1768  noobj_loss: 0.1887  bbox_loss: 0.0046  cls_loss: 0.0081  \n",
      "<<<iteration:[60/657] - total_loss: 0.2897  obj_loss: 0.1636  noobj_loss: 0.1855  bbox_loss: 0.0050  cls_loss: 0.0085  \n",
      "<<<iteration:[80/657] - total_loss: 0.2908  obj_loss: 0.1675  noobj_loss: 0.1866  bbox_loss: 0.0043  cls_loss: 0.0088  \n",
      "<<<iteration:[100/657] - total_loss: 0.2924  obj_loss: 0.1668  noobj_loss: 0.1824  bbox_loss: 0.0050  cls_loss: 0.0096  \n",
      "<<<iteration:[120/657] - total_loss: 0.2985  obj_loss: 0.1756  noobj_loss: 0.1847  bbox_loss: 0.0049  cls_loss: 0.0060  \n",
      "<<<iteration:[140/657] - total_loss: 0.3008  obj_loss: 0.1764  noobj_loss: 0.1880  bbox_loss: 0.0044  cls_loss: 0.0084  \n",
      "<<<iteration:[160/657] - total_loss: 0.2992  obj_loss: 0.1702  noobj_loss: 0.1909  bbox_loss: 0.0045  cls_loss: 0.0109  \n",
      "<<<iteration:[180/657] - total_loss: 0.2927  obj_loss: 0.1650  noobj_loss: 0.1862  bbox_loss: 0.0051  cls_loss: 0.0090  \n",
      "<<<iteration:[200/657] - total_loss: 0.2897  obj_loss: 0.1626  noobj_loss: 0.1917  bbox_loss: 0.0051  cls_loss: 0.0059  \n",
      "<<<iteration:[220/657] - total_loss: 0.2761  obj_loss: 0.1534  noobj_loss: 0.1831  bbox_loss: 0.0047  cls_loss: 0.0075  \n",
      "<<<iteration:[240/657] - total_loss: 0.2877  obj_loss: 0.1660  noobj_loss: 0.1844  bbox_loss: 0.0045  cls_loss: 0.0072  \n",
      "<<<iteration:[260/657] - total_loss: 0.2802  obj_loss: 0.1606  noobj_loss: 0.1808  bbox_loss: 0.0047  cls_loss: 0.0058  \n",
      "<<<iteration:[280/657] - total_loss: 0.2997  obj_loss: 0.1776  noobj_loss: 0.1848  bbox_loss: 0.0046  cls_loss: 0.0067  \n",
      "<<<iteration:[300/657] - total_loss: 0.2961  obj_loss: 0.1733  noobj_loss: 0.1835  bbox_loss: 0.0049  cls_loss: 0.0064  \n",
      "<<<iteration:[320/657] - total_loss: 0.2903  obj_loss: 0.1664  noobj_loss: 0.1852  bbox_loss: 0.0051  cls_loss: 0.0057  \n",
      "<<<iteration:[340/657] - total_loss: 0.2932  obj_loss: 0.1675  noobj_loss: 0.1857  bbox_loss: 0.0051  cls_loss: 0.0074  \n",
      "<<<iteration:[360/657] - total_loss: 0.2829  obj_loss: 0.1582  noobj_loss: 0.1820  bbox_loss: 0.0048  cls_loss: 0.0095  \n",
      "<<<iteration:[380/657] - total_loss: 0.2889  obj_loss: 0.1629  noobj_loss: 0.1889  bbox_loss: 0.0045  cls_loss: 0.0091  \n",
      "<<<iteration:[400/657] - total_loss: 0.2734  obj_loss: 0.1502  noobj_loss: 0.1815  bbox_loss: 0.0049  cls_loss: 0.0081  \n",
      "<<<iteration:[420/657] - total_loss: 0.2854  obj_loss: 0.1633  noobj_loss: 0.1820  bbox_loss: 0.0043  cls_loss: 0.0095  \n",
      "<<<iteration:[440/657] - total_loss: 0.2929  obj_loss: 0.1661  noobj_loss: 0.1896  bbox_loss: 0.0047  cls_loss: 0.0083  \n",
      "<<<iteration:[460/657] - total_loss: 0.2803  obj_loss: 0.1579  noobj_loss: 0.1810  bbox_loss: 0.0052  cls_loss: 0.0056  \n",
      "<<<iteration:[480/657] - total_loss: 0.2824  obj_loss: 0.1600  noobj_loss: 0.1820  bbox_loss: 0.0048  cls_loss: 0.0072  \n",
      "<<<iteration:[500/657] - total_loss: 0.2843  obj_loss: 0.1627  noobj_loss: 0.1835  bbox_loss: 0.0048  cls_loss: 0.0059  \n",
      "<<<iteration:[520/657] - total_loss: 0.2868  obj_loss: 0.1629  noobj_loss: 0.1856  bbox_loss: 0.0046  cls_loss: 0.0082  \n",
      "<<<iteration:[540/657] - total_loss: 0.2958  obj_loss: 0.1679  noobj_loss: 0.1848  bbox_loss: 0.0053  cls_loss: 0.0089  \n",
      "<<<iteration:[560/657] - total_loss: 0.2921  obj_loss: 0.1594  noobj_loss: 0.1972  bbox_loss: 0.0051  cls_loss: 0.0088  \n",
      "<<<iteration:[580/657] - total_loss: 0.2878  obj_loss: 0.1634  noobj_loss: 0.1837  bbox_loss: 0.0050  cls_loss: 0.0077  \n",
      "<<<iteration:[600/657] - total_loss: 0.2789  obj_loss: 0.1558  noobj_loss: 0.1841  bbox_loss: 0.0048  cls_loss: 0.0070  \n",
      "<<<iteration:[620/657] - total_loss: 0.2924  obj_loss: 0.1699  noobj_loss: 0.1873  bbox_loss: 0.0044  cls_loss: 0.0069  \n",
      "<<<iteration:[640/657] - total_loss: 0.2874  obj_loss: 0.1617  noobj_loss: 0.1841  bbox_loss: 0.0053  cls_loss: 0.0071  \n",
      "\n",
      "epoch:85/100 - Train Loss: 0.2892, Val Loss: 0.3057\n",
      "\n",
      "<<<iteration:[20/657] - total_loss: 0.3011  obj_loss: 0.1665  noobj_loss: 0.1980  bbox_loss: 0.0055  cls_loss: 0.0080  \n",
      "<<<iteration:[40/657] - total_loss: 0.3011  obj_loss: 0.1794  noobj_loss: 0.1823  bbox_loss: 0.0049  cls_loss: 0.0062  \n",
      "<<<iteration:[60/657] - total_loss: 0.2750  obj_loss: 0.1481  noobj_loss: 0.1828  bbox_loss: 0.0051  cls_loss: 0.0100  \n",
      "<<<iteration:[80/657] - total_loss: 0.2882  obj_loss: 0.1699  noobj_loss: 0.1752  bbox_loss: 0.0047  cls_loss: 0.0074  \n",
      "<<<iteration:[100/657] - total_loss: 0.2752  obj_loss: 0.1556  noobj_loss: 0.1823  bbox_loss: 0.0044  cls_loss: 0.0066  \n",
      "<<<iteration:[120/657] - total_loss: 0.2917  obj_loss: 0.1666  noobj_loss: 0.1865  bbox_loss: 0.0050  cls_loss: 0.0068  \n",
      "<<<iteration:[140/657] - total_loss: 0.2982  obj_loss: 0.1747  noobj_loss: 0.1858  bbox_loss: 0.0048  cls_loss: 0.0063  \n",
      "<<<iteration:[160/657] - total_loss: 0.2908  obj_loss: 0.1626  noobj_loss: 0.1946  bbox_loss: 0.0048  cls_loss: 0.0072  \n",
      "<<<iteration:[180/657] - total_loss: 0.2907  obj_loss: 0.1662  noobj_loss: 0.1845  bbox_loss: 0.0048  cls_loss: 0.0081  \n",
      "<<<iteration:[200/657] - total_loss: 0.2778  obj_loss: 0.1491  noobj_loss: 0.1862  bbox_loss: 0.0051  cls_loss: 0.0101  \n",
      "<<<iteration:[220/657] - total_loss: 0.2868  obj_loss: 0.1641  noobj_loss: 0.1822  bbox_loss: 0.0049  cls_loss: 0.0071  \n",
      "<<<iteration:[240/657] - total_loss: 0.2858  obj_loss: 0.1623  noobj_loss: 0.1845  bbox_loss: 0.0044  cls_loss: 0.0093  \n",
      "<<<iteration:[260/657] - total_loss: 0.2979  obj_loss: 0.1703  noobj_loss: 0.1867  bbox_loss: 0.0052  cls_loss: 0.0080  \n",
      "<<<iteration:[280/657] - total_loss: 0.3086  obj_loss: 0.1815  noobj_loss: 0.1905  bbox_loss: 0.0046  cls_loss: 0.0086  \n",
      "<<<iteration:[300/657] - total_loss: 0.2803  obj_loss: 0.1579  noobj_loss: 0.1894  bbox_loss: 0.0045  cls_loss: 0.0052  \n",
      "<<<iteration:[320/657] - total_loss: 0.2827  obj_loss: 0.1597  noobj_loss: 0.1882  bbox_loss: 0.0045  cls_loss: 0.0064  \n",
      "<<<iteration:[340/657] - total_loss: 0.2861  obj_loss: 0.1637  noobj_loss: 0.1842  bbox_loss: 0.0043  cls_loss: 0.0086  \n",
      "<<<iteration:[360/657] - total_loss: 0.2909  obj_loss: 0.1667  noobj_loss: 0.1841  bbox_loss: 0.0048  cls_loss: 0.0083  \n",
      "<<<iteration:[380/657] - total_loss: 0.2897  obj_loss: 0.1644  noobj_loss: 0.1846  bbox_loss: 0.0047  cls_loss: 0.0093  \n",
      "<<<iteration:[400/657] - total_loss: 0.2919  obj_loss: 0.1677  noobj_loss: 0.1869  bbox_loss: 0.0049  cls_loss: 0.0063  \n",
      "<<<iteration:[420/657] - total_loss: 0.2897  obj_loss: 0.1666  noobj_loss: 0.1821  bbox_loss: 0.0047  cls_loss: 0.0085  \n",
      "<<<iteration:[440/657] - total_loss: 0.2848  obj_loss: 0.1578  noobj_loss: 0.1889  bbox_loss: 0.0048  cls_loss: 0.0085  \n",
      "<<<iteration:[460/657] - total_loss: 0.2824  obj_loss: 0.1617  noobj_loss: 0.1893  bbox_loss: 0.0041  cls_loss: 0.0054  \n",
      "<<<iteration:[480/657] - total_loss: 0.2946  obj_loss: 0.1670  noobj_loss: 0.1911  bbox_loss: 0.0048  cls_loss: 0.0081  \n",
      "<<<iteration:[500/657] - total_loss: 0.2911  obj_loss: 0.1658  noobj_loss: 0.1753  bbox_loss: 0.0053  cls_loss: 0.0114  \n",
      "<<<iteration:[520/657] - total_loss: 0.2681  obj_loss: 0.1439  noobj_loss: 0.1871  bbox_loss: 0.0047  cls_loss: 0.0071  \n",
      "<<<iteration:[540/657] - total_loss: 0.2992  obj_loss: 0.1766  noobj_loss: 0.1827  bbox_loss: 0.0047  cls_loss: 0.0078  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<<<iteration:[560/657] - total_loss: 0.2933  obj_loss: 0.1657  noobj_loss: 0.1854  bbox_loss: 0.0049  cls_loss: 0.0103  \n",
      "<<<iteration:[580/657] - total_loss: 0.2823  obj_loss: 0.1553  noobj_loss: 0.1838  bbox_loss: 0.0052  cls_loss: 0.0093  \n",
      "<<<iteration:[600/657] - total_loss: 0.2913  obj_loss: 0.1741  noobj_loss: 0.1772  bbox_loss: 0.0044  cls_loss: 0.0069  \n",
      "<<<iteration:[620/657] - total_loss: 0.2919  obj_loss: 0.1662  noobj_loss: 0.1865  bbox_loss: 0.0053  cls_loss: 0.0060  \n",
      "<<<iteration:[640/657] - total_loss: 0.2734  obj_loss: 0.1519  noobj_loss: 0.1791  bbox_loss: 0.0051  cls_loss: 0.0064  \n",
      "\n",
      "epoch:86/100 - Train Loss: 0.2879, Val Loss: 0.3070\n",
      "\n",
      "<<<iteration:[20/657] - total_loss: 0.2896  obj_loss: 0.1636  noobj_loss: 0.1893  bbox_loss: 0.0050  cls_loss: 0.0063  \n",
      "<<<iteration:[40/657] - total_loss: 0.2775  obj_loss: 0.1524  noobj_loss: 0.1857  bbox_loss: 0.0052  cls_loss: 0.0062  \n",
      "<<<iteration:[60/657] - total_loss: 0.2750  obj_loss: 0.1538  noobj_loss: 0.1814  bbox_loss: 0.0049  cls_loss: 0.0062  \n",
      "<<<iteration:[80/657] - total_loss: 0.2964  obj_loss: 0.1666  noobj_loss: 0.1891  bbox_loss: 0.0050  cls_loss: 0.0101  \n",
      "<<<iteration:[100/657] - total_loss: 0.2841  obj_loss: 0.1582  noobj_loss: 0.1923  bbox_loss: 0.0045  cls_loss: 0.0071  \n",
      "<<<iteration:[120/657] - total_loss: 0.3005  obj_loss: 0.1689  noobj_loss: 0.1891  bbox_loss: 0.0051  cls_loss: 0.0116  \n",
      "<<<iteration:[140/657] - total_loss: 0.2890  obj_loss: 0.1656  noobj_loss: 0.1910  bbox_loss: 0.0043  cls_loss: 0.0062  \n",
      "<<<iteration:[160/657] - total_loss: 0.2872  obj_loss: 0.1612  noobj_loss: 0.1821  bbox_loss: 0.0049  cls_loss: 0.0104  \n",
      "<<<iteration:[180/657] - total_loss: 0.2968  obj_loss: 0.1742  noobj_loss: 0.1830  bbox_loss: 0.0043  cls_loss: 0.0098  \n",
      "<<<iteration:[200/657] - total_loss: 0.2937  obj_loss: 0.1688  noobj_loss: 0.1880  bbox_loss: 0.0048  cls_loss: 0.0069  \n",
      "<<<iteration:[220/657] - total_loss: 0.2843  obj_loss: 0.1629  noobj_loss: 0.1797  bbox_loss: 0.0052  cls_loss: 0.0056  \n",
      "<<<iteration:[240/657] - total_loss: 0.2935  obj_loss: 0.1694  noobj_loss: 0.1851  bbox_loss: 0.0050  cls_loss: 0.0066  \n",
      "<<<iteration:[260/657] - total_loss: 0.2993  obj_loss: 0.1746  noobj_loss: 0.1850  bbox_loss: 0.0050  cls_loss: 0.0074  \n",
      "<<<iteration:[280/657] - total_loss: 0.2748  obj_loss: 0.1514  noobj_loss: 0.1808  bbox_loss: 0.0053  cls_loss: 0.0065  \n",
      "<<<iteration:[300/657] - total_loss: 0.2811  obj_loss: 0.1548  noobj_loss: 0.1825  bbox_loss: 0.0044  cls_loss: 0.0132  \n",
      "<<<iteration:[320/657] - total_loss: 0.2853  obj_loss: 0.1617  noobj_loss: 0.1841  bbox_loss: 0.0048  cls_loss: 0.0077  \n",
      "<<<iteration:[340/657] - total_loss: 0.2809  obj_loss: 0.1525  noobj_loss: 0.1947  bbox_loss: 0.0049  cls_loss: 0.0066  \n",
      "<<<iteration:[360/657] - total_loss: 0.2793  obj_loss: 0.1557  noobj_loss: 0.1862  bbox_loss: 0.0048  cls_loss: 0.0067  \n",
      "<<<iteration:[380/657] - total_loss: 0.2900  obj_loss: 0.1645  noobj_loss: 0.1910  bbox_loss: 0.0047  cls_loss: 0.0067  \n",
      "<<<iteration:[400/657] - total_loss: 0.2842  obj_loss: 0.1599  noobj_loss: 0.1871  bbox_loss: 0.0049  cls_loss: 0.0060  \n",
      "<<<iteration:[420/657] - total_loss: 0.2951  obj_loss: 0.1727  noobj_loss: 0.1894  bbox_loss: 0.0044  cls_loss: 0.0058  \n",
      "<<<iteration:[440/657] - total_loss: 0.2839  obj_loss: 0.1643  noobj_loss: 0.1800  bbox_loss: 0.0046  cls_loss: 0.0067  \n",
      "<<<iteration:[460/657] - total_loss: 0.2859  obj_loss: 0.1619  noobj_loss: 0.1860  bbox_loss: 0.0049  cls_loss: 0.0063  \n",
      "<<<iteration:[480/657] - total_loss: 0.2793  obj_loss: 0.1608  noobj_loss: 0.1828  bbox_loss: 0.0043  cls_loss: 0.0058  \n",
      "<<<iteration:[500/657] - total_loss: 0.2910  obj_loss: 0.1659  noobj_loss: 0.1867  bbox_loss: 0.0048  cls_loss: 0.0078  \n",
      "<<<iteration:[520/657] - total_loss: 0.2913  obj_loss: 0.1650  noobj_loss: 0.1854  bbox_loss: 0.0049  cls_loss: 0.0092  \n",
      "<<<iteration:[540/657] - total_loss: 0.2852  obj_loss: 0.1629  noobj_loss: 0.1875  bbox_loss: 0.0046  cls_loss: 0.0053  \n",
      "<<<iteration:[560/657] - total_loss: 0.2849  obj_loss: 0.1613  noobj_loss: 0.1873  bbox_loss: 0.0044  cls_loss: 0.0078  \n",
      "<<<iteration:[580/657] - total_loss: 0.3065  obj_loss: 0.1812  noobj_loss: 0.1899  bbox_loss: 0.0046  cls_loss: 0.0075  \n",
      "<<<iteration:[600/657] - total_loss: 0.2910  obj_loss: 0.1654  noobj_loss: 0.1919  bbox_loss: 0.0046  cls_loss: 0.0066  \n",
      "<<<iteration:[620/657] - total_loss: 0.3004  obj_loss: 0.1744  noobj_loss: 0.1891  bbox_loss: 0.0046  cls_loss: 0.0086  \n",
      "<<<iteration:[640/657] - total_loss: 0.2777  obj_loss: 0.1554  noobj_loss: 0.1815  bbox_loss: 0.0048  cls_loss: 0.0078  \n",
      "\n",
      "epoch:87/100 - Train Loss: 0.2876, Val Loss: 0.3035\n",
      "\n",
      "<<<iteration:[20/657] - total_loss: 0.3146  obj_loss: 0.1803  noobj_loss: 0.1954  bbox_loss: 0.0053  cls_loss: 0.0100  \n",
      "<<<iteration:[40/657] - total_loss: 0.2741  obj_loss: 0.1504  noobj_loss: 0.1897  bbox_loss: 0.0045  cls_loss: 0.0063  \n",
      "<<<iteration:[60/657] - total_loss: 0.2960  obj_loss: 0.1700  noobj_loss: 0.1862  bbox_loss: 0.0048  cls_loss: 0.0092  \n",
      "<<<iteration:[80/657] - total_loss: 0.2831  obj_loss: 0.1609  noobj_loss: 0.1839  bbox_loss: 0.0047  cls_loss: 0.0069  \n",
      "<<<iteration:[100/657] - total_loss: 0.2880  obj_loss: 0.1682  noobj_loss: 0.1826  bbox_loss: 0.0045  cls_loss: 0.0057  \n",
      "<<<iteration:[120/657] - total_loss: 0.2986  obj_loss: 0.1706  noobj_loss: 0.1880  bbox_loss: 0.0051  cls_loss: 0.0085  \n",
      "<<<iteration:[140/657] - total_loss: 0.2824  obj_loss: 0.1573  noobj_loss: 0.1800  bbox_loss: 0.0052  cls_loss: 0.0092  \n",
      "<<<iteration:[160/657] - total_loss: 0.2914  obj_loss: 0.1647  noobj_loss: 0.1848  bbox_loss: 0.0049  cls_loss: 0.0101  \n",
      "<<<iteration:[180/657] - total_loss: 0.2881  obj_loss: 0.1615  noobj_loss: 0.1878  bbox_loss: 0.0050  cls_loss: 0.0078  \n",
      "<<<iteration:[200/657] - total_loss: 0.2865  obj_loss: 0.1630  noobj_loss: 0.1891  bbox_loss: 0.0046  cls_loss: 0.0060  \n",
      "<<<iteration:[220/657] - total_loss: 0.3033  obj_loss: 0.1800  noobj_loss: 0.1864  bbox_loss: 0.0046  cls_loss: 0.0068  \n",
      "<<<iteration:[240/657] - total_loss: 0.2873  obj_loss: 0.1678  noobj_loss: 0.1810  bbox_loss: 0.0046  cls_loss: 0.0057  \n",
      "<<<iteration:[260/657] - total_loss: 0.2888  obj_loss: 0.1661  noobj_loss: 0.1839  bbox_loss: 0.0047  cls_loss: 0.0074  \n",
      "<<<iteration:[280/657] - total_loss: 0.2920  obj_loss: 0.1704  noobj_loss: 0.1884  bbox_loss: 0.0041  cls_loss: 0.0068  \n",
      "<<<iteration:[300/657] - total_loss: 0.2853  obj_loss: 0.1609  noobj_loss: 0.1827  bbox_loss: 0.0050  cls_loss: 0.0082  \n",
      "<<<iteration:[320/657] - total_loss: 0.2960  obj_loss: 0.1754  noobj_loss: 0.1825  bbox_loss: 0.0044  cls_loss: 0.0076  \n",
      "<<<iteration:[340/657] - total_loss: 0.2892  obj_loss: 0.1617  noobj_loss: 0.1911  bbox_loss: 0.0050  cls_loss: 0.0070  \n",
      "<<<iteration:[360/657] - total_loss: 0.2922  obj_loss: 0.1690  noobj_loss: 0.1904  bbox_loss: 0.0044  cls_loss: 0.0061  \n",
      "<<<iteration:[380/657] - total_loss: 0.2819  obj_loss: 0.1560  noobj_loss: 0.1882  bbox_loss: 0.0047  cls_loss: 0.0081  \n",
      "<<<iteration:[400/657] - total_loss: 0.2958  obj_loss: 0.1696  noobj_loss: 0.1920  bbox_loss: 0.0046  cls_loss: 0.0072  \n",
      "<<<iteration:[420/657] - total_loss: 0.2864  obj_loss: 0.1607  noobj_loss: 0.1908  bbox_loss: 0.0048  cls_loss: 0.0061  \n",
      "<<<iteration:[440/657] - total_loss: 0.2856  obj_loss: 0.1587  noobj_loss: 0.1854  bbox_loss: 0.0053  cls_loss: 0.0075  \n",
      "<<<iteration:[460/657] - total_loss: 0.2933  obj_loss: 0.1687  noobj_loss: 0.1881  bbox_loss: 0.0046  cls_loss: 0.0074  \n",
      "<<<iteration:[480/657] - total_loss: 0.2840  obj_loss: 0.1518  noobj_loss: 0.1932  bbox_loss: 0.0051  cls_loss: 0.0098  \n",
      "<<<iteration:[500/657] - total_loss: 0.2910  obj_loss: 0.1676  noobj_loss: 0.1880  bbox_loss: 0.0044  cls_loss: 0.0071  \n",
      "<<<iteration:[520/657] - total_loss: 0.2776  obj_loss: 0.1579  noobj_loss: 0.1881  bbox_loss: 0.0040  cls_loss: 0.0058  \n",
      "<<<iteration:[540/657] - total_loss: 0.2864  obj_loss: 0.1592  noobj_loss: 0.1795  bbox_loss: 0.0050  cls_loss: 0.0124  \n",
      "<<<iteration:[560/657] - total_loss: 0.2828  obj_loss: 0.1600  noobj_loss: 0.1833  bbox_loss: 0.0047  cls_loss: 0.0079  \n",
      "<<<iteration:[580/657] - total_loss: 0.2891  obj_loss: 0.1600  noobj_loss: 0.1872  bbox_loss: 0.0054  cls_loss: 0.0084  \n",
      "<<<iteration:[600/657] - total_loss: 0.2873  obj_loss: 0.1618  noobj_loss: 0.1926  bbox_loss: 0.0043  cls_loss: 0.0077  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<<<iteration:[620/657] - total_loss: 0.3043  obj_loss: 0.1814  noobj_loss: 0.1910  bbox_loss: 0.0041  cls_loss: 0.0066  \n",
      "<<<iteration:[640/657] - total_loss: 0.2892  obj_loss: 0.1673  noobj_loss: 0.1906  bbox_loss: 0.0042  cls_loss: 0.0056  \n",
      "\n",
      "epoch:88/100 - Train Loss: 0.2890, Val Loss: 0.3056\n",
      "\n",
      "<<<iteration:[20/657] - total_loss: 0.3086  obj_loss: 0.1731  noobj_loss: 0.1980  bbox_loss: 0.0052  cls_loss: 0.0105  \n",
      "<<<iteration:[40/657] - total_loss: 0.2856  obj_loss: 0.1610  noobj_loss: 0.1885  bbox_loss: 0.0047  cls_loss: 0.0067  \n",
      "<<<iteration:[60/657] - total_loss: 0.2856  obj_loss: 0.1625  noobj_loss: 0.1923  bbox_loss: 0.0043  cls_loss: 0.0056  \n",
      "<<<iteration:[80/657] - total_loss: 0.2834  obj_loss: 0.1612  noobj_loss: 0.1873  bbox_loss: 0.0046  cls_loss: 0.0055  \n",
      "<<<iteration:[100/657] - total_loss: 0.2836  obj_loss: 0.1549  noobj_loss: 0.1848  bbox_loss: 0.0052  cls_loss: 0.0102  \n",
      "<<<iteration:[120/657] - total_loss: 0.2894  obj_loss: 0.1668  noobj_loss: 0.1914  bbox_loss: 0.0043  cls_loss: 0.0052  \n",
      "<<<iteration:[140/657] - total_loss: 0.2895  obj_loss: 0.1698  noobj_loss: 0.1789  bbox_loss: 0.0047  cls_loss: 0.0068  \n",
      "<<<iteration:[160/657] - total_loss: 0.2857  obj_loss: 0.1593  noobj_loss: 0.1902  bbox_loss: 0.0049  cls_loss: 0.0068  \n",
      "<<<iteration:[180/657] - total_loss: 0.2887  obj_loss: 0.1634  noobj_loss: 0.1859  bbox_loss: 0.0050  cls_loss: 0.0075  \n",
      "<<<iteration:[200/657] - total_loss: 0.2788  obj_loss: 0.1542  noobj_loss: 0.1826  bbox_loss: 0.0051  cls_loss: 0.0077  \n",
      "<<<iteration:[220/657] - total_loss: 0.2907  obj_loss: 0.1714  noobj_loss: 0.1783  bbox_loss: 0.0045  cls_loss: 0.0077  \n",
      "<<<iteration:[240/657] - total_loss: 0.2857  obj_loss: 0.1610  noobj_loss: 0.1880  bbox_loss: 0.0049  cls_loss: 0.0064  \n",
      "<<<iteration:[260/657] - total_loss: 0.2981  obj_loss: 0.1723  noobj_loss: 0.1820  bbox_loss: 0.0047  cls_loss: 0.0113  \n",
      "<<<iteration:[280/657] - total_loss: 0.2855  obj_loss: 0.1654  noobj_loss: 0.1768  bbox_loss: 0.0047  cls_loss: 0.0084  \n",
      "<<<iteration:[300/657] - total_loss: 0.2974  obj_loss: 0.1705  noobj_loss: 0.1833  bbox_loss: 0.0052  cls_loss: 0.0090  \n",
      "<<<iteration:[320/657] - total_loss: 0.2958  obj_loss: 0.1701  noobj_loss: 0.1851  bbox_loss: 0.0044  cls_loss: 0.0111  \n",
      "<<<iteration:[340/657] - total_loss: 0.2900  obj_loss: 0.1661  noobj_loss: 0.1945  bbox_loss: 0.0041  cls_loss: 0.0063  \n",
      "<<<iteration:[360/657] - total_loss: 0.2902  obj_loss: 0.1589  noobj_loss: 0.1992  bbox_loss: 0.0048  cls_loss: 0.0076  \n",
      "<<<iteration:[380/657] - total_loss: 0.2842  obj_loss: 0.1577  noobj_loss: 0.1885  bbox_loss: 0.0048  cls_loss: 0.0083  \n",
      "<<<iteration:[400/657] - total_loss: 0.2917  obj_loss: 0.1689  noobj_loss: 0.1839  bbox_loss: 0.0047  cls_loss: 0.0074  \n",
      "<<<iteration:[420/657] - total_loss: 0.2924  obj_loss: 0.1661  noobj_loss: 0.1970  bbox_loss: 0.0041  cls_loss: 0.0074  \n",
      "<<<iteration:[440/657] - total_loss: 0.2909  obj_loss: 0.1647  noobj_loss: 0.1884  bbox_loss: 0.0050  cls_loss: 0.0068  \n",
      "<<<iteration:[460/657] - total_loss: 0.2964  obj_loss: 0.1702  noobj_loss: 0.1901  bbox_loss: 0.0050  cls_loss: 0.0063  \n",
      "<<<iteration:[480/657] - total_loss: 0.2859  obj_loss: 0.1598  noobj_loss: 0.1943  bbox_loss: 0.0047  cls_loss: 0.0055  \n",
      "<<<iteration:[500/657] - total_loss: 0.2903  obj_loss: 0.1691  noobj_loss: 0.1837  bbox_loss: 0.0045  cls_loss: 0.0066  \n",
      "<<<iteration:[520/657] - total_loss: 0.2832  obj_loss: 0.1595  noobj_loss: 0.1871  bbox_loss: 0.0048  cls_loss: 0.0063  \n",
      "<<<iteration:[540/657] - total_loss: 0.2828  obj_loss: 0.1594  noobj_loss: 0.1853  bbox_loss: 0.0045  cls_loss: 0.0082  \n",
      "<<<iteration:[560/657] - total_loss: 0.2856  obj_loss: 0.1629  noobj_loss: 0.1855  bbox_loss: 0.0047  cls_loss: 0.0063  \n",
      "<<<iteration:[580/657] - total_loss: 0.2910  obj_loss: 0.1711  noobj_loss: 0.1827  bbox_loss: 0.0044  cls_loss: 0.0064  \n",
      "<<<iteration:[600/657] - total_loss: 0.2928  obj_loss: 0.1714  noobj_loss: 0.1872  bbox_loss: 0.0041  cls_loss: 0.0071  \n",
      "<<<iteration:[620/657] - total_loss: 0.2891  obj_loss: 0.1630  noobj_loss: 0.1908  bbox_loss: 0.0046  cls_loss: 0.0077  \n",
      "<<<iteration:[640/657] - total_loss: 0.2799  obj_loss: 0.1533  noobj_loss: 0.1855  bbox_loss: 0.0051  cls_loss: 0.0083  \n",
      "\n",
      "epoch:89/100 - Train Loss: 0.2886, Val Loss: 0.2980\n",
      "\n",
      "<<<iteration:[20/657] - total_loss: 0.3086  obj_loss: 0.1750  noobj_loss: 0.2029  bbox_loss: 0.0049  cls_loss: 0.0075  \n",
      "<<<iteration:[40/657] - total_loss: 0.3060  obj_loss: 0.1739  noobj_loss: 0.1939  bbox_loss: 0.0049  cls_loss: 0.0106  \n",
      "<<<iteration:[60/657] - total_loss: 0.2815  obj_loss: 0.1605  noobj_loss: 0.1867  bbox_loss: 0.0043  cls_loss: 0.0059  \n",
      "<<<iteration:[80/657] - total_loss: 0.2951  obj_loss: 0.1718  noobj_loss: 0.1883  bbox_loss: 0.0046  cls_loss: 0.0059  \n",
      "<<<iteration:[100/657] - total_loss: 0.2983  obj_loss: 0.1726  noobj_loss: 0.1906  bbox_loss: 0.0048  cls_loss: 0.0063  \n",
      "<<<iteration:[120/657] - total_loss: 0.2815  obj_loss: 0.1521  noobj_loss: 0.1993  bbox_loss: 0.0044  cls_loss: 0.0076  \n",
      "<<<iteration:[140/657] - total_loss: 0.2995  obj_loss: 0.1701  noobj_loss: 0.1899  bbox_loss: 0.0051  cls_loss: 0.0087  \n",
      "<<<iteration:[160/657] - total_loss: 0.2783  obj_loss: 0.1543  noobj_loss: 0.1820  bbox_loss: 0.0050  cls_loss: 0.0083  \n",
      "<<<iteration:[180/657] - total_loss: 0.2889  obj_loss: 0.1686  noobj_loss: 0.1794  bbox_loss: 0.0045  cls_loss: 0.0082  \n",
      "<<<iteration:[200/657] - total_loss: 0.2989  obj_loss: 0.1739  noobj_loss: 0.1898  bbox_loss: 0.0045  cls_loss: 0.0074  \n",
      "<<<iteration:[220/657] - total_loss: 0.2857  obj_loss: 0.1623  noobj_loss: 0.1903  bbox_loss: 0.0044  cls_loss: 0.0061  \n",
      "<<<iteration:[240/657] - total_loss: 0.2868  obj_loss: 0.1635  noobj_loss: 0.1843  bbox_loss: 0.0048  cls_loss: 0.0073  \n",
      "<<<iteration:[260/657] - total_loss: 0.2962  obj_loss: 0.1714  noobj_loss: 0.1881  bbox_loss: 0.0043  cls_loss: 0.0091  \n",
      "<<<iteration:[280/657] - total_loss: 0.2820  obj_loss: 0.1617  noobj_loss: 0.1851  bbox_loss: 0.0045  cls_loss: 0.0054  \n",
      "<<<iteration:[300/657] - total_loss: 0.2823  obj_loss: 0.1604  noobj_loss: 0.1841  bbox_loss: 0.0045  cls_loss: 0.0071  \n",
      "<<<iteration:[320/657] - total_loss: 0.2737  obj_loss: 0.1514  noobj_loss: 0.1871  bbox_loss: 0.0043  cls_loss: 0.0074  \n",
      "<<<iteration:[340/657] - total_loss: 0.2952  obj_loss: 0.1720  noobj_loss: 0.1894  bbox_loss: 0.0043  cls_loss: 0.0069  \n",
      "<<<iteration:[360/657] - total_loss: 0.2695  obj_loss: 0.1495  noobj_loss: 0.1832  bbox_loss: 0.0046  cls_loss: 0.0053  \n",
      "<<<iteration:[380/657] - total_loss: 0.2917  obj_loss: 0.1676  noobj_loss: 0.1915  bbox_loss: 0.0041  cls_loss: 0.0077  \n",
      "<<<iteration:[400/657] - total_loss: 0.2925  obj_loss: 0.1646  noobj_loss: 0.1886  bbox_loss: 0.0047  cls_loss: 0.0102  \n",
      "<<<iteration:[420/657] - total_loss: 0.2884  obj_loss: 0.1598  noobj_loss: 0.1887  bbox_loss: 0.0043  cls_loss: 0.0129  \n",
      "<<<iteration:[440/657] - total_loss: 0.3004  obj_loss: 0.1779  noobj_loss: 0.1868  bbox_loss: 0.0045  cls_loss: 0.0065  \n",
      "<<<iteration:[460/657] - total_loss: 0.2837  obj_loss: 0.1559  noobj_loss: 0.1960  bbox_loss: 0.0047  cls_loss: 0.0062  \n",
      "<<<iteration:[480/657] - total_loss: 0.3072  obj_loss: 0.1777  noobj_loss: 0.1956  bbox_loss: 0.0050  cls_loss: 0.0069  \n",
      "<<<iteration:[500/657] - total_loss: 0.2793  obj_loss: 0.1523  noobj_loss: 0.1876  bbox_loss: 0.0053  cls_loss: 0.0067  \n",
      "<<<iteration:[520/657] - total_loss: 0.2992  obj_loss: 0.1715  noobj_loss: 0.1883  bbox_loss: 0.0053  cls_loss: 0.0069  \n",
      "<<<iteration:[540/657] - total_loss: 0.2848  obj_loss: 0.1585  noobj_loss: 0.1954  bbox_loss: 0.0042  cls_loss: 0.0074  \n",
      "<<<iteration:[560/657] - total_loss: 0.2822  obj_loss: 0.1581  noobj_loss: 0.1913  bbox_loss: 0.0044  cls_loss: 0.0064  \n",
      "<<<iteration:[580/657] - total_loss: 0.2941  obj_loss: 0.1692  noobj_loss: 0.1891  bbox_loss: 0.0043  cls_loss: 0.0091  \n",
      "<<<iteration:[600/657] - total_loss: 0.2902  obj_loss: 0.1576  noobj_loss: 0.1955  bbox_loss: 0.0050  cls_loss: 0.0101  \n",
      "<<<iteration:[620/657] - total_loss: 0.2788  obj_loss: 0.1581  noobj_loss: 0.1848  bbox_loss: 0.0043  cls_loss: 0.0065  \n",
      "<<<iteration:[640/657] - total_loss: 0.2845  obj_loss: 0.1674  noobj_loss: 0.1789  bbox_loss: 0.0043  cls_loss: 0.0063  \n",
      "\n",
      "epoch:90/100 - Train Loss: 0.2893, Val Loss: 0.3040\n",
      "\n",
      "<<<iteration:[20/657] - total_loss: 0.3061  obj_loss: 0.1779  noobj_loss: 0.1978  bbox_loss: 0.0044  cls_loss: 0.0071  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<<<iteration:[40/657] - total_loss: 0.2902  obj_loss: 0.1653  noobj_loss: 0.1828  bbox_loss: 0.0051  cls_loss: 0.0078  \n",
      "<<<iteration:[60/657] - total_loss: 0.2697  obj_loss: 0.1464  noobj_loss: 0.1879  bbox_loss: 0.0044  cls_loss: 0.0073  \n",
      "<<<iteration:[80/657] - total_loss: 0.2989  obj_loss: 0.1742  noobj_loss: 0.1893  bbox_loss: 0.0044  cls_loss: 0.0081  \n",
      "<<<iteration:[100/657] - total_loss: 0.2963  obj_loss: 0.1712  noobj_loss: 0.1851  bbox_loss: 0.0049  cls_loss: 0.0078  \n",
      "<<<iteration:[120/657] - total_loss: 0.2839  obj_loss: 0.1653  noobj_loss: 0.1809  bbox_loss: 0.0045  cls_loss: 0.0056  \n",
      "<<<iteration:[140/657] - total_loss: 0.2918  obj_loss: 0.1699  noobj_loss: 0.1873  bbox_loss: 0.0043  cls_loss: 0.0067  \n",
      "<<<iteration:[160/657] - total_loss: 0.2852  obj_loss: 0.1611  noobj_loss: 0.1867  bbox_loss: 0.0050  cls_loss: 0.0058  \n",
      "<<<iteration:[180/657] - total_loss: 0.2946  obj_loss: 0.1699  noobj_loss: 0.1897  bbox_loss: 0.0043  cls_loss: 0.0084  \n",
      "<<<iteration:[200/657] - total_loss: 0.2704  obj_loss: 0.1470  noobj_loss: 0.1872  bbox_loss: 0.0046  cls_loss: 0.0070  \n",
      "<<<iteration:[220/657] - total_loss: 0.2772  obj_loss: 0.1540  noobj_loss: 0.1948  bbox_loss: 0.0041  cls_loss: 0.0053  \n",
      "<<<iteration:[240/657] - total_loss: 0.2885  obj_loss: 0.1621  noobj_loss: 0.1938  bbox_loss: 0.0044  cls_loss: 0.0074  \n",
      "<<<iteration:[260/657] - total_loss: 0.2869  obj_loss: 0.1634  noobj_loss: 0.1883  bbox_loss: 0.0046  cls_loss: 0.0062  \n",
      "<<<iteration:[280/657] - total_loss: 0.2816  obj_loss: 0.1616  noobj_loss: 0.1839  bbox_loss: 0.0044  cls_loss: 0.0063  \n",
      "<<<iteration:[300/657] - total_loss: 0.2779  obj_loss: 0.1568  noobj_loss: 0.1826  bbox_loss: 0.0045  cls_loss: 0.0075  \n",
      "<<<iteration:[320/657] - total_loss: 0.2952  obj_loss: 0.1706  noobj_loss: 0.1885  bbox_loss: 0.0045  cls_loss: 0.0080  \n",
      "<<<iteration:[340/657] - total_loss: 0.2963  obj_loss: 0.1731  noobj_loss: 0.1870  bbox_loss: 0.0043  cls_loss: 0.0081  \n",
      "<<<iteration:[360/657] - total_loss: 0.3080  obj_loss: 0.1785  noobj_loss: 0.1943  bbox_loss: 0.0048  cls_loss: 0.0085  \n",
      "<<<iteration:[380/657] - total_loss: 0.2824  obj_loss: 0.1585  noobj_loss: 0.1885  bbox_loss: 0.0045  cls_loss: 0.0073  \n",
      "<<<iteration:[400/657] - total_loss: 0.2953  obj_loss: 0.1705  noobj_loss: 0.1882  bbox_loss: 0.0048  cls_loss: 0.0067  \n",
      "<<<iteration:[420/657] - total_loss: 0.2823  obj_loss: 0.1509  noobj_loss: 0.1979  bbox_loss: 0.0052  cls_loss: 0.0067  \n",
      "<<<iteration:[440/657] - total_loss: 0.2850  obj_loss: 0.1650  noobj_loss: 0.1798  bbox_loss: 0.0047  cls_loss: 0.0068  \n",
      "<<<iteration:[460/657] - total_loss: 0.2798  obj_loss: 0.1516  noobj_loss: 0.1868  bbox_loss: 0.0052  cls_loss: 0.0088  \n",
      "<<<iteration:[480/657] - total_loss: 0.2742  obj_loss: 0.1525  noobj_loss: 0.1897  bbox_loss: 0.0042  cls_loss: 0.0058  \n",
      "<<<iteration:[500/657] - total_loss: 0.2892  obj_loss: 0.1649  noobj_loss: 0.1854  bbox_loss: 0.0050  cls_loss: 0.0068  \n",
      "<<<iteration:[520/657] - total_loss: 0.3045  obj_loss: 0.1760  noobj_loss: 0.1917  bbox_loss: 0.0045  cls_loss: 0.0099  \n",
      "<<<iteration:[540/657] - total_loss: 0.2877  obj_loss: 0.1620  noobj_loss: 0.1876  bbox_loss: 0.0049  cls_loss: 0.0076  \n",
      "<<<iteration:[560/657] - total_loss: 0.2907  obj_loss: 0.1656  noobj_loss: 0.1901  bbox_loss: 0.0044  cls_loss: 0.0080  \n",
      "<<<iteration:[580/657] - total_loss: 0.2827  obj_loss: 0.1613  noobj_loss: 0.1860  bbox_loss: 0.0045  cls_loss: 0.0060  \n",
      "<<<iteration:[600/657] - total_loss: 0.3046  obj_loss: 0.1747  noobj_loss: 0.1910  bbox_loss: 0.0046  cls_loss: 0.0113  \n",
      "<<<iteration:[620/657] - total_loss: 0.2942  obj_loss: 0.1670  noobj_loss: 0.1946  bbox_loss: 0.0045  cls_loss: 0.0076  \n",
      "<<<iteration:[640/657] - total_loss: 0.2815  obj_loss: 0.1591  noobj_loss: 0.1854  bbox_loss: 0.0045  cls_loss: 0.0072  \n",
      "\n",
      "epoch:91/100 - Train Loss: 0.2882, Val Loss: 0.3031\n",
      "\n",
      "<<<iteration:[20/657] - total_loss: 0.3045  obj_loss: 0.1781  noobj_loss: 0.1951  bbox_loss: 0.0047  cls_loss: 0.0052  \n",
      "<<<iteration:[40/657] - total_loss: 0.2833  obj_loss: 0.1580  noobj_loss: 0.1897  bbox_loss: 0.0043  cls_loss: 0.0088  \n",
      "<<<iteration:[60/657] - total_loss: 0.2810  obj_loss: 0.1612  noobj_loss: 0.1891  bbox_loss: 0.0039  cls_loss: 0.0060  \n",
      "<<<iteration:[80/657] - total_loss: 0.2901  obj_loss: 0.1628  noobj_loss: 0.1912  bbox_loss: 0.0042  cls_loss: 0.0106  \n",
      "<<<iteration:[100/657] - total_loss: 0.2770  obj_loss: 0.1513  noobj_loss: 0.1867  bbox_loss: 0.0048  cls_loss: 0.0084  \n",
      "<<<iteration:[120/657] - total_loss: 0.2861  obj_loss: 0.1625  noobj_loss: 0.1926  bbox_loss: 0.0043  cls_loss: 0.0060  \n",
      "<<<iteration:[140/657] - total_loss: 0.2798  obj_loss: 0.1572  noobj_loss: 0.1849  bbox_loss: 0.0046  cls_loss: 0.0072  \n",
      "<<<iteration:[160/657] - total_loss: 0.2885  obj_loss: 0.1625  noobj_loss: 0.1947  bbox_loss: 0.0046  cls_loss: 0.0057  \n",
      "<<<iteration:[180/657] - total_loss: 0.2899  obj_loss: 0.1687  noobj_loss: 0.1821  bbox_loss: 0.0046  cls_loss: 0.0074  \n",
      "<<<iteration:[200/657] - total_loss: 0.2883  obj_loss: 0.1690  noobj_loss: 0.1807  bbox_loss: 0.0046  cls_loss: 0.0062  \n",
      "<<<iteration:[220/657] - total_loss: 0.2935  obj_loss: 0.1711  noobj_loss: 0.1901  bbox_loss: 0.0044  cls_loss: 0.0051  \n",
      "<<<iteration:[240/657] - total_loss: 0.2854  obj_loss: 0.1631  noobj_loss: 0.1876  bbox_loss: 0.0042  cls_loss: 0.0074  \n",
      "<<<iteration:[260/657] - total_loss: 0.2872  obj_loss: 0.1638  noobj_loss: 0.1871  bbox_loss: 0.0044  cls_loss: 0.0078  \n",
      "<<<iteration:[280/657] - total_loss: 0.2905  obj_loss: 0.1744  noobj_loss: 0.1777  bbox_loss: 0.0043  cls_loss: 0.0055  \n",
      "<<<iteration:[300/657] - total_loss: 0.2899  obj_loss: 0.1672  noobj_loss: 0.1877  bbox_loss: 0.0047  cls_loss: 0.0055  \n",
      "<<<iteration:[320/657] - total_loss: 0.3010  obj_loss: 0.1767  noobj_loss: 0.1894  bbox_loss: 0.0044  cls_loss: 0.0073  \n",
      "<<<iteration:[340/657] - total_loss: 0.2808  obj_loss: 0.1589  noobj_loss: 0.1873  bbox_loss: 0.0046  cls_loss: 0.0052  \n",
      "<<<iteration:[360/657] - total_loss: 0.2916  obj_loss: 0.1587  noobj_loss: 0.1938  bbox_loss: 0.0051  cls_loss: 0.0105  \n",
      "<<<iteration:[380/657] - total_loss: 0.2961  obj_loss: 0.1716  noobj_loss: 0.1865  bbox_loss: 0.0046  cls_loss: 0.0084  \n",
      "<<<iteration:[400/657] - total_loss: 0.2902  obj_loss: 0.1604  noobj_loss: 0.1909  bbox_loss: 0.0051  cls_loss: 0.0089  \n",
      "<<<iteration:[420/657] - total_loss: 0.3002  obj_loss: 0.1714  noobj_loss: 0.1935  bbox_loss: 0.0048  cls_loss: 0.0080  \n",
      "<<<iteration:[440/657] - total_loss: 0.2791  obj_loss: 0.1587  noobj_loss: 0.1884  bbox_loss: 0.0041  cls_loss: 0.0058  \n",
      "<<<iteration:[460/657] - total_loss: 0.2853  obj_loss: 0.1559  noobj_loss: 0.1969  bbox_loss: 0.0047  cls_loss: 0.0076  \n",
      "<<<iteration:[480/657] - total_loss: 0.2934  obj_loss: 0.1666  noobj_loss: 0.1889  bbox_loss: 0.0047  cls_loss: 0.0088  \n",
      "<<<iteration:[500/657] - total_loss: 0.2877  obj_loss: 0.1620  noobj_loss: 0.1893  bbox_loss: 0.0047  cls_loss: 0.0076  \n",
      "<<<iteration:[520/657] - total_loss: 0.2829  obj_loss: 0.1585  noobj_loss: 0.1920  bbox_loss: 0.0046  cls_loss: 0.0053  \n",
      "<<<iteration:[540/657] - total_loss: 0.2822  obj_loss: 0.1615  noobj_loss: 0.1823  bbox_loss: 0.0048  cls_loss: 0.0056  \n",
      "<<<iteration:[560/657] - total_loss: 0.2812  obj_loss: 0.1618  noobj_loss: 0.1828  bbox_loss: 0.0045  cls_loss: 0.0056  \n",
      "<<<iteration:[580/657] - total_loss: 0.2995  obj_loss: 0.1674  noobj_loss: 0.1899  bbox_loss: 0.0051  cls_loss: 0.0115  \n",
      "<<<iteration:[600/657] - total_loss: 0.2891  obj_loss: 0.1617  noobj_loss: 0.1939  bbox_loss: 0.0047  cls_loss: 0.0069  \n",
      "<<<iteration:[620/657] - total_loss: 0.2939  obj_loss: 0.1685  noobj_loss: 0.1907  bbox_loss: 0.0041  cls_loss: 0.0097  \n",
      "<<<iteration:[640/657] - total_loss: 0.2960  obj_loss: 0.1739  noobj_loss: 0.1880  bbox_loss: 0.0044  cls_loss: 0.0061  \n",
      "\n",
      "epoch:92/100 - Train Loss: 0.2883, Val Loss: 0.3021\n",
      "\n",
      "<<<iteration:[20/657] - total_loss: 0.2938  obj_loss: 0.1630  noobj_loss: 0.1937  bbox_loss: 0.0052  cls_loss: 0.0081  \n",
      "<<<iteration:[40/657] - total_loss: 0.2965  obj_loss: 0.1735  noobj_loss: 0.1859  bbox_loss: 0.0046  cls_loss: 0.0070  \n",
      "<<<iteration:[60/657] - total_loss: 0.2703  obj_loss: 0.1502  noobj_loss: 0.1893  bbox_loss: 0.0039  cls_loss: 0.0061  \n",
      "<<<iteration:[80/657] - total_loss: 0.2798  obj_loss: 0.1577  noobj_loss: 0.1863  bbox_loss: 0.0044  cls_loss: 0.0071  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<<<iteration:[100/657] - total_loss: 0.2968  obj_loss: 0.1713  noobj_loss: 0.1934  bbox_loss: 0.0044  cls_loss: 0.0070  \n",
      "<<<iteration:[120/657] - total_loss: 0.2965  obj_loss: 0.1692  noobj_loss: 0.1935  bbox_loss: 0.0046  cls_loss: 0.0074  \n",
      "<<<iteration:[140/657] - total_loss: 0.2882  obj_loss: 0.1663  noobj_loss: 0.1881  bbox_loss: 0.0045  cls_loss: 0.0053  \n",
      "<<<iteration:[160/657] - total_loss: 0.2794  obj_loss: 0.1555  noobj_loss: 0.1912  bbox_loss: 0.0043  cls_loss: 0.0066  \n",
      "<<<iteration:[180/657] - total_loss: 0.2875  obj_loss: 0.1628  noobj_loss: 0.1893  bbox_loss: 0.0046  cls_loss: 0.0072  \n",
      "<<<iteration:[200/657] - total_loss: 0.2824  obj_loss: 0.1591  noobj_loss: 0.1827  bbox_loss: 0.0047  cls_loss: 0.0083  \n",
      "<<<iteration:[220/657] - total_loss: 0.2977  obj_loss: 0.1717  noobj_loss: 0.2019  bbox_loss: 0.0040  cls_loss: 0.0052  \n",
      "<<<iteration:[240/657] - total_loss: 0.2865  obj_loss: 0.1595  noobj_loss: 0.1920  bbox_loss: 0.0048  cls_loss: 0.0069  \n",
      "<<<iteration:[260/657] - total_loss: 0.2816  obj_loss: 0.1619  noobj_loss: 0.1854  bbox_loss: 0.0044  cls_loss: 0.0051  \n",
      "<<<iteration:[280/657] - total_loss: 0.2785  obj_loss: 0.1491  noobj_loss: 0.1887  bbox_loss: 0.0047  cls_loss: 0.0114  \n",
      "<<<iteration:[300/657] - total_loss: 0.2708  obj_loss: 0.1490  noobj_loss: 0.1859  bbox_loss: 0.0044  cls_loss: 0.0068  \n",
      "<<<iteration:[320/657] - total_loss: 0.2785  obj_loss: 0.1579  noobj_loss: 0.1863  bbox_loss: 0.0042  cls_loss: 0.0063  \n",
      "<<<iteration:[340/657] - total_loss: 0.2904  obj_loss: 0.1664  noobj_loss: 0.1928  bbox_loss: 0.0041  cls_loss: 0.0071  \n",
      "<<<iteration:[360/657] - total_loss: 0.2752  obj_loss: 0.1472  noobj_loss: 0.1990  bbox_loss: 0.0046  cls_loss: 0.0057  \n",
      "<<<iteration:[380/657] - total_loss: 0.3017  obj_loss: 0.1794  noobj_loss: 0.1833  bbox_loss: 0.0046  cls_loss: 0.0076  \n",
      "<<<iteration:[400/657] - total_loss: 0.2876  obj_loss: 0.1581  noobj_loss: 0.1948  bbox_loss: 0.0048  cls_loss: 0.0080  \n",
      "<<<iteration:[420/657] - total_loss: 0.2868  obj_loss: 0.1636  noobj_loss: 0.1892  bbox_loss: 0.0044  cls_loss: 0.0069  \n",
      "<<<iteration:[440/657] - total_loss: 0.2814  obj_loss: 0.1586  noobj_loss: 0.1874  bbox_loss: 0.0045  cls_loss: 0.0064  \n",
      "<<<iteration:[460/657] - total_loss: 0.2927  obj_loss: 0.1665  noobj_loss: 0.1894  bbox_loss: 0.0047  cls_loss: 0.0079  \n",
      "<<<iteration:[480/657] - total_loss: 0.2828  obj_loss: 0.1608  noobj_loss: 0.1856  bbox_loss: 0.0046  cls_loss: 0.0065  \n",
      "<<<iteration:[500/657] - total_loss: 0.2868  obj_loss: 0.1612  noobj_loss: 0.1905  bbox_loss: 0.0046  cls_loss: 0.0075  \n",
      "<<<iteration:[520/657] - total_loss: 0.2723  obj_loss: 0.1530  noobj_loss: 0.1812  bbox_loss: 0.0046  cls_loss: 0.0057  \n",
      "<<<iteration:[540/657] - total_loss: 0.2883  obj_loss: 0.1637  noobj_loss: 0.1787  bbox_loss: 0.0052  cls_loss: 0.0090  \n",
      "<<<iteration:[560/657] - total_loss: 0.2986  obj_loss: 0.1695  noobj_loss: 0.1926  bbox_loss: 0.0052  cls_loss: 0.0070  \n",
      "<<<iteration:[580/657] - total_loss: 0.2832  obj_loss: 0.1639  noobj_loss: 0.1856  bbox_loss: 0.0040  cls_loss: 0.0064  \n",
      "<<<iteration:[600/657] - total_loss: 0.2933  obj_loss: 0.1679  noobj_loss: 0.1909  bbox_loss: 0.0045  cls_loss: 0.0076  \n",
      "<<<iteration:[620/657] - total_loss: 0.2811  obj_loss: 0.1548  noobj_loss: 0.1900  bbox_loss: 0.0050  cls_loss: 0.0063  \n",
      "<<<iteration:[640/657] - total_loss: 0.2838  obj_loss: 0.1626  noobj_loss: 0.1816  bbox_loss: 0.0048  cls_loss: 0.0065  \n",
      "\n",
      "epoch:93/100 - Train Loss: 0.2854, Val Loss: 0.3028\n",
      "\n",
      "<<<iteration:[20/657] - total_loss: 0.2869  obj_loss: 0.1614  noobj_loss: 0.1883  bbox_loss: 0.0047  cls_loss: 0.0079  \n",
      "<<<iteration:[40/657] - total_loss: 0.2835  obj_loss: 0.1580  noobj_loss: 0.1948  bbox_loss: 0.0044  cls_loss: 0.0062  \n",
      "<<<iteration:[60/657] - total_loss: 0.2899  obj_loss: 0.1612  noobj_loss: 0.1927  bbox_loss: 0.0044  cls_loss: 0.0103  \n",
      "<<<iteration:[80/657] - total_loss: 0.2978  obj_loss: 0.1687  noobj_loss: 0.1969  bbox_loss: 0.0049  cls_loss: 0.0059  \n",
      "<<<iteration:[100/657] - total_loss: 0.2939  obj_loss: 0.1725  noobj_loss: 0.1837  bbox_loss: 0.0047  cls_loss: 0.0061  \n",
      "<<<iteration:[120/657] - total_loss: 0.2916  obj_loss: 0.1663  noobj_loss: 0.1879  bbox_loss: 0.0048  cls_loss: 0.0074  \n",
      "<<<iteration:[140/657] - total_loss: 0.2879  obj_loss: 0.1632  noobj_loss: 0.1849  bbox_loss: 0.0046  cls_loss: 0.0093  \n",
      "<<<iteration:[160/657] - total_loss: 0.2929  obj_loss: 0.1659  noobj_loss: 0.1853  bbox_loss: 0.0050  cls_loss: 0.0095  \n",
      "<<<iteration:[180/657] - total_loss: 0.2697  obj_loss: 0.1509  noobj_loss: 0.1849  bbox_loss: 0.0041  cls_loss: 0.0058  \n",
      "<<<iteration:[200/657] - total_loss: 0.2906  obj_loss: 0.1659  noobj_loss: 0.1892  bbox_loss: 0.0044  cls_loss: 0.0079  \n",
      "<<<iteration:[220/657] - total_loss: 0.2801  obj_loss: 0.1543  noobj_loss: 0.1900  bbox_loss: 0.0049  cls_loss: 0.0064  \n",
      "<<<iteration:[240/657] - total_loss: 0.2839  obj_loss: 0.1618  noobj_loss: 0.1856  bbox_loss: 0.0045  cls_loss: 0.0067  \n",
      "<<<iteration:[260/657] - total_loss: 0.2950  obj_loss: 0.1680  noobj_loss: 0.1870  bbox_loss: 0.0050  cls_loss: 0.0085  \n",
      "<<<iteration:[280/657] - total_loss: 0.2920  obj_loss: 0.1676  noobj_loss: 0.1868  bbox_loss: 0.0047  cls_loss: 0.0073  \n",
      "<<<iteration:[300/657] - total_loss: 0.2736  obj_loss: 0.1508  noobj_loss: 0.1865  bbox_loss: 0.0047  cls_loss: 0.0060  \n",
      "<<<iteration:[320/657] - total_loss: 0.2962  obj_loss: 0.1705  noobj_loss: 0.1902  bbox_loss: 0.0045  cls_loss: 0.0082  \n",
      "<<<iteration:[340/657] - total_loss: 0.2852  obj_loss: 0.1622  noobj_loss: 0.1930  bbox_loss: 0.0042  cls_loss: 0.0054  \n",
      "<<<iteration:[360/657] - total_loss: 0.2857  obj_loss: 0.1603  noobj_loss: 0.1879  bbox_loss: 0.0048  cls_loss: 0.0074  \n",
      "<<<iteration:[380/657] - total_loss: 0.2890  obj_loss: 0.1633  noobj_loss: 0.1882  bbox_loss: 0.0047  cls_loss: 0.0082  \n",
      "<<<iteration:[400/657] - total_loss: 0.2866  obj_loss: 0.1668  noobj_loss: 0.1737  bbox_loss: 0.0047  cls_loss: 0.0096  \n",
      "<<<iteration:[420/657] - total_loss: 0.2828  obj_loss: 0.1524  noobj_loss: 0.1898  bbox_loss: 0.0051  cls_loss: 0.0098  \n",
      "<<<iteration:[440/657] - total_loss: 0.2878  obj_loss: 0.1644  noobj_loss: 0.1911  bbox_loss: 0.0044  cls_loss: 0.0059  \n",
      "<<<iteration:[460/657] - total_loss: 0.3021  obj_loss: 0.1739  noobj_loss: 0.1967  bbox_loss: 0.0045  cls_loss: 0.0074  \n",
      "<<<iteration:[480/657] - total_loss: 0.2822  obj_loss: 0.1620  noobj_loss: 0.1832  bbox_loss: 0.0047  cls_loss: 0.0054  \n",
      "<<<iteration:[500/657] - total_loss: 0.2819  obj_loss: 0.1569  noobj_loss: 0.1874  bbox_loss: 0.0049  cls_loss: 0.0068  \n",
      "<<<iteration:[520/657] - total_loss: 0.2918  obj_loss: 0.1667  noobj_loss: 0.1963  bbox_loss: 0.0042  cls_loss: 0.0062  \n",
      "<<<iteration:[540/657] - total_loss: 0.2851  obj_loss: 0.1620  noobj_loss: 0.1935  bbox_loss: 0.0043  cls_loss: 0.0050  \n",
      "<<<iteration:[560/657] - total_loss: 0.2877  obj_loss: 0.1659  noobj_loss: 0.1877  bbox_loss: 0.0042  cls_loss: 0.0071  \n",
      "<<<iteration:[580/657] - total_loss: 0.2943  obj_loss: 0.1695  noobj_loss: 0.1909  bbox_loss: 0.0045  cls_loss: 0.0070  \n",
      "<<<iteration:[600/657] - total_loss: 0.2854  obj_loss: 0.1587  noobj_loss: 0.1910  bbox_loss: 0.0043  cls_loss: 0.0095  \n",
      "<<<iteration:[620/657] - total_loss: 0.2881  obj_loss: 0.1664  noobj_loss: 0.1920  bbox_loss: 0.0042  cls_loss: 0.0050  \n",
      "<<<iteration:[640/657] - total_loss: 0.2924  obj_loss: 0.1628  noobj_loss: 0.2009  bbox_loss: 0.0047  cls_loss: 0.0059  \n",
      "\n",
      "epoch:94/100 - Train Loss: 0.2873, Val Loss: 0.3070\n",
      "\n",
      "<<<iteration:[20/657] - total_loss: 0.2954  obj_loss: 0.1656  noobj_loss: 0.1994  bbox_loss: 0.0046  cls_loss: 0.0070  \n",
      "<<<iteration:[40/657] - total_loss: 0.2817  obj_loss: 0.1593  noobj_loss: 0.1934  bbox_loss: 0.0041  cls_loss: 0.0053  \n",
      "<<<iteration:[60/657] - total_loss: 0.2810  obj_loss: 0.1521  noobj_loss: 0.2001  bbox_loss: 0.0045  cls_loss: 0.0061  \n",
      "<<<iteration:[80/657] - total_loss: 0.2692  obj_loss: 0.1509  noobj_loss: 0.1801  bbox_loss: 0.0044  cls_loss: 0.0063  \n",
      "<<<iteration:[100/657] - total_loss: 0.2884  obj_loss: 0.1669  noobj_loss: 0.1892  bbox_loss: 0.0042  cls_loss: 0.0058  \n",
      "<<<iteration:[120/657] - total_loss: 0.2897  obj_loss: 0.1638  noobj_loss: 0.1931  bbox_loss: 0.0044  cls_loss: 0.0072  \n",
      "<<<iteration:[140/657] - total_loss: 0.2918  obj_loss: 0.1694  noobj_loss: 0.1900  bbox_loss: 0.0040  cls_loss: 0.0072  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<<<iteration:[160/657] - total_loss: 0.2920  obj_loss: 0.1597  noobj_loss: 0.2078  bbox_loss: 0.0043  cls_loss: 0.0067  \n",
      "<<<iteration:[180/657] - total_loss: 0.2923  obj_loss: 0.1622  noobj_loss: 0.1990  bbox_loss: 0.0045  cls_loss: 0.0079  \n",
      "<<<iteration:[200/657] - total_loss: 0.2793  obj_loss: 0.1573  noobj_loss: 0.1868  bbox_loss: 0.0044  cls_loss: 0.0066  \n",
      "<<<iteration:[220/657] - total_loss: 0.2899  obj_loss: 0.1647  noobj_loss: 0.1991  bbox_loss: 0.0042  cls_loss: 0.0046  \n",
      "<<<iteration:[240/657] - total_loss: 0.2816  obj_loss: 0.1577  noobj_loss: 0.1895  bbox_loss: 0.0046  cls_loss: 0.0064  \n",
      "<<<iteration:[260/657] - total_loss: 0.2814  obj_loss: 0.1592  noobj_loss: 0.1908  bbox_loss: 0.0044  cls_loss: 0.0050  \n",
      "<<<iteration:[280/657] - total_loss: 0.2832  obj_loss: 0.1622  noobj_loss: 0.1879  bbox_loss: 0.0043  cls_loss: 0.0055  \n",
      "<<<iteration:[300/657] - total_loss: 0.2788  obj_loss: 0.1569  noobj_loss: 0.1840  bbox_loss: 0.0045  cls_loss: 0.0074  \n",
      "<<<iteration:[320/657] - total_loss: 0.2826  obj_loss: 0.1616  noobj_loss: 0.1865  bbox_loss: 0.0044  cls_loss: 0.0059  \n",
      "<<<iteration:[340/657] - total_loss: 0.2910  obj_loss: 0.1685  noobj_loss: 0.1883  bbox_loss: 0.0042  cls_loss: 0.0073  \n",
      "<<<iteration:[360/657] - total_loss: 0.2888  obj_loss: 0.1643  noobj_loss: 0.1918  bbox_loss: 0.0045  cls_loss: 0.0060  \n",
      "<<<iteration:[380/657] - total_loss: 0.3011  obj_loss: 0.1707  noobj_loss: 0.1987  bbox_loss: 0.0046  cls_loss: 0.0080  \n",
      "<<<iteration:[400/657] - total_loss: 0.2937  obj_loss: 0.1671  noobj_loss: 0.1939  bbox_loss: 0.0045  cls_loss: 0.0071  \n",
      "<<<iteration:[420/657] - total_loss: 0.2936  obj_loss: 0.1706  noobj_loss: 0.1871  bbox_loss: 0.0046  cls_loss: 0.0063  \n",
      "<<<iteration:[440/657] - total_loss: 0.2847  obj_loss: 0.1614  noobj_loss: 0.1945  bbox_loss: 0.0042  cls_loss: 0.0051  \n",
      "<<<iteration:[460/657] - total_loss: 0.2958  obj_loss: 0.1709  noobj_loss: 0.1947  bbox_loss: 0.0041  cls_loss: 0.0070  \n",
      "<<<iteration:[480/657] - total_loss: 0.2940  obj_loss: 0.1722  noobj_loss: 0.1858  bbox_loss: 0.0043  cls_loss: 0.0073  \n",
      "<<<iteration:[500/657] - total_loss: 0.2904  obj_loss: 0.1660  noobj_loss: 0.1865  bbox_loss: 0.0048  cls_loss: 0.0072  \n",
      "<<<iteration:[520/657] - total_loss: 0.2885  obj_loss: 0.1666  noobj_loss: 0.1891  bbox_loss: 0.0043  cls_loss: 0.0059  \n",
      "<<<iteration:[540/657] - total_loss: 0.2880  obj_loss: 0.1656  noobj_loss: 0.1925  bbox_loss: 0.0038  cls_loss: 0.0070  \n",
      "<<<iteration:[560/657] - total_loss: 0.3004  obj_loss: 0.1726  noobj_loss: 0.1962  bbox_loss: 0.0044  cls_loss: 0.0078  \n",
      "<<<iteration:[580/657] - total_loss: 0.2919  obj_loss: 0.1668  noobj_loss: 0.1912  bbox_loss: 0.0045  cls_loss: 0.0072  \n",
      "<<<iteration:[600/657] - total_loss: 0.2903  obj_loss: 0.1554  noobj_loss: 0.2005  bbox_loss: 0.0051  cls_loss: 0.0089  \n",
      "<<<iteration:[620/657] - total_loss: 0.3029  obj_loss: 0.1697  noobj_loss: 0.1972  bbox_loss: 0.0047  cls_loss: 0.0112  \n",
      "<<<iteration:[640/657] - total_loss: 0.2899  obj_loss: 0.1642  noobj_loss: 0.1922  bbox_loss: 0.0046  cls_loss: 0.0065  \n",
      "\n",
      "epoch:95/100 - Train Loss: 0.2883, Val Loss: 0.3027\n",
      "\n",
      "<<<iteration:[20/657] - total_loss: 0.3018  obj_loss: 0.1680  noobj_loss: 0.2031  bbox_loss: 0.0050  cls_loss: 0.0073  \n",
      "<<<iteration:[40/657] - total_loss: 0.2919  obj_loss: 0.1643  noobj_loss: 0.1959  bbox_loss: 0.0043  cls_loss: 0.0081  \n",
      "<<<iteration:[60/657] - total_loss: 0.2840  obj_loss: 0.1586  noobj_loss: 0.1874  bbox_loss: 0.0051  cls_loss: 0.0060  \n",
      "<<<iteration:[80/657] - total_loss: 0.2812  obj_loss: 0.1530  noobj_loss: 0.1852  bbox_loss: 0.0054  cls_loss: 0.0087  \n",
      "<<<iteration:[100/657] - total_loss: 0.2711  obj_loss: 0.1488  noobj_loss: 0.1861  bbox_loss: 0.0045  cls_loss: 0.0070  \n",
      "<<<iteration:[120/657] - total_loss: 0.2767  obj_loss: 0.1555  noobj_loss: 0.1885  bbox_loss: 0.0043  cls_loss: 0.0053  \n",
      "<<<iteration:[140/657] - total_loss: 0.2693  obj_loss: 0.1433  noobj_loss: 0.1832  bbox_loss: 0.0052  cls_loss: 0.0085  \n",
      "<<<iteration:[160/657] - total_loss: 0.2922  obj_loss: 0.1675  noobj_loss: 0.1890  bbox_loss: 0.0046  cls_loss: 0.0073  \n",
      "<<<iteration:[180/657] - total_loss: 0.2872  obj_loss: 0.1640  noobj_loss: 0.1876  bbox_loss: 0.0046  cls_loss: 0.0065  \n",
      "<<<iteration:[200/657] - total_loss: 0.2955  obj_loss: 0.1713  noobj_loss: 0.1940  bbox_loss: 0.0043  cls_loss: 0.0058  \n",
      "<<<iteration:[220/657] - total_loss: 0.2959  obj_loss: 0.1645  noobj_loss: 0.1999  bbox_loss: 0.0047  cls_loss: 0.0080  \n",
      "<<<iteration:[240/657] - total_loss: 0.2911  obj_loss: 0.1666  noobj_loss: 0.1874  bbox_loss: 0.0046  cls_loss: 0.0077  \n",
      "<<<iteration:[260/657] - total_loss: 0.2903  obj_loss: 0.1667  noobj_loss: 0.1858  bbox_loss: 0.0047  cls_loss: 0.0073  \n",
      "<<<iteration:[280/657] - total_loss: 0.2875  obj_loss: 0.1630  noobj_loss: 0.1924  bbox_loss: 0.0044  cls_loss: 0.0064  \n",
      "<<<iteration:[300/657] - total_loss: 0.2845  obj_loss: 0.1586  noobj_loss: 0.1908  bbox_loss: 0.0049  cls_loss: 0.0059  \n",
      "<<<iteration:[320/657] - total_loss: 0.2883  obj_loss: 0.1595  noobj_loss: 0.1954  bbox_loss: 0.0049  cls_loss: 0.0067  \n",
      "<<<iteration:[340/657] - total_loss: 0.2878  obj_loss: 0.1633  noobj_loss: 0.1854  bbox_loss: 0.0050  cls_loss: 0.0070  \n",
      "<<<iteration:[360/657] - total_loss: 0.2705  obj_loss: 0.1502  noobj_loss: 0.1897  bbox_loss: 0.0041  cls_loss: 0.0048  \n",
      "<<<iteration:[380/657] - total_loss: 0.2969  obj_loss: 0.1602  noobj_loss: 0.2009  bbox_loss: 0.0045  cls_loss: 0.0135  \n",
      "<<<iteration:[400/657] - total_loss: 0.2950  obj_loss: 0.1649  noobj_loss: 0.2030  bbox_loss: 0.0045  cls_loss: 0.0063  \n",
      "<<<iteration:[420/657] - total_loss: 0.2929  obj_loss: 0.1649  noobj_loss: 0.1930  bbox_loss: 0.0050  cls_loss: 0.0066  \n",
      "<<<iteration:[440/657] - total_loss: 0.2748  obj_loss: 0.1500  noobj_loss: 0.1904  bbox_loss: 0.0046  cls_loss: 0.0069  \n",
      "<<<iteration:[460/657] - total_loss: 0.2929  obj_loss: 0.1693  noobj_loss: 0.1888  bbox_loss: 0.0044  cls_loss: 0.0073  \n",
      "<<<iteration:[480/657] - total_loss: 0.2877  obj_loss: 0.1600  noobj_loss: 0.1893  bbox_loss: 0.0052  cls_loss: 0.0069  \n",
      "<<<iteration:[500/657] - total_loss: 0.2723  obj_loss: 0.1499  noobj_loss: 0.1904  bbox_loss: 0.0044  cls_loss: 0.0051  \n",
      "<<<iteration:[520/657] - total_loss: 0.2718  obj_loss: 0.1517  noobj_loss: 0.1887  bbox_loss: 0.0040  cls_loss: 0.0058  \n",
      "<<<iteration:[540/657] - total_loss: 0.2945  obj_loss: 0.1685  noobj_loss: 0.1970  bbox_loss: 0.0044  cls_loss: 0.0057  \n",
      "<<<iteration:[560/657] - total_loss: 0.2894  obj_loss: 0.1542  noobj_loss: 0.1931  bbox_loss: 0.0054  cls_loss: 0.0118  \n",
      "<<<iteration:[580/657] - total_loss: 0.2804  obj_loss: 0.1532  noobj_loss: 0.1938  bbox_loss: 0.0047  cls_loss: 0.0069  \n",
      "<<<iteration:[600/657] - total_loss: 0.2880  obj_loss: 0.1615  noobj_loss: 0.1936  bbox_loss: 0.0046  cls_loss: 0.0067  \n",
      "<<<iteration:[620/657] - total_loss: 0.2919  obj_loss: 0.1673  noobj_loss: 0.1925  bbox_loss: 0.0046  cls_loss: 0.0053  \n",
      "<<<iteration:[640/657] - total_loss: 0.2930  obj_loss: 0.1650  noobj_loss: 0.1984  bbox_loss: 0.0045  cls_loss: 0.0064  \n",
      "\n",
      "epoch:96/100 - Train Loss: 0.2858, Val Loss: 0.2998\n",
      "\n",
      "<<<iteration:[20/657] - total_loss: 0.2983  obj_loss: 0.1691  noobj_loss: 0.2001  bbox_loss: 0.0047  cls_loss: 0.0058  \n",
      "<<<iteration:[40/657] - total_loss: 0.2830  obj_loss: 0.1621  noobj_loss: 0.1867  bbox_loss: 0.0044  cls_loss: 0.0055  \n",
      "<<<iteration:[60/657] - total_loss: 0.2891  obj_loss: 0.1599  noobj_loss: 0.1947  bbox_loss: 0.0049  cls_loss: 0.0074  \n",
      "<<<iteration:[80/657] - total_loss: 0.2873  obj_loss: 0.1617  noobj_loss: 0.1904  bbox_loss: 0.0045  cls_loss: 0.0076  \n",
      "<<<iteration:[100/657] - total_loss: 0.2910  obj_loss: 0.1672  noobj_loss: 0.1900  bbox_loss: 0.0047  cls_loss: 0.0056  \n",
      "<<<iteration:[120/657] - total_loss: 0.2912  obj_loss: 0.1664  noobj_loss: 0.1895  bbox_loss: 0.0044  cls_loss: 0.0079  \n",
      "<<<iteration:[140/657] - total_loss: 0.3052  obj_loss: 0.1743  noobj_loss: 0.2044  bbox_loss: 0.0043  cls_loss: 0.0073  \n",
      "<<<iteration:[160/657] - total_loss: 0.2827  obj_loss: 0.1567  noobj_loss: 0.1928  bbox_loss: 0.0045  cls_loss: 0.0071  \n",
      "<<<iteration:[180/657] - total_loss: 0.2786  obj_loss: 0.1540  noobj_loss: 0.1933  bbox_loss: 0.0043  cls_loss: 0.0064  \n",
      "<<<iteration:[200/657] - total_loss: 0.2792  obj_loss: 0.1556  noobj_loss: 0.1906  bbox_loss: 0.0042  cls_loss: 0.0074  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<<<iteration:[220/657] - total_loss: 0.2992  obj_loss: 0.1760  noobj_loss: 0.1919  bbox_loss: 0.0043  cls_loss: 0.0059  \n",
      "<<<iteration:[240/657] - total_loss: 0.2778  obj_loss: 0.1517  noobj_loss: 0.2016  bbox_loss: 0.0040  cls_loss: 0.0053  \n",
      "<<<iteration:[260/657] - total_loss: 0.2980  obj_loss: 0.1710  noobj_loss: 0.1884  bbox_loss: 0.0048  cls_loss: 0.0090  \n",
      "<<<iteration:[280/657] - total_loss: 0.2752  obj_loss: 0.1541  noobj_loss: 0.1888  bbox_loss: 0.0042  cls_loss: 0.0057  \n",
      "<<<iteration:[300/657] - total_loss: 0.2833  obj_loss: 0.1574  noobj_loss: 0.1952  bbox_loss: 0.0044  cls_loss: 0.0063  \n",
      "<<<iteration:[320/657] - total_loss: 0.2922  obj_loss: 0.1716  noobj_loss: 0.1862  bbox_loss: 0.0042  cls_loss: 0.0063  \n",
      "<<<iteration:[340/657] - total_loss: 0.2734  obj_loss: 0.1524  noobj_loss: 0.1868  bbox_loss: 0.0044  cls_loss: 0.0059  \n",
      "<<<iteration:[360/657] - total_loss: 0.2745  obj_loss: 0.1516  noobj_loss: 0.1750  bbox_loss: 0.0054  cls_loss: 0.0084  \n",
      "<<<iteration:[380/657] - total_loss: 0.2831  obj_loss: 0.1610  noobj_loss: 0.1910  bbox_loss: 0.0042  cls_loss: 0.0055  \n",
      "<<<iteration:[400/657] - total_loss: 0.2890  obj_loss: 0.1672  noobj_loss: 0.1892  bbox_loss: 0.0045  cls_loss: 0.0047  \n",
      "<<<iteration:[420/657] - total_loss: 0.2844  obj_loss: 0.1596  noobj_loss: 0.1866  bbox_loss: 0.0049  cls_loss: 0.0070  \n",
      "<<<iteration:[440/657] - total_loss: 0.2842  obj_loss: 0.1576  noobj_loss: 0.1953  bbox_loss: 0.0047  cls_loss: 0.0056  \n",
      "<<<iteration:[460/657] - total_loss: 0.3012  obj_loss: 0.1694  noobj_loss: 0.1908  bbox_loss: 0.0050  cls_loss: 0.0115  \n",
      "<<<iteration:[480/657] - total_loss: 0.2891  obj_loss: 0.1644  noobj_loss: 0.1887  bbox_loss: 0.0043  cls_loss: 0.0089  \n",
      "<<<iteration:[500/657] - total_loss: 0.2838  obj_loss: 0.1558  noobj_loss: 0.1982  bbox_loss: 0.0047  cls_loss: 0.0054  \n",
      "<<<iteration:[520/657] - total_loss: 0.2873  obj_loss: 0.1640  noobj_loss: 0.1921  bbox_loss: 0.0042  cls_loss: 0.0063  \n",
      "<<<iteration:[540/657] - total_loss: 0.2947  obj_loss: 0.1667  noobj_loss: 0.1963  bbox_loss: 0.0045  cls_loss: 0.0075  \n",
      "<<<iteration:[560/657] - total_loss: 0.2917  obj_loss: 0.1611  noobj_loss: 0.1994  bbox_loss: 0.0049  cls_loss: 0.0064  \n",
      "<<<iteration:[580/657] - total_loss: 0.2787  obj_loss: 0.1523  noobj_loss: 0.1936  bbox_loss: 0.0045  cls_loss: 0.0073  \n",
      "<<<iteration:[600/657] - total_loss: 0.3063  obj_loss: 0.1780  noobj_loss: 0.1940  bbox_loss: 0.0044  cls_loss: 0.0092  \n",
      "<<<iteration:[620/657] - total_loss: 0.2951  obj_loss: 0.1696  noobj_loss: 0.1961  bbox_loss: 0.0041  cls_loss: 0.0069  \n",
      "<<<iteration:[640/657] - total_loss: 0.2880  obj_loss: 0.1626  noobj_loss: 0.1925  bbox_loss: 0.0042  cls_loss: 0.0081  \n",
      "\n",
      "epoch:97/100 - Train Loss: 0.2877, Val Loss: 0.3041\n",
      "\n",
      "<<<iteration:[20/657] - total_loss: 0.3028  obj_loss: 0.1701  noobj_loss: 0.2088  bbox_loss: 0.0046  cls_loss: 0.0053  \n",
      "<<<iteration:[40/657] - total_loss: 0.2810  obj_loss: 0.1579  noobj_loss: 0.1956  bbox_loss: 0.0039  cls_loss: 0.0058  \n",
      "<<<iteration:[60/657] - total_loss: 0.2806  obj_loss: 0.1600  noobj_loss: 0.1834  bbox_loss: 0.0045  cls_loss: 0.0064  \n",
      "<<<iteration:[80/657] - total_loss: 0.2873  obj_loss: 0.1632  noobj_loss: 0.1957  bbox_loss: 0.0037  cls_loss: 0.0074  \n",
      "<<<iteration:[100/657] - total_loss: 0.2937  obj_loss: 0.1703  noobj_loss: 0.1881  bbox_loss: 0.0040  cls_loss: 0.0094  \n",
      "<<<iteration:[120/657] - total_loss: 0.2924  obj_loss: 0.1627  noobj_loss: 0.1988  bbox_loss: 0.0046  cls_loss: 0.0074  \n",
      "<<<iteration:[140/657] - total_loss: 0.2884  obj_loss: 0.1642  noobj_loss: 0.1909  bbox_loss: 0.0043  cls_loss: 0.0073  \n",
      "<<<iteration:[160/657] - total_loss: 0.2837  obj_loss: 0.1626  noobj_loss: 0.1906  bbox_loss: 0.0038  cls_loss: 0.0067  \n",
      "<<<iteration:[180/657] - total_loss: 0.2882  obj_loss: 0.1577  noobj_loss: 0.1923  bbox_loss: 0.0054  cls_loss: 0.0072  \n",
      "<<<iteration:[200/657] - total_loss: 0.2871  obj_loss: 0.1585  noobj_loss: 0.1961  bbox_loss: 0.0045  cls_loss: 0.0080  \n",
      "<<<iteration:[220/657] - total_loss: 0.2837  obj_loss: 0.1565  noobj_loss: 0.1944  bbox_loss: 0.0046  cls_loss: 0.0072  \n",
      "<<<iteration:[240/657] - total_loss: 0.2922  obj_loss: 0.1664  noobj_loss: 0.1907  bbox_loss: 0.0044  cls_loss: 0.0085  \n",
      "<<<iteration:[260/657] - total_loss: 0.2773  obj_loss: 0.1538  noobj_loss: 0.1890  bbox_loss: 0.0045  cls_loss: 0.0063  \n",
      "<<<iteration:[280/657] - total_loss: 0.2860  obj_loss: 0.1582  noobj_loss: 0.1975  bbox_loss: 0.0041  cls_loss: 0.0087  \n",
      "<<<iteration:[300/657] - total_loss: 0.2835  obj_loss: 0.1584  noobj_loss: 0.1892  bbox_loss: 0.0047  cls_loss: 0.0071  \n",
      "<<<iteration:[320/657] - total_loss: 0.3057  obj_loss: 0.1750  noobj_loss: 0.1978  bbox_loss: 0.0043  cls_loss: 0.0101  \n",
      "<<<iteration:[340/657] - total_loss: 0.3042  obj_loss: 0.1793  noobj_loss: 0.1971  bbox_loss: 0.0041  cls_loss: 0.0059  \n",
      "<<<iteration:[360/657] - total_loss: 0.2762  obj_loss: 0.1569  noobj_loss: 0.1848  bbox_loss: 0.0041  cls_loss: 0.0064  \n",
      "<<<iteration:[380/657] - total_loss: 0.2888  obj_loss: 0.1635  noobj_loss: 0.1956  bbox_loss: 0.0042  cls_loss: 0.0064  \n",
      "<<<iteration:[400/657] - total_loss: 0.2825  obj_loss: 0.1598  noobj_loss: 0.1877  bbox_loss: 0.0046  cls_loss: 0.0057  \n",
      "<<<iteration:[420/657] - total_loss: 0.2935  obj_loss: 0.1680  noobj_loss: 0.1924  bbox_loss: 0.0046  cls_loss: 0.0063  \n",
      "<<<iteration:[440/657] - total_loss: 0.2839  obj_loss: 0.1623  noobj_loss: 0.1902  bbox_loss: 0.0042  cls_loss: 0.0057  \n",
      "<<<iteration:[460/657] - total_loss: 0.2896  obj_loss: 0.1663  noobj_loss: 0.1894  bbox_loss: 0.0046  cls_loss: 0.0056  \n",
      "<<<iteration:[480/657] - total_loss: 0.2846  obj_loss: 0.1620  noobj_loss: 0.1966  bbox_loss: 0.0037  cls_loss: 0.0059  \n",
      "<<<iteration:[500/657] - total_loss: 0.2849  obj_loss: 0.1633  noobj_loss: 0.1956  bbox_loss: 0.0037  cls_loss: 0.0053  \n",
      "<<<iteration:[520/657] - total_loss: 0.2979  obj_loss: 0.1700  noobj_loss: 0.1986  bbox_loss: 0.0042  cls_loss: 0.0078  \n",
      "<<<iteration:[540/657] - total_loss: 0.2844  obj_loss: 0.1559  noobj_loss: 0.1938  bbox_loss: 0.0050  cls_loss: 0.0066  \n",
      "<<<iteration:[560/657] - total_loss: 0.2818  obj_loss: 0.1580  noobj_loss: 0.1883  bbox_loss: 0.0048  cls_loss: 0.0055  \n",
      "<<<iteration:[580/657] - total_loss: 0.2837  obj_loss: 0.1603  noobj_loss: 0.1865  bbox_loss: 0.0047  cls_loss: 0.0065  \n",
      "<<<iteration:[600/657] - total_loss: 0.2930  obj_loss: 0.1639  noobj_loss: 0.1976  bbox_loss: 0.0045  cls_loss: 0.0081  \n",
      "<<<iteration:[620/657] - total_loss: 0.2951  obj_loss: 0.1660  noobj_loss: 0.1894  bbox_loss: 0.0050  cls_loss: 0.0096  \n",
      "<<<iteration:[640/657] - total_loss: 0.2824  obj_loss: 0.1615  noobj_loss: 0.1919  bbox_loss: 0.0039  cls_loss: 0.0055  \n",
      "\n",
      "epoch:98/100 - Train Loss: 0.2877, Val Loss: 0.3079\n",
      "\n",
      "<<<iteration:[20/657] - total_loss: 0.2904  obj_loss: 0.1599  noobj_loss: 0.1997  bbox_loss: 0.0048  cls_loss: 0.0068  \n",
      "<<<iteration:[40/657] - total_loss: 0.2776  obj_loss: 0.1530  noobj_loss: 0.1859  bbox_loss: 0.0049  cls_loss: 0.0072  \n",
      "<<<iteration:[60/657] - total_loss: 0.2939  obj_loss: 0.1686  noobj_loss: 0.1929  bbox_loss: 0.0042  cls_loss: 0.0078  \n",
      "<<<iteration:[80/657] - total_loss: 0.2821  obj_loss: 0.1573  noobj_loss: 0.1873  bbox_loss: 0.0045  cls_loss: 0.0086  \n",
      "<<<iteration:[100/657] - total_loss: 0.2844  obj_loss: 0.1599  noobj_loss: 0.1929  bbox_loss: 0.0041  cls_loss: 0.0073  \n",
      "<<<iteration:[120/657] - total_loss: 0.2885  obj_loss: 0.1647  noobj_loss: 0.1948  bbox_loss: 0.0039  cls_loss: 0.0070  \n",
      "<<<iteration:[140/657] - total_loss: 0.2829  obj_loss: 0.1545  noobj_loss: 0.1924  bbox_loss: 0.0045  cls_loss: 0.0095  \n",
      "<<<iteration:[160/657] - total_loss: 0.2902  obj_loss: 0.1670  noobj_loss: 0.1867  bbox_loss: 0.0043  cls_loss: 0.0082  \n",
      "<<<iteration:[180/657] - total_loss: 0.2795  obj_loss: 0.1506  noobj_loss: 0.2000  bbox_loss: 0.0048  cls_loss: 0.0047  \n",
      "<<<iteration:[200/657] - total_loss: 0.2927  obj_loss: 0.1667  noobj_loss: 0.1945  bbox_loss: 0.0044  cls_loss: 0.0066  \n",
      "<<<iteration:[220/657] - total_loss: 0.2869  obj_loss: 0.1686  noobj_loss: 0.1773  bbox_loss: 0.0047  cls_loss: 0.0061  \n",
      "<<<iteration:[240/657] - total_loss: 0.2905  obj_loss: 0.1618  noobj_loss: 0.1937  bbox_loss: 0.0052  cls_loss: 0.0056  \n",
      "<<<iteration:[260/657] - total_loss: 0.2793  obj_loss: 0.1574  noobj_loss: 0.1909  bbox_loss: 0.0043  cls_loss: 0.0051  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<<<iteration:[280/657] - total_loss: 0.2826  obj_loss: 0.1607  noobj_loss: 0.1934  bbox_loss: 0.0039  cls_loss: 0.0055  \n",
      "<<<iteration:[300/657] - total_loss: 0.2777  obj_loss: 0.1543  noobj_loss: 0.1934  bbox_loss: 0.0042  cls_loss: 0.0060  \n",
      "<<<iteration:[320/657] - total_loss: 0.2892  obj_loss: 0.1635  noobj_loss: 0.1942  bbox_loss: 0.0045  cls_loss: 0.0060  \n",
      "<<<iteration:[340/657] - total_loss: 0.2912  obj_loss: 0.1640  noobj_loss: 0.1984  bbox_loss: 0.0043  cls_loss: 0.0066  \n",
      "<<<iteration:[360/657] - total_loss: 0.2917  obj_loss: 0.1704  noobj_loss: 0.1903  bbox_loss: 0.0042  cls_loss: 0.0050  \n",
      "<<<iteration:[380/657] - total_loss: 0.2850  obj_loss: 0.1644  noobj_loss: 0.1879  bbox_loss: 0.0042  cls_loss: 0.0058  \n",
      "<<<iteration:[400/657] - total_loss: 0.2828  obj_loss: 0.1599  noobj_loss: 0.1880  bbox_loss: 0.0041  cls_loss: 0.0084  \n",
      "<<<iteration:[420/657] - total_loss: 0.2855  obj_loss: 0.1612  noobj_loss: 0.1887  bbox_loss: 0.0046  cls_loss: 0.0072  \n",
      "<<<iteration:[440/657] - total_loss: 0.2803  obj_loss: 0.1561  noobj_loss: 0.1889  bbox_loss: 0.0047  cls_loss: 0.0062  \n",
      "<<<iteration:[460/657] - total_loss: 0.2856  obj_loss: 0.1646  noobj_loss: 0.1870  bbox_loss: 0.0042  cls_loss: 0.0064  \n",
      "<<<iteration:[480/657] - total_loss: 0.2938  obj_loss: 0.1643  noobj_loss: 0.2007  bbox_loss: 0.0045  cls_loss: 0.0067  \n",
      "<<<iteration:[500/657] - total_loss: 0.2787  obj_loss: 0.1514  noobj_loss: 0.1967  bbox_loss: 0.0043  cls_loss: 0.0076  \n",
      "<<<iteration:[520/657] - total_loss: 0.2831  obj_loss: 0.1567  noobj_loss: 0.1937  bbox_loss: 0.0048  cls_loss: 0.0056  \n",
      "<<<iteration:[540/657] - total_loss: 0.2919  obj_loss: 0.1660  noobj_loss: 0.1975  bbox_loss: 0.0045  cls_loss: 0.0048  \n",
      "<<<iteration:[560/657] - total_loss: 0.2794  obj_loss: 0.1572  noobj_loss: 0.1916  bbox_loss: 0.0041  cls_loss: 0.0061  \n",
      "<<<iteration:[580/657] - total_loss: 0.3146  obj_loss: 0.1871  noobj_loss: 0.1877  bbox_loss: 0.0046  cls_loss: 0.0108  \n",
      "<<<iteration:[600/657] - total_loss: 0.2901  obj_loss: 0.1643  noobj_loss: 0.1907  bbox_loss: 0.0046  cls_loss: 0.0072  \n",
      "<<<iteration:[620/657] - total_loss: 0.2927  obj_loss: 0.1645  noobj_loss: 0.1953  bbox_loss: 0.0044  cls_loss: 0.0084  \n",
      "<<<iteration:[640/657] - total_loss: 0.2817  obj_loss: 0.1593  noobj_loss: 0.1827  bbox_loss: 0.0048  cls_loss: 0.0070  \n",
      "\n",
      "epoch:99/100 - Train Loss: 0.2860, Val Loss: 0.3023\n",
      "\n",
      "<<<iteration:[20/657] - total_loss: 0.2971  obj_loss: 0.1682  noobj_loss: 0.1971  bbox_loss: 0.0048  cls_loss: 0.0064  \n",
      "<<<iteration:[40/657] - total_loss: 0.2794  obj_loss: 0.1569  noobj_loss: 0.1891  bbox_loss: 0.0044  cls_loss: 0.0059  \n",
      "<<<iteration:[60/657] - total_loss: 0.2829  obj_loss: 0.1566  noobj_loss: 0.1945  bbox_loss: 0.0046  cls_loss: 0.0060  \n",
      "<<<iteration:[80/657] - total_loss: 0.2798  obj_loss: 0.1541  noobj_loss: 0.1922  bbox_loss: 0.0047  cls_loss: 0.0063  \n",
      "<<<iteration:[100/657] - total_loss: 0.2858  obj_loss: 0.1577  noobj_loss: 0.1954  bbox_loss: 0.0046  cls_loss: 0.0073  \n",
      "<<<iteration:[120/657] - total_loss: 0.2898  obj_loss: 0.1661  noobj_loss: 0.1937  bbox_loss: 0.0043  cls_loss: 0.0056  \n",
      "<<<iteration:[140/657] - total_loss: 0.2932  obj_loss: 0.1691  noobj_loss: 0.1927  bbox_loss: 0.0042  cls_loss: 0.0065  \n",
      "<<<iteration:[160/657] - total_loss: 0.2851  obj_loss: 0.1599  noobj_loss: 0.1955  bbox_loss: 0.0045  cls_loss: 0.0048  \n",
      "<<<iteration:[180/657] - total_loss: 0.2773  obj_loss: 0.1556  noobj_loss: 0.1883  bbox_loss: 0.0042  cls_loss: 0.0064  \n",
      "<<<iteration:[200/657] - total_loss: 0.2769  obj_loss: 0.1499  noobj_loss: 0.1986  bbox_loss: 0.0044  cls_loss: 0.0057  \n",
      "<<<iteration:[220/657] - total_loss: 0.2910  obj_loss: 0.1634  noobj_loss: 0.1912  bbox_loss: 0.0050  cls_loss: 0.0069  \n",
      "<<<iteration:[240/657] - total_loss: 0.2871  obj_loss: 0.1635  noobj_loss: 0.1942  bbox_loss: 0.0044  cls_loss: 0.0046  \n",
      "<<<iteration:[260/657] - total_loss: 0.2877  obj_loss: 0.1691  noobj_loss: 0.1873  bbox_loss: 0.0037  cls_loss: 0.0065  \n",
      "<<<iteration:[280/657] - total_loss: 0.2940  obj_loss: 0.1667  noobj_loss: 0.1956  bbox_loss: 0.0045  cls_loss: 0.0070  \n",
      "<<<iteration:[300/657] - total_loss: 0.3053  obj_loss: 0.1767  noobj_loss: 0.1970  bbox_loss: 0.0048  cls_loss: 0.0063  \n",
      "<<<iteration:[320/657] - total_loss: 0.2783  obj_loss: 0.1491  noobj_loss: 0.1959  bbox_loss: 0.0041  cls_loss: 0.0106  \n",
      "<<<iteration:[340/657] - total_loss: 0.2899  obj_loss: 0.1631  noobj_loss: 0.1983  bbox_loss: 0.0039  cls_loss: 0.0082  \n",
      "<<<iteration:[360/657] - total_loss: 0.2850  obj_loss: 0.1604  noobj_loss: 0.1948  bbox_loss: 0.0041  cls_loss: 0.0065  \n",
      "<<<iteration:[380/657] - total_loss: 0.3000  obj_loss: 0.1681  noobj_loss: 0.2009  bbox_loss: 0.0043  cls_loss: 0.0100  \n",
      "<<<iteration:[400/657] - total_loss: 0.2775  obj_loss: 0.1555  noobj_loss: 0.1848  bbox_loss: 0.0045  cls_loss: 0.0073  \n",
      "<<<iteration:[420/657] - total_loss: 0.2882  obj_loss: 0.1654  noobj_loss: 0.1935  bbox_loss: 0.0042  cls_loss: 0.0050  \n",
      "<<<iteration:[440/657] - total_loss: 0.2722  obj_loss: 0.1503  noobj_loss: 0.1835  bbox_loss: 0.0048  cls_loss: 0.0059  \n",
      "<<<iteration:[460/657] - total_loss: 0.2929  obj_loss: 0.1678  noobj_loss: 0.1932  bbox_loss: 0.0042  cls_loss: 0.0073  \n",
      "<<<iteration:[480/657] - total_loss: 0.2946  obj_loss: 0.1679  noobj_loss: 0.1989  bbox_loss: 0.0042  cls_loss: 0.0063  \n",
      "<<<iteration:[500/657] - total_loss: 0.2850  obj_loss: 0.1591  noobj_loss: 0.1945  bbox_loss: 0.0040  cls_loss: 0.0086  \n",
      "<<<iteration:[520/657] - total_loss: 0.2714  obj_loss: 0.1473  noobj_loss: 0.1920  bbox_loss: 0.0043  cls_loss: 0.0067  \n",
      "<<<iteration:[540/657] - total_loss: 0.2922  obj_loss: 0.1642  noobj_loss: 0.1928  bbox_loss: 0.0048  cls_loss: 0.0076  \n",
      "<<<iteration:[560/657] - total_loss: 0.2903  obj_loss: 0.1629  noobj_loss: 0.1992  bbox_loss: 0.0043  cls_loss: 0.0065  \n",
      "<<<iteration:[580/657] - total_loss: 0.2883  obj_loss: 0.1589  noobj_loss: 0.2037  bbox_loss: 0.0044  cls_loss: 0.0056  \n",
      "<<<iteration:[600/657] - total_loss: 0.3064  obj_loss: 0.1777  noobj_loss: 0.1978  bbox_loss: 0.0044  cls_loss: 0.0078  \n",
      "<<<iteration:[620/657] - total_loss: 0.2865  obj_loss: 0.1618  noobj_loss: 0.1956  bbox_loss: 0.0039  cls_loss: 0.0074  \n",
      "<<<iteration:[640/657] - total_loss: 0.2840  obj_loss: 0.1551  noobj_loss: 0.1979  bbox_loss: 0.0046  cls_loss: 0.0067  \n",
      "\n",
      "epoch:100/100 - Train Loss: 0.2868, Val Loss: 0.3035\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "15a6a97c64e14bf3a9e65cad5733eb02",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='0.003 MB of 0.003 MB uploaded (0.000 MB deduped)\\r'), FloatProgress(value=1.0, max…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>Train Loss</td><td>█▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>Train bbox Loss</td><td>█▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>Train class Loss</td><td>█▃▃▂▂▂▂▂▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>Train obj Loss</td><td>▁▄▇▇█████████████████▇█▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇</td></tr><tr><td>Val Loss</td><td>█▂▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>Val bbox Loss</td><td>█▃▂▂▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>Val class Loss</td><td>█▄▃▃▃▂▂▂▂▂▂▂▂▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>Val obj Loss</td><td>▁▅▇███████▇█▇▇▇▇▇▇▇▇▇▆▇▆▆▆▆▆▅▆▆▆▆▆▆▆▆▆▆▆</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>Train Loss</td><td>0.28684</td></tr><tr><td>Train bbox Loss</td><td>0.00437</td></tr><tr><td>Train class Loss</td><td>0.00671</td></tr><tr><td>Train obj Loss</td><td>0.16125</td></tr><tr><td>Val Loss</td><td>0.30348</td></tr><tr><td>Val bbox Loss</td><td>0.00724</td></tr><tr><td>Val class Loss</td><td>0.00453</td></tr><tr><td>Val obj Loss</td><td>0.15058</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">still-serenity-1</strong> at: <a href='https://wandb.ai/urp/yolo_swin_neck_IMAGE_PATCH/runs/elvxwgth' target=\"_blank\">https://wandb.ai/urp/yolo_swin_neck_IMAGE_PATCH/runs/elvxwgth</a><br/> View job at <a href='https://wandb.ai/urp/yolo_swin_neck_IMAGE_PATCH/jobs/QXJ0aWZhY3RDb2xsZWN0aW9uOjEwODE3NDQ1OQ==/version_details/v0' target=\"_blank\">https://wandb.ai/urp/yolo_swin_neck_IMAGE_PATCH/jobs/QXJ0aWZhY3RDb2xsZWN0aW9uOjEwODE3NDQ1OQ==/version_details/v0</a><br/>Synced 5 W&B file(s), 0 media file(s), 2 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20231019_091400-elvxwgth/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "best_epoch = 0\n",
    "best_score = float('inf')\n",
    "train_losses = []\n",
    "val_losses = []\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    train_loss, val_loss = train_one_epoch(dataloaders, model, criterion, optimizer, device)\n",
    "    train_losses.append(train_loss)\n",
    "    val_losses.append(val_loss)\n",
    "#     train_loss[\"obj_loss\"] += obj_loss\n",
    "#     train_loss[\"noobj_loss\"] += noobj_loss\n",
    "#     train_loss[\"bbox_loss\"] += bbox_loss\n",
    "#     train_loss[\"cls_loss\"] += cls_loss\n",
    "    wandb.log({\"Train Loss\": train_loss['total_loss'],\n",
    "               \"Train obj Loss\":train_loss[\"obj_loss\"],\n",
    "               \"Train bbox Loss\":train_loss[\"bbox_loss\"],\n",
    "               \"Train class Loss\":train_loss[\"cls_loss\"],\n",
    "               \"Val Loss\": val_loss['total_loss'],\n",
    "               \"Val obj Loss\":val_loss[\"obj_loss\"],\n",
    "               \"Val bbox Loss\":val_loss[\"bbox_loss\"],\n",
    "               \"Val class Loss\":val_loss[\"cls_loss\"],})\n",
    "    print(f\"\\nepoch:{epoch+1}/{num_epochs} - Train Loss: {train_loss['total_loss']:.4f}, Val Loss: {val_loss['total_loss']:.4f}\\n\")\n",
    "    \n",
    "    if (epoch+1) % 10 == 0:\n",
    "        save_model(model.state_dict(), f'model_{epoch+1}.pth', save_dir=f\"./trained_model/{BACKBONE}_{PART}_LR{LR}_AUG{AUG_FACTOR}\")\n",
    "wandb.finish()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4de7fe95",
   "metadata": {},
   "source": [
    "# Test Dataset Inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "b71f9334",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import os \n",
    "import pandas as pd\n",
    "import cv2\n",
    "import torch\n",
    "import matplotlib.pyplot as plt\n",
    "from ipywidgets import interact\n",
    "import albumentations as A\n",
    "from albumentations.pytorch import ToTensorV2\n",
    "import torchvision\n",
    "from torch import nn\n",
    "import torchsummary\n",
    "from torch.utils.data import DataLoader\n",
    "from collections import defaultdict\n",
    "from torchvision.utils import make_grid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "63f8dfc5",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "64dd5b10",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_model(ckpt_path, num_classes, device):\n",
    "    checkpoint = torch.load(ckpt_path, map_location=device)\n",
    "    model = YOLO_SWIN(num_classes=num_classes)\n",
    "    model.load_state_dict(checkpoint)\n",
    "    model = model.to(device)\n",
    "    model.eval()\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "4d80869e",
   "metadata": {},
   "outputs": [],
   "source": [
    "IMAGE_SIZE=448\n",
    "transformer = A.Compose([\n",
    "            A.Resize(height=IMAGE_SIZE, width=IMAGE_SIZE),\n",
    "            A.Normalize(mean=(0.485, 0.456, 0.406),std=(0.229, 0.224, 0.225)),\n",
    "            ToTensorV2(),\n",
    "        ],\n",
    "        bbox_params=A.BboxParams(format='yolo', label_fields=['class_ids']),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "76bcd114",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ckpt_path=\"./trained_model/YOLO_SWIN_T_body_LR0.0001_AUG30/model_90.pth\"\n",
    "ckpt_path=\"/workspace/Plastic_Bottle_defect_detection/trained_model/YOLO_SWIN_T_neck_LR0.0001_Image_Patch50/model_100.pth\"\n",
    "model = load_model(ckpt_path, NUM_CLASSES, device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "0d42c594",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "start making augmented images-- augmented factor:0\n",
      "total length of augmented images: 0\n"
     ]
    }
   ],
   "source": [
    "NECK_PATH = '/home/host_data/PET_data/Neck'\n",
    "BODY_PATH = '/home/host_data/PET_data/Body'\n",
    "test_dataset=PET_dataset(\"neck\" ,neck_dir=NECK_PATH,body_dir=BODY_PATH,phase='test', transformer=transformer, aug=None)\n",
    "test_dataloaders = DataLoader(test_dataset, batch_size=1, shuffle=False, collate_fn=collate_fn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "07fed11f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "25"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(test_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "3709c974",
   "metadata": {},
   "outputs": [],
   "source": [
    "@torch.no_grad()\n",
    "def model_predict(image, model, conf_thres=0.2, iou_threshold=0.1):\n",
    "    predictions = model(image)\n",
    "    prediction = predictions.detach().cpu().squeeze(dim=0)\n",
    "    f_map=prediction\n",
    "\n",
    "#     print(prediction.shape)\n",
    "    \n",
    "    grid_size = prediction.shape[-1]\n",
    "    y_grid, x_grid = torch.meshgrid(torch.arange(grid_size), torch.arange(grid_size))\n",
    "    stride_size = IMAGE_SIZE/grid_size\n",
    "\n",
    "    conf = prediction[[0,5], ...].reshape(1, -1)\n",
    "    xc = (prediction[[1,6], ...] * IMAGE_SIZE + x_grid*stride_size).reshape(1,-1)\n",
    "    yc = (prediction[[2,7], ...] * IMAGE_SIZE + y_grid*stride_size).reshape(1,-1)\n",
    "    w = (prediction[[3,8], ...] * IMAGE_SIZE).reshape(1,-1)\n",
    "    h = (prediction[[4,9], ...] * IMAGE_SIZE).reshape(1,-1)\n",
    "    cls = torch.max(prediction[10:, ...].reshape(NUM_CLASSES, -1), dim=0).indices.tile(1,2)\n",
    "    \n",
    "    x_min = xc - w/2\n",
    "    y_min = yc - h/2\n",
    "    x_max = xc + w/2\n",
    "    y_max = yc + h/2\n",
    "\n",
    "    prediction_res = torch.cat([x_min, y_min, x_max, y_max, conf, cls], dim=0)\n",
    "    prediction_res = prediction_res.transpose(0,1)\n",
    "\n",
    "    # x_min과 y_min이 음수가 되지않고, x_max와 y_max가 이미지 크기를 넘지 않게 제한\n",
    "    prediction_res[:, 2].clip(min=0, max=image.shape[1]) \n",
    "    prediction_res[:, 3].clip(min=0, max=image.shape[0])\n",
    "        \n",
    "    pred_res = prediction_res[prediction_res[:, 4] > conf_thres]\n",
    "    nms_index = torchvision.ops.nms(boxes=pred_res[:, 0:4], scores=pred_res[:, 4], iou_threshold=iou_threshold)\n",
    "    pred_res_ = pred_res[nms_index].numpy()\n",
    "    \n",
    "    n_obj = pred_res_.shape[0]\n",
    "    bboxes = np.zeros(shape=(n_obj, 4), dtype=np.float32)\n",
    "    bboxes[:, 0:2] = (pred_res_[:, 0:2] + pred_res_[:, 2:4]) / 2\n",
    "    bboxes[:, 2:4] = pred_res_[:, 2:4] - pred_res_[:, 0:2]\n",
    "    scores = pred_res_[:, 4]\n",
    "    class_ids = pred_res_[:, 5]\n",
    "    \n",
    "    # 이미지 값이 들어가면 모델을 통해서, 후처리까지 포함된 yolo 포멧의 box좌표, 그 좌표에 대한 confidence score\n",
    "    # 그리고 class id를 반환\n",
    "    return bboxes, scores, class_ids,f_map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "10dddcd9",
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_images = []\n",
    "pred_labels =[]\n",
    "feature_maps=[]\n",
    "\n",
    "for index, batch in enumerate(test_dataloaders):\n",
    "    images = batch[0].to(device)\n",
    "    bboxes, scores, class_ids, fmap = model_predict(images, model, conf_thres=0.1, iou_threshold=0.1)\n",
    "    \n",
    "    if len(bboxes) > 0:\n",
    "        prediction_yolo = np.concatenate([bboxes, scores[:, np.newaxis], class_ids[:, np.newaxis]], axis=1)\n",
    "    else:\n",
    "        prediction_yolo = np.array([])\n",
    "    \n",
    "    # 텐서형의 이미지를 다시 unnormalize를 시키고, 다시 chw를 hwc로 바꾸고 넘파이로 바꾼다.\n",
    "    np_image = make_grid(images[0], normalize=True).cpu().permute(1,2,0).numpy()\n",
    "    pred_images.append(np_image)\n",
    "    pred_labels.append(prediction_yolo)\n",
    "    feature_maps.append(fmap)\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "b07fa545",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "06c1bb9d1ac84f97a1b01edc42824982",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "interactive(children=(IntSlider(value=0, description='index', max=24), Output()), _dom_classes=('widget-intera…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from ipywidgets import interact\n",
    "\n",
    "@interact(index=(0,len(pred_images)-1))\n",
    "def show_result(index=0):\n",
    "    print(pred_labels[index])\n",
    "    if len(pred_labels[index]) > 0:\n",
    "        result = visualize(pred_images[index], pred_labels[index][:, 0:4], pred_labels[index][:, 5])\n",
    "    else:\n",
    "        result = pred_images[index]\n",
    "        \n",
    "    plt.figure(figsize=(6,6))\n",
    "    plt.imshow(result)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "24c0544e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d9a3c356b4c14d90ab78dd516178d7f0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "interactive(children=(IntSlider(value=0, description='index', max=24), Output()), _dom_classes=('widget-intera…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#feature map에서 0,5번쨰에 해당하는 objectness 투사\n",
    "from ipywidgets import interact\n",
    "\n",
    "@interact(index=(0,len(pred_images)-1))\n",
    "def show_result(index=0):\n",
    "    print(pred_labels[index])\n",
    "    if len(pred_labels[index]) > 0:\n",
    "        result = visualize(pred_images[index], pred_labels[index][:, 0:4], pred_labels[index][:, 5])\n",
    "    else:\n",
    "        result = pred_images[index]\n",
    "    \n",
    "    f_map=feature_maps[index]\n",
    "    zero_canvas=np.zeros((448,448))\n",
    "\n",
    "    cv_re1=cv2.resize(f_map[0,:,:].numpy(),(448,448))\n",
    "    cv_re2=cv2.resize(f_map[5,:,:].numpy(),(448,448))\n",
    "    zero_canvas=zero_canvas+cv_re1+cv_re2\n",
    "\n",
    "    \n",
    "    fig = plt.figure()\n",
    "    rows = 1\n",
    "    cols = 2\n",
    "    ax1 = fig.add_subplot(rows, cols, 1)\n",
    "    ax1.imshow(result)\n",
    "    ax1.set_title('Detection')\n",
    "    ax1.axis(\"off\")\n",
    "    \n",
    "    ax2 = fig.add_subplot(rows, cols, 2)\n",
    "    ax2.imshow(zero_canvas)\n",
    "    ax2.set_title('feature map-objectness')\n",
    "    ax2.axis(\"off\")\n",
    "\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99e7d4d8",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
