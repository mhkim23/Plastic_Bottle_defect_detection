{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3c025da0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import os \n",
    "import pandas as pd\n",
    "import cv2\n",
    "import torch\n",
    "import matplotlib.pyplot as plt\n",
    "from ipywidgets import interact\n",
    "import albumentations as A\n",
    "from albumentations.pytorch import ToTensorV2\n",
    "import torchvision\n",
    "from torch import nn\n",
    "import torchsummary\n",
    "from torch.utils.data import DataLoader\n",
    "from collections import defaultdict\n",
    "from torchvision.utils import make_grid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5d503acd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cuda', index=0)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "device"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ee9eb3c",
   "metadata": {},
   "source": [
    "# Utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c7fac7d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "CLASS_NAME_TO_ID = {'BS': 0, 'SCRATCH': 1}\n",
    "CLASS_ID_TO_NAME = {0: 'BS', 1: 'SCRATCH'}\n",
    "BOX_COLOR = {'BS':(200, 0, 0), 'SCRATCH':(0, 0, 200)}\n",
    "TEXT_COLOR = (255, 255, 255)\n",
    "\n",
    "def save_model(model_state, model_name, save_dir=\"./trained_model\"):\n",
    "    os.makedirs(save_dir, exist_ok=True)\n",
    "    torch.save(model_state, os.path.join(save_dir, model_name))\n",
    "\n",
    "\n",
    "def visualize_bbox(image, bbox, class_name, color=BOX_COLOR, thickness=2):\n",
    "    x_center, y_center, w, h = bbox\n",
    "    x_min = int(x_center - w/2)\n",
    "    y_min = int(y_center - h/2)\n",
    "    x_max = int(x_center + w/2)\n",
    "    y_max = int(y_center + h/2)\n",
    "    \n",
    "    cv2.rectangle(image, (x_min, y_min), (x_max, y_max), color=color[class_name], thickness=thickness)\n",
    "    \n",
    "    ((text_width, text_height), _) = cv2.getTextSize(class_name, cv2.FONT_HERSHEY_SIMPLEX, 0.35, 1)    \n",
    "    cv2.rectangle(image, (x_min, y_min - int(1.3 * text_height)), (x_min + text_width, y_min), color[class_name], -1)\n",
    "    cv2.putText(\n",
    "        image,\n",
    "        text=class_name,\n",
    "        org=(x_min, y_min - int(0.3 * text_height)),\n",
    "        fontFace=cv2.FONT_HERSHEY_SIMPLEX,\n",
    "        fontScale=0.35, \n",
    "        color=TEXT_COLOR, \n",
    "        lineType=cv2.LINE_AA,\n",
    "    )\n",
    "    return image\n",
    "\n",
    "\n",
    "def visualize(image, bboxes, category_ids):\n",
    "    img = image.copy()\n",
    "    for bbox, category_id in zip(bboxes, category_ids):\n",
    "#         print('category_id: ',category_id)\n",
    "        class_name = CLASS_ID_TO_NAME[category_id.item()]\n",
    "        img = visualize_bbox(img, bbox, class_name)\n",
    "    return img"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62c7da98",
   "metadata": {},
   "source": [
    "# Datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ea0166e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "class PET_dataset():\n",
    "    def __init__(self,part,neck_dir,body_dir,phase, transformer=None, aug=None, aug_factor=0):\n",
    "        self.neck_dir=neck_dir\n",
    "        self.body_dir=body_dir\n",
    "        self.part=part\n",
    "        self.phase=phase\n",
    "        self.transformer=transformer\n",
    "        self.aug=aug\n",
    "        self.aug_factor=aug_factor\n",
    "        if(self.part==\"body\"):\n",
    "            self.image_files = sorted([fn for fn in os.listdir(self.body_dir+\"/\"+self.phase+\"/image\") if fn.endswith(\"jpg\")])\n",
    "            self.label_files= sorted([lab for lab in os.listdir(self.body_dir+\"/\"+self.phase+\"/label\") if lab.endswith(\"txt\")])\n",
    "        elif(self.part==\"neck\"):\n",
    "            self.image_files = sorted([fn for fn in os.listdir(self.neck_dir+\"/\"+self.phase+\"/image\") if fn.endswith(\"jpg\")])\n",
    "            self.label_files= sorted([lab for lab in os.listdir(self.neck_dir+\"/\"+self.phase+\"/label\") if lab.endswith(\"txt\")])\n",
    "        \n",
    "        self.auged_img_list, self.auged_label_list=self.make_aug_list(self.image_files, self.label_files)\n",
    "        \n",
    "    def __getitem__(self,index):\n",
    "        if(self.aug==None):\n",
    "            filename, image = self.get_image(self.part, index)\n",
    "            bboxes, class_ids = self.get_label(self.part, index)\n",
    "\n",
    "            if(self.transformer):\n",
    "                transformed_data=self.transformer(image=image, bboxes=bboxes, class_ids=class_ids)\n",
    "                image = transformed_data['image']\n",
    "                bboxes = np.array(transformed_data['bboxes'])\n",
    "                class_ids = np.array(transformed_data['class_ids'])\n",
    "\n",
    "\n",
    "            target = {}\n",
    "    #         print(f'bboxes:{bboxes}\\nclass_ids:{class_ids}\\nlen_bboxes:{len(bboxes)}\\nlen_class_ids:{len(class_ids)}')\n",
    "    #         print(f'filename: {filename}')\n",
    "            target[\"boxes\"] = torch.Tensor(bboxes).float()\n",
    "            target[\"labels\"] = torch.Tensor(class_ids).long()\n",
    "\n",
    "            ###\n",
    "            bboxes=torch.Tensor(bboxes).float()\n",
    "            class_ids=torch.Tensor(class_ids).long()\n",
    "            target = np.concatenate((bboxes, class_ids[:, np.newaxis]), axis=1)\n",
    "            ###\n",
    "        else:\n",
    "            image=self.auged_img_list[index][1]\n",
    "            target=self.auged_label_list[index]\n",
    "            filename=self.auged_img_list[index][0]\n",
    "        return image, target, filename\n",
    "    \n",
    "    def __len__(self, ):\n",
    "        length=0\n",
    "        if(self.aug==None):\n",
    "            length=len(self.image_files)\n",
    "        else:\n",
    "            length=len(self.auged_img_list)\n",
    "        return length\n",
    "    \n",
    "    def make_aug_list(self,ori_image_list,ori_label_files):\n",
    "        aug_image_list=[]\n",
    "        aug_label_list=[]\n",
    "        \n",
    "        print(f\"start making augmented images-- augmented factor:{self.aug_factor}\")\n",
    "        for i in range(len(ori_image_list)):\n",
    "            filename, ori_image = self.get_image(self.part, i)\n",
    "            ori_bboxes, ori_class_ids = self.get_label(self.part, i)\n",
    "            for j in range(self.aug_factor):\n",
    "                auged_data=self.aug(image=ori_image, bboxes=ori_bboxes, class_ids=ori_class_ids)\n",
    "                image = auged_data['image']\n",
    "                bboxes = np.array(auged_data['bboxes'])\n",
    "                class_ids = np.array(auged_data['class_ids'])\n",
    "                \n",
    "                bboxes=torch.Tensor(bboxes).float()\n",
    "                class_ids=torch.Tensor(class_ids).long()\n",
    "                \n",
    "                aug_image_list.append((filename, image))\n",
    "                aug_label_list.append(np.concatenate((bboxes, class_ids[:, np.newaxis]), axis=1))\n",
    "        \n",
    "        print(f\"total length of augmented images: {len(aug_image_list)}\")\n",
    "        \n",
    "        return aug_image_list, aug_label_list\n",
    "        \n",
    "    \n",
    "    def get_image(self, part, index): # 이미지 불러오는 함수\n",
    "        filename = self.image_files[index]\n",
    "        if(part==\"body\"):\n",
    "#             print(f\"body called!-> {self.part}\")\n",
    "            image_path = self.body_dir+\"/\"+self.phase+\"/image/\"+filename\n",
    "        elif(part==\"neck\"):\n",
    "#             print(f\"neck called!-> {self.part}\")\n",
    "            image_path = self.neck_dir+\"/\"+self.phase+\"/image/\"+filename\n",
    "        image = cv2.imread(image_path)\n",
    "        image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "        return filename, image\n",
    "    \n",
    "    def get_label(self, part, index): # label (box좌표, class_id) 불러오는 함수\n",
    "        label_filename=self.label_files[index]\n",
    "        if(part==\"body\"):\n",
    "#             print(f\"body label called!-> {self.part}\")\n",
    "            label_path = self.body_dir+\"/\"+self.phase+\"/label/\"+label_filename\n",
    "        elif(part==\"neck\"):\n",
    "#             print(f\"neck label called!-> {self.part}\")\n",
    "            label_path = self.neck_dir+\"/\"+self.phase+\"/label/\"+label_filename\n",
    "        with open(label_path, 'r') as file:\n",
    "            labels = file.readlines()\n",
    "        \n",
    "        class_ids=[]\n",
    "        bboxes=[]\n",
    "        for label in labels:\n",
    "            label=label.replace(\"\\n\", \"\")\n",
    "            obj=label.split(' ')[0]\n",
    "            coor=label.split(' ')[1:]\n",
    "            obj=int(obj)\n",
    "            coor=list(map(float, coor))\n",
    "            class_ids.append(obj)\n",
    "            bboxes.append(coor)\n",
    "            \n",
    "        return bboxes, class_ids\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "235e7cec",
   "metadata": {},
   "outputs": [],
   "source": [
    "IMAGE_SIZE = 448\n",
    "\n",
    "transformer = A.Compose([ \n",
    "        # bounding box의 변환, augmentation에서 albumentations는 Detection 학습을 할 때 굉장히 유용하다. \n",
    "        A.Resize(height=IMAGE_SIZE, width=IMAGE_SIZE),\n",
    "        A.Normalize(mean=(0.485, 0.456, 0.406),std=(0.229, 0.224, 0.225)),\n",
    "        ToTensorV2(),\n",
    "        # albumentations 라이브러리에서는 Normalization을 먼저 진행해 주고 tensor화를 진행해 주어야한다.\n",
    "    ],\n",
    "    # box 위치에 대한 transformation도 함께 진행된다. \n",
    "    bbox_params=A.BboxParams(format='yolo', label_fields=['class_ids']),\n",
    ")\n",
    "\n",
    "augmentator=A.Compose([\n",
    "#     A.Resize(height=IMAGE_SIZE, width=IMAGE_SIZE),\n",
    "    A.HorizontalFlip(p=0.7),\n",
    "#     A.Sharpen(p=0.7),\n",
    "    A.BBoxSafeRandomCrop(p=0.6),\n",
    "    A.VerticalFlip (p=0.5),\n",
    "    A.HueSaturationValue(p=0.5),\n",
    "    A.Resize(height=IMAGE_SIZE, width=IMAGE_SIZE),\n",
    "    A.Normalize(mean=(0.485, 0.456, 0.406),std=(0.229, 0.224, 0.225)),\n",
    "    ToTensorV2(),\n",
    "    ],\n",
    "    bbox_params=A.BboxParams(format='yolo', label_fields=['class_ids']),\n",
    ")\n",
    "\n",
    "def collate_fn(batch):\n",
    "    image_list = []\n",
    "    target_list = []\n",
    "    filename_list = []\n",
    "    \n",
    "    for a,b,c in batch:\n",
    "        image_list.append(a)\n",
    "        target_list.append(b)\n",
    "        filename_list.append(c)\n",
    "\n",
    "    return torch.stack(image_list, dim=0), target_list, filename_list\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a6d5c32a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "start making augmented images-- augmented factor:50\n",
      "total length of augmented images: 5850\n",
      "start making augmented images-- augmented factor:0\n",
      "total length of augmented images: 0\n"
     ]
    }
   ],
   "source": [
    "NECK_PATH = '/home/host_data/PET_data/Neck'\n",
    "BODY_PATH = '/home/host_data/PET_data/Body'\n",
    "trainset_yes_aug=PET_dataset(part='body',neck_dir=NECK_PATH,body_dir=BODY_PATH,phase='train', transformer=transformer, aug=augmentator, aug_factor=50)\n",
    "trainset_no_aug=PET_dataset(part='body',neck_dir=NECK_PATH,body_dir=BODY_PATH,phase='train', transformer=transformer, aug=None)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c0fbcd25",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'trainset_yes_aug' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[6], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[38;5;28mlen\u001b[39m(\u001b[43mtrainset_yes_aug\u001b[49m)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'trainset_yes_aug' is not defined"
     ]
    }
   ],
   "source": [
    "len(trainset_yes_aug)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "5db4ebba",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'trainset_no_aug' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[7], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[38;5;129m@interact\u001b[39m(index\u001b[38;5;241m=\u001b[39m(\u001b[38;5;241m0\u001b[39m, \u001b[38;5;28mlen\u001b[39m(\u001b[43mtrainset_no_aug\u001b[49m)\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m))\n\u001b[1;32m      2\u001b[0m \n\u001b[1;32m      3\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mshow_sample\u001b[39m(index\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m):\n\u001b[1;32m      4\u001b[0m     image, target, filename \u001b[38;5;241m=\u001b[39m trainset_no_aug[index]\n\u001b[1;32m      5\u001b[0m     image\u001b[38;5;241m=\u001b[39mimage\u001b[38;5;241m.\u001b[39mpermute(\u001b[38;5;241m1\u001b[39m,\u001b[38;5;241m2\u001b[39m,\u001b[38;5;241m0\u001b[39m)\u001b[38;5;241m.\u001b[39mnumpy()\n",
      "\u001b[0;31mNameError\u001b[0m: name 'trainset_no_aug' is not defined"
     ]
    }
   ],
   "source": [
    "@interact(index=(0, len(trainset_no_aug)-1))\n",
    "\n",
    "def show_sample(index=0):\n",
    "    image, target, filename = trainset_no_aug[index]\n",
    "    image=image.permute(1,2,0).numpy()\n",
    "    img_H, img_W, _ = image.shape\n",
    "    print(filename)\n",
    "    print(image.shape)\n",
    "#     print(image)\n",
    "\n",
    "#     bboxes = target['boxes']\n",
    "#     class_ids = target[\"labels\"]\n",
    "    \n",
    "    ###\n",
    "    bboxes = target[:, 0:4]\n",
    "    class_ids = target[:, 4]\n",
    "    ###\n",
    "    bboxes[:, [0,2]] *= img_W\n",
    "    bboxes[:, [1,3]] *= img_H\n",
    "\n",
    "    canvas = visualize(image, bboxes, class_ids)\n",
    "    plt.figure(figsize=(6,6))\n",
    "    plt.imshow(canvas)\n",
    "    plt.axis('off')\n",
    "    plt.show()\n",
    "\n",
    "# show_sample()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "5e341d7c",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'trainset_yes_aug' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[8], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[38;5;129m@interact\u001b[39m(index\u001b[38;5;241m=\u001b[39m(\u001b[38;5;241m0\u001b[39m, \u001b[38;5;28mlen\u001b[39m(\u001b[43mtrainset_yes_aug\u001b[49m)\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m))\n\u001b[1;32m      2\u001b[0m \n\u001b[1;32m      3\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mshow_sample\u001b[39m(index\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m):\n\u001b[1;32m      4\u001b[0m     image, target, filename \u001b[38;5;241m=\u001b[39m trainset_yes_aug[index]\n\u001b[1;32m      5\u001b[0m     image\u001b[38;5;241m=\u001b[39mimage\u001b[38;5;241m.\u001b[39mpermute(\u001b[38;5;241m1\u001b[39m,\u001b[38;5;241m2\u001b[39m,\u001b[38;5;241m0\u001b[39m)\u001b[38;5;241m.\u001b[39mnumpy()\n",
      "\u001b[0;31mNameError\u001b[0m: name 'trainset_yes_aug' is not defined"
     ]
    }
   ],
   "source": [
    "@interact(index=(0, len(trainset_yes_aug)-1))\n",
    "\n",
    "def show_sample(index=0):\n",
    "    image, target, filename = trainset_yes_aug[index]\n",
    "    image=image.permute(1,2,0).numpy()\n",
    "    img_H, img_W, _ = image.shape\n",
    "    print(filename)\n",
    "    print(image.shape)\n",
    "#     print(image)\n",
    "\n",
    "#     bboxes = target['boxes']\n",
    "#     class_ids = target[\"labels\"]\n",
    "    ###\n",
    "    bboxes = target[:, 0:4]\n",
    "    class_ids = target[:, 4]\n",
    "    ###\n",
    "    bboxes[:, [0,2]] *= img_W\n",
    "    bboxes[:, [1,3]] *= img_H\n",
    "    print(bboxes)\n",
    "\n",
    "    canvas = visualize(image, bboxes, class_ids)\n",
    "    plt.figure(figsize=(6,6))\n",
    "    plt.imshow(canvas)\n",
    "    plt.axis('off')\n",
    "    plt.show()\n",
    "\n",
    "# show_sample()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f151003",
   "metadata": {},
   "source": [
    "## Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "729f2964",
   "metadata": {},
   "outputs": [],
   "source": [
    "class YOLO_SWIN(nn.Module):\n",
    "    def __init__(self, num_classes):\n",
    "        super().__init__()\n",
    "\n",
    "        self.num_classes = num_classes\n",
    "        self.num_bboxes = 2\n",
    "        self.grid_size = 7\n",
    "\n",
    "#         resnet18 = torchvision.models.resnet18(pretrained = True)\n",
    "        swin=torchvision.models.swin_v2_t(weights='IMAGENET1K_V1')\n",
    "        layers = [m for m in swin.children()] #Resnet에서 Yolo에서 가져올수 있을만한 layer만 선별적으로 가져오기 위해서\n",
    "\n",
    "        # 기존 Resnet18의 layer들중에서 맨 뒤에 두개만 제외하고 다 가져와서 Backbone으로 사용\n",
    "        self.backbone = nn.Sequential(*layers[:-3]) \n",
    "        self.head = nn.Sequential(\n",
    "                nn.Conv2d(in_channels=768, out_channels=1024, kernel_size=1, padding=0,bias=False),\n",
    "                nn.BatchNorm2d(1024),\n",
    "                nn.ReLU(inplace=True),\n",
    "                nn.Conv2d(in_channels=1024, out_channels=1024, kernel_size=3, padding=1,bias=False),\n",
    "                nn.BatchNorm2d(1024),\n",
    "                nn.ReLU(inplace=True),\n",
    "                nn.Conv2d(in_channels=1024, out_channels=1024, kernel_size=3, padding=1,bias=False),\n",
    "                nn.BatchNorm2d(1024),\n",
    "                nn.ReLU(inplace=True),\n",
    "                nn.Conv2d(in_channels=1024, out_channels=1024, kernel_size=3, padding=1,bias=False),\n",
    "                nn.BatchNorm2d(1024),\n",
    "                nn.ReLU(inplace=True),\n",
    "\n",
    "                nn.Conv2d(in_channels=1024, out_channels=(4+1)*self.num_bboxes+num_classes, kernel_size=1, padding=0, bias=False),\n",
    "                nn.AdaptiveAvgPool2d(output_size=(self.grid_size, self.grid_size))\n",
    "            )\n",
    "\n",
    "    def forward(self, x):\n",
    "        out = self.backbone(x)\n",
    "        # out = self.neck(out)\n",
    "        out = self.head(out) # input (batch, 3, 448, 448) -> output feature (batch, 12, 7, 7)\n",
    "        return out\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b0a6eb83",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "YOLO_SWIN(\n",
       "  (backbone): Sequential(\n",
       "    (0): Sequential(\n",
       "      (0): Sequential(\n",
       "        (0): Conv2d(3, 96, kernel_size=(4, 4), stride=(4, 4))\n",
       "        (1): Permute()\n",
       "        (2): LayerNorm((96,), eps=1e-05, elementwise_affine=True)\n",
       "      )\n",
       "      (1): Sequential(\n",
       "        (0): SwinTransformerBlockV2(\n",
       "          (norm1): LayerNorm((96,), eps=1e-05, elementwise_affine=True)\n",
       "          (attn): ShiftedWindowAttentionV2(\n",
       "            (qkv): Linear(in_features=96, out_features=288, bias=True)\n",
       "            (proj): Linear(in_features=96, out_features=96, bias=True)\n",
       "            (cpb_mlp): Sequential(\n",
       "              (0): Linear(in_features=2, out_features=512, bias=True)\n",
       "              (1): ReLU(inplace=True)\n",
       "              (2): Linear(in_features=512, out_features=3, bias=False)\n",
       "            )\n",
       "          )\n",
       "          (stochastic_depth): StochasticDepth(p=0.0, mode=row)\n",
       "          (norm2): LayerNorm((96,), eps=1e-05, elementwise_affine=True)\n",
       "          (mlp): MLP(\n",
       "            (0): Linear(in_features=96, out_features=384, bias=True)\n",
       "            (1): GELU(approximate='none')\n",
       "            (2): Dropout(p=0.0, inplace=False)\n",
       "            (3): Linear(in_features=384, out_features=96, bias=True)\n",
       "            (4): Dropout(p=0.0, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (1): SwinTransformerBlockV2(\n",
       "          (norm1): LayerNorm((96,), eps=1e-05, elementwise_affine=True)\n",
       "          (attn): ShiftedWindowAttentionV2(\n",
       "            (qkv): Linear(in_features=96, out_features=288, bias=True)\n",
       "            (proj): Linear(in_features=96, out_features=96, bias=True)\n",
       "            (cpb_mlp): Sequential(\n",
       "              (0): Linear(in_features=2, out_features=512, bias=True)\n",
       "              (1): ReLU(inplace=True)\n",
       "              (2): Linear(in_features=512, out_features=3, bias=False)\n",
       "            )\n",
       "          )\n",
       "          (stochastic_depth): StochasticDepth(p=0.018181818181818184, mode=row)\n",
       "          (norm2): LayerNorm((96,), eps=1e-05, elementwise_affine=True)\n",
       "          (mlp): MLP(\n",
       "            (0): Linear(in_features=96, out_features=384, bias=True)\n",
       "            (1): GELU(approximate='none')\n",
       "            (2): Dropout(p=0.0, inplace=False)\n",
       "            (3): Linear(in_features=384, out_features=96, bias=True)\n",
       "            (4): Dropout(p=0.0, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (2): PatchMergingV2(\n",
       "        (reduction): Linear(in_features=384, out_features=192, bias=False)\n",
       "        (norm): LayerNorm((192,), eps=1e-05, elementwise_affine=True)\n",
       "      )\n",
       "      (3): Sequential(\n",
       "        (0): SwinTransformerBlockV2(\n",
       "          (norm1): LayerNorm((192,), eps=1e-05, elementwise_affine=True)\n",
       "          (attn): ShiftedWindowAttentionV2(\n",
       "            (qkv): Linear(in_features=192, out_features=576, bias=True)\n",
       "            (proj): Linear(in_features=192, out_features=192, bias=True)\n",
       "            (cpb_mlp): Sequential(\n",
       "              (0): Linear(in_features=2, out_features=512, bias=True)\n",
       "              (1): ReLU(inplace=True)\n",
       "              (2): Linear(in_features=512, out_features=6, bias=False)\n",
       "            )\n",
       "          )\n",
       "          (stochastic_depth): StochasticDepth(p=0.03636363636363637, mode=row)\n",
       "          (norm2): LayerNorm((192,), eps=1e-05, elementwise_affine=True)\n",
       "          (mlp): MLP(\n",
       "            (0): Linear(in_features=192, out_features=768, bias=True)\n",
       "            (1): GELU(approximate='none')\n",
       "            (2): Dropout(p=0.0, inplace=False)\n",
       "            (3): Linear(in_features=768, out_features=192, bias=True)\n",
       "            (4): Dropout(p=0.0, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (1): SwinTransformerBlockV2(\n",
       "          (norm1): LayerNorm((192,), eps=1e-05, elementwise_affine=True)\n",
       "          (attn): ShiftedWindowAttentionV2(\n",
       "            (qkv): Linear(in_features=192, out_features=576, bias=True)\n",
       "            (proj): Linear(in_features=192, out_features=192, bias=True)\n",
       "            (cpb_mlp): Sequential(\n",
       "              (0): Linear(in_features=2, out_features=512, bias=True)\n",
       "              (1): ReLU(inplace=True)\n",
       "              (2): Linear(in_features=512, out_features=6, bias=False)\n",
       "            )\n",
       "          )\n",
       "          (stochastic_depth): StochasticDepth(p=0.05454545454545456, mode=row)\n",
       "          (norm2): LayerNorm((192,), eps=1e-05, elementwise_affine=True)\n",
       "          (mlp): MLP(\n",
       "            (0): Linear(in_features=192, out_features=768, bias=True)\n",
       "            (1): GELU(approximate='none')\n",
       "            (2): Dropout(p=0.0, inplace=False)\n",
       "            (3): Linear(in_features=768, out_features=192, bias=True)\n",
       "            (4): Dropout(p=0.0, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (4): PatchMergingV2(\n",
       "        (reduction): Linear(in_features=768, out_features=384, bias=False)\n",
       "        (norm): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n",
       "      )\n",
       "      (5): Sequential(\n",
       "        (0): SwinTransformerBlockV2(\n",
       "          (norm1): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n",
       "          (attn): ShiftedWindowAttentionV2(\n",
       "            (qkv): Linear(in_features=384, out_features=1152, bias=True)\n",
       "            (proj): Linear(in_features=384, out_features=384, bias=True)\n",
       "            (cpb_mlp): Sequential(\n",
       "              (0): Linear(in_features=2, out_features=512, bias=True)\n",
       "              (1): ReLU(inplace=True)\n",
       "              (2): Linear(in_features=512, out_features=12, bias=False)\n",
       "            )\n",
       "          )\n",
       "          (stochastic_depth): StochasticDepth(p=0.07272727272727274, mode=row)\n",
       "          (norm2): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n",
       "          (mlp): MLP(\n",
       "            (0): Linear(in_features=384, out_features=1536, bias=True)\n",
       "            (1): GELU(approximate='none')\n",
       "            (2): Dropout(p=0.0, inplace=False)\n",
       "            (3): Linear(in_features=1536, out_features=384, bias=True)\n",
       "            (4): Dropout(p=0.0, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (1): SwinTransformerBlockV2(\n",
       "          (norm1): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n",
       "          (attn): ShiftedWindowAttentionV2(\n",
       "            (qkv): Linear(in_features=384, out_features=1152, bias=True)\n",
       "            (proj): Linear(in_features=384, out_features=384, bias=True)\n",
       "            (cpb_mlp): Sequential(\n",
       "              (0): Linear(in_features=2, out_features=512, bias=True)\n",
       "              (1): ReLU(inplace=True)\n",
       "              (2): Linear(in_features=512, out_features=12, bias=False)\n",
       "            )\n",
       "          )\n",
       "          (stochastic_depth): StochasticDepth(p=0.09090909090909091, mode=row)\n",
       "          (norm2): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n",
       "          (mlp): MLP(\n",
       "            (0): Linear(in_features=384, out_features=1536, bias=True)\n",
       "            (1): GELU(approximate='none')\n",
       "            (2): Dropout(p=0.0, inplace=False)\n",
       "            (3): Linear(in_features=1536, out_features=384, bias=True)\n",
       "            (4): Dropout(p=0.0, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (2): SwinTransformerBlockV2(\n",
       "          (norm1): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n",
       "          (attn): ShiftedWindowAttentionV2(\n",
       "            (qkv): Linear(in_features=384, out_features=1152, bias=True)\n",
       "            (proj): Linear(in_features=384, out_features=384, bias=True)\n",
       "            (cpb_mlp): Sequential(\n",
       "              (0): Linear(in_features=2, out_features=512, bias=True)\n",
       "              (1): ReLU(inplace=True)\n",
       "              (2): Linear(in_features=512, out_features=12, bias=False)\n",
       "            )\n",
       "          )\n",
       "          (stochastic_depth): StochasticDepth(p=0.10909090909090911, mode=row)\n",
       "          (norm2): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n",
       "          (mlp): MLP(\n",
       "            (0): Linear(in_features=384, out_features=1536, bias=True)\n",
       "            (1): GELU(approximate='none')\n",
       "            (2): Dropout(p=0.0, inplace=False)\n",
       "            (3): Linear(in_features=1536, out_features=384, bias=True)\n",
       "            (4): Dropout(p=0.0, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (3): SwinTransformerBlockV2(\n",
       "          (norm1): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n",
       "          (attn): ShiftedWindowAttentionV2(\n",
       "            (qkv): Linear(in_features=384, out_features=1152, bias=True)\n",
       "            (proj): Linear(in_features=384, out_features=384, bias=True)\n",
       "            (cpb_mlp): Sequential(\n",
       "              (0): Linear(in_features=2, out_features=512, bias=True)\n",
       "              (1): ReLU(inplace=True)\n",
       "              (2): Linear(in_features=512, out_features=12, bias=False)\n",
       "            )\n",
       "          )\n",
       "          (stochastic_depth): StochasticDepth(p=0.1272727272727273, mode=row)\n",
       "          (norm2): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n",
       "          (mlp): MLP(\n",
       "            (0): Linear(in_features=384, out_features=1536, bias=True)\n",
       "            (1): GELU(approximate='none')\n",
       "            (2): Dropout(p=0.0, inplace=False)\n",
       "            (3): Linear(in_features=1536, out_features=384, bias=True)\n",
       "            (4): Dropout(p=0.0, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (4): SwinTransformerBlockV2(\n",
       "          (norm1): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n",
       "          (attn): ShiftedWindowAttentionV2(\n",
       "            (qkv): Linear(in_features=384, out_features=1152, bias=True)\n",
       "            (proj): Linear(in_features=384, out_features=384, bias=True)\n",
       "            (cpb_mlp): Sequential(\n",
       "              (0): Linear(in_features=2, out_features=512, bias=True)\n",
       "              (1): ReLU(inplace=True)\n",
       "              (2): Linear(in_features=512, out_features=12, bias=False)\n",
       "            )\n",
       "          )\n",
       "          (stochastic_depth): StochasticDepth(p=0.14545454545454548, mode=row)\n",
       "          (norm2): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n",
       "          (mlp): MLP(\n",
       "            (0): Linear(in_features=384, out_features=1536, bias=True)\n",
       "            (1): GELU(approximate='none')\n",
       "            (2): Dropout(p=0.0, inplace=False)\n",
       "            (3): Linear(in_features=1536, out_features=384, bias=True)\n",
       "            (4): Dropout(p=0.0, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (5): SwinTransformerBlockV2(\n",
       "          (norm1): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n",
       "          (attn): ShiftedWindowAttentionV2(\n",
       "            (qkv): Linear(in_features=384, out_features=1152, bias=True)\n",
       "            (proj): Linear(in_features=384, out_features=384, bias=True)\n",
       "            (cpb_mlp): Sequential(\n",
       "              (0): Linear(in_features=2, out_features=512, bias=True)\n",
       "              (1): ReLU(inplace=True)\n",
       "              (2): Linear(in_features=512, out_features=12, bias=False)\n",
       "            )\n",
       "          )\n",
       "          (stochastic_depth): StochasticDepth(p=0.16363636363636364, mode=row)\n",
       "          (norm2): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n",
       "          (mlp): MLP(\n",
       "            (0): Linear(in_features=384, out_features=1536, bias=True)\n",
       "            (1): GELU(approximate='none')\n",
       "            (2): Dropout(p=0.0, inplace=False)\n",
       "            (3): Linear(in_features=1536, out_features=384, bias=True)\n",
       "            (4): Dropout(p=0.0, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (6): PatchMergingV2(\n",
       "        (reduction): Linear(in_features=1536, out_features=768, bias=False)\n",
       "        (norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "      )\n",
       "      (7): Sequential(\n",
       "        (0): SwinTransformerBlockV2(\n",
       "          (norm1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "          (attn): ShiftedWindowAttentionV2(\n",
       "            (qkv): Linear(in_features=768, out_features=2304, bias=True)\n",
       "            (proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (cpb_mlp): Sequential(\n",
       "              (0): Linear(in_features=2, out_features=512, bias=True)\n",
       "              (1): ReLU(inplace=True)\n",
       "              (2): Linear(in_features=512, out_features=24, bias=False)\n",
       "            )\n",
       "          )\n",
       "          (stochastic_depth): StochasticDepth(p=0.18181818181818182, mode=row)\n",
       "          (norm2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "          (mlp): MLP(\n",
       "            (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (1): GELU(approximate='none')\n",
       "            (2): Dropout(p=0.0, inplace=False)\n",
       "            (3): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (4): Dropout(p=0.0, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (1): SwinTransformerBlockV2(\n",
       "          (norm1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "          (attn): ShiftedWindowAttentionV2(\n",
       "            (qkv): Linear(in_features=768, out_features=2304, bias=True)\n",
       "            (proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (cpb_mlp): Sequential(\n",
       "              (0): Linear(in_features=2, out_features=512, bias=True)\n",
       "              (1): ReLU(inplace=True)\n",
       "              (2): Linear(in_features=512, out_features=24, bias=False)\n",
       "            )\n",
       "          )\n",
       "          (stochastic_depth): StochasticDepth(p=0.2, mode=row)\n",
       "          (norm2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "          (mlp): MLP(\n",
       "            (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (1): GELU(approximate='none')\n",
       "            (2): Dropout(p=0.0, inplace=False)\n",
       "            (3): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (4): Dropout(p=0.0, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "    (2): Permute()\n",
       "  )\n",
       "  (head): Sequential(\n",
       "    (0): Conv2d(768, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "    (1): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU(inplace=True)\n",
       "    (3): Conv2d(1024, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "    (4): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (5): ReLU(inplace=True)\n",
       "    (6): Conv2d(1024, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "    (7): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (8): ReLU(inplace=True)\n",
       "    (9): Conv2d(1024, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "    (10): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (11): ReLU(inplace=True)\n",
       "    (12): Conv2d(1024, 12, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "    (13): AdaptiveAvgPool2d(output_size=(7, 7))\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "NUM_CLASSES = 2\n",
    "model = YOLO_SWIN(num_classes=NUM_CLASSES)\n",
    "model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "361cde55",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------------------------------\n",
      "        Layer (type)               Output Shape         Param #\n",
      "================================================================\n",
      "            Conv2d-1         [-1, 96, 112, 112]           4,704\n",
      "           Permute-2         [-1, 112, 112, 96]               0\n",
      "         LayerNorm-3         [-1, 112, 112, 96]             192\n",
      "            Linear-4          [-1, 15, 15, 512]           1,536\n",
      "              ReLU-5          [-1, 15, 15, 512]               0\n",
      "            Linear-6            [-1, 15, 15, 3]           1,536\n",
      "ShiftedWindowAttentionV2-7         [-1, 112, 112, 96]               0\n",
      "         LayerNorm-8         [-1, 112, 112, 96]             192\n",
      "   StochasticDepth-9         [-1, 112, 112, 96]               0\n",
      "           Linear-10        [-1, 112, 112, 384]          37,248\n",
      "             GELU-11        [-1, 112, 112, 384]               0\n",
      "          Dropout-12        [-1, 112, 112, 384]               0\n",
      "           Linear-13         [-1, 112, 112, 96]          36,960\n",
      "          Dropout-14         [-1, 112, 112, 96]               0\n",
      "        LayerNorm-15         [-1, 112, 112, 96]             192\n",
      "  StochasticDepth-16         [-1, 112, 112, 96]               0\n",
      "SwinTransformerBlockV2-17         [-1, 112, 112, 96]               0\n",
      "           Linear-18          [-1, 15, 15, 512]           1,536\n",
      "             ReLU-19          [-1, 15, 15, 512]               0\n",
      "           Linear-20            [-1, 15, 15, 3]           1,536\n",
      "ShiftedWindowAttentionV2-21         [-1, 112, 112, 96]               0\n",
      "        LayerNorm-22         [-1, 112, 112, 96]             192\n",
      "  StochasticDepth-23         [-1, 112, 112, 96]               0\n",
      "           Linear-24        [-1, 112, 112, 384]          37,248\n",
      "             GELU-25        [-1, 112, 112, 384]               0\n",
      "          Dropout-26        [-1, 112, 112, 384]               0\n",
      "           Linear-27         [-1, 112, 112, 96]          36,960\n",
      "          Dropout-28         [-1, 112, 112, 96]               0\n",
      "        LayerNorm-29         [-1, 112, 112, 96]             192\n",
      "  StochasticDepth-30         [-1, 112, 112, 96]               0\n",
      "SwinTransformerBlockV2-31         [-1, 112, 112, 96]               0\n",
      "           Linear-32          [-1, 56, 56, 192]          73,728\n",
      "        LayerNorm-33          [-1, 56, 56, 192]             384\n",
      "   PatchMergingV2-34          [-1, 56, 56, 192]               0\n",
      "           Linear-35          [-1, 15, 15, 512]           1,536\n",
      "             ReLU-36          [-1, 15, 15, 512]               0\n",
      "           Linear-37            [-1, 15, 15, 6]           3,072\n",
      "ShiftedWindowAttentionV2-38          [-1, 56, 56, 192]               0\n",
      "        LayerNorm-39          [-1, 56, 56, 192]             384\n",
      "  StochasticDepth-40          [-1, 56, 56, 192]               0\n",
      "           Linear-41          [-1, 56, 56, 768]         148,224\n",
      "             GELU-42          [-1, 56, 56, 768]               0\n",
      "          Dropout-43          [-1, 56, 56, 768]               0\n",
      "           Linear-44          [-1, 56, 56, 192]         147,648\n",
      "          Dropout-45          [-1, 56, 56, 192]               0\n",
      "        LayerNorm-46          [-1, 56, 56, 192]             384\n",
      "  StochasticDepth-47          [-1, 56, 56, 192]               0\n",
      "SwinTransformerBlockV2-48          [-1, 56, 56, 192]               0\n",
      "           Linear-49          [-1, 15, 15, 512]           1,536\n",
      "             ReLU-50          [-1, 15, 15, 512]               0\n",
      "           Linear-51            [-1, 15, 15, 6]           3,072\n",
      "ShiftedWindowAttentionV2-52          [-1, 56, 56, 192]               0\n",
      "        LayerNorm-53          [-1, 56, 56, 192]             384\n",
      "  StochasticDepth-54          [-1, 56, 56, 192]               0\n",
      "           Linear-55          [-1, 56, 56, 768]         148,224\n",
      "             GELU-56          [-1, 56, 56, 768]               0\n",
      "          Dropout-57          [-1, 56, 56, 768]               0\n",
      "           Linear-58          [-1, 56, 56, 192]         147,648\n",
      "          Dropout-59          [-1, 56, 56, 192]               0\n",
      "        LayerNorm-60          [-1, 56, 56, 192]             384\n",
      "  StochasticDepth-61          [-1, 56, 56, 192]               0\n",
      "SwinTransformerBlockV2-62          [-1, 56, 56, 192]               0\n",
      "           Linear-63          [-1, 28, 28, 384]         294,912\n",
      "        LayerNorm-64          [-1, 28, 28, 384]             768\n",
      "   PatchMergingV2-65          [-1, 28, 28, 384]               0\n",
      "           Linear-66          [-1, 15, 15, 512]           1,536\n",
      "             ReLU-67          [-1, 15, 15, 512]               0\n",
      "           Linear-68           [-1, 15, 15, 12]           6,144\n",
      "ShiftedWindowAttentionV2-69          [-1, 28, 28, 384]               0\n",
      "        LayerNorm-70          [-1, 28, 28, 384]             768\n",
      "  StochasticDepth-71          [-1, 28, 28, 384]               0\n",
      "           Linear-72         [-1, 28, 28, 1536]         591,360\n",
      "             GELU-73         [-1, 28, 28, 1536]               0\n",
      "          Dropout-74         [-1, 28, 28, 1536]               0\n",
      "           Linear-75          [-1, 28, 28, 384]         590,208\n",
      "          Dropout-76          [-1, 28, 28, 384]               0\n",
      "        LayerNorm-77          [-1, 28, 28, 384]             768\n",
      "  StochasticDepth-78          [-1, 28, 28, 384]               0\n",
      "SwinTransformerBlockV2-79          [-1, 28, 28, 384]               0\n",
      "           Linear-80          [-1, 15, 15, 512]           1,536\n",
      "             ReLU-81          [-1, 15, 15, 512]               0\n",
      "           Linear-82           [-1, 15, 15, 12]           6,144\n",
      "ShiftedWindowAttentionV2-83          [-1, 28, 28, 384]               0\n",
      "        LayerNorm-84          [-1, 28, 28, 384]             768\n",
      "  StochasticDepth-85          [-1, 28, 28, 384]               0\n",
      "           Linear-86         [-1, 28, 28, 1536]         591,360\n",
      "             GELU-87         [-1, 28, 28, 1536]               0\n",
      "          Dropout-88         [-1, 28, 28, 1536]               0\n",
      "           Linear-89          [-1, 28, 28, 384]         590,208\n",
      "          Dropout-90          [-1, 28, 28, 384]               0\n",
      "        LayerNorm-91          [-1, 28, 28, 384]             768\n",
      "  StochasticDepth-92          [-1, 28, 28, 384]               0\n",
      "SwinTransformerBlockV2-93          [-1, 28, 28, 384]               0\n",
      "           Linear-94          [-1, 15, 15, 512]           1,536\n",
      "             ReLU-95          [-1, 15, 15, 512]               0\n",
      "           Linear-96           [-1, 15, 15, 12]           6,144\n",
      "ShiftedWindowAttentionV2-97          [-1, 28, 28, 384]               0\n",
      "        LayerNorm-98          [-1, 28, 28, 384]             768\n",
      "  StochasticDepth-99          [-1, 28, 28, 384]               0\n",
      "          Linear-100         [-1, 28, 28, 1536]         591,360\n",
      "            GELU-101         [-1, 28, 28, 1536]               0\n",
      "         Dropout-102         [-1, 28, 28, 1536]               0\n",
      "          Linear-103          [-1, 28, 28, 384]         590,208\n",
      "         Dropout-104          [-1, 28, 28, 384]               0\n",
      "       LayerNorm-105          [-1, 28, 28, 384]             768\n",
      " StochasticDepth-106          [-1, 28, 28, 384]               0\n",
      "SwinTransformerBlockV2-107          [-1, 28, 28, 384]               0\n",
      "          Linear-108          [-1, 15, 15, 512]           1,536\n",
      "            ReLU-109          [-1, 15, 15, 512]               0\n",
      "          Linear-110           [-1, 15, 15, 12]           6,144\n",
      "ShiftedWindowAttentionV2-111          [-1, 28, 28, 384]               0\n",
      "       LayerNorm-112          [-1, 28, 28, 384]             768\n",
      " StochasticDepth-113          [-1, 28, 28, 384]               0\n",
      "          Linear-114         [-1, 28, 28, 1536]         591,360\n",
      "            GELU-115         [-1, 28, 28, 1536]               0\n",
      "         Dropout-116         [-1, 28, 28, 1536]               0\n",
      "          Linear-117          [-1, 28, 28, 384]         590,208\n",
      "         Dropout-118          [-1, 28, 28, 384]               0\n",
      "       LayerNorm-119          [-1, 28, 28, 384]             768\n",
      " StochasticDepth-120          [-1, 28, 28, 384]               0\n",
      "SwinTransformerBlockV2-121          [-1, 28, 28, 384]               0\n",
      "          Linear-122          [-1, 15, 15, 512]           1,536\n",
      "            ReLU-123          [-1, 15, 15, 512]               0\n",
      "          Linear-124           [-1, 15, 15, 12]           6,144\n",
      "ShiftedWindowAttentionV2-125          [-1, 28, 28, 384]               0\n",
      "       LayerNorm-126          [-1, 28, 28, 384]             768\n",
      " StochasticDepth-127          [-1, 28, 28, 384]               0\n",
      "          Linear-128         [-1, 28, 28, 1536]         591,360\n",
      "            GELU-129         [-1, 28, 28, 1536]               0\n",
      "         Dropout-130         [-1, 28, 28, 1536]               0\n",
      "          Linear-131          [-1, 28, 28, 384]         590,208\n",
      "         Dropout-132          [-1, 28, 28, 384]               0\n",
      "       LayerNorm-133          [-1, 28, 28, 384]             768\n",
      " StochasticDepth-134          [-1, 28, 28, 384]               0\n",
      "SwinTransformerBlockV2-135          [-1, 28, 28, 384]               0\n",
      "          Linear-136          [-1, 15, 15, 512]           1,536\n",
      "            ReLU-137          [-1, 15, 15, 512]               0\n",
      "          Linear-138           [-1, 15, 15, 12]           6,144\n",
      "ShiftedWindowAttentionV2-139          [-1, 28, 28, 384]               0\n",
      "       LayerNorm-140          [-1, 28, 28, 384]             768\n",
      " StochasticDepth-141          [-1, 28, 28, 384]               0\n",
      "          Linear-142         [-1, 28, 28, 1536]         591,360\n",
      "            GELU-143         [-1, 28, 28, 1536]               0\n",
      "         Dropout-144         [-1, 28, 28, 1536]               0\n",
      "          Linear-145          [-1, 28, 28, 384]         590,208\n",
      "         Dropout-146          [-1, 28, 28, 384]               0\n",
      "       LayerNorm-147          [-1, 28, 28, 384]             768\n",
      " StochasticDepth-148          [-1, 28, 28, 384]               0\n",
      "SwinTransformerBlockV2-149          [-1, 28, 28, 384]               0\n",
      "          Linear-150          [-1, 14, 14, 768]       1,179,648\n",
      "       LayerNorm-151          [-1, 14, 14, 768]           1,536\n",
      "  PatchMergingV2-152          [-1, 14, 14, 768]               0\n",
      "          Linear-153          [-1, 15, 15, 512]           1,536\n",
      "            ReLU-154          [-1, 15, 15, 512]               0\n",
      "          Linear-155           [-1, 15, 15, 24]          12,288\n",
      "ShiftedWindowAttentionV2-156          [-1, 14, 14, 768]               0\n",
      "       LayerNorm-157          [-1, 14, 14, 768]           1,536\n",
      " StochasticDepth-158          [-1, 14, 14, 768]               0\n",
      "          Linear-159         [-1, 14, 14, 3072]       2,362,368\n",
      "            GELU-160         [-1, 14, 14, 3072]               0\n",
      "         Dropout-161         [-1, 14, 14, 3072]               0\n",
      "          Linear-162          [-1, 14, 14, 768]       2,360,064\n",
      "         Dropout-163          [-1, 14, 14, 768]               0\n",
      "       LayerNorm-164          [-1, 14, 14, 768]           1,536\n",
      " StochasticDepth-165          [-1, 14, 14, 768]               0\n",
      "SwinTransformerBlockV2-166          [-1, 14, 14, 768]               0\n",
      "          Linear-167          [-1, 15, 15, 512]           1,536\n",
      "            ReLU-168          [-1, 15, 15, 512]               0\n",
      "          Linear-169           [-1, 15, 15, 24]          12,288\n",
      "ShiftedWindowAttentionV2-170          [-1, 14, 14, 768]               0\n",
      "       LayerNorm-171          [-1, 14, 14, 768]           1,536\n",
      " StochasticDepth-172          [-1, 14, 14, 768]               0\n",
      "          Linear-173         [-1, 14, 14, 3072]       2,362,368\n",
      "            GELU-174         [-1, 14, 14, 3072]               0\n",
      "         Dropout-175         [-1, 14, 14, 3072]               0\n",
      "          Linear-176          [-1, 14, 14, 768]       2,360,064\n",
      "         Dropout-177          [-1, 14, 14, 768]               0\n",
      "       LayerNorm-178          [-1, 14, 14, 768]           1,536\n",
      " StochasticDepth-179          [-1, 14, 14, 768]               0\n",
      "SwinTransformerBlockV2-180          [-1, 14, 14, 768]               0\n",
      "       LayerNorm-181          [-1, 14, 14, 768]           1,536\n",
      "         Permute-182          [-1, 768, 14, 14]               0\n",
      "          Conv2d-183         [-1, 1024, 14, 14]         786,432\n",
      "     BatchNorm2d-184         [-1, 1024, 14, 14]           2,048\n",
      "            ReLU-185         [-1, 1024, 14, 14]               0\n",
      "          Conv2d-186         [-1, 1024, 14, 14]       9,437,184\n",
      "     BatchNorm2d-187         [-1, 1024, 14, 14]           2,048\n",
      "            ReLU-188         [-1, 1024, 14, 14]               0\n",
      "          Conv2d-189         [-1, 1024, 14, 14]       9,437,184\n",
      "     BatchNorm2d-190         [-1, 1024, 14, 14]           2,048\n",
      "            ReLU-191         [-1, 1024, 14, 14]               0\n",
      "          Conv2d-192         [-1, 1024, 14, 14]       9,437,184\n",
      "     BatchNorm2d-193         [-1, 1024, 14, 14]           2,048\n",
      "            ReLU-194         [-1, 1024, 14, 14]               0\n",
      "          Conv2d-195           [-1, 12, 14, 14]          12,288\n",
      "AdaptiveAvgPool2d-196             [-1, 12, 7, 7]               0\n",
      "================================================================\n",
      "Total params: 48,057,056\n",
      "Trainable params: 48,057,056\n",
      "Non-trainable params: 0\n",
      "----------------------------------------------------------------\n",
      "Input size (MB): 2.30\n",
      "Forward/backward pass size (MB): 966.52\n",
      "Params size (MB): 183.32\n",
      "Estimated Total Size (MB): 1152.14\n",
      "----------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "torchsummary.summary(model, (3,448,448))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "4cf3af4c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 12, 7, 7])\n"
     ]
    }
   ],
   "source": [
    "x = torch.randn(1, 3, 448, 448).to(device)\n",
    "with torch.no_grad():\n",
    "    y = model(x)\n",
    "print(y.shape)"
   ]
  },
  {
   "cell_type": "raw",
   "id": "f4c05720",
   "metadata": {
    "scrolled": true
   },
   "source": [
    "# data_dir = \"/content/drive/MyDrive/fastCamMedicalProj/DATASET/DATASET/Detection/\"\n",
    "BATCH_SIZE = 1\n",
    "\n",
    "# trainset = Detection_dataset(data_dir=data_dir, phase=\"train\", transformer=transformer)\n",
    "NECK_PATH = '/home/host_data/PET_data/Neck'\n",
    "BODY_PATH = '/home/host_data/PET_data/Body'\n",
    "trainset=PET_dataset(part='body',neck_dir=NECK_PATH,body_dir=BODY_PATH,phase='train', transformer=transformer)\n",
    "trainloader = DataLoader(trainset, batch_size=BATCH_SIZE, shuffle=False, collate_fn=collate_fn)\n",
    "\n",
    "model = YOLO_SWIN(num_classes=NUM_CLASSES)\n",
    "\n",
    "for index, batch in enumerate(trainloader):\n",
    "    images = batch[0]\n",
    "    targets = batch[1]\n",
    "    filenames = batch[2]\n",
    "    \n",
    "    predictions = model(images)\n",
    "    print(f\"filename:{filenames}, target:{targets}\")\n",
    "#     print(f\"{index}--input shape:{images.shape} -> output shape: {predictions.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8da970d7",
   "metadata": {},
   "source": [
    "# Loss func"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "3c66945c",
   "metadata": {},
   "outputs": [],
   "source": [
    "class YOLO_LOSS():\n",
    "    def __init__(self, num_classes, device, lambda_coord=5., lambda_noobj=0.5):\n",
    "        self.num_classes = num_classes\n",
    "        self.device = device\n",
    "        self.grid_size = 7\n",
    "        self.lambda_coord = lambda_coord\n",
    "        self.lambda_noobj = lambda_noobj\n",
    "        self.mse_loss = nn.MSELoss(reduction=\"sum\")\n",
    "\n",
    "    def __call__(self, predictions, targets):\n",
    "        self.batch_size, _, _, _ = predictions.shape\n",
    "        groundtruths = self.build_batch_target_grid(targets)\n",
    "        groundtruths = groundtruths.to(self.device)\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            iou1 = self.get_IoU(predictions[:, 1:5, ...], groundtruths[:, 1:5, ...])\n",
    "            iou2 = self.get_IoU(predictions[:, 6:10, ...], groundtruths[:, 1:5, ...])\n",
    "\n",
    "        ious = torch.stack([iou1, iou2], dim=1)\n",
    "        max_iou, best_box = ious.max(dim=1, keepdim=True)\n",
    "        max_iou = torch.cat([max_iou, max_iou], dim=1)\n",
    "        best_box = torch.cat([best_box.eq(0), best_box.eq(1)], dim=1)\n",
    "\n",
    "        predictions_ = predictions[:, :5*2, ...].reshape(self.batch_size, 2, 5, self.grid_size, self.grid_size)\n",
    "        obj_pred = predictions_[:, :, 0, ...]\n",
    "        xy_pred = predictions_[:, :, 1:3, ...]\n",
    "        wh_pred = predictions_[:, :, 3:5, ...]\n",
    "        cls_pred = predictions[:, 5*2:, ...]\n",
    "\n",
    "        groundtruths_ = groundtruths[:, :5, ...].reshape(self.batch_size, 1, 5, self.grid_size, self.grid_size)\n",
    "        obj_target = groundtruths_[:, :, 0, ...]\n",
    "        xy_target = groundtruths_[:, :, 1:3, ...]\n",
    "        wh_target= groundtruths_[:, :, 3:5, ...]\n",
    "        cls_target = groundtruths[:, 5:, ...]\n",
    "        \n",
    "        positive = obj_target * best_box\n",
    "\n",
    "        obj_loss = self.mse_loss(positive * obj_pred, positive * ious)\n",
    "        noobj_loss = self.mse_loss((1 - positive) * obj_pred, ious*0)\n",
    "        xy_loss = self.mse_loss(positive.unsqueeze(dim=2) * xy_pred, positive.unsqueeze(dim=2) * xy_target)\n",
    "        wh_loss = self.mse_loss(positive.unsqueeze(dim=2) * (wh_pred.sign() * (wh_pred.abs() + 1e-8).sqrt()),\n",
    "                           positive.unsqueeze(dim=2) * (wh_target + 1e-8).sqrt())\n",
    "        cls_loss = self.mse_loss(obj_target * cls_pred, cls_target)\n",
    "        \n",
    "        obj_loss /= self.batch_size\n",
    "        noobj_loss /= self.batch_size\n",
    "        bbox_loss = (xy_loss+wh_loss) / self.batch_size\n",
    "        cls_loss /= self.batch_size\n",
    "        \n",
    "        total_loss = obj_loss + self.lambda_noobj*noobj_loss + self.lambda_coord*bbox_loss + cls_loss\n",
    "        return total_loss, (obj_loss.item(), noobj_loss.item(), bbox_loss.item(), cls_loss.item())\n",
    "    \n",
    "    def build_target_grid(self, target):\n",
    "        target_grid = torch.zeros((1+4+self.num_classes, self.grid_size, self.grid_size), device=self.device)\n",
    "\n",
    "        for gt in target:\n",
    "            xc, yc, w, h, cls_id = gt\n",
    "            xn = (xc % (1/self.grid_size))\n",
    "            yn = (yc % (1/self.grid_size))\n",
    "            cls_id = int(cls_id)\n",
    "\n",
    "            i_grid = int(xc * self.grid_size)\n",
    "            j_grid = int(yc * self.grid_size)\n",
    "            target_grid[0, j_grid, i_grid] = 1\n",
    "            target_grid[1:5, j_grid, i_grid] = torch.Tensor([xn,yn,w,h])\n",
    "#             print(5+cls_id, j_grid, i_grid)\n",
    "            target_grid[5+cls_id, j_grid, i_grid] = 1\n",
    "\n",
    "        return target_grid\n",
    "    \n",
    "    def build_batch_target_grid(self, targets):\n",
    "        target_grid_batch = torch.stack([self.build_target_grid(target) for target in targets], dim=0)\n",
    "        return target_grid_batch\n",
    "    \n",
    "    def get_IoU(self, cbox1, cbox2):\n",
    "        box1 = self.xywh_to_xyxy(cbox1)\n",
    "        box2 = self.xywh_to_xyxy(cbox2)\n",
    "\n",
    "        x1 = torch.max(box1[:, 0, ...], box2[:, 0, ...])\n",
    "        y1 = torch.max(box1[:, 1, ...], box2[:, 1, ...])\n",
    "        x2 = torch.min(box1[:, 2, ...], box2[:, 2, ...])\n",
    "        y2 = torch.min(box1[:, 3, ...], box2[:, 3, ...])\n",
    "\n",
    "        intersection = (x2-x1).clamp(min=0) * (y2-y1).clamp(min=0)\n",
    "        union = abs(cbox1[:, 2, ...]*cbox1[:, 3, ...]) + \\\n",
    "                abs(cbox2[:, 2, ...]*cbox2[:, 3, ...]) - intersection\n",
    "\n",
    "        intersection[intersection.gt(0)] = intersection[intersection.gt(0)] / union[intersection.gt(0)]\n",
    "        return intersection\n",
    "    \n",
    "    def generate_xy_normed_grid(self):\n",
    "        y_offset, x_offset = torch.meshgrid(torch.arange(self.grid_size), torch.arange(self.grid_size))\n",
    "        xy_grid = torch.stack([x_offset, y_offset], dim=0)\n",
    "        xy_normed_grid = xy_grid / self.grid_size\n",
    "        return xy_normed_grid.to(self.device)\n",
    "\n",
    "    def xywh_to_xyxy(self, bboxes):\n",
    "        xy_normed_grid = self.generate_xy_normed_grid()\n",
    "        xcyc = bboxes[:,0:2,...] + xy_normed_grid.tile(self.batch_size, 1,1,1)\n",
    "        wh = bboxes[:,2:4,...]\n",
    "        x1y1 = xcyc - (wh/2)\n",
    "        x2y2 = xcyc + (wh/2)\n",
    "        return torch.cat([x1y1, x2y2], dim=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c46ad931",
   "metadata": {},
   "source": [
    "# Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "b1729df2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_one_epoch(dataloaders, model, criterion, optimizer, device):\n",
    "    train_loss = defaultdict(float)\n",
    "    val_loss = defaultdict(float)\n",
    "    \n",
    "    for phase in [\"train\", \"val\"]:\n",
    "        if phase == \"train\":\n",
    "            model.train()\n",
    "        else:\n",
    "            model.eval()\n",
    "        \n",
    "        running_loss = defaultdict(float)\n",
    "        for index, batch in enumerate(dataloaders[phase]):\n",
    "            images = batch[0].to(device)\n",
    "            targets = batch[1]\n",
    "            filenames = batch[2]\n",
    "            \n",
    "            with torch.set_grad_enabled(phase == \"train\"): # phase가 train 일때만 gradient 추적기능을 킨다.\n",
    "                predictions = model(images) #prediction shape=> B,12,7,7\n",
    "#             print(f\"predictions:{predictions}, \\ntargets: {targets}\\n\")\n",
    "            loss, (obj_loss, noobj_loss, bbox_loss, cls_loss) = criterion(predictions, targets)\n",
    "#             print(f\"loss:{loss}, obj_loss:{obj_loss}, noobj_loss:{noobj_loss}\\nbbox_loss:{bbox_loss}, cls_loss:{cls_loss}\\n--------------\\n\")\n",
    "            if phase == \"train\":\n",
    "                optimizer.zero_grad()\n",
    "                loss.backward()\n",
    "                optimizer.step()\n",
    "                \n",
    "                # 현재 epoch단계에서 loss가 얼마인지 running loss 가출력\n",
    "                running_loss[\"total_loss\"] += loss.item()\n",
    "                running_loss[\"obj_loss\"] += obj_loss\n",
    "                running_loss[\"noobj_loss\"] += noobj_loss\n",
    "                running_loss[\"bbox_loss\"] += bbox_loss\n",
    "                running_loss[\"cls_loss\"] += cls_loss\n",
    "                \n",
    "                train_loss[\"total_loss\"] += loss.item()\n",
    "                train_loss[\"obj_loss\"] += obj_loss\n",
    "                train_loss[\"noobj_loss\"] += noobj_loss\n",
    "                train_loss[\"bbox_loss\"] += bbox_loss\n",
    "                train_loss[\"cls_loss\"] += cls_loss\n",
    "                \n",
    "                if (index > 0) and (index % VERBOSE_FREQ) == 0:\n",
    "                    text = f\"<<<iteration:[{index}/{len(dataloaders[phase])}] - \"\n",
    "                    for k, v in running_loss.items():\n",
    "                        text += f\"{k}: {v/VERBOSE_FREQ:.4f}  \"\n",
    "                        running_loss[k] = 0.\n",
    "                    print(text)\n",
    "            else:\n",
    "                val_loss[\"total_loss\"] += loss.item()\n",
    "                val_loss[\"obj_loss\"] += obj_loss\n",
    "                val_loss[\"noobj_loss\"] += noobj_loss\n",
    "                val_loss[\"bbox_loss\"] += bbox_loss\n",
    "                val_loss[\"cls_loss\"] += cls_loss\n",
    "\n",
    "    for k in train_loss.keys():\n",
    "        train_loss[k] /= len(dataloaders[\"train\"])\n",
    "        val_loss[k] /= len(dataloaders[\"val\"])\n",
    "    return train_loss, val_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "cc20c145",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_dataloader(part, NECK_PATH, BODY_PATH, batch_size=2, aug_factor=0):\n",
    "    IMAGE_SIZE = 448\n",
    "    transformer = A.Compose([\n",
    "            A.Resize(height=IMAGE_SIZE, width=IMAGE_SIZE),\n",
    "            A.Normalize(mean=(0.485, 0.456, 0.406),std=(0.229, 0.224, 0.225)),\n",
    "            ToTensorV2(),\n",
    "        ],\n",
    "        bbox_params=A.BboxParams(format='yolo', label_fields=['class_ids']),\n",
    "    )\n",
    "    augmentator=A.Compose([\n",
    "    #     A.Resize(height=IMAGE_SIZE, width=IMAGE_SIZE),\n",
    "        A.HorizontalFlip(p=0.7),\n",
    "    #     A.Sharpen(p=0.7),\n",
    "        A.BBoxSafeRandomCrop(p=0.6),\n",
    "        A.VerticalFlip (p=0.6),\n",
    "        A.HueSaturationValue(p=0.6),\n",
    "        A.Resize(height=IMAGE_SIZE, width=IMAGE_SIZE),\n",
    "        A.Normalize(mean=(0.485, 0.456, 0.406),std=(0.229, 0.224, 0.225)),\n",
    "        ToTensorV2(),\n",
    "        ],\n",
    "        bbox_params=A.BboxParams(format='yolo', label_fields=['class_ids']),\n",
    "    )\n",
    "    \n",
    "    dataloaders = {}\n",
    "#     train_dataset = Detection_dataset(data_dir=data_dir, phase=\"train\", transformer=transformer)\n",
    "    train_dataset=PET_dataset(part ,neck_dir=NECK_PATH,body_dir=BODY_PATH,phase='train', transformer=transformer, aug=augmentator, aug_factor=aug_factor)\n",
    "    dataloaders[\"train\"] = DataLoader(train_dataset, batch_size=batch_size, shuffle=True, collate_fn=collate_fn)\n",
    "\n",
    "#     val_dataset = Detection_dataset(data_dir=data_dir, phase=\"val\", transformer=transformer)\n",
    "    val_dataset=PET_dataset(part ,neck_dir=NECK_PATH,body_dir=BODY_PATH,phase='valid', transformer=transformer, aug=augmentator, aug_factor=aug_factor)\n",
    "    dataloaders[\"val\"] = DataLoader(val_dataset, batch_size=batch_size, shuffle=False, collate_fn=collate_fn)\n",
    "    return dataloaders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "2771b438",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "start making augmented images-- augmented factor:30\n",
      "total length of augmented images: 3510\n",
      "start making augmented images-- augmented factor:30\n",
      "total length of augmented images: 600\n"
     ]
    }
   ],
   "source": [
    "# data_dir = \"/content/drive/MyDrive/fastCamMedicalProj/DATASET/DATASET/Detection/\"\n",
    "NECK_PATH = '/home/host_data/PET_data/Neck'\n",
    "BODY_PATH = '/home/host_data/PET_data/Body'\n",
    "is_cuda = True\n",
    "\n",
    "NUM_CLASSES = 2\n",
    "IMAGE_SIZE = 448\n",
    "BATCH_SIZE = 4\n",
    "VERBOSE_FREQ = 20\n",
    "LR=0.0001\n",
    "AUG_FACTOR=30\n",
    "BACKBONE=\"YOLO_SWIN_T\"\n",
    "PART=\"body\"\n",
    "num_epochs = 100\n",
    "# DEVICE = torch.device('cuda' if torch.cuda.is_available and is_cuda else 'cpu')\n",
    "\n",
    "dataloaders = build_dataloader(part=PART,NECK_PATH=NECK_PATH,BODY_PATH=BODY_PATH,batch_size=BATCH_SIZE, aug_factor=AUG_FACTOR)\n",
    "model = YOLO_SWIN(num_classes=NUM_CLASSES)\n",
    "model = model.to(device)\n",
    "criterion = YOLO_LOSS(num_classes=NUM_CLASSES, device=device)\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=LR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "060a24e6",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mgomduribo\u001b[0m (\u001b[33murp\u001b[0m). Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.15.12 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.15.11"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/workspace/yb/wandb/run-20231006_160259-syu3qbnc</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/urp/yolo_swin/runs/syu3qbnc' target=\"_blank\">true-flower-3</a></strong> to <a href='https://wandb.ai/urp/yolo_swin' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/urp/yolo_swin' target=\"_blank\">https://wandb.ai/urp/yolo_swin</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/urp/yolo_swin/runs/syu3qbnc' target=\"_blank\">https://wandb.ai/urp/yolo_swin/runs/syu3qbnc</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<button onClick=\"this.nextSibling.style.display='block';this.style.display='none';\">Display W&B run</button><iframe src='https://wandb.ai/urp/yolo_swin/runs/syu3qbnc?jupyter=true' style='border:none;width:100%;height:420px;display:none;'></iframe>"
      ],
      "text/plain": [
       "<wandb.sdk.wandb_run.Run at 0x7f31a0cccfd0>"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import wandb\n",
    "import random\n",
    "\n",
    "# start a new wandb run to track this script\n",
    "wandb.init(\n",
    "    # set the wandb project where this run will be logged\n",
    "    project=\"yolo_swin\",\n",
    "    \n",
    "    # track hyperparameters and run metadata\n",
    "    config={\n",
    "    \"learning_rate\": LR,\n",
    "    \"batch_size\": BATCH_SIZE,\n",
    "    \"architecture\": BACKBONE,\n",
    "    \"dataset\": \"BODY\",\n",
    "    \"epochs\": num_epochs,\n",
    "    \"aug factor\":AUG_FACTOR,\n",
    "    }\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "8ebab5dc",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.8/dist-packages/torch/functional.py:504: UserWarning: torch.meshgrid: in an upcoming release, it will be required to pass the indexing argument. (Triggered internally at /opt/pytorch/pytorch/aten/src/ATen/native/TensorShape.cpp:3423.)\n",
      "  return _VF.meshgrid(tensors, **kwargs)  # type: ignore[attr-defined]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<<<iteration:[20/878] - total_loss: 24.1707  obj_loss: 0.1836  noobj_loss: 3.4645  bbox_loss: 3.6269  cls_loss: 4.1205  \n",
      "<<<iteration:[40/878] - total_loss: 16.7985  obj_loss: 0.1470  noobj_loss: 2.5177  bbox_loss: 2.4995  cls_loss: 2.8952  \n",
      "<<<iteration:[60/878] - total_loss: 14.8321  obj_loss: 0.1544  noobj_loss: 2.6462  bbox_loss: 2.0846  cls_loss: 2.9315  \n",
      "<<<iteration:[80/878] - total_loss: 20.4857  obj_loss: 0.3012  noobj_loss: 4.6454  bbox_loss: 2.9843  cls_loss: 2.9404  \n",
      "<<<iteration:[100/878] - total_loss: 16.4303  obj_loss: 0.0941  noobj_loss: 1.9319  bbox_loss: 2.5196  cls_loss: 2.7722  \n",
      "<<<iteration:[120/878] - total_loss: 15.8625  obj_loss: 0.0932  noobj_loss: 1.8765  bbox_loss: 2.4196  cls_loss: 2.7330  \n",
      "<<<iteration:[140/878] - total_loss: 12.2725  obj_loss: 0.0835  noobj_loss: 1.6928  bbox_loss: 1.7151  cls_loss: 2.7671  \n",
      "<<<iteration:[160/878] - total_loss: 13.7770  obj_loss: 0.0804  noobj_loss: 1.5613  bbox_loss: 2.0308  cls_loss: 2.7617  \n",
      "<<<iteration:[180/878] - total_loss: 14.0103  obj_loss: 0.0966  noobj_loss: 1.6695  bbox_loss: 2.0667  cls_loss: 2.7455  \n",
      "<<<iteration:[200/878] - total_loss: 11.0710  obj_loss: 0.0574  noobj_loss: 1.0985  bbox_loss: 1.5508  cls_loss: 2.7104  \n",
      "<<<iteration:[220/878] - total_loss: 10.1702  obj_loss: 0.0627  noobj_loss: 0.8482  bbox_loss: 1.3928  cls_loss: 2.7195  \n",
      "<<<iteration:[240/878] - total_loss: 7.7627  obj_loss: 0.0511  noobj_loss: 0.5627  bbox_loss: 0.9473  cls_loss: 2.6940  \n",
      "<<<iteration:[260/878] - total_loss: 8.4569  obj_loss: 0.0557  noobj_loss: 0.6012  bbox_loss: 1.0523  cls_loss: 2.8392  \n",
      "<<<iteration:[280/878] - total_loss: 7.6975  obj_loss: 0.0556  noobj_loss: 0.5551  bbox_loss: 0.9690  cls_loss: 2.5196  \n",
      "<<<iteration:[300/878] - total_loss: 7.5091  obj_loss: 0.0471  noobj_loss: 0.4764  bbox_loss: 0.9184  cls_loss: 2.6318  \n",
      "<<<iteration:[320/878] - total_loss: 9.9513  obj_loss: 0.0385  noobj_loss: 0.4431  bbox_loss: 1.4396  cls_loss: 2.4931  \n",
      "<<<iteration:[340/878] - total_loss: 8.0872  obj_loss: 0.0451  noobj_loss: 0.4058  bbox_loss: 1.0657  cls_loss: 2.5107  \n",
      "<<<iteration:[360/878] - total_loss: 11.0085  obj_loss: 0.0529  noobj_loss: 0.3826  bbox_loss: 1.6056  cls_loss: 2.7363  \n",
      "<<<iteration:[380/878] - total_loss: 6.0579  obj_loss: 0.0399  noobj_loss: 0.2561  bbox_loss: 0.6649  cls_loss: 2.5654  \n",
      "<<<iteration:[400/878] - total_loss: 5.8320  obj_loss: 0.0590  noobj_loss: 0.2348  bbox_loss: 0.6247  cls_loss: 2.5319  \n",
      "<<<iteration:[420/878] - total_loss: 5.4420  obj_loss: 0.0528  noobj_loss: 0.2652  bbox_loss: 0.5777  cls_loss: 2.3681  \n",
      "<<<iteration:[440/878] - total_loss: 4.9295  obj_loss: 0.0615  noobj_loss: 0.1995  bbox_loss: 0.4471  cls_loss: 2.5328  \n",
      "<<<iteration:[460/878] - total_loss: 5.9796  obj_loss: 0.0717  noobj_loss: 0.2240  bbox_loss: 0.6829  cls_loss: 2.3813  \n",
      "<<<iteration:[480/878] - total_loss: 6.1771  obj_loss: 0.0454  noobj_loss: 0.2123  bbox_loss: 0.7001  cls_loss: 2.5252  \n",
      "<<<iteration:[500/878] - total_loss: 7.2387  obj_loss: 0.0417  noobj_loss: 0.2274  bbox_loss: 0.9084  cls_loss: 2.5412  \n",
      "<<<iteration:[520/878] - total_loss: 5.5104  obj_loss: 0.0748  noobj_loss: 0.1553  bbox_loss: 0.5740  cls_loss: 2.4882  \n",
      "<<<iteration:[540/878] - total_loss: 7.6127  obj_loss: 0.0343  noobj_loss: 0.1927  bbox_loss: 0.9697  cls_loss: 2.6337  \n",
      "<<<iteration:[560/878] - total_loss: 6.9752  obj_loss: 0.0390  noobj_loss: 0.1878  bbox_loss: 0.8658  cls_loss: 2.5134  \n",
      "<<<iteration:[580/878] - total_loss: 5.1804  obj_loss: 0.0455  noobj_loss: 0.1676  bbox_loss: 0.5061  cls_loss: 2.5205  \n",
      "<<<iteration:[600/878] - total_loss: 5.3826  obj_loss: 0.0674  noobj_loss: 0.1294  bbox_loss: 0.5330  cls_loss: 2.5854  \n",
      "<<<iteration:[620/878] - total_loss: 4.7861  obj_loss: 0.0495  noobj_loss: 0.1706  bbox_loss: 0.3932  cls_loss: 2.6853  \n",
      "<<<iteration:[640/878] - total_loss: 4.8070  obj_loss: 0.0650  noobj_loss: 0.1584  bbox_loss: 0.4429  cls_loss: 2.4485  \n",
      "<<<iteration:[660/878] - total_loss: 8.0040  obj_loss: 0.0544  noobj_loss: 0.1192  bbox_loss: 1.0090  cls_loss: 2.8452  \n",
      "<<<iteration:[680/878] - total_loss: 6.7182  obj_loss: 0.0380  noobj_loss: 0.1558  bbox_loss: 0.8318  cls_loss: 2.4433  \n",
      "<<<iteration:[700/878] - total_loss: 10.2172  obj_loss: 0.0396  noobj_loss: 0.1308  bbox_loss: 1.4587  cls_loss: 2.8185  \n",
      "<<<iteration:[720/878] - total_loss: 4.7587  obj_loss: 0.0691  noobj_loss: 0.1229  bbox_loss: 0.3798  cls_loss: 2.7293  \n",
      "<<<iteration:[740/878] - total_loss: 7.3683  obj_loss: 0.0464  noobj_loss: 0.1480  bbox_loss: 0.9196  cls_loss: 2.6499  \n",
      "<<<iteration:[760/878] - total_loss: 3.9646  obj_loss: 0.0707  noobj_loss: 0.1295  bbox_loss: 0.2988  cls_loss: 2.3350  \n",
      "<<<iteration:[780/878] - total_loss: 6.6920  obj_loss: 0.0424  noobj_loss: 0.1550  bbox_loss: 0.7552  cls_loss: 2.7960  \n",
      "<<<iteration:[800/878] - total_loss: 8.0534  obj_loss: 0.0387  noobj_loss: 0.1023  bbox_loss: 1.0792  cls_loss: 2.5675  \n",
      "<<<iteration:[820/878] - total_loss: 5.0991  obj_loss: 0.0485  noobj_loss: 0.1137  bbox_loss: 0.5037  cls_loss: 2.4754  \n",
      "<<<iteration:[840/878] - total_loss: 6.0363  obj_loss: 0.0533  noobj_loss: 0.1160  bbox_loss: 0.6517  cls_loss: 2.6663  \n",
      "<<<iteration:[860/878] - total_loss: 19.6385  obj_loss: 0.0319  noobj_loss: 0.3067  bbox_loss: 3.3886  cls_loss: 2.5102  \n",
      "\n",
      "epoch:1/100 - Train Loss: 9.4448, Val Loss: 6.1345\n",
      "\n",
      "<<<iteration:[20/878] - total_loss: 8.4221  obj_loss: 0.0402  noobj_loss: 0.2389  bbox_loss: 1.1054  cls_loss: 2.7353  \n",
      "<<<iteration:[40/878] - total_loss: 6.2425  obj_loss: 0.0565  noobj_loss: 0.1734  bbox_loss: 0.6872  cls_loss: 2.6631  \n",
      "<<<iteration:[60/878] - total_loss: 7.9523  obj_loss: 0.0528  noobj_loss: 0.1550  bbox_loss: 1.0575  cls_loss: 2.5345  \n",
      "<<<iteration:[80/878] - total_loss: 5.4944  obj_loss: 0.0558  noobj_loss: 0.1283  bbox_loss: 0.5490  cls_loss: 2.6295  \n",
      "<<<iteration:[100/878] - total_loss: 5.3208  obj_loss: 0.0545  noobj_loss: 0.0984  bbox_loss: 0.5333  cls_loss: 2.5504  \n",
      "<<<iteration:[120/878] - total_loss: 5.9683  obj_loss: 0.0276  noobj_loss: 0.0713  bbox_loss: 0.6502  cls_loss: 2.6542  \n",
      "<<<iteration:[140/878] - total_loss: 4.6461  obj_loss: 0.0639  noobj_loss: 0.0840  bbox_loss: 0.3959  cls_loss: 2.5606  \n",
      "<<<iteration:[160/878] - total_loss: 3.9782  obj_loss: 0.0679  noobj_loss: 0.0996  bbox_loss: 0.2906  cls_loss: 2.4077  \n",
      "<<<iteration:[180/878] - total_loss: 3.9895  obj_loss: 0.0747  noobj_loss: 0.0886  bbox_loss: 0.2919  cls_loss: 2.4111  \n",
      "<<<iteration:[200/878] - total_loss: 4.2257  obj_loss: 0.0690  noobj_loss: 0.1005  bbox_loss: 0.2973  cls_loss: 2.6200  \n",
      "<<<iteration:[220/878] - total_loss: 3.8392  obj_loss: 0.0568  noobj_loss: 0.0719  bbox_loss: 0.2881  cls_loss: 2.3059  \n",
      "<<<iteration:[240/878] - total_loss: 3.7100  obj_loss: 0.1037  noobj_loss: 0.0718  bbox_loss: 0.1985  cls_loss: 2.5782  \n",
      "<<<iteration:[260/878] - total_loss: 4.1253  obj_loss: 0.0839  noobj_loss: 0.0753  bbox_loss: 0.2876  cls_loss: 2.5659  \n",
      "<<<iteration:[280/878] - total_loss: 4.1772  obj_loss: 0.0644  noobj_loss: 0.1109  bbox_loss: 0.2995  cls_loss: 2.5597  \n",
      "<<<iteration:[300/878] - total_loss: 4.3902  obj_loss: 0.0574  noobj_loss: 0.0756  bbox_loss: 0.3023  cls_loss: 2.7838  \n",
      "<<<iteration:[320/878] - total_loss: 3.8593  obj_loss: 0.0660  noobj_loss: 0.0713  bbox_loss: 0.2781  cls_loss: 2.3671  \n",
      "<<<iteration:[340/878] - total_loss: 4.2514  obj_loss: 0.0698  noobj_loss: 0.0618  bbox_loss: 0.3080  cls_loss: 2.6109  \n",
      "<<<iteration:[360/878] - total_loss: 4.9792  obj_loss: 0.0613  noobj_loss: 0.0670  bbox_loss: 0.5604  cls_loss: 2.0825  \n",
      "<<<iteration:[380/878] - total_loss: 3.9264  obj_loss: 0.0884  noobj_loss: 0.0832  bbox_loss: 0.2031  cls_loss: 2.7809  \n",
      "<<<iteration:[400/878] - total_loss: 4.6204  obj_loss: 0.0649  noobj_loss: 0.0739  bbox_loss: 0.3863  cls_loss: 2.5872  \n",
      "<<<iteration:[420/878] - total_loss: 4.9573  obj_loss: 0.0770  noobj_loss: 0.0666  bbox_loss: 0.4295  cls_loss: 2.6998  \n",
      "<<<iteration:[440/878] - total_loss: 6.6679  obj_loss: 0.0729  noobj_loss: 0.0711  bbox_loss: 0.7802  cls_loss: 2.6586  \n",
      "<<<iteration:[460/878] - total_loss: 4.2212  obj_loss: 0.1040  noobj_loss: 0.0528  bbox_loss: 0.2824  cls_loss: 2.6788  \n",
      "<<<iteration:[480/878] - total_loss: 3.7112  obj_loss: 0.0853  noobj_loss: 0.0613  bbox_loss: 0.2410  cls_loss: 2.3903  \n",
      "<<<iteration:[500/878] - total_loss: 3.5025  obj_loss: 0.0542  noobj_loss: 0.0654  bbox_loss: 0.2143  cls_loss: 2.3443  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<<<iteration:[520/878] - total_loss: 4.5186  obj_loss: 0.0709  noobj_loss: 0.0857  bbox_loss: 0.3615  cls_loss: 2.5976  \n",
      "<<<iteration:[540/878] - total_loss: 5.5359  obj_loss: 0.0647  noobj_loss: 0.0618  bbox_loss: 0.5740  cls_loss: 2.5702  \n",
      "<<<iteration:[560/878] - total_loss: 3.9063  obj_loss: 0.0808  noobj_loss: 0.0663  bbox_loss: 0.2300  cls_loss: 2.6423  \n",
      "<<<iteration:[580/878] - total_loss: 3.8926  obj_loss: 0.0851  noobj_loss: 0.0559  bbox_loss: 0.2415  cls_loss: 2.5721  \n",
      "<<<iteration:[600/878] - total_loss: 4.6235  obj_loss: 0.0626  noobj_loss: 0.0562  bbox_loss: 0.3890  cls_loss: 2.5877  \n",
      "<<<iteration:[620/878] - total_loss: 4.8927  obj_loss: 0.0822  noobj_loss: 0.0664  bbox_loss: 0.3823  cls_loss: 2.8658  \n",
      "<<<iteration:[640/878] - total_loss: 4.1133  obj_loss: 0.0752  noobj_loss: 0.0596  bbox_loss: 0.2753  cls_loss: 2.6319  \n",
      "<<<iteration:[660/878] - total_loss: 3.4552  obj_loss: 0.0685  noobj_loss: 0.0646  bbox_loss: 0.1978  cls_loss: 2.3656  \n",
      "<<<iteration:[680/878] - total_loss: 3.5800  obj_loss: 0.0667  noobj_loss: 0.0538  bbox_loss: 0.2056  cls_loss: 2.4581  \n",
      "<<<iteration:[700/878] - total_loss: 4.5294  obj_loss: 0.0712  noobj_loss: 0.0656  bbox_loss: 0.3672  cls_loss: 2.5893  \n",
      "<<<iteration:[720/878] - total_loss: 3.8280  obj_loss: 0.0631  noobj_loss: 0.0850  bbox_loss: 0.2405  cls_loss: 2.5200  \n",
      "<<<iteration:[740/878] - total_loss: 3.6086  obj_loss: 0.0651  noobj_loss: 0.0569  bbox_loss: 0.1933  cls_loss: 2.5486  \n",
      "<<<iteration:[760/878] - total_loss: 4.0640  obj_loss: 0.0817  noobj_loss: 0.0616  bbox_loss: 0.2476  cls_loss: 2.7134  \n",
      "<<<iteration:[780/878] - total_loss: 4.2134  obj_loss: 0.0887  noobj_loss: 0.0608  bbox_loss: 0.3027  cls_loss: 2.5808  \n",
      "<<<iteration:[800/878] - total_loss: 3.8375  obj_loss: 0.1064  noobj_loss: 0.0508  bbox_loss: 0.2231  cls_loss: 2.5902  \n",
      "<<<iteration:[820/878] - total_loss: 4.4551  obj_loss: 0.0767  noobj_loss: 0.0663  bbox_loss: 0.2872  cls_loss: 2.9091  \n",
      "<<<iteration:[840/878] - total_loss: 4.0615  obj_loss: 0.0904  noobj_loss: 0.0640  bbox_loss: 0.3003  cls_loss: 2.4377  \n",
      "<<<iteration:[860/878] - total_loss: 3.5871  obj_loss: 0.0745  noobj_loss: 0.0486  bbox_loss: 0.2096  cls_loss: 2.4402  \n",
      "\n",
      "epoch:2/100 - Train Loss: 4.5432, Val Loss: 3.4791\n",
      "\n",
      "<<<iteration:[20/878] - total_loss: 4.4619  obj_loss: 0.0813  noobj_loss: 0.0656  bbox_loss: 0.3280  cls_loss: 2.7080  \n",
      "<<<iteration:[40/878] - total_loss: 3.8529  obj_loss: 0.0809  noobj_loss: 0.0460  bbox_loss: 0.2608  cls_loss: 2.4448  \n",
      "<<<iteration:[60/878] - total_loss: 3.4304  obj_loss: 0.0760  noobj_loss: 0.0410  bbox_loss: 0.1768  cls_loss: 2.4502  \n",
      "<<<iteration:[80/878] - total_loss: 3.6327  obj_loss: 0.0489  noobj_loss: 0.0546  bbox_loss: 0.1928  cls_loss: 2.5923  \n",
      "<<<iteration:[100/878] - total_loss: 4.9817  obj_loss: 0.0612  noobj_loss: 0.0402  bbox_loss: 0.4489  cls_loss: 2.6559  \n",
      "<<<iteration:[120/878] - total_loss: 3.7902  obj_loss: 0.0586  noobj_loss: 0.0474  bbox_loss: 0.2588  cls_loss: 2.4141  \n",
      "<<<iteration:[140/878] - total_loss: 4.1955  obj_loss: 0.0763  noobj_loss: 0.0687  bbox_loss: 0.3113  cls_loss: 2.5284  \n",
      "<<<iteration:[160/878] - total_loss: 3.2339  obj_loss: 0.1149  noobj_loss: 0.0434  bbox_loss: 0.1436  cls_loss: 2.3792  \n",
      "<<<iteration:[180/878] - total_loss: 3.4969  obj_loss: 0.0573  noobj_loss: 0.0494  bbox_loss: 0.1774  cls_loss: 2.5280  \n",
      "<<<iteration:[200/878] - total_loss: 3.0780  obj_loss: 0.0706  noobj_loss: 0.0348  bbox_loss: 0.1487  cls_loss: 2.2464  \n",
      "<<<iteration:[220/878] - total_loss: 4.0207  obj_loss: 0.0725  noobj_loss: 0.0436  bbox_loss: 0.2418  cls_loss: 2.7176  \n",
      "<<<iteration:[240/878] - total_loss: 3.6280  obj_loss: 0.0779  noobj_loss: 0.0363  bbox_loss: 0.2075  cls_loss: 2.4944  \n",
      "<<<iteration:[260/878] - total_loss: 3.8494  obj_loss: 0.0718  noobj_loss: 0.0480  bbox_loss: 0.1791  cls_loss: 2.8582  \n",
      "<<<iteration:[280/878] - total_loss: 3.8930  obj_loss: 0.0888  noobj_loss: 0.0573  bbox_loss: 0.2193  cls_loss: 2.6790  \n",
      "<<<iteration:[300/878] - total_loss: 3.5818  obj_loss: 0.0701  noobj_loss: 0.0498  bbox_loss: 0.2118  cls_loss: 2.4277  \n",
      "<<<iteration:[320/878] - total_loss: 3.4482  obj_loss: 0.0814  noobj_loss: 0.0685  bbox_loss: 0.1799  cls_loss: 2.4332  \n",
      "<<<iteration:[340/878] - total_loss: 3.5516  obj_loss: 0.0706  noobj_loss: 0.0501  bbox_loss: 0.1701  cls_loss: 2.6053  \n",
      "<<<iteration:[360/878] - total_loss: 3.3973  obj_loss: 0.0875  noobj_loss: 0.0453  bbox_loss: 0.1662  cls_loss: 2.4562  \n",
      "<<<iteration:[380/878] - total_loss: 4.0019  obj_loss: 0.1111  noobj_loss: 0.0811  bbox_loss: 0.2763  cls_loss: 2.4685  \n",
      "<<<iteration:[400/878] - total_loss: 3.2699  obj_loss: 0.0762  noobj_loss: 0.0562  bbox_loss: 0.1677  cls_loss: 2.3273  \n",
      "<<<iteration:[420/878] - total_loss: 3.4869  obj_loss: 0.0856  noobj_loss: 0.0512  bbox_loss: 0.2372  cls_loss: 2.1895  \n",
      "<<<iteration:[440/878] - total_loss: 3.4879  obj_loss: 0.0631  noobj_loss: 0.0476  bbox_loss: 0.1646  cls_loss: 2.5782  \n",
      "<<<iteration:[460/878] - total_loss: 3.1006  obj_loss: 0.0905  noobj_loss: 0.0429  bbox_loss: 0.1245  cls_loss: 2.3660  \n",
      "<<<iteration:[480/878] - total_loss: 3.4878  obj_loss: 0.0783  noobj_loss: 0.0388  bbox_loss: 0.1570  cls_loss: 2.6050  \n",
      "<<<iteration:[500/878] - total_loss: 3.3497  obj_loss: 0.0891  noobj_loss: 0.0360  bbox_loss: 0.1422  cls_loss: 2.5316  \n",
      "<<<iteration:[520/878] - total_loss: 4.2267  obj_loss: 0.0577  noobj_loss: 0.0442  bbox_loss: 0.2779  cls_loss: 2.7576  \n",
      "<<<iteration:[540/878] - total_loss: 3.2750  obj_loss: 0.0736  noobj_loss: 0.0538  bbox_loss: 0.1317  cls_loss: 2.5159  \n",
      "<<<iteration:[560/878] - total_loss: 3.5059  obj_loss: 0.0910  noobj_loss: 0.0450  bbox_loss: 0.1723  cls_loss: 2.5309  \n",
      "<<<iteration:[580/878] - total_loss: 3.2286  obj_loss: 0.0687  noobj_loss: 0.0514  bbox_loss: 0.1566  cls_loss: 2.3515  \n",
      "<<<iteration:[600/878] - total_loss: 2.9617  obj_loss: 0.0918  noobj_loss: 0.0575  bbox_loss: 0.1072  cls_loss: 2.3048  \n",
      "<<<iteration:[620/878] - total_loss: 3.5586  obj_loss: 0.0843  noobj_loss: 0.0664  bbox_loss: 0.1703  cls_loss: 2.5895  \n",
      "<<<iteration:[640/878] - total_loss: 2.9236  obj_loss: 0.0721  noobj_loss: 0.0308  bbox_loss: 0.1030  cls_loss: 2.3209  \n",
      "<<<iteration:[660/878] - total_loss: 3.6855  obj_loss: 0.0770  noobj_loss: 0.0384  bbox_loss: 0.1645  cls_loss: 2.7668  \n",
      "<<<iteration:[680/878] - total_loss: 3.6035  obj_loss: 0.0815  noobj_loss: 0.0364  bbox_loss: 0.1962  cls_loss: 2.5228  \n",
      "<<<iteration:[700/878] - total_loss: 3.4977  obj_loss: 0.0876  noobj_loss: 0.0630  bbox_loss: 0.1431  cls_loss: 2.6633  \n",
      "<<<iteration:[720/878] - total_loss: 3.3732  obj_loss: 0.0804  noobj_loss: 0.0401  bbox_loss: 0.1856  cls_loss: 2.3448  \n",
      "<<<iteration:[740/878] - total_loss: 2.9597  obj_loss: 0.0743  noobj_loss: 0.0380  bbox_loss: 0.1239  cls_loss: 2.2470  \n",
      "<<<iteration:[760/878] - total_loss: 3.0033  obj_loss: 0.0669  noobj_loss: 0.0364  bbox_loss: 0.1272  cls_loss: 2.2823  \n",
      "<<<iteration:[780/878] - total_loss: 3.8427  obj_loss: 0.0870  noobj_loss: 0.0833  bbox_loss: 0.2283  cls_loss: 2.5725  \n",
      "<<<iteration:[800/878] - total_loss: 3.7541  obj_loss: 0.0761  noobj_loss: 0.0648  bbox_loss: 0.1858  cls_loss: 2.7167  \n",
      "<<<iteration:[820/878] - total_loss: 3.2186  obj_loss: 0.0849  noobj_loss: 0.0457  bbox_loss: 0.1298  cls_loss: 2.4620  \n",
      "<<<iteration:[840/878] - total_loss: 3.5100  obj_loss: 0.0749  noobj_loss: 0.0557  bbox_loss: 0.1478  cls_loss: 2.6683  \n",
      "<<<iteration:[860/878] - total_loss: 3.4951  obj_loss: 0.0691  noobj_loss: 0.0727  bbox_loss: 0.1812  cls_loss: 2.4836  \n",
      "\n",
      "epoch:3/100 - Train Loss: 3.5761, Val Loss: 3.4580\n",
      "\n",
      "<<<iteration:[20/878] - total_loss: 4.0119  obj_loss: 0.0883  noobj_loss: 0.0618  bbox_loss: 0.2087  cls_loss: 2.8494  \n",
      "<<<iteration:[40/878] - total_loss: 3.2260  obj_loss: 0.0715  noobj_loss: 0.0288  bbox_loss: 0.1361  cls_loss: 2.4595  \n",
      "<<<iteration:[60/878] - total_loss: 4.4751  obj_loss: 0.0790  noobj_loss: 0.0431  bbox_loss: 0.3381  cls_loss: 2.6841  \n",
      "<<<iteration:[80/878] - total_loss: 5.2493  obj_loss: 0.0660  noobj_loss: 0.0730  bbox_loss: 0.4984  cls_loss: 2.6546  \n",
      "<<<iteration:[100/878] - total_loss: 3.7989  obj_loss: 0.0924  noobj_loss: 0.0730  bbox_loss: 0.2220  cls_loss: 2.5601  \n",
      "<<<iteration:[120/878] - total_loss: 3.5257  obj_loss: 0.0999  noobj_loss: 0.0432  bbox_loss: 0.1462  cls_loss: 2.6734  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<<<iteration:[140/878] - total_loss: 6.7775  obj_loss: 0.0709  noobj_loss: 0.0465  bbox_loss: 0.8085  cls_loss: 2.6410  \n",
      "<<<iteration:[160/878] - total_loss: 7.6416  obj_loss: 0.0902  noobj_loss: 0.0469  bbox_loss: 1.0277  cls_loss: 2.3894  \n",
      "<<<iteration:[180/878] - total_loss: 5.8051  obj_loss: 0.0595  noobj_loss: 0.0483  bbox_loss: 0.6554  cls_loss: 2.4447  \n",
      "<<<iteration:[200/878] - total_loss: 4.5505  obj_loss: 0.0868  noobj_loss: 0.0484  bbox_loss: 0.3884  cls_loss: 2.4974  \n",
      "<<<iteration:[220/878] - total_loss: 7.0316  obj_loss: 0.0970  noobj_loss: 0.0555  bbox_loss: 0.8794  cls_loss: 2.5098  \n",
      "<<<iteration:[240/878] - total_loss: 5.0737  obj_loss: 0.0538  noobj_loss: 0.0671  bbox_loss: 0.4746  cls_loss: 2.6134  \n",
      "<<<iteration:[260/878] - total_loss: 3.7928  obj_loss: 0.0934  noobj_loss: 0.0457  bbox_loss: 0.2275  cls_loss: 2.5393  \n",
      "<<<iteration:[280/878] - total_loss: 3.9719  obj_loss: 0.0987  noobj_loss: 0.0500  bbox_loss: 0.2408  cls_loss: 2.6443  \n",
      "<<<iteration:[300/878] - total_loss: 3.9316  obj_loss: 0.0738  noobj_loss: 0.0398  bbox_loss: 0.2396  cls_loss: 2.6399  \n",
      "<<<iteration:[320/878] - total_loss: 3.5789  obj_loss: 0.1012  noobj_loss: 0.0531  bbox_loss: 0.1348  cls_loss: 2.7773  \n",
      "<<<iteration:[340/878] - total_loss: 3.5115  obj_loss: 0.0805  noobj_loss: 0.0389  bbox_loss: 0.1974  cls_loss: 2.4243  \n",
      "<<<iteration:[360/878] - total_loss: 3.1688  obj_loss: 0.0689  noobj_loss: 0.0572  bbox_loss: 0.1406  cls_loss: 2.3683  \n",
      "<<<iteration:[380/878] - total_loss: 3.8485  obj_loss: 0.0889  noobj_loss: 0.0941  bbox_loss: 0.2085  cls_loss: 2.6698  \n",
      "<<<iteration:[400/878] - total_loss: 3.3186  obj_loss: 0.0968  noobj_loss: 0.0693  bbox_loss: 0.1324  cls_loss: 2.5252  \n",
      "<<<iteration:[420/878] - total_loss: 3.8260  obj_loss: 0.0854  noobj_loss: 0.0759  bbox_loss: 0.1867  cls_loss: 2.7690  \n",
      "<<<iteration:[440/878] - total_loss: 3.2813  obj_loss: 0.0617  noobj_loss: 0.0618  bbox_loss: 0.1427  cls_loss: 2.4753  \n",
      "<<<iteration:[460/878] - total_loss: 3.9812  obj_loss: 0.0578  noobj_loss: 0.0437  bbox_loss: 0.2922  cls_loss: 2.4405  \n",
      "<<<iteration:[480/878] - total_loss: 3.2574  obj_loss: 0.0668  noobj_loss: 0.0428  bbox_loss: 0.1234  cls_loss: 2.5524  \n",
      "<<<iteration:[500/878] - total_loss: 3.0807  obj_loss: 0.0775  noobj_loss: 0.0399  bbox_loss: 0.1132  cls_loss: 2.4173  \n",
      "<<<iteration:[520/878] - total_loss: 3.1830  obj_loss: 0.0746  noobj_loss: 0.0549  bbox_loss: 0.1195  cls_loss: 2.4834  \n",
      "<<<iteration:[540/878] - total_loss: 3.3048  obj_loss: 0.0721  noobj_loss: 0.0394  bbox_loss: 0.1674  cls_loss: 2.3761  \n",
      "<<<iteration:[560/878] - total_loss: 3.2375  obj_loss: 0.0929  noobj_loss: 0.0317  bbox_loss: 0.1597  cls_loss: 2.3305  \n",
      "<<<iteration:[580/878] - total_loss: 3.8659  obj_loss: 0.0915  noobj_loss: 0.0557  bbox_loss: 0.2367  cls_loss: 2.5633  \n",
      "<<<iteration:[600/878] - total_loss: 3.6288  obj_loss: 0.1077  noobj_loss: 0.0427  bbox_loss: 0.2086  cls_loss: 2.4568  \n",
      "<<<iteration:[620/878] - total_loss: 3.1346  obj_loss: 0.0853  noobj_loss: 0.0437  bbox_loss: 0.1355  cls_loss: 2.3499  \n",
      "<<<iteration:[640/878] - total_loss: 2.8986  obj_loss: 0.0829  noobj_loss: 0.0618  bbox_loss: 0.1111  cls_loss: 2.2293  \n",
      "<<<iteration:[660/878] - total_loss: 3.1725  obj_loss: 0.0749  noobj_loss: 0.0605  bbox_loss: 0.1113  cls_loss: 2.5110  \n",
      "<<<iteration:[680/878] - total_loss: 3.6897  obj_loss: 0.0914  noobj_loss: 0.1219  bbox_loss: 0.2066  cls_loss: 2.5043  \n",
      "<<<iteration:[700/878] - total_loss: 3.8129  obj_loss: 0.0710  noobj_loss: 0.0640  bbox_loss: 0.2287  cls_loss: 2.5666  \n",
      "<<<iteration:[720/878] - total_loss: 2.8908  obj_loss: 0.0748  noobj_loss: 0.0596  bbox_loss: 0.1326  cls_loss: 2.1233  \n",
      "<<<iteration:[740/878] - total_loss: 2.9984  obj_loss: 0.0790  noobj_loss: 0.0351  bbox_loss: 0.0983  cls_loss: 2.4104  \n",
      "<<<iteration:[760/878] - total_loss: 4.0732  obj_loss: 0.0711  noobj_loss: 0.0363  bbox_loss: 0.2926  cls_loss: 2.5210  \n",
      "<<<iteration:[780/878] - total_loss: 3.8176  obj_loss: 0.1046  noobj_loss: 0.0457  bbox_loss: 0.2758  cls_loss: 2.3111  \n",
      "<<<iteration:[800/878] - total_loss: 4.3765  obj_loss: 0.0497  noobj_loss: 0.0500  bbox_loss: 0.3519  cls_loss: 2.5421  \n",
      "<<<iteration:[820/878] - total_loss: 3.2289  obj_loss: 0.0901  noobj_loss: 0.0323  bbox_loss: 0.1153  cls_loss: 2.5463  \n",
      "<<<iteration:[840/878] - total_loss: 3.3157  obj_loss: 0.0744  noobj_loss: 0.0428  bbox_loss: 0.1150  cls_loss: 2.6448  \n",
      "<<<iteration:[860/878] - total_loss: 3.3140  obj_loss: 0.0627  noobj_loss: 0.0324  bbox_loss: 0.1473  cls_loss: 2.4986  \n",
      "\n",
      "epoch:4/100 - Train Loss: 3.9254, Val Loss: 3.1115\n",
      "\n",
      "<<<iteration:[20/878] - total_loss: 3.0971  obj_loss: 0.0970  noobj_loss: 0.0935  bbox_loss: 0.1131  cls_loss: 2.3877  \n",
      "<<<iteration:[40/878] - total_loss: 3.3709  obj_loss: 0.0726  noobj_loss: 0.0852  bbox_loss: 0.1364  cls_loss: 2.5738  \n",
      "<<<iteration:[60/878] - total_loss: 2.8596  obj_loss: 0.0880  noobj_loss: 0.0509  bbox_loss: 0.1061  cls_loss: 2.2156  \n",
      "<<<iteration:[80/878] - total_loss: 3.3310  obj_loss: 0.0939  noobj_loss: 0.0359  bbox_loss: 0.1447  cls_loss: 2.4957  \n",
      "<<<iteration:[100/878] - total_loss: 2.9339  obj_loss: 0.0835  noobj_loss: 0.0443  bbox_loss: 0.1066  cls_loss: 2.2954  \n",
      "<<<iteration:[120/878] - total_loss: 2.9965  obj_loss: 0.0789  noobj_loss: 0.0490  bbox_loss: 0.0957  cls_loss: 2.4146  \n",
      "<<<iteration:[140/878] - total_loss: 3.2648  obj_loss: 0.0783  noobj_loss: 0.0561  bbox_loss: 0.1286  cls_loss: 2.5152  \n",
      "<<<iteration:[160/878] - total_loss: 3.5781  obj_loss: 0.0729  noobj_loss: 0.0288  bbox_loss: 0.1368  cls_loss: 2.8069  \n",
      "<<<iteration:[180/878] - total_loss: 3.5726  obj_loss: 0.1032  noobj_loss: 0.0367  bbox_loss: 0.1491  cls_loss: 2.7054  \n",
      "<<<iteration:[200/878] - total_loss: 3.8679  obj_loss: 0.0984  noobj_loss: 0.0344  bbox_loss: 0.1949  cls_loss: 2.7778  \n",
      "<<<iteration:[220/878] - total_loss: 3.0619  obj_loss: 0.0824  noobj_loss: 0.0341  bbox_loss: 0.1221  cls_loss: 2.3520  \n",
      "<<<iteration:[240/878] - total_loss: 3.0883  obj_loss: 0.0793  noobj_loss: 0.0567  bbox_loss: 0.1384  cls_loss: 2.2888  \n",
      "<<<iteration:[260/878] - total_loss: 3.1682  obj_loss: 0.0764  noobj_loss: 0.0352  bbox_loss: 0.1500  cls_loss: 2.3244  \n",
      "<<<iteration:[280/878] - total_loss: 2.9757  obj_loss: 0.1019  noobj_loss: 0.0361  bbox_loss: 0.0909  cls_loss: 2.4010  \n",
      "<<<iteration:[300/878] - total_loss: 3.6855  obj_loss: 0.0562  noobj_loss: 0.0464  bbox_loss: 0.2071  cls_loss: 2.5708  \n",
      "<<<iteration:[320/878] - total_loss: 3.2591  obj_loss: 0.0823  noobj_loss: 0.0462  bbox_loss: 0.1173  cls_loss: 2.5674  \n",
      "<<<iteration:[340/878] - total_loss: 4.0120  obj_loss: 0.0838  noobj_loss: 0.0496  bbox_loss: 0.2321  cls_loss: 2.7429  \n",
      "<<<iteration:[360/878] - total_loss: 2.9915  obj_loss: 0.0868  noobj_loss: 0.0477  bbox_loss: 0.1038  cls_loss: 2.3617  \n",
      "<<<iteration:[380/878] - total_loss: 3.3070  obj_loss: 0.0876  noobj_loss: 0.0397  bbox_loss: 0.1523  cls_loss: 2.4379  \n",
      "<<<iteration:[400/878] - total_loss: 3.3728  obj_loss: 0.0620  noobj_loss: 0.0339  bbox_loss: 0.1723  cls_loss: 2.4325  \n",
      "<<<iteration:[420/878] - total_loss: 3.0736  obj_loss: 0.0806  noobj_loss: 0.0323  bbox_loss: 0.1076  cls_loss: 2.4391  \n",
      "<<<iteration:[440/878] - total_loss: 3.2700  obj_loss: 0.0706  noobj_loss: 0.0333  bbox_loss: 0.1829  cls_loss: 2.2683  \n",
      "<<<iteration:[460/878] - total_loss: 3.6430  obj_loss: 0.0942  noobj_loss: 0.0570  bbox_loss: 0.2004  cls_loss: 2.5183  \n",
      "<<<iteration:[480/878] - total_loss: 4.8206  obj_loss: 0.0911  noobj_loss: 0.0583  bbox_loss: 0.4800  cls_loss: 2.3004  \n",
      "<<<iteration:[500/878] - total_loss: 3.1520  obj_loss: 0.0769  noobj_loss: 0.0437  bbox_loss: 0.1251  cls_loss: 2.4278  \n",
      "<<<iteration:[520/878] - total_loss: 3.2148  obj_loss: 0.0855  noobj_loss: 0.0570  bbox_loss: 0.1384  cls_loss: 2.4089  \n",
      "<<<iteration:[540/878] - total_loss: 4.1344  obj_loss: 0.0865  noobj_loss: 0.0508  bbox_loss: 0.2937  cls_loss: 2.5537  \n",
      "<<<iteration:[560/878] - total_loss: 3.2487  obj_loss: 0.0736  noobj_loss: 0.0557  bbox_loss: 0.1713  cls_loss: 2.2907  \n",
      "<<<iteration:[580/878] - total_loss: 3.5147  obj_loss: 0.0725  noobj_loss: 0.0374  bbox_loss: 0.1774  cls_loss: 2.5364  \n",
      "<<<iteration:[600/878] - total_loss: 3.3259  obj_loss: 0.0711  noobj_loss: 0.0335  bbox_loss: 0.1740  cls_loss: 2.3682  \n",
      "<<<iteration:[620/878] - total_loss: 3.2930  obj_loss: 0.0854  noobj_loss: 0.0254  bbox_loss: 0.1523  cls_loss: 2.4335  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<<<iteration:[640/878] - total_loss: 3.8921  obj_loss: 0.0941  noobj_loss: 0.0355  bbox_loss: 0.2504  cls_loss: 2.5283  \n",
      "<<<iteration:[660/878] - total_loss: 3.7239  obj_loss: 0.0965  noobj_loss: 0.0395  bbox_loss: 0.2591  cls_loss: 2.3120  \n",
      "<<<iteration:[680/878] - total_loss: 3.2416  obj_loss: 0.0790  noobj_loss: 0.0361  bbox_loss: 0.1185  cls_loss: 2.5517  \n",
      "<<<iteration:[700/878] - total_loss: 3.5627  obj_loss: 0.0774  noobj_loss: 0.0396  bbox_loss: 0.2270  cls_loss: 2.3306  \n",
      "<<<iteration:[720/878] - total_loss: 3.5397  obj_loss: 0.0693  noobj_loss: 0.0505  bbox_loss: 0.1817  cls_loss: 2.5367  \n",
      "<<<iteration:[740/878] - total_loss: 3.3685  obj_loss: 0.0931  noobj_loss: 0.0652  bbox_loss: 0.1307  cls_loss: 2.5893  \n",
      "<<<iteration:[760/878] - total_loss: 3.2793  obj_loss: 0.0917  noobj_loss: 0.0363  bbox_loss: 0.1412  cls_loss: 2.4635  \n",
      "<<<iteration:[780/878] - total_loss: 3.7783  obj_loss: 0.0876  noobj_loss: 0.0432  bbox_loss: 0.2190  cls_loss: 2.5741  \n",
      "<<<iteration:[800/878] - total_loss: 3.4906  obj_loss: 0.0785  noobj_loss: 0.0410  bbox_loss: 0.1258  cls_loss: 2.7625  \n",
      "<<<iteration:[820/878] - total_loss: 3.1929  obj_loss: 0.0880  noobj_loss: 0.0324  bbox_loss: 0.1149  cls_loss: 2.5144  \n",
      "<<<iteration:[840/878] - total_loss: 3.0742  obj_loss: 0.0850  noobj_loss: 0.0401  bbox_loss: 0.0988  cls_loss: 2.4753  \n",
      "<<<iteration:[860/878] - total_loss: 2.8109  obj_loss: 0.0905  noobj_loss: 0.0368  bbox_loss: 0.1067  cls_loss: 2.1687  \n",
      "\n",
      "epoch:5/100 - Train Loss: 3.3712, Val Loss: 3.1673\n",
      "\n",
      "<<<iteration:[20/878] - total_loss: 3.3581  obj_loss: 0.0888  noobj_loss: 0.0340  bbox_loss: 0.1440  cls_loss: 2.5326  \n",
      "<<<iteration:[40/878] - total_loss: 3.6208  obj_loss: 0.0910  noobj_loss: 0.0409  bbox_loss: 0.1328  cls_loss: 2.8455  \n",
      "<<<iteration:[60/878] - total_loss: 3.1919  obj_loss: 0.0844  noobj_loss: 0.0400  bbox_loss: 0.1298  cls_loss: 2.4383  \n",
      "<<<iteration:[80/878] - total_loss: 3.1228  obj_loss: 0.0785  noobj_loss: 0.0322  bbox_loss: 0.1341  cls_loss: 2.3575  \n",
      "<<<iteration:[100/878] - total_loss: 3.1124  obj_loss: 0.0965  noobj_loss: 0.0419  bbox_loss: 0.1289  cls_loss: 2.3505  \n",
      "<<<iteration:[120/878] - total_loss: 2.8415  obj_loss: 0.0704  noobj_loss: 0.0413  bbox_loss: 0.1070  cls_loss: 2.2155  \n",
      "<<<iteration:[140/878] - total_loss: 3.4521  obj_loss: 0.1027  noobj_loss: 0.0629  bbox_loss: 0.1399  cls_loss: 2.6182  \n",
      "<<<iteration:[160/878] - total_loss: 3.5941  obj_loss: 0.0987  noobj_loss: 0.0739  bbox_loss: 0.1681  cls_loss: 2.6181  \n",
      "<<<iteration:[180/878] - total_loss: 3.2446  obj_loss: 0.0800  noobj_loss: 0.0445  bbox_loss: 0.1272  cls_loss: 2.5061  \n",
      "<<<iteration:[200/878] - total_loss: 3.3686  obj_loss: 0.0979  noobj_loss: 0.0378  bbox_loss: 0.1160  cls_loss: 2.6717  \n",
      "<<<iteration:[220/878] - total_loss: 3.2607  obj_loss: 0.0938  noobj_loss: 0.0540  bbox_loss: 0.1377  cls_loss: 2.4512  \n",
      "<<<iteration:[240/878] - total_loss: 3.5811  obj_loss: 0.0778  noobj_loss: 0.0314  bbox_loss: 0.2289  cls_loss: 2.3429  \n",
      "<<<iteration:[260/878] - total_loss: 3.5762  obj_loss: 0.0769  noobj_loss: 0.0379  bbox_loss: 0.1932  cls_loss: 2.5145  \n",
      "<<<iteration:[280/878] - total_loss: 3.3120  obj_loss: 0.0677  noobj_loss: 0.0319  bbox_loss: 0.1307  cls_loss: 2.5747  \n",
      "<<<iteration:[300/878] - total_loss: 2.9724  obj_loss: 0.0695  noobj_loss: 0.0304  bbox_loss: 0.1085  cls_loss: 2.3455  \n",
      "<<<iteration:[320/878] - total_loss: 3.0190  obj_loss: 0.0958  noobj_loss: 0.0366  bbox_loss: 0.1050  cls_loss: 2.3799  \n",
      "<<<iteration:[340/878] - total_loss: 3.7508  obj_loss: 0.0909  noobj_loss: 0.0341  bbox_loss: 0.1842  cls_loss: 2.7219  \n",
      "<<<iteration:[360/878] - total_loss: 2.7727  obj_loss: 0.0874  noobj_loss: 0.0336  bbox_loss: 0.0954  cls_loss: 2.1913  \n",
      "<<<iteration:[380/878] - total_loss: 3.0385  obj_loss: 0.0779  noobj_loss: 0.0295  bbox_loss: 0.1183  cls_loss: 2.3546  \n",
      "<<<iteration:[400/878] - total_loss: 3.0489  obj_loss: 0.1121  noobj_loss: 0.0345  bbox_loss: 0.0965  cls_loss: 2.4371  \n",
      "<<<iteration:[420/878] - total_loss: 3.3178  obj_loss: 0.0864  noobj_loss: 0.0261  bbox_loss: 0.1147  cls_loss: 2.6448  \n",
      "<<<iteration:[440/878] - total_loss: 2.9729  obj_loss: 0.0623  noobj_loss: 0.0356  bbox_loss: 0.1191  cls_loss: 2.2974  \n",
      "<<<iteration:[460/878] - total_loss: 3.3789  obj_loss: 0.0930  noobj_loss: 0.0359  bbox_loss: 0.1511  cls_loss: 2.5123  \n",
      "<<<iteration:[480/878] - total_loss: 2.9724  obj_loss: 0.0590  noobj_loss: 0.0486  bbox_loss: 0.1513  cls_loss: 2.1324  \n",
      "<<<iteration:[500/878] - total_loss: 3.4625  obj_loss: 0.1117  noobj_loss: 0.0399  bbox_loss: 0.1494  cls_loss: 2.5839  \n",
      "<<<iteration:[520/878] - total_loss: 3.1146  obj_loss: 0.0893  noobj_loss: 0.0352  bbox_loss: 0.1166  cls_loss: 2.4249  \n",
      "<<<iteration:[540/878] - total_loss: 3.3554  obj_loss: 0.1072  noobj_loss: 0.0295  bbox_loss: 0.1330  cls_loss: 2.5682  \n",
      "<<<iteration:[560/878] - total_loss: 3.4056  obj_loss: 0.0883  noobj_loss: 0.0298  bbox_loss: 0.1392  cls_loss: 2.6065  \n",
      "<<<iteration:[580/878] - total_loss: 3.3546  obj_loss: 0.0815  noobj_loss: 0.0307  bbox_loss: 0.1719  cls_loss: 2.3982  \n",
      "<<<iteration:[600/878] - total_loss: 3.0122  obj_loss: 0.0993  noobj_loss: 0.0331  bbox_loss: 0.1130  cls_loss: 2.3312  \n",
      "<<<iteration:[620/878] - total_loss: 2.9099  obj_loss: 0.0812  noobj_loss: 0.0362  bbox_loss: 0.1279  cls_loss: 2.1711  \n",
      "<<<iteration:[640/878] - total_loss: 3.2265  obj_loss: 0.0941  noobj_loss: 0.0531  bbox_loss: 0.1397  cls_loss: 2.4072  \n",
      "<<<iteration:[660/878] - total_loss: 2.9459  obj_loss: 0.0735  noobj_loss: 0.0325  bbox_loss: 0.0963  cls_loss: 2.3749  \n",
      "<<<iteration:[680/878] - total_loss: 3.7159  obj_loss: 0.0803  noobj_loss: 0.0392  bbox_loss: 0.2100  cls_loss: 2.5661  \n",
      "<<<iteration:[700/878] - total_loss: 3.3970  obj_loss: 0.0976  noobj_loss: 0.0402  bbox_loss: 0.1539  cls_loss: 2.5099  \n",
      "<<<iteration:[720/878] - total_loss: 2.8284  obj_loss: 0.0829  noobj_loss: 0.0341  bbox_loss: 0.1099  cls_loss: 2.1790  \n",
      "<<<iteration:[740/878] - total_loss: 3.0293  obj_loss: 0.0736  noobj_loss: 0.0313  bbox_loss: 0.1279  cls_loss: 2.3005  \n",
      "<<<iteration:[760/878] - total_loss: 3.4941  obj_loss: 0.1121  noobj_loss: 0.0282  bbox_loss: 0.1568  cls_loss: 2.5840  \n",
      "<<<iteration:[780/878] - total_loss: 3.0191  obj_loss: 0.0604  noobj_loss: 0.0244  bbox_loss: 0.1254  cls_loss: 2.3194  \n",
      "<<<iteration:[800/878] - total_loss: 3.1179  obj_loss: 0.0587  noobj_loss: 0.0356  bbox_loss: 0.1443  cls_loss: 2.3198  \n",
      "<<<iteration:[820/878] - total_loss: 3.5604  obj_loss: 0.0704  noobj_loss: 0.0459  bbox_loss: 0.2167  cls_loss: 2.3833  \n",
      "<<<iteration:[840/878] - total_loss: 28.7419  obj_loss: 0.0821  noobj_loss: 0.1495  bbox_loss: 5.1596  cls_loss: 2.7872  \n",
      "<<<iteration:[860/878] - total_loss: 7.1348  obj_loss: 0.0648  noobj_loss: 0.1340  bbox_loss: 0.8444  cls_loss: 2.7811  \n",
      "\n",
      "epoch:6/100 - Train Loss: 4.0385, Val Loss: 6.2368\n",
      "\n",
      "<<<iteration:[20/878] - total_loss: 9.2140  obj_loss: 0.0793  noobj_loss: 0.2489  bbox_loss: 1.2998  cls_loss: 2.5113  \n",
      "<<<iteration:[40/878] - total_loss: 6.7048  obj_loss: 0.0391  noobj_loss: 0.2124  bbox_loss: 0.7876  cls_loss: 2.6216  \n",
      "<<<iteration:[60/878] - total_loss: 9.8577  obj_loss: 0.0334  noobj_loss: 0.1528  bbox_loss: 1.4229  cls_loss: 2.6334  \n",
      "<<<iteration:[80/878] - total_loss: 8.4618  obj_loss: 0.0553  noobj_loss: 0.1695  bbox_loss: 1.0904  cls_loss: 2.8699  \n",
      "<<<iteration:[100/878] - total_loss: 5.2683  obj_loss: 0.0895  noobj_loss: 0.1311  bbox_loss: 0.5551  cls_loss: 2.3375  \n",
      "<<<iteration:[120/878] - total_loss: 4.7603  obj_loss: 0.0451  noobj_loss: 0.1327  bbox_loss: 0.4771  cls_loss: 2.2635  \n",
      "<<<iteration:[140/878] - total_loss: 5.1202  obj_loss: 0.0623  noobj_loss: 0.1236  bbox_loss: 0.4979  cls_loss: 2.5065  \n",
      "<<<iteration:[160/878] - total_loss: 5.6439  obj_loss: 0.0653  noobj_loss: 0.0958  bbox_loss: 0.5197  cls_loss: 2.9324  \n",
      "<<<iteration:[180/878] - total_loss: 4.5895  obj_loss: 0.0598  noobj_loss: 0.0879  bbox_loss: 0.4066  cls_loss: 2.4526  \n",
      "<<<iteration:[200/878] - total_loss: 4.9201  obj_loss: 0.0682  noobj_loss: 0.0839  bbox_loss: 0.4606  cls_loss: 2.5071  \n",
      "<<<iteration:[220/878] - total_loss: 5.8262  obj_loss: 0.0549  noobj_loss: 0.0891  bbox_loss: 0.5686  cls_loss: 2.8836  \n",
      "<<<iteration:[240/878] - total_loss: 8.0998  obj_loss: 0.0496  noobj_loss: 0.0735  bbox_loss: 1.0620  cls_loss: 2.7033  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<<<iteration:[260/878] - total_loss: 6.0623  obj_loss: 0.0473  noobj_loss: 0.0639  bbox_loss: 0.7119  cls_loss: 2.4235  \n",
      "<<<iteration:[280/878] - total_loss: 4.3954  obj_loss: 0.0522  noobj_loss: 0.0665  bbox_loss: 0.3426  cls_loss: 2.5967  \n",
      "<<<iteration:[300/878] - total_loss: 4.7539  obj_loss: 0.0608  noobj_loss: 0.0827  bbox_loss: 0.4186  cls_loss: 2.5586  \n",
      "<<<iteration:[320/878] - total_loss: 4.1681  obj_loss: 0.0495  noobj_loss: 0.0518  bbox_loss: 0.3542  cls_loss: 2.3219  \n",
      "<<<iteration:[340/878] - total_loss: 4.0271  obj_loss: 0.0765  noobj_loss: 0.0607  bbox_loss: 0.3117  cls_loss: 2.3618  \n",
      "<<<iteration:[360/878] - total_loss: 3.9393  obj_loss: 0.0515  noobj_loss: 0.0491  bbox_loss: 0.2879  cls_loss: 2.4236  \n",
      "<<<iteration:[380/878] - total_loss: 4.1947  obj_loss: 0.0982  noobj_loss: 0.0419  bbox_loss: 0.3005  cls_loss: 2.5733  \n",
      "<<<iteration:[400/878] - total_loss: 4.0290  obj_loss: 0.0920  noobj_loss: 0.0570  bbox_loss: 0.2650  cls_loss: 2.5835  \n",
      "<<<iteration:[420/878] - total_loss: 3.6866  obj_loss: 0.0931  noobj_loss: 0.0510  bbox_loss: 0.2090  cls_loss: 2.5228  \n",
      "<<<iteration:[440/878] - total_loss: 3.7516  obj_loss: 0.0727  noobj_loss: 0.0359  bbox_loss: 0.1875  cls_loss: 2.7234  \n",
      "<<<iteration:[460/878] - total_loss: 3.4495  obj_loss: 0.0791  noobj_loss: 0.0431  bbox_loss: 0.1619  cls_loss: 2.5392  \n",
      "<<<iteration:[480/878] - total_loss: 4.5004  obj_loss: 0.0632  noobj_loss: 0.0447  bbox_loss: 0.3986  cls_loss: 2.4219  \n",
      "<<<iteration:[500/878] - total_loss: 4.7512  obj_loss: 0.0559  noobj_loss: 0.0939  bbox_loss: 0.4406  cls_loss: 2.4453  \n",
      "<<<iteration:[520/878] - total_loss: 6.6245  obj_loss: 0.0354  noobj_loss: 0.0773  bbox_loss: 0.7549  cls_loss: 2.7761  \n",
      "<<<iteration:[540/878] - total_loss: 7.6424  obj_loss: 0.0407  noobj_loss: 0.0499  bbox_loss: 0.9559  cls_loss: 2.7973  \n",
      "<<<iteration:[560/878] - total_loss: 7.8405  obj_loss: 0.0433  noobj_loss: 0.0484  bbox_loss: 0.9792  cls_loss: 2.8768  \n",
      "<<<iteration:[580/878] - total_loss: 4.5519  obj_loss: 0.0757  noobj_loss: 0.0584  bbox_loss: 0.3553  cls_loss: 2.6707  \n",
      "<<<iteration:[600/878] - total_loss: 4.1729  obj_loss: 0.0523  noobj_loss: 0.0539  bbox_loss: 0.3381  cls_loss: 2.4032  \n",
      "<<<iteration:[620/878] - total_loss: 3.8972  obj_loss: 0.0588  noobj_loss: 0.0465  bbox_loss: 0.3162  cls_loss: 2.2343  \n",
      "<<<iteration:[640/878] - total_loss: 3.3846  obj_loss: 0.0722  noobj_loss: 0.0593  bbox_loss: 0.1808  cls_loss: 2.3787  \n",
      "<<<iteration:[660/878] - total_loss: 3.9770  obj_loss: 0.0646  noobj_loss: 0.0535  bbox_loss: 0.3252  cls_loss: 2.2599  \n",
      "<<<iteration:[680/878] - total_loss: 4.0949  obj_loss: 0.0640  noobj_loss: 0.0361  bbox_loss: 0.2828  cls_loss: 2.5990  \n",
      "<<<iteration:[700/878] - total_loss: 4.3592  obj_loss: 0.0828  noobj_loss: 0.0525  bbox_loss: 0.3141  cls_loss: 2.6797  \n",
      "<<<iteration:[720/878] - total_loss: 3.3338  obj_loss: 0.0569  noobj_loss: 0.0346  bbox_loss: 0.1860  cls_loss: 2.3297  \n",
      "<<<iteration:[740/878] - total_loss: 4.0646  obj_loss: 0.0788  noobj_loss: 0.0351  bbox_loss: 0.2250  cls_loss: 2.8431  \n",
      "<<<iteration:[760/878] - total_loss: 3.4522  obj_loss: 0.0664  noobj_loss: 0.0390  bbox_loss: 0.1689  cls_loss: 2.5218  \n",
      "<<<iteration:[780/878] - total_loss: 4.3001  obj_loss: 0.0840  noobj_loss: 0.0350  bbox_loss: 0.3227  cls_loss: 2.5852  \n",
      "<<<iteration:[800/878] - total_loss: 4.7902  obj_loss: 0.0883  noobj_loss: 0.0329  bbox_loss: 0.3823  cls_loss: 2.7741  \n",
      "<<<iteration:[820/878] - total_loss: 3.5614  obj_loss: 0.0954  noobj_loss: 0.0686  bbox_loss: 0.2024  cls_loss: 2.4199  \n",
      "<<<iteration:[840/878] - total_loss: 3.3180  obj_loss: 0.0613  noobj_loss: 0.0303  bbox_loss: 0.1839  cls_loss: 2.3218  \n",
      "<<<iteration:[860/878] - total_loss: 3.6088  obj_loss: 0.0764  noobj_loss: 0.0439  bbox_loss: 0.2278  cls_loss: 2.3715  \n",
      "\n",
      "epoch:7/100 - Train Loss: 4.9691, Val Loss: 3.8766\n",
      "\n",
      "<<<iteration:[20/878] - total_loss: 5.6086  obj_loss: 0.0860  noobj_loss: 0.0458  bbox_loss: 0.5522  cls_loss: 2.7389  \n",
      "<<<iteration:[40/878] - total_loss: 3.5636  obj_loss: 0.0647  noobj_loss: 0.0500  bbox_loss: 0.2555  cls_loss: 2.1961  \n",
      "<<<iteration:[60/878] - total_loss: 3.6481  obj_loss: 0.0680  noobj_loss: 0.0550  bbox_loss: 0.2278  cls_loss: 2.4137  \n",
      "<<<iteration:[80/878] - total_loss: 3.5824  obj_loss: 0.0679  noobj_loss: 0.0406  bbox_loss: 0.2210  cls_loss: 2.3892  \n",
      "<<<iteration:[100/878] - total_loss: 4.0224  obj_loss: 0.0770  noobj_loss: 0.0306  bbox_loss: 0.2646  cls_loss: 2.6072  \n",
      "<<<iteration:[120/878] - total_loss: 3.1702  obj_loss: 0.0756  noobj_loss: 0.0391  bbox_loss: 0.1586  cls_loss: 2.2821  \n",
      "<<<iteration:[140/878] - total_loss: 4.2478  obj_loss: 0.0860  noobj_loss: 0.0359  bbox_loss: 0.3047  cls_loss: 2.6203  \n",
      "<<<iteration:[160/878] - total_loss: 3.4910  obj_loss: 0.0622  noobj_loss: 0.0347  bbox_loss: 0.2266  cls_loss: 2.2784  \n",
      "<<<iteration:[180/878] - total_loss: 4.0630  obj_loss: 0.1138  noobj_loss: 0.0442  bbox_loss: 0.2963  cls_loss: 2.4455  \n",
      "<<<iteration:[200/878] - total_loss: 4.0516  obj_loss: 0.0843  noobj_loss: 0.0361  bbox_loss: 0.2832  cls_loss: 2.5332  \n",
      "<<<iteration:[220/878] - total_loss: 3.8046  obj_loss: 0.0689  noobj_loss: 0.0290  bbox_loss: 0.2388  cls_loss: 2.5274  \n",
      "<<<iteration:[240/878] - total_loss: 3.4588  obj_loss: 0.0733  noobj_loss: 0.0413  bbox_loss: 0.2112  cls_loss: 2.3090  \n",
      "<<<iteration:[260/878] - total_loss: 4.6553  obj_loss: 0.0724  noobj_loss: 0.0417  bbox_loss: 0.4158  cls_loss: 2.4833  \n",
      "<<<iteration:[280/878] - total_loss: 3.4029  obj_loss: 0.0865  noobj_loss: 0.0390  bbox_loss: 0.1634  cls_loss: 2.4801  \n",
      "<<<iteration:[300/878] - total_loss: 3.4098  obj_loss: 0.0628  noobj_loss: 0.0279  bbox_loss: 0.1803  cls_loss: 2.4315  \n",
      "<<<iteration:[320/878] - total_loss: 3.7062  obj_loss: 0.0660  noobj_loss: 0.0359  bbox_loss: 0.2396  cls_loss: 2.4242  \n",
      "<<<iteration:[340/878] - total_loss: 3.6287  obj_loss: 0.0790  noobj_loss: 0.0377  bbox_loss: 0.2389  cls_loss: 2.3361  \n",
      "<<<iteration:[360/878] - total_loss: 3.3052  obj_loss: 0.0901  noobj_loss: 0.0329  bbox_loss: 0.1277  cls_loss: 2.5603  \n",
      "<<<iteration:[380/878] - total_loss: 3.7994  obj_loss: 0.0782  noobj_loss: 0.0339  bbox_loss: 0.2562  cls_loss: 2.4234  \n",
      "<<<iteration:[400/878] - total_loss: 4.1996  obj_loss: 0.0832  noobj_loss: 0.0514  bbox_loss: 0.2774  cls_loss: 2.7038  \n",
      "<<<iteration:[420/878] - total_loss: 4.2643  obj_loss: 0.0832  noobj_loss: 0.0262  bbox_loss: 0.2790  cls_loss: 2.7732  \n",
      "<<<iteration:[440/878] - total_loss: 4.4987  obj_loss: 0.0639  noobj_loss: 0.0383  bbox_loss: 0.4457  cls_loss: 2.1872  \n",
      "<<<iteration:[460/878] - total_loss: 3.6236  obj_loss: 0.0663  noobj_loss: 0.0339  bbox_loss: 0.2485  cls_loss: 2.2979  \n",
      "<<<iteration:[480/878] - total_loss: 4.5806  obj_loss: 0.0906  noobj_loss: 0.0280  bbox_loss: 0.3078  cls_loss: 2.9370  \n",
      "<<<iteration:[500/878] - total_loss: 3.7571  obj_loss: 0.0785  noobj_loss: 0.0408  bbox_loss: 0.2283  cls_loss: 2.5164  \n",
      "<<<iteration:[520/878] - total_loss: 3.6127  obj_loss: 0.0747  noobj_loss: 0.0274  bbox_loss: 0.2257  cls_loss: 2.3960  \n",
      "<<<iteration:[540/878] - total_loss: 4.0277  obj_loss: 0.0856  noobj_loss: 0.0245  bbox_loss: 0.2300  cls_loss: 2.7799  \n",
      "<<<iteration:[560/878] - total_loss: 3.2034  obj_loss: 0.0666  noobj_loss: 0.0279  bbox_loss: 0.2004  cls_loss: 2.1208  \n",
      "<<<iteration:[580/878] - total_loss: 3.5194  obj_loss: 0.0851  noobj_loss: 0.0377  bbox_loss: 0.1824  cls_loss: 2.5035  \n",
      "<<<iteration:[600/878] - total_loss: 4.5505  obj_loss: 0.0870  noobj_loss: 0.0397  bbox_loss: 0.3147  cls_loss: 2.8700  \n",
      "<<<iteration:[620/878] - total_loss: 3.4882  obj_loss: 0.0794  noobj_loss: 0.0278  bbox_loss: 0.1616  cls_loss: 2.5867  \n",
      "<<<iteration:[640/878] - total_loss: 3.6893  obj_loss: 0.1036  noobj_loss: 0.0309  bbox_loss: 0.1719  cls_loss: 2.7107  \n",
      "<<<iteration:[660/878] - total_loss: 3.1389  obj_loss: 0.0586  noobj_loss: 0.0234  bbox_loss: 0.1233  cls_loss: 2.4520  \n",
      "<<<iteration:[680/878] - total_loss: 3.5540  obj_loss: 0.0585  noobj_loss: 0.0296  bbox_loss: 0.2616  cls_loss: 2.1728  \n",
      "<<<iteration:[700/878] - total_loss: 5.3179  obj_loss: 0.0805  noobj_loss: 0.0296  bbox_loss: 0.5003  cls_loss: 2.7209  \n",
      "<<<iteration:[720/878] - total_loss: 3.4033  obj_loss: 0.0720  noobj_loss: 0.0428  bbox_loss: 0.1576  cls_loss: 2.5221  \n",
      "<<<iteration:[740/878] - total_loss: 3.0128  obj_loss: 0.0612  noobj_loss: 0.0245  bbox_loss: 0.1165  cls_loss: 2.3569  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<<<iteration:[760/878] - total_loss: 5.9978  obj_loss: 0.0853  noobj_loss: 0.0461  bbox_loss: 0.5644  cls_loss: 3.0677  \n",
      "<<<iteration:[780/878] - total_loss: 8.2605  obj_loss: 0.0718  noobj_loss: 0.0350  bbox_loss: 1.0932  cls_loss: 2.7051  \n",
      "<<<iteration:[800/878] - total_loss: 3.6422  obj_loss: 0.0692  noobj_loss: 0.0243  bbox_loss: 0.1718  cls_loss: 2.7018  \n",
      "<<<iteration:[820/878] - total_loss: 4.0444  obj_loss: 0.0649  noobj_loss: 0.0299  bbox_loss: 0.3021  cls_loss: 2.4541  \n",
      "<<<iteration:[840/878] - total_loss: 3.2356  obj_loss: 0.0909  noobj_loss: 0.0351  bbox_loss: 0.1535  cls_loss: 2.3597  \n",
      "<<<iteration:[860/878] - total_loss: 3.0565  obj_loss: 0.0720  noobj_loss: 0.0328  bbox_loss: 0.1205  cls_loss: 2.3654  \n",
      "\n",
      "epoch:8/100 - Train Loss: 3.9482, Val Loss: 3.4244\n",
      "\n",
      "<<<iteration:[20/878] - total_loss: 3.5157  obj_loss: 0.1134  noobj_loss: 0.0280  bbox_loss: 0.1430  cls_loss: 2.6733  \n",
      "<<<iteration:[40/878] - total_loss: 3.5268  obj_loss: 0.0638  noobj_loss: 0.0332  bbox_loss: 0.2061  cls_loss: 2.4158  \n",
      "<<<iteration:[60/878] - total_loss: 4.7705  obj_loss: 0.0917  noobj_loss: 0.0231  bbox_loss: 0.3879  cls_loss: 2.7277  \n",
      "<<<iteration:[80/878] - total_loss: 3.7676  obj_loss: 0.0680  noobj_loss: 0.0295  bbox_loss: 0.2102  cls_loss: 2.6339  \n",
      "<<<iteration:[100/878] - total_loss: 3.6468  obj_loss: 0.0849  noobj_loss: 0.0305  bbox_loss: 0.1932  cls_loss: 2.5806  \n",
      "<<<iteration:[120/878] - total_loss: 3.3994  obj_loss: 0.0765  noobj_loss: 0.0256  bbox_loss: 0.1190  cls_loss: 2.7150  \n",
      "<<<iteration:[140/878] - total_loss: 3.1885  obj_loss: 0.0939  noobj_loss: 0.0264  bbox_loss: 0.1348  cls_loss: 2.4073  \n",
      "<<<iteration:[160/878] - total_loss: 3.5052  obj_loss: 0.0788  noobj_loss: 0.0494  bbox_loss: 0.1786  cls_loss: 2.5088  \n",
      "<<<iteration:[180/878] - total_loss: 3.7529  obj_loss: 0.0869  noobj_loss: 0.0259  bbox_loss: 0.3151  cls_loss: 2.0776  \n",
      "<<<iteration:[200/878] - total_loss: 3.9527  obj_loss: 0.0825  noobj_loss: 0.0317  bbox_loss: 0.2561  cls_loss: 2.5739  \n",
      "<<<iteration:[220/878] - total_loss: 3.4369  obj_loss: 0.0884  noobj_loss: 0.0274  bbox_loss: 0.2067  cls_loss: 2.3016  \n",
      "<<<iteration:[240/878] - total_loss: 3.6643  obj_loss: 0.0909  noobj_loss: 0.0330  bbox_loss: 0.1592  cls_loss: 2.7608  \n",
      "<<<iteration:[260/878] - total_loss: 4.2607  obj_loss: 0.0643  noobj_loss: 0.0330  bbox_loss: 0.3353  cls_loss: 2.5032  \n",
      "<<<iteration:[280/878] - total_loss: 3.5830  obj_loss: 0.0763  noobj_loss: 0.0197  bbox_loss: 0.1941  cls_loss: 2.5264  \n",
      "<<<iteration:[300/878] - total_loss: 3.4266  obj_loss: 0.0903  noobj_loss: 0.0367  bbox_loss: 0.1657  cls_loss: 2.4896  \n",
      "<<<iteration:[320/878] - total_loss: 3.3501  obj_loss: 0.0873  noobj_loss: 0.0371  bbox_loss: 0.1888  cls_loss: 2.2999  \n",
      "<<<iteration:[340/878] - total_loss: 3.1387  obj_loss: 0.0801  noobj_loss: 0.0301  bbox_loss: 0.1344  cls_loss: 2.3718  \n",
      "<<<iteration:[360/878] - total_loss: 3.2887  obj_loss: 0.0910  noobj_loss: 0.0266  bbox_loss: 0.1148  cls_loss: 2.6101  \n",
      "<<<iteration:[380/878] - total_loss: 4.3056  obj_loss: 0.0823  noobj_loss: 0.0268  bbox_loss: 0.3261  cls_loss: 2.5794  \n",
      "<<<iteration:[400/878] - total_loss: 3.4730  obj_loss: 0.1018  noobj_loss: 0.0274  bbox_loss: 0.1510  cls_loss: 2.6024  \n",
      "<<<iteration:[420/878] - total_loss: 2.9681  obj_loss: 0.0776  noobj_loss: 0.0296  bbox_loss: 0.1066  cls_loss: 2.3427  \n",
      "<<<iteration:[440/878] - total_loss: 3.1757  obj_loss: 0.0871  noobj_loss: 0.0247  bbox_loss: 0.1375  cls_loss: 2.3888  \n",
      "<<<iteration:[460/878] - total_loss: 2.8874  obj_loss: 0.0716  noobj_loss: 0.0247  bbox_loss: 0.1028  cls_loss: 2.2894  \n",
      "<<<iteration:[480/878] - total_loss: 3.0201  obj_loss: 0.0887  noobj_loss: 0.0261  bbox_loss: 0.1142  cls_loss: 2.3475  \n",
      "<<<iteration:[500/878] - total_loss: 3.0211  obj_loss: 0.0833  noobj_loss: 0.0252  bbox_loss: 0.1046  cls_loss: 2.4023  \n",
      "<<<iteration:[520/878] - total_loss: 4.5420  obj_loss: 0.0802  noobj_loss: 0.0419  bbox_loss: 0.4207  cls_loss: 2.3375  \n",
      "<<<iteration:[540/878] - total_loss: 4.9683  obj_loss: 0.0948  noobj_loss: 0.0282  bbox_loss: 0.5058  cls_loss: 2.3305  \n",
      "<<<iteration:[560/878] - total_loss: 3.3981  obj_loss: 0.0804  noobj_loss: 0.0245  bbox_loss: 0.2140  cls_loss: 2.2357  \n",
      "<<<iteration:[580/878] - total_loss: 3.3587  obj_loss: 0.0863  noobj_loss: 0.0265  bbox_loss: 0.1464  cls_loss: 2.5272  \n",
      "<<<iteration:[600/878] - total_loss: 3.2661  obj_loss: 0.0751  noobj_loss: 0.0242  bbox_loss: 0.1374  cls_loss: 2.4920  \n",
      "<<<iteration:[620/878] - total_loss: 4.4846  obj_loss: 0.0673  noobj_loss: 0.0284  bbox_loss: 0.4131  cls_loss: 2.3378  \n",
      "<<<iteration:[640/878] - total_loss: 3.6020  obj_loss: 0.0815  noobj_loss: 0.0355  bbox_loss: 0.1787  cls_loss: 2.6095  \n",
      "<<<iteration:[660/878] - total_loss: 4.3089  obj_loss: 0.0912  noobj_loss: 0.0370  bbox_loss: 0.3228  cls_loss: 2.5852  \n",
      "<<<iteration:[680/878] - total_loss: 4.4686  obj_loss: 0.0750  noobj_loss: 0.0254  bbox_loss: 0.3798  cls_loss: 2.4819  \n",
      "<<<iteration:[700/878] - total_loss: 4.3300  obj_loss: 0.0696  noobj_loss: 0.0336  bbox_loss: 0.3054  cls_loss: 2.7168  \n",
      "<<<iteration:[720/878] - total_loss: 3.7321  obj_loss: 0.0867  noobj_loss: 0.0277  bbox_loss: 0.2446  cls_loss: 2.4087  \n",
      "<<<iteration:[740/878] - total_loss: 3.5319  obj_loss: 0.1104  noobj_loss: 0.0319  bbox_loss: 0.1771  cls_loss: 2.5203  \n",
      "<<<iteration:[760/878] - total_loss: 3.6843  obj_loss: 0.0820  noobj_loss: 0.0290  bbox_loss: 0.2251  cls_loss: 2.4624  \n",
      "<<<iteration:[780/878] - total_loss: 3.6214  obj_loss: 0.0733  noobj_loss: 0.0257  bbox_loss: 0.1827  cls_loss: 2.6220  \n",
      "<<<iteration:[800/878] - total_loss: 2.9998  obj_loss: 0.0945  noobj_loss: 0.0361  bbox_loss: 0.1408  cls_loss: 2.1834  \n",
      "<<<iteration:[820/878] - total_loss: 3.7455  obj_loss: 0.1087  noobj_loss: 0.0379  bbox_loss: 0.1767  cls_loss: 2.7343  \n",
      "<<<iteration:[840/878] - total_loss: 4.2346  obj_loss: 0.1034  noobj_loss: 0.0252  bbox_loss: 0.2561  cls_loss: 2.8380  \n",
      "<<<iteration:[860/878] - total_loss: 3.3635  obj_loss: 0.0866  noobj_loss: 0.0269  bbox_loss: 0.1890  cls_loss: 2.3183  \n",
      "\n",
      "epoch:9/100 - Train Loss: 3.6653, Val Loss: 3.6664\n",
      "\n",
      "<<<iteration:[20/878] - total_loss: 3.8242  obj_loss: 0.1073  noobj_loss: 0.0336  bbox_loss: 0.2304  cls_loss: 2.5483  \n",
      "<<<iteration:[40/878] - total_loss: 3.6788  obj_loss: 0.0908  noobj_loss: 0.0343  bbox_loss: 0.1932  cls_loss: 2.6047  \n",
      "<<<iteration:[60/878] - total_loss: 3.1249  obj_loss: 0.0722  noobj_loss: 0.0237  bbox_loss: 0.1501  cls_loss: 2.2905  \n",
      "<<<iteration:[80/878] - total_loss: 3.3724  obj_loss: 0.0928  noobj_loss: 0.0243  bbox_loss: 0.1823  cls_loss: 2.3560  \n",
      "<<<iteration:[100/878] - total_loss: 3.4135  obj_loss: 0.0984  noobj_loss: 0.0282  bbox_loss: 0.1512  cls_loss: 2.5450  \n",
      "<<<iteration:[120/878] - total_loss: 3.9161  obj_loss: 0.0752  noobj_loss: 0.0243  bbox_loss: 0.2770  cls_loss: 2.4439  \n",
      "<<<iteration:[140/878] - total_loss: 3.6950  obj_loss: 0.0844  noobj_loss: 0.0214  bbox_loss: 0.2652  cls_loss: 2.2738  \n",
      "<<<iteration:[160/878] - total_loss: 3.2182  obj_loss: 0.0844  noobj_loss: 0.0225  bbox_loss: 0.1471  cls_loss: 2.3870  \n",
      "<<<iteration:[180/878] - total_loss: 3.3803  obj_loss: 0.0942  noobj_loss: 0.0271  bbox_loss: 0.1336  cls_loss: 2.6045  \n",
      "<<<iteration:[200/878] - total_loss: 4.6147  obj_loss: 0.0986  noobj_loss: 0.0285  bbox_loss: 0.3651  cls_loss: 2.6765  \n",
      "<<<iteration:[220/878] - total_loss: 3.1027  obj_loss: 0.0690  noobj_loss: 0.0250  bbox_loss: 0.1329  cls_loss: 2.3568  \n",
      "<<<iteration:[240/878] - total_loss: 3.6860  obj_loss: 0.0639  noobj_loss: 0.0290  bbox_loss: 0.2227  cls_loss: 2.4939  \n",
      "<<<iteration:[260/878] - total_loss: 3.3271  obj_loss: 0.0866  noobj_loss: 0.0295  bbox_loss: 0.1601  cls_loss: 2.4255  \n",
      "<<<iteration:[280/878] - total_loss: 3.2224  obj_loss: 0.0881  noobj_loss: 0.0289  bbox_loss: 0.1678  cls_loss: 2.2808  \n",
      "<<<iteration:[300/878] - total_loss: 3.3054  obj_loss: 0.0882  noobj_loss: 0.0230  bbox_loss: 0.1223  cls_loss: 2.5940  \n",
      "<<<iteration:[320/878] - total_loss: 3.1840  obj_loss: 0.0804  noobj_loss: 0.0229  bbox_loss: 0.1186  cls_loss: 2.4990  \n",
      "<<<iteration:[340/878] - total_loss: 3.2579  obj_loss: 0.0829  noobj_loss: 0.0302  bbox_loss: 0.1573  cls_loss: 2.3733  \n",
      "<<<iteration:[360/878] - total_loss: 3.6310  obj_loss: 0.0849  noobj_loss: 0.0269  bbox_loss: 0.1694  cls_loss: 2.6856  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<<<iteration:[380/878] - total_loss: 3.6968  obj_loss: 0.0861  noobj_loss: 0.0262  bbox_loss: 0.1969  cls_loss: 2.6132  \n",
      "<<<iteration:[400/878] - total_loss: 3.3783  obj_loss: 0.0797  noobj_loss: 0.0227  bbox_loss: 0.1484  cls_loss: 2.5451  \n",
      "<<<iteration:[420/878] - total_loss: 4.5724  obj_loss: 0.0784  noobj_loss: 0.0387  bbox_loss: 0.2836  cls_loss: 3.0569  \n",
      "<<<iteration:[440/878] - total_loss: 4.0861  obj_loss: 0.0633  noobj_loss: 0.0267  bbox_loss: 0.3058  cls_loss: 2.4806  \n",
      "<<<iteration:[460/878] - total_loss: 4.0546  obj_loss: 0.0700  noobj_loss: 0.0334  bbox_loss: 0.2941  cls_loss: 2.4976  \n",
      "<<<iteration:[480/878] - total_loss: 3.3747  obj_loss: 0.0894  noobj_loss: 0.0342  bbox_loss: 0.1553  cls_loss: 2.4918  \n",
      "<<<iteration:[500/878] - total_loss: 3.2763  obj_loss: 0.0751  noobj_loss: 0.0247  bbox_loss: 0.1407  cls_loss: 2.4854  \n",
      "<<<iteration:[520/878] - total_loss: 3.0527  obj_loss: 0.0583  noobj_loss: 0.0209  bbox_loss: 0.1337  cls_loss: 2.3156  \n",
      "<<<iteration:[540/878] - total_loss: 3.2982  obj_loss: 0.0733  noobj_loss: 0.0244  bbox_loss: 0.1242  cls_loss: 2.5918  \n",
      "<<<iteration:[560/878] - total_loss: 3.5540  obj_loss: 0.0895  noobj_loss: 0.0252  bbox_loss: 0.1999  cls_loss: 2.4523  \n",
      "<<<iteration:[580/878] - total_loss: 3.4084  obj_loss: 0.0879  noobj_loss: 0.0257  bbox_loss: 0.1754  cls_loss: 2.4307  \n",
      "<<<iteration:[600/878] - total_loss: 3.3016  obj_loss: 0.0665  noobj_loss: 0.0268  bbox_loss: 0.1313  cls_loss: 2.5653  \n",
      "<<<iteration:[620/878] - total_loss: 3.2779  obj_loss: 0.1159  noobj_loss: 0.0245  bbox_loss: 0.1266  cls_loss: 2.5166  \n",
      "<<<iteration:[640/878] - total_loss: 3.1178  obj_loss: 0.0864  noobj_loss: 0.0240  bbox_loss: 0.1301  cls_loss: 2.3692  \n",
      "<<<iteration:[660/878] - total_loss: 3.9494  obj_loss: 0.0706  noobj_loss: 0.0231  bbox_loss: 0.3159  cls_loss: 2.2878  \n",
      "<<<iteration:[680/878] - total_loss: 6.3471  obj_loss: 0.0691  noobj_loss: 0.0219  bbox_loss: 0.7513  cls_loss: 2.5107  \n",
      "<<<iteration:[700/878] - total_loss: 3.2523  obj_loss: 0.0801  noobj_loss: 0.0205  bbox_loss: 0.1608  cls_loss: 2.3580  \n",
      "<<<iteration:[720/878] - total_loss: 3.2690  obj_loss: 0.0761  noobj_loss: 0.0299  bbox_loss: 0.1389  cls_loss: 2.4836  \n",
      "<<<iteration:[740/878] - total_loss: 3.5789  obj_loss: 0.0827  noobj_loss: 0.0224  bbox_loss: 0.1801  cls_loss: 2.5847  \n",
      "<<<iteration:[760/878] - total_loss: 3.0288  obj_loss: 0.0787  noobj_loss: 0.0367  bbox_loss: 0.1517  cls_loss: 2.1730  \n",
      "<<<iteration:[780/878] - total_loss: 3.5454  obj_loss: 0.0936  noobj_loss: 0.0296  bbox_loss: 0.2203  cls_loss: 2.3353  \n",
      "<<<iteration:[800/878] - total_loss: 3.0661  obj_loss: 0.0675  noobj_loss: 0.0252  bbox_loss: 0.1110  cls_loss: 2.4307  \n",
      "<<<iteration:[820/878] - total_loss: 3.5761  obj_loss: 0.0862  noobj_loss: 0.0287  bbox_loss: 0.1807  cls_loss: 2.5720  \n",
      "<<<iteration:[840/878] - total_loss: 3.1149  obj_loss: 0.0724  noobj_loss: 0.0261  bbox_loss: 0.1354  cls_loss: 2.3525  \n",
      "<<<iteration:[860/878] - total_loss: 3.0952  obj_loss: 0.0801  noobj_loss: 0.0317  bbox_loss: 0.1277  cls_loss: 2.3609  \n",
      "\n",
      "epoch:10/100 - Train Loss: 3.5255, Val Loss: 3.0491\n",
      "\n",
      "<<<iteration:[20/878] - total_loss: 3.6971  obj_loss: 0.0775  noobj_loss: 0.0369  bbox_loss: 0.1560  cls_loss: 2.8211  \n",
      "<<<iteration:[40/878] - total_loss: 4.2177  obj_loss: 0.0657  noobj_loss: 0.0226  bbox_loss: 0.3154  cls_loss: 2.5640  \n",
      "<<<iteration:[60/878] - total_loss: 3.5075  obj_loss: 0.0751  noobj_loss: 0.0293  bbox_loss: 0.1887  cls_loss: 2.4742  \n",
      "<<<iteration:[80/878] - total_loss: 2.9209  obj_loss: 0.1084  noobj_loss: 0.0366  bbox_loss: 0.1362  cls_loss: 2.1135  \n",
      "<<<iteration:[100/878] - total_loss: 3.4915  obj_loss: 0.0924  noobj_loss: 0.0317  bbox_loss: 0.1914  cls_loss: 2.4264  \n",
      "<<<iteration:[120/878] - total_loss: 3.9790  obj_loss: 0.0857  noobj_loss: 0.0307  bbox_loss: 0.2498  cls_loss: 2.6287  \n",
      "<<<iteration:[140/878] - total_loss: 3.8385  obj_loss: 0.0912  noobj_loss: 0.0450  bbox_loss: 0.2715  cls_loss: 2.3673  \n",
      "<<<iteration:[160/878] - total_loss: 3.0459  obj_loss: 0.0953  noobj_loss: 0.0332  bbox_loss: 0.1122  cls_loss: 2.3729  \n",
      "<<<iteration:[180/878] - total_loss: 3.8999  obj_loss: 0.0736  noobj_loss: 0.0328  bbox_loss: 0.2253  cls_loss: 2.6835  \n",
      "<<<iteration:[200/878] - total_loss: 4.1449  obj_loss: 0.0606  noobj_loss: 0.0422  bbox_loss: 0.3440  cls_loss: 2.3430  \n",
      "<<<iteration:[220/878] - total_loss: 5.7798  obj_loss: 0.0681  noobj_loss: 0.0397  bbox_loss: 0.6143  cls_loss: 2.6203  \n",
      "<<<iteration:[240/878] - total_loss: 5.7243  obj_loss: 0.0611  noobj_loss: 0.0468  bbox_loss: 0.6185  cls_loss: 2.5474  \n",
      "<<<iteration:[260/878] - total_loss: 3.8746  obj_loss: 0.0800  noobj_loss: 0.0353  bbox_loss: 0.2703  cls_loss: 2.4255  \n",
      "<<<iteration:[280/878] - total_loss: 3.5508  obj_loss: 0.0898  noobj_loss: 0.0327  bbox_loss: 0.2274  cls_loss: 2.3075  \n",
      "<<<iteration:[300/878] - total_loss: 3.8805  obj_loss: 0.0740  noobj_loss: 0.0293  bbox_loss: 0.2126  cls_loss: 2.7289  \n",
      "<<<iteration:[320/878] - total_loss: 3.1110  obj_loss: 0.0723  noobj_loss: 0.0291  bbox_loss: 0.1326  cls_loss: 2.3610  \n",
      "<<<iteration:[340/878] - total_loss: 3.2697  obj_loss: 0.0752  noobj_loss: 0.0334  bbox_loss: 0.1479  cls_loss: 2.4384  \n",
      "<<<iteration:[360/878] - total_loss: 3.8561  obj_loss: 0.0899  noobj_loss: 0.0321  bbox_loss: 0.2251  cls_loss: 2.6249  \n",
      "<<<iteration:[380/878] - total_loss: 3.4401  obj_loss: 0.0820  noobj_loss: 0.0292  bbox_loss: 0.1549  cls_loss: 2.5687  \n",
      "<<<iteration:[400/878] - total_loss: 3.1843  obj_loss: 0.0815  noobj_loss: 0.0340  bbox_loss: 0.1147  cls_loss: 2.5122  \n",
      "<<<iteration:[420/878] - total_loss: 3.7478  obj_loss: 0.0663  noobj_loss: 0.0351  bbox_loss: 0.1919  cls_loss: 2.7043  \n",
      "<<<iteration:[440/878] - total_loss: 3.7584  obj_loss: 0.1004  noobj_loss: 0.0381  bbox_loss: 0.2236  cls_loss: 2.5212  \n",
      "<<<iteration:[460/878] - total_loss: 3.3519  obj_loss: 0.0763  noobj_loss: 0.0263  bbox_loss: 0.1083  cls_loss: 2.7210  \n",
      "<<<iteration:[480/878] - total_loss: 2.9922  obj_loss: 0.0797  noobj_loss: 0.0232  bbox_loss: 0.0951  cls_loss: 2.4254  \n",
      "<<<iteration:[500/878] - total_loss: 3.2058  obj_loss: 0.0770  noobj_loss: 0.0298  bbox_loss: 0.1272  cls_loss: 2.4780  \n",
      "<<<iteration:[520/878] - total_loss: 3.5476  obj_loss: 0.0868  noobj_loss: 0.0237  bbox_loss: 0.2108  cls_loss: 2.3949  \n",
      "<<<iteration:[540/878] - total_loss: 3.0474  obj_loss: 0.0991  noobj_loss: 0.0264  bbox_loss: 0.1193  cls_loss: 2.3386  \n",
      "<<<iteration:[560/878] - total_loss: 2.9559  obj_loss: 0.0817  noobj_loss: 0.0265  bbox_loss: 0.0859  cls_loss: 2.4316  \n",
      "<<<iteration:[580/878] - total_loss: 3.2160  obj_loss: 0.0896  noobj_loss: 0.0245  bbox_loss: 0.1258  cls_loss: 2.4850  \n",
      "<<<iteration:[600/878] - total_loss: 2.6996  obj_loss: 0.0934  noobj_loss: 0.0266  bbox_loss: 0.0828  cls_loss: 2.1790  \n",
      "<<<iteration:[620/878] - total_loss: 3.2992  obj_loss: 0.1198  noobj_loss: 0.0311  bbox_loss: 0.1204  cls_loss: 2.5620  \n",
      "<<<iteration:[640/878] - total_loss: 3.2295  obj_loss: 0.1150  noobj_loss: 0.0321  bbox_loss: 0.1122  cls_loss: 2.5372  \n",
      "<<<iteration:[660/878] - total_loss: 2.9153  obj_loss: 0.0777  noobj_loss: 0.0297  bbox_loss: 0.0998  cls_loss: 2.3238  \n",
      "<<<iteration:[680/878] - total_loss: 2.7358  obj_loss: 0.0918  noobj_loss: 0.0221  bbox_loss: 0.0946  cls_loss: 2.1602  \n",
      "<<<iteration:[700/878] - total_loss: 3.1789  obj_loss: 0.0960  noobj_loss: 0.0298  bbox_loss: 0.1362  cls_loss: 2.3872  \n",
      "<<<iteration:[720/878] - total_loss: 3.3330  obj_loss: 0.0851  noobj_loss: 0.0541  bbox_loss: 0.1813  cls_loss: 2.3145  \n",
      "<<<iteration:[740/878] - total_loss: 3.3765  obj_loss: 0.1047  noobj_loss: 0.0271  bbox_loss: 0.1253  cls_loss: 2.6318  \n",
      "<<<iteration:[760/878] - total_loss: 3.3186  obj_loss: 0.0729  noobj_loss: 0.0290  bbox_loss: 0.1481  cls_loss: 2.4909  \n",
      "<<<iteration:[780/878] - total_loss: 2.8401  obj_loss: 0.0964  noobj_loss: 0.0253  bbox_loss: 0.1082  cls_loss: 2.1902  \n",
      "<<<iteration:[800/878] - total_loss: 2.9853  obj_loss: 0.0794  noobj_loss: 0.0312  bbox_loss: 0.1098  cls_loss: 2.3412  \n",
      "<<<iteration:[820/878] - total_loss: 3.1695  obj_loss: 0.0701  noobj_loss: 0.0210  bbox_loss: 0.1265  cls_loss: 2.4564  \n",
      "<<<iteration:[840/878] - total_loss: 3.0477  obj_loss: 0.0795  noobj_loss: 0.0226  bbox_loss: 0.1088  cls_loss: 2.4127  \n",
      "<<<iteration:[860/878] - total_loss: 3.1064  obj_loss: 0.0736  noobj_loss: 0.0226  bbox_loss: 0.1138  cls_loss: 2.4524  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "epoch:11/100 - Train Loss: 3.4695, Val Loss: 3.2966\n",
      "\n",
      "<<<iteration:[20/878] - total_loss: 3.6305  obj_loss: 0.0711  noobj_loss: 0.0234  bbox_loss: 0.1445  cls_loss: 2.8253  \n",
      "<<<iteration:[40/878] - total_loss: 3.2215  obj_loss: 0.0960  noobj_loss: 0.0203  bbox_loss: 0.1149  cls_loss: 2.5408  \n",
      "<<<iteration:[60/878] - total_loss: 2.9505  obj_loss: 0.1287  noobj_loss: 0.0258  bbox_loss: 0.0973  cls_loss: 2.3226  \n",
      "<<<iteration:[80/878] - total_loss: 3.4688  obj_loss: 0.0975  noobj_loss: 0.0324  bbox_loss: 0.1398  cls_loss: 2.6559  \n",
      "<<<iteration:[100/878] - total_loss: 3.2309  obj_loss: 0.1003  noobj_loss: 0.0243  bbox_loss: 0.1173  cls_loss: 2.5318  \n",
      "<<<iteration:[120/878] - total_loss: 3.6130  obj_loss: 0.0891  noobj_loss: 0.0265  bbox_loss: 0.1988  cls_loss: 2.5169  \n",
      "<<<iteration:[140/878] - total_loss: 4.0931  obj_loss: 0.0706  noobj_loss: 0.0452  bbox_loss: 0.3184  cls_loss: 2.4078  \n",
      "<<<iteration:[160/878] - total_loss: 2.6663  obj_loss: 0.0977  noobj_loss: 0.0206  bbox_loss: 0.0948  cls_loss: 2.0843  \n",
      "<<<iteration:[180/878] - total_loss: 3.1520  obj_loss: 0.0683  noobj_loss: 0.0181  bbox_loss: 0.1245  cls_loss: 2.4523  \n",
      "<<<iteration:[200/878] - total_loss: 3.2451  obj_loss: 0.0604  noobj_loss: 0.0203  bbox_loss: 0.1671  cls_loss: 2.3391  \n",
      "<<<iteration:[220/878] - total_loss: 3.2155  obj_loss: 0.0786  noobj_loss: 0.0202  bbox_loss: 0.1071  cls_loss: 2.5913  \n",
      "<<<iteration:[240/878] - total_loss: 3.0656  obj_loss: 0.0935  noobj_loss: 0.0259  bbox_loss: 0.1073  cls_loss: 2.4226  \n",
      "<<<iteration:[260/878] - total_loss: 3.0852  obj_loss: 0.0776  noobj_loss: 0.0254  bbox_loss: 0.1215  cls_loss: 2.3876  \n",
      "<<<iteration:[280/878] - total_loss: 3.1998  obj_loss: 0.0974  noobj_loss: 0.0273  bbox_loss: 0.1336  cls_loss: 2.4211  \n",
      "<<<iteration:[300/878] - total_loss: 3.8416  obj_loss: 0.0905  noobj_loss: 0.0282  bbox_loss: 0.2075  cls_loss: 2.6995  \n",
      "<<<iteration:[320/878] - total_loss: 3.3912  obj_loss: 0.0809  noobj_loss: 0.0292  bbox_loss: 0.1882  cls_loss: 2.3546  \n",
      "<<<iteration:[340/878] - total_loss: 3.3241  obj_loss: 0.0881  noobj_loss: 0.0274  bbox_loss: 0.1417  cls_loss: 2.5140  \n",
      "<<<iteration:[360/878] - total_loss: 3.0836  obj_loss: 0.0900  noobj_loss: 0.0235  bbox_loss: 0.1015  cls_loss: 2.4745  \n",
      "<<<iteration:[380/878] - total_loss: 3.1041  obj_loss: 0.0774  noobj_loss: 0.0209  bbox_loss: 0.1197  cls_loss: 2.4179  \n",
      "<<<iteration:[400/878] - total_loss: 2.9468  obj_loss: 0.0765  noobj_loss: 0.0193  bbox_loss: 0.1170  cls_loss: 2.2755  \n",
      "<<<iteration:[420/878] - total_loss: 2.9428  obj_loss: 0.0704  noobj_loss: 0.0187  bbox_loss: 0.1225  cls_loss: 2.2507  \n",
      "<<<iteration:[440/878] - total_loss: 3.1592  obj_loss: 0.0726  noobj_loss: 0.0232  bbox_loss: 0.1309  cls_loss: 2.4205  \n",
      "<<<iteration:[460/878] - total_loss: 3.0748  obj_loss: 0.1182  noobj_loss: 0.0357  bbox_loss: 0.1027  cls_loss: 2.4254  \n",
      "<<<iteration:[480/878] - total_loss: 2.7083  obj_loss: 0.0739  noobj_loss: 0.0338  bbox_loss: 0.0770  cls_loss: 2.2327  \n",
      "<<<iteration:[500/878] - total_loss: 3.4721  obj_loss: 0.1146  noobj_loss: 0.0276  bbox_loss: 0.1560  cls_loss: 2.5638  \n",
      "<<<iteration:[520/878] - total_loss: 3.5223  obj_loss: 0.0788  noobj_loss: 0.0476  bbox_loss: 0.1758  cls_loss: 2.5406  \n",
      "<<<iteration:[540/878] - total_loss: 3.3287  obj_loss: 0.0799  noobj_loss: 0.0381  bbox_loss: 0.1734  cls_loss: 2.3629  \n",
      "<<<iteration:[560/878] - total_loss: 2.9978  obj_loss: 0.0795  noobj_loss: 0.0246  bbox_loss: 0.1496  cls_loss: 2.1582  \n",
      "<<<iteration:[580/878] - total_loss: 3.3334  obj_loss: 0.0993  noobj_loss: 0.0322  bbox_loss: 0.1562  cls_loss: 2.4371  \n",
      "<<<iteration:[600/878] - total_loss: 3.2095  obj_loss: 0.0871  noobj_loss: 0.0366  bbox_loss: 0.1154  cls_loss: 2.5273  \n",
      "<<<iteration:[620/878] - total_loss: 3.1011  obj_loss: 0.0771  noobj_loss: 0.0216  bbox_loss: 0.1153  cls_loss: 2.4367  \n",
      "<<<iteration:[640/878] - total_loss: 3.2907  obj_loss: 0.0943  noobj_loss: 0.0240  bbox_loss: 0.1687  cls_loss: 2.3408  \n",
      "<<<iteration:[660/878] - total_loss: 3.3565  obj_loss: 0.0627  noobj_loss: 0.0251  bbox_loss: 0.1929  cls_loss: 2.3166  \n",
      "<<<iteration:[680/878] - total_loss: 4.1151  obj_loss: 0.0698  noobj_loss: 0.0304  bbox_loss: 0.2700  cls_loss: 2.6802  \n",
      "<<<iteration:[700/878] - total_loss: 3.1742  obj_loss: 0.0799  noobj_loss: 0.0196  bbox_loss: 0.1109  cls_loss: 2.5300  \n",
      "<<<iteration:[720/878] - total_loss: 3.4371  obj_loss: 0.1100  noobj_loss: 0.0279  bbox_loss: 0.1601  cls_loss: 2.5125  \n",
      "<<<iteration:[740/878] - total_loss: 3.1752  obj_loss: 0.0926  noobj_loss: 0.0319  bbox_loss: 0.0995  cls_loss: 2.5691  \n",
      "<<<iteration:[760/878] - total_loss: 3.1400  obj_loss: 0.0732  noobj_loss: 0.0234  bbox_loss: 0.1340  cls_loss: 2.3851  \n",
      "<<<iteration:[780/878] - total_loss: 3.4520  obj_loss: 0.0723  noobj_loss: 0.0205  bbox_loss: 0.1569  cls_loss: 2.5850  \n",
      "<<<iteration:[800/878] - total_loss: 3.6616  obj_loss: 0.0955  noobj_loss: 0.0223  bbox_loss: 0.1574  cls_loss: 2.7681  \n",
      "<<<iteration:[820/878] - total_loss: 3.0193  obj_loss: 0.0724  noobj_loss: 0.0246  bbox_loss: 0.1059  cls_loss: 2.4052  \n",
      "<<<iteration:[840/878] - total_loss: 2.8316  obj_loss: 0.0710  noobj_loss: 0.0219  bbox_loss: 0.0792  cls_loss: 2.3535  \n",
      "<<<iteration:[860/878] - total_loss: 3.2014  obj_loss: 0.0787  noobj_loss: 0.0171  bbox_loss: 0.1244  cls_loss: 2.4921  \n",
      "\n",
      "epoch:12/100 - Train Loss: 3.2509, Val Loss: 2.9251\n",
      "\n",
      "<<<iteration:[20/878] - total_loss: 3.5963  obj_loss: 0.0859  noobj_loss: 0.0224  bbox_loss: 0.1842  cls_loss: 2.5784  \n",
      "<<<iteration:[40/878] - total_loss: 2.9584  obj_loss: 0.0922  noobj_loss: 0.0251  bbox_loss: 0.1211  cls_loss: 2.2482  \n",
      "<<<iteration:[60/878] - total_loss: 3.1494  obj_loss: 0.0700  noobj_loss: 0.0268  bbox_loss: 0.1716  cls_loss: 2.2079  \n",
      "<<<iteration:[80/878] - total_loss: 4.0461  obj_loss: 0.0862  noobj_loss: 0.0285  bbox_loss: 0.2297  cls_loss: 2.7969  \n",
      "<<<iteration:[100/878] - total_loss: 3.5972  obj_loss: 0.1012  noobj_loss: 0.0321  bbox_loss: 0.2048  cls_loss: 2.4562  \n",
      "<<<iteration:[120/878] - total_loss: 12.6490  obj_loss: 0.0742  noobj_loss: 0.0679  bbox_loss: 2.0567  cls_loss: 2.2576  \n",
      "<<<iteration:[140/878] - total_loss: 14.3650  obj_loss: 0.0675  noobj_loss: 0.0487  bbox_loss: 2.3649  cls_loss: 2.4487  \n",
      "<<<iteration:[160/878] - total_loss: 10.1723  obj_loss: 0.0993  noobj_loss: 0.0521  bbox_loss: 1.4748  cls_loss: 2.6732  \n",
      "<<<iteration:[180/878] - total_loss: 6.5180  obj_loss: 0.0867  noobj_loss: 0.0545  bbox_loss: 0.7576  cls_loss: 2.6158  \n",
      "<<<iteration:[200/878] - total_loss: 5.6187  obj_loss: 0.0736  noobj_loss: 0.0664  bbox_loss: 0.6650  cls_loss: 2.1870  \n",
      "<<<iteration:[220/878] - total_loss: 4.5952  obj_loss: 0.0634  noobj_loss: 0.0552  bbox_loss: 0.4269  cls_loss: 2.3698  \n",
      "<<<iteration:[240/878] - total_loss: 4.0521  obj_loss: 0.0942  noobj_loss: 0.0475  bbox_loss: 0.3159  cls_loss: 2.3545  \n",
      "<<<iteration:[260/878] - total_loss: 5.3008  obj_loss: 0.0752  noobj_loss: 0.0449  bbox_loss: 0.4641  cls_loss: 2.8825  \n",
      "<<<iteration:[280/878] - total_loss: 3.2525  obj_loss: 0.0931  noobj_loss: 0.0452  bbox_loss: 0.1512  cls_loss: 2.3810  \n",
      "<<<iteration:[300/878] - total_loss: 6.6704  obj_loss: 0.0792  noobj_loss: 0.0581  bbox_loss: 0.7661  cls_loss: 2.7316  \n",
      "<<<iteration:[320/878] - total_loss: 4.7913  obj_loss: 0.0793  noobj_loss: 0.0440  bbox_loss: 0.4137  cls_loss: 2.6214  \n",
      "<<<iteration:[340/878] - total_loss: 3.6936  obj_loss: 0.0925  noobj_loss: 0.0367  bbox_loss: 0.2272  cls_loss: 2.4466  \n",
      "<<<iteration:[360/878] - total_loss: 4.4593  obj_loss: 0.0899  noobj_loss: 0.0324  bbox_loss: 0.3280  cls_loss: 2.7133  \n",
      "<<<iteration:[380/878] - total_loss: 3.2144  obj_loss: 0.0713  noobj_loss: 0.0354  bbox_loss: 0.1605  cls_loss: 2.3228  \n",
      "<<<iteration:[400/878] - total_loss: 3.3295  obj_loss: 0.0694  noobj_loss: 0.0284  bbox_loss: 0.1630  cls_loss: 2.4311  \n",
      "<<<iteration:[420/878] - total_loss: 3.8983  obj_loss: 0.0791  noobj_loss: 0.0271  bbox_loss: 0.2311  cls_loss: 2.6502  \n",
      "<<<iteration:[440/878] - total_loss: 3.5727  obj_loss: 0.0718  noobj_loss: 0.0316  bbox_loss: 0.2073  cls_loss: 2.4486  \n",
      "<<<iteration:[460/878] - total_loss: 4.1738  obj_loss: 0.1026  noobj_loss: 0.0301  bbox_loss: 0.2720  cls_loss: 2.6960  \n",
      "<<<iteration:[480/878] - total_loss: 3.3722  obj_loss: 0.0791  noobj_loss: 0.0350  bbox_loss: 0.1531  cls_loss: 2.5102  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<<<iteration:[500/878] - total_loss: 3.1204  obj_loss: 0.0764  noobj_loss: 0.0353  bbox_loss: 0.1507  cls_loss: 2.2726  \n",
      "<<<iteration:[520/878] - total_loss: 3.3177  obj_loss: 0.1119  noobj_loss: 0.0286  bbox_loss: 0.1545  cls_loss: 2.4189  \n",
      "<<<iteration:[540/878] - total_loss: 4.6108  obj_loss: 0.0748  noobj_loss: 0.0387  bbox_loss: 0.3856  cls_loss: 2.5886  \n",
      "<<<iteration:[560/878] - total_loss: 3.2784  obj_loss: 0.0901  noobj_loss: 0.0245  bbox_loss: 0.1398  cls_loss: 2.4771  \n",
      "<<<iteration:[580/878] - total_loss: 2.9211  obj_loss: 0.0743  noobj_loss: 0.0332  bbox_loss: 0.0964  cls_loss: 2.3481  \n",
      "<<<iteration:[600/878] - total_loss: 3.1405  obj_loss: 0.0959  noobj_loss: 0.0287  bbox_loss: 0.1406  cls_loss: 2.3275  \n",
      "<<<iteration:[620/878] - total_loss: 2.8808  obj_loss: 0.0975  noobj_loss: 0.0229  bbox_loss: 0.1083  cls_loss: 2.2304  \n",
      "<<<iteration:[640/878] - total_loss: 3.1792  obj_loss: 0.0674  noobj_loss: 0.0252  bbox_loss: 0.1139  cls_loss: 2.5297  \n",
      "<<<iteration:[660/878] - total_loss: 3.0839  obj_loss: 0.1034  noobj_loss: 0.0285  bbox_loss: 0.1129  cls_loss: 2.4019  \n",
      "<<<iteration:[680/878] - total_loss: 3.5316  obj_loss: 0.0953  noobj_loss: 0.0240  bbox_loss: 0.1567  cls_loss: 2.6411  \n",
      "<<<iteration:[700/878] - total_loss: 3.3799  obj_loss: 0.1095  noobj_loss: 0.0244  bbox_loss: 0.1289  cls_loss: 2.6134  \n",
      "<<<iteration:[720/878] - total_loss: 3.3180  obj_loss: 0.0776  noobj_loss: 0.0286  bbox_loss: 0.1636  cls_loss: 2.4083  \n",
      "<<<iteration:[740/878] - total_loss: 3.5957  obj_loss: 0.0646  noobj_loss: 0.0293  bbox_loss: 0.1800  cls_loss: 2.6165  \n",
      "<<<iteration:[760/878] - total_loss: 3.3839  obj_loss: 0.0862  noobj_loss: 0.0237  bbox_loss: 0.1433  cls_loss: 2.5694  \n",
      "<<<iteration:[780/878] - total_loss: 3.3246  obj_loss: 0.0807  noobj_loss: 0.0181  bbox_loss: 0.1684  cls_loss: 2.3927  \n",
      "<<<iteration:[800/878] - total_loss: 3.5583  obj_loss: 0.0957  noobj_loss: 0.0255  bbox_loss: 0.1506  cls_loss: 2.6966  \n",
      "<<<iteration:[820/878] - total_loss: 3.0239  obj_loss: 0.0684  noobj_loss: 0.0217  bbox_loss: 0.1133  cls_loss: 2.3780  \n",
      "<<<iteration:[840/878] - total_loss: 3.4309  obj_loss: 0.0754  noobj_loss: 0.0196  bbox_loss: 0.1123  cls_loss: 2.7842  \n",
      "<<<iteration:[860/878] - total_loss: 3.0434  obj_loss: 0.0907  noobj_loss: 0.0240  bbox_loss: 0.0980  cls_loss: 2.4506  \n",
      "\n",
      "epoch:13/100 - Train Loss: 4.3453, Val Loss: 3.2551\n",
      "\n",
      "<<<iteration:[20/878] - total_loss: 4.0499  obj_loss: 0.1003  noobj_loss: 0.0380  bbox_loss: 0.2492  cls_loss: 2.6845  \n",
      "<<<iteration:[40/878] - total_loss: 3.4245  obj_loss: 0.0787  noobj_loss: 0.0208  bbox_loss: 0.1653  cls_loss: 2.5088  \n",
      "<<<iteration:[60/878] - total_loss: 3.6040  obj_loss: 0.0789  noobj_loss: 0.0284  bbox_loss: 0.2342  cls_loss: 2.3401  \n",
      "<<<iteration:[80/878] - total_loss: 3.0239  obj_loss: 0.0761  noobj_loss: 0.0261  bbox_loss: 0.1174  cls_loss: 2.3475  \n",
      "<<<iteration:[100/878] - total_loss: 3.2084  obj_loss: 0.1044  noobj_loss: 0.0226  bbox_loss: 0.1258  cls_loss: 2.4637  \n",
      "<<<iteration:[120/878] - total_loss: 2.9552  obj_loss: 0.0830  noobj_loss: 0.0245  bbox_loss: 0.1143  cls_loss: 2.2882  \n",
      "<<<iteration:[140/878] - total_loss: 3.5229  obj_loss: 0.0766  noobj_loss: 0.0413  bbox_loss: 0.1340  cls_loss: 2.7556  \n",
      "<<<iteration:[160/878] - total_loss: 3.2942  obj_loss: 0.0758  noobj_loss: 0.0283  bbox_loss: 0.1351  cls_loss: 2.5288  \n",
      "<<<iteration:[180/878] - total_loss: 3.0323  obj_loss: 0.0942  noobj_loss: 0.0231  bbox_loss: 0.1070  cls_loss: 2.3915  \n",
      "<<<iteration:[200/878] - total_loss: 3.2944  obj_loss: 0.0991  noobj_loss: 0.0201  bbox_loss: 0.1099  cls_loss: 2.6357  \n",
      "<<<iteration:[220/878] - total_loss: 3.5214  obj_loss: 0.0902  noobj_loss: 0.0327  bbox_loss: 0.1503  cls_loss: 2.6635  \n",
      "<<<iteration:[240/878] - total_loss: 2.8441  obj_loss: 0.0809  noobj_loss: 0.0249  bbox_loss: 0.0890  cls_loss: 2.3060  \n",
      "<<<iteration:[260/878] - total_loss: 3.2100  obj_loss: 0.0733  noobj_loss: 0.0170  bbox_loss: 0.1164  cls_loss: 2.5461  \n",
      "<<<iteration:[280/878] - total_loss: 2.8656  obj_loss: 0.0814  noobj_loss: 0.0260  bbox_loss: 0.1147  cls_loss: 2.1979  \n",
      "<<<iteration:[300/878] - total_loss: 2.7271  obj_loss: 0.0776  noobj_loss: 0.0231  bbox_loss: 0.0807  cls_loss: 2.2344  \n",
      "<<<iteration:[320/878] - total_loss: 3.4384  obj_loss: 0.0967  noobj_loss: 0.0214  bbox_loss: 0.1069  cls_loss: 2.7963  \n",
      "<<<iteration:[340/878] - total_loss: 2.8226  obj_loss: 0.0903  noobj_loss: 0.0233  bbox_loss: 0.0912  cls_loss: 2.2649  \n",
      "<<<iteration:[360/878] - total_loss: 3.3773  obj_loss: 0.0819  noobj_loss: 0.0243  bbox_loss: 0.1619  cls_loss: 2.4736  \n",
      "<<<iteration:[380/878] - total_loss: 3.1253  obj_loss: 0.0850  noobj_loss: 0.0214  bbox_loss: 0.1164  cls_loss: 2.4476  \n",
      "<<<iteration:[400/878] - total_loss: 3.2285  obj_loss: 0.1074  noobj_loss: 0.0318  bbox_loss: 0.1177  cls_loss: 2.5169  \n",
      "<<<iteration:[420/878] - total_loss: 2.9305  obj_loss: 0.0830  noobj_loss: 0.0241  bbox_loss: 0.0988  cls_loss: 2.3412  \n",
      "<<<iteration:[440/878] - total_loss: 3.2691  obj_loss: 0.0933  noobj_loss: 0.0270  bbox_loss: 0.1341  cls_loss: 2.4919  \n",
      "<<<iteration:[460/878] - total_loss: 3.5088  obj_loss: 0.1222  noobj_loss: 0.0470  bbox_loss: 0.1409  cls_loss: 2.6584  \n",
      "<<<iteration:[480/878] - total_loss: 3.2774  obj_loss: 0.0947  noobj_loss: 0.0235  bbox_loss: 0.1578  cls_loss: 2.3819  \n",
      "<<<iteration:[500/878] - total_loss: 4.3098  obj_loss: 0.0799  noobj_loss: 0.0220  bbox_loss: 0.3457  cls_loss: 2.4906  \n",
      "<<<iteration:[520/878] - total_loss: 3.0148  obj_loss: 0.0755  noobj_loss: 0.0245  bbox_loss: 0.1240  cls_loss: 2.3070  \n",
      "<<<iteration:[540/878] - total_loss: 2.8680  obj_loss: 0.0656  noobj_loss: 0.0217  bbox_loss: 0.0944  cls_loss: 2.3193  \n",
      "<<<iteration:[560/878] - total_loss: 2.9706  obj_loss: 0.0697  noobj_loss: 0.0191  bbox_loss: 0.1457  cls_loss: 2.1630  \n",
      "<<<iteration:[580/878] - total_loss: 3.5932  obj_loss: 0.0679  noobj_loss: 0.0345  bbox_loss: 0.1741  cls_loss: 2.6374  \n",
      "<<<iteration:[600/878] - total_loss: 4.1555  obj_loss: 0.1150  noobj_loss: 0.0235  bbox_loss: 0.2318  cls_loss: 2.8696  \n",
      "<<<iteration:[620/878] - total_loss: 3.6251  obj_loss: 0.0792  noobj_loss: 0.0234  bbox_loss: 0.1790  cls_loss: 2.6392  \n",
      "<<<iteration:[640/878] - total_loss: 2.9810  obj_loss: 0.0828  noobj_loss: 0.0188  bbox_loss: 0.1048  cls_loss: 2.3646  \n",
      "<<<iteration:[660/878] - total_loss: 2.8222  obj_loss: 0.0945  noobj_loss: 0.0225  bbox_loss: 0.0892  cls_loss: 2.2702  \n",
      "<<<iteration:[680/878] - total_loss: 2.9442  obj_loss: 0.0867  noobj_loss: 0.0225  bbox_loss: 0.0985  cls_loss: 2.3536  \n",
      "<<<iteration:[700/878] - total_loss: 3.3756  obj_loss: 0.0975  noobj_loss: 0.0278  bbox_loss: 0.1105  cls_loss: 2.7117  \n",
      "<<<iteration:[720/878] - total_loss: 3.0847  obj_loss: 0.0806  noobj_loss: 0.0241  bbox_loss: 0.1201  cls_loss: 2.3915  \n",
      "<<<iteration:[740/878] - total_loss: 3.4350  obj_loss: 0.0920  noobj_loss: 0.0255  bbox_loss: 0.1516  cls_loss: 2.5721  \n",
      "<<<iteration:[760/878] - total_loss: 3.4557  obj_loss: 0.0937  noobj_loss: 0.0225  bbox_loss: 0.1542  cls_loss: 2.5795  \n",
      "<<<iteration:[780/878] - total_loss: 2.9682  obj_loss: 0.0864  noobj_loss: 0.0246  bbox_loss: 0.1421  cls_loss: 2.1590  \n",
      "<<<iteration:[800/878] - total_loss: 3.0470  obj_loss: 0.0716  noobj_loss: 0.0179  bbox_loss: 0.1163  cls_loss: 2.3852  \n",
      "<<<iteration:[820/878] - total_loss: 3.3894  obj_loss: 0.0951  noobj_loss: 0.0183  bbox_loss: 0.1300  cls_loss: 2.6349  \n",
      "<<<iteration:[840/878] - total_loss: 3.9831  obj_loss: 0.0941  noobj_loss: 0.0193  bbox_loss: 0.2494  cls_loss: 2.6326  \n",
      "<<<iteration:[860/878] - total_loss: 3.7130  obj_loss: 0.0737  noobj_loss: 0.0210  bbox_loss: 0.2029  cls_loss: 2.6145  \n",
      "\n",
      "epoch:14/100 - Train Loss: 3.2893, Val Loss: 3.1176\n",
      "\n",
      "<<<iteration:[20/878] - total_loss: 3.3258  obj_loss: 0.0883  noobj_loss: 0.0195  bbox_loss: 0.1297  cls_loss: 2.5792  \n",
      "<<<iteration:[40/878] - total_loss: 3.3105  obj_loss: 0.0858  noobj_loss: 0.0242  bbox_loss: 0.1265  cls_loss: 2.5800  \n",
      "<<<iteration:[60/878] - total_loss: 3.2989  obj_loss: 0.0817  noobj_loss: 0.0206  bbox_loss: 0.1290  cls_loss: 2.5619  \n",
      "<<<iteration:[80/878] - total_loss: 3.1109  obj_loss: 0.0804  noobj_loss: 0.0207  bbox_loss: 0.1245  cls_loss: 2.3977  \n",
      "<<<iteration:[100/878] - total_loss: 3.5470  obj_loss: 0.0905  noobj_loss: 0.0281  bbox_loss: 0.1328  cls_loss: 2.7784  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<<<iteration:[120/878] - total_loss: 2.9474  obj_loss: 0.0680  noobj_loss: 0.0278  bbox_loss: 0.1132  cls_loss: 2.2994  \n",
      "<<<iteration:[140/878] - total_loss: 3.4178  obj_loss: 0.0815  noobj_loss: 0.0209  bbox_loss: 0.1718  cls_loss: 2.4671  \n",
      "<<<iteration:[160/878] - total_loss: 3.0440  obj_loss: 0.1065  noobj_loss: 0.0245  bbox_loss: 0.1139  cls_loss: 2.3557  \n",
      "<<<iteration:[180/878] - total_loss: 2.9631  obj_loss: 0.0864  noobj_loss: 0.0293  bbox_loss: 0.1083  cls_loss: 2.3204  \n",
      "<<<iteration:[200/878] - total_loss: 3.1673  obj_loss: 0.0894  noobj_loss: 0.0207  bbox_loss: 0.1195  cls_loss: 2.4698  \n",
      "<<<iteration:[220/878] - total_loss: 3.0925  obj_loss: 0.0773  noobj_loss: 0.0216  bbox_loss: 0.1329  cls_loss: 2.3399  \n",
      "<<<iteration:[240/878] - total_loss: 2.7898  obj_loss: 0.0906  noobj_loss: 0.0281  bbox_loss: 0.0956  cls_loss: 2.2073  \n",
      "<<<iteration:[260/878] - total_loss: 3.2766  obj_loss: 0.0979  noobj_loss: 0.0298  bbox_loss: 0.1158  cls_loss: 2.5849  \n",
      "<<<iteration:[280/878] - total_loss: 3.1260  obj_loss: 0.0938  noobj_loss: 0.0251  bbox_loss: 0.1066  cls_loss: 2.4866  \n",
      "<<<iteration:[300/878] - total_loss: 3.1067  obj_loss: 0.0833  noobj_loss: 0.0224  bbox_loss: 0.1128  cls_loss: 2.4482  \n",
      "<<<iteration:[320/878] - total_loss: 3.4801  obj_loss: 0.1131  noobj_loss: 0.0275  bbox_loss: 0.1404  cls_loss: 2.6514  \n",
      "<<<iteration:[340/878] - total_loss: 3.2091  obj_loss: 0.0762  noobj_loss: 0.0292  bbox_loss: 0.1372  cls_loss: 2.4324  \n",
      "<<<iteration:[360/878] - total_loss: 3.3682  obj_loss: 0.0855  noobj_loss: 0.0196  bbox_loss: 0.1536  cls_loss: 2.5050  \n",
      "<<<iteration:[380/878] - total_loss: 3.1610  obj_loss: 0.0801  noobj_loss: 0.0212  bbox_loss: 0.1258  cls_loss: 2.4412  \n",
      "<<<iteration:[400/878] - total_loss: 3.6309  obj_loss: 0.0752  noobj_loss: 0.0242  bbox_loss: 0.1668  cls_loss: 2.7094  \n",
      "<<<iteration:[420/878] - total_loss: 3.4480  obj_loss: 0.0907  noobj_loss: 0.0205  bbox_loss: 0.1282  cls_loss: 2.7062  \n",
      "<<<iteration:[440/878] - total_loss: 3.4574  obj_loss: 0.0862  noobj_loss: 0.0249  bbox_loss: 0.1821  cls_loss: 2.4485  \n",
      "<<<iteration:[460/878] - total_loss: 3.0837  obj_loss: 0.0799  noobj_loss: 0.0159  bbox_loss: 0.1096  cls_loss: 2.4480  \n",
      "<<<iteration:[480/878] - total_loss: 3.0410  obj_loss: 0.0843  noobj_loss: 0.0216  bbox_loss: 0.1263  cls_loss: 2.3144  \n",
      "<<<iteration:[500/878] - total_loss: 3.3734  obj_loss: 0.0930  noobj_loss: 0.0353  bbox_loss: 0.1819  cls_loss: 2.3532  \n",
      "<<<iteration:[520/878] - total_loss: 3.0148  obj_loss: 0.0810  noobj_loss: 0.0209  bbox_loss: 0.1309  cls_loss: 2.2686  \n",
      "<<<iteration:[540/878] - total_loss: 3.6185  obj_loss: 0.0686  noobj_loss: 0.0161  bbox_loss: 0.2167  cls_loss: 2.4586  \n",
      "<<<iteration:[560/878] - total_loss: 3.2062  obj_loss: 0.0927  noobj_loss: 0.0235  bbox_loss: 0.1187  cls_loss: 2.5079  \n",
      "<<<iteration:[580/878] - total_loss: 2.9550  obj_loss: 0.0743  noobj_loss: 0.0169  bbox_loss: 0.0970  cls_loss: 2.3871  \n",
      "<<<iteration:[600/878] - total_loss: 2.8028  obj_loss: 0.0844  noobj_loss: 0.0257  bbox_loss: 0.0989  cls_loss: 2.2110  \n",
      "<<<iteration:[620/878] - total_loss: 2.8330  obj_loss: 0.0717  noobj_loss: 0.0209  bbox_loss: 0.0864  cls_loss: 2.3188  \n",
      "<<<iteration:[640/878] - total_loss: 3.0319  obj_loss: 0.0905  noobj_loss: 0.0161  bbox_loss: 0.1045  cls_loss: 2.4111  \n",
      "<<<iteration:[660/878] - total_loss: 2.9995  obj_loss: 0.1129  noobj_loss: 0.0243  bbox_loss: 0.0938  cls_loss: 2.4053  \n",
      "<<<iteration:[680/878] - total_loss: 3.0865  obj_loss: 0.0830  noobj_loss: 0.0238  bbox_loss: 0.0956  cls_loss: 2.5138  \n",
      "<<<iteration:[700/878] - total_loss: 2.7241  obj_loss: 0.0766  noobj_loss: 0.0182  bbox_loss: 0.1088  cls_loss: 2.0944  \n",
      "<<<iteration:[720/878] - total_loss: 3.2066  obj_loss: 0.1057  noobj_loss: 0.0261  bbox_loss: 0.1172  cls_loss: 2.5019  \n",
      "<<<iteration:[740/878] - total_loss: 3.1354  obj_loss: 0.0894  noobj_loss: 0.0254  bbox_loss: 0.1111  cls_loss: 2.4778  \n",
      "<<<iteration:[760/878] - total_loss: 3.0093  obj_loss: 0.0933  noobj_loss: 0.0320  bbox_loss: 0.1394  cls_loss: 2.2030  \n",
      "<<<iteration:[780/878] - total_loss: 3.6895  obj_loss: 0.0950  noobj_loss: 0.0236  bbox_loss: 0.1649  cls_loss: 2.7582  \n",
      "<<<iteration:[800/878] - total_loss: 3.1945  obj_loss: 0.1098  noobj_loss: 0.0200  bbox_loss: 0.0933  cls_loss: 2.6080  \n",
      "<<<iteration:[820/878] - total_loss: 2.8265  obj_loss: 0.0720  noobj_loss: 0.0261  bbox_loss: 0.0982  cls_loss: 2.2503  \n",
      "<<<iteration:[840/878] - total_loss: 2.8048  obj_loss: 0.1053  noobj_loss: 0.0177  bbox_loss: 0.0956  cls_loss: 2.2125  \n",
      "<<<iteration:[860/878] - total_loss: 3.2190  obj_loss: 0.0760  noobj_loss: 0.0185  bbox_loss: 0.1060  cls_loss: 2.6038  \n",
      "\n",
      "epoch:15/100 - Train Loss: 3.1658, Val Loss: 2.9461\n",
      "\n",
      "<<<iteration:[20/878] - total_loss: 3.4307  obj_loss: 0.1104  noobj_loss: 0.0190  bbox_loss: 0.1205  cls_loss: 2.7082  \n",
      "<<<iteration:[40/878] - total_loss: 3.5936  obj_loss: 0.0949  noobj_loss: 0.0199  bbox_loss: 0.1579  cls_loss: 2.6991  \n",
      "<<<iteration:[60/878] - total_loss: 3.5411  obj_loss: 0.0819  noobj_loss: 0.0278  bbox_loss: 0.1408  cls_loss: 2.7411  \n",
      "<<<iteration:[80/878] - total_loss: 2.9801  obj_loss: 0.0863  noobj_loss: 0.0301  bbox_loss: 0.1094  cls_loss: 2.3316  \n",
      "<<<iteration:[100/878] - total_loss: 3.8259  obj_loss: 0.0872  noobj_loss: 0.0217  bbox_loss: 0.2356  cls_loss: 2.5501  \n",
      "<<<iteration:[120/878] - total_loss: 3.5239  obj_loss: 0.0921  noobj_loss: 0.0239  bbox_loss: 0.1412  cls_loss: 2.7138  \n",
      "<<<iteration:[140/878] - total_loss: 5.2694  obj_loss: 0.0967  noobj_loss: 0.0297  bbox_loss: 0.4998  cls_loss: 2.6587  \n",
      "<<<iteration:[160/878] - total_loss: 2.7048  obj_loss: 0.0647  noobj_loss: 0.0173  bbox_loss: 0.1049  cls_loss: 2.1069  \n",
      "<<<iteration:[180/878] - total_loss: 3.0694  obj_loss: 0.0950  noobj_loss: 0.0235  bbox_loss: 0.1137  cls_loss: 2.3941  \n",
      "<<<iteration:[200/878] - total_loss: 3.7868  obj_loss: 0.0870  noobj_loss: 0.0297  bbox_loss: 0.2394  cls_loss: 2.4880  \n",
      "<<<iteration:[220/878] - total_loss: 3.1916  obj_loss: 0.0964  noobj_loss: 0.0228  bbox_loss: 0.1101  cls_loss: 2.5335  \n",
      "<<<iteration:[240/878] - total_loss: 2.9398  obj_loss: 0.0982  noobj_loss: 0.0223  bbox_loss: 0.1033  cls_loss: 2.3143  \n",
      "<<<iteration:[260/878] - total_loss: 3.2720  obj_loss: 0.0867  noobj_loss: 0.0200  bbox_loss: 0.1044  cls_loss: 2.6531  \n",
      "<<<iteration:[280/878] - total_loss: 2.7506  obj_loss: 0.0936  noobj_loss: 0.0161  bbox_loss: 0.0885  cls_loss: 2.2062  \n",
      "<<<iteration:[300/878] - total_loss: 3.0355  obj_loss: 0.0930  noobj_loss: 0.0214  bbox_loss: 0.0920  cls_loss: 2.4717  \n",
      "<<<iteration:[320/878] - total_loss: 3.1810  obj_loss: 0.0934  noobj_loss: 0.0256  bbox_loss: 0.1090  cls_loss: 2.5296  \n",
      "<<<iteration:[340/878] - total_loss: 3.5652  obj_loss: 0.0940  noobj_loss: 0.0269  bbox_loss: 0.1836  cls_loss: 2.5396  \n",
      "<<<iteration:[360/878] - total_loss: 2.8983  obj_loss: 0.0946  noobj_loss: 0.0218  bbox_loss: 0.1085  cls_loss: 2.2503  \n",
      "<<<iteration:[380/878] - total_loss: 3.3427  obj_loss: 0.0790  noobj_loss: 0.0202  bbox_loss: 0.2183  cls_loss: 2.1621  \n",
      "<<<iteration:[400/878] - total_loss: 3.4034  obj_loss: 0.0820  noobj_loss: 0.0247  bbox_loss: 0.1616  cls_loss: 2.5009  \n",
      "<<<iteration:[420/878] - total_loss: 2.9235  obj_loss: 0.0542  noobj_loss: 0.0205  bbox_loss: 0.1116  cls_loss: 2.3009  \n",
      "<<<iteration:[440/878] - total_loss: 3.3193  obj_loss: 0.0935  noobj_loss: 0.0296  bbox_loss: 0.1302  cls_loss: 2.5598  \n",
      "<<<iteration:[460/878] - total_loss: 3.2339  obj_loss: 0.0912  noobj_loss: 0.0213  bbox_loss: 0.1271  cls_loss: 2.4965  \n",
      "<<<iteration:[480/878] - total_loss: 2.8648  obj_loss: 0.1087  noobj_loss: 0.0220  bbox_loss: 0.0853  cls_loss: 2.3186  \n",
      "<<<iteration:[500/878] - total_loss: 3.3539  obj_loss: 0.0954  noobj_loss: 0.0224  bbox_loss: 0.1212  cls_loss: 2.6411  \n",
      "<<<iteration:[520/878] - total_loss: 2.9746  obj_loss: 0.1234  noobj_loss: 0.0195  bbox_loss: 0.0963  cls_loss: 2.3599  \n",
      "<<<iteration:[540/878] - total_loss: 3.1741  obj_loss: 0.0812  noobj_loss: 0.0224  bbox_loss: 0.1046  cls_loss: 2.5586  \n",
      "<<<iteration:[560/878] - total_loss: 2.6231  obj_loss: 0.1060  noobj_loss: 0.0240  bbox_loss: 0.0977  cls_loss: 2.0166  \n",
      "<<<iteration:[580/878] - total_loss: 2.8718  obj_loss: 0.0823  noobj_loss: 0.0192  bbox_loss: 0.0981  cls_loss: 2.2893  \n",
      "<<<iteration:[600/878] - total_loss: 3.4325  obj_loss: 0.1114  noobj_loss: 0.0233  bbox_loss: 0.1066  cls_loss: 2.7764  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<<<iteration:[620/878] - total_loss: 3.0824  obj_loss: 0.0912  noobj_loss: 0.0330  bbox_loss: 0.1149  cls_loss: 2.4001  \n",
      "<<<iteration:[640/878] - total_loss: 2.9064  obj_loss: 0.0776  noobj_loss: 0.0263  bbox_loss: 0.1072  cls_loss: 2.2797  \n",
      "<<<iteration:[660/878] - total_loss: 2.7802  obj_loss: 0.0908  noobj_loss: 0.0183  bbox_loss: 0.0933  cls_loss: 2.2137  \n",
      "<<<iteration:[680/878] - total_loss: 3.2208  obj_loss: 0.1009  noobj_loss: 0.0303  bbox_loss: 0.1152  cls_loss: 2.5287  \n",
      "<<<iteration:[700/878] - total_loss: 2.9338  obj_loss: 0.0874  noobj_loss: 0.0181  bbox_loss: 0.0772  cls_loss: 2.4512  \n",
      "<<<iteration:[720/878] - total_loss: 2.7872  obj_loss: 0.0857  noobj_loss: 0.0203  bbox_loss: 0.0936  cls_loss: 2.2232  \n",
      "<<<iteration:[740/878] - total_loss: 3.5744  obj_loss: 0.1047  noobj_loss: 0.0227  bbox_loss: 0.1791  cls_loss: 2.5628  \n",
      "<<<iteration:[760/878] - total_loss: 2.9765  obj_loss: 0.1142  noobj_loss: 0.0286  bbox_loss: 0.1101  cls_loss: 2.2977  \n",
      "<<<iteration:[780/878] - total_loss: 2.9871  obj_loss: 0.0901  noobj_loss: 0.0195  bbox_loss: 0.1265  cls_loss: 2.2551  \n",
      "<<<iteration:[800/878] - total_loss: 3.1991  obj_loss: 0.0874  noobj_loss: 0.0188  bbox_loss: 0.1026  cls_loss: 2.5894  \n",
      "<<<iteration:[820/878] - total_loss: 2.9340  obj_loss: 0.0989  noobj_loss: 0.0187  bbox_loss: 0.0860  cls_loss: 2.3959  \n",
      "<<<iteration:[840/878] - total_loss: 2.8032  obj_loss: 0.0734  noobj_loss: 0.0198  bbox_loss: 0.1172  cls_loss: 2.1341  \n",
      "<<<iteration:[860/878] - total_loss: 3.3959  obj_loss: 0.0976  noobj_loss: 0.0213  bbox_loss: 0.1194  cls_loss: 2.6908  \n",
      "\n",
      "epoch:16/100 - Train Loss: 3.1948, Val Loss: 3.1460\n",
      "\n",
      "<<<iteration:[20/878] - total_loss: 4.4984  obj_loss: 0.0682  noobj_loss: 0.0154  bbox_loss: 0.3262  cls_loss: 2.7914  \n",
      "<<<iteration:[40/878] - total_loss: 3.0848  obj_loss: 0.0879  noobj_loss: 0.0151  bbox_loss: 0.0951  cls_loss: 2.5141  \n",
      "<<<iteration:[60/878] - total_loss: 2.9542  obj_loss: 0.0786  noobj_loss: 0.0182  bbox_loss: 0.0979  cls_loss: 2.3772  \n",
      "<<<iteration:[80/878] - total_loss: 2.6293  obj_loss: 0.0838  noobj_loss: 0.0152  bbox_loss: 0.1033  cls_loss: 2.0212  \n",
      "<<<iteration:[100/878] - total_loss: 3.2462  obj_loss: 0.0943  noobj_loss: 0.0248  bbox_loss: 0.1142  cls_loss: 2.5683  \n",
      "<<<iteration:[120/878] - total_loss: 3.1258  obj_loss: 0.0877  noobj_loss: 0.0216  bbox_loss: 0.0808  cls_loss: 2.6231  \n",
      "<<<iteration:[140/878] - total_loss: 2.8170  obj_loss: 0.1024  noobj_loss: 0.0213  bbox_loss: 0.0914  cls_loss: 2.2469  \n",
      "<<<iteration:[160/878] - total_loss: 3.3924  obj_loss: 0.1003  noobj_loss: 0.0227  bbox_loss: 0.1227  cls_loss: 2.6674  \n",
      "<<<iteration:[180/878] - total_loss: 2.9827  obj_loss: 0.0886  noobj_loss: 0.0277  bbox_loss: 0.1097  cls_loss: 2.3316  \n",
      "<<<iteration:[200/878] - total_loss: 3.2279  obj_loss: 0.1033  noobj_loss: 0.0199  bbox_loss: 0.1522  cls_loss: 2.3537  \n",
      "<<<iteration:[220/878] - total_loss: 3.4908  obj_loss: 0.1139  noobj_loss: 0.0224  bbox_loss: 0.1563  cls_loss: 2.5843  \n",
      "<<<iteration:[240/878] - total_loss: 2.7978  obj_loss: 0.1063  noobj_loss: 0.0253  bbox_loss: 0.0955  cls_loss: 2.2016  \n",
      "<<<iteration:[260/878] - total_loss: 2.7094  obj_loss: 0.0832  noobj_loss: 0.0293  bbox_loss: 0.0898  cls_loss: 2.1624  \n",
      "<<<iteration:[280/878] - total_loss: 3.1546  obj_loss: 0.0962  noobj_loss: 0.0197  bbox_loss: 0.1220  cls_loss: 2.4387  \n",
      "<<<iteration:[300/878] - total_loss: 3.2445  obj_loss: 0.0860  noobj_loss: 0.0256  bbox_loss: 0.0972  cls_loss: 2.6599  \n",
      "<<<iteration:[320/878] - total_loss: 2.7792  obj_loss: 0.0771  noobj_loss: 0.0222  bbox_loss: 0.0914  cls_loss: 2.2342  \n",
      "<<<iteration:[340/878] - total_loss: 4.4817  obj_loss: 0.0869  noobj_loss: 0.0238  bbox_loss: 0.4158  cls_loss: 2.3040  \n",
      "<<<iteration:[360/878] - total_loss: 4.3437  obj_loss: 0.0938  noobj_loss: 0.0246  bbox_loss: 0.3524  cls_loss: 2.4754  \n",
      "<<<iteration:[380/878] - total_loss: 7.8116  obj_loss: 0.0946  noobj_loss: 0.0581  bbox_loss: 1.0795  cls_loss: 2.2903  \n",
      "<<<iteration:[400/878] - total_loss: 3.7233  obj_loss: 0.0714  noobj_loss: 0.0172  bbox_loss: 0.2332  cls_loss: 2.4772  \n",
      "<<<iteration:[420/878] - total_loss: 8.2369  obj_loss: 0.0967  noobj_loss: 0.0326  bbox_loss: 1.1385  cls_loss: 2.4316  \n",
      "<<<iteration:[440/878] - total_loss: 6.5526  obj_loss: 0.1103  noobj_loss: 0.0235  bbox_loss: 0.7869  cls_loss: 2.4962  \n",
      "<<<iteration:[460/878] - total_loss: 4.5130  obj_loss: 0.0887  noobj_loss: 0.0205  bbox_loss: 0.4030  cls_loss: 2.3991  \n",
      "<<<iteration:[480/878] - total_loss: 4.5109  obj_loss: 0.0876  noobj_loss: 0.0172  bbox_loss: 0.4061  cls_loss: 2.3841  \n",
      "<<<iteration:[500/878] - total_loss: 5.8603  obj_loss: 0.1214  noobj_loss: 0.0243  bbox_loss: 0.6308  cls_loss: 2.5729  \n",
      "<<<iteration:[520/878] - total_loss: 2.9635  obj_loss: 0.1048  noobj_loss: 0.0241  bbox_loss: 0.1042  cls_loss: 2.3254  \n",
      "<<<iteration:[540/878] - total_loss: 3.6729  obj_loss: 0.0925  noobj_loss: 0.0272  bbox_loss: 0.2442  cls_loss: 2.3459  \n",
      "<<<iteration:[560/878] - total_loss: 4.1837  obj_loss: 0.0737  noobj_loss: 0.0223  bbox_loss: 0.3855  cls_loss: 2.1711  \n",
      "<<<iteration:[580/878] - total_loss: 5.2204  obj_loss: 0.0939  noobj_loss: 0.0182  bbox_loss: 0.5512  cls_loss: 2.3615  \n",
      "<<<iteration:[600/878] - total_loss: 4.1080  obj_loss: 0.0748  noobj_loss: 0.0199  bbox_loss: 0.3226  cls_loss: 2.4102  \n",
      "<<<iteration:[620/878] - total_loss: 5.3298  obj_loss: 0.0658  noobj_loss: 0.0203  bbox_loss: 0.5497  cls_loss: 2.5054  \n",
      "<<<iteration:[640/878] - total_loss: 4.5740  obj_loss: 0.0870  noobj_loss: 0.0314  bbox_loss: 0.3812  cls_loss: 2.5652  \n",
      "<<<iteration:[660/878] - total_loss: 4.8931  obj_loss: 0.1087  noobj_loss: 0.0223  bbox_loss: 0.4739  cls_loss: 2.4037  \n",
      "<<<iteration:[680/878] - total_loss: 4.5058  obj_loss: 0.0843  noobj_loss: 0.0233  bbox_loss: 0.3808  cls_loss: 2.5061  \n",
      "<<<iteration:[700/878] - total_loss: 3.8837  obj_loss: 0.0728  noobj_loss: 0.0276  bbox_loss: 0.2451  cls_loss: 2.5715  \n",
      "<<<iteration:[720/878] - total_loss: 4.9427  obj_loss: 0.1012  noobj_loss: 0.0239  bbox_loss: 0.4303  cls_loss: 2.6779  \n",
      "<<<iteration:[740/878] - total_loss: 4.0001  obj_loss: 0.0865  noobj_loss: 0.0249  bbox_loss: 0.2908  cls_loss: 2.4471  \n",
      "<<<iteration:[760/878] - total_loss: 3.9854  obj_loss: 0.0974  noobj_loss: 0.0217  bbox_loss: 0.2439  cls_loss: 2.6577  \n",
      "<<<iteration:[780/878] - total_loss: 3.4980  obj_loss: 0.0803  noobj_loss: 0.0226  bbox_loss: 0.1924  cls_loss: 2.4442  \n",
      "<<<iteration:[800/878] - total_loss: 3.6978  obj_loss: 0.0719  noobj_loss: 0.0218  bbox_loss: 0.2010  cls_loss: 2.6102  \n",
      "<<<iteration:[820/878] - total_loss: 2.8492  obj_loss: 0.0733  noobj_loss: 0.0250  bbox_loss: 0.1315  cls_loss: 2.1059  \n",
      "<<<iteration:[840/878] - total_loss: 3.6173  obj_loss: 0.0930  noobj_loss: 0.0224  bbox_loss: 0.2040  cls_loss: 2.4929  \n",
      "<<<iteration:[860/878] - total_loss: 3.4632  obj_loss: 0.0891  noobj_loss: 0.0255  bbox_loss: 0.1424  cls_loss: 2.6496  \n",
      "\n",
      "epoch:17/100 - Train Loss: 4.0216, Val Loss: 3.0544\n",
      "\n",
      "<<<iteration:[20/878] - total_loss: 3.2969  obj_loss: 0.1068  noobj_loss: 0.0255  bbox_loss: 0.1123  cls_loss: 2.6158  \n",
      "<<<iteration:[40/878] - total_loss: 3.2671  obj_loss: 0.0759  noobj_loss: 0.0424  bbox_loss: 0.1241  cls_loss: 2.5497  \n",
      "<<<iteration:[60/878] - total_loss: 3.0710  obj_loss: 0.1046  noobj_loss: 0.0244  bbox_loss: 0.1110  cls_loss: 2.3994  \n",
      "<<<iteration:[80/878] - total_loss: 3.2014  obj_loss: 0.0875  noobj_loss: 0.0201  bbox_loss: 0.1084  cls_loss: 2.5616  \n",
      "<<<iteration:[100/878] - total_loss: 3.4046  obj_loss: 0.0985  noobj_loss: 0.0201  bbox_loss: 0.1676  cls_loss: 2.4581  \n",
      "<<<iteration:[120/878] - total_loss: 2.9259  obj_loss: 0.0830  noobj_loss: 0.0197  bbox_loss: 0.1002  cls_loss: 2.3318  \n",
      "<<<iteration:[140/878] - total_loss: 3.2764  obj_loss: 0.1081  noobj_loss: 0.0213  bbox_loss: 0.1235  cls_loss: 2.5404  \n",
      "<<<iteration:[160/878] - total_loss: 2.8378  obj_loss: 0.0809  noobj_loss: 0.0215  bbox_loss: 0.0876  cls_loss: 2.3083  \n",
      "<<<iteration:[180/878] - total_loss: 2.8875  obj_loss: 0.1081  noobj_loss: 0.0212  bbox_loss: 0.1012  cls_loss: 2.2626  \n",
      "<<<iteration:[200/878] - total_loss: 2.8414  obj_loss: 0.0915  noobj_loss: 0.0203  bbox_loss: 0.0954  cls_loss: 2.2627  \n",
      "<<<iteration:[220/878] - total_loss: 3.0790  obj_loss: 0.0752  noobj_loss: 0.0198  bbox_loss: 0.1074  cls_loss: 2.4569  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<<<iteration:[240/878] - total_loss: 2.7761  obj_loss: 0.0756  noobj_loss: 0.0195  bbox_loss: 0.0979  cls_loss: 2.2013  \n",
      "<<<iteration:[260/878] - total_loss: 3.2246  obj_loss: 0.0942  noobj_loss: 0.0217  bbox_loss: 0.1149  cls_loss: 2.5450  \n",
      "<<<iteration:[280/878] - total_loss: 3.0258  obj_loss: 0.1007  noobj_loss: 0.0235  bbox_loss: 0.1303  cls_loss: 2.2619  \n",
      "<<<iteration:[300/878] - total_loss: 3.4938  obj_loss: 0.0813  noobj_loss: 0.0225  bbox_loss: 0.1673  cls_loss: 2.5649  \n",
      "<<<iteration:[320/878] - total_loss: 2.9532  obj_loss: 0.0875  noobj_loss: 0.0383  bbox_loss: 0.1211  cls_loss: 2.2410  \n",
      "<<<iteration:[340/878] - total_loss: 3.8047  obj_loss: 0.1106  noobj_loss: 0.0459  bbox_loss: 0.1615  cls_loss: 2.8634  \n",
      "<<<iteration:[360/878] - total_loss: 3.1827  obj_loss: 0.1002  noobj_loss: 0.0201  bbox_loss: 0.1414  cls_loss: 2.3655  \n",
      "<<<iteration:[380/878] - total_loss: 3.1907  obj_loss: 0.0872  noobj_loss: 0.0210  bbox_loss: 0.1272  cls_loss: 2.4568  \n",
      "<<<iteration:[400/878] - total_loss: 2.9263  obj_loss: 0.0930  noobj_loss: 0.0211  bbox_loss: 0.0992  cls_loss: 2.3266  \n",
      "<<<iteration:[420/878] - total_loss: 2.8864  obj_loss: 0.1153  noobj_loss: 0.0337  bbox_loss: 0.0957  cls_loss: 2.2755  \n",
      "<<<iteration:[440/878] - total_loss: 3.0702  obj_loss: 0.1080  noobj_loss: 0.0222  bbox_loss: 0.0880  cls_loss: 2.5113  \n",
      "<<<iteration:[460/878] - total_loss: 3.0235  obj_loss: 0.0985  noobj_loss: 0.0216  bbox_loss: 0.1215  cls_loss: 2.3066  \n",
      "<<<iteration:[480/878] - total_loss: 2.8273  obj_loss: 0.0806  noobj_loss: 0.0185  bbox_loss: 0.1065  cls_loss: 2.2049  \n",
      "<<<iteration:[500/878] - total_loss: 2.7939  obj_loss: 0.0609  noobj_loss: 0.0178  bbox_loss: 0.0951  cls_loss: 2.2485  \n",
      "<<<iteration:[520/878] - total_loss: 2.7768  obj_loss: 0.0684  noobj_loss: 0.0188  bbox_loss: 0.0822  cls_loss: 2.2879  \n",
      "<<<iteration:[540/878] - total_loss: 3.3367  obj_loss: 0.1107  noobj_loss: 0.0265  bbox_loss: 0.1067  cls_loss: 2.6791  \n",
      "<<<iteration:[560/878] - total_loss: 3.2417  obj_loss: 0.0821  noobj_loss: 0.0189  bbox_loss: 0.1220  cls_loss: 2.5400  \n",
      "<<<iteration:[580/878] - total_loss: 2.9597  obj_loss: 0.0799  noobj_loss: 0.0183  bbox_loss: 0.1082  cls_loss: 2.3298  \n",
      "<<<iteration:[600/878] - total_loss: 3.1460  obj_loss: 0.0943  noobj_loss: 0.0210  bbox_loss: 0.0989  cls_loss: 2.5468  \n",
      "<<<iteration:[620/878] - total_loss: 3.1421  obj_loss: 0.0929  noobj_loss: 0.0221  bbox_loss: 0.1063  cls_loss: 2.5066  \n",
      "<<<iteration:[640/878] - total_loss: 3.0251  obj_loss: 0.0966  noobj_loss: 0.0197  bbox_loss: 0.1117  cls_loss: 2.3600  \n",
      "<<<iteration:[660/878] - total_loss: 3.0872  obj_loss: 0.0693  noobj_loss: 0.0197  bbox_loss: 0.1097  cls_loss: 2.4594  \n",
      "<<<iteration:[680/878] - total_loss: 3.5127  obj_loss: 0.0810  noobj_loss: 0.0297  bbox_loss: 0.1469  cls_loss: 2.6825  \n",
      "<<<iteration:[700/878] - total_loss: 2.9925  obj_loss: 0.0948  noobj_loss: 0.0220  bbox_loss: 0.1073  cls_loss: 2.3501  \n",
      "<<<iteration:[720/878] - total_loss: 2.9195  obj_loss: 0.0950  noobj_loss: 0.0207  bbox_loss: 0.0864  cls_loss: 2.3823  \n",
      "<<<iteration:[740/878] - total_loss: 3.1221  obj_loss: 0.0669  noobj_loss: 0.0184  bbox_loss: 0.0985  cls_loss: 2.5532  \n",
      "<<<iteration:[760/878] - total_loss: 3.0757  obj_loss: 0.1040  noobj_loss: 0.0199  bbox_loss: 0.1022  cls_loss: 2.4507  \n",
      "<<<iteration:[780/878] - total_loss: 3.0439  obj_loss: 0.0831  noobj_loss: 0.0268  bbox_loss: 0.1080  cls_loss: 2.4074  \n",
      "<<<iteration:[800/878] - total_loss: 2.8073  obj_loss: 0.0791  noobj_loss: 0.0203  bbox_loss: 0.0848  cls_loss: 2.2942  \n",
      "<<<iteration:[820/878] - total_loss: 3.1032  obj_loss: 0.0833  noobj_loss: 0.0252  bbox_loss: 0.0933  cls_loss: 2.5410  \n",
      "<<<iteration:[840/878] - total_loss: 3.2577  obj_loss: 0.0844  noobj_loss: 0.0228  bbox_loss: 0.1186  cls_loss: 2.5690  \n",
      "<<<iteration:[860/878] - total_loss: 3.2520  obj_loss: 0.0983  noobj_loss: 0.0186  bbox_loss: 0.0971  cls_loss: 2.6587  \n",
      "\n",
      "epoch:18/100 - Train Loss: 3.0898, Val Loss: 3.0856\n",
      "\n",
      "<<<iteration:[20/878] - total_loss: 3.1300  obj_loss: 0.0865  noobj_loss: 0.0226  bbox_loss: 0.1069  cls_loss: 2.4975  \n",
      "<<<iteration:[40/878] - total_loss: 2.6468  obj_loss: 0.0834  noobj_loss: 0.0189  bbox_loss: 0.0816  cls_loss: 2.1461  \n",
      "<<<iteration:[60/878] - total_loss: 3.0084  obj_loss: 0.0837  noobj_loss: 0.0182  bbox_loss: 0.1005  cls_loss: 2.4130  \n",
      "<<<iteration:[80/878] - total_loss: 3.0464  obj_loss: 0.0729  noobj_loss: 0.0227  bbox_loss: 0.0926  cls_loss: 2.4990  \n",
      "<<<iteration:[100/878] - total_loss: 3.3325  obj_loss: 0.1002  noobj_loss: 0.0234  bbox_loss: 0.1227  cls_loss: 2.6071  \n",
      "<<<iteration:[120/878] - total_loss: 3.3704  obj_loss: 0.0687  noobj_loss: 0.0166  bbox_loss: 0.1592  cls_loss: 2.4975  \n",
      "<<<iteration:[140/878] - total_loss: 3.1797  obj_loss: 0.0748  noobj_loss: 0.0244  bbox_loss: 0.1150  cls_loss: 2.5178  \n",
      "<<<iteration:[160/878] - total_loss: 3.3879  obj_loss: 0.1009  noobj_loss: 0.0243  bbox_loss: 0.1339  cls_loss: 2.6052  \n",
      "<<<iteration:[180/878] - total_loss: 3.0101  obj_loss: 0.1083  noobj_loss: 0.0268  bbox_loss: 0.0774  cls_loss: 2.5016  \n",
      "<<<iteration:[200/878] - total_loss: 2.7742  obj_loss: 0.0773  noobj_loss: 0.0214  bbox_loss: 0.0945  cls_loss: 2.2136  \n",
      "<<<iteration:[220/878] - total_loss: 2.8560  obj_loss: 0.0764  noobj_loss: 0.0198  bbox_loss: 0.0931  cls_loss: 2.3041  \n",
      "<<<iteration:[240/878] - total_loss: 3.0516  obj_loss: 0.0983  noobj_loss: 0.0200  bbox_loss: 0.0904  cls_loss: 2.4914  \n",
      "<<<iteration:[260/878] - total_loss: 3.5232  obj_loss: 0.1219  noobj_loss: 0.0217  bbox_loss: 0.1657  cls_loss: 2.5621  \n",
      "<<<iteration:[280/878] - total_loss: 2.9669  obj_loss: 0.0903  noobj_loss: 0.0217  bbox_loss: 0.1395  cls_loss: 2.1682  \n",
      "<<<iteration:[300/878] - total_loss: 2.7411  obj_loss: 0.0946  noobj_loss: 0.0221  bbox_loss: 0.1046  cls_loss: 2.1126  \n",
      "<<<iteration:[320/878] - total_loss: 3.1886  obj_loss: 0.0929  noobj_loss: 0.0220  bbox_loss: 0.1325  cls_loss: 2.4221  \n",
      "<<<iteration:[340/878] - total_loss: 2.9302  obj_loss: 0.0878  noobj_loss: 0.0303  bbox_loss: 0.1319  cls_loss: 2.1675  \n",
      "<<<iteration:[360/878] - total_loss: 3.0510  obj_loss: 0.0707  noobj_loss: 0.0149  bbox_loss: 0.1263  cls_loss: 2.3414  \n",
      "<<<iteration:[380/878] - total_loss: 3.1587  obj_loss: 0.1117  noobj_loss: 0.0236  bbox_loss: 0.0997  cls_loss: 2.5369  \n",
      "<<<iteration:[400/878] - total_loss: 2.8658  obj_loss: 0.0791  noobj_loss: 0.0199  bbox_loss: 0.0895  cls_loss: 2.3293  \n",
      "<<<iteration:[420/878] - total_loss: 3.2189  obj_loss: 0.0857  noobj_loss: 0.0315  bbox_loss: 0.1116  cls_loss: 2.5597  \n",
      "<<<iteration:[440/878] - total_loss: 2.9925  obj_loss: 0.1128  noobj_loss: 0.0271  bbox_loss: 0.0874  cls_loss: 2.4291  \n",
      "<<<iteration:[460/878] - total_loss: 3.0774  obj_loss: 0.0834  noobj_loss: 0.0199  bbox_loss: 0.1147  cls_loss: 2.4107  \n",
      "<<<iteration:[480/878] - total_loss: 3.1076  obj_loss: 0.1022  noobj_loss: 0.0186  bbox_loss: 0.0854  cls_loss: 2.5689  \n",
      "<<<iteration:[500/878] - total_loss: 3.1279  obj_loss: 0.0883  noobj_loss: 0.0207  bbox_loss: 0.1078  cls_loss: 2.4903  \n",
      "<<<iteration:[520/878] - total_loss: 2.8645  obj_loss: 0.1117  noobj_loss: 0.0235  bbox_loss: 0.1027  cls_loss: 2.2274  \n",
      "<<<iteration:[540/878] - total_loss: 3.1873  obj_loss: 0.0789  noobj_loss: 0.0224  bbox_loss: 0.1026  cls_loss: 2.5844  \n",
      "<<<iteration:[560/878] - total_loss: 3.0507  obj_loss: 0.0828  noobj_loss: 0.0275  bbox_loss: 0.1179  cls_loss: 2.3645  \n",
      "<<<iteration:[580/878] - total_loss: 2.9456  obj_loss: 0.1218  noobj_loss: 0.0273  bbox_loss: 0.1010  cls_loss: 2.3051  \n",
      "<<<iteration:[600/878] - total_loss: 2.9327  obj_loss: 0.1000  noobj_loss: 0.0226  bbox_loss: 0.1138  cls_loss: 2.2522  \n",
      "<<<iteration:[620/878] - total_loss: 2.8909  obj_loss: 0.1058  noobj_loss: 0.0231  bbox_loss: 0.0994  cls_loss: 2.2765  \n",
      "<<<iteration:[640/878] - total_loss: 3.5251  obj_loss: 0.1029  noobj_loss: 0.0269  bbox_loss: 0.1547  cls_loss: 2.6354  \n",
      "<<<iteration:[660/878] - total_loss: 3.8985  obj_loss: 0.0812  noobj_loss: 0.0332  bbox_loss: 0.2521  cls_loss: 2.5400  \n",
      "<<<iteration:[680/878] - total_loss: 8.7233  obj_loss: 0.0994  noobj_loss: 0.0310  bbox_loss: 1.2163  cls_loss: 2.5269  \n",
      "<<<iteration:[700/878] - total_loss: 5.7487  obj_loss: 0.0829  noobj_loss: 0.0312  bbox_loss: 0.6808  cls_loss: 2.2461  \n",
      "<<<iteration:[720/878] - total_loss: 4.4476  obj_loss: 0.0725  noobj_loss: 0.0363  bbox_loss: 0.4087  cls_loss: 2.3136  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<<<iteration:[740/878] - total_loss: 4.9929  obj_loss: 0.0727  noobj_loss: 0.0239  bbox_loss: 0.5142  cls_loss: 2.3371  \n",
      "<<<iteration:[760/878] - total_loss: 3.5921  obj_loss: 0.1029  noobj_loss: 0.0260  bbox_loss: 0.1670  cls_loss: 2.6411  \n",
      "<<<iteration:[780/878] - total_loss: 4.6060  obj_loss: 0.0936  noobj_loss: 0.0313  bbox_loss: 0.4249  cls_loss: 2.3723  \n",
      "<<<iteration:[800/878] - total_loss: 4.4387  obj_loss: 0.0915  noobj_loss: 0.0238  bbox_loss: 0.3966  cls_loss: 2.3521  \n",
      "<<<iteration:[820/878] - total_loss: 3.3119  obj_loss: 0.0839  noobj_loss: 0.0260  bbox_loss: 0.1623  cls_loss: 2.4034  \n",
      "<<<iteration:[840/878] - total_loss: 3.7750  obj_loss: 0.0846  noobj_loss: 0.0231  bbox_loss: 0.2391  cls_loss: 2.4834  \n",
      "<<<iteration:[860/878] - total_loss: 3.7244  obj_loss: 0.0863  noobj_loss: 0.0227  bbox_loss: 0.1941  cls_loss: 2.6563  \n",
      "\n",
      "epoch:19/100 - Train Loss: 3.4694, Val Loss: 3.0925\n",
      "\n",
      "<<<iteration:[20/878] - total_loss: 3.4758  obj_loss: 0.1003  noobj_loss: 0.0217  bbox_loss: 0.1646  cls_loss: 2.5418  \n",
      "<<<iteration:[40/878] - total_loss: 3.1652  obj_loss: 0.1146  noobj_loss: 0.0276  bbox_loss: 0.1142  cls_loss: 2.4658  \n",
      "<<<iteration:[60/878] - total_loss: 3.5008  obj_loss: 0.0789  noobj_loss: 0.0312  bbox_loss: 0.1860  cls_loss: 2.4761  \n",
      "<<<iteration:[80/878] - total_loss: 2.9819  obj_loss: 0.1153  noobj_loss: 0.0183  bbox_loss: 0.0899  cls_loss: 2.4080  \n",
      "<<<iteration:[100/878] - total_loss: 3.1936  obj_loss: 0.0864  noobj_loss: 0.0212  bbox_loss: 0.1644  cls_loss: 2.2743  \n",
      "<<<iteration:[120/878] - total_loss: 3.9088  obj_loss: 0.0749  noobj_loss: 0.0393  bbox_loss: 0.2400  cls_loss: 2.6143  \n",
      "<<<iteration:[140/878] - total_loss: 3.2249  obj_loss: 0.0834  noobj_loss: 0.0253  bbox_loss: 0.1651  cls_loss: 2.3035  \n",
      "<<<iteration:[160/878] - total_loss: 3.6855  obj_loss: 0.0857  noobj_loss: 0.0554  bbox_loss: 0.2571  cls_loss: 2.2864  \n",
      "<<<iteration:[180/878] - total_loss: 3.6364  obj_loss: 0.0924  noobj_loss: 0.0254  bbox_loss: 0.1732  cls_loss: 2.6654  \n",
      "<<<iteration:[200/878] - total_loss: 2.8173  obj_loss: 0.0998  noobj_loss: 0.0205  bbox_loss: 0.1011  cls_loss: 2.2020  \n",
      "<<<iteration:[220/878] - total_loss: 3.1542  obj_loss: 0.0850  noobj_loss: 0.0200  bbox_loss: 0.1550  cls_loss: 2.2841  \n",
      "<<<iteration:[240/878] - total_loss: 3.6247  obj_loss: 0.0845  noobj_loss: 0.0279  bbox_loss: 0.1909  cls_loss: 2.5718  \n",
      "<<<iteration:[260/878] - total_loss: 3.2964  obj_loss: 0.0877  noobj_loss: 0.0170  bbox_loss: 0.1335  cls_loss: 2.5327  \n",
      "<<<iteration:[280/878] - total_loss: 3.4314  obj_loss: 0.1010  noobj_loss: 0.0267  bbox_loss: 0.1102  cls_loss: 2.7663  \n",
      "<<<iteration:[300/878] - total_loss: 3.2826  obj_loss: 0.0931  noobj_loss: 0.0316  bbox_loss: 0.1178  cls_loss: 2.5847  \n",
      "<<<iteration:[320/878] - total_loss: 3.1402  obj_loss: 0.0917  noobj_loss: 0.0218  bbox_loss: 0.1298  cls_loss: 2.3885  \n",
      "<<<iteration:[340/878] - total_loss: 3.2183  obj_loss: 0.1000  noobj_loss: 0.0270  bbox_loss: 0.1427  cls_loss: 2.3912  \n",
      "<<<iteration:[360/878] - total_loss: 2.7884  obj_loss: 0.0763  noobj_loss: 0.0185  bbox_loss: 0.0940  cls_loss: 2.2327  \n",
      "<<<iteration:[380/878] - total_loss: 3.2760  obj_loss: 0.0799  noobj_loss: 0.0197  bbox_loss: 0.1336  cls_loss: 2.5184  \n",
      "<<<iteration:[400/878] - total_loss: 3.0783  obj_loss: 0.0962  noobj_loss: 0.0182  bbox_loss: 0.1211  cls_loss: 2.3677  \n",
      "<<<iteration:[420/878] - total_loss: 2.7764  obj_loss: 0.0644  noobj_loss: 0.0202  bbox_loss: 0.1047  cls_loss: 2.1786  \n",
      "<<<iteration:[440/878] - total_loss: 2.8959  obj_loss: 0.0992  noobj_loss: 0.0410  bbox_loss: 0.1177  cls_loss: 2.1876  \n",
      "<<<iteration:[460/878] - total_loss: 3.2144  obj_loss: 0.0959  noobj_loss: 0.0229  bbox_loss: 0.1272  cls_loss: 2.4708  \n",
      "<<<iteration:[480/878] - total_loss: 2.9103  obj_loss: 0.0663  noobj_loss: 0.0176  bbox_loss: 0.1011  cls_loss: 2.3299  \n",
      "<<<iteration:[500/878] - total_loss: 3.2473  obj_loss: 0.0688  noobj_loss: 0.0209  bbox_loss: 0.1003  cls_loss: 2.6664  \n",
      "<<<iteration:[520/878] - total_loss: 3.1380  obj_loss: 0.1032  noobj_loss: 0.0226  bbox_loss: 0.0927  cls_loss: 2.5598  \n",
      "<<<iteration:[540/878] - total_loss: 2.9434  obj_loss: 0.0822  noobj_loss: 0.0196  bbox_loss: 0.0974  cls_loss: 2.3643  \n",
      "<<<iteration:[560/878] - total_loss: 3.0292  obj_loss: 0.1046  noobj_loss: 0.0221  bbox_loss: 0.1120  cls_loss: 2.3537  \n",
      "<<<iteration:[580/878] - total_loss: 2.8110  obj_loss: 0.0863  noobj_loss: 0.0183  bbox_loss: 0.0990  cls_loss: 2.2206  \n",
      "<<<iteration:[600/878] - total_loss: 2.8358  obj_loss: 0.0946  noobj_loss: 0.0179  bbox_loss: 0.0884  cls_loss: 2.2901  \n",
      "<<<iteration:[620/878] - total_loss: 3.2381  obj_loss: 0.0929  noobj_loss: 0.0190  bbox_loss: 0.0959  cls_loss: 2.6561  \n",
      "<<<iteration:[640/878] - total_loss: 3.0364  obj_loss: 0.0841  noobj_loss: 0.0225  bbox_loss: 0.0933  cls_loss: 2.4746  \n",
      "<<<iteration:[660/878] - total_loss: 2.9785  obj_loss: 0.1055  noobj_loss: 0.0156  bbox_loss: 0.0860  cls_loss: 2.4351  \n",
      "<<<iteration:[680/878] - total_loss: 3.3761  obj_loss: 0.0733  noobj_loss: 0.0406  bbox_loss: 0.1306  cls_loss: 2.6295  \n",
      "<<<iteration:[700/878] - total_loss: 2.9619  obj_loss: 0.0943  noobj_loss: 0.0256  bbox_loss: 0.1139  cls_loss: 2.2852  \n",
      "<<<iteration:[720/878] - total_loss: 3.1785  obj_loss: 0.1028  noobj_loss: 0.0217  bbox_loss: 0.1078  cls_loss: 2.5258  \n",
      "<<<iteration:[740/878] - total_loss: 2.9327  obj_loss: 0.0636  noobj_loss: 0.0168  bbox_loss: 0.0861  cls_loss: 2.4301  \n",
      "<<<iteration:[760/878] - total_loss: 3.0796  obj_loss: 0.0864  noobj_loss: 0.0214  bbox_loss: 0.1070  cls_loss: 2.4476  \n",
      "<<<iteration:[780/878] - total_loss: 3.0492  obj_loss: 0.1170  noobj_loss: 0.0203  bbox_loss: 0.1265  cls_loss: 2.2894  \n",
      "<<<iteration:[800/878] - total_loss: 2.9149  obj_loss: 0.0808  noobj_loss: 0.0168  bbox_loss: 0.1145  cls_loss: 2.2533  \n",
      "<<<iteration:[820/878] - total_loss: 2.9992  obj_loss: 0.0824  noobj_loss: 0.0164  bbox_loss: 0.1013  cls_loss: 2.4020  \n",
      "<<<iteration:[840/878] - total_loss: 2.8223  obj_loss: 0.1054  noobj_loss: 0.0197  bbox_loss: 0.0992  cls_loss: 2.2109  \n",
      "<<<iteration:[860/878] - total_loss: 2.7101  obj_loss: 0.0921  noobj_loss: 0.0242  bbox_loss: 0.0804  cls_loss: 2.2041  \n",
      "\n",
      "epoch:20/100 - Train Loss: 3.1432, Val Loss: 3.1654\n",
      "\n",
      "<<<iteration:[20/878] - total_loss: 4.0425  obj_loss: 0.1001  noobj_loss: 0.0169  bbox_loss: 0.2908  cls_loss: 2.4797  \n",
      "<<<iteration:[40/878] - total_loss: 2.9122  obj_loss: 0.0639  noobj_loss: 0.0145  bbox_loss: 0.1001  cls_loss: 2.3405  \n",
      "<<<iteration:[60/878] - total_loss: 3.1877  obj_loss: 0.0644  noobj_loss: 0.0172  bbox_loss: 0.1624  cls_loss: 2.3029  \n",
      "<<<iteration:[80/878] - total_loss: 2.9037  obj_loss: 0.1141  noobj_loss: 0.0234  bbox_loss: 0.0921  cls_loss: 2.3173  \n",
      "<<<iteration:[100/878] - total_loss: 3.7478  obj_loss: 0.0902  noobj_loss: 0.0176  bbox_loss: 0.2623  cls_loss: 2.3372  \n",
      "<<<iteration:[120/878] - total_loss: 2.9894  obj_loss: 0.0709  noobj_loss: 0.0202  bbox_loss: 0.1732  cls_loss: 2.0424  \n",
      "<<<iteration:[140/878] - total_loss: 2.9485  obj_loss: 0.0798  noobj_loss: 0.0223  bbox_loss: 0.1096  cls_loss: 2.3095  \n",
      "<<<iteration:[160/878] - total_loss: 3.9702  obj_loss: 0.0882  noobj_loss: 0.0226  bbox_loss: 0.2818  cls_loss: 2.4619  \n",
      "<<<iteration:[180/878] - total_loss: 3.5834  obj_loss: 0.0785  noobj_loss: 0.0187  bbox_loss: 0.1548  cls_loss: 2.7216  \n",
      "<<<iteration:[200/878] - total_loss: 2.9380  obj_loss: 0.1058  noobj_loss: 0.0189  bbox_loss: 0.0869  cls_loss: 2.3882  \n",
      "<<<iteration:[220/878] - total_loss: 3.1247  obj_loss: 0.0752  noobj_loss: 0.0180  bbox_loss: 0.1253  cls_loss: 2.4138  \n",
      "<<<iteration:[240/878] - total_loss: 3.0229  obj_loss: 0.1103  noobj_loss: 0.0298  bbox_loss: 0.1070  cls_loss: 2.3627  \n",
      "<<<iteration:[260/878] - total_loss: 2.7120  obj_loss: 0.1140  noobj_loss: 0.0198  bbox_loss: 0.0861  cls_loss: 2.1577  \n",
      "<<<iteration:[280/878] - total_loss: 3.2231  obj_loss: 0.0858  noobj_loss: 0.0185  bbox_loss: 0.0988  cls_loss: 2.6342  \n",
      "<<<iteration:[300/878] - total_loss: 3.1703  obj_loss: 0.0682  noobj_loss: 0.0201  bbox_loss: 0.0974  cls_loss: 2.6051  \n",
      "<<<iteration:[320/878] - total_loss: 3.1698  obj_loss: 0.0929  noobj_loss: 0.0166  bbox_loss: 0.1267  cls_loss: 2.4353  \n",
      "<<<iteration:[340/878] - total_loss: 3.3608  obj_loss: 0.1051  noobj_loss: 0.0196  bbox_loss: 0.1755  cls_loss: 2.3682  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<<<iteration:[360/878] - total_loss: 2.8354  obj_loss: 0.0767  noobj_loss: 0.0190  bbox_loss: 0.1063  cls_loss: 2.2175  \n",
      "<<<iteration:[380/878] - total_loss: 2.9653  obj_loss: 0.1004  noobj_loss: 0.0179  bbox_loss: 0.1120  cls_loss: 2.2960  \n",
      "<<<iteration:[400/878] - total_loss: 2.9488  obj_loss: 0.0874  noobj_loss: 0.0192  bbox_loss: 0.1005  cls_loss: 2.3493  \n",
      "<<<iteration:[420/878] - total_loss: 2.8315  obj_loss: 0.1149  noobj_loss: 0.0212  bbox_loss: 0.1037  cls_loss: 2.1873  \n",
      "<<<iteration:[440/878] - total_loss: 3.2649  obj_loss: 0.1111  noobj_loss: 0.0244  bbox_loss: 0.1113  cls_loss: 2.5853  \n",
      "<<<iteration:[460/878] - total_loss: 2.7232  obj_loss: 0.0888  noobj_loss: 0.0188  bbox_loss: 0.0922  cls_loss: 2.1643  \n",
      "<<<iteration:[480/878] - total_loss: 3.1285  obj_loss: 0.0917  noobj_loss: 0.0194  bbox_loss: 0.1142  cls_loss: 2.4558  \n",
      "<<<iteration:[500/878] - total_loss: 3.2720  obj_loss: 0.0810  noobj_loss: 0.0179  bbox_loss: 0.1109  cls_loss: 2.6276  \n",
      "<<<iteration:[520/878] - total_loss: 3.2122  obj_loss: 0.0874  noobj_loss: 0.0162  bbox_loss: 0.1029  cls_loss: 2.6023  \n",
      "<<<iteration:[540/878] - total_loss: 2.9842  obj_loss: 0.0814  noobj_loss: 0.0166  bbox_loss: 0.0905  cls_loss: 2.4422  \n",
      "<<<iteration:[560/878] - total_loss: 3.0352  obj_loss: 0.1033  noobj_loss: 0.0164  bbox_loss: 0.0850  cls_loss: 2.4987  \n",
      "<<<iteration:[580/878] - total_loss: 2.8665  obj_loss: 0.0781  noobj_loss: 0.0173  bbox_loss: 0.0796  cls_loss: 2.3815  \n",
      "<<<iteration:[600/878] - total_loss: 3.1871  obj_loss: 0.1063  noobj_loss: 0.0174  bbox_loss: 0.1119  cls_loss: 2.5124  \n",
      "<<<iteration:[620/878] - total_loss: 3.2576  obj_loss: 0.0686  noobj_loss: 0.0218  bbox_loss: 0.1199  cls_loss: 2.5787  \n",
      "<<<iteration:[640/878] - total_loss: 3.0728  obj_loss: 0.0977  noobj_loss: 0.0251  bbox_loss: 0.1033  cls_loss: 2.4462  \n",
      "<<<iteration:[660/878] - total_loss: 2.8316  obj_loss: 0.0780  noobj_loss: 0.0227  bbox_loss: 0.1113  cls_loss: 2.1860  \n",
      "<<<iteration:[680/878] - total_loss: 3.0301  obj_loss: 0.0799  noobj_loss: 0.0189  bbox_loss: 0.1198  cls_loss: 2.3419  \n",
      "<<<iteration:[700/878] - total_loss: 2.9815  obj_loss: 0.0961  noobj_loss: 0.0237  bbox_loss: 0.1089  cls_loss: 2.3290  \n",
      "<<<iteration:[720/878] - total_loss: 2.9940  obj_loss: 0.1048  noobj_loss: 0.0192  bbox_loss: 0.1173  cls_loss: 2.2933  \n",
      "<<<iteration:[740/878] - total_loss: 3.2337  obj_loss: 0.1033  noobj_loss: 0.0184  bbox_loss: 0.1179  cls_loss: 2.5317  \n",
      "<<<iteration:[760/878] - total_loss: 2.7906  obj_loss: 0.0823  noobj_loss: 0.0200  bbox_loss: 0.0872  cls_loss: 2.2625  \n",
      "<<<iteration:[780/878] - total_loss: 3.0708  obj_loss: 0.1198  noobj_loss: 0.0261  bbox_loss: 0.0996  cls_loss: 2.4400  \n",
      "<<<iteration:[800/878] - total_loss: 3.2568  obj_loss: 0.0907  noobj_loss: 0.0239  bbox_loss: 0.1303  cls_loss: 2.5026  \n",
      "<<<iteration:[820/878] - total_loss: 3.0625  obj_loss: 0.0703  noobj_loss: 0.0230  bbox_loss: 0.1152  cls_loss: 2.4046  \n",
      "<<<iteration:[840/878] - total_loss: 2.9282  obj_loss: 0.1243  noobj_loss: 0.0183  bbox_loss: 0.1168  cls_loss: 2.2108  \n",
      "<<<iteration:[860/878] - total_loss: 3.6993  obj_loss: 0.0851  noobj_loss: 0.0260  bbox_loss: 0.2001  cls_loss: 2.6008  \n",
      "\n",
      "epoch:21/100 - Train Loss: 3.1432, Val Loss: 3.2144\n",
      "\n",
      "<<<iteration:[20/878] - total_loss: 3.1177  obj_loss: 0.1172  noobj_loss: 0.0212  bbox_loss: 0.1120  cls_loss: 2.4300  \n",
      "<<<iteration:[40/878] - total_loss: 3.1522  obj_loss: 0.1079  noobj_loss: 0.0205  bbox_loss: 0.1455  cls_loss: 2.3067  \n",
      "<<<iteration:[60/878] - total_loss: 2.9596  obj_loss: 0.0698  noobj_loss: 0.0217  bbox_loss: 0.1440  cls_loss: 2.1593  \n",
      "<<<iteration:[80/878] - total_loss: 3.5656  obj_loss: 0.0863  noobj_loss: 0.0221  bbox_loss: 0.1761  cls_loss: 2.5875  \n",
      "<<<iteration:[100/878] - total_loss: 3.2616  obj_loss: 0.1215  noobj_loss: 0.0242  bbox_loss: 0.1325  cls_loss: 2.4658  \n",
      "<<<iteration:[120/878] - total_loss: 3.9055  obj_loss: 0.0980  noobj_loss: 0.0306  bbox_loss: 0.2513  cls_loss: 2.5355  \n",
      "<<<iteration:[140/878] - total_loss: 3.1798  obj_loss: 0.0858  noobj_loss: 0.0233  bbox_loss: 0.1122  cls_loss: 2.5214  \n",
      "<<<iteration:[160/878] - total_loss: 3.1274  obj_loss: 0.0722  noobj_loss: 0.0188  bbox_loss: 0.1253  cls_loss: 2.4191  \n",
      "<<<iteration:[180/878] - total_loss: 3.2317  obj_loss: 0.1212  noobj_loss: 0.0254  bbox_loss: 0.1081  cls_loss: 2.5574  \n",
      "<<<iteration:[200/878] - total_loss: 3.0255  obj_loss: 0.0711  noobj_loss: 0.0205  bbox_loss: 0.0966  cls_loss: 2.4612  \n",
      "<<<iteration:[220/878] - total_loss: 3.0365  obj_loss: 0.0947  noobj_loss: 0.0198  bbox_loss: 0.0955  cls_loss: 2.4545  \n",
      "<<<iteration:[240/878] - total_loss: 3.3210  obj_loss: 0.0840  noobj_loss: 0.0273  bbox_loss: 0.1461  cls_loss: 2.4927  \n",
      "<<<iteration:[260/878] - total_loss: 3.0470  obj_loss: 0.0948  noobj_loss: 0.0199  bbox_loss: 0.1033  cls_loss: 2.4257  \n",
      "<<<iteration:[280/878] - total_loss: 3.2196  obj_loss: 0.0832  noobj_loss: 0.0555  bbox_loss: 0.1519  cls_loss: 2.3490  \n",
      "<<<iteration:[300/878] - total_loss: 3.7545  obj_loss: 0.0815  noobj_loss: 0.0216  bbox_loss: 0.2544  cls_loss: 2.3899  \n",
      "<<<iteration:[320/878] - total_loss: 3.4834  obj_loss: 0.0815  noobj_loss: 0.0159  bbox_loss: 0.1370  cls_loss: 2.7088  \n",
      "<<<iteration:[340/878] - total_loss: 2.9504  obj_loss: 0.0865  noobj_loss: 0.0183  bbox_loss: 0.0991  cls_loss: 2.3592  \n",
      "<<<iteration:[360/878] - total_loss: 3.5411  obj_loss: 0.0714  noobj_loss: 0.0161  bbox_loss: 0.1521  cls_loss: 2.7012  \n",
      "<<<iteration:[380/878] - total_loss: 2.9306  obj_loss: 0.0688  noobj_loss: 0.0170  bbox_loss: 0.0894  cls_loss: 2.4062  \n",
      "<<<iteration:[400/878] - total_loss: 3.1424  obj_loss: 0.0856  noobj_loss: 0.0179  bbox_loss: 0.1241  cls_loss: 2.4271  \n",
      "<<<iteration:[420/878] - total_loss: 3.0920  obj_loss: 0.0688  noobj_loss: 0.0255  bbox_loss: 0.0972  cls_loss: 2.5243  \n",
      "<<<iteration:[440/878] - total_loss: 2.9377  obj_loss: 0.1320  noobj_loss: 0.0197  bbox_loss: 0.1057  cls_loss: 2.2674  \n",
      "<<<iteration:[460/878] - total_loss: 3.1806  obj_loss: 0.1070  noobj_loss: 0.0269  bbox_loss: 0.0981  cls_loss: 2.5699  \n",
      "<<<iteration:[480/878] - total_loss: 3.4117  obj_loss: 0.1103  noobj_loss: 0.0200  bbox_loss: 0.1097  cls_loss: 2.7430  \n",
      "<<<iteration:[500/878] - total_loss: 2.3976  obj_loss: 0.0986  noobj_loss: 0.0261  bbox_loss: 0.0745  cls_loss: 1.9136  \n",
      "<<<iteration:[520/878] - total_loss: 2.7671  obj_loss: 0.0844  noobj_loss: 0.0149  bbox_loss: 0.0907  cls_loss: 2.2217  \n",
      "<<<iteration:[540/878] - total_loss: 2.9840  obj_loss: 0.1015  noobj_loss: 0.0165  bbox_loss: 0.1172  cls_loss: 2.2882  \n",
      "<<<iteration:[560/878] - total_loss: 3.2432  obj_loss: 0.1129  noobj_loss: 0.0223  bbox_loss: 0.1493  cls_loss: 2.3726  \n",
      "<<<iteration:[580/878] - total_loss: 2.6461  obj_loss: 0.0846  noobj_loss: 0.0189  bbox_loss: 0.0929  cls_loss: 2.0875  \n",
      "<<<iteration:[600/878] - total_loss: 3.2988  obj_loss: 0.0898  noobj_loss: 0.0198  bbox_loss: 0.1160  cls_loss: 2.6193  \n",
      "<<<iteration:[620/878] - total_loss: 2.4741  obj_loss: 0.0895  noobj_loss: 0.0166  bbox_loss: 0.0768  cls_loss: 1.9923  \n",
      "<<<iteration:[640/878] - total_loss: 2.8855  obj_loss: 0.0814  noobj_loss: 0.0189  bbox_loss: 0.0903  cls_loss: 2.3429  \n",
      "<<<iteration:[660/878] - total_loss: 2.5982  obj_loss: 0.0817  noobj_loss: 0.0216  bbox_loss: 0.0853  cls_loss: 2.0791  \n",
      "<<<iteration:[680/878] - total_loss: 3.3594  obj_loss: 0.1043  noobj_loss: 0.0186  bbox_loss: 0.1582  cls_loss: 2.4546  \n",
      "<<<iteration:[700/878] - total_loss: 3.1176  obj_loss: 0.0906  noobj_loss: 0.0210  bbox_loss: 0.1268  cls_loss: 2.3827  \n",
      "<<<iteration:[720/878] - total_loss: 3.0197  obj_loss: 0.1001  noobj_loss: 0.0178  bbox_loss: 0.0943  cls_loss: 2.4392  \n",
      "<<<iteration:[740/878] - total_loss: 2.9985  obj_loss: 0.0780  noobj_loss: 0.0161  bbox_loss: 0.0904  cls_loss: 2.4605  \n",
      "<<<iteration:[760/878] - total_loss: 2.6108  obj_loss: 0.0878  noobj_loss: 0.0209  bbox_loss: 0.0848  cls_loss: 2.0884  \n",
      "<<<iteration:[780/878] - total_loss: 3.0969  obj_loss: 0.1112  noobj_loss: 0.0235  bbox_loss: 0.1389  cls_loss: 2.2797  \n",
      "<<<iteration:[800/878] - total_loss: 2.9069  obj_loss: 0.0726  noobj_loss: 0.0212  bbox_loss: 0.1054  cls_loss: 2.2967  \n",
      "<<<iteration:[820/878] - total_loss: 3.0944  obj_loss: 0.1055  noobj_loss: 0.0184  bbox_loss: 0.0887  cls_loss: 2.5362  \n",
      "<<<iteration:[840/878] - total_loss: 2.8989  obj_loss: 0.0883  noobj_loss: 0.0188  bbox_loss: 0.0993  cls_loss: 2.3045  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<<<iteration:[860/878] - total_loss: 2.7802  obj_loss: 0.0958  noobj_loss: 0.0175  bbox_loss: 0.0884  cls_loss: 2.2336  \n",
      "\n",
      "epoch:22/100 - Train Loss: 3.0821, Val Loss: 3.1069\n",
      "\n",
      "<<<iteration:[20/878] - total_loss: 3.2726  obj_loss: 0.0903  noobj_loss: 0.0171  bbox_loss: 0.1158  cls_loss: 2.5947  \n",
      "<<<iteration:[40/878] - total_loss: 2.7145  obj_loss: 0.0763  noobj_loss: 0.0180  bbox_loss: 0.0941  cls_loss: 2.1587  \n",
      "<<<iteration:[60/878] - total_loss: 2.9671  obj_loss: 0.0887  noobj_loss: 0.0164  bbox_loss: 0.0867  cls_loss: 2.4368  \n",
      "<<<iteration:[80/878] - total_loss: 3.1803  obj_loss: 0.1023  noobj_loss: 0.0200  bbox_loss: 0.1037  cls_loss: 2.5496  \n",
      "<<<iteration:[100/878] - total_loss: 3.1640  obj_loss: 0.0890  noobj_loss: 0.0340  bbox_loss: 0.1461  cls_loss: 2.3277  \n",
      "<<<iteration:[120/878] - total_loss: 3.0385  obj_loss: 0.1142  noobj_loss: 0.0184  bbox_loss: 0.1013  cls_loss: 2.4086  \n",
      "<<<iteration:[140/878] - total_loss: 3.0168  obj_loss: 0.1002  noobj_loss: 0.0327  bbox_loss: 0.1063  cls_loss: 2.3689  \n",
      "<<<iteration:[160/878] - total_loss: 2.8130  obj_loss: 0.0852  noobj_loss: 0.0164  bbox_loss: 0.0794  cls_loss: 2.3228  \n",
      "<<<iteration:[180/878] - total_loss: 3.4345  obj_loss: 0.0941  noobj_loss: 0.0179  bbox_loss: 0.1411  cls_loss: 2.6258  \n",
      "<<<iteration:[200/878] - total_loss: 3.1164  obj_loss: 0.0876  noobj_loss: 0.0169  bbox_loss: 0.0986  cls_loss: 2.5274  \n",
      "<<<iteration:[220/878] - total_loss: 3.1322  obj_loss: 0.0932  noobj_loss: 0.0165  bbox_loss: 0.1130  cls_loss: 2.4656  \n",
      "<<<iteration:[240/878] - total_loss: 2.8061  obj_loss: 0.1150  noobj_loss: 0.0224  bbox_loss: 0.0851  cls_loss: 2.2545  \n",
      "<<<iteration:[260/878] - total_loss: 3.2861  obj_loss: 0.0964  noobj_loss: 0.0173  bbox_loss: 0.1618  cls_loss: 2.3721  \n",
      "<<<iteration:[280/878] - total_loss: 2.9284  obj_loss: 0.0918  noobj_loss: 0.0230  bbox_loss: 0.1038  cls_loss: 2.3062  \n",
      "<<<iteration:[300/878] - total_loss: 2.8563  obj_loss: 0.0922  noobj_loss: 0.0172  bbox_loss: 0.0823  cls_loss: 2.3438  \n",
      "<<<iteration:[320/878] - total_loss: 2.7203  obj_loss: 0.0807  noobj_loss: 0.0158  bbox_loss: 0.0737  cls_loss: 2.2632  \n",
      "<<<iteration:[340/878] - total_loss: 2.8718  obj_loss: 0.0908  noobj_loss: 0.0186  bbox_loss: 0.0957  cls_loss: 2.2932  \n",
      "<<<iteration:[360/878] - total_loss: 3.3080  obj_loss: 0.1151  noobj_loss: 0.0274  bbox_loss: 0.1424  cls_loss: 2.4672  \n",
      "<<<iteration:[380/878] - total_loss: 3.0472  obj_loss: 0.0958  noobj_loss: 0.0177  bbox_loss: 0.1166  cls_loss: 2.3594  \n",
      "<<<iteration:[400/878] - total_loss: 2.5944  obj_loss: 0.0974  noobj_loss: 0.0240  bbox_loss: 0.0896  cls_loss: 2.0369  \n",
      "<<<iteration:[420/878] - total_loss: 3.0436  obj_loss: 0.1054  noobj_loss: 0.0195  bbox_loss: 0.1003  cls_loss: 2.4270  \n",
      "<<<iteration:[440/878] - total_loss: 3.0505  obj_loss: 0.0956  noobj_loss: 0.0184  bbox_loss: 0.0947  cls_loss: 2.4721  \n",
      "<<<iteration:[460/878] - total_loss: 2.8166  obj_loss: 0.1160  noobj_loss: 0.0189  bbox_loss: 0.0773  cls_loss: 2.3046  \n",
      "<<<iteration:[480/878] - total_loss: 3.1213  obj_loss: 0.0859  noobj_loss: 0.0180  bbox_loss: 0.1130  cls_loss: 2.4614  \n",
      "<<<iteration:[500/878] - total_loss: 3.1086  obj_loss: 0.0767  noobj_loss: 0.0381  bbox_loss: 0.1555  cls_loss: 2.2351  \n",
      "<<<iteration:[520/878] - total_loss: 2.5474  obj_loss: 0.0621  noobj_loss: 0.0240  bbox_loss: 0.1013  cls_loss: 1.9669  \n",
      "<<<iteration:[540/878] - total_loss: 2.7912  obj_loss: 0.0768  noobj_loss: 0.0173  bbox_loss: 0.1036  cls_loss: 2.1875  \n",
      "<<<iteration:[560/878] - total_loss: 2.8297  obj_loss: 0.1024  noobj_loss: 0.0177  bbox_loss: 0.0915  cls_loss: 2.2610  \n",
      "<<<iteration:[580/878] - total_loss: 2.8410  obj_loss: 0.1004  noobj_loss: 0.0168  bbox_loss: 0.0954  cls_loss: 2.2554  \n",
      "<<<iteration:[600/878] - total_loss: 3.1266  obj_loss: 0.0905  noobj_loss: 0.0202  bbox_loss: 0.1213  cls_loss: 2.4194  \n",
      "<<<iteration:[620/878] - total_loss: 2.9433  obj_loss: 0.0838  noobj_loss: 0.0170  bbox_loss: 0.0926  cls_loss: 2.3879  \n",
      "<<<iteration:[640/878] - total_loss: 2.8987  obj_loss: 0.1028  noobj_loss: 0.0186  bbox_loss: 0.0956  cls_loss: 2.3088  \n",
      "<<<iteration:[660/878] - total_loss: 2.7169  obj_loss: 0.0922  noobj_loss: 0.0222  bbox_loss: 0.0844  cls_loss: 2.1919  \n",
      "<<<iteration:[680/878] - total_loss: 2.8572  obj_loss: 0.0914  noobj_loss: 0.0171  bbox_loss: 0.0971  cls_loss: 2.2719  \n",
      "<<<iteration:[700/878] - total_loss: 2.8244  obj_loss: 0.0902  noobj_loss: 0.0157  bbox_loss: 0.0862  cls_loss: 2.2951  \n",
      "<<<iteration:[720/878] - total_loss: 3.0960  obj_loss: 0.0892  noobj_loss: 0.0176  bbox_loss: 0.1068  cls_loss: 2.4641  \n",
      "<<<iteration:[740/878] - total_loss: 2.9300  obj_loss: 0.0916  noobj_loss: 0.0263  bbox_loss: 0.1267  cls_loss: 2.1916  \n",
      "<<<iteration:[760/878] - total_loss: 3.1263  obj_loss: 0.0964  noobj_loss: 0.0172  bbox_loss: 0.0935  cls_loss: 2.5537  \n",
      "<<<iteration:[780/878] - total_loss: 3.3631  obj_loss: 0.1036  noobj_loss: 0.0210  bbox_loss: 0.1506  cls_loss: 2.4957  \n",
      "<<<iteration:[800/878] - total_loss: 3.1141  obj_loss: 0.1002  noobj_loss: 0.0289  bbox_loss: 0.0989  cls_loss: 2.5050  \n",
      "<<<iteration:[820/878] - total_loss: 2.9044  obj_loss: 0.1149  noobj_loss: 0.0190  bbox_loss: 0.0977  cls_loss: 2.2913  \n",
      "<<<iteration:[840/878] - total_loss: 3.0025  obj_loss: 0.1127  noobj_loss: 0.0199  bbox_loss: 0.0892  cls_loss: 2.4336  \n",
      "<<<iteration:[860/878] - total_loss: 3.8260  obj_loss: 0.0787  noobj_loss: 0.0169  bbox_loss: 0.2034  cls_loss: 2.7217  \n",
      "\n",
      "epoch:23/100 - Train Loss: 2.9948, Val Loss: 4.1064\n",
      "\n",
      "<<<iteration:[20/878] - total_loss: 3.8339  obj_loss: 0.1017  noobj_loss: 0.0221  bbox_loss: 0.2495  cls_loss: 2.4736  \n",
      "<<<iteration:[40/878] - total_loss: 3.1043  obj_loss: 0.0993  noobj_loss: 0.0194  bbox_loss: 0.1126  cls_loss: 2.4320  \n",
      "<<<iteration:[60/878] - total_loss: 2.9913  obj_loss: 0.0934  noobj_loss: 0.0183  bbox_loss: 0.1129  cls_loss: 2.3244  \n",
      "<<<iteration:[80/878] - total_loss: 3.0480  obj_loss: 0.1106  noobj_loss: 0.0219  bbox_loss: 0.1026  cls_loss: 2.4135  \n",
      "<<<iteration:[100/878] - total_loss: 2.8567  obj_loss: 0.0815  noobj_loss: 0.0182  bbox_loss: 0.0911  cls_loss: 2.3104  \n",
      "<<<iteration:[120/878] - total_loss: 2.9528  obj_loss: 0.0869  noobj_loss: 0.0231  bbox_loss: 0.1063  cls_loss: 2.3227  \n",
      "<<<iteration:[140/878] - total_loss: 2.6914  obj_loss: 0.0955  noobj_loss: 0.0181  bbox_loss: 0.0973  cls_loss: 2.1002  \n",
      "<<<iteration:[160/878] - total_loss: 3.9601  obj_loss: 0.0637  noobj_loss: 0.0287  bbox_loss: 0.2778  cls_loss: 2.4932  \n",
      "<<<iteration:[180/878] - total_loss: 3.2044  obj_loss: 0.1049  noobj_loss: 0.0184  bbox_loss: 0.1459  cls_loss: 2.3609  \n",
      "<<<iteration:[200/878] - total_loss: 3.1417  obj_loss: 0.1073  noobj_loss: 0.0254  bbox_loss: 0.1560  cls_loss: 2.2417  \n",
      "<<<iteration:[220/878] - total_loss: 3.1998  obj_loss: 0.0927  noobj_loss: 0.0194  bbox_loss: 0.1568  cls_loss: 2.3137  \n",
      "<<<iteration:[240/878] - total_loss: 3.3419  obj_loss: 0.1326  noobj_loss: 0.0223  bbox_loss: 0.1409  cls_loss: 2.4935  \n",
      "<<<iteration:[260/878] - total_loss: 4.1945  obj_loss: 0.0825  noobj_loss: 0.0221  bbox_loss: 0.2967  cls_loss: 2.6175  \n",
      "<<<iteration:[280/878] - total_loss: 3.0307  obj_loss: 0.1047  noobj_loss: 0.0187  bbox_loss: 0.0975  cls_loss: 2.4291  \n",
      "<<<iteration:[300/878] - total_loss: 3.3168  obj_loss: 0.1013  noobj_loss: 0.0215  bbox_loss: 0.1624  cls_loss: 2.3928  \n",
      "<<<iteration:[320/878] - total_loss: 3.1195  obj_loss: 0.0932  noobj_loss: 0.0203  bbox_loss: 0.1091  cls_loss: 2.4707  \n",
      "<<<iteration:[340/878] - total_loss: 2.9090  obj_loss: 0.0915  noobj_loss: 0.0216  bbox_loss: 0.1021  cls_loss: 2.2963  \n",
      "<<<iteration:[360/878] - total_loss: 2.8884  obj_loss: 0.0785  noobj_loss: 0.0218  bbox_loss: 0.1059  cls_loss: 2.2697  \n",
      "<<<iteration:[380/878] - total_loss: 2.8588  obj_loss: 0.1120  noobj_loss: 0.0220  bbox_loss: 0.0843  cls_loss: 2.3145  \n",
      "<<<iteration:[400/878] - total_loss: 2.7446  obj_loss: 0.0836  noobj_loss: 0.0188  bbox_loss: 0.0900  cls_loss: 2.2015  \n",
      "<<<iteration:[420/878] - total_loss: 2.9523  obj_loss: 0.1190  noobj_loss: 0.0313  bbox_loss: 0.1284  cls_loss: 2.1757  \n",
      "<<<iteration:[440/878] - total_loss: 3.0280  obj_loss: 0.1020  noobj_loss: 0.0389  bbox_loss: 0.1232  cls_loss: 2.2907  \n",
      "<<<iteration:[460/878] - total_loss: 3.0738  obj_loss: 0.0994  noobj_loss: 0.0219  bbox_loss: 0.1191  cls_loss: 2.3681  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<<<iteration:[480/878] - total_loss: 2.9023  obj_loss: 0.1054  noobj_loss: 0.0192  bbox_loss: 0.0966  cls_loss: 2.3043  \n",
      "<<<iteration:[500/878] - total_loss: 2.9104  obj_loss: 0.1070  noobj_loss: 0.0283  bbox_loss: 0.1374  cls_loss: 2.1020  \n",
      "<<<iteration:[520/878] - total_loss: 3.1507  obj_loss: 0.0794  noobj_loss: 0.0297  bbox_loss: 0.1368  cls_loss: 2.3727  \n",
      "<<<iteration:[540/878] - total_loss: 3.0736  obj_loss: 0.0928  noobj_loss: 0.0175  bbox_loss: 0.1254  cls_loss: 2.3452  \n",
      "<<<iteration:[560/878] - total_loss: 3.1777  obj_loss: 0.1125  noobj_loss: 0.0160  bbox_loss: 0.0995  cls_loss: 2.5599  \n",
      "<<<iteration:[580/878] - total_loss: 3.1316  obj_loss: 0.0950  noobj_loss: 0.0179  bbox_loss: 0.1112  cls_loss: 2.4716  \n",
      "<<<iteration:[600/878] - total_loss: 3.2049  obj_loss: 0.1167  noobj_loss: 0.0190  bbox_loss: 0.1247  cls_loss: 2.4553  \n",
      "<<<iteration:[620/878] - total_loss: 2.9215  obj_loss: 0.0983  noobj_loss: 0.0190  bbox_loss: 0.0859  cls_loss: 2.3843  \n",
      "<<<iteration:[640/878] - total_loss: 3.1976  obj_loss: 0.0816  noobj_loss: 0.0193  bbox_loss: 0.1406  cls_loss: 2.4031  \n",
      "<<<iteration:[660/878] - total_loss: 2.7156  obj_loss: 0.0717  noobj_loss: 0.0159  bbox_loss: 0.0939  cls_loss: 2.1665  \n",
      "<<<iteration:[680/878] - total_loss: 2.9219  obj_loss: 0.0793  noobj_loss: 0.0170  bbox_loss: 0.0921  cls_loss: 2.3737  \n",
      "<<<iteration:[700/878] - total_loss: 2.9560  obj_loss: 0.1076  noobj_loss: 0.0151  bbox_loss: 0.0906  cls_loss: 2.3878  \n",
      "<<<iteration:[720/878] - total_loss: 2.9412  obj_loss: 0.0909  noobj_loss: 0.0174  bbox_loss: 0.0981  cls_loss: 2.3513  \n",
      "<<<iteration:[740/878] - total_loss: 2.7678  obj_loss: 0.0849  noobj_loss: 0.0163  bbox_loss: 0.1019  cls_loss: 2.1651  \n",
      "<<<iteration:[760/878] - total_loss: 2.8291  obj_loss: 0.0920  noobj_loss: 0.0215  bbox_loss: 0.1026  cls_loss: 2.2135  \n",
      "<<<iteration:[780/878] - total_loss: 3.0864  obj_loss: 0.1013  noobj_loss: 0.0188  bbox_loss: 0.0994  cls_loss: 2.4790  \n",
      "<<<iteration:[800/878] - total_loss: 2.9831  obj_loss: 0.0929  noobj_loss: 0.0207  bbox_loss: 0.0925  cls_loss: 2.4174  \n",
      "<<<iteration:[820/878] - total_loss: 2.7806  obj_loss: 0.0683  noobj_loss: 0.0167  bbox_loss: 0.0908  cls_loss: 2.2498  \n",
      "<<<iteration:[840/878] - total_loss: 3.1127  obj_loss: 0.0764  noobj_loss: 0.0194  bbox_loss: 0.1126  cls_loss: 2.4636  \n",
      "<<<iteration:[860/878] - total_loss: 2.9845  obj_loss: 0.1049  noobj_loss: 0.0186  bbox_loss: 0.0979  cls_loss: 2.3810  \n",
      "\n",
      "epoch:24/100 - Train Loss: 3.0690, Val Loss: 2.9581\n",
      "\n",
      "<<<iteration:[20/878] - total_loss: 3.5255  obj_loss: 0.1067  noobj_loss: 0.0465  bbox_loss: 0.1865  cls_loss: 2.4632  \n",
      "<<<iteration:[40/878] - total_loss: 2.9443  obj_loss: 0.0916  noobj_loss: 0.0221  bbox_loss: 0.1028  cls_loss: 2.3275  \n",
      "<<<iteration:[60/878] - total_loss: 2.9231  obj_loss: 0.0782  noobj_loss: 0.0176  bbox_loss: 0.0877  cls_loss: 2.3975  \n",
      "<<<iteration:[80/878] - total_loss: 2.8830  obj_loss: 0.0933  noobj_loss: 0.0187  bbox_loss: 0.1242  cls_loss: 2.1592  \n",
      "<<<iteration:[100/878] - total_loss: 2.6503  obj_loss: 0.1057  noobj_loss: 0.0210  bbox_loss: 0.0968  cls_loss: 2.0500  \n",
      "<<<iteration:[120/878] - total_loss: 3.2037  obj_loss: 0.0795  noobj_loss: 0.0234  bbox_loss: 0.1288  cls_loss: 2.4686  \n",
      "<<<iteration:[140/878] - total_loss: 2.9314  obj_loss: 0.0661  noobj_loss: 0.0182  bbox_loss: 0.0974  cls_loss: 2.3690  \n",
      "<<<iteration:[160/878] - total_loss: 2.8909  obj_loss: 0.0926  noobj_loss: 0.0188  bbox_loss: 0.1064  cls_loss: 2.2570  \n",
      "<<<iteration:[180/878] - total_loss: 3.0849  obj_loss: 0.0697  noobj_loss: 0.0210  bbox_loss: 0.1134  cls_loss: 2.4375  \n",
      "<<<iteration:[200/878] - total_loss: 2.7722  obj_loss: 0.0826  noobj_loss: 0.0196  bbox_loss: 0.0986  cls_loss: 2.1870  \n",
      "<<<iteration:[220/878] - total_loss: 2.9642  obj_loss: 0.0729  noobj_loss: 0.0200  bbox_loss: 0.0906  cls_loss: 2.4283  \n",
      "<<<iteration:[240/878] - total_loss: 3.0095  obj_loss: 0.0776  noobj_loss: 0.0173  bbox_loss: 0.1173  cls_loss: 2.3366  \n",
      "<<<iteration:[260/878] - total_loss: 3.1199  obj_loss: 0.0818  noobj_loss: 0.0161  bbox_loss: 0.0975  cls_loss: 2.5423  \n",
      "<<<iteration:[280/878] - total_loss: 2.5200  obj_loss: 0.0863  noobj_loss: 0.0148  bbox_loss: 0.0731  cls_loss: 2.0611  \n",
      "<<<iteration:[300/878] - total_loss: 3.1884  obj_loss: 0.0958  noobj_loss: 0.0188  bbox_loss: 0.1091  cls_loss: 2.5377  \n",
      "<<<iteration:[320/878] - total_loss: 2.6214  obj_loss: 0.0963  noobj_loss: 0.0163  bbox_loss: 0.0751  cls_loss: 2.1415  \n",
      "<<<iteration:[340/878] - total_loss: 2.9024  obj_loss: 0.0830  noobj_loss: 0.0180  bbox_loss: 0.0925  cls_loss: 2.3477  \n",
      "<<<iteration:[360/878] - total_loss: 2.8450  obj_loss: 0.0917  noobj_loss: 0.0151  bbox_loss: 0.0920  cls_loss: 2.2856  \n",
      "<<<iteration:[380/878] - total_loss: 2.8388  obj_loss: 0.0821  noobj_loss: 0.0191  bbox_loss: 0.0831  cls_loss: 2.3317  \n",
      "<<<iteration:[400/878] - total_loss: 2.7620  obj_loss: 0.1017  noobj_loss: 0.0188  bbox_loss: 0.0672  cls_loss: 2.3149  \n",
      "<<<iteration:[420/878] - total_loss: 2.8763  obj_loss: 0.1015  noobj_loss: 0.0167  bbox_loss: 0.1259  cls_loss: 2.1370  \n",
      "<<<iteration:[440/878] - total_loss: 3.0728  obj_loss: 0.0930  noobj_loss: 0.0209  bbox_loss: 0.0994  cls_loss: 2.4723  \n",
      "<<<iteration:[460/878] - total_loss: 2.9915  obj_loss: 0.1021  noobj_loss: 0.0218  bbox_loss: 0.1016  cls_loss: 2.3706  \n",
      "<<<iteration:[480/878] - total_loss: 3.0334  obj_loss: 0.1031  noobj_loss: 0.0212  bbox_loss: 0.1083  cls_loss: 2.3781  \n",
      "<<<iteration:[500/878] - total_loss: 3.0141  obj_loss: 0.1063  noobj_loss: 0.0201  bbox_loss: 0.1015  cls_loss: 2.3905  \n",
      "<<<iteration:[520/878] - total_loss: 2.6848  obj_loss: 0.1048  noobj_loss: 0.0182  bbox_loss: 0.0824  cls_loss: 2.1590  \n",
      "<<<iteration:[540/878] - total_loss: 3.0842  obj_loss: 0.0880  noobj_loss: 0.0160  bbox_loss: 0.0873  cls_loss: 2.5518  \n",
      "<<<iteration:[560/878] - total_loss: 2.9441  obj_loss: 0.0849  noobj_loss: 0.0197  bbox_loss: 0.1188  cls_loss: 2.2556  \n",
      "<<<iteration:[580/878] - total_loss: 2.8273  obj_loss: 0.1012  noobj_loss: 0.0228  bbox_loss: 0.1038  cls_loss: 2.1957  \n",
      "<<<iteration:[600/878] - total_loss: 3.1005  obj_loss: 0.0929  noobj_loss: 0.0266  bbox_loss: 0.1257  cls_loss: 2.3657  \n",
      "<<<iteration:[620/878] - total_loss: 3.4340  obj_loss: 0.1034  noobj_loss: 0.0336  bbox_loss: 0.1436  cls_loss: 2.5961  \n",
      "<<<iteration:[640/878] - total_loss: 3.0360  obj_loss: 0.1017  noobj_loss: 0.0211  bbox_loss: 0.1292  cls_loss: 2.2779  \n",
      "<<<iteration:[660/878] - total_loss: 2.7456  obj_loss: 0.1053  noobj_loss: 0.0202  bbox_loss: 0.0817  cls_loss: 2.2219  \n",
      "<<<iteration:[680/878] - total_loss: 2.9251  obj_loss: 0.0894  noobj_loss: 0.0184  bbox_loss: 0.0928  cls_loss: 2.3624  \n",
      "<<<iteration:[700/878] - total_loss: 3.2862  obj_loss: 0.1156  noobj_loss: 0.0206  bbox_loss: 0.1143  cls_loss: 2.5889  \n",
      "<<<iteration:[720/878] - total_loss: 3.3703  obj_loss: 0.0913  noobj_loss: 0.0194  bbox_loss: 0.1130  cls_loss: 2.7042  \n",
      "<<<iteration:[740/878] - total_loss: 2.5567  obj_loss: 0.0825  noobj_loss: 0.0154  bbox_loss: 0.0825  cls_loss: 2.0541  \n",
      "<<<iteration:[760/878] - total_loss: 3.1710  obj_loss: 0.1118  noobj_loss: 0.0189  bbox_loss: 0.0976  cls_loss: 2.5619  \n",
      "<<<iteration:[780/878] - total_loss: 4.4960  obj_loss: 0.0944  noobj_loss: 0.0220  bbox_loss: 0.4134  cls_loss: 2.3236  \n",
      "<<<iteration:[800/878] - total_loss: 3.1152  obj_loss: 0.0977  noobj_loss: 0.0168  bbox_loss: 0.1376  cls_loss: 2.3211  \n",
      "<<<iteration:[820/878] - total_loss: 2.5742  obj_loss: 0.0923  noobj_loss: 0.0240  bbox_loss: 0.0916  cls_loss: 2.0119  \n",
      "<<<iteration:[840/878] - total_loss: 2.8881  obj_loss: 0.0970  noobj_loss: 0.0199  bbox_loss: 0.0844  cls_loss: 2.3593  \n",
      "<<<iteration:[860/878] - total_loss: 2.9999  obj_loss: 0.1028  noobj_loss: 0.0184  bbox_loss: 0.0988  cls_loss: 2.3940  \n",
      "\n",
      "epoch:25/100 - Train Loss: 2.9869, Val Loss: 2.9306\n",
      "\n",
      "<<<iteration:[20/878] - total_loss: 3.0774  obj_loss: 0.1113  noobj_loss: 0.0223  bbox_loss: 0.1405  cls_loss: 2.2527  \n",
      "<<<iteration:[40/878] - total_loss: 2.8452  obj_loss: 0.0956  noobj_loss: 0.0229  bbox_loss: 0.0895  cls_loss: 2.2904  \n",
      "<<<iteration:[60/878] - total_loss: 2.8323  obj_loss: 0.0955  noobj_loss: 0.0184  bbox_loss: 0.1084  cls_loss: 2.1858  \n",
      "<<<iteration:[80/878] - total_loss: 2.9525  obj_loss: 0.0943  noobj_loss: 0.0202  bbox_loss: 0.0865  cls_loss: 2.4158  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<<<iteration:[100/878] - total_loss: 2.7355  obj_loss: 0.0973  noobj_loss: 0.0210  bbox_loss: 0.0759  cls_loss: 2.2480  \n",
      "<<<iteration:[120/878] - total_loss: 2.8322  obj_loss: 0.1270  noobj_loss: 0.0274  bbox_loss: 0.1041  cls_loss: 2.1708  \n",
      "<<<iteration:[140/878] - total_loss: 2.8773  obj_loss: 0.0838  noobj_loss: 0.0198  bbox_loss: 0.0907  cls_loss: 2.3300  \n",
      "<<<iteration:[160/878] - total_loss: 2.7761  obj_loss: 0.1155  noobj_loss: 0.0182  bbox_loss: 0.0763  cls_loss: 2.2702  \n",
      "<<<iteration:[180/878] - total_loss: 2.9920  obj_loss: 0.0782  noobj_loss: 0.0197  bbox_loss: 0.1094  cls_loss: 2.3569  \n",
      "<<<iteration:[200/878] - total_loss: 2.4517  obj_loss: 0.0861  noobj_loss: 0.0183  bbox_loss: 0.0753  cls_loss: 1.9797  \n",
      "<<<iteration:[220/878] - total_loss: 3.1264  obj_loss: 0.0899  noobj_loss: 0.0189  bbox_loss: 0.1047  cls_loss: 2.5035  \n",
      "<<<iteration:[240/878] - total_loss: 2.8156  obj_loss: 0.0716  noobj_loss: 0.0360  bbox_loss: 0.1086  cls_loss: 2.1832  \n",
      "<<<iteration:[260/878] - total_loss: 2.8307  obj_loss: 0.0721  noobj_loss: 0.0185  bbox_loss: 0.1015  cls_loss: 2.2418  \n",
      "<<<iteration:[280/878] - total_loss: 2.8407  obj_loss: 0.1004  noobj_loss: 0.0206  bbox_loss: 0.1002  cls_loss: 2.2289  \n",
      "<<<iteration:[300/878] - total_loss: 2.9097  obj_loss: 0.0672  noobj_loss: 0.0152  bbox_loss: 0.1097  cls_loss: 2.2862  \n",
      "<<<iteration:[320/878] - total_loss: 3.1056  obj_loss: 0.0989  noobj_loss: 0.0171  bbox_loss: 0.1265  cls_loss: 2.3657  \n",
      "<<<iteration:[340/878] - total_loss: 3.0263  obj_loss: 0.1211  noobj_loss: 0.0237  bbox_loss: 0.1046  cls_loss: 2.3704  \n",
      "<<<iteration:[360/878] - total_loss: 3.1851  obj_loss: 0.1185  noobj_loss: 0.0489  bbox_loss: 0.1430  cls_loss: 2.3271  \n",
      "<<<iteration:[380/878] - total_loss: 3.2895  obj_loss: 0.1123  noobj_loss: 0.0211  bbox_loss: 0.1149  cls_loss: 2.5922  \n",
      "<<<iteration:[400/878] - total_loss: 3.5780  obj_loss: 0.0794  noobj_loss: 0.0262  bbox_loss: 0.1909  cls_loss: 2.5311  \n",
      "<<<iteration:[420/878] - total_loss: 2.9213  obj_loss: 0.0956  noobj_loss: 0.0227  bbox_loss: 0.1215  cls_loss: 2.2070  \n",
      "<<<iteration:[440/878] - total_loss: 3.1297  obj_loss: 0.1079  noobj_loss: 0.0195  bbox_loss: 0.0931  cls_loss: 2.5464  \n",
      "<<<iteration:[460/878] - total_loss: 3.0326  obj_loss: 0.0756  noobj_loss: 0.0189  bbox_loss: 0.0901  cls_loss: 2.4971  \n",
      "<<<iteration:[480/878] - total_loss: 2.9661  obj_loss: 0.1135  noobj_loss: 0.0189  bbox_loss: 0.1022  cls_loss: 2.3323  \n",
      "<<<iteration:[500/878] - total_loss: 2.9146  obj_loss: 0.1227  noobj_loss: 0.0196  bbox_loss: 0.0828  cls_loss: 2.3682  \n",
      "<<<iteration:[520/878] - total_loss: 2.8035  obj_loss: 0.1054  noobj_loss: 0.0212  bbox_loss: 0.0983  cls_loss: 2.1960  \n",
      "<<<iteration:[540/878] - total_loss: 2.8900  obj_loss: 0.1017  noobj_loss: 0.0301  bbox_loss: 0.1119  cls_loss: 2.2138  \n",
      "<<<iteration:[560/878] - total_loss: 2.5784  obj_loss: 0.0930  noobj_loss: 0.0206  bbox_loss: 0.0872  cls_loss: 2.0393  \n",
      "<<<iteration:[580/878] - total_loss: 3.0457  obj_loss: 0.1478  noobj_loss: 0.0431  bbox_loss: 0.1455  cls_loss: 2.1487  \n",
      "<<<iteration:[600/878] - total_loss: 3.3643  obj_loss: 0.1281  noobj_loss: 0.0306  bbox_loss: 0.1295  cls_loss: 2.5736  \n",
      "<<<iteration:[620/878] - total_loss: 2.8372  obj_loss: 0.0927  noobj_loss: 0.0175  bbox_loss: 0.0985  cls_loss: 2.2432  \n",
      "<<<iteration:[640/878] - total_loss: 2.8917  obj_loss: 0.0981  noobj_loss: 0.0181  bbox_loss: 0.0960  cls_loss: 2.3044  \n",
      "<<<iteration:[660/878] - total_loss: 2.8891  obj_loss: 0.0800  noobj_loss: 0.0197  bbox_loss: 0.0802  cls_loss: 2.3984  \n",
      "<<<iteration:[680/878] - total_loss: 2.8665  obj_loss: 0.1415  noobj_loss: 0.0218  bbox_loss: 0.0809  cls_loss: 2.3097  \n",
      "<<<iteration:[700/878] - total_loss: 3.0426  obj_loss: 0.1165  noobj_loss: 0.0252  bbox_loss: 0.0957  cls_loss: 2.4347  \n",
      "<<<iteration:[720/878] - total_loss: 3.0927  obj_loss: 0.0901  noobj_loss: 0.0265  bbox_loss: 0.0921  cls_loss: 2.5288  \n",
      "<<<iteration:[740/878] - total_loss: 3.0372  obj_loss: 0.0848  noobj_loss: 0.0153  bbox_loss: 0.0965  cls_loss: 2.4625  \n",
      "<<<iteration:[760/878] - total_loss: 2.9255  obj_loss: 0.0879  noobj_loss: 0.0170  bbox_loss: 0.0732  cls_loss: 2.4632  \n",
      "<<<iteration:[780/878] - total_loss: 2.8970  obj_loss: 0.1110  noobj_loss: 0.0201  bbox_loss: 0.1104  cls_loss: 2.2236  \n",
      "<<<iteration:[800/878] - total_loss: 2.7178  obj_loss: 0.1174  noobj_loss: 0.0187  bbox_loss: 0.0848  cls_loss: 2.1672  \n",
      "<<<iteration:[820/878] - total_loss: 2.7624  obj_loss: 0.0694  noobj_loss: 0.0176  bbox_loss: 0.0987  cls_loss: 2.1909  \n",
      "<<<iteration:[840/878] - total_loss: 3.2128  obj_loss: 0.0875  noobj_loss: 0.0175  bbox_loss: 0.1076  cls_loss: 2.5787  \n",
      "<<<iteration:[860/878] - total_loss: 2.6184  obj_loss: 0.1113  noobj_loss: 0.0175  bbox_loss: 0.0816  cls_loss: 2.0901  \n",
      "\n",
      "epoch:26/100 - Train Loss: 2.9480, Val Loss: 9.0093\n",
      "\n",
      "<<<iteration:[20/878] - total_loss: 3.2600  obj_loss: 0.0917  noobj_loss: 0.0224  bbox_loss: 0.1463  cls_loss: 2.4258  \n",
      "<<<iteration:[40/878] - total_loss: 3.4454  obj_loss: 0.0765  noobj_loss: 0.0187  bbox_loss: 0.1420  cls_loss: 2.6494  \n",
      "<<<iteration:[60/878] - total_loss: 3.3888  obj_loss: 0.0670  noobj_loss: 0.0149  bbox_loss: 0.1921  cls_loss: 2.3539  \n",
      "<<<iteration:[80/878] - total_loss: 3.0209  obj_loss: 0.0900  noobj_loss: 0.0181  bbox_loss: 0.1089  cls_loss: 2.3775  \n",
      "<<<iteration:[100/878] - total_loss: 2.9767  obj_loss: 0.0830  noobj_loss: 0.0162  bbox_loss: 0.0842  cls_loss: 2.4644  \n",
      "<<<iteration:[120/878] - total_loss: 2.6899  obj_loss: 0.1081  noobj_loss: 0.0158  bbox_loss: 0.0785  cls_loss: 2.1811  \n",
      "<<<iteration:[140/878] - total_loss: 2.8614  obj_loss: 0.0813  noobj_loss: 0.0193  bbox_loss: 0.0928  cls_loss: 2.3065  \n",
      "<<<iteration:[160/878] - total_loss: 3.2529  obj_loss: 0.1187  noobj_loss: 0.0202  bbox_loss: 0.1347  cls_loss: 2.4508  \n",
      "<<<iteration:[180/878] - total_loss: 2.8141  obj_loss: 0.1165  noobj_loss: 0.0196  bbox_loss: 0.0896  cls_loss: 2.2399  \n",
      "<<<iteration:[200/878] - total_loss: 2.9215  obj_loss: 0.1182  noobj_loss: 0.0237  bbox_loss: 0.1229  cls_loss: 2.1767  \n",
      "<<<iteration:[220/878] - total_loss: 2.8377  obj_loss: 0.0919  noobj_loss: 0.0193  bbox_loss: 0.0871  cls_loss: 2.3005  \n",
      "<<<iteration:[240/878] - total_loss: 2.8447  obj_loss: 0.0980  noobj_loss: 0.0208  bbox_loss: 0.0990  cls_loss: 2.2412  \n",
      "<<<iteration:[260/878] - total_loss: 2.7860  obj_loss: 0.0708  noobj_loss: 0.0166  bbox_loss: 0.0811  cls_loss: 2.3016  \n",
      "<<<iteration:[280/878] - total_loss: 2.6809  obj_loss: 0.1018  noobj_loss: 0.0195  bbox_loss: 0.0766  cls_loss: 2.1865  \n",
      "<<<iteration:[300/878] - total_loss: 3.0524  obj_loss: 0.0730  noobj_loss: 0.0185  bbox_loss: 0.1229  cls_loss: 2.3558  \n",
      "<<<iteration:[320/878] - total_loss: 2.7627  obj_loss: 0.0892  noobj_loss: 0.0225  bbox_loss: 0.0968  cls_loss: 2.1782  \n",
      "<<<iteration:[340/878] - total_loss: 2.8970  obj_loss: 0.0757  noobj_loss: 0.0188  bbox_loss: 0.0963  cls_loss: 2.3307  \n",
      "<<<iteration:[360/878] - total_loss: 2.8693  obj_loss: 0.0901  noobj_loss: 0.0163  bbox_loss: 0.0883  cls_loss: 2.3295  \n",
      "<<<iteration:[380/878] - total_loss: 2.7265  obj_loss: 0.1164  noobj_loss: 0.0213  bbox_loss: 0.0974  cls_loss: 2.1123  \n",
      "<<<iteration:[400/878] - total_loss: 3.0122  obj_loss: 0.0847  noobj_loss: 0.0182  bbox_loss: 0.0929  cls_loss: 2.4541  \n",
      "<<<iteration:[420/878] - total_loss: 2.7731  obj_loss: 0.0820  noobj_loss: 0.0290  bbox_loss: 0.1014  cls_loss: 2.1694  \n",
      "<<<iteration:[440/878] - total_loss: 2.8803  obj_loss: 0.0962  noobj_loss: 0.0165  bbox_loss: 0.0998  cls_loss: 2.2769  \n",
      "<<<iteration:[460/878] - total_loss: 2.9469  obj_loss: 0.1175  noobj_loss: 0.0240  bbox_loss: 0.0954  cls_loss: 2.3407  \n",
      "<<<iteration:[480/878] - total_loss: 3.1852  obj_loss: 0.1450  noobj_loss: 0.0266  bbox_loss: 0.0978  cls_loss: 2.5379  \n",
      "<<<iteration:[500/878] - total_loss: 3.0266  obj_loss: 0.1026  noobj_loss: 0.0235  bbox_loss: 0.1198  cls_loss: 2.3133  \n",
      "<<<iteration:[520/878] - total_loss: 2.8268  obj_loss: 0.0784  noobj_loss: 0.0161  bbox_loss: 0.0839  cls_loss: 2.3209  \n",
      "<<<iteration:[540/878] - total_loss: 2.8097  obj_loss: 0.0957  noobj_loss: 0.0178  bbox_loss: 0.0987  cls_loss: 2.2118  \n",
      "<<<iteration:[560/878] - total_loss: 2.9128  obj_loss: 0.1244  noobj_loss: 0.0208  bbox_loss: 0.0867  cls_loss: 2.3443  \n",
      "<<<iteration:[580/878] - total_loss: 3.2669  obj_loss: 0.0929  noobj_loss: 0.0199  bbox_loss: 0.1168  cls_loss: 2.5800  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<<<iteration:[600/878] - total_loss: 3.1342  obj_loss: 0.1313  noobj_loss: 0.0247  bbox_loss: 0.1884  cls_loss: 2.0486  \n",
      "<<<iteration:[620/878] - total_loss: 2.9875  obj_loss: 0.1117  noobj_loss: 0.0229  bbox_loss: 0.0942  cls_loss: 2.3932  \n",
      "<<<iteration:[640/878] - total_loss: 2.7521  obj_loss: 0.0729  noobj_loss: 0.0189  bbox_loss: 0.1162  cls_loss: 2.0887  \n",
      "<<<iteration:[660/878] - total_loss: 2.7363  obj_loss: 0.1095  noobj_loss: 0.0220  bbox_loss: 0.0719  cls_loss: 2.2561  \n",
      "<<<iteration:[680/878] - total_loss: 2.8862  obj_loss: 0.1171  noobj_loss: 0.0208  bbox_loss: 0.0860  cls_loss: 2.3289  \n",
      "<<<iteration:[700/878] - total_loss: 2.5816  obj_loss: 0.1051  noobj_loss: 0.0218  bbox_loss: 0.0931  cls_loss: 2.0003  \n",
      "<<<iteration:[720/878] - total_loss: 2.6704  obj_loss: 0.0909  noobj_loss: 0.0231  bbox_loss: 0.1036  cls_loss: 2.0501  \n",
      "<<<iteration:[740/878] - total_loss: 3.1035  obj_loss: 0.0914  noobj_loss: 0.0201  bbox_loss: 0.1124  cls_loss: 2.4399  \n",
      "<<<iteration:[760/878] - total_loss: 2.9952  obj_loss: 0.0986  noobj_loss: 0.0185  bbox_loss: 0.0807  cls_loss: 2.4836  \n",
      "<<<iteration:[780/878] - total_loss: 2.3678  obj_loss: 0.1083  noobj_loss: 0.0217  bbox_loss: 0.0746  cls_loss: 1.8755  \n",
      "<<<iteration:[800/878] - total_loss: 2.7991  obj_loss: 0.1083  noobj_loss: 0.0249  bbox_loss: 0.0954  cls_loss: 2.2012  \n",
      "<<<iteration:[820/878] - total_loss: 2.6248  obj_loss: 0.0730  noobj_loss: 0.0180  bbox_loss: 0.0892  cls_loss: 2.0970  \n",
      "<<<iteration:[840/878] - total_loss: 2.9988  obj_loss: 0.1240  noobj_loss: 0.0224  bbox_loss: 0.0917  cls_loss: 2.4053  \n",
      "<<<iteration:[860/878] - total_loss: 3.1646  obj_loss: 0.1007  noobj_loss: 0.0173  bbox_loss: 0.0811  cls_loss: 2.6500  \n",
      "\n",
      "epoch:27/100 - Train Loss: 2.9113, Val Loss: 3.0460\n",
      "\n",
      "<<<iteration:[20/878] - total_loss: 3.4676  obj_loss: 0.1076  noobj_loss: 0.0184  bbox_loss: 0.1574  cls_loss: 2.5638  \n",
      "<<<iteration:[40/878] - total_loss: 2.5632  obj_loss: 0.1066  noobj_loss: 0.0212  bbox_loss: 0.0777  cls_loss: 2.0573  \n",
      "<<<iteration:[60/878] - total_loss: 3.0097  obj_loss: 0.0979  noobj_loss: 0.0237  bbox_loss: 0.1378  cls_loss: 2.2109  \n",
      "<<<iteration:[80/878] - total_loss: 2.7532  obj_loss: 0.0822  noobj_loss: 0.0171  bbox_loss: 0.0853  cls_loss: 2.2361  \n",
      "<<<iteration:[100/878] - total_loss: 2.9091  obj_loss: 0.0850  noobj_loss: 0.0256  bbox_loss: 0.0976  cls_loss: 2.3235  \n",
      "<<<iteration:[120/878] - total_loss: 2.8778  obj_loss: 0.0898  noobj_loss: 0.0188  bbox_loss: 0.0930  cls_loss: 2.3138  \n",
      "<<<iteration:[140/878] - total_loss: 2.8357  obj_loss: 0.0920  noobj_loss: 0.0166  bbox_loss: 0.0808  cls_loss: 2.3317  \n",
      "<<<iteration:[160/878] - total_loss: 2.4769  obj_loss: 0.1140  noobj_loss: 0.0213  bbox_loss: 0.0777  cls_loss: 1.9638  \n",
      "<<<iteration:[180/878] - total_loss: 2.9273  obj_loss: 0.0940  noobj_loss: 0.0215  bbox_loss: 0.1086  cls_loss: 2.2797  \n",
      "<<<iteration:[200/878] - total_loss: 2.6763  obj_loss: 0.1011  noobj_loss: 0.0212  bbox_loss: 0.1191  cls_loss: 1.9689  \n",
      "<<<iteration:[220/878] - total_loss: 2.8903  obj_loss: 0.0864  noobj_loss: 0.0175  bbox_loss: 0.0864  cls_loss: 2.3631  \n",
      "<<<iteration:[240/878] - total_loss: 2.8648  obj_loss: 0.0993  noobj_loss: 0.0182  bbox_loss: 0.0971  cls_loss: 2.2709  \n",
      "<<<iteration:[260/878] - total_loss: 2.9012  obj_loss: 0.1281  noobj_loss: 0.0256  bbox_loss: 0.0964  cls_loss: 2.2785  \n",
      "<<<iteration:[280/878] - total_loss: 2.9024  obj_loss: 0.0989  noobj_loss: 0.0204  bbox_loss: 0.0858  cls_loss: 2.3644  \n",
      "<<<iteration:[300/878] - total_loss: 2.6787  obj_loss: 0.0809  noobj_loss: 0.0200  bbox_loss: 0.0918  cls_loss: 2.1287  \n",
      "<<<iteration:[320/878] - total_loss: 3.0841  obj_loss: 0.1157  noobj_loss: 0.0198  bbox_loss: 0.1137  cls_loss: 2.3902  \n",
      "<<<iteration:[340/878] - total_loss: 3.2107  obj_loss: 0.0969  noobj_loss: 0.0190  bbox_loss: 0.1084  cls_loss: 2.5622  \n",
      "<<<iteration:[360/878] - total_loss: 2.7360  obj_loss: 0.1023  noobj_loss: 0.0171  bbox_loss: 0.0834  cls_loss: 2.2082  \n",
      "<<<iteration:[380/878] - total_loss: 2.8013  obj_loss: 0.1121  noobj_loss: 0.0225  bbox_loss: 0.0924  cls_loss: 2.2162  \n",
      "<<<iteration:[400/878] - total_loss: 2.8160  obj_loss: 0.0846  noobj_loss: 0.0191  bbox_loss: 0.0832  cls_loss: 2.3059  \n",
      "<<<iteration:[420/878] - total_loss: 3.7388  obj_loss: 0.0982  noobj_loss: 0.0191  bbox_loss: 0.1901  cls_loss: 2.6804  \n",
      "<<<iteration:[440/878] - total_loss: 2.9595  obj_loss: 0.0839  noobj_loss: 0.0189  bbox_loss: 0.1291  cls_loss: 2.2206  \n",
      "<<<iteration:[460/878] - total_loss: 3.3024  obj_loss: 0.1155  noobj_loss: 0.0241  bbox_loss: 0.1330  cls_loss: 2.5100  \n",
      "<<<iteration:[480/878] - total_loss: 2.8654  obj_loss: 0.0880  noobj_loss: 0.0167  bbox_loss: 0.1267  cls_loss: 2.1357  \n",
      "<<<iteration:[500/878] - total_loss: 2.7694  obj_loss: 0.0935  noobj_loss: 0.0168  bbox_loss: 0.0899  cls_loss: 2.2179  \n",
      "<<<iteration:[520/878] - total_loss: 2.8151  obj_loss: 0.1008  noobj_loss: 0.0196  bbox_loss: 0.0839  cls_loss: 2.2850  \n",
      "<<<iteration:[540/878] - total_loss: 3.2125  obj_loss: 0.1119  noobj_loss: 0.0215  bbox_loss: 0.1136  cls_loss: 2.5220  \n",
      "<<<iteration:[560/878] - total_loss: 2.7555  obj_loss: 0.0803  noobj_loss: 0.0189  bbox_loss: 0.0692  cls_loss: 2.3195  \n",
      "<<<iteration:[580/878] - total_loss: 2.6826  obj_loss: 0.0958  noobj_loss: 0.0247  bbox_loss: 0.0881  cls_loss: 2.1339  \n",
      "<<<iteration:[600/878] - total_loss: 2.8077  obj_loss: 0.0906  noobj_loss: 0.0180  bbox_loss: 0.0884  cls_loss: 2.2661  \n",
      "<<<iteration:[620/878] - total_loss: 2.6394  obj_loss: 0.1002  noobj_loss: 0.0187  bbox_loss: 0.0794  cls_loss: 2.1330  \n",
      "<<<iteration:[640/878] - total_loss: 2.6566  obj_loss: 0.1118  noobj_loss: 0.0217  bbox_loss: 0.0883  cls_loss: 2.0925  \n",
      "<<<iteration:[660/878] - total_loss: 2.6747  obj_loss: 0.1050  noobj_loss: 0.0192  bbox_loss: 0.0725  cls_loss: 2.1979  \n",
      "<<<iteration:[680/878] - total_loss: 2.5519  obj_loss: 0.0915  noobj_loss: 0.0194  bbox_loss: 0.0753  cls_loss: 2.0742  \n",
      "<<<iteration:[700/878] - total_loss: 2.7170  obj_loss: 0.1023  noobj_loss: 0.0189  bbox_loss: 0.0967  cls_loss: 2.1218  \n",
      "<<<iteration:[720/878] - total_loss: 2.8563  obj_loss: 0.0967  noobj_loss: 0.0211  bbox_loss: 0.1017  cls_loss: 2.2404  \n",
      "<<<iteration:[740/878] - total_loss: 2.9892  obj_loss: 0.0987  noobj_loss: 0.0219  bbox_loss: 0.0962  cls_loss: 2.3985  \n",
      "<<<iteration:[760/878] - total_loss: 2.7116  obj_loss: 0.0775  noobj_loss: 0.0170  bbox_loss: 0.0829  cls_loss: 2.2109  \n",
      "<<<iteration:[780/878] - total_loss: 2.9147  obj_loss: 0.0863  noobj_loss: 0.0171  bbox_loss: 0.0830  cls_loss: 2.4050  \n",
      "<<<iteration:[800/878] - total_loss: 2.9708  obj_loss: 0.1230  noobj_loss: 0.0269  bbox_loss: 0.1101  cls_loss: 2.2838  \n",
      "<<<iteration:[820/878] - total_loss: 2.6440  obj_loss: 0.1051  noobj_loss: 0.0227  bbox_loss: 0.1023  cls_loss: 2.0159  \n",
      "<<<iteration:[840/878] - total_loss: 2.8936  obj_loss: 0.0765  noobj_loss: 0.0245  bbox_loss: 0.0942  cls_loss: 2.3337  \n",
      "<<<iteration:[860/878] - total_loss: 2.6718  obj_loss: 0.0857  noobj_loss: 0.0203  bbox_loss: 0.0981  cls_loss: 2.0855  \n",
      "\n",
      "epoch:28/100 - Train Loss: 2.8727, Val Loss: 5.1408\n",
      "\n",
      "<<<iteration:[20/878] - total_loss: 3.3325  obj_loss: 0.1288  noobj_loss: 0.0238  bbox_loss: 0.2198  cls_loss: 2.0928  \n",
      "<<<iteration:[40/878] - total_loss: 3.1002  obj_loss: 0.1185  noobj_loss: 0.0220  bbox_loss: 0.0959  cls_loss: 2.4914  \n",
      "<<<iteration:[60/878] - total_loss: 2.7086  obj_loss: 0.1223  noobj_loss: 0.0243  bbox_loss: 0.0868  cls_loss: 2.1403  \n",
      "<<<iteration:[80/878] - total_loss: 2.3705  obj_loss: 0.0789  noobj_loss: 0.0181  bbox_loss: 0.0723  cls_loss: 1.9209  \n",
      "<<<iteration:[100/878] - total_loss: 2.6059  obj_loss: 0.0862  noobj_loss: 0.0165  bbox_loss: 0.0889  cls_loss: 2.0670  \n",
      "<<<iteration:[120/878] - total_loss: 2.9323  obj_loss: 0.1053  noobj_loss: 0.0181  bbox_loss: 0.0841  cls_loss: 2.3975  \n",
      "<<<iteration:[140/878] - total_loss: 2.5540  obj_loss: 0.0945  noobj_loss: 0.0207  bbox_loss: 0.0787  cls_loss: 2.0558  \n",
      "<<<iteration:[160/878] - total_loss: 2.8248  obj_loss: 0.0970  noobj_loss: 0.0205  bbox_loss: 0.0918  cls_loss: 2.2584  \n",
      "<<<iteration:[180/878] - total_loss: 2.4192  obj_loss: 0.1365  noobj_loss: 0.0192  bbox_loss: 0.0688  cls_loss: 1.9292  \n",
      "<<<iteration:[200/878] - total_loss: 2.7728  obj_loss: 0.0936  noobj_loss: 0.0219  bbox_loss: 0.0895  cls_loss: 2.2208  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<<<iteration:[220/878] - total_loss: 2.6764  obj_loss: 0.0957  noobj_loss: 0.0197  bbox_loss: 0.0878  cls_loss: 2.1320  \n",
      "<<<iteration:[240/878] - total_loss: 3.2945  obj_loss: 0.0824  noobj_loss: 0.0188  bbox_loss: 0.2002  cls_loss: 2.2016  \n",
      "<<<iteration:[260/878] - total_loss: 3.3792  obj_loss: 0.0790  noobj_loss: 0.0172  bbox_loss: 0.1957  cls_loss: 2.3129  \n",
      "<<<iteration:[280/878] - total_loss: 3.0595  obj_loss: 0.1058  noobj_loss: 0.0225  bbox_loss: 0.1084  cls_loss: 2.4002  \n",
      "<<<iteration:[300/878] - total_loss: 3.0999  obj_loss: 0.0998  noobj_loss: 0.0196  bbox_loss: 0.0926  cls_loss: 2.5275  \n",
      "<<<iteration:[320/878] - total_loss: 3.0052  obj_loss: 0.1039  noobj_loss: 0.0243  bbox_loss: 0.0967  cls_loss: 2.4059  \n",
      "<<<iteration:[340/878] - total_loss: 2.8673  obj_loss: 0.0953  noobj_loss: 0.0184  bbox_loss: 0.1009  cls_loss: 2.2583  \n",
      "<<<iteration:[360/878] - total_loss: 2.9035  obj_loss: 0.0855  noobj_loss: 0.0180  bbox_loss: 0.0949  cls_loss: 2.3345  \n",
      "<<<iteration:[380/878] - total_loss: 3.2481  obj_loss: 0.0958  noobj_loss: 0.0206  bbox_loss: 0.1196  cls_loss: 2.5441  \n",
      "<<<iteration:[400/878] - total_loss: 2.9683  obj_loss: 0.0978  noobj_loss: 0.0205  bbox_loss: 0.0998  cls_loss: 2.3613  \n",
      "<<<iteration:[420/878] - total_loss: 2.8261  obj_loss: 0.0884  noobj_loss: 0.0191  bbox_loss: 0.0871  cls_loss: 2.2926  \n",
      "<<<iteration:[440/878] - total_loss: 3.1010  obj_loss: 0.0839  noobj_loss: 0.0198  bbox_loss: 0.1141  cls_loss: 2.4370  \n",
      "<<<iteration:[460/878] - total_loss: 2.7900  obj_loss: 0.0876  noobj_loss: 0.0275  bbox_loss: 0.1020  cls_loss: 2.1789  \n",
      "<<<iteration:[480/878] - total_loss: 2.6903  obj_loss: 0.0860  noobj_loss: 0.0199  bbox_loss: 0.0893  cls_loss: 2.1477  \n",
      "<<<iteration:[500/878] - total_loss: 2.7114  obj_loss: 0.0824  noobj_loss: 0.0327  bbox_loss: 0.0854  cls_loss: 2.1858  \n",
      "<<<iteration:[520/878] - total_loss: 2.8830  obj_loss: 0.1046  noobj_loss: 0.0354  bbox_loss: 0.1130  cls_loss: 2.1957  \n",
      "<<<iteration:[540/878] - total_loss: 3.2759  obj_loss: 0.0909  noobj_loss: 0.0188  bbox_loss: 0.1226  cls_loss: 2.5624  \n",
      "<<<iteration:[560/878] - total_loss: 3.0007  obj_loss: 0.1161  noobj_loss: 0.0177  bbox_loss: 0.0978  cls_loss: 2.3865  \n",
      "<<<iteration:[580/878] - total_loss: 2.9282  obj_loss: 0.1266  noobj_loss: 0.0242  bbox_loss: 0.0972  cls_loss: 2.3035  \n",
      "<<<iteration:[600/878] - total_loss: 2.8202  obj_loss: 0.1303  noobj_loss: 0.0239  bbox_loss: 0.0962  cls_loss: 2.1971  \n",
      "<<<iteration:[620/878] - total_loss: 2.7431  obj_loss: 0.1053  noobj_loss: 0.0224  bbox_loss: 0.0964  cls_loss: 2.1446  \n",
      "<<<iteration:[640/878] - total_loss: 2.5890  obj_loss: 0.0677  noobj_loss: 0.0192  bbox_loss: 0.0813  cls_loss: 2.1053  \n",
      "<<<iteration:[660/878] - total_loss: 2.8189  obj_loss: 0.0895  noobj_loss: 0.0208  bbox_loss: 0.0980  cls_loss: 2.2290  \n",
      "<<<iteration:[680/878] - total_loss: 2.7836  obj_loss: 0.0715  noobj_loss: 0.0201  bbox_loss: 0.1080  cls_loss: 2.1618  \n",
      "<<<iteration:[700/878] - total_loss: 3.1282  obj_loss: 0.1125  noobj_loss: 0.0297  bbox_loss: 0.1099  cls_loss: 2.4513  \n",
      "<<<iteration:[720/878] - total_loss: 2.8381  obj_loss: 0.0956  noobj_loss: 0.0196  bbox_loss: 0.0885  cls_loss: 2.2900  \n",
      "<<<iteration:[740/878] - total_loss: 2.9573  obj_loss: 0.0927  noobj_loss: 0.0187  bbox_loss: 0.0875  cls_loss: 2.4176  \n",
      "<<<iteration:[760/878] - total_loss: 2.7553  obj_loss: 0.0895  noobj_loss: 0.0188  bbox_loss: 0.0963  cls_loss: 2.1750  \n",
      "<<<iteration:[780/878] - total_loss: 2.9151  obj_loss: 0.0980  noobj_loss: 0.0222  bbox_loss: 0.1210  cls_loss: 2.2013  \n",
      "<<<iteration:[800/878] - total_loss: 3.1754  obj_loss: 0.0948  noobj_loss: 0.0187  bbox_loss: 0.1312  cls_loss: 2.4151  \n",
      "<<<iteration:[820/878] - total_loss: 2.6741  obj_loss: 0.0942  noobj_loss: 0.0184  bbox_loss: 0.0845  cls_loss: 2.1481  \n",
      "<<<iteration:[840/878] - total_loss: 2.9642  obj_loss: 0.0950  noobj_loss: 0.0200  bbox_loss: 0.1140  cls_loss: 2.2894  \n",
      "<<<iteration:[860/878] - total_loss: 2.7207  obj_loss: 0.1008  noobj_loss: 0.0158  bbox_loss: 0.1120  cls_loss: 2.0520  \n",
      "\n",
      "epoch:29/100 - Train Loss: 2.8941, Val Loss: 3.0045\n",
      "\n",
      "<<<iteration:[20/878] - total_loss: 2.8154  obj_loss: 0.0843  noobj_loss: 0.0212  bbox_loss: 0.0792  cls_loss: 2.3247  \n",
      "<<<iteration:[40/878] - total_loss: 2.6382  obj_loss: 0.1000  noobj_loss: 0.0175  bbox_loss: 0.0731  cls_loss: 2.1638  \n",
      "<<<iteration:[60/878] - total_loss: 2.7283  obj_loss: 0.0933  noobj_loss: 0.0220  bbox_loss: 0.0871  cls_loss: 2.1888  \n",
      "<<<iteration:[80/878] - total_loss: 2.9329  obj_loss: 0.1204  noobj_loss: 0.0289  bbox_loss: 0.1043  cls_loss: 2.2766  \n",
      "<<<iteration:[100/878] - total_loss: 2.8217  obj_loss: 0.0963  noobj_loss: 0.0233  bbox_loss: 0.0871  cls_loss: 2.2784  \n",
      "<<<iteration:[120/878] - total_loss: 3.0124  obj_loss: 0.1077  noobj_loss: 0.0240  bbox_loss: 0.0996  cls_loss: 2.3946  \n",
      "<<<iteration:[140/878] - total_loss: 2.7057  obj_loss: 0.0802  noobj_loss: 0.0193  bbox_loss: 0.0883  cls_loss: 2.1747  \n",
      "<<<iteration:[160/878] - total_loss: 2.6241  obj_loss: 0.1063  noobj_loss: 0.0215  bbox_loss: 0.0988  cls_loss: 2.0133  \n",
      "<<<iteration:[180/878] - total_loss: 2.9227  obj_loss: 0.1058  noobj_loss: 0.0269  bbox_loss: 0.0961  cls_loss: 2.3230  \n",
      "<<<iteration:[200/878] - total_loss: 2.7919  obj_loss: 0.1091  noobj_loss: 0.0206  bbox_loss: 0.0754  cls_loss: 2.2955  \n",
      "<<<iteration:[220/878] - total_loss: 3.1552  obj_loss: 0.0961  noobj_loss: 0.0182  bbox_loss: 0.1285  cls_loss: 2.4077  \n",
      "<<<iteration:[240/878] - total_loss: 2.8005  obj_loss: 0.0867  noobj_loss: 0.0189  bbox_loss: 0.0856  cls_loss: 2.2762  \n",
      "<<<iteration:[260/878] - total_loss: 2.8781  obj_loss: 0.0731  noobj_loss: 0.0206  bbox_loss: 0.0969  cls_loss: 2.3103  \n",
      "<<<iteration:[280/878] - total_loss: 2.6956  obj_loss: 0.0890  noobj_loss: 0.0186  bbox_loss: 0.0851  cls_loss: 2.1719  \n",
      "<<<iteration:[300/878] - total_loss: 2.7232  obj_loss: 0.0995  noobj_loss: 0.0194  bbox_loss: 0.0839  cls_loss: 2.1944  \n",
      "<<<iteration:[320/878] - total_loss: 2.5749  obj_loss: 0.0897  noobj_loss: 0.0230  bbox_loss: 0.0802  cls_loss: 2.0726  \n",
      "<<<iteration:[340/878] - total_loss: 2.7088  obj_loss: 0.1190  noobj_loss: 0.0213  bbox_loss: 0.0918  cls_loss: 2.1202  \n",
      "<<<iteration:[360/878] - total_loss: 2.6713  obj_loss: 0.0840  noobj_loss: 0.0224  bbox_loss: 0.0833  cls_loss: 2.1593  \n",
      "<<<iteration:[380/878] - total_loss: 2.8879  obj_loss: 0.1288  noobj_loss: 0.0220  bbox_loss: 0.0884  cls_loss: 2.3060  \n",
      "<<<iteration:[400/878] - total_loss: 2.7595  obj_loss: 0.0918  noobj_loss: 0.0287  bbox_loss: 0.0798  cls_loss: 2.2544  \n",
      "<<<iteration:[420/878] - total_loss: 3.0492  obj_loss: 0.1071  noobj_loss: 0.0269  bbox_loss: 0.1039  cls_loss: 2.4092  \n",
      "<<<iteration:[440/878] - total_loss: 2.8651  obj_loss: 0.1095  noobj_loss: 0.0228  bbox_loss: 0.1025  cls_loss: 2.2317  \n",
      "<<<iteration:[460/878] - total_loss: 2.5542  obj_loss: 0.0767  noobj_loss: 0.0226  bbox_loss: 0.0915  cls_loss: 2.0088  \n",
      "<<<iteration:[480/878] - total_loss: 2.8007  obj_loss: 0.0726  noobj_loss: 0.0177  bbox_loss: 0.1011  cls_loss: 2.2139  \n",
      "<<<iteration:[500/878] - total_loss: 2.8799  obj_loss: 0.1101  noobj_loss: 0.0187  bbox_loss: 0.0996  cls_loss: 2.2624  \n",
      "<<<iteration:[520/878] - total_loss: 2.6987  obj_loss: 0.1109  noobj_loss: 0.0221  bbox_loss: 0.0940  cls_loss: 2.1066  \n",
      "<<<iteration:[540/878] - total_loss: 2.6513  obj_loss: 0.1004  noobj_loss: 0.0203  bbox_loss: 0.0699  cls_loss: 2.1913  \n",
      "<<<iteration:[560/878] - total_loss: 2.8334  obj_loss: 0.0732  noobj_loss: 0.0171  bbox_loss: 0.1044  cls_loss: 2.2296  \n",
      "<<<iteration:[580/878] - total_loss: 2.9025  obj_loss: 0.0921  noobj_loss: 0.0202  bbox_loss: 0.0883  cls_loss: 2.3591  \n",
      "<<<iteration:[600/878] - total_loss: 2.5107  obj_loss: 0.0818  noobj_loss: 0.0164  bbox_loss: 0.0716  cls_loss: 2.0626  \n",
      "<<<iteration:[620/878] - total_loss: 2.7749  obj_loss: 0.0943  noobj_loss: 0.0195  bbox_loss: 0.0942  cls_loss: 2.2001  \n",
      "<<<iteration:[640/878] - total_loss: 2.8017  obj_loss: 0.0934  noobj_loss: 0.0182  bbox_loss: 0.1000  cls_loss: 2.1990  \n",
      "<<<iteration:[660/878] - total_loss: 2.8855  obj_loss: 0.1054  noobj_loss: 0.0254  bbox_loss: 0.1227  cls_loss: 2.1538  \n",
      "<<<iteration:[680/878] - total_loss: 2.7644  obj_loss: 0.0908  noobj_loss: 0.0191  bbox_loss: 0.1148  cls_loss: 2.0902  \n",
      "<<<iteration:[700/878] - total_loss: 2.9183  obj_loss: 0.1063  noobj_loss: 0.0197  bbox_loss: 0.1027  cls_loss: 2.2886  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<<<iteration:[720/878] - total_loss: 3.0020  obj_loss: 0.1205  noobj_loss: 0.0212  bbox_loss: 0.0930  cls_loss: 2.4058  \n",
      "<<<iteration:[740/878] - total_loss: 2.8060  obj_loss: 0.1111  noobj_loss: 0.0206  bbox_loss: 0.0988  cls_loss: 2.1907  \n",
      "<<<iteration:[760/878] - total_loss: 2.8944  obj_loss: 0.1086  noobj_loss: 0.0220  bbox_loss: 0.0976  cls_loss: 2.2868  \n",
      "<<<iteration:[780/878] - total_loss: 3.3783  obj_loss: 0.0967  noobj_loss: 0.0198  bbox_loss: 0.1581  cls_loss: 2.4811  \n",
      "<<<iteration:[800/878] - total_loss: 2.5942  obj_loss: 0.0968  noobj_loss: 0.0190  bbox_loss: 0.0791  cls_loss: 2.0924  \n",
      "<<<iteration:[820/878] - total_loss: 3.1344  obj_loss: 0.0916  noobj_loss: 0.0196  bbox_loss: 0.0937  cls_loss: 2.5646  \n",
      "<<<iteration:[840/878] - total_loss: 3.1307  obj_loss: 0.0985  noobj_loss: 0.0217  bbox_loss: 0.1113  cls_loss: 2.4646  \n",
      "<<<iteration:[860/878] - total_loss: 2.9654  obj_loss: 0.1264  noobj_loss: 0.0357  bbox_loss: 0.0962  cls_loss: 2.3403  \n",
      "\n",
      "epoch:30/100 - Train Loss: 2.8260, Val Loss: 3.0078\n",
      "\n",
      "<<<iteration:[20/878] - total_loss: 3.1658  obj_loss: 0.1079  noobj_loss: 0.0220  bbox_loss: 0.0977  cls_loss: 2.5586  \n",
      "<<<iteration:[40/878] - total_loss: 2.9357  obj_loss: 0.1301  noobj_loss: 0.0193  bbox_loss: 0.0804  cls_loss: 2.3942  \n",
      "<<<iteration:[60/878] - total_loss: 2.6370  obj_loss: 0.1156  noobj_loss: 0.0260  bbox_loss: 0.0843  cls_loss: 2.0870  \n",
      "<<<iteration:[80/878] - total_loss: 3.0399  obj_loss: 0.0798  noobj_loss: 0.0199  bbox_loss: 0.1027  cls_loss: 2.4368  \n",
      "<<<iteration:[100/878] - total_loss: 2.7481  obj_loss: 0.0832  noobj_loss: 0.0170  bbox_loss: 0.0919  cls_loss: 2.1968  \n",
      "<<<iteration:[120/878] - total_loss: 2.7785  obj_loss: 0.0941  noobj_loss: 0.0187  bbox_loss: 0.0776  cls_loss: 2.2871  \n",
      "<<<iteration:[140/878] - total_loss: 2.7001  obj_loss: 0.0920  noobj_loss: 0.0214  bbox_loss: 0.0917  cls_loss: 2.1387  \n",
      "<<<iteration:[160/878] - total_loss: 3.2059  obj_loss: 0.0808  noobj_loss: 0.0371  bbox_loss: 0.2170  cls_loss: 2.0217  \n",
      "<<<iteration:[180/878] - total_loss: 2.4486  obj_loss: 0.1116  noobj_loss: 0.0228  bbox_loss: 0.0893  cls_loss: 1.8793  \n",
      "<<<iteration:[200/878] - total_loss: 2.6426  obj_loss: 0.0801  noobj_loss: 0.0212  bbox_loss: 0.1008  cls_loss: 2.0480  \n",
      "<<<iteration:[220/878] - total_loss: 2.8370  obj_loss: 0.0955  noobj_loss: 0.0201  bbox_loss: 0.1106  cls_loss: 2.1782  \n",
      "<<<iteration:[240/878] - total_loss: 2.7105  obj_loss: 0.0851  noobj_loss: 0.0192  bbox_loss: 0.0952  cls_loss: 2.1397  \n",
      "<<<iteration:[260/878] - total_loss: 2.6728  obj_loss: 0.0849  noobj_loss: 0.0203  bbox_loss: 0.0865  cls_loss: 2.1450  \n",
      "<<<iteration:[280/878] - total_loss: 2.9767  obj_loss: 0.1237  noobj_loss: 0.0182  bbox_loss: 0.0863  cls_loss: 2.4122  \n",
      "<<<iteration:[300/878] - total_loss: 2.6425  obj_loss: 0.1195  noobj_loss: 0.0239  bbox_loss: 0.0819  cls_loss: 2.1013  \n",
      "<<<iteration:[320/878] - total_loss: 2.6339  obj_loss: 0.0777  noobj_loss: 0.0197  bbox_loss: 0.0794  cls_loss: 2.1492  \n",
      "<<<iteration:[340/878] - total_loss: 3.0042  obj_loss: 0.1307  noobj_loss: 0.0246  bbox_loss: 0.0967  cls_loss: 2.3776  \n",
      "<<<iteration:[360/878] - total_loss: 2.7800  obj_loss: 0.0989  noobj_loss: 0.0204  bbox_loss: 0.0934  cls_loss: 2.2039  \n",
      "<<<iteration:[380/878] - total_loss: 2.8540  obj_loss: 0.1016  noobj_loss: 0.0253  bbox_loss: 0.1061  cls_loss: 2.2093  \n",
      "<<<iteration:[400/878] - total_loss: 2.7681  obj_loss: 0.1137  noobj_loss: 0.0205  bbox_loss: 0.0783  cls_loss: 2.2529  \n",
      "<<<iteration:[420/878] - total_loss: 2.9951  obj_loss: 0.1304  noobj_loss: 0.0199  bbox_loss: 0.1039  cls_loss: 2.3353  \n",
      "<<<iteration:[440/878] - total_loss: 2.7546  obj_loss: 0.0930  noobj_loss: 0.0205  bbox_loss: 0.0885  cls_loss: 2.2088  \n",
      "<<<iteration:[460/878] - total_loss: 3.2368  obj_loss: 0.1161  noobj_loss: 0.0301  bbox_loss: 0.1683  cls_loss: 2.2641  \n",
      "<<<iteration:[480/878] - total_loss: 2.4530  obj_loss: 0.0970  noobj_loss: 0.0228  bbox_loss: 0.1081  cls_loss: 1.8039  \n",
      "<<<iteration:[500/878] - total_loss: 3.1326  obj_loss: 0.1179  noobj_loss: 0.0214  bbox_loss: 0.1201  cls_loss: 2.4035  \n",
      "<<<iteration:[520/878] - total_loss: 3.0226  obj_loss: 0.1154  noobj_loss: 0.0357  bbox_loss: 0.1060  cls_loss: 2.3596  \n",
      "<<<iteration:[540/878] - total_loss: 3.4686  obj_loss: 0.1259  noobj_loss: 0.0208  bbox_loss: 0.1235  cls_loss: 2.7150  \n",
      "<<<iteration:[560/878] - total_loss: 2.6395  obj_loss: 0.0762  noobj_loss: 0.0206  bbox_loss: 0.0856  cls_loss: 2.1249  \n",
      "<<<iteration:[580/878] - total_loss: 2.6911  obj_loss: 0.0815  noobj_loss: 0.0206  bbox_loss: 0.0991  cls_loss: 2.1039  \n",
      "<<<iteration:[600/878] - total_loss: 2.7892  obj_loss: 0.0989  noobj_loss: 0.0195  bbox_loss: 0.0970  cls_loss: 2.1954  \n",
      "<<<iteration:[620/878] - total_loss: 2.7442  obj_loss: 0.0833  noobj_loss: 0.0197  bbox_loss: 0.0943  cls_loss: 2.1796  \n",
      "<<<iteration:[640/878] - total_loss: 3.1453  obj_loss: 0.1406  noobj_loss: 0.0243  bbox_loss: 0.1124  cls_loss: 2.4306  \n",
      "<<<iteration:[660/878] - total_loss: 3.0173  obj_loss: 0.1164  noobj_loss: 0.0250  bbox_loss: 0.1113  cls_loss: 2.3317  \n",
      "<<<iteration:[680/878] - total_loss: 3.1545  obj_loss: 0.1017  noobj_loss: 0.0302  bbox_loss: 0.1104  cls_loss: 2.4859  \n",
      "<<<iteration:[700/878] - total_loss: 2.4134  obj_loss: 0.1138  noobj_loss: 0.0215  bbox_loss: 0.0747  cls_loss: 1.9155  \n",
      "<<<iteration:[720/878] - total_loss: 2.5953  obj_loss: 0.1135  noobj_loss: 0.0186  bbox_loss: 0.0810  cls_loss: 2.0675  \n",
      "<<<iteration:[740/878] - total_loss: 2.4365  obj_loss: 0.1009  noobj_loss: 0.0202  bbox_loss: 0.0784  cls_loss: 1.9335  \n",
      "<<<iteration:[760/878] - total_loss: 2.9390  obj_loss: 0.0979  noobj_loss: 0.0204  bbox_loss: 0.0904  cls_loss: 2.3790  \n",
      "<<<iteration:[780/878] - total_loss: 2.7049  obj_loss: 0.0949  noobj_loss: 0.0182  bbox_loss: 0.0816  cls_loss: 2.1930  \n",
      "<<<iteration:[800/878] - total_loss: 2.7307  obj_loss: 0.1034  noobj_loss: 0.0187  bbox_loss: 0.1073  cls_loss: 2.0812  \n",
      "<<<iteration:[820/878] - total_loss: 2.8970  obj_loss: 0.0831  noobj_loss: 0.0380  bbox_loss: 0.0962  cls_loss: 2.3139  \n",
      "<<<iteration:[840/878] - total_loss: 2.8150  obj_loss: 0.0765  noobj_loss: 0.0219  bbox_loss: 0.0957  cls_loss: 2.2491  \n",
      "<<<iteration:[860/878] - total_loss: 2.5430  obj_loss: 0.0843  noobj_loss: 0.0183  bbox_loss: 0.0818  cls_loss: 2.0407  \n",
      "\n",
      "epoch:31/100 - Train Loss: 2.8230, Val Loss: 2.9906\n",
      "\n",
      "<<<iteration:[20/878] - total_loss: 2.9967  obj_loss: 0.1076  noobj_loss: 0.0215  bbox_loss: 0.0884  cls_loss: 2.4365  \n",
      "<<<iteration:[40/878] - total_loss: 2.9375  obj_loss: 0.1160  noobj_loss: 0.0210  bbox_loss: 0.0791  cls_loss: 2.4157  \n",
      "<<<iteration:[60/878] - total_loss: 2.4121  obj_loss: 0.0890  noobj_loss: 0.0234  bbox_loss: 0.0836  cls_loss: 1.8934  \n",
      "<<<iteration:[80/878] - total_loss: 2.8490  obj_loss: 0.0741  noobj_loss: 0.0179  bbox_loss: 0.0903  cls_loss: 2.3146  \n",
      "<<<iteration:[100/878] - total_loss: 2.5251  obj_loss: 0.1021  noobj_loss: 0.0230  bbox_loss: 0.0844  cls_loss: 1.9894  \n",
      "<<<iteration:[120/878] - total_loss: 2.6139  obj_loss: 0.0669  noobj_loss: 0.0180  bbox_loss: 0.0842  cls_loss: 2.1172  \n",
      "<<<iteration:[140/878] - total_loss: 2.5771  obj_loss: 0.0718  noobj_loss: 0.0154  bbox_loss: 0.0879  cls_loss: 2.0583  \n",
      "<<<iteration:[160/878] - total_loss: 2.6067  obj_loss: 0.0941  noobj_loss: 0.0196  bbox_loss: 0.0815  cls_loss: 2.0953  \n",
      "<<<iteration:[180/878] - total_loss: 2.7446  obj_loss: 0.0941  noobj_loss: 0.0216  bbox_loss: 0.1008  cls_loss: 2.1355  \n",
      "<<<iteration:[200/878] - total_loss: 2.9272  obj_loss: 0.0956  noobj_loss: 0.0194  bbox_loss: 0.0987  cls_loss: 2.3286  \n",
      "<<<iteration:[220/878] - total_loss: 2.9040  obj_loss: 0.1276  noobj_loss: 0.0215  bbox_loss: 0.0970  cls_loss: 2.2806  \n",
      "<<<iteration:[240/878] - total_loss: 2.6170  obj_loss: 0.1174  noobj_loss: 0.0202  bbox_loss: 0.0788  cls_loss: 2.0956  \n",
      "<<<iteration:[260/878] - total_loss: 2.6739  obj_loss: 0.1067  noobj_loss: 0.0267  bbox_loss: 0.1021  cls_loss: 2.0436  \n",
      "<<<iteration:[280/878] - total_loss: 3.1024  obj_loss: 0.1213  noobj_loss: 0.0218  bbox_loss: 0.1051  cls_loss: 2.4449  \n",
      "<<<iteration:[300/878] - total_loss: 3.1164  obj_loss: 0.1032  noobj_loss: 0.0208  bbox_loss: 0.1363  cls_loss: 2.3215  \n",
      "<<<iteration:[320/878] - total_loss: 2.6892  obj_loss: 0.0902  noobj_loss: 0.0222  bbox_loss: 0.0846  cls_loss: 2.1649  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<<<iteration:[340/878] - total_loss: 2.5854  obj_loss: 0.0918  noobj_loss: 0.0182  bbox_loss: 0.0687  cls_loss: 2.1410  \n",
      "<<<iteration:[360/878] - total_loss: 2.8324  obj_loss: 0.1167  noobj_loss: 0.0195  bbox_loss: 0.0883  cls_loss: 2.2645  \n",
      "<<<iteration:[380/878] - total_loss: 2.6726  obj_loss: 0.0711  noobj_loss: 0.0167  bbox_loss: 0.1324  cls_loss: 1.9310  \n",
      "<<<iteration:[400/878] - total_loss: 2.9939  obj_loss: 0.1036  noobj_loss: 0.0212  bbox_loss: 0.1098  cls_loss: 2.3307  \n",
      "<<<iteration:[420/878] - total_loss: 2.9456  obj_loss: 0.1035  noobj_loss: 0.0199  bbox_loss: 0.1064  cls_loss: 2.3002  \n",
      "<<<iteration:[440/878] - total_loss: 2.8313  obj_loss: 0.0984  noobj_loss: 0.0196  bbox_loss: 0.1037  cls_loss: 2.2044  \n",
      "<<<iteration:[460/878] - total_loss: 2.8806  obj_loss: 0.1176  noobj_loss: 0.0220  bbox_loss: 0.1017  cls_loss: 2.2436  \n",
      "<<<iteration:[480/878] - total_loss: 2.8637  obj_loss: 0.1169  noobj_loss: 0.0209  bbox_loss: 0.1006  cls_loss: 2.2332  \n",
      "<<<iteration:[500/878] - total_loss: 2.8246  obj_loss: 0.0964  noobj_loss: 0.0190  bbox_loss: 0.0869  cls_loss: 2.2843  \n",
      "<<<iteration:[520/878] - total_loss: 2.5489  obj_loss: 0.1080  noobj_loss: 0.0220  bbox_loss: 0.0820  cls_loss: 2.0198  \n",
      "<<<iteration:[540/878] - total_loss: 3.1703  obj_loss: 0.1139  noobj_loss: 0.0219  bbox_loss: 0.1224  cls_loss: 2.4334  \n",
      "<<<iteration:[560/878] - total_loss: 2.5746  obj_loss: 0.1167  noobj_loss: 0.0218  bbox_loss: 0.0753  cls_loss: 2.0705  \n",
      "<<<iteration:[580/878] - total_loss: 2.4871  obj_loss: 0.0972  noobj_loss: 0.0237  bbox_loss: 0.0846  cls_loss: 1.9552  \n",
      "<<<iteration:[600/878] - total_loss: 2.5861  obj_loss: 0.1022  noobj_loss: 0.0218  bbox_loss: 0.0825  cls_loss: 2.0602  \n",
      "<<<iteration:[620/878] - total_loss: 2.8446  obj_loss: 0.1300  noobj_loss: 0.0248  bbox_loss: 0.0857  cls_loss: 2.2736  \n",
      "<<<iteration:[640/878] - total_loss: 2.8027  obj_loss: 0.1018  noobj_loss: 0.0207  bbox_loss: 0.0972  cls_loss: 2.2044  \n",
      "<<<iteration:[660/878] - total_loss: 2.6691  obj_loss: 0.0985  noobj_loss: 0.0214  bbox_loss: 0.0806  cls_loss: 2.1568  \n",
      "<<<iteration:[680/878] - total_loss: 2.8027  obj_loss: 0.0738  noobj_loss: 0.0224  bbox_loss: 0.1007  cls_loss: 2.2144  \n",
      "<<<iteration:[700/878] - total_loss: 2.8188  obj_loss: 0.0872  noobj_loss: 0.0232  bbox_loss: 0.0834  cls_loss: 2.3031  \n",
      "<<<iteration:[720/878] - total_loss: 2.5738  obj_loss: 0.0954  noobj_loss: 0.0187  bbox_loss: 0.0789  cls_loss: 2.0746  \n",
      "<<<iteration:[740/878] - total_loss: 2.9896  obj_loss: 0.1080  noobj_loss: 0.0213  bbox_loss: 0.0943  cls_loss: 2.3992  \n",
      "<<<iteration:[760/878] - total_loss: 2.8084  obj_loss: 0.0928  noobj_loss: 0.0202  bbox_loss: 0.0982  cls_loss: 2.2146  \n",
      "<<<iteration:[780/878] - total_loss: 2.6737  obj_loss: 0.0780  noobj_loss: 0.0194  bbox_loss: 0.0863  cls_loss: 2.1546  \n",
      "<<<iteration:[800/878] - total_loss: 2.5109  obj_loss: 0.0780  noobj_loss: 0.0215  bbox_loss: 0.0859  cls_loss: 1.9926  \n",
      "<<<iteration:[820/878] - total_loss: 2.8026  obj_loss: 0.0841  noobj_loss: 0.0163  bbox_loss: 0.0810  cls_loss: 2.3051  \n",
      "<<<iteration:[840/878] - total_loss: 2.9011  obj_loss: 0.1199  noobj_loss: 0.0202  bbox_loss: 0.0834  cls_loss: 2.3540  \n",
      "<<<iteration:[860/878] - total_loss: 2.8630  obj_loss: 0.0924  noobj_loss: 0.0217  bbox_loss: 0.0931  cls_loss: 2.2941  \n",
      "\n",
      "epoch:32/100 - Train Loss: 2.7674, Val Loss: 3.1419\n",
      "\n",
      "<<<iteration:[20/878] - total_loss: 3.1235  obj_loss: 0.1348  noobj_loss: 0.0277  bbox_loss: 0.1173  cls_loss: 2.3884  \n",
      "<<<iteration:[40/878] - total_loss: 2.6465  obj_loss: 0.0876  noobj_loss: 0.0186  bbox_loss: 0.0738  cls_loss: 2.1804  \n",
      "<<<iteration:[60/878] - total_loss: 2.8865  obj_loss: 0.1093  noobj_loss: 0.0207  bbox_loss: 0.1140  cls_loss: 2.1970  \n",
      "<<<iteration:[80/878] - total_loss: 2.5816  obj_loss: 0.1163  noobj_loss: 0.0218  bbox_loss: 0.0819  cls_loss: 2.0451  \n",
      "<<<iteration:[100/878] - total_loss: 2.8258  obj_loss: 0.0954  noobj_loss: 0.0286  bbox_loss: 0.1019  cls_loss: 2.2064  \n",
      "<<<iteration:[120/878] - total_loss: 2.6693  obj_loss: 0.1108  noobj_loss: 0.0240  bbox_loss: 0.0836  cls_loss: 2.1285  \n",
      "<<<iteration:[140/878] - total_loss: 2.9144  obj_loss: 0.1107  noobj_loss: 0.0215  bbox_loss: 0.0874  cls_loss: 2.3560  \n",
      "<<<iteration:[160/878] - total_loss: 2.7429  obj_loss: 0.1138  noobj_loss: 0.0241  bbox_loss: 0.0998  cls_loss: 2.1182  \n",
      "<<<iteration:[180/878] - total_loss: 2.7042  obj_loss: 0.1095  noobj_loss: 0.0238  bbox_loss: 0.0756  cls_loss: 2.2050  \n",
      "<<<iteration:[200/878] - total_loss: 2.7313  obj_loss: 0.0972  noobj_loss: 0.0180  bbox_loss: 0.0724  cls_loss: 2.2631  \n",
      "<<<iteration:[220/878] - total_loss: 2.9422  obj_loss: 0.1170  noobj_loss: 0.0203  bbox_loss: 0.1244  cls_loss: 2.1931  \n",
      "<<<iteration:[240/878] - total_loss: 2.8391  obj_loss: 0.0956  noobj_loss: 0.0254  bbox_loss: 0.0985  cls_loss: 2.2383  \n",
      "<<<iteration:[260/878] - total_loss: 2.6844  obj_loss: 0.0683  noobj_loss: 0.0167  bbox_loss: 0.1044  cls_loss: 2.0857  \n",
      "<<<iteration:[280/878] - total_loss: 2.6154  obj_loss: 0.1007  noobj_loss: 0.0193  bbox_loss: 0.0936  cls_loss: 2.0370  \n",
      "<<<iteration:[300/878] - total_loss: 2.5997  obj_loss: 0.1045  noobj_loss: 0.0226  bbox_loss: 0.0914  cls_loss: 2.0269  \n",
      "<<<iteration:[320/878] - total_loss: 2.9345  obj_loss: 0.0782  noobj_loss: 0.0201  bbox_loss: 0.1024  cls_loss: 2.3343  \n",
      "<<<iteration:[340/878] - total_loss: 2.8443  obj_loss: 0.0945  noobj_loss: 0.0209  bbox_loss: 0.0919  cls_loss: 2.2800  \n",
      "<<<iteration:[360/878] - total_loss: 2.5441  obj_loss: 0.0912  noobj_loss: 0.0198  bbox_loss: 0.0735  cls_loss: 2.0753  \n",
      "<<<iteration:[380/878] - total_loss: 2.7910  obj_loss: 0.0883  noobj_loss: 0.0169  bbox_loss: 0.0868  cls_loss: 2.2602  \n",
      "<<<iteration:[400/878] - total_loss: 2.5710  obj_loss: 0.1063  noobj_loss: 0.0215  bbox_loss: 0.0860  cls_loss: 2.0242  \n",
      "<<<iteration:[420/878] - total_loss: 2.9096  obj_loss: 0.1043  noobj_loss: 0.0189  bbox_loss: 0.0907  cls_loss: 2.3423  \n",
      "<<<iteration:[440/878] - total_loss: 2.6772  obj_loss: 0.0752  noobj_loss: 0.0219  bbox_loss: 0.0804  cls_loss: 2.1892  \n",
      "<<<iteration:[460/878] - total_loss: 2.6205  obj_loss: 0.1306  noobj_loss: 0.0201  bbox_loss: 0.0756  cls_loss: 2.1018  \n",
      "<<<iteration:[480/878] - total_loss: 2.8877  obj_loss: 0.0935  noobj_loss: 0.0206  bbox_loss: 0.0912  cls_loss: 2.3280  \n",
      "<<<iteration:[500/878] - total_loss: 2.4532  obj_loss: 0.0990  noobj_loss: 0.0191  bbox_loss: 0.0744  cls_loss: 1.9724  \n",
      "<<<iteration:[520/878] - total_loss: 3.2930  obj_loss: 0.1054  noobj_loss: 0.0197  bbox_loss: 0.1822  cls_loss: 2.2666  \n",
      "<<<iteration:[540/878] - total_loss: 2.8763  obj_loss: 0.1070  noobj_loss: 0.0231  bbox_loss: 0.1020  cls_loss: 2.2480  \n",
      "<<<iteration:[560/878] - total_loss: 2.3873  obj_loss: 0.1124  noobj_loss: 0.0244  bbox_loss: 0.0668  cls_loss: 1.9286  \n",
      "<<<iteration:[580/878] - total_loss: 3.0891  obj_loss: 0.1018  noobj_loss: 0.0263  bbox_loss: 0.1213  cls_loss: 2.3674  \n",
      "<<<iteration:[600/878] - total_loss: 2.4767  obj_loss: 0.0857  noobj_loss: 0.0197  bbox_loss: 0.0787  cls_loss: 1.9879  \n",
      "<<<iteration:[620/878] - total_loss: 2.9696  obj_loss: 0.1011  noobj_loss: 0.0211  bbox_loss: 0.0905  cls_loss: 2.4055  \n",
      "<<<iteration:[640/878] - total_loss: 2.4496  obj_loss: 0.0823  noobj_loss: 0.0350  bbox_loss: 0.0815  cls_loss: 1.9422  \n",
      "<<<iteration:[660/878] - total_loss: 2.8807  obj_loss: 0.1118  noobj_loss: 0.0259  bbox_loss: 0.0927  cls_loss: 2.2925  \n",
      "<<<iteration:[680/878] - total_loss: 2.7871  obj_loss: 0.0866  noobj_loss: 0.0176  bbox_loss: 0.0962  cls_loss: 2.2108  \n",
      "<<<iteration:[700/878] - total_loss: 2.8968  obj_loss: 0.1028  noobj_loss: 0.0203  bbox_loss: 0.1144  cls_loss: 2.2121  \n",
      "<<<iteration:[720/878] - total_loss: 2.6420  obj_loss: 0.0881  noobj_loss: 0.0284  bbox_loss: 0.1041  cls_loss: 2.0194  \n",
      "<<<iteration:[740/878] - total_loss: 2.7682  obj_loss: 0.1097  noobj_loss: 0.0204  bbox_loss: 0.0843  cls_loss: 2.2267  \n",
      "<<<iteration:[760/878] - total_loss: 2.9159  obj_loss: 0.0902  noobj_loss: 0.0232  bbox_loss: 0.1029  cls_loss: 2.2994  \n",
      "<<<iteration:[780/878] - total_loss: 2.5968  obj_loss: 0.1094  noobj_loss: 0.0212  bbox_loss: 0.0903  cls_loss: 2.0255  \n",
      "<<<iteration:[800/878] - total_loss: 2.4267  obj_loss: 0.1030  noobj_loss: 0.0187  bbox_loss: 0.0701  cls_loss: 1.9641  \n",
      "<<<iteration:[820/878] - total_loss: 2.6542  obj_loss: 0.1138  noobj_loss: 0.0221  bbox_loss: 0.0849  cls_loss: 2.1047  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<<<iteration:[840/878] - total_loss: 2.6430  obj_loss: 0.1187  noobj_loss: 0.0224  bbox_loss: 0.0778  cls_loss: 2.1239  \n",
      "<<<iteration:[860/878] - total_loss: 2.7491  obj_loss: 0.0820  noobj_loss: 0.0215  bbox_loss: 0.0907  cls_loss: 2.2027  \n",
      "\n",
      "epoch:33/100 - Train Loss: 2.7444, Val Loss: 3.1481\n",
      "\n",
      "<<<iteration:[20/878] - total_loss: 2.6526  obj_loss: 0.0883  noobj_loss: 0.0212  bbox_loss: 0.0762  cls_loss: 2.1727  \n",
      "<<<iteration:[40/878] - total_loss: 2.7359  obj_loss: 0.0711  noobj_loss: 0.0173  bbox_loss: 0.0921  cls_loss: 2.1956  \n",
      "<<<iteration:[60/878] - total_loss: 2.8680  obj_loss: 0.1121  noobj_loss: 0.0208  bbox_loss: 0.1033  cls_loss: 2.2290  \n",
      "<<<iteration:[80/878] - total_loss: 2.3967  obj_loss: 0.1071  noobj_loss: 0.0215  bbox_loss: 0.0822  cls_loss: 1.8678  \n",
      "<<<iteration:[100/878] - total_loss: 2.4161  obj_loss: 0.0837  noobj_loss: 0.0153  bbox_loss: 0.0752  cls_loss: 1.9488  \n",
      "<<<iteration:[120/878] - total_loss: 3.0003  obj_loss: 0.1113  noobj_loss: 0.0207  bbox_loss: 0.1128  cls_loss: 2.3147  \n",
      "<<<iteration:[140/878] - total_loss: 3.0796  obj_loss: 0.1293  noobj_loss: 0.0224  bbox_loss: 0.1083  cls_loss: 2.3975  \n",
      "<<<iteration:[160/878] - total_loss: 2.5606  obj_loss: 0.1138  noobj_loss: 0.0213  bbox_loss: 0.0889  cls_loss: 1.9916  \n",
      "<<<iteration:[180/878] - total_loss: 2.8793  obj_loss: 0.1120  noobj_loss: 0.0241  bbox_loss: 0.0890  cls_loss: 2.3104  \n",
      "<<<iteration:[200/878] - total_loss: 2.7577  obj_loss: 0.1078  noobj_loss: 0.0212  bbox_loss: 0.0979  cls_loss: 2.1496  \n",
      "<<<iteration:[220/878] - total_loss: 2.5819  obj_loss: 0.1163  noobj_loss: 0.0252  bbox_loss: 0.0985  cls_loss: 1.9607  \n",
      "<<<iteration:[240/878] - total_loss: 2.7210  obj_loss: 0.0984  noobj_loss: 0.0201  bbox_loss: 0.0771  cls_loss: 2.2271  \n",
      "<<<iteration:[260/878] - total_loss: 2.3740  obj_loss: 0.0918  noobj_loss: 0.0219  bbox_loss: 0.0839  cls_loss: 1.8518  \n",
      "<<<iteration:[280/878] - total_loss: 2.7032  obj_loss: 0.0978  noobj_loss: 0.0206  bbox_loss: 0.0864  cls_loss: 2.1630  \n",
      "<<<iteration:[300/878] - total_loss: 2.9853  obj_loss: 0.1063  noobj_loss: 0.0224  bbox_loss: 0.1051  cls_loss: 2.3424  \n",
      "<<<iteration:[320/878] - total_loss: 2.3809  obj_loss: 0.0934  noobj_loss: 0.0191  bbox_loss: 0.0802  cls_loss: 1.8771  \n",
      "<<<iteration:[340/878] - total_loss: 2.5476  obj_loss: 0.0903  noobj_loss: 0.0214  bbox_loss: 0.0751  cls_loss: 2.0713  \n",
      "<<<iteration:[360/878] - total_loss: 2.6489  obj_loss: 0.0968  noobj_loss: 0.0201  bbox_loss: 0.0758  cls_loss: 2.1631  \n",
      "<<<iteration:[380/878] - total_loss: 3.5270  obj_loss: 0.0894  noobj_loss: 0.0195  bbox_loss: 0.2118  cls_loss: 2.3688  \n",
      "<<<iteration:[400/878] - total_loss: 2.5254  obj_loss: 0.0994  noobj_loss: 0.0174  bbox_loss: 0.0731  cls_loss: 2.0519  \n",
      "<<<iteration:[420/878] - total_loss: 2.7054  obj_loss: 0.1081  noobj_loss: 0.0231  bbox_loss: 0.0943  cls_loss: 2.1145  \n",
      "<<<iteration:[440/878] - total_loss: 3.0276  obj_loss: 0.1067  noobj_loss: 0.0235  bbox_loss: 0.0915  cls_loss: 2.4517  \n",
      "<<<iteration:[460/878] - total_loss: 2.6653  obj_loss: 0.0877  noobj_loss: 0.0214  bbox_loss: 0.0887  cls_loss: 2.1235  \n",
      "<<<iteration:[480/878] - total_loss: 2.7597  obj_loss: 0.0981  noobj_loss: 0.0209  bbox_loss: 0.0904  cls_loss: 2.1991  \n",
      "<<<iteration:[500/878] - total_loss: 2.9704  obj_loss: 0.0931  noobj_loss: 0.0198  bbox_loss: 0.1089  cls_loss: 2.3228  \n",
      "<<<iteration:[520/878] - total_loss: 2.6990  obj_loss: 0.0924  noobj_loss: 0.0260  bbox_loss: 0.0921  cls_loss: 2.1333  \n",
      "<<<iteration:[540/878] - total_loss: 2.7909  obj_loss: 0.1049  noobj_loss: 0.0198  bbox_loss: 0.0933  cls_loss: 2.2097  \n",
      "<<<iteration:[560/878] - total_loss: 2.5684  obj_loss: 0.0812  noobj_loss: 0.0178  bbox_loss: 0.0780  cls_loss: 2.0880  \n",
      "<<<iteration:[580/878] - total_loss: 2.8664  obj_loss: 0.1022  noobj_loss: 0.0195  bbox_loss: 0.0855  cls_loss: 2.3270  \n",
      "<<<iteration:[600/878] - total_loss: 2.7221  obj_loss: 0.0733  noobj_loss: 0.0188  bbox_loss: 0.0840  cls_loss: 2.2196  \n",
      "<<<iteration:[620/878] - total_loss: 2.7769  obj_loss: 0.1163  noobj_loss: 0.0214  bbox_loss: 0.0967  cls_loss: 2.1662  \n",
      "<<<iteration:[640/878] - total_loss: 2.8578  obj_loss: 0.1237  noobj_loss: 0.0223  bbox_loss: 0.0978  cls_loss: 2.2337  \n",
      "<<<iteration:[660/878] - total_loss: 2.8076  obj_loss: 0.0847  noobj_loss: 0.0265  bbox_loss: 0.1515  cls_loss: 1.9520  \n",
      "<<<iteration:[680/878] - total_loss: 2.7617  obj_loss: 0.0896  noobj_loss: 0.0219  bbox_loss: 0.0941  cls_loss: 2.1909  \n",
      "<<<iteration:[700/878] - total_loss: 3.0772  obj_loss: 0.0935  noobj_loss: 0.0194  bbox_loss: 0.1575  cls_loss: 2.1864  \n",
      "<<<iteration:[720/878] - total_loss: 2.6049  obj_loss: 0.1058  noobj_loss: 0.0226  bbox_loss: 0.1149  cls_loss: 1.9135  \n",
      "<<<iteration:[740/878] - total_loss: 2.9249  obj_loss: 0.1215  noobj_loss: 0.0229  bbox_loss: 0.1102  cls_loss: 2.2410  \n",
      "<<<iteration:[760/878] - total_loss: 2.5296  obj_loss: 0.0841  noobj_loss: 0.0195  bbox_loss: 0.0685  cls_loss: 2.0932  \n",
      "<<<iteration:[780/878] - total_loss: 2.5222  obj_loss: 0.1128  noobj_loss: 0.0205  bbox_loss: 0.0868  cls_loss: 1.9651  \n",
      "<<<iteration:[800/878] - total_loss: 3.0378  obj_loss: 0.1153  noobj_loss: 0.0238  bbox_loss: 0.0966  cls_loss: 2.4274  \n",
      "<<<iteration:[820/878] - total_loss: 2.5447  obj_loss: 0.0887  noobj_loss: 0.0241  bbox_loss: 0.1012  cls_loss: 1.9380  \n",
      "<<<iteration:[840/878] - total_loss: 2.4867  obj_loss: 0.1101  noobj_loss: 0.0198  bbox_loss: 0.0783  cls_loss: 1.9754  \n",
      "<<<iteration:[860/878] - total_loss: 2.5810  obj_loss: 0.0928  noobj_loss: 0.0196  bbox_loss: 0.0930  cls_loss: 2.0134  \n",
      "\n",
      "epoch:34/100 - Train Loss: 2.7310, Val Loss: 3.0038\n",
      "\n",
      "<<<iteration:[20/878] - total_loss: 2.5976  obj_loss: 0.1100  noobj_loss: 0.0226  bbox_loss: 0.0766  cls_loss: 2.0935  \n",
      "<<<iteration:[40/878] - total_loss: 2.9085  obj_loss: 0.0942  noobj_loss: 0.0266  bbox_loss: 0.0932  cls_loss: 2.3347  \n",
      "<<<iteration:[60/878] - total_loss: 2.5833  obj_loss: 0.1036  noobj_loss: 0.0205  bbox_loss: 0.0775  cls_loss: 2.0819  \n",
      "<<<iteration:[80/878] - total_loss: 2.4619  obj_loss: 0.0711  noobj_loss: 0.0220  bbox_loss: 0.0852  cls_loss: 1.9537  \n",
      "<<<iteration:[100/878] - total_loss: 2.6910  obj_loss: 0.0998  noobj_loss: 0.0203  bbox_loss: 0.0962  cls_loss: 2.1002  \n",
      "<<<iteration:[120/878] - total_loss: 2.6909  obj_loss: 0.0997  noobj_loss: 0.0211  bbox_loss: 0.0853  cls_loss: 2.1542  \n",
      "<<<iteration:[140/878] - total_loss: 2.6622  obj_loss: 0.0734  noobj_loss: 0.0193  bbox_loss: 0.1188  cls_loss: 1.9851  \n",
      "<<<iteration:[160/878] - total_loss: 2.5375  obj_loss: 0.1038  noobj_loss: 0.0181  bbox_loss: 0.0840  cls_loss: 2.0046  \n",
      "<<<iteration:[180/878] - total_loss: 2.7754  obj_loss: 0.1251  noobj_loss: 0.0202  bbox_loss: 0.0939  cls_loss: 2.1708  \n",
      "<<<iteration:[200/878] - total_loss: 2.8490  obj_loss: 0.0941  noobj_loss: 0.0219  bbox_loss: 0.0983  cls_loss: 2.2524  \n",
      "<<<iteration:[220/878] - total_loss: 2.9428  obj_loss: 0.0843  noobj_loss: 0.0274  bbox_loss: 0.0889  cls_loss: 2.4002  \n",
      "<<<iteration:[240/878] - total_loss: 2.4953  obj_loss: 0.1076  noobj_loss: 0.0201  bbox_loss: 0.0848  cls_loss: 1.9537  \n",
      "<<<iteration:[260/878] - total_loss: 2.3794  obj_loss: 0.1181  noobj_loss: 0.0233  bbox_loss: 0.0713  cls_loss: 1.8933  \n",
      "<<<iteration:[280/878] - total_loss: 2.9366  obj_loss: 0.1176  noobj_loss: 0.0230  bbox_loss: 0.1048  cls_loss: 2.2836  \n",
      "<<<iteration:[300/878] - total_loss: 2.7672  obj_loss: 0.1299  noobj_loss: 0.0341  bbox_loss: 0.0896  cls_loss: 2.1721  \n",
      "<<<iteration:[320/878] - total_loss: 2.9000  obj_loss: 0.1215  noobj_loss: 0.0286  bbox_loss: 0.0898  cls_loss: 2.3154  \n",
      "<<<iteration:[340/878] - total_loss: 2.7263  obj_loss: 0.1135  noobj_loss: 0.0253  bbox_loss: 0.1045  cls_loss: 2.0777  \n",
      "<<<iteration:[360/878] - total_loss: 2.7299  obj_loss: 0.0958  noobj_loss: 0.0253  bbox_loss: 0.1004  cls_loss: 2.1192  \n",
      "<<<iteration:[380/878] - total_loss: 2.7222  obj_loss: 0.1102  noobj_loss: 0.0207  bbox_loss: 0.0969  cls_loss: 2.1173  \n",
      "<<<iteration:[400/878] - total_loss: 2.6712  obj_loss: 0.1028  noobj_loss: 0.0218  bbox_loss: 0.0733  cls_loss: 2.1913  \n",
      "<<<iteration:[420/878] - total_loss: 2.4758  obj_loss: 0.1015  noobj_loss: 0.0235  bbox_loss: 0.0765  cls_loss: 1.9802  \n",
      "<<<iteration:[440/878] - total_loss: 3.1763  obj_loss: 0.1060  noobj_loss: 0.0205  bbox_loss: 0.1473  cls_loss: 2.3235  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<<<iteration:[460/878] - total_loss: 2.6047  obj_loss: 0.0900  noobj_loss: 0.0200  bbox_loss: 0.0980  cls_loss: 2.0148  \n",
      "<<<iteration:[480/878] - total_loss: 2.4734  obj_loss: 0.0870  noobj_loss: 0.0207  bbox_loss: 0.0793  cls_loss: 1.9795  \n",
      "<<<iteration:[500/878] - total_loss: 2.6780  obj_loss: 0.1029  noobj_loss: 0.0187  bbox_loss: 0.0781  cls_loss: 2.1754  \n",
      "<<<iteration:[520/878] - total_loss: 2.8098  obj_loss: 0.1085  noobj_loss: 0.0224  bbox_loss: 0.0999  cls_loss: 2.1907  \n",
      "<<<iteration:[540/878] - total_loss: 2.7499  obj_loss: 0.0922  noobj_loss: 0.0239  bbox_loss: 0.1198  cls_loss: 2.0466  \n",
      "<<<iteration:[560/878] - total_loss: 3.3500  obj_loss: 0.1055  noobj_loss: 0.0234  bbox_loss: 0.2378  cls_loss: 2.0437  \n",
      "<<<iteration:[580/878] - total_loss: 2.6998  obj_loss: 0.1010  noobj_loss: 0.0237  bbox_loss: 0.0973  cls_loss: 2.1004  \n",
      "<<<iteration:[600/878] - total_loss: 2.6254  obj_loss: 0.0949  noobj_loss: 0.0209  bbox_loss: 0.0947  cls_loss: 2.0465  \n",
      "<<<iteration:[620/878] - total_loss: 2.4347  obj_loss: 0.0747  noobj_loss: 0.0287  bbox_loss: 0.1207  cls_loss: 1.7421  \n",
      "<<<iteration:[640/878] - total_loss: 2.7983  obj_loss: 0.1316  noobj_loss: 0.0230  bbox_loss: 0.0803  cls_loss: 2.2535  \n",
      "<<<iteration:[660/878] - total_loss: 2.5219  obj_loss: 0.0833  noobj_loss: 0.0258  bbox_loss: 0.0958  cls_loss: 1.9468  \n",
      "<<<iteration:[680/878] - total_loss: 2.6287  obj_loss: 0.0982  noobj_loss: 0.0229  bbox_loss: 0.0850  cls_loss: 2.0941  \n",
      "<<<iteration:[700/878] - total_loss: 2.6979  obj_loss: 0.0898  noobj_loss: 0.0206  bbox_loss: 0.0903  cls_loss: 2.1465  \n",
      "<<<iteration:[720/878] - total_loss: 2.5324  obj_loss: 0.0999  noobj_loss: 0.0188  bbox_loss: 0.0749  cls_loss: 2.0489  \n",
      "<<<iteration:[740/878] - total_loss: 2.5786  obj_loss: 0.0924  noobj_loss: 0.0193  bbox_loss: 0.0794  cls_loss: 2.0797  \n",
      "<<<iteration:[760/878] - total_loss: 2.6725  obj_loss: 0.0834  noobj_loss: 0.0188  bbox_loss: 0.0848  cls_loss: 2.1556  \n",
      "<<<iteration:[780/878] - total_loss: 2.9409  obj_loss: 0.1316  noobj_loss: 0.0281  bbox_loss: 0.0954  cls_loss: 2.3181  \n",
      "<<<iteration:[800/878] - total_loss: 2.7364  obj_loss: 0.1153  noobj_loss: 0.0212  bbox_loss: 0.0711  cls_loss: 2.2548  \n",
      "<<<iteration:[820/878] - total_loss: 2.6271  obj_loss: 0.0980  noobj_loss: 0.0209  bbox_loss: 0.0768  cls_loss: 2.1345  \n",
      "<<<iteration:[840/878] - total_loss: 2.7356  obj_loss: 0.1085  noobj_loss: 0.0218  bbox_loss: 0.0918  cls_loss: 2.1570  \n",
      "<<<iteration:[860/878] - total_loss: 2.5696  obj_loss: 0.1188  noobj_loss: 0.0240  bbox_loss: 0.0759  cls_loss: 2.0591  \n",
      "\n",
      "epoch:35/100 - Train Loss: 2.6954, Val Loss: 3.1132\n",
      "\n",
      "<<<iteration:[20/878] - total_loss: 2.8016  obj_loss: 0.1178  noobj_loss: 0.0234  bbox_loss: 0.0880  cls_loss: 2.2320  \n",
      "<<<iteration:[40/878] - total_loss: 2.7313  obj_loss: 0.1262  noobj_loss: 0.0227  bbox_loss: 0.0734  cls_loss: 2.2269  \n",
      "<<<iteration:[60/878] - total_loss: 3.2854  obj_loss: 0.0963  noobj_loss: 0.0353  bbox_loss: 0.2331  cls_loss: 2.0060  \n",
      "<<<iteration:[80/878] - total_loss: 3.2183  obj_loss: 0.0925  noobj_loss: 0.0222  bbox_loss: 0.1883  cls_loss: 2.1731  \n",
      "<<<iteration:[100/878] - total_loss: 2.9372  obj_loss: 0.1101  noobj_loss: 0.0239  bbox_loss: 0.0953  cls_loss: 2.3384  \n",
      "<<<iteration:[120/878] - total_loss: 3.0175  obj_loss: 0.0855  noobj_loss: 0.0266  bbox_loss: 0.1719  cls_loss: 2.0591  \n",
      "<<<iteration:[140/878] - total_loss: 3.1429  obj_loss: 0.0955  noobj_loss: 0.0180  bbox_loss: 0.2045  cls_loss: 2.0157  \n",
      "<<<iteration:[160/878] - total_loss: 2.8369  obj_loss: 0.0944  noobj_loss: 0.0223  bbox_loss: 0.1101  cls_loss: 2.1809  \n",
      "<<<iteration:[180/878] - total_loss: 2.7093  obj_loss: 0.0977  noobj_loss: 0.0202  bbox_loss: 0.0919  cls_loss: 2.1419  \n",
      "<<<iteration:[200/878] - total_loss: 2.8278  obj_loss: 0.0870  noobj_loss: 0.0211  bbox_loss: 0.1208  cls_loss: 2.1264  \n",
      "<<<iteration:[220/878] - total_loss: 2.4618  obj_loss: 0.1141  noobj_loss: 0.0235  bbox_loss: 0.1071  cls_loss: 1.8006  \n",
      "<<<iteration:[240/878] - total_loss: 2.9455  obj_loss: 0.1248  noobj_loss: 0.0230  bbox_loss: 0.1012  cls_loss: 2.3032  \n",
      "<<<iteration:[260/878] - total_loss: 2.8456  obj_loss: 0.0962  noobj_loss: 0.0260  bbox_loss: 0.0981  cls_loss: 2.2459  \n",
      "<<<iteration:[280/878] - total_loss: 2.4462  obj_loss: 0.1243  noobj_loss: 0.0253  bbox_loss: 0.0799  cls_loss: 1.9096  \n",
      "<<<iteration:[300/878] - total_loss: 2.6836  obj_loss: 0.0854  noobj_loss: 0.0222  bbox_loss: 0.0921  cls_loss: 2.1269  \n",
      "<<<iteration:[320/878] - total_loss: 2.5921  obj_loss: 0.1023  noobj_loss: 0.0281  bbox_loss: 0.1010  cls_loss: 1.9709  \n",
      "<<<iteration:[340/878] - total_loss: 2.3327  obj_loss: 0.0913  noobj_loss: 0.0236  bbox_loss: 0.0735  cls_loss: 1.8620  \n",
      "<<<iteration:[360/878] - total_loss: 2.8601  obj_loss: 0.1126  noobj_loss: 0.0200  bbox_loss: 0.0831  cls_loss: 2.3220  \n",
      "<<<iteration:[380/878] - total_loss: 2.6370  obj_loss: 0.0988  noobj_loss: 0.0196  bbox_loss: 0.0897  cls_loss: 2.0799  \n",
      "<<<iteration:[400/878] - total_loss: 2.7352  obj_loss: 0.1002  noobj_loss: 0.0243  bbox_loss: 0.0890  cls_loss: 2.1777  \n",
      "<<<iteration:[420/878] - total_loss: 2.6531  obj_loss: 0.0728  noobj_loss: 0.0188  bbox_loss: 0.0864  cls_loss: 2.1390  \n",
      "<<<iteration:[440/878] - total_loss: 2.3054  obj_loss: 0.0805  noobj_loss: 0.0196  bbox_loss: 0.0774  cls_loss: 1.8280  \n",
      "<<<iteration:[460/878] - total_loss: 2.6460  obj_loss: 0.1022  noobj_loss: 0.0205  bbox_loss: 0.0767  cls_loss: 2.1503  \n",
      "<<<iteration:[480/878] - total_loss: 2.4964  obj_loss: 0.0785  noobj_loss: 0.0202  bbox_loss: 0.0826  cls_loss: 1.9949  \n",
      "<<<iteration:[500/878] - total_loss: 2.2460  obj_loss: 0.0814  noobj_loss: 0.0218  bbox_loss: 0.0772  cls_loss: 1.7676  \n",
      "<<<iteration:[520/878] - total_loss: 2.5044  obj_loss: 0.1420  noobj_loss: 0.0254  bbox_loss: 0.0758  cls_loss: 1.9706  \n",
      "<<<iteration:[540/878] - total_loss: 2.3225  obj_loss: 0.0909  noobj_loss: 0.0228  bbox_loss: 0.0901  cls_loss: 1.7695  \n",
      "<<<iteration:[560/878] - total_loss: 3.2840  obj_loss: 0.1130  noobj_loss: 0.0357  bbox_loss: 0.1379  cls_loss: 2.4634  \n",
      "<<<iteration:[580/878] - total_loss: 2.5350  obj_loss: 0.0766  noobj_loss: 0.0246  bbox_loss: 0.1148  cls_loss: 1.8722  \n",
      "<<<iteration:[600/878] - total_loss: 2.4523  obj_loss: 0.0989  noobj_loss: 0.0237  bbox_loss: 0.0793  cls_loss: 1.9450  \n",
      "<<<iteration:[620/878] - total_loss: 2.7396  obj_loss: 0.1216  noobj_loss: 0.0236  bbox_loss: 0.1015  cls_loss: 2.0985  \n",
      "<<<iteration:[640/878] - total_loss: 2.4145  obj_loss: 0.0978  noobj_loss: 0.0279  bbox_loss: 0.0717  cls_loss: 1.9443  \n",
      "<<<iteration:[660/878] - total_loss: 2.7156  obj_loss: 0.0980  noobj_loss: 0.0235  bbox_loss: 0.0768  cls_loss: 2.2217  \n",
      "<<<iteration:[680/878] - total_loss: 2.5017  obj_loss: 0.1167  noobj_loss: 0.0229  bbox_loss: 0.0845  cls_loss: 1.9512  \n",
      "<<<iteration:[700/878] - total_loss: 2.2935  obj_loss: 0.1046  noobj_loss: 0.0229  bbox_loss: 0.0894  cls_loss: 1.7306  \n",
      "<<<iteration:[720/878] - total_loss: 2.6803  obj_loss: 0.1236  noobj_loss: 0.0244  bbox_loss: 0.1063  cls_loss: 2.0129  \n",
      "<<<iteration:[740/878] - total_loss: 2.3950  obj_loss: 0.1289  noobj_loss: 0.0244  bbox_loss: 0.0859  cls_loss: 1.8242  \n",
      "<<<iteration:[760/878] - total_loss: 2.5097  obj_loss: 0.1094  noobj_loss: 0.0252  bbox_loss: 0.0923  cls_loss: 1.9262  \n",
      "<<<iteration:[780/878] - total_loss: 2.4896  obj_loss: 0.0966  noobj_loss: 0.0193  bbox_loss: 0.0805  cls_loss: 1.9811  \n",
      "<<<iteration:[800/878] - total_loss: 2.4838  obj_loss: 0.1231  noobj_loss: 0.0256  bbox_loss: 0.0897  cls_loss: 1.8994  \n",
      "<<<iteration:[820/878] - total_loss: 2.6660  obj_loss: 0.1012  noobj_loss: 0.0256  bbox_loss: 0.0886  cls_loss: 2.1091  \n",
      "<<<iteration:[840/878] - total_loss: 2.5806  obj_loss: 0.1344  noobj_loss: 0.0269  bbox_loss: 0.1017  cls_loss: 1.9242  \n",
      "<<<iteration:[860/878] - total_loss: 2.5619  obj_loss: 0.0891  noobj_loss: 0.0221  bbox_loss: 0.0804  cls_loss: 2.0598  \n",
      "\n",
      "epoch:36/100 - Train Loss: 2.6546, Val Loss: 2.8223\n",
      "\n",
      "<<<iteration:[20/878] - total_loss: 2.6130  obj_loss: 0.0993  noobj_loss: 0.0252  bbox_loss: 0.1264  cls_loss: 1.8691  \n",
      "<<<iteration:[40/878] - total_loss: 2.4551  obj_loss: 0.1146  noobj_loss: 0.0216  bbox_loss: 0.0927  cls_loss: 1.8661  \n",
      "<<<iteration:[60/878] - total_loss: 2.3043  obj_loss: 0.1344  noobj_loss: 0.0368  bbox_loss: 0.0945  cls_loss: 1.6788  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<<<iteration:[80/878] - total_loss: 2.6607  obj_loss: 0.0828  noobj_loss: 0.0259  bbox_loss: 0.0943  cls_loss: 2.0935  \n",
      "<<<iteration:[100/878] - total_loss: 3.3362  obj_loss: 0.0845  noobj_loss: 0.0181  bbox_loss: 0.2419  cls_loss: 2.0331  \n",
      "<<<iteration:[120/878] - total_loss: 2.3234  obj_loss: 0.0839  noobj_loss: 0.0184  bbox_loss: 0.0790  cls_loss: 1.8353  \n",
      "<<<iteration:[140/878] - total_loss: 2.6290  obj_loss: 0.1077  noobj_loss: 0.0241  bbox_loss: 0.1085  cls_loss: 1.9667  \n",
      "<<<iteration:[160/878] - total_loss: 2.1007  obj_loss: 0.0859  noobj_loss: 0.0229  bbox_loss: 0.0676  cls_loss: 1.6651  \n",
      "<<<iteration:[180/878] - total_loss: 2.2842  obj_loss: 0.1077  noobj_loss: 0.0360  bbox_loss: 0.0834  cls_loss: 1.7416  \n",
      "<<<iteration:[200/878] - total_loss: 2.4299  obj_loss: 0.0929  noobj_loss: 0.0198  bbox_loss: 0.0690  cls_loss: 1.9820  \n",
      "<<<iteration:[220/878] - total_loss: 2.3498  obj_loss: 0.1102  noobj_loss: 0.0201  bbox_loss: 0.0776  cls_loss: 1.8414  \n",
      "<<<iteration:[240/878] - total_loss: 2.5813  obj_loss: 0.1141  noobj_loss: 0.0264  bbox_loss: 0.0889  cls_loss: 2.0096  \n",
      "<<<iteration:[260/878] - total_loss: 2.1758  obj_loss: 0.1272  noobj_loss: 0.0241  bbox_loss: 0.0812  cls_loss: 1.6304  \n",
      "<<<iteration:[280/878] - total_loss: 2.4682  obj_loss: 0.1162  noobj_loss: 0.0210  bbox_loss: 0.0762  cls_loss: 1.9604  \n",
      "<<<iteration:[300/878] - total_loss: 2.1160  obj_loss: 0.0866  noobj_loss: 0.0183  bbox_loss: 0.0741  cls_loss: 1.6497  \n",
      "<<<iteration:[320/878] - total_loss: 2.4456  obj_loss: 0.0876  noobj_loss: 0.0224  bbox_loss: 0.1005  cls_loss: 1.8443  \n",
      "<<<iteration:[340/878] - total_loss: 2.1378  obj_loss: 0.1025  noobj_loss: 0.0239  bbox_loss: 0.0808  cls_loss: 1.6195  \n",
      "<<<iteration:[360/878] - total_loss: 2.3467  obj_loss: 0.1564  noobj_loss: 0.0254  bbox_loss: 0.1020  cls_loss: 1.6674  \n",
      "<<<iteration:[380/878] - total_loss: 2.3782  obj_loss: 0.1484  noobj_loss: 0.0359  bbox_loss: 0.1066  cls_loss: 1.6791  \n",
      "<<<iteration:[400/878] - total_loss: 2.3759  obj_loss: 0.1225  noobj_loss: 0.0257  bbox_loss: 0.0742  cls_loss: 1.8697  \n",
      "<<<iteration:[420/878] - total_loss: 2.1603  obj_loss: 0.1198  noobj_loss: 0.0235  bbox_loss: 0.0856  cls_loss: 1.6006  \n",
      "<<<iteration:[440/878] - total_loss: 2.4731  obj_loss: 0.0942  noobj_loss: 0.0237  bbox_loss: 0.1020  cls_loss: 1.8568  \n",
      "<<<iteration:[460/878] - total_loss: 2.2283  obj_loss: 0.1021  noobj_loss: 0.0224  bbox_loss: 0.0867  cls_loss: 1.6816  \n",
      "<<<iteration:[480/878] - total_loss: 2.4827  obj_loss: 0.1007  noobj_loss: 0.0226  bbox_loss: 0.1137  cls_loss: 1.8023  \n",
      "<<<iteration:[500/878] - total_loss: 2.2385  obj_loss: 0.1185  noobj_loss: 0.0234  bbox_loss: 0.0786  cls_loss: 1.7152  \n",
      "<<<iteration:[520/878] - total_loss: 2.0407  obj_loss: 0.0924  noobj_loss: 0.0211  bbox_loss: 0.0919  cls_loss: 1.4781  \n",
      "<<<iteration:[540/878] - total_loss: 2.3986  obj_loss: 0.1309  noobj_loss: 0.0223  bbox_loss: 0.0788  cls_loss: 1.8626  \n",
      "<<<iteration:[560/878] - total_loss: 2.1528  obj_loss: 0.1106  noobj_loss: 0.0208  bbox_loss: 0.0778  cls_loss: 1.6430  \n",
      "<<<iteration:[580/878] - total_loss: 2.2571  obj_loss: 0.0899  noobj_loss: 0.0199  bbox_loss: 0.0813  cls_loss: 1.7507  \n",
      "<<<iteration:[600/878] - total_loss: 2.2135  obj_loss: 0.1148  noobj_loss: 0.0213  bbox_loss: 0.0752  cls_loss: 1.7121  \n",
      "<<<iteration:[620/878] - total_loss: 2.4119  obj_loss: 0.1304  noobj_loss: 0.0235  bbox_loss: 0.0982  cls_loss: 1.7788  \n",
      "<<<iteration:[640/878] - total_loss: 2.0274  obj_loss: 0.1025  noobj_loss: 0.0211  bbox_loss: 0.0755  cls_loss: 1.5368  \n",
      "<<<iteration:[660/878] - total_loss: 2.3518  obj_loss: 0.1002  noobj_loss: 0.0196  bbox_loss: 0.0763  cls_loss: 1.8603  \n",
      "<<<iteration:[680/878] - total_loss: 2.2584  obj_loss: 0.1211  noobj_loss: 0.0214  bbox_loss: 0.0807  cls_loss: 1.7229  \n",
      "<<<iteration:[700/878] - total_loss: 2.1535  obj_loss: 0.1079  noobj_loss: 0.0219  bbox_loss: 0.0801  cls_loss: 1.6344  \n",
      "<<<iteration:[720/878] - total_loss: 1.7121  obj_loss: 0.1094  noobj_loss: 0.0225  bbox_loss: 0.0614  cls_loss: 1.2847  \n",
      "<<<iteration:[740/878] - total_loss: 2.2492  obj_loss: 0.1055  noobj_loss: 0.0236  bbox_loss: 0.0867  cls_loss: 1.6985  \n",
      "<<<iteration:[760/878] - total_loss: 2.1581  obj_loss: 0.1004  noobj_loss: 0.0276  bbox_loss: 0.0884  cls_loss: 1.6018  \n",
      "<<<iteration:[780/878] - total_loss: 2.3354  obj_loss: 0.1095  noobj_loss: 0.0217  bbox_loss: 0.0870  cls_loss: 1.7802  \n",
      "<<<iteration:[800/878] - total_loss: 2.0146  obj_loss: 0.1129  noobj_loss: 0.0231  bbox_loss: 0.0766  cls_loss: 1.5070  \n",
      "<<<iteration:[820/878] - total_loss: 2.2692  obj_loss: 0.1341  noobj_loss: 0.0244  bbox_loss: 0.1023  cls_loss: 1.6114  \n",
      "<<<iteration:[840/878] - total_loss: 1.9513  obj_loss: 0.1086  noobj_loss: 0.0214  bbox_loss: 0.0920  cls_loss: 1.3720  \n",
      "<<<iteration:[860/878] - total_loss: 2.1929  obj_loss: 0.1346  noobj_loss: 0.0248  bbox_loss: 0.0896  cls_loss: 1.5977  \n",
      "\n",
      "epoch:37/100 - Train Loss: 2.3026, Val Loss: 2.0569\n",
      "\n",
      "<<<iteration:[20/878] - total_loss: 2.3397  obj_loss: 0.1260  noobj_loss: 0.0263  bbox_loss: 0.1182  cls_loss: 1.6096  \n",
      "<<<iteration:[40/878] - total_loss: 1.8678  obj_loss: 0.0995  noobj_loss: 0.0234  bbox_loss: 0.0774  cls_loss: 1.3697  \n",
      "<<<iteration:[60/878] - total_loss: 1.9259  obj_loss: 0.1219  noobj_loss: 0.0243  bbox_loss: 0.0821  cls_loss: 1.3811  \n",
      "<<<iteration:[80/878] - total_loss: 1.9270  obj_loss: 0.1044  noobj_loss: 0.0225  bbox_loss: 0.0682  cls_loss: 1.4703  \n",
      "<<<iteration:[100/878] - total_loss: 1.8913  obj_loss: 0.1315  noobj_loss: 0.0278  bbox_loss: 0.0763  cls_loss: 1.3646  \n",
      "<<<iteration:[120/878] - total_loss: 1.8670  obj_loss: 0.1263  noobj_loss: 0.0311  bbox_loss: 0.0777  cls_loss: 1.3366  \n",
      "<<<iteration:[140/878] - total_loss: 1.7894  obj_loss: 0.1124  noobj_loss: 0.0261  bbox_loss: 0.0840  cls_loss: 1.2437  \n",
      "<<<iteration:[160/878] - total_loss: 2.6920  obj_loss: 0.1352  noobj_loss: 0.0232  bbox_loss: 0.1658  cls_loss: 1.7164  \n",
      "<<<iteration:[180/878] - total_loss: 2.1387  obj_loss: 0.1354  noobj_loss: 0.0290  bbox_loss: 0.1010  cls_loss: 1.4838  \n",
      "<<<iteration:[200/878] - total_loss: 1.8898  obj_loss: 0.1188  noobj_loss: 0.0246  bbox_loss: 0.0873  cls_loss: 1.3222  \n",
      "<<<iteration:[220/878] - total_loss: 1.9961  obj_loss: 0.1404  noobj_loss: 0.0253  bbox_loss: 0.0806  cls_loss: 1.4400  \n",
      "<<<iteration:[240/878] - total_loss: 1.8372  obj_loss: 0.0898  noobj_loss: 0.0239  bbox_loss: 0.0896  cls_loss: 1.2874  \n",
      "<<<iteration:[260/878] - total_loss: 2.0250  obj_loss: 0.1026  noobj_loss: 0.0256  bbox_loss: 0.1007  cls_loss: 1.4061  \n",
      "<<<iteration:[280/878] - total_loss: 1.8904  obj_loss: 0.1095  noobj_loss: 0.0221  bbox_loss: 0.0743  cls_loss: 1.3985  \n",
      "<<<iteration:[300/878] - total_loss: 2.1969  obj_loss: 0.1085  noobj_loss: 0.0311  bbox_loss: 0.0834  cls_loss: 1.6558  \n",
      "<<<iteration:[320/878] - total_loss: 1.8205  obj_loss: 0.0956  noobj_loss: 0.0215  bbox_loss: 0.0663  cls_loss: 1.3825  \n",
      "<<<iteration:[340/878] - total_loss: 2.0264  obj_loss: 0.0923  noobj_loss: 0.0277  bbox_loss: 0.1418  cls_loss: 1.2114  \n",
      "<<<iteration:[360/878] - total_loss: 1.9997  obj_loss: 0.1057  noobj_loss: 0.0221  bbox_loss: 0.1128  cls_loss: 1.3188  \n",
      "<<<iteration:[380/878] - total_loss: 1.7606  obj_loss: 0.1001  noobj_loss: 0.0232  bbox_loss: 0.0856  cls_loss: 1.2211  \n",
      "<<<iteration:[400/878] - total_loss: 1.6249  obj_loss: 0.1034  noobj_loss: 0.0226  bbox_loss: 0.0586  cls_loss: 1.2169  \n",
      "<<<iteration:[420/878] - total_loss: 1.7298  obj_loss: 0.1199  noobj_loss: 0.0417  bbox_loss: 0.0856  cls_loss: 1.1610  \n",
      "<<<iteration:[440/878] - total_loss: 1.6976  obj_loss: 0.0856  noobj_loss: 0.0211  bbox_loss: 0.0623  cls_loss: 1.2900  \n",
      "<<<iteration:[460/878] - total_loss: 1.7890  obj_loss: 0.1160  noobj_loss: 0.0215  bbox_loss: 0.0688  cls_loss: 1.3181  \n",
      "<<<iteration:[480/878] - total_loss: 2.1495  obj_loss: 0.1181  noobj_loss: 0.0303  bbox_loss: 0.1257  cls_loss: 1.3878  \n",
      "<<<iteration:[500/878] - total_loss: 2.1873  obj_loss: 0.1068  noobj_loss: 0.0261  bbox_loss: 0.1828  cls_loss: 1.1537  \n",
      "<<<iteration:[520/878] - total_loss: 2.0402  obj_loss: 0.1307  noobj_loss: 0.0261  bbox_loss: 0.1040  cls_loss: 1.3762  \n",
      "<<<iteration:[540/878] - total_loss: 1.8789  obj_loss: 0.1100  noobj_loss: 0.0286  bbox_loss: 0.1274  cls_loss: 1.1177  \n",
      "<<<iteration:[560/878] - total_loss: 1.8455  obj_loss: 0.1157  noobj_loss: 0.0208  bbox_loss: 0.0997  cls_loss: 1.2209  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<<<iteration:[580/878] - total_loss: 1.5998  obj_loss: 0.1313  noobj_loss: 0.0247  bbox_loss: 0.0676  cls_loss: 1.1180  \n",
      "<<<iteration:[600/878] - total_loss: 1.5601  obj_loss: 0.1066  noobj_loss: 0.0249  bbox_loss: 0.0610  cls_loss: 1.1359  \n",
      "<<<iteration:[620/878] - total_loss: 1.7730  obj_loss: 0.1044  noobj_loss: 0.0215  bbox_loss: 0.0857  cls_loss: 1.2293  \n",
      "<<<iteration:[640/878] - total_loss: 2.2475  obj_loss: 0.1242  noobj_loss: 0.0390  bbox_loss: 0.1915  cls_loss: 1.1465  \n",
      "<<<iteration:[660/878] - total_loss: 2.0275  obj_loss: 0.1121  noobj_loss: 0.0319  bbox_loss: 0.1266  cls_loss: 1.2665  \n",
      "<<<iteration:[680/878] - total_loss: 1.7224  obj_loss: 0.1129  noobj_loss: 0.0229  bbox_loss: 0.0689  cls_loss: 1.2538  \n",
      "<<<iteration:[700/878] - total_loss: 1.7001  obj_loss: 0.1266  noobj_loss: 0.0294  bbox_loss: 0.0909  cls_loss: 1.1045  \n",
      "<<<iteration:[720/878] - total_loss: 1.7777  obj_loss: 0.1236  noobj_loss: 0.0240  bbox_loss: 0.0867  cls_loss: 1.2085  \n",
      "<<<iteration:[740/878] - total_loss: 1.8864  obj_loss: 0.1513  noobj_loss: 0.0252  bbox_loss: 0.0771  cls_loss: 1.3371  \n",
      "<<<iteration:[760/878] - total_loss: 1.6366  obj_loss: 0.1551  noobj_loss: 0.0261  bbox_loss: 0.0766  cls_loss: 1.0856  \n",
      "<<<iteration:[780/878] - total_loss: 1.8563  obj_loss: 0.1566  noobj_loss: 0.0318  bbox_loss: 0.0928  cls_loss: 1.2198  \n",
      "<<<iteration:[800/878] - total_loss: 1.8137  obj_loss: 0.1435  noobj_loss: 0.0282  bbox_loss: 0.0824  cls_loss: 1.2438  \n",
      "<<<iteration:[820/878] - total_loss: 1.4457  obj_loss: 0.1437  noobj_loss: 0.0302  bbox_loss: 0.0744  cls_loss: 0.9148  \n",
      "<<<iteration:[840/878] - total_loss: 1.3180  obj_loss: 0.1176  noobj_loss: 0.0298  bbox_loss: 0.0673  cls_loss: 0.8489  \n",
      "<<<iteration:[860/878] - total_loss: 1.8557  obj_loss: 0.1136  noobj_loss: 0.0276  bbox_loss: 0.0970  cls_loss: 1.2434  \n",
      "\n",
      "epoch:38/100 - Train Loss: 1.8839, Val Loss: 1.6569\n",
      "\n",
      "<<<iteration:[20/878] - total_loss: 2.1611  obj_loss: 0.1231  noobj_loss: 0.0283  bbox_loss: 0.1587  cls_loss: 1.2303  \n",
      "<<<iteration:[40/878] - total_loss: 1.6450  obj_loss: 0.1011  noobj_loss: 0.0264  bbox_loss: 0.0755  cls_loss: 1.1530  \n",
      "<<<iteration:[60/878] - total_loss: 1.9862  obj_loss: 0.1461  noobj_loss: 0.0270  bbox_loss: 0.1181  cls_loss: 1.2363  \n",
      "<<<iteration:[80/878] - total_loss: 1.7367  obj_loss: 0.1101  noobj_loss: 0.0238  bbox_loss: 0.0992  cls_loss: 1.1188  \n",
      "<<<iteration:[100/878] - total_loss: 1.8235  obj_loss: 0.1354  noobj_loss: 0.0273  bbox_loss: 0.0929  cls_loss: 1.2099  \n",
      "<<<iteration:[120/878] - total_loss: 1.4927  obj_loss: 0.1412  noobj_loss: 0.0253  bbox_loss: 0.0720  cls_loss: 0.9790  \n",
      "<<<iteration:[140/878] - total_loss: 1.7023  obj_loss: 0.0983  noobj_loss: 0.0274  bbox_loss: 0.0908  cls_loss: 1.1361  \n",
      "<<<iteration:[160/878] - total_loss: 1.6273  obj_loss: 0.1256  noobj_loss: 0.0277  bbox_loss: 0.0775  cls_loss: 1.1003  \n",
      "<<<iteration:[180/878] - total_loss: 1.8697  obj_loss: 0.1431  noobj_loss: 0.0452  bbox_loss: 0.1335  cls_loss: 1.0368  \n",
      "<<<iteration:[200/878] - total_loss: 1.4747  obj_loss: 0.1038  noobj_loss: 0.0254  bbox_loss: 0.0594  cls_loss: 1.0614  \n",
      "<<<iteration:[220/878] - total_loss: 1.6826  obj_loss: 0.1350  noobj_loss: 0.0252  bbox_loss: 0.1040  cls_loss: 1.0149  \n",
      "<<<iteration:[240/878] - total_loss: 2.0606  obj_loss: 0.1073  noobj_loss: 0.0313  bbox_loss: 0.1581  cls_loss: 1.1470  \n",
      "<<<iteration:[260/878] - total_loss: 1.6952  obj_loss: 0.1257  noobj_loss: 0.0244  bbox_loss: 0.0698  cls_loss: 1.2081  \n",
      "<<<iteration:[280/878] - total_loss: 1.5125  obj_loss: 0.1243  noobj_loss: 0.0256  bbox_loss: 0.0896  cls_loss: 0.9272  \n",
      "<<<iteration:[300/878] - total_loss: 1.7272  obj_loss: 0.1560  noobj_loss: 0.0310  bbox_loss: 0.1182  cls_loss: 0.9647  \n",
      "<<<iteration:[320/878] - total_loss: 1.5288  obj_loss: 0.1274  noobj_loss: 0.0270  bbox_loss: 0.0823  cls_loss: 0.9764  \n",
      "<<<iteration:[340/878] - total_loss: 1.4943  obj_loss: 0.1278  noobj_loss: 0.0256  bbox_loss: 0.0730  cls_loss: 0.9887  \n",
      "<<<iteration:[360/878] - total_loss: 1.6359  obj_loss: 0.1465  noobj_loss: 0.0348  bbox_loss: 0.0670  cls_loss: 1.1368  \n",
      "<<<iteration:[380/878] - total_loss: 1.8533  obj_loss: 0.1063  noobj_loss: 0.0223  bbox_loss: 0.1361  cls_loss: 1.0553  \n",
      "<<<iteration:[400/878] - total_loss: 1.8779  obj_loss: 0.1461  noobj_loss: 0.0254  bbox_loss: 0.1519  cls_loss: 0.9598  \n",
      "<<<iteration:[420/878] - total_loss: 1.5502  obj_loss: 0.1113  noobj_loss: 0.0285  bbox_loss: 0.0794  cls_loss: 1.0279  \n",
      "<<<iteration:[440/878] - total_loss: 1.7420  obj_loss: 0.1036  noobj_loss: 0.0286  bbox_loss: 0.1154  cls_loss: 1.0471  \n",
      "<<<iteration:[460/878] - total_loss: 1.8113  obj_loss: 0.1168  noobj_loss: 0.0271  bbox_loss: 0.0813  cls_loss: 1.2742  \n",
      "<<<iteration:[480/878] - total_loss: 1.4003  obj_loss: 0.1352  noobj_loss: 0.0298  bbox_loss: 0.0701  cls_loss: 0.8997  \n",
      "<<<iteration:[500/878] - total_loss: 1.5451  obj_loss: 0.1084  noobj_loss: 0.0251  bbox_loss: 0.0723  cls_loss: 1.0625  \n",
      "<<<iteration:[520/878] - total_loss: 1.6770  obj_loss: 0.1414  noobj_loss: 0.0292  bbox_loss: 0.0684  cls_loss: 1.1789  \n",
      "<<<iteration:[540/878] - total_loss: 1.5464  obj_loss: 0.1330  noobj_loss: 0.0280  bbox_loss: 0.0780  cls_loss: 1.0093  \n",
      "<<<iteration:[560/878] - total_loss: 1.6948  obj_loss: 0.1639  noobj_loss: 0.0354  bbox_loss: 0.0896  cls_loss: 1.0651  \n",
      "<<<iteration:[580/878] - total_loss: 1.4480  obj_loss: 0.1175  noobj_loss: 0.0248  bbox_loss: 0.0651  cls_loss: 0.9927  \n",
      "<<<iteration:[600/878] - total_loss: 1.6064  obj_loss: 0.1546  noobj_loss: 0.0288  bbox_loss: 0.0821  cls_loss: 1.0270  \n",
      "<<<iteration:[620/878] - total_loss: 1.5263  obj_loss: 0.1233  noobj_loss: 0.0293  bbox_loss: 0.0667  cls_loss: 1.0550  \n",
      "<<<iteration:[640/878] - total_loss: 1.6507  obj_loss: 0.1678  noobj_loss: 0.0330  bbox_loss: 0.0952  cls_loss: 0.9903  \n",
      "<<<iteration:[660/878] - total_loss: 1.5206  obj_loss: 0.1296  noobj_loss: 0.0318  bbox_loss: 0.0758  cls_loss: 0.9959  \n",
      "<<<iteration:[680/878] - total_loss: 1.2770  obj_loss: 0.0954  noobj_loss: 0.0247  bbox_loss: 0.0657  cls_loss: 0.8407  \n",
      "<<<iteration:[700/878] - total_loss: 1.8298  obj_loss: 0.1241  noobj_loss: 0.0282  bbox_loss: 0.0997  cls_loss: 1.1929  \n",
      "<<<iteration:[720/878] - total_loss: 1.5852  obj_loss: 0.1328  noobj_loss: 0.0282  bbox_loss: 0.0841  cls_loss: 1.0177  \n",
      "<<<iteration:[740/878] - total_loss: 1.5322  obj_loss: 0.1238  noobj_loss: 0.0348  bbox_loss: 0.0761  cls_loss: 1.0107  \n",
      "<<<iteration:[760/878] - total_loss: 1.6363  obj_loss: 0.1565  noobj_loss: 0.0290  bbox_loss: 0.0689  cls_loss: 1.1208  \n",
      "<<<iteration:[780/878] - total_loss: 1.5189  obj_loss: 0.1374  noobj_loss: 0.0281  bbox_loss: 0.0664  cls_loss: 1.0356  \n",
      "<<<iteration:[800/878] - total_loss: 1.5047  obj_loss: 0.1098  noobj_loss: 0.0275  bbox_loss: 0.0677  cls_loss: 1.0428  \n",
      "<<<iteration:[820/878] - total_loss: 1.3878  obj_loss: 0.1101  noobj_loss: 0.0231  bbox_loss: 0.0504  cls_loss: 1.0140  \n",
      "<<<iteration:[840/878] - total_loss: 1.4501  obj_loss: 0.1197  noobj_loss: 0.0270  bbox_loss: 0.0699  cls_loss: 0.9673  \n",
      "<<<iteration:[860/878] - total_loss: 1.4010  obj_loss: 0.1373  noobj_loss: 0.0290  bbox_loss: 0.0688  cls_loss: 0.9051  \n",
      "\n",
      "epoch:39/100 - Train Loss: 1.6302, Val Loss: 1.4265\n",
      "\n",
      "<<<iteration:[20/878] - total_loss: 1.6106  obj_loss: 0.1358  noobj_loss: 0.0253  bbox_loss: 0.0602  cls_loss: 1.1611  \n",
      "<<<iteration:[40/878] - total_loss: 1.4390  obj_loss: 0.1120  noobj_loss: 0.0318  bbox_loss: 0.0736  cls_loss: 0.9430  \n",
      "<<<iteration:[60/878] - total_loss: 1.5069  obj_loss: 0.1428  noobj_loss: 0.0299  bbox_loss: 0.0701  cls_loss: 0.9987  \n",
      "<<<iteration:[80/878] - total_loss: 1.5945  obj_loss: 0.1315  noobj_loss: 0.0321  bbox_loss: 0.0957  cls_loss: 0.9687  \n",
      "<<<iteration:[100/878] - total_loss: 1.3483  obj_loss: 0.1423  noobj_loss: 0.0258  bbox_loss: 0.0752  cls_loss: 0.8172  \n",
      "<<<iteration:[120/878] - total_loss: 1.8858  obj_loss: 0.1219  noobj_loss: 0.0258  bbox_loss: 0.1800  cls_loss: 0.8511  \n",
      "<<<iteration:[140/878] - total_loss: 1.5757  obj_loss: 0.1211  noobj_loss: 0.0311  bbox_loss: 0.1024  cls_loss: 0.9269  \n",
      "<<<iteration:[160/878] - total_loss: 1.2853  obj_loss: 0.1666  noobj_loss: 0.0323  bbox_loss: 0.0657  cls_loss: 0.7740  \n",
      "<<<iteration:[180/878] - total_loss: 1.4748  obj_loss: 0.1326  noobj_loss: 0.0293  bbox_loss: 0.0652  cls_loss: 1.0014  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<<<iteration:[200/878] - total_loss: 1.3024  obj_loss: 0.1359  noobj_loss: 0.0297  bbox_loss: 0.0708  cls_loss: 0.7976  \n",
      "<<<iteration:[220/878] - total_loss: 1.4533  obj_loss: 0.1396  noobj_loss: 0.0277  bbox_loss: 0.0771  cls_loss: 0.9144  \n",
      "<<<iteration:[240/878] - total_loss: 1.6071  obj_loss: 0.1418  noobj_loss: 0.0279  bbox_loss: 0.0662  cls_loss: 1.1205  \n",
      "<<<iteration:[260/878] - total_loss: 1.4942  obj_loss: 0.1213  noobj_loss: 0.0284  bbox_loss: 0.0740  cls_loss: 0.9888  \n",
      "<<<iteration:[280/878] - total_loss: 1.4305  obj_loss: 0.1705  noobj_loss: 0.0302  bbox_loss: 0.0638  cls_loss: 0.9258  \n",
      "<<<iteration:[300/878] - total_loss: 1.2589  obj_loss: 0.1329  noobj_loss: 0.0287  bbox_loss: 0.0779  cls_loss: 0.7222  \n",
      "<<<iteration:[320/878] - total_loss: 1.3448  obj_loss: 0.1267  noobj_loss: 0.0228  bbox_loss: 0.0614  cls_loss: 0.8995  \n",
      "<<<iteration:[340/878] - total_loss: 1.3240  obj_loss: 0.1190  noobj_loss: 0.0291  bbox_loss: 0.0791  cls_loss: 0.7950  \n",
      "<<<iteration:[360/878] - total_loss: 1.2859  obj_loss: 0.1142  noobj_loss: 0.0252  bbox_loss: 0.0559  cls_loss: 0.8795  \n",
      "<<<iteration:[380/878] - total_loss: 1.3213  obj_loss: 0.1236  noobj_loss: 0.0260  bbox_loss: 0.0585  cls_loss: 0.8923  \n",
      "<<<iteration:[400/878] - total_loss: 1.3415  obj_loss: 0.1400  noobj_loss: 0.0279  bbox_loss: 0.0628  cls_loss: 0.8737  \n",
      "<<<iteration:[420/878] - total_loss: 1.4457  obj_loss: 0.1674  noobj_loss: 0.0311  bbox_loss: 0.0731  cls_loss: 0.8975  \n",
      "<<<iteration:[440/878] - total_loss: 1.4031  obj_loss: 0.1576  noobj_loss: 0.0303  bbox_loss: 0.0572  cls_loss: 0.9446  \n",
      "<<<iteration:[460/878] - total_loss: 1.2811  obj_loss: 0.1681  noobj_loss: 0.0316  bbox_loss: 0.0681  cls_loss: 0.7569  \n",
      "<<<iteration:[480/878] - total_loss: 1.3146  obj_loss: 0.1483  noobj_loss: 0.0365  bbox_loss: 0.0664  cls_loss: 0.8161  \n",
      "<<<iteration:[500/878] - total_loss: 1.5636  obj_loss: 0.1631  noobj_loss: 0.0312  bbox_loss: 0.0873  cls_loss: 0.9483  \n",
      "<<<iteration:[520/878] - total_loss: 1.3635  obj_loss: 0.1198  noobj_loss: 0.0284  bbox_loss: 0.0691  cls_loss: 0.8842  \n",
      "<<<iteration:[540/878] - total_loss: 1.3170  obj_loss: 0.1338  noobj_loss: 0.0284  bbox_loss: 0.0583  cls_loss: 0.8777  \n",
      "<<<iteration:[560/878] - total_loss: 1.4116  obj_loss: 0.1068  noobj_loss: 0.0291  bbox_loss: 0.0755  cls_loss: 0.9127  \n",
      "<<<iteration:[580/878] - total_loss: 1.2036  obj_loss: 0.1206  noobj_loss: 0.0254  bbox_loss: 0.0597  cls_loss: 0.7720  \n",
      "<<<iteration:[600/878] - total_loss: 1.3920  obj_loss: 0.1407  noobj_loss: 0.0274  bbox_loss: 0.0672  cls_loss: 0.9016  \n",
      "<<<iteration:[620/878] - total_loss: 1.4547  obj_loss: 0.1152  noobj_loss: 0.0330  bbox_loss: 0.0627  cls_loss: 1.0093  \n",
      "<<<iteration:[640/878] - total_loss: 1.5314  obj_loss: 0.1536  noobj_loss: 0.0332  bbox_loss: 0.0847  cls_loss: 0.9375  \n",
      "<<<iteration:[660/878] - total_loss: 1.3994  obj_loss: 0.1348  noobj_loss: 0.0292  bbox_loss: 0.0609  cls_loss: 0.9455  \n",
      "<<<iteration:[680/878] - total_loss: 1.4869  obj_loss: 0.1578  noobj_loss: 0.0298  bbox_loss: 0.0649  cls_loss: 0.9896  \n",
      "<<<iteration:[700/878] - total_loss: 1.3764  obj_loss: 0.1611  noobj_loss: 0.0327  bbox_loss: 0.0660  cls_loss: 0.8691  \n",
      "<<<iteration:[720/878] - total_loss: 1.2575  obj_loss: 0.1486  noobj_loss: 0.0294  bbox_loss: 0.0657  cls_loss: 0.7657  \n",
      "<<<iteration:[740/878] - total_loss: 1.1377  obj_loss: 0.1353  noobj_loss: 0.0264  bbox_loss: 0.0560  cls_loss: 0.7092  \n",
      "<<<iteration:[760/878] - total_loss: 1.3211  obj_loss: 0.1269  noobj_loss: 0.0296  bbox_loss: 0.0717  cls_loss: 0.8211  \n",
      "<<<iteration:[780/878] - total_loss: 1.3413  obj_loss: 0.1519  noobj_loss: 0.0320  bbox_loss: 0.0839  cls_loss: 0.7539  \n",
      "<<<iteration:[800/878] - total_loss: 1.2898  obj_loss: 0.1514  noobj_loss: 0.0294  bbox_loss: 0.0610  cls_loss: 0.8189  \n",
      "<<<iteration:[820/878] - total_loss: 1.3188  obj_loss: 0.1262  noobj_loss: 0.0269  bbox_loss: 0.0691  cls_loss: 0.8335  \n",
      "<<<iteration:[840/878] - total_loss: 1.2944  obj_loss: 0.1468  noobj_loss: 0.0311  bbox_loss: 0.0620  cls_loss: 0.8218  \n",
      "<<<iteration:[860/878] - total_loss: 1.6860  obj_loss: 0.1289  noobj_loss: 0.0282  bbox_loss: 0.1296  cls_loss: 0.8951  \n",
      "\n",
      "epoch:40/100 - Train Loss: 1.4041, Val Loss: 1.3402\n",
      "\n",
      "<<<iteration:[20/878] - total_loss: 1.4842  obj_loss: 0.1578  noobj_loss: 0.0274  bbox_loss: 0.0772  cls_loss: 0.9267  \n",
      "<<<iteration:[40/878] - total_loss: 1.3093  obj_loss: 0.1402  noobj_loss: 0.0293  bbox_loss: 0.0789  cls_loss: 0.7599  \n",
      "<<<iteration:[60/878] - total_loss: 1.1972  obj_loss: 0.1165  noobj_loss: 0.0263  bbox_loss: 0.0645  cls_loss: 0.7448  \n",
      "<<<iteration:[80/878] - total_loss: 1.4094  obj_loss: 0.1136  noobj_loss: 0.0261  bbox_loss: 0.0935  cls_loss: 0.8154  \n",
      "<<<iteration:[100/878] - total_loss: 1.3251  obj_loss: 0.1387  noobj_loss: 0.0295  bbox_loss: 0.0653  cls_loss: 0.8449  \n",
      "<<<iteration:[120/878] - total_loss: 1.1830  obj_loss: 0.1298  noobj_loss: 0.0311  bbox_loss: 0.0585  cls_loss: 0.7449  \n",
      "<<<iteration:[140/878] - total_loss: 1.1734  obj_loss: 0.1365  noobj_loss: 0.0285  bbox_loss: 0.0635  cls_loss: 0.7051  \n",
      "<<<iteration:[160/878] - total_loss: 1.3947  obj_loss: 0.1522  noobj_loss: 0.0291  bbox_loss: 0.0830  cls_loss: 0.8129  \n",
      "<<<iteration:[180/878] - total_loss: 1.5469  obj_loss: 0.1550  noobj_loss: 0.0320  bbox_loss: 0.0931  cls_loss: 0.9104  \n",
      "<<<iteration:[200/878] - total_loss: 1.3019  obj_loss: 0.1320  noobj_loss: 0.0299  bbox_loss: 0.0670  cls_loss: 0.8201  \n",
      "<<<iteration:[220/878] - total_loss: 1.3729  obj_loss: 0.1587  noobj_loss: 0.0274  bbox_loss: 0.0543  cls_loss: 0.9290  \n",
      "<<<iteration:[240/878] - total_loss: 1.2704  obj_loss: 0.1281  noobj_loss: 0.0273  bbox_loss: 0.0610  cls_loss: 0.8236  \n",
      "<<<iteration:[260/878] - total_loss: 1.2305  obj_loss: 0.1449  noobj_loss: 0.0341  bbox_loss: 0.0661  cls_loss: 0.7381  \n",
      "<<<iteration:[280/878] - total_loss: 1.2965  obj_loss: 0.1429  noobj_loss: 0.0299  bbox_loss: 0.0661  cls_loss: 0.8083  \n",
      "<<<iteration:[300/878] - total_loss: 1.2283  obj_loss: 0.1251  noobj_loss: 0.0287  bbox_loss: 0.0566  cls_loss: 0.8057  \n",
      "<<<iteration:[320/878] - total_loss: 1.1627  obj_loss: 0.1666  noobj_loss: 0.0309  bbox_loss: 0.0613  cls_loss: 0.6740  \n",
      "<<<iteration:[340/878] - total_loss: 1.2837  obj_loss: 0.1631  noobj_loss: 0.0406  bbox_loss: 0.0832  cls_loss: 0.6844  \n",
      "<<<iteration:[360/878] - total_loss: 1.0540  obj_loss: 0.1379  noobj_loss: 0.0305  bbox_loss: 0.0565  cls_loss: 0.6182  \n",
      "<<<iteration:[380/878] - total_loss: 1.6112  obj_loss: 0.1591  noobj_loss: 0.0306  bbox_loss: 0.0936  cls_loss: 0.9686  \n",
      "<<<iteration:[400/878] - total_loss: 1.3336  obj_loss: 0.1399  noobj_loss: 0.0269  bbox_loss: 0.0974  cls_loss: 0.6932  \n",
      "<<<iteration:[420/878] - total_loss: 1.3800  obj_loss: 0.1647  noobj_loss: 0.0279  bbox_loss: 0.0555  cls_loss: 0.9238  \n",
      "<<<iteration:[440/878] - total_loss: 1.4995  obj_loss: 0.1466  noobj_loss: 0.0355  bbox_loss: 0.0913  cls_loss: 0.8788  \n",
      "<<<iteration:[460/878] - total_loss: 1.4551  obj_loss: 0.1729  noobj_loss: 0.0359  bbox_loss: 0.0783  cls_loss: 0.8727  \n",
      "<<<iteration:[480/878] - total_loss: 1.3972  obj_loss: 0.1329  noobj_loss: 0.0314  bbox_loss: 0.0862  cls_loss: 0.8178  \n",
      "<<<iteration:[500/878] - total_loss: 1.0986  obj_loss: 0.1227  noobj_loss: 0.0267  bbox_loss: 0.0732  cls_loss: 0.5965  \n",
      "<<<iteration:[520/878] - total_loss: 1.2678  obj_loss: 0.1556  noobj_loss: 0.0288  bbox_loss: 0.0566  cls_loss: 0.8149  \n",
      "<<<iteration:[540/878] - total_loss: 1.4064  obj_loss: 0.1630  noobj_loss: 0.0341  bbox_loss: 0.0667  cls_loss: 0.8928  \n",
      "<<<iteration:[560/878] - total_loss: 1.4378  obj_loss: 0.1316  noobj_loss: 0.0401  bbox_loss: 0.1058  cls_loss: 0.7573  \n",
      "<<<iteration:[580/878] - total_loss: 1.4428  obj_loss: 0.1472  noobj_loss: 0.0318  bbox_loss: 0.0831  cls_loss: 0.8643  \n",
      "<<<iteration:[600/878] - total_loss: 1.4974  obj_loss: 0.1559  noobj_loss: 0.0305  bbox_loss: 0.0766  cls_loss: 0.9433  \n",
      "<<<iteration:[620/878] - total_loss: 1.1684  obj_loss: 0.1519  noobj_loss: 0.0292  bbox_loss: 0.0566  cls_loss: 0.7187  \n",
      "<<<iteration:[640/878] - total_loss: 1.1457  obj_loss: 0.1387  noobj_loss: 0.0323  bbox_loss: 0.0592  cls_loss: 0.6951  \n",
      "<<<iteration:[660/878] - total_loss: 1.4335  obj_loss: 0.1706  noobj_loss: 0.0378  bbox_loss: 0.0952  cls_loss: 0.7678  \n",
      "<<<iteration:[680/878] - total_loss: 1.5683  obj_loss: 0.1671  noobj_loss: 0.0330  bbox_loss: 0.0926  cls_loss: 0.9220  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<<<iteration:[700/878] - total_loss: 1.1550  obj_loss: 0.1566  noobj_loss: 0.0318  bbox_loss: 0.0562  cls_loss: 0.7013  \n",
      "<<<iteration:[720/878] - total_loss: 1.1222  obj_loss: 0.1101  noobj_loss: 0.0275  bbox_loss: 0.0604  cls_loss: 0.6966  \n",
      "<<<iteration:[740/878] - total_loss: 1.1318  obj_loss: 0.1328  noobj_loss: 0.0302  bbox_loss: 0.0627  cls_loss: 0.6702  \n",
      "<<<iteration:[760/878] - total_loss: 1.0296  obj_loss: 0.1464  noobj_loss: 0.0297  bbox_loss: 0.0529  cls_loss: 0.6040  \n",
      "<<<iteration:[780/878] - total_loss: 1.3554  obj_loss: 0.1493  noobj_loss: 0.0322  bbox_loss: 0.0871  cls_loss: 0.7544  \n",
      "<<<iteration:[800/878] - total_loss: 1.2754  obj_loss: 0.1633  noobj_loss: 0.0352  bbox_loss: 0.0634  cls_loss: 0.7776  \n",
      "<<<iteration:[820/878] - total_loss: 1.3155  obj_loss: 0.1489  noobj_loss: 0.0305  bbox_loss: 0.0649  cls_loss: 0.8270  \n",
      "<<<iteration:[840/878] - total_loss: 1.1828  obj_loss: 0.1659  noobj_loss: 0.0313  bbox_loss: 0.0648  cls_loss: 0.6774  \n",
      "<<<iteration:[860/878] - total_loss: 1.1647  obj_loss: 0.1391  noobj_loss: 0.0306  bbox_loss: 0.0675  cls_loss: 0.6728  \n",
      "\n",
      "epoch:41/100 - Train Loss: 1.3020, Val Loss: 1.3129\n",
      "\n",
      "<<<iteration:[20/878] - total_loss: 1.3869  obj_loss: 0.1421  noobj_loss: 0.0334  bbox_loss: 0.0829  cls_loss: 0.8135  \n",
      "<<<iteration:[40/878] - total_loss: 1.1643  obj_loss: 0.1341  noobj_loss: 0.0296  bbox_loss: 0.0474  cls_loss: 0.7782  \n",
      "<<<iteration:[60/878] - total_loss: 1.1978  obj_loss: 0.1540  noobj_loss: 0.0330  bbox_loss: 0.0499  cls_loss: 0.7779  \n",
      "<<<iteration:[80/878] - total_loss: 1.0686  obj_loss: 0.1462  noobj_loss: 0.0297  bbox_loss: 0.0545  cls_loss: 0.6351  \n",
      "<<<iteration:[100/878] - total_loss: 1.1267  obj_loss: 0.1433  noobj_loss: 0.0295  bbox_loss: 0.0583  cls_loss: 0.6769  \n",
      "<<<iteration:[120/878] - total_loss: 1.1103  obj_loss: 0.1438  noobj_loss: 0.0332  bbox_loss: 0.0665  cls_loss: 0.6176  \n",
      "<<<iteration:[140/878] - total_loss: 1.3460  obj_loss: 0.1311  noobj_loss: 0.0335  bbox_loss: 0.0740  cls_loss: 0.8280  \n",
      "<<<iteration:[160/878] - total_loss: 1.0590  obj_loss: 0.1607  noobj_loss: 0.0390  bbox_loss: 0.0578  cls_loss: 0.5897  \n",
      "<<<iteration:[180/878] - total_loss: 1.1902  obj_loss: 0.1450  noobj_loss: 0.0276  bbox_loss: 0.0508  cls_loss: 0.7776  \n",
      "<<<iteration:[200/878] - total_loss: 1.2892  obj_loss: 0.1655  noobj_loss: 0.0375  bbox_loss: 0.0743  cls_loss: 0.7337  \n",
      "<<<iteration:[220/878] - total_loss: 1.2856  obj_loss: 0.1611  noobj_loss: 0.0337  bbox_loss: 0.0652  cls_loss: 0.7815  \n",
      "<<<iteration:[240/878] - total_loss: 1.0484  obj_loss: 0.1358  noobj_loss: 0.0302  bbox_loss: 0.0625  cls_loss: 0.5850  \n",
      "<<<iteration:[260/878] - total_loss: 1.3709  obj_loss: 0.1337  noobj_loss: 0.0315  bbox_loss: 0.0877  cls_loss: 0.7829  \n",
      "<<<iteration:[280/878] - total_loss: 1.0895  obj_loss: 0.1397  noobj_loss: 0.0298  bbox_loss: 0.0562  cls_loss: 0.6539  \n",
      "<<<iteration:[300/878] - total_loss: 1.3609  obj_loss: 0.1655  noobj_loss: 0.0301  bbox_loss: 0.0829  cls_loss: 0.7657  \n",
      "<<<iteration:[320/878] - total_loss: 1.0910  obj_loss: 0.1387  noobj_loss: 0.0319  bbox_loss: 0.0562  cls_loss: 0.6554  \n",
      "<<<iteration:[340/878] - total_loss: 1.0987  obj_loss: 0.1518  noobj_loss: 0.0341  bbox_loss: 0.0603  cls_loss: 0.6283  \n",
      "<<<iteration:[360/878] - total_loss: 1.0579  obj_loss: 0.1599  noobj_loss: 0.0323  bbox_loss: 0.0544  cls_loss: 0.6097  \n",
      "<<<iteration:[380/878] - total_loss: 2.0080  obj_loss: 0.1380  noobj_loss: 0.0547  bbox_loss: 0.2027  cls_loss: 0.8289  \n",
      "<<<iteration:[400/878] - total_loss: 1.2032  obj_loss: 0.1421  noobj_loss: 0.0284  bbox_loss: 0.0810  cls_loss: 0.6418  \n",
      "<<<iteration:[420/878] - total_loss: 1.1439  obj_loss: 0.1677  noobj_loss: 0.0291  bbox_loss: 0.0491  cls_loss: 0.7161  \n",
      "<<<iteration:[440/878] - total_loss: 1.2423  obj_loss: 0.1596  noobj_loss: 0.0325  bbox_loss: 0.0670  cls_loss: 0.7312  \n",
      "<<<iteration:[460/878] - total_loss: 1.4468  obj_loss: 0.1617  noobj_loss: 0.0360  bbox_loss: 0.1177  cls_loss: 0.6787  \n",
      "<<<iteration:[480/878] - total_loss: 1.2400  obj_loss: 0.1584  noobj_loss: 0.0326  bbox_loss: 0.0685  cls_loss: 0.7227  \n",
      "<<<iteration:[500/878] - total_loss: 1.1899  obj_loss: 0.1552  noobj_loss: 0.0328  bbox_loss: 0.0679  cls_loss: 0.6789  \n",
      "<<<iteration:[520/878] - total_loss: 1.0444  obj_loss: 0.1217  noobj_loss: 0.0316  bbox_loss: 0.0562  cls_loss: 0.6262  \n",
      "<<<iteration:[540/878] - total_loss: 1.1479  obj_loss: 0.1502  noobj_loss: 0.0328  bbox_loss: 0.0587  cls_loss: 0.6881  \n",
      "<<<iteration:[560/878] - total_loss: 1.1581  obj_loss: 0.1212  noobj_loss: 0.0315  bbox_loss: 0.0678  cls_loss: 0.6822  \n",
      "<<<iteration:[580/878] - total_loss: 1.3203  obj_loss: 0.1523  noobj_loss: 0.0332  bbox_loss: 0.0766  cls_loss: 0.7685  \n",
      "<<<iteration:[600/878] - total_loss: 1.2785  obj_loss: 0.1623  noobj_loss: 0.0316  bbox_loss: 0.0578  cls_loss: 0.8113  \n",
      "<<<iteration:[620/878] - total_loss: 1.2335  obj_loss: 0.1521  noobj_loss: 0.0328  bbox_loss: 0.0683  cls_loss: 0.7234  \n",
      "<<<iteration:[640/878] - total_loss: 1.3307  obj_loss: 0.1382  noobj_loss: 0.0389  bbox_loss: 0.0773  cls_loss: 0.7865  \n",
      "<<<iteration:[660/878] - total_loss: 0.9360  obj_loss: 0.1066  noobj_loss: 0.0290  bbox_loss: 0.0516  cls_loss: 0.5567  \n",
      "<<<iteration:[680/878] - total_loss: 1.6503  obj_loss: 0.1766  noobj_loss: 0.0425  bbox_loss: 0.1350  cls_loss: 0.7775  \n",
      "<<<iteration:[700/878] - total_loss: 1.8600  obj_loss: 0.1294  noobj_loss: 0.0379  bbox_loss: 0.1879  cls_loss: 0.7721  \n",
      "<<<iteration:[720/878] - total_loss: 1.2967  obj_loss: 0.1592  noobj_loss: 0.0325  bbox_loss: 0.0908  cls_loss: 0.6672  \n",
      "<<<iteration:[740/878] - total_loss: 1.1432  obj_loss: 0.1523  noobj_loss: 0.0317  bbox_loss: 0.0613  cls_loss: 0.6684  \n",
      "<<<iteration:[760/878] - total_loss: 1.0425  obj_loss: 0.1689  noobj_loss: 0.0318  bbox_loss: 0.0583  cls_loss: 0.5663  \n",
      "<<<iteration:[780/878] - total_loss: 1.2560  obj_loss: 0.1845  noobj_loss: 0.0416  bbox_loss: 0.0750  cls_loss: 0.6755  \n",
      "<<<iteration:[800/878] - total_loss: 1.1686  obj_loss: 0.1556  noobj_loss: 0.0384  bbox_loss: 0.0784  cls_loss: 0.6020  \n",
      "<<<iteration:[820/878] - total_loss: 1.2116  obj_loss: 0.1500  noobj_loss: 0.0375  bbox_loss: 0.0681  cls_loss: 0.7024  \n",
      "<<<iteration:[840/878] - total_loss: 1.1669  obj_loss: 0.1586  noobj_loss: 0.0357  bbox_loss: 0.0569  cls_loss: 0.7061  \n",
      "<<<iteration:[860/878] - total_loss: 1.1853  obj_loss: 0.1570  noobj_loss: 0.0397  bbox_loss: 0.0627  cls_loss: 0.6950  \n",
      "\n",
      "epoch:42/100 - Train Loss: 1.2332, Val Loss: 1.2897\n",
      "\n",
      "<<<iteration:[20/878] - total_loss: 1.0071  obj_loss: 0.1653  noobj_loss: 0.0340  bbox_loss: 0.0558  cls_loss: 0.5457  \n",
      "<<<iteration:[40/878] - total_loss: 1.3064  obj_loss: 0.1778  noobj_loss: 0.0327  bbox_loss: 0.0616  cls_loss: 0.8043  \n",
      "<<<iteration:[60/878] - total_loss: 1.1110  obj_loss: 0.1563  noobj_loss: 0.0384  bbox_loss: 0.0538  cls_loss: 0.6665  \n",
      "<<<iteration:[80/878] - total_loss: 1.1694  obj_loss: 0.1495  noobj_loss: 0.0317  bbox_loss: 0.0511  cls_loss: 0.7483  \n",
      "<<<iteration:[100/878] - total_loss: 1.3751  obj_loss: 0.1561  noobj_loss: 0.0422  bbox_loss: 0.1250  cls_loss: 0.5729  \n",
      "<<<iteration:[120/878] - total_loss: 1.4915  obj_loss: 0.1848  noobj_loss: 0.0345  bbox_loss: 0.0967  cls_loss: 0.8060  \n",
      "<<<iteration:[140/878] - total_loss: 1.1289  obj_loss: 0.1496  noobj_loss: 0.0356  bbox_loss: 0.0645  cls_loss: 0.6391  \n",
      "<<<iteration:[160/878] - total_loss: 1.0033  obj_loss: 0.1542  noobj_loss: 0.0336  bbox_loss: 0.0653  cls_loss: 0.5057  \n",
      "<<<iteration:[180/878] - total_loss: 1.1415  obj_loss: 0.1338  noobj_loss: 0.0290  bbox_loss: 0.0539  cls_loss: 0.7238  \n",
      "<<<iteration:[200/878] - total_loss: 1.1791  obj_loss: 0.1415  noobj_loss: 0.0339  bbox_loss: 0.0734  cls_loss: 0.6534  \n",
      "<<<iteration:[220/878] - total_loss: 1.1197  obj_loss: 0.1348  noobj_loss: 0.0302  bbox_loss: 0.0520  cls_loss: 0.7099  \n",
      "<<<iteration:[240/878] - total_loss: 1.0393  obj_loss: 0.1732  noobj_loss: 0.0324  bbox_loss: 0.0546  cls_loss: 0.5770  \n",
      "<<<iteration:[260/878] - total_loss: 1.3119  obj_loss: 0.1667  noobj_loss: 0.0368  bbox_loss: 0.0757  cls_loss: 0.7483  \n",
      "<<<iteration:[280/878] - total_loss: 1.2711  obj_loss: 0.1473  noobj_loss: 0.0464  bbox_loss: 0.0711  cls_loss: 0.7452  \n",
      "<<<iteration:[300/878] - total_loss: 1.1930  obj_loss: 0.1572  noobj_loss: 0.0346  bbox_loss: 0.0626  cls_loss: 0.7055  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<<<iteration:[320/878] - total_loss: 1.1734  obj_loss: 0.1811  noobj_loss: 0.0346  bbox_loss: 0.0576  cls_loss: 0.6870  \n",
      "<<<iteration:[340/878] - total_loss: 1.0097  obj_loss: 0.1480  noobj_loss: 0.0364  bbox_loss: 0.0597  cls_loss: 0.5450  \n",
      "<<<iteration:[360/878] - total_loss: 1.2835  obj_loss: 0.1874  noobj_loss: 0.0372  bbox_loss: 0.0688  cls_loss: 0.7334  \n",
      "<<<iteration:[380/878] - total_loss: 1.1844  obj_loss: 0.1491  noobj_loss: 0.0349  bbox_loss: 0.0573  cls_loss: 0.7315  \n",
      "<<<iteration:[400/878] - total_loss: 1.0820  obj_loss: 0.1841  noobj_loss: 0.0401  bbox_loss: 0.0597  cls_loss: 0.5793  \n",
      "<<<iteration:[420/878] - total_loss: 1.0386  obj_loss: 0.1783  noobj_loss: 0.0377  bbox_loss: 0.0648  cls_loss: 0.5172  \n",
      "<<<iteration:[440/878] - total_loss: 0.9284  obj_loss: 0.1411  noobj_loss: 0.0363  bbox_loss: 0.0438  cls_loss: 0.5503  \n",
      "<<<iteration:[460/878] - total_loss: 1.0099  obj_loss: 0.1616  noobj_loss: 0.0295  bbox_loss: 0.0575  cls_loss: 0.5459  \n",
      "<<<iteration:[480/878] - total_loss: 1.0660  obj_loss: 0.1483  noobj_loss: 0.0340  bbox_loss: 0.0618  cls_loss: 0.5919  \n",
      "<<<iteration:[500/878] - total_loss: 1.0156  obj_loss: 0.1525  noobj_loss: 0.0334  bbox_loss: 0.0493  cls_loss: 0.6000  \n",
      "<<<iteration:[520/878] - total_loss: 1.1380  obj_loss: 0.1526  noobj_loss: 0.0337  bbox_loss: 0.0595  cls_loss: 0.6712  \n",
      "<<<iteration:[540/878] - total_loss: 1.3332  obj_loss: 0.2009  noobj_loss: 0.0400  bbox_loss: 0.0692  cls_loss: 0.7662  \n",
      "<<<iteration:[560/878] - total_loss: 1.0628  obj_loss: 0.1421  noobj_loss: 0.0479  bbox_loss: 0.0656  cls_loss: 0.5687  \n",
      "<<<iteration:[580/878] - total_loss: 1.0312  obj_loss: 0.1687  noobj_loss: 0.0387  bbox_loss: 0.0541  cls_loss: 0.5728  \n",
      "<<<iteration:[600/878] - total_loss: 0.9655  obj_loss: 0.1560  noobj_loss: 0.0340  bbox_loss: 0.0564  cls_loss: 0.5104  \n",
      "<<<iteration:[620/878] - total_loss: 1.2823  obj_loss: 0.1388  noobj_loss: 0.0365  bbox_loss: 0.0805  cls_loss: 0.7230  \n",
      "<<<iteration:[640/878] - total_loss: 1.0763  obj_loss: 0.1621  noobj_loss: 0.0380  bbox_loss: 0.0687  cls_loss: 0.5519  \n",
      "<<<iteration:[660/878] - total_loss: 1.4261  obj_loss: 0.1750  noobj_loss: 0.0346  bbox_loss: 0.1119  cls_loss: 0.6745  \n",
      "<<<iteration:[680/878] - total_loss: 1.5436  obj_loss: 0.1584  noobj_loss: 0.0342  bbox_loss: 0.1273  cls_loss: 0.7316  \n",
      "<<<iteration:[700/878] - total_loss: 1.0893  obj_loss: 0.1656  noobj_loss: 0.0346  bbox_loss: 0.0639  cls_loss: 0.5869  \n",
      "<<<iteration:[720/878] - total_loss: 1.0210  obj_loss: 0.1383  noobj_loss: 0.0316  bbox_loss: 0.0614  cls_loss: 0.5598  \n",
      "<<<iteration:[740/878] - total_loss: 1.2229  obj_loss: 0.1418  noobj_loss: 0.0294  bbox_loss: 0.0522  cls_loss: 0.8053  \n",
      "<<<iteration:[760/878] - total_loss: 1.3474  obj_loss: 0.1273  noobj_loss: 0.0301  bbox_loss: 0.1001  cls_loss: 0.7046  \n",
      "<<<iteration:[780/878] - total_loss: 1.0343  obj_loss: 0.1714  noobj_loss: 0.0356  bbox_loss: 0.0563  cls_loss: 0.5638  \n",
      "<<<iteration:[800/878] - total_loss: 0.9983  obj_loss: 0.1288  noobj_loss: 0.0347  bbox_loss: 0.0570  cls_loss: 0.5671  \n",
      "<<<iteration:[820/878] - total_loss: 1.1382  obj_loss: 0.1735  noobj_loss: 0.0340  bbox_loss: 0.0605  cls_loss: 0.6452  \n",
      "<<<iteration:[840/878] - total_loss: 0.9979  obj_loss: 0.1291  noobj_loss: 0.0383  bbox_loss: 0.0516  cls_loss: 0.5918  \n",
      "<<<iteration:[860/878] - total_loss: 1.1378  obj_loss: 0.1481  noobj_loss: 0.0320  bbox_loss: 0.0902  cls_loss: 0.5226  \n",
      "\n",
      "epoch:43/100 - Train Loss: 1.1460, Val Loss: 1.2799\n",
      "\n",
      "<<<iteration:[20/878] - total_loss: 1.0834  obj_loss: 0.1743  noobj_loss: 0.0373  bbox_loss: 0.0556  cls_loss: 0.6124  \n",
      "<<<iteration:[40/878] - total_loss: 1.0300  obj_loss: 0.1519  noobj_loss: 0.0351  bbox_loss: 0.0497  cls_loss: 0.6121  \n",
      "<<<iteration:[60/878] - total_loss: 1.0866  obj_loss: 0.1423  noobj_loss: 0.0328  bbox_loss: 0.0600  cls_loss: 0.6281  \n",
      "<<<iteration:[80/878] - total_loss: 1.0631  obj_loss: 0.1727  noobj_loss: 0.0369  bbox_loss: 0.0632  cls_loss: 0.5557  \n",
      "<<<iteration:[100/878] - total_loss: 1.2368  obj_loss: 0.1513  noobj_loss: 0.0413  bbox_loss: 0.0862  cls_loss: 0.6340  \n",
      "<<<iteration:[120/878] - total_loss: 1.2923  obj_loss: 0.1609  noobj_loss: 0.0321  bbox_loss: 0.0862  cls_loss: 0.6843  \n",
      "<<<iteration:[140/878] - total_loss: 1.1399  obj_loss: 0.1832  noobj_loss: 0.0350  bbox_loss: 0.0606  cls_loss: 0.6362  \n",
      "<<<iteration:[160/878] - total_loss: 1.0750  obj_loss: 0.1650  noobj_loss: 0.0375  bbox_loss: 0.0567  cls_loss: 0.6076  \n",
      "<<<iteration:[180/878] - total_loss: 0.9714  obj_loss: 0.1264  noobj_loss: 0.0363  bbox_loss: 0.0596  cls_loss: 0.5289  \n",
      "<<<iteration:[200/878] - total_loss: 1.3184  obj_loss: 0.1350  noobj_loss: 0.0371  bbox_loss: 0.0775  cls_loss: 0.7774  \n",
      "<<<iteration:[220/878] - total_loss: 0.9086  obj_loss: 0.1732  noobj_loss: 0.0411  bbox_loss: 0.0512  cls_loss: 0.4587  \n",
      "<<<iteration:[240/878] - total_loss: 1.1080  obj_loss: 0.1571  noobj_loss: 0.0350  bbox_loss: 0.0509  cls_loss: 0.6791  \n",
      "<<<iteration:[260/878] - total_loss: 1.0550  obj_loss: 0.1590  noobj_loss: 0.0422  bbox_loss: 0.0625  cls_loss: 0.5626  \n",
      "<<<iteration:[280/878] - total_loss: 0.8697  obj_loss: 0.1551  noobj_loss: 0.0396  bbox_loss: 0.0521  cls_loss: 0.4346  \n",
      "<<<iteration:[300/878] - total_loss: 0.9840  obj_loss: 0.1536  noobj_loss: 0.0458  bbox_loss: 0.0604  cls_loss: 0.5054  \n",
      "<<<iteration:[320/878] - total_loss: 1.1069  obj_loss: 0.1753  noobj_loss: 0.0373  bbox_loss: 0.0704  cls_loss: 0.5611  \n",
      "<<<iteration:[340/878] - total_loss: 1.2023  obj_loss: 0.1628  noobj_loss: 0.0406  bbox_loss: 0.0530  cls_loss: 0.7539  \n",
      "<<<iteration:[360/878] - total_loss: 0.8557  obj_loss: 0.1183  noobj_loss: 0.0340  bbox_loss: 0.0448  cls_loss: 0.4966  \n",
      "<<<iteration:[380/878] - total_loss: 1.1900  obj_loss: 0.1938  noobj_loss: 0.0498  bbox_loss: 0.0749  cls_loss: 0.5966  \n",
      "<<<iteration:[400/878] - total_loss: 1.1597  obj_loss: 0.1659  noobj_loss: 0.0377  bbox_loss: 0.0725  cls_loss: 0.6123  \n",
      "<<<iteration:[420/878] - total_loss: 1.1381  obj_loss: 0.1611  noobj_loss: 0.0388  bbox_loss: 0.0550  cls_loss: 0.6824  \n",
      "<<<iteration:[440/878] - total_loss: 1.1109  obj_loss: 0.1768  noobj_loss: 0.0363  bbox_loss: 0.0543  cls_loss: 0.6447  \n",
      "<<<iteration:[460/878] - total_loss: 0.9554  obj_loss: 0.1349  noobj_loss: 0.0332  bbox_loss: 0.0494  cls_loss: 0.5568  \n",
      "<<<iteration:[480/878] - total_loss: 1.0702  obj_loss: 0.1650  noobj_loss: 0.0356  bbox_loss: 0.0562  cls_loss: 0.6064  \n",
      "<<<iteration:[500/878] - total_loss: 1.1281  obj_loss: 0.1559  noobj_loss: 0.0327  bbox_loss: 0.0616  cls_loss: 0.6479  \n",
      "<<<iteration:[520/878] - total_loss: 0.9761  obj_loss: 0.1500  noobj_loss: 0.0397  bbox_loss: 0.0626  cls_loss: 0.4930  \n",
      "<<<iteration:[540/878] - total_loss: 1.0195  obj_loss: 0.1823  noobj_loss: 0.0376  bbox_loss: 0.0524  cls_loss: 0.5566  \n",
      "<<<iteration:[560/878] - total_loss: 1.1795  obj_loss: 0.1840  noobj_loss: 0.0445  bbox_loss: 0.0694  cls_loss: 0.6262  \n",
      "<<<iteration:[580/878] - total_loss: 1.1065  obj_loss: 0.1709  noobj_loss: 0.0397  bbox_loss: 0.0610  cls_loss: 0.6107  \n",
      "<<<iteration:[600/878] - total_loss: 1.0807  obj_loss: 0.1575  noobj_loss: 0.0375  bbox_loss: 0.0554  cls_loss: 0.6273  \n",
      "<<<iteration:[620/878] - total_loss: 1.1558  obj_loss: 0.1622  noobj_loss: 0.0429  bbox_loss: 0.0744  cls_loss: 0.6000  \n",
      "<<<iteration:[640/878] - total_loss: 1.3480  obj_loss: 0.1556  noobj_loss: 0.0599  bbox_loss: 0.1271  cls_loss: 0.5267  \n",
      "<<<iteration:[660/878] - total_loss: 1.2081  obj_loss: 0.1448  noobj_loss: 0.0353  bbox_loss: 0.0531  cls_loss: 0.7799  \n",
      "<<<iteration:[680/878] - total_loss: 1.0353  obj_loss: 0.1652  noobj_loss: 0.0344  bbox_loss: 0.0605  cls_loss: 0.5502  \n",
      "<<<iteration:[700/878] - total_loss: 1.0133  obj_loss: 0.1471  noobj_loss: 0.0387  bbox_loss: 0.0610  cls_loss: 0.5418  \n",
      "<<<iteration:[720/878] - total_loss: 1.1145  obj_loss: 0.1633  noobj_loss: 0.0357  bbox_loss: 0.0682  cls_loss: 0.5923  \n",
      "<<<iteration:[740/878] - total_loss: 0.9054  obj_loss: 0.1733  noobj_loss: 0.0370  bbox_loss: 0.0584  cls_loss: 0.4217  \n",
      "<<<iteration:[760/878] - total_loss: 1.0562  obj_loss: 0.1417  noobj_loss: 0.0348  bbox_loss: 0.0581  cls_loss: 0.6067  \n",
      "<<<iteration:[780/878] - total_loss: 0.9273  obj_loss: 0.1711  noobj_loss: 0.0369  bbox_loss: 0.0428  cls_loss: 0.5235  \n",
      "<<<iteration:[800/878] - total_loss: 0.9638  obj_loss: 0.1820  noobj_loss: 0.0383  bbox_loss: 0.0541  cls_loss: 0.4919  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<<<iteration:[820/878] - total_loss: 0.9375  obj_loss: 0.1513  noobj_loss: 0.0375  bbox_loss: 0.0491  cls_loss: 0.5219  \n",
      "<<<iteration:[840/878] - total_loss: 0.9754  obj_loss: 0.1760  noobj_loss: 0.0447  bbox_loss: 0.0578  cls_loss: 0.4881  \n",
      "<<<iteration:[860/878] - total_loss: 1.0660  obj_loss: 0.1628  noobj_loss: 0.0407  bbox_loss: 0.0725  cls_loss: 0.5204  \n",
      "\n",
      "epoch:44/100 - Train Loss: 1.0743, Val Loss: 1.2235\n",
      "\n",
      "<<<iteration:[20/878] - total_loss: 1.0317  obj_loss: 0.1888  noobj_loss: 0.0416  bbox_loss: 0.0674  cls_loss: 0.4851  \n",
      "<<<iteration:[40/878] - total_loss: 0.9619  obj_loss: 0.1459  noobj_loss: 0.0403  bbox_loss: 0.0431  cls_loss: 0.5801  \n",
      "<<<iteration:[60/878] - total_loss: 0.9241  obj_loss: 0.1527  noobj_loss: 0.0367  bbox_loss: 0.0506  cls_loss: 0.5003  \n",
      "<<<iteration:[80/878] - total_loss: 1.1447  obj_loss: 0.1796  noobj_loss: 0.0381  bbox_loss: 0.0654  cls_loss: 0.6189  \n",
      "<<<iteration:[100/878] - total_loss: 0.9753  obj_loss: 0.1673  noobj_loss: 0.0366  bbox_loss: 0.0505  cls_loss: 0.5374  \n",
      "<<<iteration:[120/878] - total_loss: 1.3028  obj_loss: 0.1974  noobj_loss: 0.0455  bbox_loss: 0.1006  cls_loss: 0.5795  \n",
      "<<<iteration:[140/878] - total_loss: 1.1052  obj_loss: 0.1678  noobj_loss: 0.0437  bbox_loss: 0.0900  cls_loss: 0.4654  \n",
      "<<<iteration:[160/878] - total_loss: 1.1080  obj_loss: 0.1467  noobj_loss: 0.0395  bbox_loss: 0.0564  cls_loss: 0.6594  \n",
      "<<<iteration:[180/878] - total_loss: 1.1511  obj_loss: 0.1398  noobj_loss: 0.0353  bbox_loss: 0.0893  cls_loss: 0.5471  \n",
      "<<<iteration:[200/878] - total_loss: 1.0088  obj_loss: 0.1922  noobj_loss: 0.0430  bbox_loss: 0.0613  cls_loss: 0.4886  \n",
      "<<<iteration:[220/878] - total_loss: 1.1826  obj_loss: 0.1807  noobj_loss: 0.0412  bbox_loss: 0.0846  cls_loss: 0.5583  \n",
      "<<<iteration:[240/878] - total_loss: 0.9894  obj_loss: 0.1589  noobj_loss: 0.0421  bbox_loss: 0.0606  cls_loss: 0.5065  \n",
      "<<<iteration:[260/878] - total_loss: 0.9946  obj_loss: 0.1703  noobj_loss: 0.0420  bbox_loss: 0.0450  cls_loss: 0.5782  \n",
      "<<<iteration:[280/878] - total_loss: 1.0912  obj_loss: 0.1309  noobj_loss: 0.0338  bbox_loss: 0.0478  cls_loss: 0.7045  \n",
      "<<<iteration:[300/878] - total_loss: 1.0735  obj_loss: 0.2142  noobj_loss: 0.0551  bbox_loss: 0.0676  cls_loss: 0.4937  \n",
      "<<<iteration:[320/878] - total_loss: 0.8820  obj_loss: 0.1611  noobj_loss: 0.0426  bbox_loss: 0.0674  cls_loss: 0.3624  \n",
      "<<<iteration:[340/878] - total_loss: 1.1882  obj_loss: 0.1677  noobj_loss: 0.0447  bbox_loss: 0.0663  cls_loss: 0.6666  \n",
      "<<<iteration:[360/878] - total_loss: 0.9517  obj_loss: 0.1680  noobj_loss: 0.0390  bbox_loss: 0.0546  cls_loss: 0.4914  \n",
      "<<<iteration:[380/878] - total_loss: 1.0860  obj_loss: 0.1649  noobj_loss: 0.0392  bbox_loss: 0.0451  cls_loss: 0.6761  \n",
      "<<<iteration:[400/878] - total_loss: 0.8382  obj_loss: 0.1299  noobj_loss: 0.0426  bbox_loss: 0.0547  cls_loss: 0.4134  \n",
      "<<<iteration:[420/878] - total_loss: 1.0392  obj_loss: 0.1981  noobj_loss: 0.0416  bbox_loss: 0.0565  cls_loss: 0.5377  \n",
      "<<<iteration:[440/878] - total_loss: 1.0236  obj_loss: 0.1543  noobj_loss: 0.0404  bbox_loss: 0.0599  cls_loss: 0.5495  \n",
      "<<<iteration:[460/878] - total_loss: 1.0894  obj_loss: 0.1858  noobj_loss: 0.0448  bbox_loss: 0.0617  cls_loss: 0.5724  \n",
      "<<<iteration:[480/878] - total_loss: 1.0067  obj_loss: 0.2359  noobj_loss: 0.0522  bbox_loss: 0.0609  cls_loss: 0.4399  \n",
      "<<<iteration:[500/878] - total_loss: 1.0462  obj_loss: 0.1420  noobj_loss: 0.0415  bbox_loss: 0.0562  cls_loss: 0.6025  \n",
      "<<<iteration:[520/878] - total_loss: 1.1445  obj_loss: 0.1738  noobj_loss: 0.0403  bbox_loss: 0.0781  cls_loss: 0.5602  \n",
      "<<<iteration:[540/878] - total_loss: 0.9838  obj_loss: 0.1732  noobj_loss: 0.0375  bbox_loss: 0.0497  cls_loss: 0.5433  \n",
      "<<<iteration:[560/878] - total_loss: 1.0343  obj_loss: 0.1356  noobj_loss: 0.0405  bbox_loss: 0.0628  cls_loss: 0.5643  \n",
      "<<<iteration:[580/878] - total_loss: 1.3358  obj_loss: 0.1479  noobj_loss: 0.0473  bbox_loss: 0.1189  cls_loss: 0.5695  \n",
      "<<<iteration:[600/878] - total_loss: 1.0981  obj_loss: 0.2008  noobj_loss: 0.0501  bbox_loss: 0.0671  cls_loss: 0.5365  \n",
      "<<<iteration:[620/878] - total_loss: 0.9422  obj_loss: 0.1387  noobj_loss: 0.0391  bbox_loss: 0.0420  cls_loss: 0.5741  \n",
      "<<<iteration:[640/878] - total_loss: 0.9452  obj_loss: 0.1736  noobj_loss: 0.0470  bbox_loss: 0.0512  cls_loss: 0.4923  \n",
      "<<<iteration:[660/878] - total_loss: 0.9581  obj_loss: 0.1767  noobj_loss: 0.0478  bbox_loss: 0.0622  cls_loss: 0.4464  \n",
      "<<<iteration:[680/878] - total_loss: 0.9026  obj_loss: 0.1837  noobj_loss: 0.0399  bbox_loss: 0.0471  cls_loss: 0.4635  \n",
      "<<<iteration:[700/878] - total_loss: 1.0911  obj_loss: 0.1624  noobj_loss: 0.0378  bbox_loss: 0.0694  cls_loss: 0.5628  \n",
      "<<<iteration:[720/878] - total_loss: 1.2176  obj_loss: 0.1438  noobj_loss: 0.0340  bbox_loss: 0.0894  cls_loss: 0.6096  \n",
      "<<<iteration:[740/878] - total_loss: 0.9779  obj_loss: 0.1560  noobj_loss: 0.0366  bbox_loss: 0.0550  cls_loss: 0.5285  \n",
      "<<<iteration:[760/878] - total_loss: 1.0951  obj_loss: 0.2036  noobj_loss: 0.0456  bbox_loss: 0.0591  cls_loss: 0.5734  \n",
      "<<<iteration:[780/878] - total_loss: 1.0022  obj_loss: 0.1570  noobj_loss: 0.0367  bbox_loss: 0.0516  cls_loss: 0.5686  \n",
      "<<<iteration:[800/878] - total_loss: 0.9246  obj_loss: 0.1597  noobj_loss: 0.0378  bbox_loss: 0.0503  cls_loss: 0.4947  \n",
      "<<<iteration:[820/878] - total_loss: 1.0678  obj_loss: 0.1478  noobj_loss: 0.0383  bbox_loss: 0.0556  cls_loss: 0.6230  \n",
      "<<<iteration:[840/878] - total_loss: 0.8967  obj_loss: 0.1569  noobj_loss: 0.0350  bbox_loss: 0.0496  cls_loss: 0.4744  \n",
      "<<<iteration:[860/878] - total_loss: 0.9104  obj_loss: 0.1321  noobj_loss: 0.0394  bbox_loss: 0.0566  cls_loss: 0.4755  \n",
      "\n",
      "epoch:45/100 - Train Loss: 1.0399, Val Loss: 1.2095\n",
      "\n",
      "<<<iteration:[20/878] - total_loss: 1.1651  obj_loss: 0.1664  noobj_loss: 0.0406  bbox_loss: 0.0902  cls_loss: 0.5274  \n",
      "<<<iteration:[40/878] - total_loss: 0.8206  obj_loss: 0.1936  noobj_loss: 0.0403  bbox_loss: 0.0455  cls_loss: 0.3794  \n",
      "<<<iteration:[60/878] - total_loss: 1.0093  obj_loss: 0.1366  noobj_loss: 0.0480  bbox_loss: 0.0750  cls_loss: 0.4735  \n",
      "<<<iteration:[80/878] - total_loss: 0.9286  obj_loss: 0.1776  noobj_loss: 0.0391  bbox_loss: 0.0571  cls_loss: 0.4458  \n",
      "<<<iteration:[100/878] - total_loss: 0.9530  obj_loss: 0.1573  noobj_loss: 0.0409  bbox_loss: 0.0530  cls_loss: 0.5104  \n",
      "<<<iteration:[120/878] - total_loss: 1.0591  obj_loss: 0.1931  noobj_loss: 0.0419  bbox_loss: 0.0538  cls_loss: 0.5759  \n",
      "<<<iteration:[140/878] - total_loss: 0.9123  obj_loss: 0.1693  noobj_loss: 0.0413  bbox_loss: 0.0532  cls_loss: 0.4565  \n",
      "<<<iteration:[160/878] - total_loss: 0.9899  obj_loss: 0.1716  noobj_loss: 0.0365  bbox_loss: 0.0449  cls_loss: 0.5759  \n",
      "<<<iteration:[180/878] - total_loss: 0.8917  obj_loss: 0.1277  noobj_loss: 0.0363  bbox_loss: 0.0550  cls_loss: 0.4710  \n",
      "<<<iteration:[200/878] - total_loss: 0.9605  obj_loss: 0.1837  noobj_loss: 0.0392  bbox_loss: 0.0480  cls_loss: 0.5172  \n",
      "<<<iteration:[220/878] - total_loss: 0.8755  obj_loss: 0.1643  noobj_loss: 0.0398  bbox_loss: 0.0451  cls_loss: 0.4656  \n",
      "<<<iteration:[240/878] - total_loss: 0.8975  obj_loss: 0.1717  noobj_loss: 0.0395  bbox_loss: 0.0505  cls_loss: 0.4535  \n",
      "<<<iteration:[260/878] - total_loss: 1.1926  obj_loss: 0.2065  noobj_loss: 0.0515  bbox_loss: 0.0762  cls_loss: 0.5796  \n",
      "<<<iteration:[280/878] - total_loss: 0.9615  obj_loss: 0.1453  noobj_loss: 0.0370  bbox_loss: 0.0520  cls_loss: 0.5378  \n",
      "<<<iteration:[300/878] - total_loss: 0.9733  obj_loss: 0.1879  noobj_loss: 0.0424  bbox_loss: 0.0587  cls_loss: 0.4707  \n",
      "<<<iteration:[320/878] - total_loss: 0.9565  obj_loss: 0.1953  noobj_loss: 0.0550  bbox_loss: 0.0625  cls_loss: 0.4212  \n",
      "<<<iteration:[340/878] - total_loss: 1.0408  obj_loss: 0.1783  noobj_loss: 0.0488  bbox_loss: 0.0589  cls_loss: 0.5434  \n",
      "<<<iteration:[360/878] - total_loss: 0.8423  obj_loss: 0.1479  noobj_loss: 0.0420  bbox_loss: 0.0479  cls_loss: 0.4338  \n",
      "<<<iteration:[380/878] - total_loss: 1.0738  obj_loss: 0.2202  noobj_loss: 0.0414  bbox_loss: 0.0567  cls_loss: 0.5496  \n",
      "<<<iteration:[400/878] - total_loss: 0.8756  obj_loss: 0.2036  noobj_loss: 0.0513  bbox_loss: 0.0490  cls_loss: 0.4015  \n",
      "<<<iteration:[420/878] - total_loss: 1.0216  obj_loss: 0.2094  noobj_loss: 0.0483  bbox_loss: 0.0576  cls_loss: 0.5001  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<<<iteration:[440/878] - total_loss: 1.0408  obj_loss: 0.1602  noobj_loss: 0.0449  bbox_loss: 0.0567  cls_loss: 0.5744  \n",
      "<<<iteration:[460/878] - total_loss: 1.0701  obj_loss: 0.1693  noobj_loss: 0.0408  bbox_loss: 0.0569  cls_loss: 0.5960  \n",
      "<<<iteration:[480/878] - total_loss: 0.8400  obj_loss: 0.1859  noobj_loss: 0.0439  bbox_loss: 0.0517  cls_loss: 0.3734  \n",
      "<<<iteration:[500/878] - total_loss: 0.9674  obj_loss: 0.1569  noobj_loss: 0.0426  bbox_loss: 0.0524  cls_loss: 0.5273  \n",
      "<<<iteration:[520/878] - total_loss: 1.0481  obj_loss: 0.1808  noobj_loss: 0.0430  bbox_loss: 0.0483  cls_loss: 0.6043  \n",
      "<<<iteration:[540/878] - total_loss: 0.8760  obj_loss: 0.1407  noobj_loss: 0.0371  bbox_loss: 0.0434  cls_loss: 0.4998  \n",
      "<<<iteration:[560/878] - total_loss: 0.9994  obj_loss: 0.1618  noobj_loss: 0.0467  bbox_loss: 0.0782  cls_loss: 0.4231  \n",
      "<<<iteration:[580/878] - total_loss: 1.1024  obj_loss: 0.1805  noobj_loss: 0.0463  bbox_loss: 0.0896  cls_loss: 0.4510  \n",
      "<<<iteration:[600/878] - total_loss: 1.1485  obj_loss: 0.1665  noobj_loss: 0.0510  bbox_loss: 0.0926  cls_loss: 0.4938  \n",
      "<<<iteration:[620/878] - total_loss: 0.8746  obj_loss: 0.1518  noobj_loss: 0.0445  bbox_loss: 0.0568  cls_loss: 0.4163  \n",
      "<<<iteration:[640/878] - total_loss: 0.9940  obj_loss: 0.1739  noobj_loss: 0.0403  bbox_loss: 0.0503  cls_loss: 0.5484  \n",
      "<<<iteration:[660/878] - total_loss: 1.2455  obj_loss: 0.1983  noobj_loss: 0.0467  bbox_loss: 0.0738  cls_loss: 0.6546  \n",
      "<<<iteration:[680/878] - total_loss: 0.9081  obj_loss: 0.1505  noobj_loss: 0.0416  bbox_loss: 0.0554  cls_loss: 0.4601  \n",
      "<<<iteration:[700/878] - total_loss: 0.9775  obj_loss: 0.1583  noobj_loss: 0.0415  bbox_loss: 0.0614  cls_loss: 0.4916  \n",
      "<<<iteration:[720/878] - total_loss: 1.0517  obj_loss: 0.2051  noobj_loss: 0.0515  bbox_loss: 0.0648  cls_loss: 0.4970  \n",
      "<<<iteration:[740/878] - total_loss: 0.9992  obj_loss: 0.1444  noobj_loss: 0.0389  bbox_loss: 0.0517  cls_loss: 0.5769  \n",
      "<<<iteration:[760/878] - total_loss: 1.0032  obj_loss: 0.1900  noobj_loss: 0.0437  bbox_loss: 0.0521  cls_loss: 0.5306  \n",
      "<<<iteration:[780/878] - total_loss: 0.9411  obj_loss: 0.1477  noobj_loss: 0.0461  bbox_loss: 0.0612  cls_loss: 0.4646  \n",
      "<<<iteration:[800/878] - total_loss: 1.0168  obj_loss: 0.1543  noobj_loss: 0.0388  bbox_loss: 0.0513  cls_loss: 0.5865  \n",
      "<<<iteration:[820/878] - total_loss: 0.9656  obj_loss: 0.1720  noobj_loss: 0.0382  bbox_loss: 0.0525  cls_loss: 0.5119  \n",
      "<<<iteration:[840/878] - total_loss: 1.0115  obj_loss: 0.1771  noobj_loss: 0.0423  bbox_loss: 0.0630  cls_loss: 0.4979  \n",
      "<<<iteration:[860/878] - total_loss: 1.0898  obj_loss: 0.1677  noobj_loss: 0.0541  bbox_loss: 0.0758  cls_loss: 0.5162  \n",
      "\n",
      "epoch:46/100 - Train Loss: 0.9899, Val Loss: 1.2089\n",
      "\n",
      "<<<iteration:[20/878] - total_loss: 1.1303  obj_loss: 0.1814  noobj_loss: 0.0444  bbox_loss: 0.0630  cls_loss: 0.6117  \n",
      "<<<iteration:[40/878] - total_loss: 0.9149  obj_loss: 0.1632  noobj_loss: 0.0440  bbox_loss: 0.0538  cls_loss: 0.4609  \n",
      "<<<iteration:[60/878] - total_loss: 0.9585  obj_loss: 0.1450  noobj_loss: 0.0459  bbox_loss: 0.0532  cls_loss: 0.5248  \n",
      "<<<iteration:[80/878] - total_loss: 0.8472  obj_loss: 0.1758  noobj_loss: 0.0418  bbox_loss: 0.0489  cls_loss: 0.4059  \n",
      "<<<iteration:[100/878] - total_loss: 0.9893  obj_loss: 0.2005  noobj_loss: 0.0413  bbox_loss: 0.0464  cls_loss: 0.5361  \n",
      "<<<iteration:[120/878] - total_loss: 0.9564  obj_loss: 0.1649  noobj_loss: 0.0532  bbox_loss: 0.0567  cls_loss: 0.4814  \n",
      "<<<iteration:[140/878] - total_loss: 0.8229  obj_loss: 0.1753  noobj_loss: 0.0531  bbox_loss: 0.0508  cls_loss: 0.3670  \n",
      "<<<iteration:[160/878] - total_loss: 0.9978  obj_loss: 0.1961  noobj_loss: 0.0433  bbox_loss: 0.0594  cls_loss: 0.4830  \n",
      "<<<iteration:[180/878] - total_loss: 0.9412  obj_loss: 0.1774  noobj_loss: 0.0470  bbox_loss: 0.0507  cls_loss: 0.4868  \n",
      "<<<iteration:[200/878] - total_loss: 0.8424  obj_loss: 0.1672  noobj_loss: 0.0450  bbox_loss: 0.0484  cls_loss: 0.4107  \n",
      "<<<iteration:[220/878] - total_loss: 0.8629  obj_loss: 0.1848  noobj_loss: 0.0439  bbox_loss: 0.0447  cls_loss: 0.4325  \n",
      "<<<iteration:[240/878] - total_loss: 0.8199  obj_loss: 0.2111  noobj_loss: 0.0456  bbox_loss: 0.0430  cls_loss: 0.3711  \n",
      "<<<iteration:[260/878] - total_loss: 0.8986  obj_loss: 0.1832  noobj_loss: 0.0453  bbox_loss: 0.0467  cls_loss: 0.4591  \n",
      "<<<iteration:[280/878] - total_loss: 0.9078  obj_loss: 0.1782  noobj_loss: 0.0473  bbox_loss: 0.0512  cls_loss: 0.4500  \n",
      "<<<iteration:[300/878] - total_loss: 0.7673  obj_loss: 0.1806  noobj_loss: 0.0500  bbox_loss: 0.0528  cls_loss: 0.2977  \n",
      "<<<iteration:[320/878] - total_loss: 1.2541  obj_loss: 0.1681  noobj_loss: 0.0482  bbox_loss: 0.1015  cls_loss: 0.5543  \n",
      "<<<iteration:[340/878] - total_loss: 0.9906  obj_loss: 0.1903  noobj_loss: 0.0455  bbox_loss: 0.0625  cls_loss: 0.4651  \n",
      "<<<iteration:[360/878] - total_loss: 1.2348  obj_loss: 0.1734  noobj_loss: 0.0438  bbox_loss: 0.0594  cls_loss: 0.7423  \n",
      "<<<iteration:[380/878] - total_loss: 1.0055  obj_loss: 0.1612  noobj_loss: 0.0501  bbox_loss: 0.0691  cls_loss: 0.4735  \n",
      "<<<iteration:[400/878] - total_loss: 1.0371  obj_loss: 0.1838  noobj_loss: 0.0440  bbox_loss: 0.0723  cls_loss: 0.4695  \n",
      "<<<iteration:[420/878] - total_loss: 1.0291  obj_loss: 0.1950  noobj_loss: 0.0491  bbox_loss: 0.0520  cls_loss: 0.5497  \n",
      "<<<iteration:[440/878] - total_loss: 0.9865  obj_loss: 0.1549  noobj_loss: 0.0456  bbox_loss: 0.0616  cls_loss: 0.5007  \n",
      "<<<iteration:[460/878] - total_loss: 0.8787  obj_loss: 0.1767  noobj_loss: 0.0520  bbox_loss: 0.0597  cls_loss: 0.3775  \n",
      "<<<iteration:[480/878] - total_loss: 0.8803  obj_loss: 0.1638  noobj_loss: 0.0450  bbox_loss: 0.0435  cls_loss: 0.4767  \n",
      "<<<iteration:[500/878] - total_loss: 0.8153  obj_loss: 0.1437  noobj_loss: 0.0391  bbox_loss: 0.0496  cls_loss: 0.4042  \n",
      "<<<iteration:[520/878] - total_loss: 1.0507  obj_loss: 0.1807  noobj_loss: 0.0456  bbox_loss: 0.0640  cls_loss: 0.5274  \n",
      "<<<iteration:[540/878] - total_loss: 0.9867  obj_loss: 0.1892  noobj_loss: 0.0438  bbox_loss: 0.0629  cls_loss: 0.4611  \n",
      "<<<iteration:[560/878] - total_loss: 0.9415  obj_loss: 0.1454  noobj_loss: 0.0454  bbox_loss: 0.0564  cls_loss: 0.4914  \n",
      "<<<iteration:[580/878] - total_loss: 0.9981  obj_loss: 0.2070  noobj_loss: 0.0510  bbox_loss: 0.0494  cls_loss: 0.5187  \n",
      "<<<iteration:[600/878] - total_loss: 0.8564  obj_loss: 0.1811  noobj_loss: 0.0510  bbox_loss: 0.0432  cls_loss: 0.4340  \n",
      "<<<iteration:[620/878] - total_loss: 0.8735  obj_loss: 0.1827  noobj_loss: 0.0436  bbox_loss: 0.0533  cls_loss: 0.4025  \n",
      "<<<iteration:[640/878] - total_loss: 0.9002  obj_loss: 0.1628  noobj_loss: 0.0465  bbox_loss: 0.0559  cls_loss: 0.4346  \n",
      "<<<iteration:[660/878] - total_loss: 0.9288  obj_loss: 0.1994  noobj_loss: 0.0474  bbox_loss: 0.0506  cls_loss: 0.4527  \n",
      "<<<iteration:[680/878] - total_loss: 0.8514  obj_loss: 0.1994  noobj_loss: 0.0493  bbox_loss: 0.0621  cls_loss: 0.3169  \n",
      "<<<iteration:[700/878] - total_loss: 0.9872  obj_loss: 0.1393  noobj_loss: 0.0560  bbox_loss: 0.0543  cls_loss: 0.5485  \n",
      "<<<iteration:[720/878] - total_loss: 0.8425  obj_loss: 0.1691  noobj_loss: 0.0445  bbox_loss: 0.0484  cls_loss: 0.4093  \n",
      "<<<iteration:[740/878] - total_loss: 1.1839  obj_loss: 0.2064  noobj_loss: 0.0463  bbox_loss: 0.0657  cls_loss: 0.6257  \n",
      "<<<iteration:[760/878] - total_loss: 0.9786  obj_loss: 0.1309  noobj_loss: 0.0448  bbox_loss: 0.0601  cls_loss: 0.5249  \n",
      "<<<iteration:[780/878] - total_loss: 0.9004  obj_loss: 0.1775  noobj_loss: 0.0444  bbox_loss: 0.0648  cls_loss: 0.3767  \n",
      "<<<iteration:[800/878] - total_loss: 0.9980  obj_loss: 0.1996  noobj_loss: 0.0537  bbox_loss: 0.0620  cls_loss: 0.4616  \n",
      "<<<iteration:[820/878] - total_loss: 1.3096  obj_loss: 0.1589  noobj_loss: 0.0520  bbox_loss: 0.1103  cls_loss: 0.5731  \n",
      "<<<iteration:[840/878] - total_loss: 1.0809  obj_loss: 0.2118  noobj_loss: 0.0480  bbox_loss: 0.0776  cls_loss: 0.4570  \n",
      "<<<iteration:[860/878] - total_loss: 1.0044  obj_loss: 0.1865  noobj_loss: 0.0491  bbox_loss: 0.0561  cls_loss: 0.5128  \n",
      "\n",
      "epoch:47/100 - Train Loss: 0.9669, Val Loss: 1.1709\n",
      "\n",
      "<<<iteration:[20/878] - total_loss: 0.9195  obj_loss: 0.1811  noobj_loss: 0.0526  bbox_loss: 0.0507  cls_loss: 0.4588  \n",
      "<<<iteration:[40/878] - total_loss: 0.8560  obj_loss: 0.1601  noobj_loss: 0.0437  bbox_loss: 0.0512  cls_loss: 0.4180  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<<<iteration:[60/878] - total_loss: 1.0581  obj_loss: 0.1617  noobj_loss: 0.0452  bbox_loss: 0.0800  cls_loss: 0.4738  \n",
      "<<<iteration:[80/878] - total_loss: 1.0745  obj_loss: 0.1841  noobj_loss: 0.0569  bbox_loss: 0.0677  cls_loss: 0.5237  \n",
      "<<<iteration:[100/878] - total_loss: 1.1013  obj_loss: 0.1491  noobj_loss: 0.0525  bbox_loss: 0.0804  cls_loss: 0.5237  \n",
      "<<<iteration:[120/878] - total_loss: 1.4170  obj_loss: 0.1515  noobj_loss: 0.0584  bbox_loss: 0.1528  cls_loss: 0.4722  \n",
      "<<<iteration:[140/878] - total_loss: 1.0925  obj_loss: 0.1553  noobj_loss: 0.0397  bbox_loss: 0.0852  cls_loss: 0.4915  \n",
      "<<<iteration:[160/878] - total_loss: 1.2309  obj_loss: 0.1155  noobj_loss: 0.0508  bbox_loss: 0.1129  cls_loss: 0.5256  \n",
      "<<<iteration:[180/878] - total_loss: 0.9726  obj_loss: 0.1507  noobj_loss: 0.0394  bbox_loss: 0.0424  cls_loss: 0.5902  \n",
      "<<<iteration:[200/878] - total_loss: 1.0452  obj_loss: 0.1487  noobj_loss: 0.0425  bbox_loss: 0.0813  cls_loss: 0.4686  \n",
      "<<<iteration:[220/878] - total_loss: 1.0047  obj_loss: 0.1831  noobj_loss: 0.0466  bbox_loss: 0.0580  cls_loss: 0.5085  \n",
      "<<<iteration:[240/878] - total_loss: 0.9519  obj_loss: 0.1901  noobj_loss: 0.0498  bbox_loss: 0.0464  cls_loss: 0.5048  \n",
      "<<<iteration:[260/878] - total_loss: 0.8202  obj_loss: 0.1762  noobj_loss: 0.0492  bbox_loss: 0.0464  cls_loss: 0.3877  \n",
      "<<<iteration:[280/878] - total_loss: 0.7523  obj_loss: 0.1799  noobj_loss: 0.0489  bbox_loss: 0.0427  cls_loss: 0.3347  \n",
      "<<<iteration:[300/878] - total_loss: 0.9583  obj_loss: 0.2052  noobj_loss: 0.0558  bbox_loss: 0.0546  cls_loss: 0.4524  \n",
      "<<<iteration:[320/878] - total_loss: 0.9427  obj_loss: 0.1756  noobj_loss: 0.0524  bbox_loss: 0.0500  cls_loss: 0.4911  \n",
      "<<<iteration:[340/878] - total_loss: 0.9135  obj_loss: 0.2103  noobj_loss: 0.0463  bbox_loss: 0.0500  cls_loss: 0.4302  \n",
      "<<<iteration:[360/878] - total_loss: 0.9315  obj_loss: 0.2061  noobj_loss: 0.0495  bbox_loss: 0.0575  cls_loss: 0.4130  \n",
      "<<<iteration:[380/878] - total_loss: 1.0651  obj_loss: 0.1896  noobj_loss: 0.0569  bbox_loss: 0.0615  cls_loss: 0.5398  \n",
      "<<<iteration:[400/878] - total_loss: 0.7233  obj_loss: 0.1864  noobj_loss: 0.0457  bbox_loss: 0.0470  cls_loss: 0.2792  \n",
      "<<<iteration:[420/878] - total_loss: 0.8342  obj_loss: 0.1811  noobj_loss: 0.0512  bbox_loss: 0.0541  cls_loss: 0.3567  \n",
      "<<<iteration:[440/878] - total_loss: 0.8368  obj_loss: 0.1901  noobj_loss: 0.0569  bbox_loss: 0.0462  cls_loss: 0.3870  \n",
      "<<<iteration:[460/878] - total_loss: 0.9562  obj_loss: 0.1616  noobj_loss: 0.0488  bbox_loss: 0.0664  cls_loss: 0.4384  \n",
      "<<<iteration:[480/878] - total_loss: 0.9233  obj_loss: 0.2032  noobj_loss: 0.0489  bbox_loss: 0.0572  cls_loss: 0.4098  \n",
      "<<<iteration:[500/878] - total_loss: 0.8273  obj_loss: 0.1634  noobj_loss: 0.0427  bbox_loss: 0.0460  cls_loss: 0.4125  \n",
      "<<<iteration:[520/878] - total_loss: 0.9425  obj_loss: 0.1875  noobj_loss: 0.0466  bbox_loss: 0.0502  cls_loss: 0.4806  \n",
      "<<<iteration:[540/878] - total_loss: 0.8488  obj_loss: 0.1812  noobj_loss: 0.0443  bbox_loss: 0.0479  cls_loss: 0.4061  \n",
      "<<<iteration:[560/878] - total_loss: 0.7835  obj_loss: 0.1937  noobj_loss: 0.0507  bbox_loss: 0.0433  cls_loss: 0.3479  \n",
      "<<<iteration:[580/878] - total_loss: 1.0015  obj_loss: 0.2034  noobj_loss: 0.0514  bbox_loss: 0.0704  cls_loss: 0.4203  \n",
      "<<<iteration:[600/878] - total_loss: 0.8418  obj_loss: 0.1818  noobj_loss: 0.0493  bbox_loss: 0.0482  cls_loss: 0.3943  \n",
      "<<<iteration:[620/878] - total_loss: 0.9763  obj_loss: 0.1808  noobj_loss: 0.0546  bbox_loss: 0.0531  cls_loss: 0.5026  \n",
      "<<<iteration:[640/878] - total_loss: 0.9040  obj_loss: 0.1788  noobj_loss: 0.0490  bbox_loss: 0.0411  cls_loss: 0.4949  \n",
      "<<<iteration:[660/878] - total_loss: 1.0091  obj_loss: 0.1576  noobj_loss: 0.0487  bbox_loss: 0.0507  cls_loss: 0.5738  \n",
      "<<<iteration:[680/878] - total_loss: 1.0780  obj_loss: 0.1650  noobj_loss: 0.0494  bbox_loss: 0.0479  cls_loss: 0.6487  \n",
      "<<<iteration:[700/878] - total_loss: 0.8206  obj_loss: 0.1742  noobj_loss: 0.0484  bbox_loss: 0.0520  cls_loss: 0.3621  \n",
      "<<<iteration:[720/878] - total_loss: 0.9846  obj_loss: 0.2167  noobj_loss: 0.0500  bbox_loss: 0.0500  cls_loss: 0.4929  \n",
      "<<<iteration:[740/878] - total_loss: 0.8932  obj_loss: 0.1982  noobj_loss: 0.0520  bbox_loss: 0.0593  cls_loss: 0.3726  \n",
      "<<<iteration:[760/878] - total_loss: 0.9521  obj_loss: 0.1659  noobj_loss: 0.0499  bbox_loss: 0.0678  cls_loss: 0.4221  \n",
      "<<<iteration:[780/878] - total_loss: 0.7547  obj_loss: 0.1627  noobj_loss: 0.0437  bbox_loss: 0.0491  cls_loss: 0.3245  \n",
      "<<<iteration:[800/878] - total_loss: 1.1271  obj_loss: 0.2068  noobj_loss: 0.0505  bbox_loss: 0.0955  cls_loss: 0.4174  \n",
      "<<<iteration:[820/878] - total_loss: 0.8832  obj_loss: 0.2042  noobj_loss: 0.0553  bbox_loss: 0.0509  cls_loss: 0.3969  \n",
      "<<<iteration:[840/878] - total_loss: 0.8609  obj_loss: 0.1763  noobj_loss: 0.0459  bbox_loss: 0.0440  cls_loss: 0.4417  \n",
      "<<<iteration:[860/878] - total_loss: 0.8112  obj_loss: 0.1915  noobj_loss: 0.0507  bbox_loss: 0.0476  cls_loss: 0.3561  \n",
      "\n",
      "epoch:48/100 - Train Loss: 0.9457, Val Loss: 1.1783\n",
      "\n",
      "<<<iteration:[20/878] - total_loss: 0.8870  obj_loss: 0.1773  noobj_loss: 0.0495  bbox_loss: 0.0525  cls_loss: 0.4223  \n",
      "<<<iteration:[40/878] - total_loss: 0.9330  obj_loss: 0.1860  noobj_loss: 0.0538  bbox_loss: 0.0467  cls_loss: 0.4867  \n",
      "<<<iteration:[60/878] - total_loss: 0.9210  obj_loss: 0.1952  noobj_loss: 0.0535  bbox_loss: 0.0541  cls_loss: 0.4287  \n",
      "<<<iteration:[80/878] - total_loss: 1.0287  obj_loss: 0.1482  noobj_loss: 0.0630  bbox_loss: 0.0723  cls_loss: 0.4874  \n",
      "<<<iteration:[100/878] - total_loss: 0.8537  obj_loss: 0.1975  noobj_loss: 0.0479  bbox_loss: 0.0401  cls_loss: 0.4316  \n",
      "<<<iteration:[120/878] - total_loss: 1.0473  obj_loss: 0.1494  noobj_loss: 0.0469  bbox_loss: 0.0535  cls_loss: 0.6071  \n",
      "<<<iteration:[140/878] - total_loss: 0.8562  obj_loss: 0.1770  noobj_loss: 0.0468  bbox_loss: 0.0566  cls_loss: 0.3729  \n",
      "<<<iteration:[160/878] - total_loss: 0.8571  obj_loss: 0.1418  noobj_loss: 0.0554  bbox_loss: 0.0520  cls_loss: 0.4273  \n",
      "<<<iteration:[180/878] - total_loss: 0.9002  obj_loss: 0.1748  noobj_loss: 0.0451  bbox_loss: 0.0574  cls_loss: 0.4156  \n",
      "<<<iteration:[200/878] - total_loss: 0.8724  obj_loss: 0.1869  noobj_loss: 0.0545  bbox_loss: 0.0539  cls_loss: 0.3888  \n",
      "<<<iteration:[220/878] - total_loss: 0.8544  obj_loss: 0.1558  noobj_loss: 0.0506  bbox_loss: 0.0499  cls_loss: 0.4237  \n",
      "<<<iteration:[240/878] - total_loss: 0.8970  obj_loss: 0.2083  noobj_loss: 0.0542  bbox_loss: 0.0562  cls_loss: 0.3804  \n",
      "<<<iteration:[260/878] - total_loss: 0.8276  obj_loss: 0.1852  noobj_loss: 0.0551  bbox_loss: 0.0484  cls_loss: 0.3730  \n",
      "<<<iteration:[280/878] - total_loss: 0.8453  obj_loss: 0.1756  noobj_loss: 0.0511  bbox_loss: 0.0558  cls_loss: 0.3650  \n",
      "<<<iteration:[300/878] - total_loss: 0.8993  obj_loss: 0.1999  noobj_loss: 0.0536  bbox_loss: 0.0602  cls_loss: 0.3718  \n",
      "<<<iteration:[320/878] - total_loss: 0.9777  obj_loss: 0.1918  noobj_loss: 0.0597  bbox_loss: 0.0607  cls_loss: 0.4526  \n",
      "<<<iteration:[340/878] - total_loss: 1.0018  obj_loss: 0.1911  noobj_loss: 0.0524  bbox_loss: 0.0556  cls_loss: 0.5065  \n",
      "<<<iteration:[360/878] - total_loss: 0.7880  obj_loss: 0.1798  noobj_loss: 0.0516  bbox_loss: 0.0527  cls_loss: 0.3186  \n",
      "<<<iteration:[380/878] - total_loss: 0.8828  obj_loss: 0.1884  noobj_loss: 0.0576  bbox_loss: 0.0456  cls_loss: 0.4376  \n",
      "<<<iteration:[400/878] - total_loss: 0.7462  obj_loss: 0.1728  noobj_loss: 0.0480  bbox_loss: 0.0392  cls_loss: 0.3533  \n",
      "<<<iteration:[420/878] - total_loss: 0.9506  obj_loss: 0.2161  noobj_loss: 0.0520  bbox_loss: 0.0640  cls_loss: 0.3884  \n",
      "<<<iteration:[440/878] - total_loss: 1.9045  obj_loss: 0.1414  noobj_loss: 0.0843  bbox_loss: 0.2264  cls_loss: 0.5889  \n",
      "<<<iteration:[460/878] - total_loss: 0.9326  obj_loss: 0.2094  noobj_loss: 0.0543  bbox_loss: 0.0839  cls_loss: 0.2763  \n",
      "<<<iteration:[480/878] - total_loss: 0.9472  obj_loss: 0.1867  noobj_loss: 0.0570  bbox_loss: 0.0629  cls_loss: 0.4177  \n",
      "<<<iteration:[500/878] - total_loss: 1.1051  obj_loss: 0.1949  noobj_loss: 0.0538  bbox_loss: 0.1014  cls_loss: 0.3763  \n",
      "<<<iteration:[520/878] - total_loss: 1.0268  obj_loss: 0.1829  noobj_loss: 0.0504  bbox_loss: 0.0692  cls_loss: 0.4725  \n",
      "<<<iteration:[540/878] - total_loss: 0.8749  obj_loss: 0.1663  noobj_loss: 0.0457  bbox_loss: 0.0511  cls_loss: 0.4303  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<<<iteration:[560/878] - total_loss: 0.8318  obj_loss: 0.1727  noobj_loss: 0.0532  bbox_loss: 0.0482  cls_loss: 0.3914  \n",
      "<<<iteration:[580/878] - total_loss: 0.7673  obj_loss: 0.1781  noobj_loss: 0.0506  bbox_loss: 0.0405  cls_loss: 0.3614  \n",
      "<<<iteration:[600/878] - total_loss: 0.9836  obj_loss: 0.1915  noobj_loss: 0.0551  bbox_loss: 0.0616  cls_loss: 0.4567  \n",
      "<<<iteration:[620/878] - total_loss: 0.8659  obj_loss: 0.1753  noobj_loss: 0.0573  bbox_loss: 0.0442  cls_loss: 0.4408  \n",
      "<<<iteration:[640/878] - total_loss: 0.8978  obj_loss: 0.1796  noobj_loss: 0.0472  bbox_loss: 0.0542  cls_loss: 0.4234  \n",
      "<<<iteration:[660/878] - total_loss: 1.0544  obj_loss: 0.1727  noobj_loss: 0.0498  bbox_loss: 0.0651  cls_loss: 0.5314  \n",
      "<<<iteration:[680/878] - total_loss: 0.8442  obj_loss: 0.1956  noobj_loss: 0.0531  bbox_loss: 0.0473  cls_loss: 0.3857  \n",
      "<<<iteration:[700/878] - total_loss: 1.0775  obj_loss: 0.1824  noobj_loss: 0.0487  bbox_loss: 0.0600  cls_loss: 0.5707  \n",
      "<<<iteration:[720/878] - total_loss: 0.9734  obj_loss: 0.2157  noobj_loss: 0.0532  bbox_loss: 0.0694  cls_loss: 0.3843  \n",
      "<<<iteration:[740/878] - total_loss: 0.9645  obj_loss: 0.1803  noobj_loss: 0.0544  bbox_loss: 0.0578  cls_loss: 0.4679  \n",
      "<<<iteration:[760/878] - total_loss: 1.0023  obj_loss: 0.1956  noobj_loss: 0.0559  bbox_loss: 0.0454  cls_loss: 0.5516  \n",
      "<<<iteration:[780/878] - total_loss: 0.7910  obj_loss: 0.1454  noobj_loss: 0.0478  bbox_loss: 0.0423  cls_loss: 0.4103  \n",
      "<<<iteration:[800/878] - total_loss: 0.8336  obj_loss: 0.1319  noobj_loss: 0.0482  bbox_loss: 0.0412  cls_loss: 0.4717  \n",
      "<<<iteration:[820/878] - total_loss: 0.7795  obj_loss: 0.1887  noobj_loss: 0.0524  bbox_loss: 0.0445  cls_loss: 0.3419  \n",
      "<<<iteration:[840/878] - total_loss: 0.9348  obj_loss: 0.2075  noobj_loss: 0.0614  bbox_loss: 0.0545  cls_loss: 0.4242  \n",
      "<<<iteration:[860/878] - total_loss: 0.9273  obj_loss: 0.2176  noobj_loss: 0.0708  bbox_loss: 0.0623  cls_loss: 0.3629  \n",
      "\n",
      "epoch:49/100 - Train Loss: 0.9308, Val Loss: 1.3401\n",
      "\n",
      "<<<iteration:[20/878] - total_loss: 0.9360  obj_loss: 0.1956  noobj_loss: 0.0654  bbox_loss: 0.0718  cls_loss: 0.3485  \n",
      "<<<iteration:[40/878] - total_loss: 0.8534  obj_loss: 0.1925  noobj_loss: 0.0586  bbox_loss: 0.0585  cls_loss: 0.3393  \n",
      "<<<iteration:[60/878] - total_loss: 0.9962  obj_loss: 0.2051  noobj_loss: 0.0708  bbox_loss: 0.0544  cls_loss: 0.4836  \n",
      "<<<iteration:[80/878] - total_loss: 0.8290  obj_loss: 0.1830  noobj_loss: 0.0586  bbox_loss: 0.0425  cls_loss: 0.4040  \n",
      "<<<iteration:[100/878] - total_loss: 0.8518  obj_loss: 0.1846  noobj_loss: 0.0624  bbox_loss: 0.0436  cls_loss: 0.4183  \n",
      "<<<iteration:[120/878] - total_loss: 0.9419  obj_loss: 0.2106  noobj_loss: 0.0571  bbox_loss: 0.0519  cls_loss: 0.4434  \n",
      "<<<iteration:[140/878] - total_loss: 0.8152  obj_loss: 0.1814  noobj_loss: 0.0497  bbox_loss: 0.0470  cls_loss: 0.3740  \n",
      "<<<iteration:[160/878] - total_loss: 0.9064  obj_loss: 0.1854  noobj_loss: 0.0540  bbox_loss: 0.0414  cls_loss: 0.4872  \n",
      "<<<iteration:[180/878] - total_loss: 0.8863  obj_loss: 0.2199  noobj_loss: 0.0565  bbox_loss: 0.0447  cls_loss: 0.4146  \n",
      "<<<iteration:[200/878] - total_loss: 1.0909  obj_loss: 0.1752  noobj_loss: 0.0626  bbox_loss: 0.0635  cls_loss: 0.5671  \n",
      "<<<iteration:[220/878] - total_loss: 0.9088  obj_loss: 0.1656  noobj_loss: 0.0548  bbox_loss: 0.0557  cls_loss: 0.4375  \n",
      "<<<iteration:[240/878] - total_loss: 0.7928  obj_loss: 0.1803  noobj_loss: 0.0552  bbox_loss: 0.0522  cls_loss: 0.3242  \n",
      "<<<iteration:[260/878] - total_loss: 0.8189  obj_loss: 0.1537  noobj_loss: 0.0540  bbox_loss: 0.0559  cls_loss: 0.3589  \n",
      "<<<iteration:[280/878] - total_loss: 0.9484  obj_loss: 0.1749  noobj_loss: 0.0527  bbox_loss: 0.0502  cls_loss: 0.4962  \n",
      "<<<iteration:[300/878] - total_loss: 0.7509  obj_loss: 0.1876  noobj_loss: 0.0539  bbox_loss: 0.0439  cls_loss: 0.3169  \n",
      "<<<iteration:[320/878] - total_loss: 0.7581  obj_loss: 0.1614  noobj_loss: 0.0550  bbox_loss: 0.0485  cls_loss: 0.3265  \n",
      "<<<iteration:[340/878] - total_loss: 0.8560  obj_loss: 0.1924  noobj_loss: 0.0524  bbox_loss: 0.0442  cls_loss: 0.4162  \n",
      "<<<iteration:[360/878] - total_loss: 0.9303  obj_loss: 0.1646  noobj_loss: 0.0649  bbox_loss: 0.0589  cls_loss: 0.4386  \n",
      "<<<iteration:[380/878] - total_loss: 0.8882  obj_loss: 0.2132  noobj_loss: 0.0575  bbox_loss: 0.0455  cls_loss: 0.4186  \n",
      "<<<iteration:[400/878] - total_loss: 0.9029  obj_loss: 0.1856  noobj_loss: 0.0565  bbox_loss: 0.0594  cls_loss: 0.3918  \n",
      "<<<iteration:[420/878] - total_loss: 1.1789  obj_loss: 0.1942  noobj_loss: 0.0645  bbox_loss: 0.0835  cls_loss: 0.5352  \n",
      "<<<iteration:[440/878] - total_loss: 0.8152  obj_loss: 0.1795  noobj_loss: 0.0519  bbox_loss: 0.0559  cls_loss: 0.3304  \n",
      "<<<iteration:[460/878] - total_loss: 0.8135  obj_loss: 0.1925  noobj_loss: 0.0540  bbox_loss: 0.0409  cls_loss: 0.3897  \n",
      "<<<iteration:[480/878] - total_loss: 0.9090  obj_loss: 0.1818  noobj_loss: 0.0786  bbox_loss: 0.0625  cls_loss: 0.3753  \n",
      "<<<iteration:[500/878] - total_loss: 0.7957  obj_loss: 0.1867  noobj_loss: 0.0660  bbox_loss: 0.0503  cls_loss: 0.3247  \n",
      "<<<iteration:[520/878] - total_loss: 0.8446  obj_loss: 0.1882  noobj_loss: 0.0572  bbox_loss: 0.0486  cls_loss: 0.3848  \n",
      "<<<iteration:[540/878] - total_loss: 0.9334  obj_loss: 0.2007  noobj_loss: 0.0482  bbox_loss: 0.0427  cls_loss: 0.4950  \n",
      "<<<iteration:[560/878] - total_loss: 1.0014  obj_loss: 0.2163  noobj_loss: 0.0567  bbox_loss: 0.0498  cls_loss: 0.5075  \n",
      "<<<iteration:[580/878] - total_loss: 0.8862  obj_loss: 0.2177  noobj_loss: 0.0642  bbox_loss: 0.0515  cls_loss: 0.3790  \n",
      "<<<iteration:[600/878] - total_loss: 0.8061  obj_loss: 0.1690  noobj_loss: 0.0539  bbox_loss: 0.0459  cls_loss: 0.3807  \n",
      "<<<iteration:[620/878] - total_loss: 0.8079  obj_loss: 0.1757  noobj_loss: 0.0532  bbox_loss: 0.0439  cls_loss: 0.3862  \n",
      "<<<iteration:[640/878] - total_loss: 0.9408  obj_loss: 0.1813  noobj_loss: 0.0568  bbox_loss: 0.0431  cls_loss: 0.5157  \n",
      "<<<iteration:[660/878] - total_loss: 0.8436  obj_loss: 0.1636  noobj_loss: 0.0512  bbox_loss: 0.0426  cls_loss: 0.4411  \n",
      "<<<iteration:[680/878] - total_loss: 0.8773  obj_loss: 0.1830  noobj_loss: 0.0532  bbox_loss: 0.0492  cls_loss: 0.4218  \n",
      "<<<iteration:[700/878] - total_loss: 0.9663  obj_loss: 0.1824  noobj_loss: 0.0531  bbox_loss: 0.0809  cls_loss: 0.3526  \n",
      "<<<iteration:[720/878] - total_loss: 0.7320  obj_loss: 0.1649  noobj_loss: 0.0679  bbox_loss: 0.0408  cls_loss: 0.3292  \n",
      "<<<iteration:[740/878] - total_loss: 0.8420  obj_loss: 0.1562  noobj_loss: 0.0538  bbox_loss: 0.0462  cls_loss: 0.4280  \n",
      "<<<iteration:[760/878] - total_loss: 0.8484  obj_loss: 0.2180  noobj_loss: 0.0600  bbox_loss: 0.0472  cls_loss: 0.3642  \n",
      "<<<iteration:[780/878] - total_loss: 0.9074  obj_loss: 0.1694  noobj_loss: 0.0566  bbox_loss: 0.0442  cls_loss: 0.4887  \n",
      "<<<iteration:[800/878] - total_loss: 0.9104  obj_loss: 0.1357  noobj_loss: 0.0607  bbox_loss: 0.0747  cls_loss: 0.3711  \n",
      "<<<iteration:[820/878] - total_loss: 0.7205  obj_loss: 0.1632  noobj_loss: 0.0503  bbox_loss: 0.0455  cls_loss: 0.3046  \n",
      "<<<iteration:[840/878] - total_loss: 0.8617  obj_loss: 0.1900  noobj_loss: 0.0570  bbox_loss: 0.0644  cls_loss: 0.3210  \n",
      "<<<iteration:[860/878] - total_loss: 1.0039  obj_loss: 0.1964  noobj_loss: 0.0536  bbox_loss: 0.0487  cls_loss: 0.5375  \n",
      "\n",
      "epoch:50/100 - Train Loss: 0.8796, Val Loss: 1.1637\n",
      "\n",
      "<<<iteration:[20/878] - total_loss: 0.8717  obj_loss: 0.2581  noobj_loss: 0.0625  bbox_loss: 0.0487  cls_loss: 0.3391  \n",
      "<<<iteration:[40/878] - total_loss: 0.8464  obj_loss: 0.1485  noobj_loss: 0.0545  bbox_loss: 0.0442  cls_loss: 0.4497  \n",
      "<<<iteration:[60/878] - total_loss: 0.9028  obj_loss: 0.1881  noobj_loss: 0.0519  bbox_loss: 0.0438  cls_loss: 0.4698  \n",
      "<<<iteration:[80/878] - total_loss: 0.6634  obj_loss: 0.1490  noobj_loss: 0.0505  bbox_loss: 0.0352  cls_loss: 0.3132  \n",
      "<<<iteration:[100/878] - total_loss: 0.7702  obj_loss: 0.1583  noobj_loss: 0.0567  bbox_loss: 0.0533  cls_loss: 0.3173  \n",
      "<<<iteration:[120/878] - total_loss: 0.8213  obj_loss: 0.1882  noobj_loss: 0.0653  bbox_loss: 0.0435  cls_loss: 0.3827  \n",
      "<<<iteration:[140/878] - total_loss: 0.9602  obj_loss: 0.1926  noobj_loss: 0.0625  bbox_loss: 0.0634  cls_loss: 0.4196  \n",
      "<<<iteration:[160/878] - total_loss: 0.8690  obj_loss: 0.1858  noobj_loss: 0.0512  bbox_loss: 0.0416  cls_loss: 0.4495  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<<<iteration:[180/878] - total_loss: 0.7124  obj_loss: 0.2164  noobj_loss: 0.0555  bbox_loss: 0.0461  cls_loss: 0.2377  \n",
      "<<<iteration:[200/878] - total_loss: 0.8296  obj_loss: 0.1935  noobj_loss: 0.0569  bbox_loss: 0.0427  cls_loss: 0.3939  \n",
      "<<<iteration:[220/878] - total_loss: 0.9289  obj_loss: 0.1547  noobj_loss: 0.0555  bbox_loss: 0.0471  cls_loss: 0.5109  \n",
      "<<<iteration:[240/878] - total_loss: 0.8413  obj_loss: 0.1882  noobj_loss: 0.0620  bbox_loss: 0.0435  cls_loss: 0.4048  \n",
      "<<<iteration:[260/878] - total_loss: 0.8687  obj_loss: 0.1444  noobj_loss: 0.0581  bbox_loss: 0.0494  cls_loss: 0.4481  \n",
      "<<<iteration:[280/878] - total_loss: 0.9076  obj_loss: 0.1941  noobj_loss: 0.0599  bbox_loss: 0.0489  cls_loss: 0.4389  \n",
      "<<<iteration:[300/878] - total_loss: 0.8288  obj_loss: 0.1552  noobj_loss: 0.0586  bbox_loss: 0.0589  cls_loss: 0.3496  \n",
      "<<<iteration:[320/878] - total_loss: 0.9477  obj_loss: 0.1755  noobj_loss: 0.0509  bbox_loss: 0.0583  cls_loss: 0.4554  \n",
      "<<<iteration:[340/878] - total_loss: 0.9163  obj_loss: 0.1513  noobj_loss: 0.0571  bbox_loss: 0.0579  cls_loss: 0.4471  \n",
      "<<<iteration:[360/878] - total_loss: 0.9010  obj_loss: 0.1981  noobj_loss: 0.0589  bbox_loss: 0.0488  cls_loss: 0.4296  \n",
      "<<<iteration:[380/878] - total_loss: 0.8324  obj_loss: 0.2022  noobj_loss: 0.0635  bbox_loss: 0.0422  cls_loss: 0.3875  \n",
      "<<<iteration:[400/878] - total_loss: 0.7783  obj_loss: 0.1775  noobj_loss: 0.0566  bbox_loss: 0.0441  cls_loss: 0.3518  \n",
      "<<<iteration:[420/878] - total_loss: 0.7947  obj_loss: 0.2462  noobj_loss: 0.0616  bbox_loss: 0.0402  cls_loss: 0.3165  \n",
      "<<<iteration:[440/878] - total_loss: 0.7158  obj_loss: 0.1790  noobj_loss: 0.0668  bbox_loss: 0.0460  cls_loss: 0.2735  \n",
      "<<<iteration:[460/878] - total_loss: 0.7237  obj_loss: 0.1858  noobj_loss: 0.0551  bbox_loss: 0.0449  cls_loss: 0.2858  \n",
      "<<<iteration:[480/878] - total_loss: 0.8119  obj_loss: 0.2129  noobj_loss: 0.0675  bbox_loss: 0.0428  cls_loss: 0.3510  \n",
      "<<<iteration:[500/878] - total_loss: 0.7449  obj_loss: 0.1525  noobj_loss: 0.0614  bbox_loss: 0.0549  cls_loss: 0.2872  \n",
      "<<<iteration:[520/878] - total_loss: 0.8045  obj_loss: 0.1573  noobj_loss: 0.0565  bbox_loss: 0.0534  cls_loss: 0.3519  \n",
      "<<<iteration:[540/878] - total_loss: 0.8534  obj_loss: 0.2074  noobj_loss: 0.0644  bbox_loss: 0.0496  cls_loss: 0.3661  \n",
      "<<<iteration:[560/878] - total_loss: 0.7545  obj_loss: 0.1613  noobj_loss: 0.0589  bbox_loss: 0.0445  cls_loss: 0.3413  \n",
      "<<<iteration:[580/878] - total_loss: 0.8453  obj_loss: 0.1924  noobj_loss: 0.0653  bbox_loss: 0.0564  cls_loss: 0.3383  \n",
      "<<<iteration:[600/878] - total_loss: 0.8123  obj_loss: 0.1550  noobj_loss: 0.0589  bbox_loss: 0.0484  cls_loss: 0.3861  \n",
      "<<<iteration:[620/878] - total_loss: 0.9102  obj_loss: 0.2165  noobj_loss: 0.0662  bbox_loss: 0.0723  cls_loss: 0.2989  \n",
      "<<<iteration:[640/878] - total_loss: 0.8038  obj_loss: 0.1835  noobj_loss: 0.0635  bbox_loss: 0.0379  cls_loss: 0.3990  \n",
      "<<<iteration:[660/878] - total_loss: 0.8370  obj_loss: 0.2096  noobj_loss: 0.0593  bbox_loss: 0.0449  cls_loss: 0.3730  \n",
      "<<<iteration:[680/878] - total_loss: 0.8269  obj_loss: 0.1870  noobj_loss: 0.0629  bbox_loss: 0.0473  cls_loss: 0.3720  \n",
      "<<<iteration:[700/878] - total_loss: 0.8043  obj_loss: 0.1835  noobj_loss: 0.0616  bbox_loss: 0.0452  cls_loss: 0.3643  \n",
      "<<<iteration:[720/878] - total_loss: 0.7021  obj_loss: 0.1782  noobj_loss: 0.0597  bbox_loss: 0.0394  cls_loss: 0.2973  \n",
      "<<<iteration:[740/878] - total_loss: 0.8620  obj_loss: 0.1805  noobj_loss: 0.0566  bbox_loss: 0.0461  cls_loss: 0.4227  \n",
      "<<<iteration:[760/878] - total_loss: 0.9191  obj_loss: 0.2067  noobj_loss: 0.0671  bbox_loss: 0.0448  cls_loss: 0.4547  \n",
      "<<<iteration:[780/878] - total_loss: 1.6455  obj_loss: 0.1761  noobj_loss: 0.0759  bbox_loss: 0.2117  cls_loss: 0.3730  \n",
      "<<<iteration:[800/878] - total_loss: 1.0944  obj_loss: 0.1600  noobj_loss: 0.0666  bbox_loss: 0.1156  cls_loss: 0.3233  \n",
      "<<<iteration:[820/878] - total_loss: 1.1117  obj_loss: 0.1937  noobj_loss: 0.0613  bbox_loss: 0.0854  cls_loss: 0.4604  \n",
      "<<<iteration:[840/878] - total_loss: 0.8363  obj_loss: 0.1664  noobj_loss: 0.0540  bbox_loss: 0.0527  cls_loss: 0.3794  \n",
      "<<<iteration:[860/878] - total_loss: 0.8620  obj_loss: 0.1937  noobj_loss: 0.0578  bbox_loss: 0.0520  cls_loss: 0.3794  \n",
      "\n",
      "epoch:51/100 - Train Loss: 0.8612, Val Loss: 1.1606\n",
      "\n",
      "<<<iteration:[20/878] - total_loss: 0.8413  obj_loss: 0.1379  noobj_loss: 0.0660  bbox_loss: 0.0562  cls_loss: 0.3893  \n",
      "<<<iteration:[40/878] - total_loss: 0.7164  obj_loss: 0.1479  noobj_loss: 0.0572  bbox_loss: 0.0472  cls_loss: 0.3039  \n",
      "<<<iteration:[60/878] - total_loss: 0.8388  obj_loss: 0.1998  noobj_loss: 0.0599  bbox_loss: 0.0467  cls_loss: 0.3754  \n",
      "<<<iteration:[80/878] - total_loss: 0.8887  obj_loss: 0.1819  noobj_loss: 0.0592  bbox_loss: 0.0503  cls_loss: 0.4258  \n",
      "<<<iteration:[100/878] - total_loss: 0.7910  obj_loss: 0.1908  noobj_loss: 0.0728  bbox_loss: 0.0455  cls_loss: 0.3361  \n",
      "<<<iteration:[120/878] - total_loss: 0.8267  obj_loss: 0.1890  noobj_loss: 0.0588  bbox_loss: 0.0406  cls_loss: 0.4052  \n",
      "<<<iteration:[140/878] - total_loss: 0.8079  obj_loss: 0.1718  noobj_loss: 0.0757  bbox_loss: 0.0506  cls_loss: 0.3451  \n",
      "<<<iteration:[160/878] - total_loss: 0.8334  obj_loss: 0.1633  noobj_loss: 0.0538  bbox_loss: 0.0478  cls_loss: 0.4041  \n",
      "<<<iteration:[180/878] - total_loss: 0.8983  obj_loss: 0.1804  noobj_loss: 0.0707  bbox_loss: 0.0810  cls_loss: 0.2774  \n",
      "<<<iteration:[200/878] - total_loss: 0.7369  obj_loss: 0.1955  noobj_loss: 0.0628  bbox_loss: 0.0523  cls_loss: 0.2485  \n",
      "<<<iteration:[220/878] - total_loss: 0.8537  obj_loss: 0.2278  noobj_loss: 0.0675  bbox_loss: 0.0506  cls_loss: 0.3392  \n",
      "<<<iteration:[240/878] - total_loss: 0.7301  obj_loss: 0.1854  noobj_loss: 0.0665  bbox_loss: 0.0404  cls_loss: 0.3095  \n",
      "<<<iteration:[260/878] - total_loss: 0.8150  obj_loss: 0.1951  noobj_loss: 0.0618  bbox_loss: 0.0493  cls_loss: 0.3427  \n",
      "<<<iteration:[280/878] - total_loss: 0.8181  obj_loss: 0.1758  noobj_loss: 0.0597  bbox_loss: 0.0453  cls_loss: 0.3862  \n",
      "<<<iteration:[300/878] - total_loss: 0.9001  obj_loss: 0.1974  noobj_loss: 0.0635  bbox_loss: 0.0545  cls_loss: 0.3985  \n",
      "<<<iteration:[320/878] - total_loss: 0.7578  obj_loss: 0.1606  noobj_loss: 0.0563  bbox_loss: 0.0418  cls_loss: 0.3603  \n",
      "<<<iteration:[340/878] - total_loss: 0.8173  obj_loss: 0.1787  noobj_loss: 0.0631  bbox_loss: 0.0367  cls_loss: 0.4234  \n",
      "<<<iteration:[360/878] - total_loss: 0.8452  obj_loss: 0.2087  noobj_loss: 0.0629  bbox_loss: 0.0438  cls_loss: 0.3860  \n",
      "<<<iteration:[380/878] - total_loss: 0.7430  obj_loss: 0.1558  noobj_loss: 0.0574  bbox_loss: 0.0488  cls_loss: 0.3146  \n",
      "<<<iteration:[400/878] - total_loss: 0.8826  obj_loss: 0.1775  noobj_loss: 0.0602  bbox_loss: 0.0560  cls_loss: 0.3949  \n",
      "<<<iteration:[420/878] - total_loss: 0.7457  obj_loss: 0.1665  noobj_loss: 0.0645  bbox_loss: 0.0519  cls_loss: 0.2873  \n",
      "<<<iteration:[440/878] - total_loss: 0.9237  obj_loss: 0.1849  noobj_loss: 0.0605  bbox_loss: 0.0535  cls_loss: 0.4409  \n",
      "<<<iteration:[460/878] - total_loss: 0.8059  obj_loss: 0.1662  noobj_loss: 0.0593  bbox_loss: 0.0406  cls_loss: 0.4070  \n",
      "<<<iteration:[480/878] - total_loss: 0.8480  obj_loss: 0.1745  noobj_loss: 0.0593  bbox_loss: 0.0546  cls_loss: 0.3712  \n",
      "<<<iteration:[500/878] - total_loss: 0.7988  obj_loss: 0.1888  noobj_loss: 0.0630  bbox_loss: 0.0501  cls_loss: 0.3282  \n",
      "<<<iteration:[520/878] - total_loss: 0.7865  obj_loss: 0.1560  noobj_loss: 0.0658  bbox_loss: 0.0479  cls_loss: 0.3580  \n",
      "<<<iteration:[540/878] - total_loss: 0.7114  obj_loss: 0.1894  noobj_loss: 0.0650  bbox_loss: 0.0392  cls_loss: 0.2934  \n",
      "<<<iteration:[560/878] - total_loss: 1.0845  obj_loss: 0.2081  noobj_loss: 0.0703  bbox_loss: 0.0774  cls_loss: 0.4543  \n",
      "<<<iteration:[580/878] - total_loss: 0.9070  obj_loss: 0.2013  noobj_loss: 0.0664  bbox_loss: 0.0726  cls_loss: 0.3095  \n",
      "<<<iteration:[600/878] - total_loss: 0.7967  obj_loss: 0.1880  noobj_loss: 0.0671  bbox_loss: 0.0560  cls_loss: 0.2951  \n",
      "<<<iteration:[620/878] - total_loss: 1.2030  obj_loss: 0.2019  noobj_loss: 0.0759  bbox_loss: 0.1077  cls_loss: 0.4247  \n",
      "<<<iteration:[640/878] - total_loss: 1.4016  obj_loss: 0.1836  noobj_loss: 0.0612  bbox_loss: 0.1603  cls_loss: 0.3860  \n",
      "<<<iteration:[660/878] - total_loss: 0.8392  obj_loss: 0.1465  noobj_loss: 0.0639  bbox_loss: 0.0597  cls_loss: 0.3623  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<<<iteration:[680/878] - total_loss: 0.9371  obj_loss: 0.1789  noobj_loss: 0.0635  bbox_loss: 0.0679  cls_loss: 0.3872  \n",
      "<<<iteration:[700/878] - total_loss: 0.7497  obj_loss: 0.1500  noobj_loss: 0.0550  bbox_loss: 0.0445  cls_loss: 0.3495  \n",
      "<<<iteration:[720/878] - total_loss: 0.9934  obj_loss: 0.1991  noobj_loss: 0.0610  bbox_loss: 0.0690  cls_loss: 0.4187  \n",
      "<<<iteration:[740/878] - total_loss: 0.9571  obj_loss: 0.2001  noobj_loss: 0.0655  bbox_loss: 0.0474  cls_loss: 0.4872  \n",
      "<<<iteration:[760/878] - total_loss: 0.9919  obj_loss: 0.1739  noobj_loss: 0.0625  bbox_loss: 0.0619  cls_loss: 0.4772  \n",
      "<<<iteration:[780/878] - total_loss: 0.7444  obj_loss: 0.1781  noobj_loss: 0.0578  bbox_loss: 0.0548  cls_loss: 0.2634  \n",
      "<<<iteration:[800/878] - total_loss: 0.9073  obj_loss: 0.2044  noobj_loss: 0.0638  bbox_loss: 0.0522  cls_loss: 0.4099  \n",
      "<<<iteration:[820/878] - total_loss: 0.8772  obj_loss: 0.1855  noobj_loss: 0.0679  bbox_loss: 0.0458  cls_loss: 0.4289  \n",
      "<<<iteration:[840/878] - total_loss: 0.8759  obj_loss: 0.1748  noobj_loss: 0.0578  bbox_loss: 0.0498  cls_loss: 0.4231  \n",
      "<<<iteration:[860/878] - total_loss: 0.7003  obj_loss: 0.1969  noobj_loss: 0.0592  bbox_loss: 0.0434  cls_loss: 0.2569  \n",
      "\n",
      "epoch:52/100 - Train Loss: 0.8561, Val Loss: 1.1375\n",
      "\n",
      "<<<iteration:[20/878] - total_loss: 1.1033  obj_loss: 0.1835  noobj_loss: 0.0652  bbox_loss: 0.1013  cls_loss: 0.3807  \n",
      "<<<iteration:[40/878] - total_loss: 0.7817  obj_loss: 0.1895  noobj_loss: 0.0611  bbox_loss: 0.0608  cls_loss: 0.2576  \n",
      "<<<iteration:[60/878] - total_loss: 0.7514  obj_loss: 0.1722  noobj_loss: 0.0625  bbox_loss: 0.0619  cls_loss: 0.2383  \n",
      "<<<iteration:[80/878] - total_loss: 0.7512  obj_loss: 0.1617  noobj_loss: 0.0591  bbox_loss: 0.0395  cls_loss: 0.3624  \n",
      "<<<iteration:[100/878] - total_loss: 0.9688  obj_loss: 0.2179  noobj_loss: 0.0718  bbox_loss: 0.0502  cls_loss: 0.4642  \n",
      "<<<iteration:[120/878] - total_loss: 0.8836  obj_loss: 0.1946  noobj_loss: 0.0688  bbox_loss: 0.0548  cls_loss: 0.3806  \n",
      "<<<iteration:[140/878] - total_loss: 0.7123  obj_loss: 0.2200  noobj_loss: 0.0737  bbox_loss: 0.0401  cls_loss: 0.2550  \n",
      "<<<iteration:[160/878] - total_loss: 0.6638  obj_loss: 0.1607  noobj_loss: 0.0622  bbox_loss: 0.0450  cls_loss: 0.2467  \n",
      "<<<iteration:[180/878] - total_loss: 0.7450  obj_loss: 0.1865  noobj_loss: 0.0592  bbox_loss: 0.0422  cls_loss: 0.3177  \n",
      "<<<iteration:[200/878] - total_loss: 0.7469  obj_loss: 0.1829  noobj_loss: 0.0660  bbox_loss: 0.0465  cls_loss: 0.2983  \n",
      "<<<iteration:[220/878] - total_loss: 0.7985  obj_loss: 0.1702  noobj_loss: 0.0597  bbox_loss: 0.0426  cls_loss: 0.3857  \n",
      "<<<iteration:[240/878] - total_loss: 1.1850  obj_loss: 0.1342  noobj_loss: 0.0765  bbox_loss: 0.1155  cls_loss: 0.4353  \n",
      "<<<iteration:[260/878] - total_loss: 0.8577  obj_loss: 0.1706  noobj_loss: 0.0513  bbox_loss: 0.0438  cls_loss: 0.4425  \n",
      "<<<iteration:[280/878] - total_loss: 1.0771  obj_loss: 0.1787  noobj_loss: 0.0808  bbox_loss: 0.0965  cls_loss: 0.3757  \n",
      "<<<iteration:[300/878] - total_loss: 0.8301  obj_loss: 0.1719  noobj_loss: 0.0551  bbox_loss: 0.0646  cls_loss: 0.3079  \n",
      "<<<iteration:[320/878] - total_loss: 0.8492  obj_loss: 0.2042  noobj_loss: 0.0643  bbox_loss: 0.0447  cls_loss: 0.3895  \n",
      "<<<iteration:[340/878] - total_loss: 0.7432  obj_loss: 0.1958  noobj_loss: 0.0587  bbox_loss: 0.0405  cls_loss: 0.3154  \n",
      "<<<iteration:[360/878] - total_loss: 0.8582  obj_loss: 0.2436  noobj_loss: 0.0680  bbox_loss: 0.0526  cls_loss: 0.3176  \n",
      "<<<iteration:[380/878] - total_loss: 0.9022  obj_loss: 0.1920  noobj_loss: 0.0636  bbox_loss: 0.0613  cls_loss: 0.3717  \n",
      "<<<iteration:[400/878] - total_loss: 0.7303  obj_loss: 0.2210  noobj_loss: 0.0642  bbox_loss: 0.0413  cls_loss: 0.2705  \n",
      "<<<iteration:[420/878] - total_loss: 1.0497  obj_loss: 0.1781  noobj_loss: 0.0701  bbox_loss: 0.0994  cls_loss: 0.3397  \n",
      "<<<iteration:[440/878] - total_loss: 0.9127  obj_loss: 0.2262  noobj_loss: 0.0656  bbox_loss: 0.0526  cls_loss: 0.3907  \n",
      "<<<iteration:[460/878] - total_loss: 0.8795  obj_loss: 0.2037  noobj_loss: 0.0646  bbox_loss: 0.0473  cls_loss: 0.4070  \n",
      "<<<iteration:[480/878] - total_loss: 0.6992  obj_loss: 0.2010  noobj_loss: 0.0672  bbox_loss: 0.0439  cls_loss: 0.2454  \n",
      "<<<iteration:[500/878] - total_loss: 0.8552  obj_loss: 0.2031  noobj_loss: 0.0645  bbox_loss: 0.0401  cls_loss: 0.4193  \n",
      "<<<iteration:[520/878] - total_loss: 0.7182  obj_loss: 0.1617  noobj_loss: 0.0635  bbox_loss: 0.0435  cls_loss: 0.3071  \n",
      "<<<iteration:[540/878] - total_loss: 0.9483  obj_loss: 0.1737  noobj_loss: 0.0633  bbox_loss: 0.0502  cls_loss: 0.4919  \n",
      "<<<iteration:[560/878] - total_loss: 0.6007  obj_loss: 0.1649  noobj_loss: 0.0564  bbox_loss: 0.0418  cls_loss: 0.1988  \n",
      "<<<iteration:[580/878] - total_loss: 0.7208  obj_loss: 0.1635  noobj_loss: 0.0586  bbox_loss: 0.0469  cls_loss: 0.2936  \n",
      "<<<iteration:[600/878] - total_loss: 0.7671  obj_loss: 0.2022  noobj_loss: 0.0649  bbox_loss: 0.0419  cls_loss: 0.3231  \n",
      "<<<iteration:[620/878] - total_loss: 0.8986  obj_loss: 0.1729  noobj_loss: 0.0737  bbox_loss: 0.0607  cls_loss: 0.3855  \n",
      "<<<iteration:[640/878] - total_loss: 0.8009  obj_loss: 0.1752  noobj_loss: 0.0608  bbox_loss: 0.0576  cls_loss: 0.3071  \n",
      "<<<iteration:[660/878] - total_loss: 0.8128  obj_loss: 0.1874  noobj_loss: 0.0616  bbox_loss: 0.0437  cls_loss: 0.3761  \n",
      "<<<iteration:[680/878] - total_loss: 0.8491  obj_loss: 0.1962  noobj_loss: 0.0670  bbox_loss: 0.0615  cls_loss: 0.3121  \n",
      "<<<iteration:[700/878] - total_loss: 0.7718  obj_loss: 0.1795  noobj_loss: 0.0681  bbox_loss: 0.0446  cls_loss: 0.3350  \n",
      "<<<iteration:[720/878] - total_loss: 0.8503  obj_loss: 0.2009  noobj_loss: 0.0677  bbox_loss: 0.0499  cls_loss: 0.3659  \n",
      "<<<iteration:[740/878] - total_loss: 0.8128  obj_loss: 0.1861  noobj_loss: 0.0709  bbox_loss: 0.0469  cls_loss: 0.3565  \n",
      "<<<iteration:[760/878] - total_loss: 0.7536  obj_loss: 0.1547  noobj_loss: 0.0643  bbox_loss: 0.0385  cls_loss: 0.3743  \n",
      "<<<iteration:[780/878] - total_loss: 0.7339  obj_loss: 0.1555  noobj_loss: 0.0619  bbox_loss: 0.0354  cls_loss: 0.3706  \n",
      "<<<iteration:[800/878] - total_loss: 0.8502  obj_loss: 0.1979  noobj_loss: 0.0690  bbox_loss: 0.0500  cls_loss: 0.3677  \n",
      "<<<iteration:[820/878] - total_loss: 0.8683  obj_loss: 0.2092  noobj_loss: 0.0779  bbox_loss: 0.0487  cls_loss: 0.3767  \n",
      "<<<iteration:[840/878] - total_loss: 0.8474  obj_loss: 0.2061  noobj_loss: 0.0662  bbox_loss: 0.0426  cls_loss: 0.3951  \n",
      "<<<iteration:[860/878] - total_loss: 0.7256  obj_loss: 0.1682  noobj_loss: 0.0609  bbox_loss: 0.0371  cls_loss: 0.3417  \n",
      "\n",
      "epoch:53/100 - Train Loss: 0.8328, Val Loss: 1.2188\n",
      "\n",
      "<<<iteration:[20/878] - total_loss: 0.8674  obj_loss: 0.2076  noobj_loss: 0.0656  bbox_loss: 0.0487  cls_loss: 0.3836  \n",
      "<<<iteration:[40/878] - total_loss: 0.7451  obj_loss: 0.1968  noobj_loss: 0.0628  bbox_loss: 0.0575  cls_loss: 0.2293  \n",
      "<<<iteration:[60/878] - total_loss: 0.8867  obj_loss: 0.2183  noobj_loss: 0.0677  bbox_loss: 0.0542  cls_loss: 0.3636  \n",
      "<<<iteration:[80/878] - total_loss: 0.7169  obj_loss: 0.2061  noobj_loss: 0.0643  bbox_loss: 0.0414  cls_loss: 0.2715  \n",
      "<<<iteration:[100/878] - total_loss: 0.8067  obj_loss: 0.1786  noobj_loss: 0.0720  bbox_loss: 0.0469  cls_loss: 0.3573  \n",
      "<<<iteration:[120/878] - total_loss: 0.7748  obj_loss: 0.2208  noobj_loss: 0.0656  bbox_loss: 0.0436  cls_loss: 0.3030  \n",
      "<<<iteration:[140/878] - total_loss: 0.8662  obj_loss: 0.1474  noobj_loss: 0.0711  bbox_loss: 0.0551  cls_loss: 0.4075  \n",
      "<<<iteration:[160/878] - total_loss: 0.9032  obj_loss: 0.1823  noobj_loss: 0.0643  bbox_loss: 0.0642  cls_loss: 0.3677  \n",
      "<<<iteration:[180/878] - total_loss: 0.7718  obj_loss: 0.1593  noobj_loss: 0.0609  bbox_loss: 0.0434  cls_loss: 0.3648  \n",
      "<<<iteration:[200/878] - total_loss: 0.8695  obj_loss: 0.2024  noobj_loss: 0.0746  bbox_loss: 0.0472  cls_loss: 0.3940  \n",
      "<<<iteration:[220/878] - total_loss: 0.7527  obj_loss: 0.1678  noobj_loss: 0.0696  bbox_loss: 0.0440  cls_loss: 0.3300  \n",
      "<<<iteration:[240/878] - total_loss: 0.8482  obj_loss: 0.1779  noobj_loss: 0.0570  bbox_loss: 0.0490  cls_loss: 0.3967  \n",
      "<<<iteration:[260/878] - total_loss: 0.8294  obj_loss: 0.1779  noobj_loss: 0.0575  bbox_loss: 0.0510  cls_loss: 0.3678  \n",
      "<<<iteration:[280/878] - total_loss: 0.9746  obj_loss: 0.1824  noobj_loss: 0.0731  bbox_loss: 0.0872  cls_loss: 0.3197  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<<<iteration:[300/878] - total_loss: 0.7957  obj_loss: 0.1877  noobj_loss: 0.0584  bbox_loss: 0.0579  cls_loss: 0.2890  \n",
      "<<<iteration:[320/878] - total_loss: 0.8294  obj_loss: 0.1927  noobj_loss: 0.0671  bbox_loss: 0.0624  cls_loss: 0.2911  \n",
      "<<<iteration:[340/878] - total_loss: 0.9041  obj_loss: 0.2014  noobj_loss: 0.0681  bbox_loss: 0.0463  cls_loss: 0.4372  \n",
      "<<<iteration:[360/878] - total_loss: 0.7854  obj_loss: 0.1604  noobj_loss: 0.0816  bbox_loss: 0.0445  cls_loss: 0.3618  \n",
      "<<<iteration:[380/878] - total_loss: 0.8172  obj_loss: 0.2086  noobj_loss: 0.0677  bbox_loss: 0.0475  cls_loss: 0.3373  \n",
      "<<<iteration:[400/878] - total_loss: 0.7758  obj_loss: 0.1915  noobj_loss: 0.0660  bbox_loss: 0.0455  cls_loss: 0.3239  \n",
      "<<<iteration:[420/878] - total_loss: 0.7496  obj_loss: 0.2215  noobj_loss: 0.0719  bbox_loss: 0.0451  cls_loss: 0.2668  \n",
      "<<<iteration:[440/878] - total_loss: 0.8066  obj_loss: 0.2345  noobj_loss: 0.0681  bbox_loss: 0.0375  cls_loss: 0.3508  \n",
      "<<<iteration:[460/878] - total_loss: 0.8951  obj_loss: 0.1825  noobj_loss: 0.0758  bbox_loss: 0.0508  cls_loss: 0.4206  \n",
      "<<<iteration:[480/878] - total_loss: 0.7136  obj_loss: 0.1669  noobj_loss: 0.0666  bbox_loss: 0.0532  cls_loss: 0.2475  \n",
      "<<<iteration:[500/878] - total_loss: 0.9661  obj_loss: 0.1891  noobj_loss: 0.0702  bbox_loss: 0.0734  cls_loss: 0.3750  \n",
      "<<<iteration:[520/878] - total_loss: 0.7748  obj_loss: 0.2101  noobj_loss: 0.0796  bbox_loss: 0.0433  cls_loss: 0.3086  \n",
      "<<<iteration:[540/878] - total_loss: 0.7020  obj_loss: 0.2066  noobj_loss: 0.0702  bbox_loss: 0.0428  cls_loss: 0.2463  \n",
      "<<<iteration:[560/878] - total_loss: 0.6456  obj_loss: 0.1760  noobj_loss: 0.0603  bbox_loss: 0.0334  cls_loss: 0.2727  \n",
      "<<<iteration:[580/878] - total_loss: 0.7978  obj_loss: 0.1794  noobj_loss: 0.0699  bbox_loss: 0.0536  cls_loss: 0.3155  \n",
      "<<<iteration:[600/878] - total_loss: 0.7310  obj_loss: 0.2008  noobj_loss: 0.0738  bbox_loss: 0.0391  cls_loss: 0.2978  \n",
      "<<<iteration:[620/878] - total_loss: 1.0156  obj_loss: 0.1511  noobj_loss: 0.0783  bbox_loss: 0.1023  cls_loss: 0.3136  \n",
      "<<<iteration:[640/878] - total_loss: 0.7922  obj_loss: 0.1783  noobj_loss: 0.0676  bbox_loss: 0.0468  cls_loss: 0.3461  \n",
      "<<<iteration:[660/878] - total_loss: 0.8494  obj_loss: 0.2263  noobj_loss: 0.0637  bbox_loss: 0.0410  cls_loss: 0.3865  \n",
      "<<<iteration:[680/878] - total_loss: 0.7964  obj_loss: 0.1940  noobj_loss: 0.0728  bbox_loss: 0.0456  cls_loss: 0.3380  \n",
      "<<<iteration:[700/878] - total_loss: 0.7887  obj_loss: 0.1975  noobj_loss: 0.0662  bbox_loss: 0.0565  cls_loss: 0.2754  \n",
      "<<<iteration:[720/878] - total_loss: 0.8104  obj_loss: 0.2158  noobj_loss: 0.0608  bbox_loss: 0.0403  cls_loss: 0.3625  \n",
      "<<<iteration:[740/878] - total_loss: 0.8797  obj_loss: 0.2177  noobj_loss: 0.0738  bbox_loss: 0.0729  cls_loss: 0.2605  \n",
      "<<<iteration:[760/878] - total_loss: 0.7742  obj_loss: 0.1590  noobj_loss: 0.0626  bbox_loss: 0.0561  cls_loss: 0.3032  \n",
      "<<<iteration:[780/878] - total_loss: 0.7443  obj_loss: 0.2038  noobj_loss: 0.0667  bbox_loss: 0.0424  cls_loss: 0.2954  \n",
      "<<<iteration:[800/878] - total_loss: 0.6844  obj_loss: 0.1822  noobj_loss: 0.0642  bbox_loss: 0.0432  cls_loss: 0.2540  \n",
      "<<<iteration:[820/878] - total_loss: 0.7495  obj_loss: 0.2025  noobj_loss: 0.0685  bbox_loss: 0.0410  cls_loss: 0.3080  \n",
      "<<<iteration:[840/878] - total_loss: 0.7692  obj_loss: 0.1851  noobj_loss: 0.0705  bbox_loss: 0.0428  cls_loss: 0.3348  \n",
      "<<<iteration:[860/878] - total_loss: 0.7955  obj_loss: 0.2049  noobj_loss: 0.0775  bbox_loss: 0.0420  cls_loss: 0.3419  \n",
      "\n",
      "epoch:54/100 - Train Loss: 0.8070, Val Loss: 1.1739\n",
      "\n",
      "<<<iteration:[20/878] - total_loss: 0.7321  obj_loss: 0.1778  noobj_loss: 0.0743  bbox_loss: 0.0397  cls_loss: 0.3187  \n",
      "<<<iteration:[40/878] - total_loss: 0.7543  obj_loss: 0.2124  noobj_loss: 0.0674  bbox_loss: 0.0477  cls_loss: 0.2698  \n",
      "<<<iteration:[60/878] - total_loss: 0.6580  obj_loss: 0.1857  noobj_loss: 0.0741  bbox_loss: 0.0387  cls_loss: 0.2419  \n",
      "<<<iteration:[80/878] - total_loss: 0.8320  obj_loss: 0.1876  noobj_loss: 0.0686  bbox_loss: 0.0413  cls_loss: 0.4036  \n",
      "<<<iteration:[100/878] - total_loss: 0.7636  obj_loss: 0.1729  noobj_loss: 0.0677  bbox_loss: 0.0538  cls_loss: 0.2879  \n",
      "<<<iteration:[120/878] - total_loss: 0.7487  obj_loss: 0.1798  noobj_loss: 0.0649  bbox_loss: 0.0517  cls_loss: 0.2779  \n",
      "<<<iteration:[140/878] - total_loss: 0.5760  obj_loss: 0.1546  noobj_loss: 0.0557  bbox_loss: 0.0366  cls_loss: 0.2105  \n",
      "<<<iteration:[160/878] - total_loss: 0.7822  obj_loss: 0.2161  noobj_loss: 0.0750  bbox_loss: 0.0559  cls_loss: 0.2491  \n",
      "<<<iteration:[180/878] - total_loss: 0.7438  obj_loss: 0.1604  noobj_loss: 0.0672  bbox_loss: 0.0486  cls_loss: 0.3068  \n",
      "<<<iteration:[200/878] - total_loss: 0.9206  obj_loss: 0.1909  noobj_loss: 0.0661  bbox_loss: 0.0456  cls_loss: 0.4689  \n",
      "<<<iteration:[220/878] - total_loss: 0.6988  obj_loss: 0.1992  noobj_loss: 0.0634  bbox_loss: 0.0358  cls_loss: 0.2891  \n",
      "<<<iteration:[240/878] - total_loss: 1.0870  obj_loss: 0.1775  noobj_loss: 0.0721  bbox_loss: 0.0922  cls_loss: 0.4122  \n",
      "<<<iteration:[260/878] - total_loss: 1.2552  obj_loss: 0.1908  noobj_loss: 0.0642  bbox_loss: 0.1540  cls_loss: 0.2623  \n",
      "<<<iteration:[280/878] - total_loss: 1.2036  obj_loss: 0.1780  noobj_loss: 0.0617  bbox_loss: 0.1115  cls_loss: 0.4370  \n",
      "<<<iteration:[300/878] - total_loss: 0.8130  obj_loss: 0.2052  noobj_loss: 0.0733  bbox_loss: 0.0434  cls_loss: 0.3543  \n",
      "<<<iteration:[320/878] - total_loss: 0.8143  obj_loss: 0.2140  noobj_loss: 0.0688  bbox_loss: 0.0448  cls_loss: 0.3417  \n",
      "<<<iteration:[340/878] - total_loss: 0.7383  obj_loss: 0.1625  noobj_loss: 0.0646  bbox_loss: 0.0519  cls_loss: 0.2843  \n",
      "<<<iteration:[360/878] - total_loss: 0.6326  obj_loss: 0.1606  noobj_loss: 0.0603  bbox_loss: 0.0370  cls_loss: 0.2567  \n",
      "<<<iteration:[380/878] - total_loss: 0.7924  obj_loss: 0.2057  noobj_loss: 0.0726  bbox_loss: 0.0521  cls_loss: 0.2897  \n",
      "<<<iteration:[400/878] - total_loss: 0.8468  obj_loss: 0.1883  noobj_loss: 0.0621  bbox_loss: 0.0490  cls_loss: 0.3827  \n",
      "<<<iteration:[420/878] - total_loss: 0.6219  obj_loss: 0.1986  noobj_loss: 0.0702  bbox_loss: 0.0385  cls_loss: 0.1958  \n",
      "<<<iteration:[440/878] - total_loss: 0.8107  obj_loss: 0.1984  noobj_loss: 0.0730  bbox_loss: 0.0480  cls_loss: 0.3358  \n",
      "<<<iteration:[460/878] - total_loss: 0.7476  obj_loss: 0.1645  noobj_loss: 0.0674  bbox_loss: 0.0469  cls_loss: 0.3148  \n",
      "<<<iteration:[480/878] - total_loss: 0.8473  obj_loss: 0.1865  noobj_loss: 0.0710  bbox_loss: 0.0489  cls_loss: 0.3809  \n",
      "<<<iteration:[500/878] - total_loss: 0.9368  obj_loss: 0.2104  noobj_loss: 0.0828  bbox_loss: 0.0748  cls_loss: 0.3112  \n",
      "<<<iteration:[520/878] - total_loss: 0.7094  obj_loss: 0.1858  noobj_loss: 0.0679  bbox_loss: 0.0455  cls_loss: 0.2623  \n",
      "<<<iteration:[540/878] - total_loss: 0.7045  obj_loss: 0.1583  noobj_loss: 0.0649  bbox_loss: 0.0425  cls_loss: 0.3013  \n",
      "<<<iteration:[560/878] - total_loss: 0.6871  obj_loss: 0.1885  noobj_loss: 0.0688  bbox_loss: 0.0401  cls_loss: 0.2635  \n",
      "<<<iteration:[580/878] - total_loss: 0.7026  obj_loss: 0.2223  noobj_loss: 0.0683  bbox_loss: 0.0369  cls_loss: 0.2614  \n",
      "<<<iteration:[600/878] - total_loss: 0.7682  obj_loss: 0.2036  noobj_loss: 0.0829  bbox_loss: 0.0413  cls_loss: 0.3168  \n",
      "<<<iteration:[620/878] - total_loss: 0.8573  obj_loss: 0.2263  noobj_loss: 0.0762  bbox_loss: 0.0441  cls_loss: 0.3721  \n",
      "<<<iteration:[640/878] - total_loss: 0.6494  obj_loss: 0.1698  noobj_loss: 0.0708  bbox_loss: 0.0405  cls_loss: 0.2417  \n",
      "<<<iteration:[660/878] - total_loss: 0.8404  obj_loss: 0.2168  noobj_loss: 0.0751  bbox_loss: 0.0486  cls_loss: 0.3430  \n",
      "<<<iteration:[680/878] - total_loss: 0.6937  obj_loss: 0.1921  noobj_loss: 0.0758  bbox_loss: 0.0439  cls_loss: 0.2445  \n",
      "<<<iteration:[700/878] - total_loss: 0.7237  obj_loss: 0.1627  noobj_loss: 0.0671  bbox_loss: 0.0389  cls_loss: 0.3333  \n",
      "<<<iteration:[720/878] - total_loss: 0.8340  obj_loss: 0.2145  noobj_loss: 0.0754  bbox_loss: 0.0433  cls_loss: 0.3654  \n",
      "<<<iteration:[740/878] - total_loss: 0.7246  obj_loss: 0.1592  noobj_loss: 0.0665  bbox_loss: 0.0433  cls_loss: 0.3157  \n",
      "<<<iteration:[760/878] - total_loss: 0.7436  obj_loss: 0.1839  noobj_loss: 0.0649  bbox_loss: 0.0426  cls_loss: 0.3142  \n",
      "<<<iteration:[780/878] - total_loss: 0.8424  obj_loss: 0.2278  noobj_loss: 0.0790  bbox_loss: 0.0397  cls_loss: 0.3768  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<<<iteration:[800/878] - total_loss: 0.7118  obj_loss: 0.1822  noobj_loss: 0.0762  bbox_loss: 0.0424  cls_loss: 0.2793  \n",
      "<<<iteration:[820/878] - total_loss: 0.8461  obj_loss: 0.1807  noobj_loss: 0.0716  bbox_loss: 0.0383  cls_loss: 0.4381  \n",
      "<<<iteration:[840/878] - total_loss: 0.8392  obj_loss: 0.1911  noobj_loss: 0.0763  bbox_loss: 0.0635  cls_loss: 0.2923  \n",
      "<<<iteration:[860/878] - total_loss: 0.8820  obj_loss: 0.1820  noobj_loss: 0.0784  bbox_loss: 0.0558  cls_loss: 0.3816  \n",
      "\n",
      "epoch:55/100 - Train Loss: 0.7895, Val Loss: 1.1597\n",
      "\n",
      "<<<iteration:[20/878] - total_loss: 0.8101  obj_loss: 0.2014  noobj_loss: 0.0688  bbox_loss: 0.0473  cls_loss: 0.3379  \n",
      "<<<iteration:[40/878] - total_loss: 0.7509  obj_loss: 0.1730  noobj_loss: 0.0751  bbox_loss: 0.0390  cls_loss: 0.3454  \n",
      "<<<iteration:[60/878] - total_loss: 0.6776  obj_loss: 0.1891  noobj_loss: 0.0724  bbox_loss: 0.0450  cls_loss: 0.2271  \n",
      "<<<iteration:[80/878] - total_loss: 0.7266  obj_loss: 0.1849  noobj_loss: 0.0719  bbox_loss: 0.0393  cls_loss: 0.3095  \n",
      "<<<iteration:[100/878] - total_loss: 1.0146  obj_loss: 0.2353  noobj_loss: 0.0945  bbox_loss: 0.0677  cls_loss: 0.3935  \n",
      "<<<iteration:[120/878] - total_loss: 0.7139  obj_loss: 0.1950  noobj_loss: 0.0721  bbox_loss: 0.0382  cls_loss: 0.2917  \n",
      "<<<iteration:[140/878] - total_loss: 0.6807  obj_loss: 0.1971  noobj_loss: 0.0683  bbox_loss: 0.0393  cls_loss: 0.2528  \n",
      "<<<iteration:[160/878] - total_loss: 0.8598  obj_loss: 0.2130  noobj_loss: 0.0769  bbox_loss: 0.0450  cls_loss: 0.3831  \n",
      "<<<iteration:[180/878] - total_loss: 0.6960  obj_loss: 0.2082  noobj_loss: 0.0860  bbox_loss: 0.0463  cls_loss: 0.2131  \n",
      "<<<iteration:[200/878] - total_loss: 0.8035  obj_loss: 0.1960  noobj_loss: 0.0745  bbox_loss: 0.0478  cls_loss: 0.3313  \n",
      "<<<iteration:[220/878] - total_loss: 0.7889  obj_loss: 0.1924  noobj_loss: 0.0753  bbox_loss: 0.0517  cls_loss: 0.3005  \n",
      "<<<iteration:[240/878] - total_loss: 0.7100  obj_loss: 0.1860  noobj_loss: 0.0661  bbox_loss: 0.0447  cls_loss: 0.2673  \n",
      "<<<iteration:[260/878] - total_loss: 0.9099  obj_loss: 0.2167  noobj_loss: 0.0752  bbox_loss: 0.0442  cls_loss: 0.4347  \n",
      "<<<iteration:[280/878] - total_loss: 0.7533  obj_loss: 0.1714  noobj_loss: 0.0709  bbox_loss: 0.0527  cls_loss: 0.2829  \n",
      "<<<iteration:[300/878] - total_loss: 0.7302  obj_loss: 0.1608  noobj_loss: 0.0717  bbox_loss: 0.0500  cls_loss: 0.2837  \n",
      "<<<iteration:[320/878] - total_loss: 0.7095  obj_loss: 0.2073  noobj_loss: 0.0794  bbox_loss: 0.0456  cls_loss: 0.2343  \n",
      "<<<iteration:[340/878] - total_loss: 0.8596  obj_loss: 0.1628  noobj_loss: 0.0818  bbox_loss: 0.0526  cls_loss: 0.3926  \n",
      "<<<iteration:[360/878] - total_loss: 0.6574  obj_loss: 0.2298  noobj_loss: 0.0755  bbox_loss: 0.0346  cls_loss: 0.2168  \n",
      "<<<iteration:[380/878] - total_loss: 0.7760  obj_loss: 0.1949  noobj_loss: 0.0973  bbox_loss: 0.0476  cls_loss: 0.2944  \n",
      "<<<iteration:[400/878] - total_loss: 0.7301  obj_loss: 0.1944  noobj_loss: 0.0677  bbox_loss: 0.0440  cls_loss: 0.2819  \n",
      "<<<iteration:[420/878] - total_loss: 0.5806  obj_loss: 0.1880  noobj_loss: 0.0689  bbox_loss: 0.0366  cls_loss: 0.1749  \n",
      "<<<iteration:[440/878] - total_loss: 0.8228  obj_loss: 0.2040  noobj_loss: 0.0759  bbox_loss: 0.0476  cls_loss: 0.3429  \n",
      "<<<iteration:[460/878] - total_loss: 0.7657  obj_loss: 0.1824  noobj_loss: 0.0765  bbox_loss: 0.0525  cls_loss: 0.2824  \n",
      "<<<iteration:[480/878] - total_loss: 0.7621  obj_loss: 0.1772  noobj_loss: 0.0682  bbox_loss: 0.0415  cls_loss: 0.3431  \n",
      "<<<iteration:[500/878] - total_loss: 0.6422  obj_loss: 0.1652  noobj_loss: 0.0725  bbox_loss: 0.0343  cls_loss: 0.2693  \n",
      "<<<iteration:[520/878] - total_loss: 0.8577  obj_loss: 0.2007  noobj_loss: 0.0671  bbox_loss: 0.0405  cls_loss: 0.4209  \n",
      "<<<iteration:[540/878] - total_loss: 0.7080  obj_loss: 0.2031  noobj_loss: 0.0738  bbox_loss: 0.0411  cls_loss: 0.2625  \n",
      "<<<iteration:[560/878] - total_loss: 0.8287  obj_loss: 0.1909  noobj_loss: 0.0798  bbox_loss: 0.0480  cls_loss: 0.3582  \n",
      "<<<iteration:[580/878] - total_loss: 0.7982  obj_loss: 0.1795  noobj_loss: 0.0684  bbox_loss: 0.0392  cls_loss: 0.3886  \n",
      "<<<iteration:[600/878] - total_loss: 0.7952  obj_loss: 0.2028  noobj_loss: 0.0964  bbox_loss: 0.0477  cls_loss: 0.3055  \n",
      "<<<iteration:[620/878] - total_loss: 0.6623  obj_loss: 0.1779  noobj_loss: 0.0589  bbox_loss: 0.0379  cls_loss: 0.2655  \n",
      "<<<iteration:[640/878] - total_loss: 0.7023  obj_loss: 0.2051  noobj_loss: 0.0758  bbox_loss: 0.0331  cls_loss: 0.2939  \n",
      "<<<iteration:[660/878] - total_loss: 0.7699  obj_loss: 0.1918  noobj_loss: 0.0868  bbox_loss: 0.0438  cls_loss: 0.3155  \n",
      "<<<iteration:[680/878] - total_loss: 0.6554  obj_loss: 0.2137  noobj_loss: 0.0733  bbox_loss: 0.0390  cls_loss: 0.2099  \n",
      "<<<iteration:[700/878] - total_loss: 0.7198  obj_loss: 0.1928  noobj_loss: 0.0893  bbox_loss: 0.0513  cls_loss: 0.2260  \n",
      "<<<iteration:[720/878] - total_loss: 0.6981  obj_loss: 0.1688  noobj_loss: 0.0763  bbox_loss: 0.0328  cls_loss: 0.3269  \n",
      "<<<iteration:[740/878] - total_loss: 0.8368  obj_loss: 0.2068  noobj_loss: 0.0889  bbox_loss: 0.0503  cls_loss: 0.3343  \n",
      "<<<iteration:[760/878] - total_loss: 0.7584  obj_loss: 0.1825  noobj_loss: 0.0733  bbox_loss: 0.0365  cls_loss: 0.3567  \n",
      "<<<iteration:[780/878] - total_loss: 0.5910  obj_loss: 0.1488  noobj_loss: 0.0653  bbox_loss: 0.0380  cls_loss: 0.2196  \n",
      "<<<iteration:[800/878] - total_loss: 0.8019  obj_loss: 0.1684  noobj_loss: 0.0705  bbox_loss: 0.0360  cls_loss: 0.4183  \n",
      "<<<iteration:[820/878] - total_loss: 0.7035  obj_loss: 0.1904  noobj_loss: 0.0749  bbox_loss: 0.0384  cls_loss: 0.2834  \n",
      "<<<iteration:[840/878] - total_loss: 0.7774  obj_loss: 0.2032  noobj_loss: 0.0773  bbox_loss: 0.0502  cls_loss: 0.2847  \n",
      "<<<iteration:[860/878] - total_loss: 0.7028  obj_loss: 0.1675  noobj_loss: 0.0685  bbox_loss: 0.0473  cls_loss: 0.2646  \n",
      "\n",
      "epoch:56/100 - Train Loss: 0.7517, Val Loss: 1.1679\n",
      "\n",
      "<<<iteration:[20/878] - total_loss: 0.8800  obj_loss: 0.2175  noobj_loss: 0.0789  bbox_loss: 0.0584  cls_loss: 0.3309  \n",
      "<<<iteration:[40/878] - total_loss: 0.7834  obj_loss: 0.1865  noobj_loss: 0.0702  bbox_loss: 0.0431  cls_loss: 0.3461  \n",
      "<<<iteration:[60/878] - total_loss: 0.6806  obj_loss: 0.1412  noobj_loss: 0.0715  bbox_loss: 0.0464  cls_loss: 0.2718  \n",
      "<<<iteration:[80/878] - total_loss: 0.8627  obj_loss: 0.2167  noobj_loss: 0.0769  bbox_loss: 0.0589  cls_loss: 0.3129  \n",
      "<<<iteration:[100/878] - total_loss: 0.8323  obj_loss: 0.1925  noobj_loss: 0.0829  bbox_loss: 0.0495  cls_loss: 0.3508  \n",
      "<<<iteration:[120/878] - total_loss: 0.8171  obj_loss: 0.2016  noobj_loss: 0.0694  bbox_loss: 0.0456  cls_loss: 0.3529  \n",
      "<<<iteration:[140/878] - total_loss: 0.8389  obj_loss: 0.2356  noobj_loss: 0.0823  bbox_loss: 0.0513  cls_loss: 0.3058  \n",
      "<<<iteration:[160/878] - total_loss: 0.7424  obj_loss: 0.1894  noobj_loss: 0.0786  bbox_loss: 0.0397  cls_loss: 0.3150  \n",
      "<<<iteration:[180/878] - total_loss: 0.7090  obj_loss: 0.1904  noobj_loss: 0.0666  bbox_loss: 0.0449  cls_loss: 0.2608  \n",
      "<<<iteration:[200/878] - total_loss: 0.7804  obj_loss: 0.2064  noobj_loss: 0.0853  bbox_loss: 0.0427  cls_loss: 0.3179  \n",
      "<<<iteration:[220/878] - total_loss: 0.6227  obj_loss: 0.1818  noobj_loss: 0.0920  bbox_loss: 0.0445  cls_loss: 0.1722  \n",
      "<<<iteration:[240/878] - total_loss: 0.7499  obj_loss: 0.2215  noobj_loss: 0.0787  bbox_loss: 0.0399  cls_loss: 0.2895  \n",
      "<<<iteration:[260/878] - total_loss: 0.6785  obj_loss: 0.1980  noobj_loss: 0.0828  bbox_loss: 0.0379  cls_loss: 0.2495  \n",
      "<<<iteration:[280/878] - total_loss: 0.6593  obj_loss: 0.1750  noobj_loss: 0.0746  bbox_loss: 0.0408  cls_loss: 0.2429  \n",
      "<<<iteration:[300/878] - total_loss: 0.7705  obj_loss: 0.1879  noobj_loss: 0.0822  bbox_loss: 0.0519  cls_loss: 0.2818  \n",
      "<<<iteration:[320/878] - total_loss: 0.8394  obj_loss: 0.2104  noobj_loss: 0.0885  bbox_loss: 0.0544  cls_loss: 0.3124  \n",
      "<<<iteration:[340/878] - total_loss: 0.6809  obj_loss: 0.1639  noobj_loss: 0.0667  bbox_loss: 0.0411  cls_loss: 0.2782  \n",
      "<<<iteration:[360/878] - total_loss: 0.7434  obj_loss: 0.2037  noobj_loss: 0.0697  bbox_loss: 0.0392  cls_loss: 0.3088  \n",
      "<<<iteration:[380/878] - total_loss: 0.7348  obj_loss: 0.1801  noobj_loss: 0.0721  bbox_loss: 0.0516  cls_loss: 0.2606  \n",
      "<<<iteration:[400/878] - total_loss: 0.6207  obj_loss: 0.1889  noobj_loss: 0.0691  bbox_loss: 0.0291  cls_loss: 0.2518  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<<<iteration:[420/878] - total_loss: 0.8276  obj_loss: 0.2040  noobj_loss: 0.0829  bbox_loss: 0.0508  cls_loss: 0.3283  \n",
      "<<<iteration:[440/878] - total_loss: 0.7911  obj_loss: 0.2005  noobj_loss: 0.0733  bbox_loss: 0.0436  cls_loss: 0.3358  \n",
      "<<<iteration:[460/878] - total_loss: 0.7272  obj_loss: 0.1855  noobj_loss: 0.0797  bbox_loss: 0.0390  cls_loss: 0.3069  \n",
      "<<<iteration:[480/878] - total_loss: 0.7228  obj_loss: 0.2225  noobj_loss: 0.0747  bbox_loss: 0.0376  cls_loss: 0.2751  \n",
      "<<<iteration:[500/878] - total_loss: 0.6798  obj_loss: 0.1872  noobj_loss: 0.0752  bbox_loss: 0.0410  cls_loss: 0.2499  \n",
      "<<<iteration:[520/878] - total_loss: 0.7224  obj_loss: 0.1870  noobj_loss: 0.0739  bbox_loss: 0.0418  cls_loss: 0.2896  \n",
      "<<<iteration:[540/878] - total_loss: 0.7943  obj_loss: 0.2240  noobj_loss: 0.0816  bbox_loss: 0.0467  cls_loss: 0.2958  \n",
      "<<<iteration:[560/878] - total_loss: 0.7706  obj_loss: 0.2161  noobj_loss: 0.0746  bbox_loss: 0.0400  cls_loss: 0.3170  \n",
      "<<<iteration:[580/878] - total_loss: 0.7715  obj_loss: 0.1745  noobj_loss: 0.0720  bbox_loss: 0.0397  cls_loss: 0.3627  \n",
      "<<<iteration:[600/878] - total_loss: 0.7630  obj_loss: 0.2197  noobj_loss: 0.0764  bbox_loss: 0.0472  cls_loss: 0.2692  \n",
      "<<<iteration:[620/878] - total_loss: 0.7658  obj_loss: 0.1814  noobj_loss: 0.0744  bbox_loss: 0.0371  cls_loss: 0.3617  \n",
      "<<<iteration:[640/878] - total_loss: 0.7044  obj_loss: 0.1907  noobj_loss: 0.0700  bbox_loss: 0.0433  cls_loss: 0.2621  \n",
      "<<<iteration:[660/878] - total_loss: 0.7261  obj_loss: 0.2020  noobj_loss: 0.0697  bbox_loss: 0.0370  cls_loss: 0.3041  \n",
      "<<<iteration:[680/878] - total_loss: 0.6117  obj_loss: 0.1650  noobj_loss: 0.0728  bbox_loss: 0.0406  cls_loss: 0.2070  \n",
      "<<<iteration:[700/878] - total_loss: 0.7236  obj_loss: 0.2131  noobj_loss: 0.0753  bbox_loss: 0.0372  cls_loss: 0.2868  \n",
      "<<<iteration:[720/878] - total_loss: 0.7444  obj_loss: 0.2175  noobj_loss: 0.0800  bbox_loss: 0.0372  cls_loss: 0.3007  \n",
      "<<<iteration:[740/878] - total_loss: 0.7950  obj_loss: 0.2054  noobj_loss: 0.0860  bbox_loss: 0.0366  cls_loss: 0.3633  \n",
      "<<<iteration:[760/878] - total_loss: 0.7551  obj_loss: 0.1846  noobj_loss: 0.0784  bbox_loss: 0.0466  cls_loss: 0.2983  \n",
      "<<<iteration:[780/878] - total_loss: 0.7001  obj_loss: 0.1826  noobj_loss: 0.0781  bbox_loss: 0.0375  cls_loss: 0.2910  \n",
      "<<<iteration:[800/878] - total_loss: 0.7392  obj_loss: 0.1796  noobj_loss: 0.0757  bbox_loss: 0.0419  cls_loss: 0.3120  \n",
      "<<<iteration:[820/878] - total_loss: 0.7108  obj_loss: 0.2115  noobj_loss: 0.0755  bbox_loss: 0.0433  cls_loss: 0.2448  \n",
      "<<<iteration:[840/878] - total_loss: 0.6045  obj_loss: 0.1998  noobj_loss: 0.0868  bbox_loss: 0.0376  cls_loss: 0.1733  \n",
      "<<<iteration:[860/878] - total_loss: 0.6323  obj_loss: 0.1725  noobj_loss: 0.0676  bbox_loss: 0.0355  cls_loss: 0.2485  \n",
      "\n",
      "epoch:57/100 - Train Loss: 0.7422, Val Loss: 1.1879\n",
      "\n",
      "<<<iteration:[20/878] - total_loss: 0.8108  obj_loss: 0.2226  noobj_loss: 0.0744  bbox_loss: 0.0461  cls_loss: 0.3203  \n",
      "<<<iteration:[40/878] - total_loss: 0.7313  obj_loss: 0.2060  noobj_loss: 0.0838  bbox_loss: 0.0417  cls_loss: 0.2749  \n",
      "<<<iteration:[60/878] - total_loss: 0.6799  obj_loss: 0.1936  noobj_loss: 0.0822  bbox_loss: 0.0350  cls_loss: 0.2701  \n",
      "<<<iteration:[80/878] - total_loss: 0.8024  obj_loss: 0.1956  noobj_loss: 0.0786  bbox_loss: 0.0485  cls_loss: 0.3250  \n",
      "<<<iteration:[100/878] - total_loss: 0.6927  obj_loss: 0.1722  noobj_loss: 0.0699  bbox_loss: 0.0448  cls_loss: 0.2614  \n",
      "<<<iteration:[120/878] - total_loss: 0.7485  obj_loss: 0.2024  noobj_loss: 0.0808  bbox_loss: 0.0443  cls_loss: 0.2843  \n",
      "<<<iteration:[140/878] - total_loss: 0.6960  obj_loss: 0.1925  noobj_loss: 0.0858  bbox_loss: 0.0392  cls_loss: 0.2645  \n",
      "<<<iteration:[160/878] - total_loss: 0.7114  obj_loss: 0.1907  noobj_loss: 0.0727  bbox_loss: 0.0399  cls_loss: 0.2847  \n",
      "<<<iteration:[180/878] - total_loss: 0.7042  obj_loss: 0.1756  noobj_loss: 0.0791  bbox_loss: 0.0375  cls_loss: 0.3016  \n",
      "<<<iteration:[200/878] - total_loss: 0.6681  obj_loss: 0.2178  noobj_loss: 0.0754  bbox_loss: 0.0369  cls_loss: 0.2278  \n",
      "<<<iteration:[220/878] - total_loss: 0.6724  obj_loss: 0.2208  noobj_loss: 0.0786  bbox_loss: 0.0361  cls_loss: 0.2319  \n",
      "<<<iteration:[240/878] - total_loss: 0.7343  obj_loss: 0.2179  noobj_loss: 0.0850  bbox_loss: 0.0406  cls_loss: 0.2708  \n",
      "<<<iteration:[260/878] - total_loss: 0.7162  obj_loss: 0.2053  noobj_loss: 0.0789  bbox_loss: 0.0476  cls_loss: 0.2334  \n",
      "<<<iteration:[280/878] - total_loss: 0.7629  obj_loss: 0.2267  noobj_loss: 0.0838  bbox_loss: 0.0380  cls_loss: 0.3042  \n",
      "<<<iteration:[300/878] - total_loss: 0.6342  obj_loss: 0.2052  noobj_loss: 0.0865  bbox_loss: 0.0297  cls_loss: 0.2375  \n",
      "<<<iteration:[320/878] - total_loss: 0.6909  obj_loss: 0.1635  noobj_loss: 0.0770  bbox_loss: 0.0484  cls_loss: 0.2469  \n",
      "<<<iteration:[340/878] - total_loss: 0.6270  obj_loss: 0.1670  noobj_loss: 0.0763  bbox_loss: 0.0314  cls_loss: 0.2649  \n",
      "<<<iteration:[360/878] - total_loss: 0.6811  obj_loss: 0.2074  noobj_loss: 0.0782  bbox_loss: 0.0357  cls_loss: 0.2561  \n",
      "<<<iteration:[380/878] - total_loss: 0.7013  obj_loss: 0.2163  noobj_loss: 0.0787  bbox_loss: 0.0363  cls_loss: 0.2643  \n",
      "<<<iteration:[400/878] - total_loss: 0.7100  obj_loss: 0.1726  noobj_loss: 0.0811  bbox_loss: 0.0420  cls_loss: 0.2871  \n",
      "<<<iteration:[420/878] - total_loss: 0.7255  obj_loss: 0.1843  noobj_loss: 0.0765  bbox_loss: 0.0363  cls_loss: 0.3216  \n",
      "<<<iteration:[440/878] - total_loss: 0.7934  obj_loss: 0.1959  noobj_loss: 0.0847  bbox_loss: 0.0401  cls_loss: 0.3547  \n",
      "<<<iteration:[460/878] - total_loss: 0.7297  obj_loss: 0.2301  noobj_loss: 0.0873  bbox_loss: 0.0469  cls_loss: 0.2213  \n",
      "<<<iteration:[480/878] - total_loss: 0.7200  obj_loss: 0.1872  noobj_loss: 0.0703  bbox_loss: 0.0368  cls_loss: 0.3138  \n",
      "<<<iteration:[500/878] - total_loss: 0.6245  obj_loss: 0.1951  noobj_loss: 0.0686  bbox_loss: 0.0308  cls_loss: 0.2413  \n",
      "<<<iteration:[520/878] - total_loss: 0.6555  obj_loss: 0.2190  noobj_loss: 0.0813  bbox_loss: 0.0335  cls_loss: 0.2285  \n",
      "<<<iteration:[540/878] - total_loss: 0.7375  obj_loss: 0.1903  noobj_loss: 0.0664  bbox_loss: 0.0430  cls_loss: 0.2988  \n",
      "<<<iteration:[560/878] - total_loss: 0.8418  obj_loss: 0.1937  noobj_loss: 0.0748  bbox_loss: 0.0483  cls_loss: 0.3691  \n",
      "<<<iteration:[580/878] - total_loss: 0.7667  obj_loss: 0.2289  noobj_loss: 0.0885  bbox_loss: 0.0327  cls_loss: 0.3299  \n",
      "<<<iteration:[600/878] - total_loss: 0.8039  obj_loss: 0.2411  noobj_loss: 0.0855  bbox_loss: 0.0442  cls_loss: 0.2989  \n",
      "<<<iteration:[620/878] - total_loss: 0.7148  obj_loss: 0.1963  noobj_loss: 0.0732  bbox_loss: 0.0389  cls_loss: 0.2872  \n",
      "<<<iteration:[640/878] - total_loss: 0.6953  obj_loss: 0.1960  noobj_loss: 0.0901  bbox_loss: 0.0347  cls_loss: 0.2807  \n",
      "<<<iteration:[660/878] - total_loss: 0.6722  obj_loss: 0.2029  noobj_loss: 0.0828  bbox_loss: 0.0442  cls_loss: 0.2070  \n",
      "<<<iteration:[680/878] - total_loss: 0.7941  obj_loss: 0.2053  noobj_loss: 0.0831  bbox_loss: 0.0436  cls_loss: 0.3294  \n",
      "<<<iteration:[700/878] - total_loss: 0.8137  obj_loss: 0.2399  noobj_loss: 0.0873  bbox_loss: 0.0400  cls_loss: 0.3303  \n",
      "<<<iteration:[720/878] - total_loss: 0.7479  obj_loss: 0.2136  noobj_loss: 0.0807  bbox_loss: 0.0450  cls_loss: 0.2688  \n",
      "<<<iteration:[740/878] - total_loss: 0.7907  obj_loss: 0.1740  noobj_loss: 0.0732  bbox_loss: 0.0371  cls_loss: 0.3945  \n",
      "<<<iteration:[760/878] - total_loss: 0.6352  obj_loss: 0.1973  noobj_loss: 0.0766  bbox_loss: 0.0385  cls_loss: 0.2070  \n",
      "<<<iteration:[780/878] - total_loss: 0.9071  obj_loss: 0.2259  noobj_loss: 0.0749  bbox_loss: 0.0573  cls_loss: 0.3570  \n",
      "<<<iteration:[800/878] - total_loss: 0.6159  obj_loss: 0.1855  noobj_loss: 0.0697  bbox_loss: 0.0417  cls_loss: 0.1870  \n",
      "<<<iteration:[820/878] - total_loss: 0.5349  obj_loss: 0.1640  noobj_loss: 0.0732  bbox_loss: 0.0342  cls_loss: 0.1632  \n",
      "<<<iteration:[840/878] - total_loss: 0.7471  obj_loss: 0.2138  noobj_loss: 0.0876  bbox_loss: 0.0430  cls_loss: 0.2744  \n",
      "<<<iteration:[860/878] - total_loss: 0.7132  obj_loss: 0.1770  noobj_loss: 0.0828  bbox_loss: 0.0397  cls_loss: 0.2961  \n",
      "\n",
      "epoch:58/100 - Train Loss: 0.7206, Val Loss: 1.1854\n",
      "\n",
      "<<<iteration:[20/878] - total_loss: 0.7780  obj_loss: 0.2441  noobj_loss: 0.0896  bbox_loss: 0.0340  cls_loss: 0.3191  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<<<iteration:[40/878] - total_loss: 0.6894  obj_loss: 0.1842  noobj_loss: 0.0828  bbox_loss: 0.0310  cls_loss: 0.3085  \n",
      "<<<iteration:[60/878] - total_loss: 0.7442  obj_loss: 0.2221  noobj_loss: 0.0876  bbox_loss: 0.0363  cls_loss: 0.2966  \n",
      "<<<iteration:[80/878] - total_loss: 0.5842  obj_loss: 0.1518  noobj_loss: 0.0809  bbox_loss: 0.0346  cls_loss: 0.2188  \n",
      "<<<iteration:[100/878] - total_loss: 0.6976  obj_loss: 0.1970  noobj_loss: 0.0899  bbox_loss: 0.0340  cls_loss: 0.2854  \n",
      "<<<iteration:[120/878] - total_loss: 0.8101  obj_loss: 0.1777  noobj_loss: 0.0702  bbox_loss: 0.0561  cls_loss: 0.3169  \n",
      "<<<iteration:[140/878] - total_loss: 0.7896  obj_loss: 0.1982  noobj_loss: 0.0812  bbox_loss: 0.0499  cls_loss: 0.3012  \n",
      "<<<iteration:[160/878] - total_loss: 0.7189  obj_loss: 0.1895  noobj_loss: 0.0760  bbox_loss: 0.0415  cls_loss: 0.2840  \n",
      "<<<iteration:[180/878] - total_loss: 0.6851  obj_loss: 0.2058  noobj_loss: 0.0737  bbox_loss: 0.0429  cls_loss: 0.2279  \n",
      "<<<iteration:[200/878] - total_loss: 0.6784  obj_loss: 0.2069  noobj_loss: 0.0831  bbox_loss: 0.0357  cls_loss: 0.2513  \n",
      "<<<iteration:[220/878] - total_loss: 0.7000  obj_loss: 0.1937  noobj_loss: 0.0799  bbox_loss: 0.0335  cls_loss: 0.2986  \n",
      "<<<iteration:[240/878] - total_loss: 0.6542  obj_loss: 0.1774  noobj_loss: 0.0711  bbox_loss: 0.0351  cls_loss: 0.2659  \n",
      "<<<iteration:[260/878] - total_loss: 0.7086  obj_loss: 0.1711  noobj_loss: 0.0738  bbox_loss: 0.0578  cls_loss: 0.2116  \n",
      "<<<iteration:[280/878] - total_loss: 0.8907  obj_loss: 0.2418  noobj_loss: 0.0830  bbox_loss: 0.0637  cls_loss: 0.2889  \n",
      "<<<iteration:[300/878] - total_loss: 0.8134  obj_loss: 0.2319  noobj_loss: 0.0782  bbox_loss: 0.0575  cls_loss: 0.2551  \n",
      "<<<iteration:[320/878] - total_loss: 0.5949  obj_loss: 0.1816  noobj_loss: 0.0818  bbox_loss: 0.0330  cls_loss: 0.2073  \n",
      "<<<iteration:[340/878] - total_loss: 0.7559  obj_loss: 0.2078  noobj_loss: 0.0809  bbox_loss: 0.0404  cls_loss: 0.3055  \n",
      "<<<iteration:[360/878] - total_loss: 0.6908  obj_loss: 0.1911  noobj_loss: 0.0791  bbox_loss: 0.0425  cls_loss: 0.2476  \n",
      "<<<iteration:[380/878] - total_loss: 0.7019  obj_loss: 0.1634  noobj_loss: 0.0835  bbox_loss: 0.0393  cls_loss: 0.3004  \n",
      "<<<iteration:[400/878] - total_loss: 0.7756  obj_loss: 0.1775  noobj_loss: 0.0720  bbox_loss: 0.0476  cls_loss: 0.3242  \n",
      "<<<iteration:[420/878] - total_loss: 0.6662  obj_loss: 0.1698  noobj_loss: 0.0802  bbox_loss: 0.0350  cls_loss: 0.2814  \n",
      "<<<iteration:[440/878] - total_loss: 0.7223  obj_loss: 0.1893  noobj_loss: 0.0779  bbox_loss: 0.0449  cls_loss: 0.2695  \n",
      "<<<iteration:[460/878] - total_loss: 0.7310  obj_loss: 0.2033  noobj_loss: 0.0732  bbox_loss: 0.0472  cls_loss: 0.2552  \n",
      "<<<iteration:[480/878] - total_loss: 0.7316  obj_loss: 0.2171  noobj_loss: 0.0897  bbox_loss: 0.0444  cls_loss: 0.2476  \n",
      "<<<iteration:[500/878] - total_loss: 0.7312  obj_loss: 0.2015  noobj_loss: 0.0750  bbox_loss: 0.0492  cls_loss: 0.2462  \n",
      "<<<iteration:[520/878] - total_loss: 0.6835  obj_loss: 0.2036  noobj_loss: 0.0732  bbox_loss: 0.0390  cls_loss: 0.2481  \n",
      "<<<iteration:[540/878] - total_loss: 0.7244  obj_loss: 0.1793  noobj_loss: 0.0831  bbox_loss: 0.0537  cls_loss: 0.2349  \n",
      "<<<iteration:[560/878] - total_loss: 0.7102  obj_loss: 0.1921  noobj_loss: 0.0725  bbox_loss: 0.0381  cls_loss: 0.2914  \n",
      "<<<iteration:[580/878] - total_loss: 0.8841  obj_loss: 0.2317  noobj_loss: 0.0896  bbox_loss: 0.0490  cls_loss: 0.3627  \n",
      "<<<iteration:[600/878] - total_loss: 0.8012  obj_loss: 0.1856  noobj_loss: 0.0855  bbox_loss: 0.0451  cls_loss: 0.3476  \n",
      "<<<iteration:[620/878] - total_loss: 0.7066  obj_loss: 0.2044  noobj_loss: 0.0865  bbox_loss: 0.0419  cls_loss: 0.2494  \n",
      "<<<iteration:[640/878] - total_loss: 0.6961  obj_loss: 0.1683  noobj_loss: 0.0693  bbox_loss: 0.0349  cls_loss: 0.3187  \n",
      "<<<iteration:[660/878] - total_loss: 0.7159  obj_loss: 0.1958  noobj_loss: 0.0768  bbox_loss: 0.0403  cls_loss: 0.2802  \n",
      "<<<iteration:[680/878] - total_loss: 0.6902  obj_loss: 0.2093  noobj_loss: 0.0777  bbox_loss: 0.0355  cls_loss: 0.2647  \n",
      "<<<iteration:[700/878] - total_loss: 0.8226  obj_loss: 0.2317  noobj_loss: 0.0933  bbox_loss: 0.0433  cls_loss: 0.3279  \n",
      "<<<iteration:[720/878] - total_loss: 0.6758  obj_loss: 0.1850  noobj_loss: 0.0828  bbox_loss: 0.0353  cls_loss: 0.2731  \n",
      "<<<iteration:[740/878] - total_loss: 0.7900  obj_loss: 0.2442  noobj_loss: 0.0819  bbox_loss: 0.0416  cls_loss: 0.2969  \n",
      "<<<iteration:[760/878] - total_loss: 0.6668  obj_loss: 0.1980  noobj_loss: 0.0842  bbox_loss: 0.0439  cls_loss: 0.2071  \n",
      "<<<iteration:[780/878] - total_loss: 0.7608  obj_loss: 0.2212  noobj_loss: 0.0995  bbox_loss: 0.0459  cls_loss: 0.2605  \n",
      "<<<iteration:[800/878] - total_loss: 0.7442  obj_loss: 0.2004  noobj_loss: 0.0769  bbox_loss: 0.0437  cls_loss: 0.2867  \n",
      "<<<iteration:[820/878] - total_loss: 0.6499  obj_loss: 0.1983  noobj_loss: 0.0829  bbox_loss: 0.0348  cls_loss: 0.2362  \n",
      "<<<iteration:[840/878] - total_loss: 0.6578  obj_loss: 0.2126  noobj_loss: 0.0923  bbox_loss: 0.0404  cls_loss: 0.1972  \n",
      "<<<iteration:[860/878] - total_loss: 0.6771  obj_loss: 0.2011  noobj_loss: 0.0838  bbox_loss: 0.0378  cls_loss: 0.2449  \n",
      "\n",
      "epoch:59/100 - Train Loss: 0.7220, Val Loss: 1.1299\n",
      "\n",
      "<<<iteration:[20/878] - total_loss: 0.7365  obj_loss: 0.1914  noobj_loss: 0.0949  bbox_loss: 0.0402  cls_loss: 0.2965  \n",
      "<<<iteration:[40/878] - total_loss: 0.8839  obj_loss: 0.1902  noobj_loss: 0.0729  bbox_loss: 0.0734  cls_loss: 0.2902  \n",
      "<<<iteration:[60/878] - total_loss: 0.7157  obj_loss: 0.1864  noobj_loss: 0.0720  bbox_loss: 0.0479  cls_loss: 0.2538  \n",
      "<<<iteration:[80/878] - total_loss: 0.8831  obj_loss: 0.1506  noobj_loss: 0.0808  bbox_loss: 0.0753  cls_loss: 0.3157  \n",
      "<<<iteration:[100/878] - total_loss: 0.6769  obj_loss: 0.2220  noobj_loss: 0.0872  bbox_loss: 0.0365  cls_loss: 0.2286  \n",
      "<<<iteration:[120/878] - total_loss: 0.7051  obj_loss: 0.1943  noobj_loss: 0.0812  bbox_loss: 0.0331  cls_loss: 0.3049  \n",
      "<<<iteration:[140/878] - total_loss: 0.6599  obj_loss: 0.1976  noobj_loss: 0.0774  bbox_loss: 0.0418  cls_loss: 0.2148  \n",
      "<<<iteration:[160/878] - total_loss: 0.6494  obj_loss: 0.2175  noobj_loss: 0.0964  bbox_loss: 0.0389  cls_loss: 0.1893  \n",
      "<<<iteration:[180/878] - total_loss: 0.6557  obj_loss: 0.1997  noobj_loss: 0.0772  bbox_loss: 0.0365  cls_loss: 0.2350  \n",
      "<<<iteration:[200/878] - total_loss: 0.7075  obj_loss: 0.2601  noobj_loss: 0.0906  bbox_loss: 0.0348  cls_loss: 0.2279  \n",
      "<<<iteration:[220/878] - total_loss: 0.6744  obj_loss: 0.2368  noobj_loss: 0.0930  bbox_loss: 0.0342  cls_loss: 0.2204  \n",
      "<<<iteration:[240/878] - total_loss: 0.7498  obj_loss: 0.2272  noobj_loss: 0.0933  bbox_loss: 0.0319  cls_loss: 0.3166  \n",
      "<<<iteration:[260/878] - total_loss: 0.7466  obj_loss: 0.2047  noobj_loss: 0.0960  bbox_loss: 0.0441  cls_loss: 0.2732  \n",
      "<<<iteration:[280/878] - total_loss: 0.6836  obj_loss: 0.2022  noobj_loss: 0.0839  bbox_loss: 0.0422  cls_loss: 0.2283  \n",
      "<<<iteration:[300/878] - total_loss: 0.7090  obj_loss: 0.2210  noobj_loss: 0.0982  bbox_loss: 0.0393  cls_loss: 0.2424  \n",
      "<<<iteration:[320/878] - total_loss: 0.6322  obj_loss: 0.1839  noobj_loss: 0.0833  bbox_loss: 0.0327  cls_loss: 0.2431  \n",
      "<<<iteration:[340/878] - total_loss: 0.6754  obj_loss: 0.2091  noobj_loss: 0.0793  bbox_loss: 0.0361  cls_loss: 0.2462  \n",
      "<<<iteration:[360/878] - total_loss: 0.7441  obj_loss: 0.1747  noobj_loss: 0.0916  bbox_loss: 0.0464  cls_loss: 0.2914  \n",
      "<<<iteration:[380/878] - total_loss: 0.7102  obj_loss: 0.2171  noobj_loss: 0.0759  bbox_loss: 0.0375  cls_loss: 0.2677  \n",
      "<<<iteration:[400/878] - total_loss: 0.7001  obj_loss: 0.2073  noobj_loss: 0.0863  bbox_loss: 0.0408  cls_loss: 0.2459  \n",
      "<<<iteration:[420/878] - total_loss: 0.6948  obj_loss: 0.2092  noobj_loss: 0.0997  bbox_loss: 0.0348  cls_loss: 0.2619  \n",
      "<<<iteration:[440/878] - total_loss: 0.8293  obj_loss: 0.1704  noobj_loss: 0.0940  bbox_loss: 0.0463  cls_loss: 0.3801  \n",
      "<<<iteration:[460/878] - total_loss: 0.5501  obj_loss: 0.1636  noobj_loss: 0.0721  bbox_loss: 0.0310  cls_loss: 0.1957  \n",
      "<<<iteration:[480/878] - total_loss: 0.6517  obj_loss: 0.2028  noobj_loss: 0.0743  bbox_loss: 0.0356  cls_loss: 0.2338  \n",
      "<<<iteration:[500/878] - total_loss: 0.7284  obj_loss: 0.1960  noobj_loss: 0.0910  bbox_loss: 0.0337  cls_loss: 0.3181  \n",
      "<<<iteration:[520/878] - total_loss: 0.7624  obj_loss: 0.2028  noobj_loss: 0.0822  bbox_loss: 0.0423  cls_loss: 0.3069  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<<<iteration:[540/878] - total_loss: 0.6361  obj_loss: 0.1731  noobj_loss: 0.0736  bbox_loss: 0.0381  cls_loss: 0.2358  \n",
      "<<<iteration:[560/878] - total_loss: 0.6276  obj_loss: 0.1998  noobj_loss: 0.0796  bbox_loss: 0.0326  cls_loss: 0.2252  \n",
      "<<<iteration:[580/878] - total_loss: 0.7719  obj_loss: 0.2131  noobj_loss: 0.0816  bbox_loss: 0.0373  cls_loss: 0.3313  \n",
      "<<<iteration:[600/878] - total_loss: 0.7528  obj_loss: 0.1937  noobj_loss: 0.0758  bbox_loss: 0.0283  cls_loss: 0.3798  \n",
      "<<<iteration:[620/878] - total_loss: 0.6546  obj_loss: 0.1792  noobj_loss: 0.0781  bbox_loss: 0.0328  cls_loss: 0.2724  \n",
      "<<<iteration:[640/878] - total_loss: 0.6932  obj_loss: 0.1917  noobj_loss: 0.0836  bbox_loss: 0.0434  cls_loss: 0.2426  \n",
      "<<<iteration:[660/878] - total_loss: 0.7461  obj_loss: 0.2496  noobj_loss: 0.0762  bbox_loss: 0.0394  cls_loss: 0.2613  \n",
      "<<<iteration:[680/878] - total_loss: 0.6944  obj_loss: 0.1803  noobj_loss: 0.0837  bbox_loss: 0.0406  cls_loss: 0.2693  \n",
      "<<<iteration:[700/878] - total_loss: 0.6862  obj_loss: 0.1899  noobj_loss: 0.0787  bbox_loss: 0.0341  cls_loss: 0.2867  \n",
      "<<<iteration:[720/878] - total_loss: 0.5646  obj_loss: 0.1779  noobj_loss: 0.0849  bbox_loss: 0.0366  cls_loss: 0.1615  \n",
      "<<<iteration:[740/878] - total_loss: 0.6793  obj_loss: 0.1719  noobj_loss: 0.0791  bbox_loss: 0.0401  cls_loss: 0.2671  \n",
      "<<<iteration:[760/878] - total_loss: 0.7711  obj_loss: 0.2282  noobj_loss: 0.0891  bbox_loss: 0.0450  cls_loss: 0.2732  \n",
      "<<<iteration:[780/878] - total_loss: 0.7816  obj_loss: 0.2150  noobj_loss: 0.0769  bbox_loss: 0.0402  cls_loss: 0.3272  \n",
      "<<<iteration:[800/878] - total_loss: 0.8437  obj_loss: 0.2191  noobj_loss: 0.0889  bbox_loss: 0.0520  cls_loss: 0.3202  \n",
      "<<<iteration:[820/878] - total_loss: 0.7210  obj_loss: 0.1996  noobj_loss: 0.0808  bbox_loss: 0.0472  cls_loss: 0.2453  \n",
      "<<<iteration:[840/878] - total_loss: 0.6711  obj_loss: 0.2093  noobj_loss: 0.0770  bbox_loss: 0.0368  cls_loss: 0.2394  \n",
      "<<<iteration:[860/878] - total_loss: 0.7399  obj_loss: 0.1968  noobj_loss: 0.0886  bbox_loss: 0.0401  cls_loss: 0.2985  \n",
      "\n",
      "epoch:60/100 - Train Loss: 0.7095, Val Loss: 1.1501\n",
      "\n",
      "<<<iteration:[20/878] - total_loss: 0.6579  obj_loss: 0.1880  noobj_loss: 0.0934  bbox_loss: 0.0381  cls_loss: 0.2328  \n",
      "<<<iteration:[40/878] - total_loss: 0.6284  obj_loss: 0.2022  noobj_loss: 0.0831  bbox_loss: 0.0390  cls_loss: 0.1899  \n",
      "<<<iteration:[60/878] - total_loss: 0.6444  obj_loss: 0.2112  noobj_loss: 0.0919  bbox_loss: 0.0393  cls_loss: 0.1906  \n",
      "<<<iteration:[80/878] - total_loss: 0.6548  obj_loss: 0.2122  noobj_loss: 0.0883  bbox_loss: 0.0349  cls_loss: 0.2239  \n",
      "<<<iteration:[100/878] - total_loss: 0.5994  obj_loss: 0.2077  noobj_loss: 0.0785  bbox_loss: 0.0337  cls_loss: 0.1839  \n",
      "<<<iteration:[120/878] - total_loss: 0.6166  obj_loss: 0.1626  noobj_loss: 0.0833  bbox_loss: 0.0338  cls_loss: 0.2432  \n",
      "<<<iteration:[140/878] - total_loss: 0.6774  obj_loss: 0.1988  noobj_loss: 0.0765  bbox_loss: 0.0411  cls_loss: 0.2349  \n",
      "<<<iteration:[160/878] - total_loss: 0.6793  obj_loss: 0.2082  noobj_loss: 0.0903  bbox_loss: 0.0362  cls_loss: 0.2450  \n",
      "<<<iteration:[180/878] - total_loss: 0.9145  obj_loss: 0.1705  noobj_loss: 0.0851  bbox_loss: 0.0964  cls_loss: 0.2193  \n",
      "<<<iteration:[200/878] - total_loss: 0.7425  obj_loss: 0.2132  noobj_loss: 0.0807  bbox_loss: 0.0474  cls_loss: 0.2521  \n",
      "<<<iteration:[220/878] - total_loss: 0.6735  obj_loss: 0.2000  noobj_loss: 0.0835  bbox_loss: 0.0414  cls_loss: 0.2249  \n",
      "<<<iteration:[240/878] - total_loss: 0.7905  obj_loss: 0.2109  noobj_loss: 0.0882  bbox_loss: 0.0437  cls_loss: 0.3172  \n",
      "<<<iteration:[260/878] - total_loss: 0.6012  obj_loss: 0.1798  noobj_loss: 0.0828  bbox_loss: 0.0418  cls_loss: 0.1712  \n",
      "<<<iteration:[280/878] - total_loss: 0.8025  obj_loss: 0.2270  noobj_loss: 0.0779  bbox_loss: 0.0530  cls_loss: 0.2718  \n",
      "<<<iteration:[300/878] - total_loss: 0.7940  obj_loss: 0.2182  noobj_loss: 0.0954  bbox_loss: 0.0383  cls_loss: 0.3364  \n",
      "<<<iteration:[320/878] - total_loss: 0.5981  obj_loss: 0.1874  noobj_loss: 0.0783  bbox_loss: 0.0309  cls_loss: 0.2173  \n",
      "<<<iteration:[340/878] - total_loss: 0.6209  obj_loss: 0.1854  noobj_loss: 0.0740  bbox_loss: 0.0422  cls_loss: 0.1874  \n",
      "<<<iteration:[360/878] - total_loss: 0.7740  obj_loss: 0.2071  noobj_loss: 0.0896  bbox_loss: 0.0484  cls_loss: 0.2799  \n",
      "<<<iteration:[380/878] - total_loss: 0.8261  obj_loss: 0.1564  noobj_loss: 0.0837  bbox_loss: 0.0498  cls_loss: 0.3788  \n",
      "<<<iteration:[400/878] - total_loss: 0.7979  obj_loss: 0.1849  noobj_loss: 0.0711  bbox_loss: 0.0362  cls_loss: 0.3964  \n",
      "<<<iteration:[420/878] - total_loss: 0.7086  obj_loss: 0.1968  noobj_loss: 0.0887  bbox_loss: 0.0354  cls_loss: 0.2904  \n",
      "<<<iteration:[440/878] - total_loss: 0.6699  obj_loss: 0.1715  noobj_loss: 0.0739  bbox_loss: 0.0444  cls_loss: 0.2392  \n",
      "<<<iteration:[460/878] - total_loss: 0.7389  obj_loss: 0.2167  noobj_loss: 0.0755  bbox_loss: 0.0340  cls_loss: 0.3144  \n",
      "<<<iteration:[480/878] - total_loss: 0.6131  obj_loss: 0.1686  noobj_loss: 0.0859  bbox_loss: 0.0368  cls_loss: 0.2176  \n",
      "<<<iteration:[500/878] - total_loss: 0.6307  obj_loss: 0.1841  noobj_loss: 0.0741  bbox_loss: 0.0361  cls_loss: 0.2291  \n",
      "<<<iteration:[520/878] - total_loss: 0.8608  obj_loss: 0.2241  noobj_loss: 0.0795  bbox_loss: 0.0419  cls_loss: 0.3876  \n",
      "<<<iteration:[540/878] - total_loss: 0.6528  obj_loss: 0.1979  noobj_loss: 0.0862  bbox_loss: 0.0328  cls_loss: 0.2479  \n",
      "<<<iteration:[560/878] - total_loss: 0.5883  obj_loss: 0.1751  noobj_loss: 0.0721  bbox_loss: 0.0376  cls_loss: 0.1892  \n",
      "<<<iteration:[580/878] - total_loss: 0.7013  obj_loss: 0.2322  noobj_loss: 0.0898  bbox_loss: 0.0373  cls_loss: 0.2375  \n",
      "<<<iteration:[600/878] - total_loss: 0.8444  obj_loss: 0.2206  noobj_loss: 0.0944  bbox_loss: 0.0481  cls_loss: 0.3363  \n",
      "<<<iteration:[620/878] - total_loss: 0.6870  obj_loss: 0.2252  noobj_loss: 0.0919  bbox_loss: 0.0431  cls_loss: 0.2003  \n",
      "<<<iteration:[640/878] - total_loss: 0.7244  obj_loss: 0.2003  noobj_loss: 0.0882  bbox_loss: 0.0442  cls_loss: 0.2593  \n",
      "<<<iteration:[660/878] - total_loss: 0.8597  obj_loss: 0.2230  noobj_loss: 0.0812  bbox_loss: 0.0451  cls_loss: 0.3704  \n",
      "<<<iteration:[680/878] - total_loss: 0.7660  obj_loss: 0.1943  noobj_loss: 0.1053  bbox_loss: 0.0448  cls_loss: 0.2952  \n",
      "<<<iteration:[700/878] - total_loss: 0.6639  obj_loss: 0.1950  noobj_loss: 0.0893  bbox_loss: 0.0385  cls_loss: 0.2319  \n",
      "<<<iteration:[720/878] - total_loss: 0.7986  obj_loss: 0.1876  noobj_loss: 0.0797  bbox_loss: 0.0522  cls_loss: 0.3103  \n",
      "<<<iteration:[740/878] - total_loss: 0.9098  obj_loss: 0.2576  noobj_loss: 0.0964  bbox_loss: 0.0669  cls_loss: 0.2693  \n",
      "<<<iteration:[760/878] - total_loss: 0.7424  obj_loss: 0.1917  noobj_loss: 0.0953  bbox_loss: 0.0348  cls_loss: 0.3291  \n",
      "<<<iteration:[780/878] - total_loss: 0.6449  obj_loss: 0.2310  noobj_loss: 0.0889  bbox_loss: 0.0312  cls_loss: 0.2133  \n",
      "<<<iteration:[800/878] - total_loss: 0.6217  obj_loss: 0.1934  noobj_loss: 0.0855  bbox_loss: 0.0344  cls_loss: 0.2134  \n",
      "<<<iteration:[820/878] - total_loss: 0.7840  obj_loss: 0.1789  noobj_loss: 0.0813  bbox_loss: 0.0552  cls_loss: 0.2886  \n",
      "<<<iteration:[840/878] - total_loss: 0.6177  obj_loss: 0.1996  noobj_loss: 0.0797  bbox_loss: 0.0305  cls_loss: 0.2259  \n",
      "<<<iteration:[860/878] - total_loss: 0.5881  obj_loss: 0.1754  noobj_loss: 0.0754  bbox_loss: 0.0362  cls_loss: 0.1939  \n",
      "\n",
      "epoch:61/100 - Train Loss: 0.7070, Val Loss: 1.1764\n",
      "\n",
      "<<<iteration:[20/878] - total_loss: 0.7618  obj_loss: 0.2520  noobj_loss: 0.0916  bbox_loss: 0.0368  cls_loss: 0.2800  \n",
      "<<<iteration:[40/878] - total_loss: 0.5964  obj_loss: 0.2004  noobj_loss: 0.0911  bbox_loss: 0.0378  cls_loss: 0.1617  \n",
      "<<<iteration:[60/878] - total_loss: 0.9044  obj_loss: 0.1799  noobj_loss: 0.0932  bbox_loss: 0.0813  cls_loss: 0.2712  \n",
      "<<<iteration:[80/878] - total_loss: 0.6998  obj_loss: 0.1931  noobj_loss: 0.0783  bbox_loss: 0.0407  cls_loss: 0.2642  \n",
      "<<<iteration:[100/878] - total_loss: 0.6445  obj_loss: 0.1812  noobj_loss: 0.0821  bbox_loss: 0.0314  cls_loss: 0.2652  \n",
      "<<<iteration:[120/878] - total_loss: 0.6888  obj_loss: 0.1743  noobj_loss: 0.0806  bbox_loss: 0.0353  cls_loss: 0.2974  \n",
      "<<<iteration:[140/878] - total_loss: 0.7298  obj_loss: 0.2154  noobj_loss: 0.0986  bbox_loss: 0.0363  cls_loss: 0.2835  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<<<iteration:[160/878] - total_loss: 0.6270  obj_loss: 0.1929  noobj_loss: 0.0939  bbox_loss: 0.0326  cls_loss: 0.2242  \n",
      "<<<iteration:[180/878] - total_loss: 0.7374  obj_loss: 0.2098  noobj_loss: 0.1127  bbox_loss: 0.0446  cls_loss: 0.2482  \n",
      "<<<iteration:[200/878] - total_loss: 0.7258  obj_loss: 0.2254  noobj_loss: 0.1005  bbox_loss: 0.0474  cls_loss: 0.2130  \n",
      "<<<iteration:[220/878] - total_loss: 0.6416  obj_loss: 0.2289  noobj_loss: 0.0806  bbox_loss: 0.0345  cls_loss: 0.2000  \n",
      "<<<iteration:[240/878] - total_loss: 0.6922  obj_loss: 0.1869  noobj_loss: 0.0817  bbox_loss: 0.0302  cls_loss: 0.3138  \n",
      "<<<iteration:[260/878] - total_loss: 0.6479  obj_loss: 0.1738  noobj_loss: 0.0819  bbox_loss: 0.0459  cls_loss: 0.2034  \n",
      "<<<iteration:[280/878] - total_loss: 0.6413  obj_loss: 0.1815  noobj_loss: 0.0771  bbox_loss: 0.0353  cls_loss: 0.2447  \n",
      "<<<iteration:[300/878] - total_loss: 0.6132  obj_loss: 0.1964  noobj_loss: 0.0792  bbox_loss: 0.0337  cls_loss: 0.2089  \n",
      "<<<iteration:[320/878] - total_loss: 0.7372  obj_loss: 0.2260  noobj_loss: 0.0661  bbox_loss: 0.0354  cls_loss: 0.3012  \n",
      "<<<iteration:[340/878] - total_loss: 0.5661  obj_loss: 0.1680  noobj_loss: 0.0748  bbox_loss: 0.0359  cls_loss: 0.1814  \n",
      "<<<iteration:[360/878] - total_loss: 0.7142  obj_loss: 0.2026  noobj_loss: 0.0792  bbox_loss: 0.0461  cls_loss: 0.2414  \n",
      "<<<iteration:[380/878] - total_loss: 0.7459  obj_loss: 0.2245  noobj_loss: 0.0849  bbox_loss: 0.0457  cls_loss: 0.2504  \n",
      "<<<iteration:[400/878] - total_loss: 0.6048  obj_loss: 0.2245  noobj_loss: 0.0947  bbox_loss: 0.0308  cls_loss: 0.1792  \n",
      "<<<iteration:[420/878] - total_loss: 0.5584  obj_loss: 0.2022  noobj_loss: 0.0907  bbox_loss: 0.0285  cls_loss: 0.1680  \n",
      "<<<iteration:[440/878] - total_loss: 0.6212  obj_loss: 0.1507  noobj_loss: 0.0824  bbox_loss: 0.0342  cls_loss: 0.2584  \n",
      "<<<iteration:[460/878] - total_loss: 0.6626  obj_loss: 0.1957  noobj_loss: 0.0861  bbox_loss: 0.0333  cls_loss: 0.2575  \n",
      "<<<iteration:[480/878] - total_loss: 0.6310  obj_loss: 0.1985  noobj_loss: 0.0769  bbox_loss: 0.0328  cls_loss: 0.2302  \n",
      "<<<iteration:[500/878] - total_loss: 0.6927  obj_loss: 0.1909  noobj_loss: 0.0908  bbox_loss: 0.0573  cls_loss: 0.1698  \n",
      "<<<iteration:[520/878] - total_loss: 0.8109  obj_loss: 0.2169  noobj_loss: 0.0935  bbox_loss: 0.0661  cls_loss: 0.2166  \n",
      "<<<iteration:[540/878] - total_loss: 0.5664  obj_loss: 0.1862  noobj_loss: 0.0959  bbox_loss: 0.0376  cls_loss: 0.1441  \n",
      "<<<iteration:[560/878] - total_loss: 0.7167  obj_loss: 0.2018  noobj_loss: 0.0895  bbox_loss: 0.0473  cls_loss: 0.2335  \n",
      "<<<iteration:[580/878] - total_loss: 0.7705  obj_loss: 0.2123  noobj_loss: 0.0974  bbox_loss: 0.0469  cls_loss: 0.2750  \n",
      "<<<iteration:[600/878] - total_loss: 0.5429  obj_loss: 0.2010  noobj_loss: 0.0832  bbox_loss: 0.0297  cls_loss: 0.1519  \n",
      "<<<iteration:[620/878] - total_loss: 0.7078  obj_loss: 0.1999  noobj_loss: 0.0906  bbox_loss: 0.0412  cls_loss: 0.2568  \n",
      "<<<iteration:[640/878] - total_loss: 0.7373  obj_loss: 0.2078  noobj_loss: 0.0802  bbox_loss: 0.0370  cls_loss: 0.3042  \n",
      "<<<iteration:[660/878] - total_loss: 0.5837  obj_loss: 0.2024  noobj_loss: 0.0812  bbox_loss: 0.0350  cls_loss: 0.1656  \n",
      "<<<iteration:[680/878] - total_loss: 0.8278  obj_loss: 0.2185  noobj_loss: 0.0856  bbox_loss: 0.0430  cls_loss: 0.3515  \n",
      "<<<iteration:[700/878] - total_loss: 0.6048  obj_loss: 0.2074  noobj_loss: 0.0922  bbox_loss: 0.0355  cls_loss: 0.1740  \n",
      "<<<iteration:[720/878] - total_loss: 0.7262  obj_loss: 0.1946  noobj_loss: 0.1089  bbox_loss: 0.0402  cls_loss: 0.2761  \n",
      "<<<iteration:[740/878] - total_loss: 0.6670  obj_loss: 0.2272  noobj_loss: 0.0902  bbox_loss: 0.0414  cls_loss: 0.1879  \n",
      "<<<iteration:[760/878] - total_loss: 0.7818  obj_loss: 0.1816  noobj_loss: 0.0855  bbox_loss: 0.0543  cls_loss: 0.2860  \n",
      "<<<iteration:[780/878] - total_loss: 0.7645  obj_loss: 0.2263  noobj_loss: 0.0813  bbox_loss: 0.0400  cls_loss: 0.2973  \n",
      "<<<iteration:[800/878] - total_loss: 0.8360  obj_loss: 0.2290  noobj_loss: 0.0964  bbox_loss: 0.0419  cls_loss: 0.3492  \n",
      "<<<iteration:[820/878] - total_loss: 0.7145  obj_loss: 0.2275  noobj_loss: 0.0866  bbox_loss: 0.0383  cls_loss: 0.2524  \n",
      "<<<iteration:[840/878] - total_loss: 0.6454  obj_loss: 0.1961  noobj_loss: 0.0968  bbox_loss: 0.0351  cls_loss: 0.2255  \n",
      "<<<iteration:[860/878] - total_loss: 0.6302  obj_loss: 0.1704  noobj_loss: 0.0823  bbox_loss: 0.0340  cls_loss: 0.2485  \n",
      "\n",
      "epoch:62/100 - Train Loss: 0.6853, Val Loss: 1.1334\n",
      "\n",
      "<<<iteration:[20/878] - total_loss: 0.7010  obj_loss: 0.1714  noobj_loss: 0.0776  bbox_loss: 0.0410  cls_loss: 0.2861  \n",
      "<<<iteration:[40/878] - total_loss: 0.6344  obj_loss: 0.1970  noobj_loss: 0.0892  bbox_loss: 0.0405  cls_loss: 0.1900  \n",
      "<<<iteration:[60/878] - total_loss: 0.8344  obj_loss: 0.2299  noobj_loss: 0.0983  bbox_loss: 0.0636  cls_loss: 0.2373  \n",
      "<<<iteration:[80/878] - total_loss: 0.6686  obj_loss: 0.2201  noobj_loss: 0.0900  bbox_loss: 0.0386  cls_loss: 0.2104  \n",
      "<<<iteration:[100/878] - total_loss: 0.7451  obj_loss: 0.2051  noobj_loss: 0.0945  bbox_loss: 0.0480  cls_loss: 0.2525  \n",
      "<<<iteration:[120/878] - total_loss: 0.5901  obj_loss: 0.1911  noobj_loss: 0.0860  bbox_loss: 0.0294  cls_loss: 0.2091  \n",
      "<<<iteration:[140/878] - total_loss: 0.6549  obj_loss: 0.1753  noobj_loss: 0.0832  bbox_loss: 0.0363  cls_loss: 0.2566  \n",
      "<<<iteration:[160/878] - total_loss: 0.7315  obj_loss: 0.2028  noobj_loss: 0.0886  bbox_loss: 0.0470  cls_loss: 0.2493  \n",
      "<<<iteration:[180/878] - total_loss: 0.6706  obj_loss: 0.2539  noobj_loss: 0.0983  bbox_loss: 0.0314  cls_loss: 0.2106  \n",
      "<<<iteration:[200/878] - total_loss: 0.6277  obj_loss: 0.2282  noobj_loss: 0.0920  bbox_loss: 0.0370  cls_loss: 0.1682  \n",
      "<<<iteration:[220/878] - total_loss: 0.7018  obj_loss: 0.1983  noobj_loss: 0.0973  bbox_loss: 0.0507  cls_loss: 0.2015  \n",
      "<<<iteration:[240/878] - total_loss: 0.7800  obj_loss: 0.2208  noobj_loss: 0.0932  bbox_loss: 0.0435  cls_loss: 0.2950  \n",
      "<<<iteration:[260/878] - total_loss: 0.7091  obj_loss: 0.1812  noobj_loss: 0.0715  bbox_loss: 0.0336  cls_loss: 0.3242  \n",
      "<<<iteration:[280/878] - total_loss: 0.6659  obj_loss: 0.1914  noobj_loss: 0.0856  bbox_loss: 0.0387  cls_loss: 0.2381  \n",
      "<<<iteration:[300/878] - total_loss: 0.5921  obj_loss: 0.1952  noobj_loss: 0.0931  bbox_loss: 0.0378  cls_loss: 0.1612  \n",
      "<<<iteration:[320/878] - total_loss: 0.5912  obj_loss: 0.2075  noobj_loss: 0.0801  bbox_loss: 0.0296  cls_loss: 0.1954  \n",
      "<<<iteration:[340/878] - total_loss: 0.6758  obj_loss: 0.2070  noobj_loss: 0.0891  bbox_loss: 0.0302  cls_loss: 0.2733  \n",
      "<<<iteration:[360/878] - total_loss: 0.6531  obj_loss: 0.1952  noobj_loss: 0.0962  bbox_loss: 0.0351  cls_loss: 0.2341  \n",
      "<<<iteration:[380/878] - total_loss: 0.5856  obj_loss: 0.1873  noobj_loss: 0.0953  bbox_loss: 0.0330  cls_loss: 0.1854  \n",
      "<<<iteration:[400/878] - total_loss: 0.7787  obj_loss: 0.2228  noobj_loss: 0.0876  bbox_loss: 0.0614  cls_loss: 0.2050  \n",
      "<<<iteration:[420/878] - total_loss: 0.6017  obj_loss: 0.2036  noobj_loss: 0.0845  bbox_loss: 0.0354  cls_loss: 0.1790  \n",
      "<<<iteration:[440/878] - total_loss: 0.7373  obj_loss: 0.2219  noobj_loss: 0.0969  bbox_loss: 0.0484  cls_loss: 0.2249  \n",
      "<<<iteration:[460/878] - total_loss: 0.7852  obj_loss: 0.2266  noobj_loss: 0.0837  bbox_loss: 0.0480  cls_loss: 0.2769  \n",
      "<<<iteration:[480/878] - total_loss: 0.6715  obj_loss: 0.2430  noobj_loss: 0.0973  bbox_loss: 0.0363  cls_loss: 0.1986  \n",
      "<<<iteration:[500/878] - total_loss: 0.6518  obj_loss: 0.2026  noobj_loss: 0.0794  bbox_loss: 0.0375  cls_loss: 0.2218  \n",
      "<<<iteration:[520/878] - total_loss: 0.6970  obj_loss: 0.1934  noobj_loss: 0.0813  bbox_loss: 0.0363  cls_loss: 0.2816  \n",
      "<<<iteration:[540/878] - total_loss: 0.6953  obj_loss: 0.1904  noobj_loss: 0.0800  bbox_loss: 0.0472  cls_loss: 0.2290  \n",
      "<<<iteration:[560/878] - total_loss: 0.7471  obj_loss: 0.2110  noobj_loss: 0.1009  bbox_loss: 0.0405  cls_loss: 0.2834  \n",
      "<<<iteration:[580/878] - total_loss: 0.6473  obj_loss: 0.1714  noobj_loss: 0.0843  bbox_loss: 0.0346  cls_loss: 0.2606  \n",
      "<<<iteration:[600/878] - total_loss: 0.6851  obj_loss: 0.2323  noobj_loss: 0.0862  bbox_loss: 0.0352  cls_loss: 0.2336  \n",
      "<<<iteration:[620/878] - total_loss: 0.6219  obj_loss: 0.2268  noobj_loss: 0.0904  bbox_loss: 0.0329  cls_loss: 0.1857  \n",
      "<<<iteration:[640/878] - total_loss: 0.6648  obj_loss: 0.2185  noobj_loss: 0.0914  bbox_loss: 0.0336  cls_loss: 0.2325  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<<<iteration:[660/878] - total_loss: 0.6898  obj_loss: 0.2215  noobj_loss: 0.0994  bbox_loss: 0.0344  cls_loss: 0.2467  \n",
      "<<<iteration:[680/878] - total_loss: 0.6284  obj_loss: 0.2011  noobj_loss: 0.0847  bbox_loss: 0.0325  cls_loss: 0.2225  \n",
      "<<<iteration:[700/878] - total_loss: 0.6427  obj_loss: 0.1856  noobj_loss: 0.0784  bbox_loss: 0.0407  cls_loss: 0.2144  \n",
      "<<<iteration:[720/878] - total_loss: 0.7632  obj_loss: 0.2293  noobj_loss: 0.0937  bbox_loss: 0.0473  cls_loss: 0.2504  \n",
      "<<<iteration:[740/878] - total_loss: 0.6870  obj_loss: 0.2326  noobj_loss: 0.0950  bbox_loss: 0.0352  cls_loss: 0.2308  \n",
      "<<<iteration:[760/878] - total_loss: 0.7196  obj_loss: 0.1865  noobj_loss: 0.0889  bbox_loss: 0.0419  cls_loss: 0.2792  \n",
      "<<<iteration:[780/878] - total_loss: 0.6761  obj_loss: 0.2165  noobj_loss: 0.0892  bbox_loss: 0.0342  cls_loss: 0.2439  \n",
      "<<<iteration:[800/878] - total_loss: 0.6414  obj_loss: 0.1747  noobj_loss: 0.0853  bbox_loss: 0.0417  cls_loss: 0.2155  \n",
      "<<<iteration:[820/878] - total_loss: 0.6462  obj_loss: 0.2040  noobj_loss: 0.0902  bbox_loss: 0.0315  cls_loss: 0.2395  \n",
      "<<<iteration:[840/878] - total_loss: 0.6459  obj_loss: 0.2188  noobj_loss: 0.0873  bbox_loss: 0.0355  cls_loss: 0.2058  \n",
      "<<<iteration:[860/878] - total_loss: 0.6908  obj_loss: 0.2229  noobj_loss: 0.0931  bbox_loss: 0.0338  cls_loss: 0.2525  \n",
      "\n",
      "epoch:63/100 - Train Loss: 0.6760, Val Loss: 1.1291\n",
      "\n",
      "<<<iteration:[20/878] - total_loss: 0.7046  obj_loss: 0.2101  noobj_loss: 0.0986  bbox_loss: 0.0428  cls_loss: 0.2314  \n",
      "<<<iteration:[40/878] - total_loss: 0.7629  obj_loss: 0.2167  noobj_loss: 0.0830  bbox_loss: 0.0465  cls_loss: 0.2722  \n",
      "<<<iteration:[60/878] - total_loss: 0.7188  obj_loss: 0.1950  noobj_loss: 0.0862  bbox_loss: 0.0430  cls_loss: 0.2656  \n",
      "<<<iteration:[80/878] - total_loss: 0.6538  obj_loss: 0.2199  noobj_loss: 0.0899  bbox_loss: 0.0345  cls_loss: 0.2165  \n",
      "<<<iteration:[100/878] - total_loss: 0.6369  obj_loss: 0.1793  noobj_loss: 0.0845  bbox_loss: 0.0330  cls_loss: 0.2505  \n",
      "<<<iteration:[120/878] - total_loss: 0.6739  obj_loss: 0.1878  noobj_loss: 0.0847  bbox_loss: 0.0400  cls_loss: 0.2436  \n",
      "<<<iteration:[140/878] - total_loss: 0.5825  obj_loss: 0.2000  noobj_loss: 0.0923  bbox_loss: 0.0316  cls_loss: 0.1785  \n",
      "<<<iteration:[160/878] - total_loss: 0.7156  obj_loss: 0.2285  noobj_loss: 0.0882  bbox_loss: 0.0300  cls_loss: 0.2930  \n",
      "<<<iteration:[180/878] - total_loss: 0.5555  obj_loss: 0.1987  noobj_loss: 0.0911  bbox_loss: 0.0389  cls_loss: 0.1168  \n",
      "<<<iteration:[200/878] - total_loss: 0.6986  obj_loss: 0.1896  noobj_loss: 0.0917  bbox_loss: 0.0469  cls_loss: 0.2286  \n",
      "<<<iteration:[220/878] - total_loss: 0.6660  obj_loss: 0.2215  noobj_loss: 0.0895  bbox_loss: 0.0384  cls_loss: 0.2079  \n",
      "<<<iteration:[240/878] - total_loss: 0.6334  obj_loss: 0.1776  noobj_loss: 0.0997  bbox_loss: 0.0385  cls_loss: 0.2137  \n",
      "<<<iteration:[260/878] - total_loss: 0.6492  obj_loss: 0.2154  noobj_loss: 0.0939  bbox_loss: 0.0301  cls_loss: 0.2363  \n",
      "<<<iteration:[280/878] - total_loss: 0.7266  obj_loss: 0.1981  noobj_loss: 0.0968  bbox_loss: 0.0392  cls_loss: 0.2841  \n",
      "<<<iteration:[300/878] - total_loss: 0.6839  obj_loss: 0.2096  noobj_loss: 0.0951  bbox_loss: 0.0398  cls_loss: 0.2276  \n",
      "<<<iteration:[320/878] - total_loss: 0.6614  obj_loss: 0.1965  noobj_loss: 0.0973  bbox_loss: 0.0486  cls_loss: 0.1731  \n",
      "<<<iteration:[340/878] - total_loss: 0.7223  obj_loss: 0.1996  noobj_loss: 0.0917  bbox_loss: 0.0520  cls_loss: 0.2167  \n",
      "<<<iteration:[360/878] - total_loss: 0.7338  obj_loss: 0.2065  noobj_loss: 0.1003  bbox_loss: 0.0416  cls_loss: 0.2690  \n",
      "<<<iteration:[380/878] - total_loss: 0.6412  obj_loss: 0.1879  noobj_loss: 0.0774  bbox_loss: 0.0367  cls_loss: 0.2308  \n",
      "<<<iteration:[400/878] - total_loss: 0.6630  obj_loss: 0.2128  noobj_loss: 0.1007  bbox_loss: 0.0371  cls_loss: 0.2141  \n",
      "<<<iteration:[420/878] - total_loss: 0.6935  obj_loss: 0.1955  noobj_loss: 0.1079  bbox_loss: 0.0485  cls_loss: 0.2017  \n",
      "<<<iteration:[440/878] - total_loss: 0.6209  obj_loss: 0.2137  noobj_loss: 0.0838  bbox_loss: 0.0348  cls_loss: 0.1913  \n",
      "<<<iteration:[460/878] - total_loss: 0.6726  obj_loss: 0.2333  noobj_loss: 0.0953  bbox_loss: 0.0460  cls_loss: 0.1615  \n",
      "<<<iteration:[480/878] - total_loss: 0.7772  obj_loss: 0.2084  noobj_loss: 0.1013  bbox_loss: 0.0574  cls_loss: 0.2312  \n",
      "<<<iteration:[500/878] - total_loss: 0.6681  obj_loss: 0.2143  noobj_loss: 0.0872  bbox_loss: 0.0438  cls_loss: 0.1912  \n",
      "<<<iteration:[520/878] - total_loss: 0.7851  obj_loss: 0.1773  noobj_loss: 0.0983  bbox_loss: 0.0719  cls_loss: 0.1992  \n",
      "<<<iteration:[540/878] - total_loss: 0.5990  obj_loss: 0.2139  noobj_loss: 0.0866  bbox_loss: 0.0290  cls_loss: 0.1969  \n",
      "<<<iteration:[560/878] - total_loss: 0.7794  obj_loss: 0.2216  noobj_loss: 0.0879  bbox_loss: 0.0397  cls_loss: 0.3155  \n",
      "<<<iteration:[580/878] - total_loss: 0.6650  obj_loss: 0.2049  noobj_loss: 0.1003  bbox_loss: 0.0397  cls_loss: 0.2113  \n",
      "<<<iteration:[600/878] - total_loss: 0.6599  obj_loss: 0.2166  noobj_loss: 0.0801  bbox_loss: 0.0382  cls_loss: 0.2123  \n",
      "<<<iteration:[620/878] - total_loss: 0.6962  obj_loss: 0.1941  noobj_loss: 0.0896  bbox_loss: 0.0283  cls_loss: 0.3159  \n",
      "<<<iteration:[640/878] - total_loss: 0.7993  obj_loss: 0.2284  noobj_loss: 0.1057  bbox_loss: 0.0492  cls_loss: 0.2719  \n",
      "<<<iteration:[660/878] - total_loss: 0.5677  obj_loss: 0.1976  noobj_loss: 0.0888  bbox_loss: 0.0286  cls_loss: 0.1825  \n",
      "<<<iteration:[680/878] - total_loss: 0.5932  obj_loss: 0.1992  noobj_loss: 0.0888  bbox_loss: 0.0335  cls_loss: 0.1823  \n",
      "<<<iteration:[700/878] - total_loss: 0.6212  obj_loss: 0.2271  noobj_loss: 0.0923  bbox_loss: 0.0354  cls_loss: 0.1708  \n",
      "<<<iteration:[720/878] - total_loss: 0.6900  obj_loss: 0.2246  noobj_loss: 0.0910  bbox_loss: 0.0302  cls_loss: 0.2687  \n",
      "<<<iteration:[740/878] - total_loss: 0.7108  obj_loss: 0.1664  noobj_loss: 0.0819  bbox_loss: 0.0359  cls_loss: 0.3241  \n",
      "<<<iteration:[760/878] - total_loss: 0.7279  obj_loss: 0.2259  noobj_loss: 0.1073  bbox_loss: 0.0372  cls_loss: 0.2621  \n",
      "<<<iteration:[780/878] - total_loss: 0.6813  obj_loss: 0.1812  noobj_loss: 0.0961  bbox_loss: 0.0357  cls_loss: 0.2738  \n",
      "<<<iteration:[800/878] - total_loss: 0.6464  obj_loss: 0.2127  noobj_loss: 0.1032  bbox_loss: 0.0444  cls_loss: 0.1602  \n",
      "<<<iteration:[820/878] - total_loss: 0.7308  obj_loss: 0.2029  noobj_loss: 0.0808  bbox_loss: 0.0386  cls_loss: 0.2943  \n",
      "<<<iteration:[840/878] - total_loss: 0.7117  obj_loss: 0.1827  noobj_loss: 0.0787  bbox_loss: 0.0326  cls_loss: 0.3267  \n",
      "<<<iteration:[860/878] - total_loss: 0.6486  obj_loss: 0.2267  noobj_loss: 0.0912  bbox_loss: 0.0351  cls_loss: 0.2008  \n",
      "\n",
      "epoch:64/100 - Train Loss: 0.6776, Val Loss: 1.1842\n",
      "\n",
      "<<<iteration:[20/878] - total_loss: 0.7157  obj_loss: 0.2462  noobj_loss: 0.0931  bbox_loss: 0.0338  cls_loss: 0.2540  \n",
      "<<<iteration:[40/878] - total_loss: 0.6369  obj_loss: 0.2053  noobj_loss: 0.0766  bbox_loss: 0.0346  cls_loss: 0.2204  \n",
      "<<<iteration:[60/878] - total_loss: 0.6851  obj_loss: 0.1840  noobj_loss: 0.0912  bbox_loss: 0.0446  cls_loss: 0.2326  \n",
      "<<<iteration:[80/878] - total_loss: 0.7490  obj_loss: 0.2284  noobj_loss: 0.0951  bbox_loss: 0.0363  cls_loss: 0.2917  \n",
      "<<<iteration:[100/878] - total_loss: 0.5569  obj_loss: 0.1625  noobj_loss: 0.0794  bbox_loss: 0.0299  cls_loss: 0.2051  \n",
      "<<<iteration:[120/878] - total_loss: 0.6812  obj_loss: 0.2068  noobj_loss: 0.0951  bbox_loss: 0.0398  cls_loss: 0.2281  \n",
      "<<<iteration:[140/878] - total_loss: 0.8190  obj_loss: 0.1868  noobj_loss: 0.1098  bbox_loss: 0.0776  cls_loss: 0.1892  \n",
      "<<<iteration:[160/878] - total_loss: 0.6712  obj_loss: 0.1933  noobj_loss: 0.0876  bbox_loss: 0.0432  cls_loss: 0.2182  \n",
      "<<<iteration:[180/878] - total_loss: 0.6522  obj_loss: 0.1935  noobj_loss: 0.0870  bbox_loss: 0.0359  cls_loss: 0.2355  \n",
      "<<<iteration:[200/878] - total_loss: 0.7429  obj_loss: 0.1954  noobj_loss: 0.0973  bbox_loss: 0.0429  cls_loss: 0.2844  \n",
      "<<<iteration:[220/878] - total_loss: 0.5754  obj_loss: 0.2013  noobj_loss: 0.0847  bbox_loss: 0.0403  cls_loss: 0.1304  \n",
      "<<<iteration:[240/878] - total_loss: 0.7059  obj_loss: 0.2078  noobj_loss: 0.0859  bbox_loss: 0.0369  cls_loss: 0.2705  \n",
      "<<<iteration:[260/878] - total_loss: 0.6972  obj_loss: 0.2016  noobj_loss: 0.0849  bbox_loss: 0.0340  cls_loss: 0.2830  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<<<iteration:[280/878] - total_loss: 0.6132  obj_loss: 0.2381  noobj_loss: 0.0920  bbox_loss: 0.0332  cls_loss: 0.1633  \n",
      "<<<iteration:[300/878] - total_loss: 0.6974  obj_loss: 0.1820  noobj_loss: 0.0921  bbox_loss: 0.0410  cls_loss: 0.2646  \n",
      "<<<iteration:[320/878] - total_loss: 0.7301  obj_loss: 0.2476  noobj_loss: 0.0876  bbox_loss: 0.0358  cls_loss: 0.2596  \n",
      "<<<iteration:[340/878] - total_loss: 0.6419  obj_loss: 0.2247  noobj_loss: 0.1093  bbox_loss: 0.0317  cls_loss: 0.2039  \n",
      "<<<iteration:[360/878] - total_loss: 0.6941  obj_loss: 0.2073  noobj_loss: 0.0945  bbox_loss: 0.0336  cls_loss: 0.2715  \n",
      "<<<iteration:[380/878] - total_loss: 0.6480  obj_loss: 0.1755  noobj_loss: 0.0906  bbox_loss: 0.0375  cls_loss: 0.2400  \n",
      "<<<iteration:[400/878] - total_loss: 0.6586  obj_loss: 0.2034  noobj_loss: 0.0924  bbox_loss: 0.0314  cls_loss: 0.2521  \n",
      "<<<iteration:[420/878] - total_loss: 0.6325  obj_loss: 0.1644  noobj_loss: 0.0865  bbox_loss: 0.0364  cls_loss: 0.2429  \n",
      "<<<iteration:[440/878] - total_loss: 0.7607  obj_loss: 0.2176  noobj_loss: 0.0965  bbox_loss: 0.0352  cls_loss: 0.3189  \n",
      "<<<iteration:[460/878] - total_loss: 0.6830  obj_loss: 0.2295  noobj_loss: 0.1026  bbox_loss: 0.0323  cls_loss: 0.2406  \n",
      "<<<iteration:[480/878] - total_loss: 0.5715  obj_loss: 0.1571  noobj_loss: 0.0806  bbox_loss: 0.0325  cls_loss: 0.2118  \n",
      "<<<iteration:[500/878] - total_loss: 0.6959  obj_loss: 0.2420  noobj_loss: 0.1024  bbox_loss: 0.0342  cls_loss: 0.2317  \n",
      "<<<iteration:[520/878] - total_loss: 0.6837  obj_loss: 0.2097  noobj_loss: 0.1055  bbox_loss: 0.0385  cls_loss: 0.2290  \n",
      "<<<iteration:[540/878] - total_loss: 0.6011  obj_loss: 0.2231  noobj_loss: 0.0798  bbox_loss: 0.0284  cls_loss: 0.1961  \n",
      "<<<iteration:[560/878] - total_loss: 0.7411  obj_loss: 0.2164  noobj_loss: 0.0935  bbox_loss: 0.0330  cls_loss: 0.3127  \n",
      "<<<iteration:[580/878] - total_loss: 0.7239  obj_loss: 0.1865  noobj_loss: 0.0984  bbox_loss: 0.0388  cls_loss: 0.2940  \n",
      "<<<iteration:[600/878] - total_loss: 0.6892  obj_loss: 0.2302  noobj_loss: 0.1005  bbox_loss: 0.0386  cls_loss: 0.2158  \n",
      "<<<iteration:[620/878] - total_loss: 0.6482  obj_loss: 0.2275  noobj_loss: 0.0925  bbox_loss: 0.0383  cls_loss: 0.1829  \n",
      "<<<iteration:[640/878] - total_loss: 0.6155  obj_loss: 0.1832  noobj_loss: 0.0914  bbox_loss: 0.0375  cls_loss: 0.1989  \n",
      "<<<iteration:[660/878] - total_loss: 0.6626  obj_loss: 0.2135  noobj_loss: 0.0895  bbox_loss: 0.0406  cls_loss: 0.2015  \n",
      "<<<iteration:[680/878] - total_loss: 0.6589  obj_loss: 0.2153  noobj_loss: 0.0974  bbox_loss: 0.0396  cls_loss: 0.1972  \n",
      "<<<iteration:[700/878] - total_loss: 0.6109  obj_loss: 0.1794  noobj_loss: 0.0893  bbox_loss: 0.0327  cls_loss: 0.2233  \n",
      "<<<iteration:[720/878] - total_loss: 0.7289  obj_loss: 0.2282  noobj_loss: 0.0932  bbox_loss: 0.0319  cls_loss: 0.2946  \n",
      "<<<iteration:[740/878] - total_loss: 0.7437  obj_loss: 0.2217  noobj_loss: 0.1162  bbox_loss: 0.0346  cls_loss: 0.2909  \n",
      "<<<iteration:[760/878] - total_loss: 0.6602  obj_loss: 0.2520  noobj_loss: 0.1035  bbox_loss: 0.0369  cls_loss: 0.1717  \n",
      "<<<iteration:[780/878] - total_loss: 0.7127  obj_loss: 0.2524  noobj_loss: 0.1092  bbox_loss: 0.0331  cls_loss: 0.2402  \n",
      "<<<iteration:[800/878] - total_loss: 0.6541  obj_loss: 0.2054  noobj_loss: 0.0972  bbox_loss: 0.0288  cls_loss: 0.2559  \n",
      "<<<iteration:[820/878] - total_loss: 0.5891  obj_loss: 0.1958  noobj_loss: 0.0900  bbox_loss: 0.0300  cls_loss: 0.1982  \n",
      "<<<iteration:[840/878] - total_loss: 0.6383  obj_loss: 0.2164  noobj_loss: 0.0933  bbox_loss: 0.0304  cls_loss: 0.2234  \n",
      "<<<iteration:[860/878] - total_loss: 0.6447  obj_loss: 0.2141  noobj_loss: 0.0894  bbox_loss: 0.0392  cls_loss: 0.1897  \n",
      "\n",
      "epoch:65/100 - Train Loss: 0.6714, Val Loss: 1.6162\n",
      "\n",
      "<<<iteration:[20/878] - total_loss: 0.9944  obj_loss: 0.1973  noobj_loss: 0.0943  bbox_loss: 0.1064  cls_loss: 0.2180  \n",
      "<<<iteration:[40/878] - total_loss: 0.6213  obj_loss: 0.1964  noobj_loss: 0.0912  bbox_loss: 0.0394  cls_loss: 0.1824  \n",
      "<<<iteration:[60/878] - total_loss: 0.6179  obj_loss: 0.2140  noobj_loss: 0.0956  bbox_loss: 0.0374  cls_loss: 0.1693  \n",
      "<<<iteration:[80/878] - total_loss: 0.6453  obj_loss: 0.1855  noobj_loss: 0.0910  bbox_loss: 0.0391  cls_loss: 0.2187  \n",
      "<<<iteration:[100/878] - total_loss: 0.5271  obj_loss: 0.1756  noobj_loss: 0.0948  bbox_loss: 0.0287  cls_loss: 0.1606  \n",
      "<<<iteration:[120/878] - total_loss: 0.6044  obj_loss: 0.2055  noobj_loss: 0.0989  bbox_loss: 0.0309  cls_loss: 0.1949  \n",
      "<<<iteration:[140/878] - total_loss: 0.6352  obj_loss: 0.2196  noobj_loss: 0.0914  bbox_loss: 0.0299  cls_loss: 0.2202  \n",
      "<<<iteration:[160/878] - total_loss: 0.6698  obj_loss: 0.2213  noobj_loss: 0.1012  bbox_loss: 0.0396  cls_loss: 0.2000  \n",
      "<<<iteration:[180/878] - total_loss: 0.5558  obj_loss: 0.1987  noobj_loss: 0.0949  bbox_loss: 0.0312  cls_loss: 0.1536  \n",
      "<<<iteration:[200/878] - total_loss: 0.7166  obj_loss: 0.2497  noobj_loss: 0.0906  bbox_loss: 0.0308  cls_loss: 0.2677  \n",
      "<<<iteration:[220/878] - total_loss: 0.6732  obj_loss: 0.1726  noobj_loss: 0.1042  bbox_loss: 0.0352  cls_loss: 0.2723  \n",
      "<<<iteration:[240/878] - total_loss: 0.6463  obj_loss: 0.2280  noobj_loss: 0.0888  bbox_loss: 0.0291  cls_loss: 0.2285  \n",
      "<<<iteration:[260/878] - total_loss: 0.7218  obj_loss: 0.2219  noobj_loss: 0.0835  bbox_loss: 0.0322  cls_loss: 0.2970  \n",
      "<<<iteration:[280/878] - total_loss: 0.5942  obj_loss: 0.2013  noobj_loss: 0.0906  bbox_loss: 0.0307  cls_loss: 0.1942  \n",
      "<<<iteration:[300/878] - total_loss: 0.6778  obj_loss: 0.2000  noobj_loss: 0.0940  bbox_loss: 0.0368  cls_loss: 0.2467  \n",
      "<<<iteration:[320/878] - total_loss: 0.5251  obj_loss: 0.1766  noobj_loss: 0.0851  bbox_loss: 0.0280  cls_loss: 0.1658  \n",
      "<<<iteration:[340/878] - total_loss: 0.6693  obj_loss: 0.1796  noobj_loss: 0.0847  bbox_loss: 0.0386  cls_loss: 0.2542  \n",
      "<<<iteration:[360/878] - total_loss: 0.5628  obj_loss: 0.2075  noobj_loss: 0.0831  bbox_loss: 0.0327  cls_loss: 0.1504  \n",
      "<<<iteration:[380/878] - total_loss: 0.7294  obj_loss: 0.2331  noobj_loss: 0.0909  bbox_loss: 0.0349  cls_loss: 0.2763  \n",
      "<<<iteration:[400/878] - total_loss: 0.5765  obj_loss: 0.2000  noobj_loss: 0.1064  bbox_loss: 0.0351  cls_loss: 0.1476  \n",
      "<<<iteration:[420/878] - total_loss: 0.6643  obj_loss: 0.2202  noobj_loss: 0.0990  bbox_loss: 0.0337  cls_loss: 0.2262  \n",
      "<<<iteration:[440/878] - total_loss: 0.6700  obj_loss: 0.2280  noobj_loss: 0.1012  bbox_loss: 0.0338  cls_loss: 0.2222  \n",
      "<<<iteration:[460/878] - total_loss: 0.7376  obj_loss: 0.2086  noobj_loss: 0.0971  bbox_loss: 0.0615  cls_loss: 0.1732  \n",
      "<<<iteration:[480/878] - total_loss: 0.6107  obj_loss: 0.1917  noobj_loss: 0.0814  bbox_loss: 0.0363  cls_loss: 0.1965  \n",
      "<<<iteration:[500/878] - total_loss: 0.6148  obj_loss: 0.1994  noobj_loss: 0.0908  bbox_loss: 0.0290  cls_loss: 0.2249  \n",
      "<<<iteration:[520/878] - total_loss: 0.6150  obj_loss: 0.2086  noobj_loss: 0.0955  bbox_loss: 0.0339  cls_loss: 0.1893  \n",
      "<<<iteration:[540/878] - total_loss: 0.7063  obj_loss: 0.2250  noobj_loss: 0.0948  bbox_loss: 0.0434  cls_loss: 0.2167  \n",
      "<<<iteration:[560/878] - total_loss: 0.6729  obj_loss: 0.1778  noobj_loss: 0.0926  bbox_loss: 0.0527  cls_loss: 0.1856  \n",
      "<<<iteration:[580/878] - total_loss: 0.6534  obj_loss: 0.2048  noobj_loss: 0.0969  bbox_loss: 0.0422  cls_loss: 0.1890  \n",
      "<<<iteration:[600/878] - total_loss: 0.6893  obj_loss: 0.2076  noobj_loss: 0.1089  bbox_loss: 0.0397  cls_loss: 0.2286  \n",
      "<<<iteration:[620/878] - total_loss: 0.6895  obj_loss: 0.2021  noobj_loss: 0.0908  bbox_loss: 0.0352  cls_loss: 0.2661  \n",
      "<<<iteration:[640/878] - total_loss: 0.6643  obj_loss: 0.1926  noobj_loss: 0.0834  bbox_loss: 0.0361  cls_loss: 0.2496  \n",
      "<<<iteration:[660/878] - total_loss: 0.6762  obj_loss: 0.2065  noobj_loss: 0.1003  bbox_loss: 0.0340  cls_loss: 0.2497  \n",
      "<<<iteration:[680/878] - total_loss: 0.7498  obj_loss: 0.2330  noobj_loss: 0.1007  bbox_loss: 0.0362  cls_loss: 0.2855  \n",
      "<<<iteration:[700/878] - total_loss: 0.7186  obj_loss: 0.2225  noobj_loss: 0.0979  bbox_loss: 0.0389  cls_loss: 0.2528  \n",
      "<<<iteration:[720/878] - total_loss: 0.6188  obj_loss: 0.2071  noobj_loss: 0.0998  bbox_loss: 0.0293  cls_loss: 0.2154  \n",
      "<<<iteration:[740/878] - total_loss: 0.6816  obj_loss: 0.2151  noobj_loss: 0.0878  bbox_loss: 0.0377  cls_loss: 0.2343  \n",
      "<<<iteration:[760/878] - total_loss: 0.7032  obj_loss: 0.1897  noobj_loss: 0.0854  bbox_loss: 0.0467  cls_loss: 0.2372  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<<<iteration:[780/878] - total_loss: 0.8048  obj_loss: 0.1983  noobj_loss: 0.1115  bbox_loss: 0.0503  cls_loss: 0.2990  \n",
      "<<<iteration:[800/878] - total_loss: 0.7290  obj_loss: 0.2430  noobj_loss: 0.0959  bbox_loss: 0.0497  cls_loss: 0.1894  \n",
      "<<<iteration:[820/878] - total_loss: 0.7318  obj_loss: 0.2322  noobj_loss: 0.0922  bbox_loss: 0.0415  cls_loss: 0.2458  \n",
      "<<<iteration:[840/878] - total_loss: 0.6901  obj_loss: 0.2415  noobj_loss: 0.1000  bbox_loss: 0.0350  cls_loss: 0.2234  \n",
      "<<<iteration:[860/878] - total_loss: 0.6494  obj_loss: 0.2204  noobj_loss: 0.1045  bbox_loss: 0.0400  cls_loss: 0.1769  \n",
      "\n",
      "epoch:66/100 - Train Loss: 0.6688, Val Loss: 1.1832\n",
      "\n",
      "<<<iteration:[20/878] - total_loss: 0.6936  obj_loss: 0.2422  noobj_loss: 0.1075  bbox_loss: 0.0330  cls_loss: 0.2325  \n",
      "<<<iteration:[40/878] - total_loss: 0.7420  obj_loss: 0.2385  noobj_loss: 0.0993  bbox_loss: 0.0342  cls_loss: 0.2827  \n",
      "<<<iteration:[60/878] - total_loss: 0.6888  obj_loss: 0.1906  noobj_loss: 0.1066  bbox_loss: 0.0381  cls_loss: 0.2547  \n",
      "<<<iteration:[80/878] - total_loss: 0.6034  obj_loss: 0.1369  noobj_loss: 0.0943  bbox_loss: 0.0447  cls_loss: 0.1956  \n",
      "<<<iteration:[100/878] - total_loss: 0.6213  obj_loss: 0.2251  noobj_loss: 0.0936  bbox_loss: 0.0334  cls_loss: 0.1822  \n",
      "<<<iteration:[120/878] - total_loss: 0.5821  obj_loss: 0.1882  noobj_loss: 0.1000  bbox_loss: 0.0286  cls_loss: 0.2010  \n",
      "<<<iteration:[140/878] - total_loss: 0.6267  obj_loss: 0.2125  noobj_loss: 0.0981  bbox_loss: 0.0321  cls_loss: 0.2045  \n",
      "<<<iteration:[160/878] - total_loss: 0.6125  obj_loss: 0.2042  noobj_loss: 0.0927  bbox_loss: 0.0364  cls_loss: 0.1798  \n",
      "<<<iteration:[180/878] - total_loss: 0.5706  obj_loss: 0.1720  noobj_loss: 0.0753  bbox_loss: 0.0410  cls_loss: 0.1562  \n",
      "<<<iteration:[200/878] - total_loss: 0.5997  obj_loss: 0.2298  noobj_loss: 0.1074  bbox_loss: 0.0321  cls_loss: 0.1558  \n",
      "<<<iteration:[220/878] - total_loss: 0.7207  obj_loss: 0.2411  noobj_loss: 0.1006  bbox_loss: 0.0315  cls_loss: 0.2717  \n",
      "<<<iteration:[240/878] - total_loss: 0.6728  obj_loss: 0.2284  noobj_loss: 0.1013  bbox_loss: 0.0387  cls_loss: 0.2005  \n",
      "<<<iteration:[260/878] - total_loss: 0.6369  obj_loss: 0.2117  noobj_loss: 0.0932  bbox_loss: 0.0296  cls_loss: 0.2306  \n",
      "<<<iteration:[280/878] - total_loss: 0.6413  obj_loss: 0.2166  noobj_loss: 0.0940  bbox_loss: 0.0322  cls_loss: 0.2166  \n",
      "<<<iteration:[300/878] - total_loss: 0.5908  obj_loss: 0.2018  noobj_loss: 0.0895  bbox_loss: 0.0318  cls_loss: 0.1851  \n",
      "<<<iteration:[320/878] - total_loss: 0.6445  obj_loss: 0.1924  noobj_loss: 0.0897  bbox_loss: 0.0411  cls_loss: 0.2020  \n",
      "<<<iteration:[340/878] - total_loss: 0.6699  obj_loss: 0.2220  noobj_loss: 0.0937  bbox_loss: 0.0323  cls_loss: 0.2395  \n",
      "<<<iteration:[360/878] - total_loss: 0.6734  obj_loss: 0.2025  noobj_loss: 0.1086  bbox_loss: 0.0461  cls_loss: 0.1862  \n",
      "<<<iteration:[380/878] - total_loss: 0.5922  obj_loss: 0.1758  noobj_loss: 0.0890  bbox_loss: 0.0304  cls_loss: 0.2199  \n",
      "<<<iteration:[400/878] - total_loss: 0.5437  obj_loss: 0.2183  noobj_loss: 0.0861  bbox_loss: 0.0266  cls_loss: 0.1496  \n",
      "<<<iteration:[420/878] - total_loss: 0.6118  obj_loss: 0.1925  noobj_loss: 0.0747  bbox_loss: 0.0342  cls_loss: 0.2107  \n",
      "<<<iteration:[440/878] - total_loss: 0.5903  obj_loss: 0.2427  noobj_loss: 0.1022  bbox_loss: 0.0343  cls_loss: 0.1253  \n",
      "<<<iteration:[460/878] - total_loss: 0.5941  obj_loss: 0.2281  noobj_loss: 0.1025  bbox_loss: 0.0311  cls_loss: 0.1594  \n",
      "<<<iteration:[480/878] - total_loss: 0.6452  obj_loss: 0.1919  noobj_loss: 0.1000  bbox_loss: 0.0351  cls_loss: 0.2280  \n",
      "<<<iteration:[500/878] - total_loss: 0.5494  obj_loss: 0.1937  noobj_loss: 0.0987  bbox_loss: 0.0317  cls_loss: 0.1478  \n",
      "<<<iteration:[520/878] - total_loss: 0.7236  obj_loss: 0.2122  noobj_loss: 0.0934  bbox_loss: 0.0353  cls_loss: 0.2883  \n",
      "<<<iteration:[540/878] - total_loss: 0.6674  obj_loss: 0.2581  noobj_loss: 0.0953  bbox_loss: 0.0317  cls_loss: 0.2033  \n",
      "<<<iteration:[560/878] - total_loss: 0.7145  obj_loss: 0.2291  noobj_loss: 0.0975  bbox_loss: 0.0379  cls_loss: 0.2471  \n",
      "<<<iteration:[580/878] - total_loss: 0.8282  obj_loss: 0.2339  noobj_loss: 0.1041  bbox_loss: 0.0444  cls_loss: 0.3204  \n",
      "<<<iteration:[600/878] - total_loss: 0.5706  obj_loss: 0.1893  noobj_loss: 0.0909  bbox_loss: 0.0334  cls_loss: 0.1687  \n",
      "<<<iteration:[620/878] - total_loss: 0.7021  obj_loss: 0.2309  noobj_loss: 0.0863  bbox_loss: 0.0431  cls_loss: 0.2124  \n",
      "<<<iteration:[640/878] - total_loss: 0.6187  obj_loss: 0.2171  noobj_loss: 0.0974  bbox_loss: 0.0374  cls_loss: 0.1661  \n",
      "<<<iteration:[660/878] - total_loss: 0.5633  obj_loss: 0.2104  noobj_loss: 0.0961  bbox_loss: 0.0350  cls_loss: 0.1297  \n",
      "<<<iteration:[680/878] - total_loss: 0.6937  obj_loss: 0.2449  noobj_loss: 0.1034  bbox_loss: 0.0344  cls_loss: 0.2249  \n",
      "<<<iteration:[700/878] - total_loss: 0.6796  obj_loss: 0.2364  noobj_loss: 0.0961  bbox_loss: 0.0320  cls_loss: 0.2349  \n",
      "<<<iteration:[720/878] - total_loss: 0.7064  obj_loss: 0.2306  noobj_loss: 0.0902  bbox_loss: 0.0381  cls_loss: 0.2399  \n",
      "<<<iteration:[740/878] - total_loss: 0.7610  obj_loss: 0.2014  noobj_loss: 0.1030  bbox_loss: 0.0553  cls_loss: 0.2315  \n",
      "<<<iteration:[760/878] - total_loss: 0.6832  obj_loss: 0.2396  noobj_loss: 0.0933  bbox_loss: 0.0363  cls_loss: 0.2154  \n",
      "<<<iteration:[780/878] - total_loss: 0.7999  obj_loss: 0.2126  noobj_loss: 0.1085  bbox_loss: 0.0495  cls_loss: 0.2856  \n",
      "<<<iteration:[800/878] - total_loss: 0.6021  obj_loss: 0.1996  noobj_loss: 0.0929  bbox_loss: 0.0311  cls_loss: 0.2003  \n",
      "<<<iteration:[820/878] - total_loss: 0.6855  obj_loss: 0.1597  noobj_loss: 0.1033  bbox_loss: 0.0534  cls_loss: 0.2068  \n",
      "<<<iteration:[840/878] - total_loss: 1.5953  obj_loss: 0.1947  noobj_loss: 0.0808  bbox_loss: 0.2060  cls_loss: 0.3303  \n",
      "<<<iteration:[860/878] - total_loss: 1.5314  obj_loss: 0.2203  noobj_loss: 0.0985  bbox_loss: 0.2180  cls_loss: 0.1717  \n",
      "\n",
      "epoch:67/100 - Train Loss: 0.7203, Val Loss: 2.1161\n",
      "\n",
      "<<<iteration:[20/878] - total_loss: 1.0452  obj_loss: 0.2454  noobj_loss: 0.0876  bbox_loss: 0.0941  cls_loss: 0.2857  \n",
      "<<<iteration:[40/878] - total_loss: 0.6834  obj_loss: 0.2163  noobj_loss: 0.0963  bbox_loss: 0.0377  cls_loss: 0.2305  \n",
      "<<<iteration:[60/878] - total_loss: 0.5747  obj_loss: 0.1968  noobj_loss: 0.0887  bbox_loss: 0.0389  cls_loss: 0.1388  \n",
      "<<<iteration:[80/878] - total_loss: 0.6867  obj_loss: 0.1977  noobj_loss: 0.0803  bbox_loss: 0.0544  cls_loss: 0.1769  \n",
      "<<<iteration:[100/878] - total_loss: 0.7086  obj_loss: 0.2188  noobj_loss: 0.1015  bbox_loss: 0.0456  cls_loss: 0.2111  \n",
      "<<<iteration:[120/878] - total_loss: 0.9646  obj_loss: 0.1960  noobj_loss: 0.1003  bbox_loss: 0.0927  cls_loss: 0.2551  \n",
      "<<<iteration:[140/878] - total_loss: 0.6466  obj_loss: 0.1888  noobj_loss: 0.0911  bbox_loss: 0.0383  cls_loss: 0.2208  \n",
      "<<<iteration:[160/878] - total_loss: 0.7708  obj_loss: 0.1862  noobj_loss: 0.0909  bbox_loss: 0.0683  cls_loss: 0.1976  \n",
      "<<<iteration:[180/878] - total_loss: 0.8852  obj_loss: 0.2059  noobj_loss: 0.0937  bbox_loss: 0.0741  cls_loss: 0.2618  \n",
      "<<<iteration:[200/878] - total_loss: 0.7810  obj_loss: 0.2003  noobj_loss: 0.0869  bbox_loss: 0.0587  cls_loss: 0.2439  \n",
      "<<<iteration:[220/878] - total_loss: 0.8393  obj_loss: 0.1974  noobj_loss: 0.1126  bbox_loss: 0.0745  cls_loss: 0.2133  \n",
      "<<<iteration:[240/878] - total_loss: 0.6789  obj_loss: 0.2029  noobj_loss: 0.0932  bbox_loss: 0.0436  cls_loss: 0.2115  \n",
      "<<<iteration:[260/878] - total_loss: 0.6526  obj_loss: 0.1970  noobj_loss: 0.1017  bbox_loss: 0.0410  cls_loss: 0.1998  \n",
      "<<<iteration:[280/878] - total_loss: 0.6613  obj_loss: 0.1690  noobj_loss: 0.0885  bbox_loss: 0.0309  cls_loss: 0.2936  \n",
      "<<<iteration:[300/878] - total_loss: 0.6144  obj_loss: 0.2376  noobj_loss: 0.0919  bbox_loss: 0.0328  cls_loss: 0.1671  \n",
      "<<<iteration:[320/878] - total_loss: 0.6833  obj_loss: 0.2132  noobj_loss: 0.1015  bbox_loss: 0.0441  cls_loss: 0.1990  \n",
      "<<<iteration:[340/878] - total_loss: 0.6502  obj_loss: 0.2401  noobj_loss: 0.0821  bbox_loss: 0.0299  cls_loss: 0.2193  \n",
      "<<<iteration:[360/878] - total_loss: 0.6090  obj_loss: 0.1845  noobj_loss: 0.1005  bbox_loss: 0.0336  cls_loss: 0.2061  \n",
      "<<<iteration:[380/878] - total_loss: 0.6153  obj_loss: 0.1739  noobj_loss: 0.0859  bbox_loss: 0.0297  cls_loss: 0.2498  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<<<iteration:[400/878] - total_loss: 0.5688  obj_loss: 0.2185  noobj_loss: 0.0970  bbox_loss: 0.0342  cls_loss: 0.1309  \n",
      "<<<iteration:[420/878] - total_loss: 0.6109  obj_loss: 0.1915  noobj_loss: 0.0955  bbox_loss: 0.0337  cls_loss: 0.2031  \n",
      "<<<iteration:[440/878] - total_loss: 0.6662  obj_loss: 0.1792  noobj_loss: 0.0841  bbox_loss: 0.0314  cls_loss: 0.2879  \n",
      "<<<iteration:[460/878] - total_loss: 0.7165  obj_loss: 0.2349  noobj_loss: 0.1001  bbox_loss: 0.0369  cls_loss: 0.2469  \n",
      "<<<iteration:[480/878] - total_loss: 0.5386  obj_loss: 0.1937  noobj_loss: 0.0876  bbox_loss: 0.0312  cls_loss: 0.1451  \n",
      "<<<iteration:[500/878] - total_loss: 0.4855  obj_loss: 0.1864  noobj_loss: 0.0802  bbox_loss: 0.0272  cls_loss: 0.1229  \n",
      "<<<iteration:[520/878] - total_loss: 0.5241  obj_loss: 0.1847  noobj_loss: 0.0922  bbox_loss: 0.0335  cls_loss: 0.1260  \n",
      "<<<iteration:[540/878] - total_loss: 0.6815  obj_loss: 0.2411  noobj_loss: 0.0900  bbox_loss: 0.0302  cls_loss: 0.2443  \n",
      "<<<iteration:[560/878] - total_loss: 0.6211  obj_loss: 0.2108  noobj_loss: 0.0966  bbox_loss: 0.0313  cls_loss: 0.2054  \n",
      "<<<iteration:[580/878] - total_loss: 0.7223  obj_loss: 0.2463  noobj_loss: 0.1056  bbox_loss: 0.0342  cls_loss: 0.2523  \n",
      "<<<iteration:[600/878] - total_loss: 0.6797  obj_loss: 0.2386  noobj_loss: 0.1012  bbox_loss: 0.0351  cls_loss: 0.2151  \n",
      "<<<iteration:[620/878] - total_loss: 0.6901  obj_loss: 0.2032  noobj_loss: 0.0997  bbox_loss: 0.0374  cls_loss: 0.2500  \n",
      "<<<iteration:[640/878] - total_loss: 0.6966  obj_loss: 0.2416  noobj_loss: 0.1028  bbox_loss: 0.0442  cls_loss: 0.1827  \n",
      "<<<iteration:[660/878] - total_loss: 0.8618  obj_loss: 0.2012  noobj_loss: 0.1059  bbox_loss: 0.0577  cls_loss: 0.3192  \n",
      "<<<iteration:[680/878] - total_loss: 0.5027  obj_loss: 0.1829  noobj_loss: 0.0892  bbox_loss: 0.0286  cls_loss: 0.1320  \n",
      "<<<iteration:[700/878] - total_loss: 0.6234  obj_loss: 0.2398  noobj_loss: 0.0982  bbox_loss: 0.0298  cls_loss: 0.1856  \n",
      "<<<iteration:[720/878] - total_loss: 0.7004  obj_loss: 0.2181  noobj_loss: 0.0923  bbox_loss: 0.0360  cls_loss: 0.2560  \n",
      "<<<iteration:[740/878] - total_loss: 0.6678  obj_loss: 0.2677  noobj_loss: 0.1156  bbox_loss: 0.0336  cls_loss: 0.1742  \n",
      "<<<iteration:[760/878] - total_loss: 0.6503  obj_loss: 0.2124  noobj_loss: 0.0961  bbox_loss: 0.0435  cls_loss: 0.1725  \n",
      "<<<iteration:[780/878] - total_loss: 0.8141  obj_loss: 0.2043  noobj_loss: 0.0934  bbox_loss: 0.0663  cls_loss: 0.2316  \n",
      "<<<iteration:[800/878] - total_loss: 0.7643  obj_loss: 0.1947  noobj_loss: 0.0921  bbox_loss: 0.0444  cls_loss: 0.3018  \n",
      "<<<iteration:[820/878] - total_loss: 0.6683  obj_loss: 0.2380  noobj_loss: 0.0994  bbox_loss: 0.0437  cls_loss: 0.1622  \n",
      "<<<iteration:[840/878] - total_loss: 0.5725  obj_loss: 0.2150  noobj_loss: 0.1001  bbox_loss: 0.0336  cls_loss: 0.1396  \n",
      "<<<iteration:[860/878] - total_loss: 0.7507  obj_loss: 0.2413  noobj_loss: 0.1037  bbox_loss: 0.0398  cls_loss: 0.2586  \n",
      "\n",
      "epoch:68/100 - Train Loss: 0.6841, Val Loss: 1.1412\n",
      "\n",
      "<<<iteration:[20/878] - total_loss: 0.6746  obj_loss: 0.2246  noobj_loss: 0.1001  bbox_loss: 0.0415  cls_loss: 0.1924  \n",
      "<<<iteration:[40/878] - total_loss: 0.5694  obj_loss: 0.1969  noobj_loss: 0.0930  bbox_loss: 0.0306  cls_loss: 0.1730  \n",
      "<<<iteration:[60/878] - total_loss: 0.6399  obj_loss: 0.1901  noobj_loss: 0.0930  bbox_loss: 0.0357  cls_loss: 0.2249  \n",
      "<<<iteration:[80/878] - total_loss: 0.6042  obj_loss: 0.2104  noobj_loss: 0.0999  bbox_loss: 0.0344  cls_loss: 0.1718  \n",
      "<<<iteration:[100/878] - total_loss: 0.5911  obj_loss: 0.2365  noobj_loss: 0.1103  bbox_loss: 0.0272  cls_loss: 0.1636  \n",
      "<<<iteration:[120/878] - total_loss: 0.5777  obj_loss: 0.2176  noobj_loss: 0.1041  bbox_loss: 0.0308  cls_loss: 0.1543  \n",
      "<<<iteration:[140/878] - total_loss: 0.7163  obj_loss: 0.2531  noobj_loss: 0.0920  bbox_loss: 0.0317  cls_loss: 0.2589  \n",
      "<<<iteration:[160/878] - total_loss: 0.6300  obj_loss: 0.1932  noobj_loss: 0.1010  bbox_loss: 0.0298  cls_loss: 0.2376  \n",
      "<<<iteration:[180/878] - total_loss: 0.5647  obj_loss: 0.1850  noobj_loss: 0.0869  bbox_loss: 0.0264  cls_loss: 0.2041  \n",
      "<<<iteration:[200/878] - total_loss: 0.6171  obj_loss: 0.1991  noobj_loss: 0.1079  bbox_loss: 0.0324  cls_loss: 0.2020  \n",
      "<<<iteration:[220/878] - total_loss: 0.6463  obj_loss: 0.2021  noobj_loss: 0.0942  bbox_loss: 0.0344  cls_loss: 0.2251  \n",
      "<<<iteration:[240/878] - total_loss: 0.6093  obj_loss: 0.2097  noobj_loss: 0.0870  bbox_loss: 0.0369  cls_loss: 0.1715  \n",
      "<<<iteration:[260/878] - total_loss: 0.5103  obj_loss: 0.2136  noobj_loss: 0.0915  bbox_loss: 0.0277  cls_loss: 0.1123  \n",
      "<<<iteration:[280/878] - total_loss: 0.6069  obj_loss: 0.2218  noobj_loss: 0.0934  bbox_loss: 0.0298  cls_loss: 0.1896  \n",
      "<<<iteration:[300/878] - total_loss: 0.6318  obj_loss: 0.2110  noobj_loss: 0.0916  bbox_loss: 0.0335  cls_loss: 0.2073  \n",
      "<<<iteration:[320/878] - total_loss: 0.6832  obj_loss: 0.2298  noobj_loss: 0.1158  bbox_loss: 0.0362  cls_loss: 0.2145  \n",
      "<<<iteration:[340/878] - total_loss: 0.5126  obj_loss: 0.2138  noobj_loss: 0.0847  bbox_loss: 0.0270  cls_loss: 0.1213  \n",
      "<<<iteration:[360/878] - total_loss: 0.5205  obj_loss: 0.2142  noobj_loss: 0.1026  bbox_loss: 0.0284  cls_loss: 0.1129  \n",
      "<<<iteration:[380/878] - total_loss: 0.5831  obj_loss: 0.2164  noobj_loss: 0.0905  bbox_loss: 0.0330  cls_loss: 0.1565  \n",
      "<<<iteration:[400/878] - total_loss: 0.6488  obj_loss: 0.2142  noobj_loss: 0.1016  bbox_loss: 0.0401  cls_loss: 0.1835  \n",
      "<<<iteration:[420/878] - total_loss: 0.5812  obj_loss: 0.2005  noobj_loss: 0.0939  bbox_loss: 0.0321  cls_loss: 0.1732  \n",
      "<<<iteration:[440/878] - total_loss: 0.6638  obj_loss: 0.2679  noobj_loss: 0.1129  bbox_loss: 0.0331  cls_loss: 0.1737  \n",
      "<<<iteration:[460/878] - total_loss: 0.6538  obj_loss: 0.2153  noobj_loss: 0.1140  bbox_loss: 0.0318  cls_loss: 0.2225  \n",
      "<<<iteration:[480/878] - total_loss: 0.6881  obj_loss: 0.2045  noobj_loss: 0.1036  bbox_loss: 0.0384  cls_loss: 0.2396  \n",
      "<<<iteration:[500/878] - total_loss: 0.6653  obj_loss: 0.1919  noobj_loss: 0.0950  bbox_loss: 0.0318  cls_loss: 0.2670  \n",
      "<<<iteration:[520/878] - total_loss: 0.5830  obj_loss: 0.1938  noobj_loss: 0.0960  bbox_loss: 0.0337  cls_loss: 0.1728  \n",
      "<<<iteration:[540/878] - total_loss: 0.6061  obj_loss: 0.2074  noobj_loss: 0.1054  bbox_loss: 0.0359  cls_loss: 0.1666  \n",
      "<<<iteration:[560/878] - total_loss: 1.2864  obj_loss: 0.1888  noobj_loss: 0.1019  bbox_loss: 0.1353  cls_loss: 0.3704  \n",
      "<<<iteration:[580/878] - total_loss: 0.7373  obj_loss: 0.2078  noobj_loss: 0.1014  bbox_loss: 0.0420  cls_loss: 0.2687  \n",
      "<<<iteration:[600/878] - total_loss: 0.9966  obj_loss: 0.1682  noobj_loss: 0.0825  bbox_loss: 0.1046  cls_loss: 0.2642  \n",
      "<<<iteration:[620/878] - total_loss: 0.4442  obj_loss: 0.1632  noobj_loss: 0.0716  bbox_loss: 0.0237  cls_loss: 0.1266  \n",
      "<<<iteration:[640/878] - total_loss: 0.9943  obj_loss: 0.2070  noobj_loss: 0.0917  bbox_loss: 0.1090  cls_loss: 0.1965  \n",
      "<<<iteration:[660/878] - total_loss: 0.9261  obj_loss: 0.1984  noobj_loss: 0.1025  bbox_loss: 0.1014  cls_loss: 0.1694  \n",
      "<<<iteration:[680/878] - total_loss: 0.6974  obj_loss: 0.2120  noobj_loss: 0.0956  bbox_loss: 0.0366  cls_loss: 0.2548  \n",
      "<<<iteration:[700/878] - total_loss: 0.7311  obj_loss: 0.2395  noobj_loss: 0.0944  bbox_loss: 0.0335  cls_loss: 0.2770  \n",
      "<<<iteration:[720/878] - total_loss: 0.6761  obj_loss: 0.2017  noobj_loss: 0.0961  bbox_loss: 0.0355  cls_loss: 0.2489  \n",
      "<<<iteration:[740/878] - total_loss: 0.6167  obj_loss: 0.2028  noobj_loss: 0.0873  bbox_loss: 0.0311  cls_loss: 0.2148  \n",
      "<<<iteration:[760/878] - total_loss: 0.7046  obj_loss: 0.2134  noobj_loss: 0.1112  bbox_loss: 0.0388  cls_loss: 0.2418  \n",
      "<<<iteration:[780/878] - total_loss: 1.0721  obj_loss: 0.1893  noobj_loss: 0.1004  bbox_loss: 0.1177  cls_loss: 0.2443  \n",
      "<<<iteration:[800/878] - total_loss: 0.7482  obj_loss: 0.1844  noobj_loss: 0.0943  bbox_loss: 0.0648  cls_loss: 0.1924  \n",
      "<<<iteration:[820/878] - total_loss: 0.7076  obj_loss: 0.2542  noobj_loss: 0.1042  bbox_loss: 0.0309  cls_loss: 0.2470  \n",
      "<<<iteration:[840/878] - total_loss: 0.7584  obj_loss: 0.2776  noobj_loss: 0.1071  bbox_loss: 0.0585  cls_loss: 0.1348  \n",
      "<<<iteration:[860/878] - total_loss: 0.6919  obj_loss: 0.2236  noobj_loss: 0.1115  bbox_loss: 0.0416  cls_loss: 0.2048  \n",
      "\n",
      "epoch:69/100 - Train Loss: 0.6832, Val Loss: 1.1899\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<<<iteration:[20/878] - total_loss: 0.8008  obj_loss: 0.2158  noobj_loss: 0.0968  bbox_loss: 0.0500  cls_loss: 0.2867  \n",
      "<<<iteration:[40/878] - total_loss: 0.7227  obj_loss: 0.2192  noobj_loss: 0.1035  bbox_loss: 0.0447  cls_loss: 0.2283  \n",
      "<<<iteration:[60/878] - total_loss: 0.5921  obj_loss: 0.2208  noobj_loss: 0.1030  bbox_loss: 0.0282  cls_loss: 0.1785  \n",
      "<<<iteration:[80/878] - total_loss: 0.6870  obj_loss: 0.1941  noobj_loss: 0.0977  bbox_loss: 0.0544  cls_loss: 0.1722  \n",
      "<<<iteration:[100/878] - total_loss: 0.6753  obj_loss: 0.2014  noobj_loss: 0.0981  bbox_loss: 0.0347  cls_loss: 0.2512  \n",
      "<<<iteration:[120/878] - total_loss: 0.6339  obj_loss: 0.2301  noobj_loss: 0.1118  bbox_loss: 0.0381  cls_loss: 0.1572  \n",
      "<<<iteration:[140/878] - total_loss: 0.7152  obj_loss: 0.2193  noobj_loss: 0.1034  bbox_loss: 0.0474  cls_loss: 0.2071  \n",
      "<<<iteration:[160/878] - total_loss: 0.7487  obj_loss: 0.2192  noobj_loss: 0.1061  bbox_loss: 0.0518  cls_loss: 0.2173  \n",
      "<<<iteration:[180/878] - total_loss: 0.6910  obj_loss: 0.1888  noobj_loss: 0.0788  bbox_loss: 0.0308  cls_loss: 0.3087  \n",
      "<<<iteration:[200/878] - total_loss: 0.5439  obj_loss: 0.2038  noobj_loss: 0.0836  bbox_loss: 0.0263  cls_loss: 0.1666  \n",
      "<<<iteration:[220/878] - total_loss: 0.5643  obj_loss: 0.1713  noobj_loss: 0.0846  bbox_loss: 0.0300  cls_loss: 0.2007  \n",
      "<<<iteration:[240/878] - total_loss: 0.6723  obj_loss: 0.2203  noobj_loss: 0.0935  bbox_loss: 0.0391  cls_loss: 0.2098  \n",
      "<<<iteration:[260/878] - total_loss: 0.6906  obj_loss: 0.1852  noobj_loss: 0.1022  bbox_loss: 0.0356  cls_loss: 0.2763  \n",
      "<<<iteration:[280/878] - total_loss: 0.6511  obj_loss: 0.2096  noobj_loss: 0.1055  bbox_loss: 0.0400  cls_loss: 0.1888  \n",
      "<<<iteration:[300/878] - total_loss: 0.6587  obj_loss: 0.2070  noobj_loss: 0.1078  bbox_loss: 0.0337  cls_loss: 0.2294  \n",
      "<<<iteration:[320/878] - total_loss: 0.5381  obj_loss: 0.2083  noobj_loss: 0.0915  bbox_loss: 0.0351  cls_loss: 0.1087  \n",
      "<<<iteration:[340/878] - total_loss: 0.6272  obj_loss: 0.2183  noobj_loss: 0.1019  bbox_loss: 0.0341  cls_loss: 0.1877  \n",
      "<<<iteration:[360/878] - total_loss: 0.6342  obj_loss: 0.2197  noobj_loss: 0.1029  bbox_loss: 0.0328  cls_loss: 0.1993  \n",
      "<<<iteration:[380/878] - total_loss: 0.8444  obj_loss: 0.2735  noobj_loss: 0.1260  bbox_loss: 0.0442  cls_loss: 0.2870  \n",
      "<<<iteration:[400/878] - total_loss: 0.6527  obj_loss: 0.2109  noobj_loss: 0.1093  bbox_loss: 0.0357  cls_loss: 0.2089  \n",
      "<<<iteration:[420/878] - total_loss: 0.6238  obj_loss: 0.1930  noobj_loss: 0.0961  bbox_loss: 0.0413  cls_loss: 0.1764  \n",
      "<<<iteration:[440/878] - total_loss: 0.8148  obj_loss: 0.2558  noobj_loss: 0.1031  bbox_loss: 0.0448  cls_loss: 0.2833  \n",
      "<<<iteration:[460/878] - total_loss: 0.5985  obj_loss: 0.2072  noobj_loss: 0.0902  bbox_loss: 0.0328  cls_loss: 0.1822  \n",
      "<<<iteration:[480/878] - total_loss: 0.6416  obj_loss: 0.2169  noobj_loss: 0.1160  bbox_loss: 0.0415  cls_loss: 0.1594  \n",
      "<<<iteration:[500/878] - total_loss: 0.6748  obj_loss: 0.2112  noobj_loss: 0.1069  bbox_loss: 0.0329  cls_loss: 0.2456  \n",
      "<<<iteration:[520/878] - total_loss: 0.5124  obj_loss: 0.1843  noobj_loss: 0.0965  bbox_loss: 0.0312  cls_loss: 0.1238  \n",
      "<<<iteration:[540/878] - total_loss: 0.6412  obj_loss: 0.2088  noobj_loss: 0.0977  bbox_loss: 0.0332  cls_loss: 0.2178  \n",
      "<<<iteration:[560/878] - total_loss: 0.6387  obj_loss: 0.2051  noobj_loss: 0.0990  bbox_loss: 0.0269  cls_loss: 0.2496  \n",
      "<<<iteration:[580/878] - total_loss: 0.5508  obj_loss: 0.1865  noobj_loss: 0.0959  bbox_loss: 0.0355  cls_loss: 0.1388  \n",
      "<<<iteration:[600/878] - total_loss: 0.6314  obj_loss: 0.2317  noobj_loss: 0.1147  bbox_loss: 0.0265  cls_loss: 0.2097  \n",
      "<<<iteration:[620/878] - total_loss: 0.6557  obj_loss: 0.2155  noobj_loss: 0.0971  bbox_loss: 0.0316  cls_loss: 0.2338  \n",
      "<<<iteration:[640/878] - total_loss: 0.6598  obj_loss: 0.2004  noobj_loss: 0.0976  bbox_loss: 0.0389  cls_loss: 0.2162  \n",
      "<<<iteration:[660/878] - total_loss: 0.5823  obj_loss: 0.2234  noobj_loss: 0.0926  bbox_loss: 0.0289  cls_loss: 0.1680  \n",
      "<<<iteration:[680/878] - total_loss: 0.5395  obj_loss: 0.2007  noobj_loss: 0.1068  bbox_loss: 0.0291  cls_loss: 0.1397  \n",
      "<<<iteration:[700/878] - total_loss: 0.5466  obj_loss: 0.2113  noobj_loss: 0.1093  bbox_loss: 0.0293  cls_loss: 0.1344  \n",
      "<<<iteration:[720/878] - total_loss: 0.5980  obj_loss: 0.2381  noobj_loss: 0.0957  bbox_loss: 0.0318  cls_loss: 0.1530  \n",
      "<<<iteration:[740/878] - total_loss: 0.6049  obj_loss: 0.2294  noobj_loss: 0.1077  bbox_loss: 0.0324  cls_loss: 0.1596  \n",
      "<<<iteration:[760/878] - total_loss: 0.5610  obj_loss: 0.2217  noobj_loss: 0.1001  bbox_loss: 0.0302  cls_loss: 0.1383  \n",
      "<<<iteration:[780/878] - total_loss: 0.7190  obj_loss: 0.2241  noobj_loss: 0.0970  bbox_loss: 0.0537  cls_loss: 0.1781  \n",
      "<<<iteration:[800/878] - total_loss: 0.5977  obj_loss: 0.2486  noobj_loss: 0.0975  bbox_loss: 0.0328  cls_loss: 0.1364  \n",
      "<<<iteration:[820/878] - total_loss: 0.6545  obj_loss: 0.2487  noobj_loss: 0.1112  bbox_loss: 0.0336  cls_loss: 0.1822  \n",
      "<<<iteration:[840/878] - total_loss: 0.7031  obj_loss: 0.2127  noobj_loss: 0.1069  bbox_loss: 0.0266  cls_loss: 0.3038  \n",
      "<<<iteration:[860/878] - total_loss: 0.6981  obj_loss: 0.2042  noobj_loss: 0.1136  bbox_loss: 0.0417  cls_loss: 0.2285  \n",
      "\n",
      "epoch:70/100 - Train Loss: 0.6463, Val Loss: 1.1539\n",
      "\n",
      "<<<iteration:[20/878] - total_loss: 0.6917  obj_loss: 0.2372  noobj_loss: 0.1198  bbox_loss: 0.0328  cls_loss: 0.2308  \n",
      "<<<iteration:[40/878] - total_loss: 0.6791  obj_loss: 0.2135  noobj_loss: 0.1083  bbox_loss: 0.0322  cls_loss: 0.2503  \n",
      "<<<iteration:[60/878] - total_loss: 0.5929  obj_loss: 0.2047  noobj_loss: 0.1000  bbox_loss: 0.0282  cls_loss: 0.1971  \n",
      "<<<iteration:[80/878] - total_loss: 0.6162  obj_loss: 0.2223  noobj_loss: 0.1176  bbox_loss: 0.0324  cls_loss: 0.1732  \n",
      "<<<iteration:[100/878] - total_loss: 0.6039  obj_loss: 0.1556  noobj_loss: 0.0944  bbox_loss: 0.0361  cls_loss: 0.2205  \n",
      "<<<iteration:[120/878] - total_loss: 0.6604  obj_loss: 0.2150  noobj_loss: 0.0997  bbox_loss: 0.0369  cls_loss: 0.2110  \n",
      "<<<iteration:[140/878] - total_loss: 0.6312  obj_loss: 0.2099  noobj_loss: 0.0970  bbox_loss: 0.0387  cls_loss: 0.1793  \n",
      "<<<iteration:[160/878] - total_loss: 0.6405  obj_loss: 0.2106  noobj_loss: 0.0929  bbox_loss: 0.0322  cls_loss: 0.2224  \n",
      "<<<iteration:[180/878] - total_loss: 0.5997  obj_loss: 0.2004  noobj_loss: 0.0950  bbox_loss: 0.0368  cls_loss: 0.1677  \n",
      "<<<iteration:[200/878] - total_loss: 0.6562  obj_loss: 0.2393  noobj_loss: 0.0990  bbox_loss: 0.0348  cls_loss: 0.1934  \n",
      "<<<iteration:[220/878] - total_loss: 0.5558  obj_loss: 0.1918  noobj_loss: 0.0975  bbox_loss: 0.0352  cls_loss: 0.1395  \n",
      "<<<iteration:[240/878] - total_loss: 0.5633  obj_loss: 0.1807  noobj_loss: 0.0937  bbox_loss: 0.0347  cls_loss: 0.1620  \n",
      "<<<iteration:[260/878] - total_loss: 0.6592  obj_loss: 0.2237  noobj_loss: 0.1079  bbox_loss: 0.0284  cls_loss: 0.2398  \n",
      "<<<iteration:[280/878] - total_loss: 0.6389  obj_loss: 0.2371  noobj_loss: 0.1067  bbox_loss: 0.0274  cls_loss: 0.2113  \n",
      "<<<iteration:[300/878] - total_loss: 0.5651  obj_loss: 0.2113  noobj_loss: 0.1109  bbox_loss: 0.0307  cls_loss: 0.1446  \n",
      "<<<iteration:[320/878] - total_loss: 0.5883  obj_loss: 0.2055  noobj_loss: 0.0885  bbox_loss: 0.0340  cls_loss: 0.1683  \n",
      "<<<iteration:[340/878] - total_loss: 0.7836  obj_loss: 0.2382  noobj_loss: 0.0900  bbox_loss: 0.0299  cls_loss: 0.3510  \n",
      "<<<iteration:[360/878] - total_loss: 0.7622  obj_loss: 0.2367  noobj_loss: 0.1150  bbox_loss: 0.0437  cls_loss: 0.2497  \n",
      "<<<iteration:[380/878] - total_loss: 0.6257  obj_loss: 0.2227  noobj_loss: 0.0950  bbox_loss: 0.0331  cls_loss: 0.1899  \n",
      "<<<iteration:[400/878] - total_loss: 0.7036  obj_loss: 0.2259  noobj_loss: 0.1085  bbox_loss: 0.0451  cls_loss: 0.1979  \n",
      "<<<iteration:[420/878] - total_loss: 0.6569  obj_loss: 0.2151  noobj_loss: 0.1195  bbox_loss: 0.0369  cls_loss: 0.1976  \n",
      "<<<iteration:[440/878] - total_loss: 0.5976  obj_loss: 0.2202  noobj_loss: 0.0986  bbox_loss: 0.0285  cls_loss: 0.1858  \n",
      "<<<iteration:[460/878] - total_loss: 0.6138  obj_loss: 0.2247  noobj_loss: 0.1067  bbox_loss: 0.0409  cls_loss: 0.1311  \n",
      "<<<iteration:[480/878] - total_loss: 0.6270  obj_loss: 0.2039  noobj_loss: 0.0883  bbox_loss: 0.0413  cls_loss: 0.1726  \n",
      "<<<iteration:[500/878] - total_loss: 0.6896  obj_loss: 0.2363  noobj_loss: 0.0919  bbox_loss: 0.0349  cls_loss: 0.2328  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<<<iteration:[520/878] - total_loss: 0.6002  obj_loss: 0.2644  noobj_loss: 0.1044  bbox_loss: 0.0304  cls_loss: 0.1315  \n",
      "<<<iteration:[540/878] - total_loss: 0.5632  obj_loss: 0.2310  noobj_loss: 0.1027  bbox_loss: 0.0273  cls_loss: 0.1444  \n",
      "<<<iteration:[560/878] - total_loss: 0.6052  obj_loss: 0.2048  noobj_loss: 0.0984  bbox_loss: 0.0390  cls_loss: 0.1561  \n",
      "<<<iteration:[580/878] - total_loss: 0.5756  obj_loss: 0.2094  noobj_loss: 0.0969  bbox_loss: 0.0280  cls_loss: 0.1777  \n",
      "<<<iteration:[600/878] - total_loss: 0.4800  obj_loss: 0.1928  noobj_loss: 0.1044  bbox_loss: 0.0287  cls_loss: 0.0915  \n",
      "<<<iteration:[620/878] - total_loss: 0.5502  obj_loss: 0.2345  noobj_loss: 0.0980  bbox_loss: 0.0333  cls_loss: 0.1001  \n",
      "<<<iteration:[640/878] - total_loss: 0.6413  obj_loss: 0.2346  noobj_loss: 0.1000  bbox_loss: 0.0284  cls_loss: 0.2147  \n",
      "<<<iteration:[660/878] - total_loss: 0.5935  obj_loss: 0.2297  noobj_loss: 0.1047  bbox_loss: 0.0306  cls_loss: 0.1583  \n",
      "<<<iteration:[680/878] - total_loss: 0.7031  obj_loss: 0.2227  noobj_loss: 0.1061  bbox_loss: 0.0327  cls_loss: 0.2638  \n",
      "<<<iteration:[700/878] - total_loss: 0.5635  obj_loss: 0.1951  noobj_loss: 0.0935  bbox_loss: 0.0307  cls_loss: 0.1680  \n",
      "<<<iteration:[720/878] - total_loss: 0.6245  obj_loss: 0.1686  noobj_loss: 0.0870  bbox_loss: 0.0359  cls_loss: 0.2328  \n",
      "<<<iteration:[740/878] - total_loss: 0.6933  obj_loss: 0.2290  noobj_loss: 0.1197  bbox_loss: 0.0408  cls_loss: 0.2004  \n",
      "<<<iteration:[760/878] - total_loss: 0.6183  obj_loss: 0.2593  noobj_loss: 0.1145  bbox_loss: 0.0282  cls_loss: 0.1608  \n",
      "<<<iteration:[780/878] - total_loss: 0.6452  obj_loss: 0.2473  noobj_loss: 0.1165  bbox_loss: 0.0321  cls_loss: 0.1793  \n",
      "<<<iteration:[800/878] - total_loss: 0.6151  obj_loss: 0.2665  noobj_loss: 0.1067  bbox_loss: 0.0321  cls_loss: 0.1346  \n",
      "<<<iteration:[820/878] - total_loss: 0.6629  obj_loss: 0.2475  noobj_loss: 0.1226  bbox_loss: 0.0374  cls_loss: 0.1673  \n",
      "<<<iteration:[840/878] - total_loss: 0.6608  obj_loss: 0.2362  noobj_loss: 0.1160  bbox_loss: 0.0304  cls_loss: 0.2148  \n",
      "<<<iteration:[860/878] - total_loss: 0.6510  obj_loss: 0.1846  noobj_loss: 0.1000  bbox_loss: 0.0384  cls_loss: 0.2243  \n",
      "\n",
      "epoch:71/100 - Train Loss: 0.6315, Val Loss: 1.7340\n",
      "\n",
      "<<<iteration:[20/878] - total_loss: 0.7392  obj_loss: 0.2282  noobj_loss: 0.1097  bbox_loss: 0.0497  cls_loss: 0.2075  \n",
      "<<<iteration:[40/878] - total_loss: 0.5699  obj_loss: 0.1877  noobj_loss: 0.1063  bbox_loss: 0.0335  cls_loss: 0.1616  \n",
      "<<<iteration:[60/878] - total_loss: 0.6808  obj_loss: 0.2010  noobj_loss: 0.1060  bbox_loss: 0.0363  cls_loss: 0.2453  \n",
      "<<<iteration:[80/878] - total_loss: 0.5791  obj_loss: 0.2359  noobj_loss: 0.1025  bbox_loss: 0.0290  cls_loss: 0.1469  \n",
      "<<<iteration:[100/878] - total_loss: 0.6392  obj_loss: 0.2401  noobj_loss: 0.1043  bbox_loss: 0.0367  cls_loss: 0.1635  \n",
      "<<<iteration:[120/878] - total_loss: 0.5585  obj_loss: 0.1952  noobj_loss: 0.1032  bbox_loss: 0.0319  cls_loss: 0.1523  \n",
      "<<<iteration:[140/878] - total_loss: 0.5656  obj_loss: 0.1883  noobj_loss: 0.1167  bbox_loss: 0.0286  cls_loss: 0.1760  \n",
      "<<<iteration:[160/878] - total_loss: 0.6885  obj_loss: 0.2144  noobj_loss: 0.1068  bbox_loss: 0.0385  cls_loss: 0.2284  \n",
      "<<<iteration:[180/878] - total_loss: 0.6526  obj_loss: 0.2295  noobj_loss: 0.1209  bbox_loss: 0.0350  cls_loss: 0.1875  \n",
      "<<<iteration:[200/878] - total_loss: 0.6613  obj_loss: 0.2315  noobj_loss: 0.1103  bbox_loss: 0.0356  cls_loss: 0.1966  \n",
      "<<<iteration:[220/878] - total_loss: 0.6189  obj_loss: 0.2524  noobj_loss: 0.0996  bbox_loss: 0.0281  cls_loss: 0.1760  \n",
      "<<<iteration:[240/878] - total_loss: 0.5695  obj_loss: 0.2507  noobj_loss: 0.1100  bbox_loss: 0.0281  cls_loss: 0.1235  \n",
      "<<<iteration:[260/878] - total_loss: 0.5838  obj_loss: 0.2218  noobj_loss: 0.1015  bbox_loss: 0.0275  cls_loss: 0.1739  \n",
      "<<<iteration:[280/878] - total_loss: 0.6432  obj_loss: 0.2135  noobj_loss: 0.1160  bbox_loss: 0.0364  cls_loss: 0.1897  \n",
      "<<<iteration:[300/878] - total_loss: 0.6242  obj_loss: 0.2266  noobj_loss: 0.1102  bbox_loss: 0.0279  cls_loss: 0.2031  \n",
      "<<<iteration:[320/878] - total_loss: 0.5954  obj_loss: 0.1900  noobj_loss: 0.0968  bbox_loss: 0.0321  cls_loss: 0.1966  \n",
      "<<<iteration:[340/878] - total_loss: 0.6827  obj_loss: 0.2135  noobj_loss: 0.0993  bbox_loss: 0.0289  cls_loss: 0.2754  \n",
      "<<<iteration:[360/878] - total_loss: 0.6326  obj_loss: 0.2487  noobj_loss: 0.1071  bbox_loss: 0.0291  cls_loss: 0.1848  \n",
      "<<<iteration:[380/878] - total_loss: 0.5698  obj_loss: 0.2236  noobj_loss: 0.1037  bbox_loss: 0.0352  cls_loss: 0.1181  \n",
      "<<<iteration:[400/878] - total_loss: 0.5482  obj_loss: 0.2282  noobj_loss: 0.1096  bbox_loss: 0.0279  cls_loss: 0.1258  \n",
      "<<<iteration:[420/878] - total_loss: 0.5496  obj_loss: 0.2209  noobj_loss: 0.1153  bbox_loss: 0.0370  cls_loss: 0.0861  \n",
      "<<<iteration:[440/878] - total_loss: 0.7700  obj_loss: 0.2125  noobj_loss: 0.1089  bbox_loss: 0.0366  cls_loss: 0.3198  \n",
      "<<<iteration:[460/878] - total_loss: 0.6584  obj_loss: 0.2379  noobj_loss: 0.1086  bbox_loss: 0.0304  cls_loss: 0.2144  \n",
      "<<<iteration:[480/878] - total_loss: 0.5732  obj_loss: 0.2166  noobj_loss: 0.1078  bbox_loss: 0.0300  cls_loss: 0.1529  \n",
      "<<<iteration:[500/878] - total_loss: 0.6913  obj_loss: 0.2269  noobj_loss: 0.0926  bbox_loss: 0.0282  cls_loss: 0.2772  \n",
      "<<<iteration:[520/878] - total_loss: 0.6000  obj_loss: 0.1974  noobj_loss: 0.1086  bbox_loss: 0.0311  cls_loss: 0.1930  \n",
      "<<<iteration:[540/878] - total_loss: 0.5485  obj_loss: 0.2048  noobj_loss: 0.0911  bbox_loss: 0.0281  cls_loss: 0.1578  \n",
      "<<<iteration:[560/878] - total_loss: 0.7020  obj_loss: 0.1980  noobj_loss: 0.1214  bbox_loss: 0.0511  cls_loss: 0.1879  \n",
      "<<<iteration:[580/878] - total_loss: 0.8028  obj_loss: 0.2243  noobj_loss: 0.1152  bbox_loss: 0.0645  cls_loss: 0.1987  \n",
      "<<<iteration:[600/878] - total_loss: 0.7418  obj_loss: 0.2432  noobj_loss: 0.1023  bbox_loss: 0.0342  cls_loss: 0.2766  \n",
      "<<<iteration:[620/878] - total_loss: 0.6415  obj_loss: 0.1848  noobj_loss: 0.1339  bbox_loss: 0.0385  cls_loss: 0.1973  \n",
      "<<<iteration:[640/878] - total_loss: 0.5258  obj_loss: 0.2099  noobj_loss: 0.0960  bbox_loss: 0.0266  cls_loss: 0.1351  \n",
      "<<<iteration:[660/878] - total_loss: 0.4979  obj_loss: 0.2094  noobj_loss: 0.0937  bbox_loss: 0.0296  cls_loss: 0.0933  \n",
      "<<<iteration:[680/878] - total_loss: 0.6058  obj_loss: 0.2317  noobj_loss: 0.0989  bbox_loss: 0.0319  cls_loss: 0.1652  \n",
      "<<<iteration:[700/878] - total_loss: 0.5625  obj_loss: 0.2074  noobj_loss: 0.0992  bbox_loss: 0.0286  cls_loss: 0.1626  \n",
      "<<<iteration:[720/878] - total_loss: 0.5764  obj_loss: 0.2123  noobj_loss: 0.1234  bbox_loss: 0.0315  cls_loss: 0.1450  \n",
      "<<<iteration:[740/878] - total_loss: 0.6116  obj_loss: 0.2236  noobj_loss: 0.1040  bbox_loss: 0.0331  cls_loss: 0.1704  \n",
      "<<<iteration:[760/878] - total_loss: 0.6736  obj_loss: 0.2263  noobj_loss: 0.1073  bbox_loss: 0.0351  cls_loss: 0.2183  \n",
      "<<<iteration:[780/878] - total_loss: 0.6395  obj_loss: 0.2059  noobj_loss: 0.0873  bbox_loss: 0.0301  cls_loss: 0.2396  \n",
      "<<<iteration:[800/878] - total_loss: 0.7197  obj_loss: 0.2121  noobj_loss: 0.0899  bbox_loss: 0.0293  cls_loss: 0.3163  \n",
      "<<<iteration:[820/878] - total_loss: 0.5714  obj_loss: 0.1851  noobj_loss: 0.1085  bbox_loss: 0.0379  cls_loss: 0.1423  \n",
      "<<<iteration:[840/878] - total_loss: 0.7027  obj_loss: 0.2514  noobj_loss: 0.1025  bbox_loss: 0.0294  cls_loss: 0.2530  \n",
      "<<<iteration:[860/878] - total_loss: 0.6221  obj_loss: 0.2566  noobj_loss: 0.1192  bbox_loss: 0.0257  cls_loss: 0.1775  \n",
      "\n",
      "epoch:72/100 - Train Loss: 0.6273, Val Loss: 1.1525\n",
      "\n",
      "<<<iteration:[20/878] - total_loss: 0.6150  obj_loss: 0.2663  noobj_loss: 0.1220  bbox_loss: 0.0297  cls_loss: 0.1391  \n",
      "<<<iteration:[40/878] - total_loss: 0.6000  obj_loss: 0.1991  noobj_loss: 0.0996  bbox_loss: 0.0306  cls_loss: 0.1980  \n",
      "<<<iteration:[60/878] - total_loss: 0.6731  obj_loss: 0.2362  noobj_loss: 0.1097  bbox_loss: 0.0342  cls_loss: 0.2112  \n",
      "<<<iteration:[80/878] - total_loss: 0.6173  obj_loss: 0.2104  noobj_loss: 0.1066  bbox_loss: 0.0380  cls_loss: 0.1638  \n",
      "<<<iteration:[100/878] - total_loss: 0.5925  obj_loss: 0.1744  noobj_loss: 0.0942  bbox_loss: 0.0363  cls_loss: 0.1897  \n",
      "<<<iteration:[120/878] - total_loss: 0.5961  obj_loss: 0.2261  noobj_loss: 0.0926  bbox_loss: 0.0310  cls_loss: 0.1686  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<<<iteration:[140/878] - total_loss: 0.6642  obj_loss: 0.2456  noobj_loss: 0.1107  bbox_loss: 0.0394  cls_loss: 0.1661  \n",
      "<<<iteration:[160/878] - total_loss: 0.6272  obj_loss: 0.2190  noobj_loss: 0.1119  bbox_loss: 0.0458  cls_loss: 0.1232  \n",
      "<<<iteration:[180/878] - total_loss: 0.5525  obj_loss: 0.2255  noobj_loss: 0.0940  bbox_loss: 0.0275  cls_loss: 0.1423  \n",
      "<<<iteration:[200/878] - total_loss: 0.5873  obj_loss: 0.2133  noobj_loss: 0.1092  bbox_loss: 0.0348  cls_loss: 0.1453  \n",
      "<<<iteration:[220/878] - total_loss: 0.6990  obj_loss: 0.2298  noobj_loss: 0.1101  bbox_loss: 0.0314  cls_loss: 0.2572  \n",
      "<<<iteration:[240/878] - total_loss: 0.7239  obj_loss: 0.2115  noobj_loss: 0.1125  bbox_loss: 0.0440  cls_loss: 0.2359  \n",
      "<<<iteration:[260/878] - total_loss: 0.5517  obj_loss: 0.2331  noobj_loss: 0.0983  bbox_loss: 0.0298  cls_loss: 0.1203  \n",
      "<<<iteration:[280/878] - total_loss: 0.5732  obj_loss: 0.1746  noobj_loss: 0.1023  bbox_loss: 0.0291  cls_loss: 0.2019  \n",
      "<<<iteration:[300/878] - total_loss: 0.6625  obj_loss: 0.2467  noobj_loss: 0.1086  bbox_loss: 0.0333  cls_loss: 0.1949  \n",
      "<<<iteration:[320/878] - total_loss: 0.6030  obj_loss: 0.2289  noobj_loss: 0.1008  bbox_loss: 0.0267  cls_loss: 0.1903  \n",
      "<<<iteration:[340/878] - total_loss: 0.6326  obj_loss: 0.2489  noobj_loss: 0.1089  bbox_loss: 0.0332  cls_loss: 0.1632  \n",
      "<<<iteration:[360/878] - total_loss: 0.6955  obj_loss: 0.2637  noobj_loss: 0.1139  bbox_loss: 0.0287  cls_loss: 0.2310  \n",
      "<<<iteration:[380/878] - total_loss: 0.5703  obj_loss: 0.2009  noobj_loss: 0.1046  bbox_loss: 0.0358  cls_loss: 0.1382  \n",
      "<<<iteration:[400/878] - total_loss: 0.5696  obj_loss: 0.2201  noobj_loss: 0.1175  bbox_loss: 0.0298  cls_loss: 0.1416  \n",
      "<<<iteration:[420/878] - total_loss: 0.5337  obj_loss: 0.2212  noobj_loss: 0.1012  bbox_loss: 0.0290  cls_loss: 0.1171  \n",
      "<<<iteration:[440/878] - total_loss: 0.5211  obj_loss: 0.1953  noobj_loss: 0.1028  bbox_loss: 0.0303  cls_loss: 0.1229  \n",
      "<<<iteration:[460/878] - total_loss: 0.6972  obj_loss: 0.2658  noobj_loss: 0.1089  bbox_loss: 0.0316  cls_loss: 0.2191  \n",
      "<<<iteration:[480/878] - total_loss: 0.6516  obj_loss: 0.1916  noobj_loss: 0.0942  bbox_loss: 0.0360  cls_loss: 0.2328  \n",
      "<<<iteration:[500/878] - total_loss: 0.6605  obj_loss: 0.2187  noobj_loss: 0.0977  bbox_loss: 0.0316  cls_loss: 0.2351  \n",
      "<<<iteration:[520/878] - total_loss: 0.6690  obj_loss: 0.2390  noobj_loss: 0.1194  bbox_loss: 0.0330  cls_loss: 0.2054  \n",
      "<<<iteration:[540/878] - total_loss: 0.6333  obj_loss: 0.2401  noobj_loss: 0.1045  bbox_loss: 0.0313  cls_loss: 0.1845  \n",
      "<<<iteration:[560/878] - total_loss: 0.5767  obj_loss: 0.2333  noobj_loss: 0.1058  bbox_loss: 0.0266  cls_loss: 0.1575  \n",
      "<<<iteration:[580/878] - total_loss: 0.6550  obj_loss: 0.2185  noobj_loss: 0.1114  bbox_loss: 0.0297  cls_loss: 0.2325  \n",
      "<<<iteration:[600/878] - total_loss: 0.5978  obj_loss: 0.1862  noobj_loss: 0.1097  bbox_loss: 0.0353  cls_loss: 0.1805  \n",
      "<<<iteration:[620/878] - total_loss: 0.5854  obj_loss: 0.2568  noobj_loss: 0.1101  bbox_loss: 0.0318  cls_loss: 0.1145  \n",
      "<<<iteration:[640/878] - total_loss: 0.5918  obj_loss: 0.2247  noobj_loss: 0.0949  bbox_loss: 0.0291  cls_loss: 0.1740  \n",
      "<<<iteration:[660/878] - total_loss: 0.7218  obj_loss: 0.2241  noobj_loss: 0.1000  bbox_loss: 0.0585  cls_loss: 0.1553  \n",
      "<<<iteration:[680/878] - total_loss: 0.7054  obj_loss: 0.2235  noobj_loss: 0.1064  bbox_loss: 0.0432  cls_loss: 0.2129  \n",
      "<<<iteration:[700/878] - total_loss: 0.7687  obj_loss: 0.2213  noobj_loss: 0.1049  bbox_loss: 0.0539  cls_loss: 0.2253  \n",
      "<<<iteration:[720/878] - total_loss: 0.6071  obj_loss: 0.2336  noobj_loss: 0.1013  bbox_loss: 0.0337  cls_loss: 0.1543  \n",
      "<<<iteration:[740/878] - total_loss: 0.5258  obj_loss: 0.2011  noobj_loss: 0.0943  bbox_loss: 0.0298  cls_loss: 0.1283  \n",
      "<<<iteration:[760/878] - total_loss: 0.6878  obj_loss: 0.2152  noobj_loss: 0.1134  bbox_loss: 0.0471  cls_loss: 0.1805  \n",
      "<<<iteration:[780/878] - total_loss: 0.8253  obj_loss: 0.2237  noobj_loss: 0.1240  bbox_loss: 0.0791  cls_loss: 0.1442  \n",
      "<<<iteration:[800/878] - total_loss: 0.6174  obj_loss: 0.2405  noobj_loss: 0.1185  bbox_loss: 0.0296  cls_loss: 0.1697  \n",
      "<<<iteration:[820/878] - total_loss: 0.6461  obj_loss: 0.2005  noobj_loss: 0.0952  bbox_loss: 0.0267  cls_loss: 0.2647  \n",
      "<<<iteration:[840/878] - total_loss: 0.6455  obj_loss: 0.2024  noobj_loss: 0.1052  bbox_loss: 0.0380  cls_loss: 0.2005  \n",
      "<<<iteration:[860/878] - total_loss: 0.7694  obj_loss: 0.2392  noobj_loss: 0.1054  bbox_loss: 0.0364  cls_loss: 0.2955  \n",
      "\n",
      "epoch:73/100 - Train Loss: 0.6344, Val Loss: 1.1524\n",
      "\n",
      "<<<iteration:[20/878] - total_loss: 0.6331  obj_loss: 0.2261  noobj_loss: 0.1177  bbox_loss: 0.0352  cls_loss: 0.1723  \n",
      "<<<iteration:[40/878] - total_loss: 0.6162  obj_loss: 0.2344  noobj_loss: 0.1082  bbox_loss: 0.0345  cls_loss: 0.1551  \n",
      "<<<iteration:[60/878] - total_loss: 0.5507  obj_loss: 0.1855  noobj_loss: 0.0971  bbox_loss: 0.0312  cls_loss: 0.1606  \n",
      "<<<iteration:[80/878] - total_loss: 0.6140  obj_loss: 0.2063  noobj_loss: 0.1072  bbox_loss: 0.0322  cls_loss: 0.1932  \n",
      "<<<iteration:[100/878] - total_loss: 0.5926  obj_loss: 0.2197  noobj_loss: 0.1128  bbox_loss: 0.0317  cls_loss: 0.1582  \n",
      "<<<iteration:[120/878] - total_loss: 0.6028  obj_loss: 0.2001  noobj_loss: 0.0934  bbox_loss: 0.0300  cls_loss: 0.2059  \n",
      "<<<iteration:[140/878] - total_loss: 0.5818  obj_loss: 0.2562  noobj_loss: 0.1035  bbox_loss: 0.0318  cls_loss: 0.1150  \n",
      "<<<iteration:[160/878] - total_loss: 0.6572  obj_loss: 0.2140  noobj_loss: 0.0980  bbox_loss: 0.0344  cls_loss: 0.2220  \n",
      "<<<iteration:[180/878] - total_loss: 0.5412  obj_loss: 0.2023  noobj_loss: 0.1117  bbox_loss: 0.0279  cls_loss: 0.1435  \n",
      "<<<iteration:[200/878] - total_loss: 0.6322  obj_loss: 0.1936  noobj_loss: 0.1107  bbox_loss: 0.0380  cls_loss: 0.1933  \n",
      "<<<iteration:[220/878] - total_loss: 0.6367  obj_loss: 0.2308  noobj_loss: 0.1101  bbox_loss: 0.0372  cls_loss: 0.1649  \n",
      "<<<iteration:[240/878] - total_loss: 0.6806  obj_loss: 0.2624  noobj_loss: 0.1071  bbox_loss: 0.0327  cls_loss: 0.2010  \n",
      "<<<iteration:[260/878] - total_loss: 0.6140  obj_loss: 0.2299  noobj_loss: 0.1157  bbox_loss: 0.0369  cls_loss: 0.1419  \n",
      "<<<iteration:[280/878] - total_loss: 0.5708  obj_loss: 0.1971  noobj_loss: 0.1099  bbox_loss: 0.0381  cls_loss: 0.1281  \n",
      "<<<iteration:[300/878] - total_loss: 0.6138  obj_loss: 0.2506  noobj_loss: 0.1096  bbox_loss: 0.0272  cls_loss: 0.1721  \n",
      "<<<iteration:[320/878] - total_loss: 0.6856  obj_loss: 0.2108  noobj_loss: 0.1190  bbox_loss: 0.0402  cls_loss: 0.2145  \n",
      "<<<iteration:[340/878] - total_loss: 0.5755  obj_loss: 0.2244  noobj_loss: 0.1040  bbox_loss: 0.0265  cls_loss: 0.1664  \n",
      "<<<iteration:[360/878] - total_loss: 0.6864  obj_loss: 0.2461  noobj_loss: 0.1085  bbox_loss: 0.0315  cls_loss: 0.2283  \n",
      "<<<iteration:[380/878] - total_loss: 0.6022  obj_loss: 0.2202  noobj_loss: 0.1093  bbox_loss: 0.0287  cls_loss: 0.1840  \n",
      "<<<iteration:[400/878] - total_loss: 0.6095  obj_loss: 0.2203  noobj_loss: 0.0998  bbox_loss: 0.0307  cls_loss: 0.1858  \n",
      "<<<iteration:[420/878] - total_loss: 0.5823  obj_loss: 0.2158  noobj_loss: 0.1015  bbox_loss: 0.0287  cls_loss: 0.1723  \n",
      "<<<iteration:[440/878] - total_loss: 0.5644  obj_loss: 0.2351  noobj_loss: 0.1038  bbox_loss: 0.0278  cls_loss: 0.1386  \n",
      "<<<iteration:[460/878] - total_loss: 0.6135  obj_loss: 0.2514  noobj_loss: 0.1317  bbox_loss: 0.0337  cls_loss: 0.1278  \n",
      "<<<iteration:[480/878] - total_loss: 0.7391  obj_loss: 0.2284  noobj_loss: 0.1342  bbox_loss: 0.0412  cls_loss: 0.2376  \n",
      "<<<iteration:[500/878] - total_loss: 0.6035  obj_loss: 0.2331  noobj_loss: 0.1061  bbox_loss: 0.0310  cls_loss: 0.1625  \n",
      "<<<iteration:[520/878] - total_loss: 0.5865  obj_loss: 0.2255  noobj_loss: 0.1336  bbox_loss: 0.0325  cls_loss: 0.1317  \n",
      "<<<iteration:[540/878] - total_loss: 0.5611  obj_loss: 0.1910  noobj_loss: 0.0990  bbox_loss: 0.0255  cls_loss: 0.1930  \n",
      "<<<iteration:[560/878] - total_loss: 0.7244  obj_loss: 0.2855  noobj_loss: 0.1275  bbox_loss: 0.0350  cls_loss: 0.2004  \n",
      "<<<iteration:[580/878] - total_loss: 0.5164  obj_loss: 0.2376  noobj_loss: 0.1151  bbox_loss: 0.0225  cls_loss: 0.1087  \n",
      "<<<iteration:[600/878] - total_loss: 0.6165  obj_loss: 0.2176  noobj_loss: 0.1016  bbox_loss: 0.0326  cls_loss: 0.1852  \n",
      "<<<iteration:[620/878] - total_loss: 0.5235  obj_loss: 0.1940  noobj_loss: 0.1002  bbox_loss: 0.0261  cls_loss: 0.1487  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<<<iteration:[640/878] - total_loss: 0.6156  obj_loss: 0.2088  noobj_loss: 0.0866  bbox_loss: 0.0310  cls_loss: 0.2088  \n",
      "<<<iteration:[660/878] - total_loss: 0.5165  obj_loss: 0.2007  noobj_loss: 0.0888  bbox_loss: 0.0250  cls_loss: 0.1464  \n",
      "<<<iteration:[680/878] - total_loss: 0.6693  obj_loss: 0.2512  noobj_loss: 0.1033  bbox_loss: 0.0307  cls_loss: 0.2128  \n",
      "<<<iteration:[700/878] - total_loss: 0.6160  obj_loss: 0.1757  noobj_loss: 0.1027  bbox_loss: 0.0301  cls_loss: 0.2385  \n",
      "<<<iteration:[720/878] - total_loss: 0.5808  obj_loss: 0.2563  noobj_loss: 0.1015  bbox_loss: 0.0286  cls_loss: 0.1308  \n",
      "<<<iteration:[740/878] - total_loss: 0.7513  obj_loss: 0.2201  noobj_loss: 0.1068  bbox_loss: 0.0523  cls_loss: 0.2165  \n",
      "<<<iteration:[760/878] - total_loss: 0.5501  obj_loss: 0.2080  noobj_loss: 0.1154  bbox_loss: 0.0315  cls_loss: 0.1269  \n",
      "<<<iteration:[780/878] - total_loss: 0.6509  obj_loss: 0.2265  noobj_loss: 0.1114  bbox_loss: 0.0323  cls_loss: 0.2073  \n",
      "<<<iteration:[800/878] - total_loss: 0.7188  obj_loss: 0.2623  noobj_loss: 0.1222  bbox_loss: 0.0352  cls_loss: 0.2195  \n",
      "<<<iteration:[820/878] - total_loss: 0.6396  obj_loss: 0.2183  noobj_loss: 0.1002  bbox_loss: 0.0294  cls_loss: 0.2244  \n",
      "<<<iteration:[840/878] - total_loss: 0.6899  obj_loss: 0.1982  noobj_loss: 0.1346  bbox_loss: 0.0426  cls_loss: 0.2115  \n",
      "<<<iteration:[860/878] - total_loss: 0.5782  obj_loss: 0.2235  noobj_loss: 0.1011  bbox_loss: 0.0320  cls_loss: 0.1442  \n",
      "\n",
      "epoch:74/100 - Train Loss: 0.6159, Val Loss: 1.1542\n",
      "\n",
      "<<<iteration:[20/878] - total_loss: 0.6291  obj_loss: 0.2048  noobj_loss: 0.1126  bbox_loss: 0.0315  cls_loss: 0.2104  \n",
      "<<<iteration:[40/878] - total_loss: 0.7369  obj_loss: 0.2873  noobj_loss: 0.1152  bbox_loss: 0.0390  cls_loss: 0.1968  \n",
      "<<<iteration:[60/878] - total_loss: 0.5209  obj_loss: 0.2317  noobj_loss: 0.1089  bbox_loss: 0.0241  cls_loss: 0.1144  \n",
      "<<<iteration:[80/878] - total_loss: 0.6590  obj_loss: 0.2308  noobj_loss: 0.1209  bbox_loss: 0.0317  cls_loss: 0.2091  \n",
      "<<<iteration:[100/878] - total_loss: 0.7320  obj_loss: 0.2304  noobj_loss: 0.1293  bbox_loss: 0.0349  cls_loss: 0.2624  \n",
      "<<<iteration:[120/878] - total_loss: 0.5434  obj_loss: 0.2119  noobj_loss: 0.1194  bbox_loss: 0.0299  cls_loss: 0.1223  \n",
      "<<<iteration:[140/878] - total_loss: 0.5935  obj_loss: 0.2740  noobj_loss: 0.1123  bbox_loss: 0.0293  cls_loss: 0.1169  \n",
      "<<<iteration:[160/878] - total_loss: 0.6691  obj_loss: 0.2309  noobj_loss: 0.1175  bbox_loss: 0.0352  cls_loss: 0.2034  \n",
      "<<<iteration:[180/878] - total_loss: 0.8503  obj_loss: 0.1826  noobj_loss: 0.1165  bbox_loss: 0.0730  cls_loss: 0.2444  \n",
      "<<<iteration:[200/878] - total_loss: 0.7385  obj_loss: 0.2502  noobj_loss: 0.1141  bbox_loss: 0.0464  cls_loss: 0.1995  \n",
      "<<<iteration:[220/878] - total_loss: 0.5732  obj_loss: 0.2037  noobj_loss: 0.0959  bbox_loss: 0.0320  cls_loss: 0.1616  \n",
      "<<<iteration:[240/878] - total_loss: 0.6545  obj_loss: 0.2623  noobj_loss: 0.1077  bbox_loss: 0.0418  cls_loss: 0.1292  \n",
      "<<<iteration:[260/878] - total_loss: 0.4907  obj_loss: 0.2102  noobj_loss: 0.1050  bbox_loss: 0.0255  cls_loss: 0.1007  \n",
      "<<<iteration:[280/878] - total_loss: 0.5441  obj_loss: 0.2390  noobj_loss: 0.1059  bbox_loss: 0.0236  cls_loss: 0.1340  \n",
      "<<<iteration:[300/878] - total_loss: 0.6500  obj_loss: 0.2234  noobj_loss: 0.1106  bbox_loss: 0.0305  cls_loss: 0.2188  \n",
      "<<<iteration:[320/878] - total_loss: 0.7001  obj_loss: 0.2317  noobj_loss: 0.1023  bbox_loss: 0.0417  cls_loss: 0.2086  \n",
      "<<<iteration:[340/878] - total_loss: 0.5764  obj_loss: 0.2618  noobj_loss: 0.1074  bbox_loss: 0.0274  cls_loss: 0.1240  \n",
      "<<<iteration:[360/878] - total_loss: 0.5603  obj_loss: 0.1914  noobj_loss: 0.1072  bbox_loss: 0.0353  cls_loss: 0.1388  \n",
      "<<<iteration:[380/878] - total_loss: 0.6694  obj_loss: 0.2584  noobj_loss: 0.1098  bbox_loss: 0.0362  cls_loss: 0.1749  \n",
      "<<<iteration:[400/878] - total_loss: 0.5542  obj_loss: 0.2529  noobj_loss: 0.1141  bbox_loss: 0.0269  cls_loss: 0.1097  \n",
      "<<<iteration:[420/878] - total_loss: 0.5224  obj_loss: 0.1643  noobj_loss: 0.1039  bbox_loss: 0.0257  cls_loss: 0.1777  \n",
      "<<<iteration:[440/878] - total_loss: 0.6568  obj_loss: 0.2092  noobj_loss: 0.1084  bbox_loss: 0.0332  cls_loss: 0.2272  \n",
      "<<<iteration:[460/878] - total_loss: 0.6962  obj_loss: 0.2002  noobj_loss: 0.1135  bbox_loss: 0.0381  cls_loss: 0.2487  \n",
      "<<<iteration:[480/878] - total_loss: 0.6917  obj_loss: 0.2246  noobj_loss: 0.1050  bbox_loss: 0.0400  cls_loss: 0.2145  \n",
      "<<<iteration:[500/878] - total_loss: 0.6187  obj_loss: 0.2338  noobj_loss: 0.1041  bbox_loss: 0.0298  cls_loss: 0.1840  \n",
      "<<<iteration:[520/878] - total_loss: 0.7038  obj_loss: 0.2037  noobj_loss: 0.1124  bbox_loss: 0.0335  cls_loss: 0.2762  \n",
      "<<<iteration:[540/878] - total_loss: 0.6501  obj_loss: 0.2359  noobj_loss: 0.1122  bbox_loss: 0.0266  cls_loss: 0.2250  \n",
      "<<<iteration:[560/878] - total_loss: 0.5688  obj_loss: 0.2307  noobj_loss: 0.1200  bbox_loss: 0.0308  cls_loss: 0.1242  \n",
      "<<<iteration:[580/878] - total_loss: 0.5992  obj_loss: 0.1959  noobj_loss: 0.0914  bbox_loss: 0.0330  cls_loss: 0.1929  \n",
      "<<<iteration:[600/878] - total_loss: 0.5674  obj_loss: 0.2177  noobj_loss: 0.0985  bbox_loss: 0.0270  cls_loss: 0.1653  \n",
      "<<<iteration:[620/878] - total_loss: 0.5794  obj_loss: 0.2296  noobj_loss: 0.0993  bbox_loss: 0.0288  cls_loss: 0.1564  \n",
      "<<<iteration:[640/878] - total_loss: 0.5890  obj_loss: 0.2067  noobj_loss: 0.0996  bbox_loss: 0.0303  cls_loss: 0.1809  \n",
      "<<<iteration:[660/878] - total_loss: 0.5813  obj_loss: 0.2105  noobj_loss: 0.1138  bbox_loss: 0.0343  cls_loss: 0.1423  \n",
      "<<<iteration:[680/878] - total_loss: 0.6523  obj_loss: 0.2023  noobj_loss: 0.1063  bbox_loss: 0.0326  cls_loss: 0.2337  \n",
      "<<<iteration:[700/878] - total_loss: 0.5971  obj_loss: 0.2449  noobj_loss: 0.1002  bbox_loss: 0.0284  cls_loss: 0.1602  \n",
      "<<<iteration:[720/878] - total_loss: 0.6262  obj_loss: 0.2253  noobj_loss: 0.1022  bbox_loss: 0.0305  cls_loss: 0.1973  \n",
      "<<<iteration:[740/878] - total_loss: 0.6749  obj_loss: 0.2458  noobj_loss: 0.1106  bbox_loss: 0.0348  cls_loss: 0.1999  \n",
      "<<<iteration:[760/878] - total_loss: 0.5437  obj_loss: 0.2518  noobj_loss: 0.1166  bbox_loss: 0.0288  cls_loss: 0.0894  \n",
      "<<<iteration:[780/878] - total_loss: 0.6585  obj_loss: 0.2159  noobj_loss: 0.1130  bbox_loss: 0.0324  cls_loss: 0.2240  \n",
      "<<<iteration:[800/878] - total_loss: 0.6298  obj_loss: 0.1968  noobj_loss: 0.0999  bbox_loss: 0.0358  cls_loss: 0.2039  \n",
      "<<<iteration:[820/878] - total_loss: 0.6305  obj_loss: 0.2240  noobj_loss: 0.1141  bbox_loss: 0.0394  cls_loss: 0.1524  \n",
      "<<<iteration:[840/878] - total_loss: 0.6598  obj_loss: 0.2392  noobj_loss: 0.0903  bbox_loss: 0.0256  cls_loss: 0.2477  \n",
      "<<<iteration:[860/878] - total_loss: 0.5429  obj_loss: 0.2276  noobj_loss: 0.1156  bbox_loss: 0.0288  cls_loss: 0.1137  \n",
      "\n",
      "epoch:75/100 - Train Loss: 0.6247, Val Loss: 1.1635\n",
      "\n",
      "<<<iteration:[20/878] - total_loss: 0.6411  obj_loss: 0.1583  noobj_loss: 0.1127  bbox_loss: 0.0453  cls_loss: 0.1998  \n",
      "<<<iteration:[40/878] - total_loss: 0.6423  obj_loss: 0.2135  noobj_loss: 0.1029  bbox_loss: 0.0347  cls_loss: 0.2037  \n",
      "<<<iteration:[60/878] - total_loss: 0.6398  obj_loss: 0.2435  noobj_loss: 0.1098  bbox_loss: 0.0263  cls_loss: 0.2097  \n",
      "<<<iteration:[80/878] - total_loss: 0.5769  obj_loss: 0.2279  noobj_loss: 0.0978  bbox_loss: 0.0291  cls_loss: 0.1546  \n",
      "<<<iteration:[100/878] - total_loss: 0.6610  obj_loss: 0.2462  noobj_loss: 0.1068  bbox_loss: 0.0341  cls_loss: 0.1912  \n",
      "<<<iteration:[120/878] - total_loss: 0.6729  obj_loss: 0.1975  noobj_loss: 0.1059  bbox_loss: 0.0375  cls_loss: 0.2352  \n",
      "<<<iteration:[140/878] - total_loss: 0.5864  obj_loss: 0.2373  noobj_loss: 0.1069  bbox_loss: 0.0315  cls_loss: 0.1381  \n",
      "<<<iteration:[160/878] - total_loss: 0.5847  obj_loss: 0.2153  noobj_loss: 0.1009  bbox_loss: 0.0337  cls_loss: 0.1504  \n",
      "<<<iteration:[180/878] - total_loss: 0.5816  obj_loss: 0.2152  noobj_loss: 0.1200  bbox_loss: 0.0285  cls_loss: 0.1636  \n",
      "<<<iteration:[200/878] - total_loss: 0.5794  obj_loss: 0.2247  noobj_loss: 0.1100  bbox_loss: 0.0276  cls_loss: 0.1617  \n",
      "<<<iteration:[220/878] - total_loss: 0.6484  obj_loss: 0.2636  noobj_loss: 0.1039  bbox_loss: 0.0282  cls_loss: 0.1918  \n",
      "<<<iteration:[240/878] - total_loss: 0.5809  obj_loss: 0.2310  noobj_loss: 0.1055  bbox_loss: 0.0277  cls_loss: 0.1588  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<<<iteration:[260/878] - total_loss: 0.5919  obj_loss: 0.2578  noobj_loss: 0.1186  bbox_loss: 0.0277  cls_loss: 0.1362  \n",
      "<<<iteration:[280/878] - total_loss: 0.5273  obj_loss: 0.2320  noobj_loss: 0.1143  bbox_loss: 0.0304  cls_loss: 0.0863  \n",
      "<<<iteration:[300/878] - total_loss: 0.6724  obj_loss: 0.2081  noobj_loss: 0.1096  bbox_loss: 0.0382  cls_loss: 0.2184  \n",
      "<<<iteration:[320/878] - total_loss: 0.6766  obj_loss: 0.2684  noobj_loss: 0.1149  bbox_loss: 0.0311  cls_loss: 0.1953  \n",
      "<<<iteration:[340/878] - total_loss: 0.6135  obj_loss: 0.2511  noobj_loss: 0.1145  bbox_loss: 0.0303  cls_loss: 0.1535  \n",
      "<<<iteration:[360/878] - total_loss: 0.4938  obj_loss: 0.1900  noobj_loss: 0.1024  bbox_loss: 0.0295  cls_loss: 0.1052  \n",
      "<<<iteration:[380/878] - total_loss: 0.6680  obj_loss: 0.2223  noobj_loss: 0.0948  bbox_loss: 0.0304  cls_loss: 0.2463  \n",
      "<<<iteration:[400/878] - total_loss: 0.6268  obj_loss: 0.2342  noobj_loss: 0.1146  bbox_loss: 0.0351  cls_loss: 0.1600  \n",
      "<<<iteration:[420/878] - total_loss: 0.5303  obj_loss: 0.1796  noobj_loss: 0.1071  bbox_loss: 0.0300  cls_loss: 0.1474  \n",
      "<<<iteration:[440/878] - total_loss: 0.6172  obj_loss: 0.2170  noobj_loss: 0.0971  bbox_loss: 0.0303  cls_loss: 0.2003  \n",
      "<<<iteration:[460/878] - total_loss: 0.5580  obj_loss: 0.2472  noobj_loss: 0.0980  bbox_loss: 0.0285  cls_loss: 0.1195  \n",
      "<<<iteration:[480/878] - total_loss: 0.5733  obj_loss: 0.2491  noobj_loss: 0.1211  bbox_loss: 0.0288  cls_loss: 0.1194  \n",
      "<<<iteration:[500/878] - total_loss: 0.5395  obj_loss: 0.1930  noobj_loss: 0.1024  bbox_loss: 0.0235  cls_loss: 0.1778  \n",
      "<<<iteration:[520/878] - total_loss: 0.5619  obj_loss: 0.1864  noobj_loss: 0.1074  bbox_loss: 0.0330  cls_loss: 0.1569  \n",
      "<<<iteration:[540/878] - total_loss: 0.5410  obj_loss: 0.1972  noobj_loss: 0.0949  bbox_loss: 0.0305  cls_loss: 0.1439  \n",
      "<<<iteration:[560/878] - total_loss: 0.6187  obj_loss: 0.2702  noobj_loss: 0.1455  bbox_loss: 0.0284  cls_loss: 0.1339  \n",
      "<<<iteration:[580/878] - total_loss: 0.5942  obj_loss: 0.2546  noobj_loss: 0.1060  bbox_loss: 0.0296  cls_loss: 0.1388  \n",
      "<<<iteration:[600/878] - total_loss: 0.5042  obj_loss: 0.2007  noobj_loss: 0.1084  bbox_loss: 0.0276  cls_loss: 0.1114  \n",
      "<<<iteration:[620/878] - total_loss: 0.6051  obj_loss: 0.2550  noobj_loss: 0.1192  bbox_loss: 0.0332  cls_loss: 0.1245  \n",
      "<<<iteration:[640/878] - total_loss: 0.6502  obj_loss: 0.1994  noobj_loss: 0.1093  bbox_loss: 0.0335  cls_loss: 0.2289  \n",
      "<<<iteration:[660/878] - total_loss: 0.6539  obj_loss: 0.2466  noobj_loss: 0.1137  bbox_loss: 0.0257  cls_loss: 0.2218  \n",
      "<<<iteration:[680/878] - total_loss: 0.5702  obj_loss: 0.2254  noobj_loss: 0.1092  bbox_loss: 0.0276  cls_loss: 0.1524  \n",
      "<<<iteration:[700/878] - total_loss: 0.5088  obj_loss: 0.2147  noobj_loss: 0.1032  bbox_loss: 0.0284  cls_loss: 0.1004  \n",
      "<<<iteration:[720/878] - total_loss: 0.6435  obj_loss: 0.2444  noobj_loss: 0.1190  bbox_loss: 0.0297  cls_loss: 0.1911  \n",
      "<<<iteration:[740/878] - total_loss: 0.5938  obj_loss: 0.2323  noobj_loss: 0.1143  bbox_loss: 0.0245  cls_loss: 0.1817  \n",
      "<<<iteration:[760/878] - total_loss: 0.6727  obj_loss: 0.2381  noobj_loss: 0.1085  bbox_loss: 0.0291  cls_loss: 0.2347  \n",
      "<<<iteration:[780/878] - total_loss: 0.4913  obj_loss: 0.1949  noobj_loss: 0.1188  bbox_loss: 0.0245  cls_loss: 0.1147  \n",
      "<<<iteration:[800/878] - total_loss: 0.5789  obj_loss: 0.2192  noobj_loss: 0.1298  bbox_loss: 0.0319  cls_loss: 0.1352  \n",
      "<<<iteration:[820/878] - total_loss: 0.5827  obj_loss: 0.2112  noobj_loss: 0.1138  bbox_loss: 0.0305  cls_loss: 0.1622  \n",
      "<<<iteration:[840/878] - total_loss: 0.7958  obj_loss: 0.2409  noobj_loss: 0.1060  bbox_loss: 0.0592  cls_loss: 0.2059  \n",
      "<<<iteration:[860/878] - total_loss: 0.5844  obj_loss: 0.2394  noobj_loss: 0.0976  bbox_loss: 0.0302  cls_loss: 0.1451  \n",
      "\n",
      "epoch:76/100 - Train Loss: 0.5996, Val Loss: 1.1253\n",
      "\n",
      "<<<iteration:[20/878] - total_loss: 0.6815  obj_loss: 0.2857  noobj_loss: 0.1288  bbox_loss: 0.0308  cls_loss: 0.1775  \n",
      "<<<iteration:[40/878] - total_loss: 0.4896  obj_loss: 0.1910  noobj_loss: 0.1056  bbox_loss: 0.0273  cls_loss: 0.1092  \n",
      "<<<iteration:[60/878] - total_loss: 0.6472  obj_loss: 0.2491  noobj_loss: 0.1036  bbox_loss: 0.0264  cls_loss: 0.2144  \n",
      "<<<iteration:[80/878] - total_loss: 0.6285  obj_loss: 0.1906  noobj_loss: 0.1215  bbox_loss: 0.0341  cls_loss: 0.2065  \n",
      "<<<iteration:[100/878] - total_loss: 0.5686  obj_loss: 0.2243  noobj_loss: 0.1040  bbox_loss: 0.0239  cls_loss: 0.1726  \n",
      "<<<iteration:[120/878] - total_loss: 0.5279  obj_loss: 0.2039  noobj_loss: 0.1218  bbox_loss: 0.0286  cls_loss: 0.1201  \n",
      "<<<iteration:[140/878] - total_loss: 0.4764  obj_loss: 0.2094  noobj_loss: 0.1067  bbox_loss: 0.0252  cls_loss: 0.0874  \n",
      "<<<iteration:[160/878] - total_loss: 0.5521  obj_loss: 0.2167  noobj_loss: 0.1046  bbox_loss: 0.0343  cls_loss: 0.1117  \n",
      "<<<iteration:[180/878] - total_loss: 0.7594  obj_loss: 0.2630  noobj_loss: 0.1084  bbox_loss: 0.0546  cls_loss: 0.1690  \n",
      "<<<iteration:[200/878] - total_loss: 0.8108  obj_loss: 0.2135  noobj_loss: 0.0975  bbox_loss: 0.0703  cls_loss: 0.1970  \n",
      "<<<iteration:[220/878] - total_loss: 0.6309  obj_loss: 0.2837  noobj_loss: 0.1219  bbox_loss: 0.0324  cls_loss: 0.1242  \n",
      "<<<iteration:[240/878] - total_loss: 1.2292  obj_loss: 0.1771  noobj_loss: 0.1361  bbox_loss: 0.1606  cls_loss: 0.1812  \n",
      "<<<iteration:[260/878] - total_loss: 0.7621  obj_loss: 0.2447  noobj_loss: 0.1132  bbox_loss: 0.0496  cls_loss: 0.2129  \n",
      "<<<iteration:[280/878] - total_loss: 0.6487  obj_loss: 0.2347  noobj_loss: 0.1261  bbox_loss: 0.0467  cls_loss: 0.1176  \n",
      "<<<iteration:[300/878] - total_loss: 0.7732  obj_loss: 0.2429  noobj_loss: 0.1031  bbox_loss: 0.0698  cls_loss: 0.1295  \n",
      "<<<iteration:[320/878] - total_loss: 0.6567  obj_loss: 0.2148  noobj_loss: 0.1135  bbox_loss: 0.0474  cls_loss: 0.1481  \n",
      "<<<iteration:[340/878] - total_loss: 0.9712  obj_loss: 0.1987  noobj_loss: 0.1146  bbox_loss: 0.1049  cls_loss: 0.1906  \n",
      "<<<iteration:[360/878] - total_loss: 0.5706  obj_loss: 0.1814  noobj_loss: 0.0959  bbox_loss: 0.0316  cls_loss: 0.1834  \n",
      "<<<iteration:[380/878] - total_loss: 0.5850  obj_loss: 0.2541  noobj_loss: 0.1114  bbox_loss: 0.0315  cls_loss: 0.1179  \n",
      "<<<iteration:[400/878] - total_loss: 0.6509  obj_loss: 0.2788  noobj_loss: 0.1263  bbox_loss: 0.0298  cls_loss: 0.1600  \n",
      "<<<iteration:[420/878] - total_loss: 0.6410  obj_loss: 0.2103  noobj_loss: 0.1243  bbox_loss: 0.0384  cls_loss: 0.1764  \n",
      "<<<iteration:[440/878] - total_loss: 0.6405  obj_loss: 0.2014  noobj_loss: 0.1089  bbox_loss: 0.0314  cls_loss: 0.2277  \n",
      "<<<iteration:[460/878] - total_loss: 0.5882  obj_loss: 0.2220  noobj_loss: 0.1047  bbox_loss: 0.0342  cls_loss: 0.1426  \n",
      "<<<iteration:[480/878] - total_loss: 0.6507  obj_loss: 0.2365  noobj_loss: 0.1113  bbox_loss: 0.0306  cls_loss: 0.2055  \n",
      "<<<iteration:[500/878] - total_loss: 0.5542  obj_loss: 0.2508  noobj_loss: 0.1187  bbox_loss: 0.0246  cls_loss: 0.1211  \n",
      "<<<iteration:[520/878] - total_loss: 0.5597  obj_loss: 0.1709  noobj_loss: 0.1054  bbox_loss: 0.0297  cls_loss: 0.1874  \n",
      "<<<iteration:[540/878] - total_loss: 0.5662  obj_loss: 0.2143  noobj_loss: 0.0996  bbox_loss: 0.0287  cls_loss: 0.1588  \n",
      "<<<iteration:[560/878] - total_loss: 0.7756  obj_loss: 0.2480  noobj_loss: 0.1215  bbox_loss: 0.0464  cls_loss: 0.2349  \n",
      "<<<iteration:[580/878] - total_loss: 0.5563  obj_loss: 0.1882  noobj_loss: 0.0988  bbox_loss: 0.0326  cls_loss: 0.1555  \n",
      "<<<iteration:[600/878] - total_loss: 0.7760  obj_loss: 0.2552  noobj_loss: 0.1029  bbox_loss: 0.0432  cls_loss: 0.2531  \n",
      "<<<iteration:[620/878] - total_loss: 0.7035  obj_loss: 0.2321  noobj_loss: 0.1213  bbox_loss: 0.0346  cls_loss: 0.2380  \n",
      "<<<iteration:[640/878] - total_loss: 0.6159  obj_loss: 0.2350  noobj_loss: 0.1193  bbox_loss: 0.0313  cls_loss: 0.1646  \n",
      "<<<iteration:[660/878] - total_loss: 0.4827  obj_loss: 0.1819  noobj_loss: 0.1078  bbox_loss: 0.0269  cls_loss: 0.1124  \n",
      "<<<iteration:[680/878] - total_loss: 0.5745  obj_loss: 0.2268  noobj_loss: 0.1082  bbox_loss: 0.0312  cls_loss: 0.1377  \n",
      "<<<iteration:[700/878] - total_loss: 0.6350  obj_loss: 0.2213  noobj_loss: 0.1201  bbox_loss: 0.0308  cls_loss: 0.1995  \n",
      "<<<iteration:[720/878] - total_loss: 0.5294  obj_loss: 0.1846  noobj_loss: 0.1091  bbox_loss: 0.0278  cls_loss: 0.1513  \n",
      "<<<iteration:[740/878] - total_loss: 0.6188  obj_loss: 0.2458  noobj_loss: 0.0994  bbox_loss: 0.0309  cls_loss: 0.1689  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<<<iteration:[760/878] - total_loss: 0.6411  obj_loss: 0.2091  noobj_loss: 0.1041  bbox_loss: 0.0261  cls_loss: 0.2496  \n",
      "<<<iteration:[780/878] - total_loss: 0.6028  obj_loss: 0.2074  noobj_loss: 0.1146  bbox_loss: 0.0329  cls_loss: 0.1734  \n",
      "<<<iteration:[800/878] - total_loss: 0.6123  obj_loss: 0.2338  noobj_loss: 0.1149  bbox_loss: 0.0313  cls_loss: 0.1648  \n",
      "<<<iteration:[820/878] - total_loss: 0.5991  obj_loss: 0.2409  noobj_loss: 0.0949  bbox_loss: 0.0280  cls_loss: 0.1708  \n",
      "<<<iteration:[840/878] - total_loss: 0.5805  obj_loss: 0.2484  noobj_loss: 0.1249  bbox_loss: 0.0262  cls_loss: 0.1387  \n",
      "<<<iteration:[860/878] - total_loss: 0.6399  obj_loss: 0.2173  noobj_loss: 0.1208  bbox_loss: 0.0351  cls_loss: 0.1868  \n",
      "\n",
      "epoch:77/100 - Train Loss: 0.6441, Val Loss: 1.1702\n",
      "\n",
      "<<<iteration:[20/878] - total_loss: 0.5819  obj_loss: 0.2513  noobj_loss: 0.1186  bbox_loss: 0.0303  cls_loss: 0.1199  \n",
      "<<<iteration:[40/878] - total_loss: 0.5851  obj_loss: 0.2473  noobj_loss: 0.1245  bbox_loss: 0.0248  cls_loss: 0.1516  \n",
      "<<<iteration:[60/878] - total_loss: 0.5968  obj_loss: 0.2682  noobj_loss: 0.1142  bbox_loss: 0.0287  cls_loss: 0.1281  \n",
      "<<<iteration:[80/878] - total_loss: 0.6410  obj_loss: 0.2310  noobj_loss: 0.1045  bbox_loss: 0.0274  cls_loss: 0.2208  \n",
      "<<<iteration:[100/878] - total_loss: 0.5529  obj_loss: 0.2046  noobj_loss: 0.1000  bbox_loss: 0.0282  cls_loss: 0.1575  \n",
      "<<<iteration:[120/878] - total_loss: 0.5702  obj_loss: 0.2158  noobj_loss: 0.0965  bbox_loss: 0.0313  cls_loss: 0.1498  \n",
      "<<<iteration:[140/878] - total_loss: 0.5749  obj_loss: 0.2342  noobj_loss: 0.1185  bbox_loss: 0.0289  cls_loss: 0.1370  \n",
      "<<<iteration:[160/878] - total_loss: 0.5549  obj_loss: 0.2323  noobj_loss: 0.1183  bbox_loss: 0.0250  cls_loss: 0.1385  \n",
      "<<<iteration:[180/878] - total_loss: 0.6216  obj_loss: 0.2548  noobj_loss: 0.1197  bbox_loss: 0.0271  cls_loss: 0.1715  \n",
      "<<<iteration:[200/878] - total_loss: 0.5642  obj_loss: 0.2178  noobj_loss: 0.1120  bbox_loss: 0.0315  cls_loss: 0.1327  \n",
      "<<<iteration:[220/878] - total_loss: 0.5712  obj_loss: 0.2421  noobj_loss: 0.1186  bbox_loss: 0.0291  cls_loss: 0.1244  \n",
      "<<<iteration:[240/878] - total_loss: 0.6326  obj_loss: 0.2095  noobj_loss: 0.1095  bbox_loss: 0.0310  cls_loss: 0.2134  \n",
      "<<<iteration:[260/878] - total_loss: 0.6555  obj_loss: 0.2282  noobj_loss: 0.1034  bbox_loss: 0.0354  cls_loss: 0.1988  \n",
      "<<<iteration:[280/878] - total_loss: 0.5984  obj_loss: 0.1869  noobj_loss: 0.1037  bbox_loss: 0.0371  cls_loss: 0.1739  \n",
      "<<<iteration:[300/878] - total_loss: 0.6557  obj_loss: 0.2286  noobj_loss: 0.1025  bbox_loss: 0.0369  cls_loss: 0.1915  \n",
      "<<<iteration:[320/878] - total_loss: 0.8862  obj_loss: 0.2056  noobj_loss: 0.1082  bbox_loss: 0.1003  cls_loss: 0.1250  \n",
      "<<<iteration:[340/878] - total_loss: 0.5713  obj_loss: 0.2258  noobj_loss: 0.1052  bbox_loss: 0.0278  cls_loss: 0.1538  \n",
      "<<<iteration:[360/878] - total_loss: 0.5730  obj_loss: 0.2395  noobj_loss: 0.1029  bbox_loss: 0.0245  cls_loss: 0.1596  \n",
      "<<<iteration:[380/878] - total_loss: 0.5721  obj_loss: 0.2482  noobj_loss: 0.1183  bbox_loss: 0.0251  cls_loss: 0.1395  \n",
      "<<<iteration:[400/878] - total_loss: 0.7724  obj_loss: 0.2785  noobj_loss: 0.1324  bbox_loss: 0.0379  cls_loss: 0.2379  \n",
      "<<<iteration:[420/878] - total_loss: 0.6443  obj_loss: 0.2070  noobj_loss: 0.1023  bbox_loss: 0.0285  cls_loss: 0.2435  \n",
      "<<<iteration:[440/878] - total_loss: 0.5813  obj_loss: 0.1940  noobj_loss: 0.1058  bbox_loss: 0.0356  cls_loss: 0.1562  \n",
      "<<<iteration:[460/878] - total_loss: 0.5182  obj_loss: 0.2305  noobj_loss: 0.0990  bbox_loss: 0.0256  cls_loss: 0.1103  \n",
      "<<<iteration:[480/878] - total_loss: 0.6441  obj_loss: 0.2845  noobj_loss: 0.1314  bbox_loss: 0.0288  cls_loss: 0.1498  \n",
      "<<<iteration:[500/878] - total_loss: 0.5597  obj_loss: 0.2230  noobj_loss: 0.1102  bbox_loss: 0.0279  cls_loss: 0.1419  \n",
      "<<<iteration:[520/878] - total_loss: 0.6026  obj_loss: 0.2383  noobj_loss: 0.1159  bbox_loss: 0.0241  cls_loss: 0.1860  \n",
      "<<<iteration:[540/878] - total_loss: 0.5792  obj_loss: 0.2077  noobj_loss: 0.1239  bbox_loss: 0.0300  cls_loss: 0.1596  \n",
      "<<<iteration:[560/878] - total_loss: 0.5540  obj_loss: 0.2243  noobj_loss: 0.1072  bbox_loss: 0.0319  cls_loss: 0.1166  \n",
      "<<<iteration:[580/878] - total_loss: 0.5607  obj_loss: 0.2128  noobj_loss: 0.1153  bbox_loss: 0.0290  cls_loss: 0.1454  \n",
      "<<<iteration:[600/878] - total_loss: 0.5571  obj_loss: 0.2430  noobj_loss: 0.1130  bbox_loss: 0.0272  cls_loss: 0.1218  \n",
      "<<<iteration:[620/878] - total_loss: 0.6181  obj_loss: 0.2361  noobj_loss: 0.1131  bbox_loss: 0.0346  cls_loss: 0.1523  \n",
      "<<<iteration:[640/878] - total_loss: 0.6038  obj_loss: 0.2359  noobj_loss: 0.1085  bbox_loss: 0.0285  cls_loss: 0.1712  \n",
      "<<<iteration:[660/878] - total_loss: 0.6822  obj_loss: 0.2519  noobj_loss: 0.1276  bbox_loss: 0.0345  cls_loss: 0.1939  \n",
      "<<<iteration:[680/878] - total_loss: 0.5573  obj_loss: 0.2395  noobj_loss: 0.1251  bbox_loss: 0.0276  cls_loss: 0.1172  \n",
      "<<<iteration:[700/878] - total_loss: 0.5786  obj_loss: 0.2319  noobj_loss: 0.1094  bbox_loss: 0.0291  cls_loss: 0.1464  \n",
      "<<<iteration:[720/878] - total_loss: 0.6510  obj_loss: 0.2704  noobj_loss: 0.1222  bbox_loss: 0.0353  cls_loss: 0.1430  \n",
      "<<<iteration:[740/878] - total_loss: 0.6047  obj_loss: 0.2445  noobj_loss: 0.1314  bbox_loss: 0.0327  cls_loss: 0.1313  \n",
      "<<<iteration:[760/878] - total_loss: 0.5597  obj_loss: 0.2239  noobj_loss: 0.1100  bbox_loss: 0.0290  cls_loss: 0.1357  \n",
      "<<<iteration:[780/878] - total_loss: 0.5879  obj_loss: 0.2167  noobj_loss: 0.1083  bbox_loss: 0.0280  cls_loss: 0.1770  \n",
      "<<<iteration:[800/878] - total_loss: 0.6574  obj_loss: 0.2179  noobj_loss: 0.1182  bbox_loss: 0.0366  cls_loss: 0.1976  \n",
      "<<<iteration:[820/878] - total_loss: 0.5766  obj_loss: 0.2194  noobj_loss: 0.1163  bbox_loss: 0.0290  cls_loss: 0.1543  \n",
      "<<<iteration:[840/878] - total_loss: 0.5425  obj_loss: 0.2123  noobj_loss: 0.1098  bbox_loss: 0.0277  cls_loss: 0.1367  \n",
      "<<<iteration:[860/878] - total_loss: 0.6013  obj_loss: 0.2489  noobj_loss: 0.1131  bbox_loss: 0.0297  cls_loss: 0.1475  \n",
      "\n",
      "epoch:78/100 - Train Loss: 0.6014, Val Loss: 1.1406\n",
      "\n",
      "<<<iteration:[20/878] - total_loss: 0.6148  obj_loss: 0.2137  noobj_loss: 0.1145  bbox_loss: 0.0286  cls_loss: 0.2009  \n",
      "<<<iteration:[40/878] - total_loss: 0.6463  obj_loss: 0.2646  noobj_loss: 0.1129  bbox_loss: 0.0300  cls_loss: 0.1750  \n",
      "<<<iteration:[60/878] - total_loss: 0.6260  obj_loss: 0.2725  noobj_loss: 0.1200  bbox_loss: 0.0315  cls_loss: 0.1360  \n",
      "<<<iteration:[80/878] - total_loss: 0.5482  obj_loss: 0.2142  noobj_loss: 0.1362  bbox_loss: 0.0307  cls_loss: 0.1121  \n",
      "<<<iteration:[100/878] - total_loss: 0.5707  obj_loss: 0.2292  noobj_loss: 0.1055  bbox_loss: 0.0298  cls_loss: 0.1399  \n",
      "<<<iteration:[120/878] - total_loss: 0.5654  obj_loss: 0.2345  noobj_loss: 0.1093  bbox_loss: 0.0307  cls_loss: 0.1226  \n",
      "<<<iteration:[140/878] - total_loss: 0.5459  obj_loss: 0.2147  noobj_loss: 0.1262  bbox_loss: 0.0313  cls_loss: 0.1116  \n",
      "<<<iteration:[160/878] - total_loss: 0.5068  obj_loss: 0.2062  noobj_loss: 0.1226  bbox_loss: 0.0280  cls_loss: 0.0992  \n",
      "<<<iteration:[180/878] - total_loss: 0.5442  obj_loss: 0.2067  noobj_loss: 0.1083  bbox_loss: 0.0301  cls_loss: 0.1329  \n",
      "<<<iteration:[200/878] - total_loss: 1.0067  obj_loss: 0.2277  noobj_loss: 0.1292  bbox_loss: 0.1066  cls_loss: 0.1815  \n",
      "<<<iteration:[220/878] - total_loss: 0.5482  obj_loss: 0.2156  noobj_loss: 0.1147  bbox_loss: 0.0275  cls_loss: 0.1377  \n",
      "<<<iteration:[240/878] - total_loss: 0.6856  obj_loss: 0.2083  noobj_loss: 0.1073  bbox_loss: 0.0454  cls_loss: 0.1965  \n",
      "<<<iteration:[260/878] - total_loss: 0.6047  obj_loss: 0.2027  noobj_loss: 0.1079  bbox_loss: 0.0362  cls_loss: 0.1673  \n",
      "<<<iteration:[280/878] - total_loss: 0.5774  obj_loss: 0.2182  noobj_loss: 0.1183  bbox_loss: 0.0284  cls_loss: 0.1579  \n",
      "<<<iteration:[300/878] - total_loss: 0.5685  obj_loss: 0.2556  noobj_loss: 0.1059  bbox_loss: 0.0304  cls_loss: 0.1078  \n",
      "<<<iteration:[320/878] - total_loss: 0.6295  obj_loss: 0.2080  noobj_loss: 0.1173  bbox_loss: 0.0336  cls_loss: 0.1951  \n",
      "<<<iteration:[340/878] - total_loss: 0.5413  obj_loss: 0.2299  noobj_loss: 0.1137  bbox_loss: 0.0239  cls_loss: 0.1351  \n",
      "<<<iteration:[360/878] - total_loss: 0.6002  obj_loss: 0.2266  noobj_loss: 0.1205  bbox_loss: 0.0304  cls_loss: 0.1614  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<<<iteration:[380/878] - total_loss: 0.5834  obj_loss: 0.2219  noobj_loss: 0.0981  bbox_loss: 0.0308  cls_loss: 0.1582  \n",
      "<<<iteration:[400/878] - total_loss: 0.5382  obj_loss: 0.2405  noobj_loss: 0.1081  bbox_loss: 0.0246  cls_loss: 0.1204  \n",
      "<<<iteration:[420/878] - total_loss: 0.5344  obj_loss: 0.2011  noobj_loss: 0.1024  bbox_loss: 0.0274  cls_loss: 0.1450  \n",
      "<<<iteration:[440/878] - total_loss: 0.5632  obj_loss: 0.2515  noobj_loss: 0.1111  bbox_loss: 0.0265  cls_loss: 0.1236  \n",
      "<<<iteration:[460/878] - total_loss: 0.6027  obj_loss: 0.2220  noobj_loss: 0.1086  bbox_loss: 0.0278  cls_loss: 0.1875  \n",
      "<<<iteration:[480/878] - total_loss: 0.6761  obj_loss: 0.2435  noobj_loss: 0.1105  bbox_loss: 0.0272  cls_loss: 0.2414  \n",
      "<<<iteration:[500/878] - total_loss: 0.5915  obj_loss: 0.2271  noobj_loss: 0.1035  bbox_loss: 0.0323  cls_loss: 0.1513  \n",
      "<<<iteration:[520/878] - total_loss: 0.6970  obj_loss: 0.2226  noobj_loss: 0.1130  bbox_loss: 0.0283  cls_loss: 0.2765  \n",
      "<<<iteration:[540/878] - total_loss: 0.6266  obj_loss: 0.2775  noobj_loss: 0.1215  bbox_loss: 0.0311  cls_loss: 0.1329  \n",
      "<<<iteration:[560/878] - total_loss: 0.5471  obj_loss: 0.2435  noobj_loss: 0.1033  bbox_loss: 0.0286  cls_loss: 0.1088  \n",
      "<<<iteration:[580/878] - total_loss: 0.5805  obj_loss: 0.2058  noobj_loss: 0.1086  bbox_loss: 0.0280  cls_loss: 0.1804  \n",
      "<<<iteration:[600/878] - total_loss: 0.5202  obj_loss: 0.2222  noobj_loss: 0.1033  bbox_loss: 0.0257  cls_loss: 0.1177  \n",
      "<<<iteration:[620/878] - total_loss: 0.5884  obj_loss: 0.2625  noobj_loss: 0.1317  bbox_loss: 0.0243  cls_loss: 0.1383  \n",
      "<<<iteration:[640/878] - total_loss: 0.5456  obj_loss: 0.1930  noobj_loss: 0.1299  bbox_loss: 0.0290  cls_loss: 0.1425  \n",
      "<<<iteration:[660/878] - total_loss: 0.4891  obj_loss: 0.2135  noobj_loss: 0.1007  bbox_loss: 0.0238  cls_loss: 0.1064  \n",
      "<<<iteration:[680/878] - total_loss: 0.5201  obj_loss: 0.2081  noobj_loss: 0.1180  bbox_loss: 0.0265  cls_loss: 0.1206  \n",
      "<<<iteration:[700/878] - total_loss: 0.6661  obj_loss: 0.2389  noobj_loss: 0.1275  bbox_loss: 0.0296  cls_loss: 0.2152  \n",
      "<<<iteration:[720/878] - total_loss: 0.6055  obj_loss: 0.1970  noobj_loss: 0.1013  bbox_loss: 0.0274  cls_loss: 0.2207  \n",
      "<<<iteration:[740/878] - total_loss: 0.5841  obj_loss: 0.2311  noobj_loss: 0.1039  bbox_loss: 0.0277  cls_loss: 0.1625  \n",
      "<<<iteration:[760/878] - total_loss: 0.6269  obj_loss: 0.2450  noobj_loss: 0.1133  bbox_loss: 0.0355  cls_loss: 0.1478  \n",
      "<<<iteration:[780/878] - total_loss: 0.6212  obj_loss: 0.2306  noobj_loss: 0.1064  bbox_loss: 0.0275  cls_loss: 0.1998  \n",
      "<<<iteration:[800/878] - total_loss: 0.6258  obj_loss: 0.2137  noobj_loss: 0.1111  bbox_loss: 0.0284  cls_loss: 0.2145  \n",
      "<<<iteration:[820/878] - total_loss: 0.5244  obj_loss: 0.2210  noobj_loss: 0.1181  bbox_loss: 0.0292  cls_loss: 0.0986  \n",
      "<<<iteration:[840/878] - total_loss: 0.5871  obj_loss: 0.2667  noobj_loss: 0.1134  bbox_loss: 0.0289  cls_loss: 0.1194  \n",
      "<<<iteration:[860/878] - total_loss: 0.5710  obj_loss: 0.2362  noobj_loss: 0.1227  bbox_loss: 0.0259  cls_loss: 0.1441  \n",
      "\n",
      "epoch:79/100 - Train Loss: 0.5921, Val Loss: 1.1335\n",
      "\n",
      "<<<iteration:[20/878] - total_loss: 0.6199  obj_loss: 0.2538  noobj_loss: 0.1427  bbox_loss: 0.0346  cls_loss: 0.1220  \n",
      "<<<iteration:[40/878] - total_loss: 0.5880  obj_loss: 0.1682  noobj_loss: 0.1034  bbox_loss: 0.0321  cls_loss: 0.2078  \n",
      "<<<iteration:[60/878] - total_loss: 0.5396  obj_loss: 0.2269  noobj_loss: 0.1064  bbox_loss: 0.0269  cls_loss: 0.1250  \n",
      "<<<iteration:[80/878] - total_loss: 0.6268  obj_loss: 0.2314  noobj_loss: 0.1059  bbox_loss: 0.0301  cls_loss: 0.1920  \n",
      "<<<iteration:[100/878] - total_loss: 0.6545  obj_loss: 0.2595  noobj_loss: 0.1260  bbox_loss: 0.0345  cls_loss: 0.1594  \n",
      "<<<iteration:[120/878] - total_loss: 0.6610  obj_loss: 0.2502  noobj_loss: 0.1115  bbox_loss: 0.0249  cls_loss: 0.2307  \n",
      "<<<iteration:[140/878] - total_loss: 0.7538  obj_loss: 0.2105  noobj_loss: 0.1276  bbox_loss: 0.0458  cls_loss: 0.2508  \n",
      "<<<iteration:[160/878] - total_loss: 0.6073  obj_loss: 0.2621  noobj_loss: 0.1254  bbox_loss: 0.0245  cls_loss: 0.1602  \n",
      "<<<iteration:[180/878] - total_loss: 0.5519  obj_loss: 0.1927  noobj_loss: 0.1339  bbox_loss: 0.0322  cls_loss: 0.1314  \n",
      "<<<iteration:[200/878] - total_loss: 0.6515  obj_loss: 0.2412  noobj_loss: 0.1084  bbox_loss: 0.0308  cls_loss: 0.2020  \n",
      "<<<iteration:[220/878] - total_loss: 0.5626  obj_loss: 0.2386  noobj_loss: 0.1153  bbox_loss: 0.0268  cls_loss: 0.1325  \n",
      "<<<iteration:[240/878] - total_loss: 0.5744  obj_loss: 0.2316  noobj_loss: 0.0994  bbox_loss: 0.0204  cls_loss: 0.1910  \n",
      "<<<iteration:[260/878] - total_loss: 0.4948  obj_loss: 0.2490  noobj_loss: 0.1253  bbox_loss: 0.0245  cls_loss: 0.0606  \n",
      "<<<iteration:[280/878] - total_loss: 0.6267  obj_loss: 0.2112  noobj_loss: 0.1144  bbox_loss: 0.0289  cls_loss: 0.2139  \n",
      "<<<iteration:[300/878] - total_loss: 0.6161  obj_loss: 0.2580  noobj_loss: 0.1106  bbox_loss: 0.0299  cls_loss: 0.1531  \n",
      "<<<iteration:[320/878] - total_loss: 0.5238  obj_loss: 0.1988  noobj_loss: 0.1045  bbox_loss: 0.0269  cls_loss: 0.1384  \n",
      "<<<iteration:[340/878] - total_loss: 0.5758  obj_loss: 0.2219  noobj_loss: 0.1254  bbox_loss: 0.0347  cls_loss: 0.1178  \n",
      "<<<iteration:[360/878] - total_loss: 0.6208  obj_loss: 0.1923  noobj_loss: 0.1095  bbox_loss: 0.0297  cls_loss: 0.2254  \n",
      "<<<iteration:[380/878] - total_loss: 0.6429  obj_loss: 0.2236  noobj_loss: 0.1103  bbox_loss: 0.0378  cls_loss: 0.1753  \n",
      "<<<iteration:[400/878] - total_loss: 0.5857  obj_loss: 0.2226  noobj_loss: 0.1047  bbox_loss: 0.0283  cls_loss: 0.1695  \n",
      "<<<iteration:[420/878] - total_loss: 0.4544  obj_loss: 0.2050  noobj_loss: 0.1090  bbox_loss: 0.0251  cls_loss: 0.0695  \n",
      "<<<iteration:[440/878] - total_loss: 0.6311  obj_loss: 0.2646  noobj_loss: 0.1212  bbox_loss: 0.0286  cls_loss: 0.1627  \n",
      "<<<iteration:[460/878] - total_loss: 0.5958  obj_loss: 0.2335  noobj_loss: 0.1129  bbox_loss: 0.0219  cls_loss: 0.1964  \n",
      "<<<iteration:[480/878] - total_loss: 0.5465  obj_loss: 0.2136  noobj_loss: 0.1054  bbox_loss: 0.0291  cls_loss: 0.1347  \n",
      "<<<iteration:[500/878] - total_loss: 0.6353  obj_loss: 0.2426  noobj_loss: 0.1109  bbox_loss: 0.0329  cls_loss: 0.1730  \n",
      "<<<iteration:[520/878] - total_loss: 0.5711  obj_loss: 0.2473  noobj_loss: 0.1299  bbox_loss: 0.0228  cls_loss: 0.1449  \n",
      "<<<iteration:[540/878] - total_loss: 0.5752  obj_loss: 0.2497  noobj_loss: 0.1062  bbox_loss: 0.0220  cls_loss: 0.1625  \n",
      "<<<iteration:[560/878] - total_loss: 0.5833  obj_loss: 0.2075  noobj_loss: 0.1092  bbox_loss: 0.0282  cls_loss: 0.1802  \n",
      "<<<iteration:[580/878] - total_loss: 0.6589  obj_loss: 0.2329  noobj_loss: 0.1272  bbox_loss: 0.0277  cls_loss: 0.2240  \n",
      "<<<iteration:[600/878] - total_loss: 0.5500  obj_loss: 0.2325  noobj_loss: 0.1043  bbox_loss: 0.0248  cls_loss: 0.1412  \n",
      "<<<iteration:[620/878] - total_loss: 0.6433  obj_loss: 0.2638  noobj_loss: 0.1250  bbox_loss: 0.0306  cls_loss: 0.1642  \n",
      "<<<iteration:[640/878] - total_loss: 0.5871  obj_loss: 0.2370  noobj_loss: 0.1267  bbox_loss: 0.0283  cls_loss: 0.1454  \n",
      "<<<iteration:[660/878] - total_loss: 0.5756  obj_loss: 0.2601  noobj_loss: 0.1345  bbox_loss: 0.0298  cls_loss: 0.0993  \n",
      "<<<iteration:[680/878] - total_loss: 0.5440  obj_loss: 0.2459  noobj_loss: 0.1269  bbox_loss: 0.0231  cls_loss: 0.1192  \n",
      "<<<iteration:[700/878] - total_loss: 0.7027  obj_loss: 0.2193  noobj_loss: 0.1142  bbox_loss: 0.0298  cls_loss: 0.2775  \n",
      "<<<iteration:[720/878] - total_loss: 0.6426  obj_loss: 0.2172  noobj_loss: 0.1094  bbox_loss: 0.0488  cls_loss: 0.1266  \n",
      "<<<iteration:[740/878] - total_loss: 0.5949  obj_loss: 0.2657  noobj_loss: 0.1184  bbox_loss: 0.0289  cls_loss: 0.1253  \n",
      "<<<iteration:[760/878] - total_loss: 0.5335  obj_loss: 0.2377  noobj_loss: 0.1044  bbox_loss: 0.0280  cls_loss: 0.1037  \n",
      "<<<iteration:[780/878] - total_loss: 0.5312  obj_loss: 0.2185  noobj_loss: 0.1120  bbox_loss: 0.0283  cls_loss: 0.1152  \n",
      "<<<iteration:[800/878] - total_loss: 0.5416  obj_loss: 0.2226  noobj_loss: 0.1302  bbox_loss: 0.0257  cls_loss: 0.1254  \n",
      "<<<iteration:[820/878] - total_loss: 0.6920  obj_loss: 0.2874  noobj_loss: 0.1181  bbox_loss: 0.0306  cls_loss: 0.1925  \n",
      "<<<iteration:[840/878] - total_loss: 0.5579  obj_loss: 0.2348  noobj_loss: 0.1124  bbox_loss: 0.0283  cls_loss: 0.1252  \n",
      "<<<iteration:[860/878] - total_loss: 0.6459  obj_loss: 0.2510  noobj_loss: 0.1175  bbox_loss: 0.0297  cls_loss: 0.1876  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "epoch:80/100 - Train Loss: 0.5966, Val Loss: 1.1478\n",
      "\n",
      "<<<iteration:[20/878] - total_loss: 0.5978  obj_loss: 0.2793  noobj_loss: 0.1245  bbox_loss: 0.0312  cls_loss: 0.0999  \n",
      "<<<iteration:[40/878] - total_loss: 0.5722  obj_loss: 0.2362  noobj_loss: 0.1267  bbox_loss: 0.0287  cls_loss: 0.1292  \n",
      "<<<iteration:[60/878] - total_loss: 0.5721  obj_loss: 0.2369  noobj_loss: 0.1128  bbox_loss: 0.0274  cls_loss: 0.1417  \n",
      "<<<iteration:[80/878] - total_loss: 0.5564  obj_loss: 0.2281  noobj_loss: 0.1235  bbox_loss: 0.0256  cls_loss: 0.1386  \n",
      "<<<iteration:[100/878] - total_loss: 0.5819  obj_loss: 0.2126  noobj_loss: 0.1126  bbox_loss: 0.0254  cls_loss: 0.1861  \n",
      "<<<iteration:[120/878] - total_loss: 0.5247  obj_loss: 0.1972  noobj_loss: 0.1002  bbox_loss: 0.0274  cls_loss: 0.1403  \n",
      "<<<iteration:[140/878] - total_loss: 0.5571  obj_loss: 0.2635  noobj_loss: 0.1079  bbox_loss: 0.0273  cls_loss: 0.1032  \n",
      "<<<iteration:[160/878] - total_loss: 0.5709  obj_loss: 0.2531  noobj_loss: 0.1402  bbox_loss: 0.0270  cls_loss: 0.1129  \n",
      "<<<iteration:[180/878] - total_loss: 0.5563  obj_loss: 0.2705  noobj_loss: 0.1221  bbox_loss: 0.0234  cls_loss: 0.1076  \n",
      "<<<iteration:[200/878] - total_loss: 0.5504  obj_loss: 0.2080  noobj_loss: 0.1255  bbox_loss: 0.0229  cls_loss: 0.1651  \n",
      "<<<iteration:[220/878] - total_loss: 0.6075  obj_loss: 0.1799  noobj_loss: 0.1272  bbox_loss: 0.0450  cls_loss: 0.1389  \n",
      "<<<iteration:[240/878] - total_loss: 0.5901  obj_loss: 0.2194  noobj_loss: 0.1125  bbox_loss: 0.0318  cls_loss: 0.1552  \n",
      "<<<iteration:[260/878] - total_loss: 0.7006  obj_loss: 0.2311  noobj_loss: 0.1135  bbox_loss: 0.0390  cls_loss: 0.2180  \n",
      "<<<iteration:[280/878] - total_loss: 0.6143  obj_loss: 0.2055  noobj_loss: 0.1174  bbox_loss: 0.0277  cls_loss: 0.2113  \n",
      "<<<iteration:[300/878] - total_loss: 0.5495  obj_loss: 0.2417  noobj_loss: 0.1235  bbox_loss: 0.0277  cls_loss: 0.1076  \n",
      "<<<iteration:[320/878] - total_loss: 0.5024  obj_loss: 0.2387  noobj_loss: 0.1148  bbox_loss: 0.0233  cls_loss: 0.0900  \n",
      "<<<iteration:[340/878] - total_loss: 0.6184  obj_loss: 0.2343  noobj_loss: 0.1110  bbox_loss: 0.0266  cls_loss: 0.1953  \n",
      "<<<iteration:[360/878] - total_loss: 0.5476  obj_loss: 0.2348  noobj_loss: 0.1304  bbox_loss: 0.0303  cls_loss: 0.0962  \n",
      "<<<iteration:[380/878] - total_loss: 0.5961  obj_loss: 0.2215  noobj_loss: 0.1167  bbox_loss: 0.0294  cls_loss: 0.1690  \n",
      "<<<iteration:[400/878] - total_loss: 0.6659  obj_loss: 0.2137  noobj_loss: 0.1147  bbox_loss: 0.0315  cls_loss: 0.2373  \n",
      "<<<iteration:[420/878] - total_loss: 0.6188  obj_loss: 0.2370  noobj_loss: 0.1077  bbox_loss: 0.0340  cls_loss: 0.1579  \n",
      "<<<iteration:[440/878] - total_loss: 0.5951  obj_loss: 0.2038  noobj_loss: 0.1206  bbox_loss: 0.0323  cls_loss: 0.1695  \n",
      "<<<iteration:[460/878] - total_loss: 0.5386  obj_loss: 0.1877  noobj_loss: 0.1035  bbox_loss: 0.0260  cls_loss: 0.1692  \n",
      "<<<iteration:[480/878] - total_loss: 0.6949  obj_loss: 0.2637  noobj_loss: 0.1142  bbox_loss: 0.0362  cls_loss: 0.1932  \n",
      "<<<iteration:[500/878] - total_loss: 0.5890  obj_loss: 0.2259  noobj_loss: 0.1267  bbox_loss: 0.0322  cls_loss: 0.1389  \n",
      "<<<iteration:[520/878] - total_loss: 0.6841  obj_loss: 0.2623  noobj_loss: 0.1235  bbox_loss: 0.0481  cls_loss: 0.1196  \n",
      "<<<iteration:[540/878] - total_loss: 0.6612  obj_loss: 0.2412  noobj_loss: 0.1265  bbox_loss: 0.0252  cls_loss: 0.2310  \n",
      "<<<iteration:[560/878] - total_loss: 0.7111  obj_loss: 0.2547  noobj_loss: 0.1077  bbox_loss: 0.0431  cls_loss: 0.1869  \n",
      "<<<iteration:[580/878] - total_loss: 0.5345  obj_loss: 0.2255  noobj_loss: 0.0981  bbox_loss: 0.0273  cls_loss: 0.1232  \n",
      "<<<iteration:[600/878] - total_loss: 0.5534  obj_loss: 0.1959  noobj_loss: 0.1048  bbox_loss: 0.0256  cls_loss: 0.1772  \n",
      "<<<iteration:[620/878] - total_loss: 0.6105  obj_loss: 0.2546  noobj_loss: 0.1134  bbox_loss: 0.0251  cls_loss: 0.1739  \n",
      "<<<iteration:[640/878] - total_loss: 0.6198  obj_loss: 0.2290  noobj_loss: 0.1181  bbox_loss: 0.0299  cls_loss: 0.1821  \n",
      "<<<iteration:[660/878] - total_loss: 0.6144  obj_loss: 0.2132  noobj_loss: 0.1303  bbox_loss: 0.0348  cls_loss: 0.1624  \n",
      "<<<iteration:[680/878] - total_loss: 0.5802  obj_loss: 0.2055  noobj_loss: 0.1117  bbox_loss: 0.0295  cls_loss: 0.1714  \n",
      "<<<iteration:[700/878] - total_loss: 0.5832  obj_loss: 0.2672  noobj_loss: 0.1383  bbox_loss: 0.0247  cls_loss: 0.1231  \n",
      "<<<iteration:[720/878] - total_loss: 0.5420  obj_loss: 0.2444  noobj_loss: 0.1147  bbox_loss: 0.0265  cls_loss: 0.1079  \n",
      "<<<iteration:[740/878] - total_loss: 0.5979  obj_loss: 0.2518  noobj_loss: 0.1179  bbox_loss: 0.0287  cls_loss: 0.1435  \n",
      "<<<iteration:[760/878] - total_loss: 0.5611  obj_loss: 0.2255  noobj_loss: 0.1184  bbox_loss: 0.0309  cls_loss: 0.1219  \n",
      "<<<iteration:[780/878] - total_loss: 0.5822  obj_loss: 0.1920  noobj_loss: 0.0997  bbox_loss: 0.0310  cls_loss: 0.1853  \n",
      "<<<iteration:[800/878] - total_loss: 0.4942  obj_loss: 0.2209  noobj_loss: 0.1220  bbox_loss: 0.0257  cls_loss: 0.0841  \n",
      "<<<iteration:[820/878] - total_loss: 0.5750  obj_loss: 0.2411  noobj_loss: 0.1177  bbox_loss: 0.0331  cls_loss: 0.1097  \n",
      "<<<iteration:[840/878] - total_loss: 0.5610  obj_loss: 0.2377  noobj_loss: 0.1166  bbox_loss: 0.0341  cls_loss: 0.0945  \n",
      "<<<iteration:[860/878] - total_loss: 0.5851  obj_loss: 0.2056  noobj_loss: 0.1184  bbox_loss: 0.0260  cls_loss: 0.1904  \n",
      "\n",
      "epoch:81/100 - Train Loss: 0.5860, Val Loss: 1.1494\n",
      "\n",
      "<<<iteration:[20/878] - total_loss: 0.5658  obj_loss: 0.2280  noobj_loss: 0.1154  bbox_loss: 0.0315  cls_loss: 0.1226  \n",
      "<<<iteration:[40/878] - total_loss: 0.5264  obj_loss: 0.2095  noobj_loss: 0.1089  bbox_loss: 0.0286  cls_loss: 0.1192  \n",
      "<<<iteration:[60/878] - total_loss: 0.6059  obj_loss: 0.2301  noobj_loss: 0.1051  bbox_loss: 0.0326  cls_loss: 0.1600  \n",
      "<<<iteration:[80/878] - total_loss: 0.6211  obj_loss: 0.2698  noobj_loss: 0.1326  bbox_loss: 0.0321  cls_loss: 0.1243  \n",
      "<<<iteration:[100/878] - total_loss: 0.4728  obj_loss: 0.2262  noobj_loss: 0.1138  bbox_loss: 0.0252  cls_loss: 0.0634  \n",
      "<<<iteration:[120/878] - total_loss: 0.5284  obj_loss: 0.2246  noobj_loss: 0.1248  bbox_loss: 0.0283  cls_loss: 0.0999  \n",
      "<<<iteration:[140/878] - total_loss: 0.5854  obj_loss: 0.2366  noobj_loss: 0.1253  bbox_loss: 0.0273  cls_loss: 0.1497  \n",
      "<<<iteration:[160/878] - total_loss: 0.5984  obj_loss: 0.2757  noobj_loss: 0.1325  bbox_loss: 0.0257  cls_loss: 0.1278  \n",
      "<<<iteration:[180/878] - total_loss: 0.6017  obj_loss: 0.2300  noobj_loss: 0.1225  bbox_loss: 0.0254  cls_loss: 0.1836  \n",
      "<<<iteration:[200/878] - total_loss: 0.5089  obj_loss: 0.2477  noobj_loss: 0.1241  bbox_loss: 0.0247  cls_loss: 0.0758  \n",
      "<<<iteration:[220/878] - total_loss: 0.4632  obj_loss: 0.1777  noobj_loss: 0.1147  bbox_loss: 0.0268  cls_loss: 0.0940  \n",
      "<<<iteration:[240/878] - total_loss: 0.5636  obj_loss: 0.2333  noobj_loss: 0.1169  bbox_loss: 0.0224  cls_loss: 0.1597  \n",
      "<<<iteration:[260/878] - total_loss: 0.5926  obj_loss: 0.2462  noobj_loss: 0.1242  bbox_loss: 0.0276  cls_loss: 0.1463  \n",
      "<<<iteration:[280/878] - total_loss: 0.6068  obj_loss: 0.2110  noobj_loss: 0.1312  bbox_loss: 0.0244  cls_loss: 0.2083  \n",
      "<<<iteration:[300/878] - total_loss: 0.5681  obj_loss: 0.2137  noobj_loss: 0.1181  bbox_loss: 0.0274  cls_loss: 0.1584  \n",
      "<<<iteration:[320/878] - total_loss: 0.6671  obj_loss: 0.2347  noobj_loss: 0.1120  bbox_loss: 0.0278  cls_loss: 0.2375  \n",
      "<<<iteration:[340/878] - total_loss: 0.5627  obj_loss: 0.2337  noobj_loss: 0.1187  bbox_loss: 0.0258  cls_loss: 0.1406  \n",
      "<<<iteration:[360/878] - total_loss: 0.6412  obj_loss: 0.2292  noobj_loss: 0.0995  bbox_loss: 0.0238  cls_loss: 0.2434  \n",
      "<<<iteration:[380/878] - total_loss: 0.6398  obj_loss: 0.2553  noobj_loss: 0.1265  bbox_loss: 0.0293  cls_loss: 0.1748  \n",
      "<<<iteration:[400/878] - total_loss: 0.5190  obj_loss: 0.2369  noobj_loss: 0.1114  bbox_loss: 0.0264  cls_loss: 0.0942  \n",
      "<<<iteration:[420/878] - total_loss: 0.6171  obj_loss: 0.2501  noobj_loss: 0.1157  bbox_loss: 0.0277  cls_loss: 0.1707  \n",
      "<<<iteration:[440/878] - total_loss: 0.6360  obj_loss: 0.2045  noobj_loss: 0.1361  bbox_loss: 0.0399  cls_loss: 0.1639  \n",
      "<<<iteration:[460/878] - total_loss: 0.5993  obj_loss: 0.2167  noobj_loss: 0.1065  bbox_loss: 0.0347  cls_loss: 0.1560  \n",
      "<<<iteration:[480/878] - total_loss: 0.6118  obj_loss: 0.2094  noobj_loss: 0.1282  bbox_loss: 0.0330  cls_loss: 0.1732  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<<<iteration:[500/878] - total_loss: 0.6481  obj_loss: 0.2635  noobj_loss: 0.1398  bbox_loss: 0.0344  cls_loss: 0.1430  \n",
      "<<<iteration:[520/878] - total_loss: 0.5197  obj_loss: 0.2058  noobj_loss: 0.1251  bbox_loss: 0.0313  cls_loss: 0.0951  \n",
      "<<<iteration:[540/878] - total_loss: 0.5619  obj_loss: 0.2339  noobj_loss: 0.1036  bbox_loss: 0.0304  cls_loss: 0.1239  \n",
      "<<<iteration:[560/878] - total_loss: 0.5027  obj_loss: 0.2409  noobj_loss: 0.1097  bbox_loss: 0.0266  cls_loss: 0.0741  \n",
      "<<<iteration:[580/878] - total_loss: 0.5616  obj_loss: 0.2267  noobj_loss: 0.1192  bbox_loss: 0.0281  cls_loss: 0.1348  \n",
      "<<<iteration:[600/878] - total_loss: 0.5407  obj_loss: 0.2051  noobj_loss: 0.1077  bbox_loss: 0.0236  cls_loss: 0.1639  \n",
      "<<<iteration:[620/878] - total_loss: 0.6615  obj_loss: 0.2050  noobj_loss: 0.1164  bbox_loss: 0.0457  cls_loss: 0.1697  \n",
      "<<<iteration:[640/878] - total_loss: 0.6331  obj_loss: 0.2583  noobj_loss: 0.1365  bbox_loss: 0.0284  cls_loss: 0.1646  \n",
      "<<<iteration:[660/878] - total_loss: 0.5092  obj_loss: 0.2389  noobj_loss: 0.1380  bbox_loss: 0.0223  cls_loss: 0.0897  \n",
      "<<<iteration:[680/878] - total_loss: 0.5327  obj_loss: 0.2207  noobj_loss: 0.1170  bbox_loss: 0.0278  cls_loss: 0.1147  \n",
      "<<<iteration:[700/878] - total_loss: 0.6056  obj_loss: 0.2369  noobj_loss: 0.1145  bbox_loss: 0.0348  cls_loss: 0.1375  \n",
      "<<<iteration:[720/878] - total_loss: 0.6392  obj_loss: 0.2381  noobj_loss: 0.1214  bbox_loss: 0.0436  cls_loss: 0.1223  \n",
      "<<<iteration:[740/878] - total_loss: 0.6340  obj_loss: 0.2041  noobj_loss: 0.1154  bbox_loss: 0.0327  cls_loss: 0.2085  \n",
      "<<<iteration:[760/878] - total_loss: 0.5041  obj_loss: 0.2227  noobj_loss: 0.1112  bbox_loss: 0.0279  cls_loss: 0.0863  \n",
      "<<<iteration:[780/878] - total_loss: 0.5675  obj_loss: 0.2705  noobj_loss: 0.1176  bbox_loss: 0.0268  cls_loss: 0.1041  \n",
      "<<<iteration:[800/878] - total_loss: 0.5580  obj_loss: 0.2302  noobj_loss: 0.1186  bbox_loss: 0.0291  cls_loss: 0.1229  \n",
      "<<<iteration:[820/878] - total_loss: 0.5299  obj_loss: 0.2030  noobj_loss: 0.1092  bbox_loss: 0.0274  cls_loss: 0.1351  \n",
      "<<<iteration:[840/878] - total_loss: 0.5416  obj_loss: 0.2277  noobj_loss: 0.1176  bbox_loss: 0.0238  cls_loss: 0.1361  \n",
      "<<<iteration:[860/878] - total_loss: 0.6046  obj_loss: 0.2223  noobj_loss: 0.1059  bbox_loss: 0.0253  cls_loss: 0.2029  \n",
      "\n",
      "epoch:82/100 - Train Loss: 0.5747, Val Loss: 1.1314\n",
      "\n",
      "<<<iteration:[20/878] - total_loss: 0.6516  obj_loss: 0.2744  noobj_loss: 0.1290  bbox_loss: 0.0338  cls_loss: 0.1434  \n",
      "<<<iteration:[40/878] - total_loss: 0.5300  obj_loss: 0.2046  noobj_loss: 0.1027  bbox_loss: 0.0269  cls_loss: 0.1396  \n",
      "<<<iteration:[60/878] - total_loss: 0.5905  obj_loss: 0.2227  noobj_loss: 0.1130  bbox_loss: 0.0302  cls_loss: 0.1602  \n",
      "<<<iteration:[80/878] - total_loss: 0.5979  obj_loss: 0.2239  noobj_loss: 0.1111  bbox_loss: 0.0301  cls_loss: 0.1681  \n",
      "<<<iteration:[100/878] - total_loss: 0.5188  obj_loss: 0.2154  noobj_loss: 0.1168  bbox_loss: 0.0225  cls_loss: 0.1327  \n",
      "<<<iteration:[120/878] - total_loss: 0.5935  obj_loss: 0.2614  noobj_loss: 0.1303  bbox_loss: 0.0291  cls_loss: 0.1214  \n",
      "<<<iteration:[140/878] - total_loss: 0.5486  obj_loss: 0.2028  noobj_loss: 0.1147  bbox_loss: 0.0384  cls_loss: 0.0967  \n",
      "<<<iteration:[160/878] - total_loss: 0.5809  obj_loss: 0.2662  noobj_loss: 0.1176  bbox_loss: 0.0272  cls_loss: 0.1199  \n",
      "<<<iteration:[180/878] - total_loss: 0.5364  obj_loss: 0.2265  noobj_loss: 0.1203  bbox_loss: 0.0269  cls_loss: 0.1151  \n",
      "<<<iteration:[200/878] - total_loss: 0.4781  obj_loss: 0.2036  noobj_loss: 0.1124  bbox_loss: 0.0303  cls_loss: 0.0670  \n",
      "<<<iteration:[220/878] - total_loss: 0.5354  obj_loss: 0.2135  noobj_loss: 0.1015  bbox_loss: 0.0241  cls_loss: 0.1506  \n",
      "<<<iteration:[240/878] - total_loss: 0.6193  obj_loss: 0.2762  noobj_loss: 0.1311  bbox_loss: 0.0296  cls_loss: 0.1295  \n",
      "<<<iteration:[260/878] - total_loss: 0.6212  obj_loss: 0.2351  noobj_loss: 0.1213  bbox_loss: 0.0223  cls_loss: 0.2140  \n",
      "<<<iteration:[280/878] - total_loss: 0.4635  obj_loss: 0.1801  noobj_loss: 0.1227  bbox_loss: 0.0250  cls_loss: 0.0971  \n",
      "<<<iteration:[300/878] - total_loss: 0.7976  obj_loss: 0.2207  noobj_loss: 0.1501  bbox_loss: 0.0433  cls_loss: 0.2855  \n",
      "<<<iteration:[320/878] - total_loss: 0.5063  obj_loss: 0.2307  noobj_loss: 0.1183  bbox_loss: 0.0253  cls_loss: 0.0899  \n",
      "<<<iteration:[340/878] - total_loss: 0.4991  obj_loss: 0.2239  noobj_loss: 0.1180  bbox_loss: 0.0236  cls_loss: 0.0980  \n",
      "<<<iteration:[360/878] - total_loss: 0.5559  obj_loss: 0.2355  noobj_loss: 0.1141  bbox_loss: 0.0283  cls_loss: 0.1220  \n",
      "<<<iteration:[380/878] - total_loss: 0.5287  obj_loss: 0.1916  noobj_loss: 0.1236  bbox_loss: 0.0265  cls_loss: 0.1428  \n",
      "<<<iteration:[400/878] - total_loss: 0.5455  obj_loss: 0.1881  noobj_loss: 0.1109  bbox_loss: 0.0276  cls_loss: 0.1641  \n",
      "<<<iteration:[420/878] - total_loss: 0.4983  obj_loss: 0.1951  noobj_loss: 0.1040  bbox_loss: 0.0304  cls_loss: 0.0991  \n",
      "<<<iteration:[440/878] - total_loss: 0.5214  obj_loss: 0.2102  noobj_loss: 0.1016  bbox_loss: 0.0246  cls_loss: 0.1374  \n",
      "<<<iteration:[460/878] - total_loss: 0.5341  obj_loss: 0.2350  noobj_loss: 0.1118  bbox_loss: 0.0234  cls_loss: 0.1260  \n",
      "<<<iteration:[480/878] - total_loss: 0.5876  obj_loss: 0.2611  noobj_loss: 0.1229  bbox_loss: 0.0291  cls_loss: 0.1193  \n",
      "<<<iteration:[500/878] - total_loss: 0.5689  obj_loss: 0.2330  noobj_loss: 0.1247  bbox_loss: 0.0236  cls_loss: 0.1555  \n",
      "<<<iteration:[520/878] - total_loss: 0.5468  obj_loss: 0.2085  noobj_loss: 0.1245  bbox_loss: 0.0230  cls_loss: 0.1609  \n",
      "<<<iteration:[540/878] - total_loss: 0.5949  obj_loss: 0.2896  noobj_loss: 0.1275  bbox_loss: 0.0284  cls_loss: 0.0996  \n",
      "<<<iteration:[560/878] - total_loss: 0.6290  obj_loss: 0.3080  noobj_loss: 0.1237  bbox_loss: 0.0228  cls_loss: 0.1451  \n",
      "<<<iteration:[580/878] - total_loss: 0.5556  obj_loss: 0.2394  noobj_loss: 0.1057  bbox_loss: 0.0243  cls_loss: 0.1420  \n",
      "<<<iteration:[600/878] - total_loss: 0.6398  obj_loss: 0.2260  noobj_loss: 0.1211  bbox_loss: 0.0262  cls_loss: 0.2222  \n",
      "<<<iteration:[620/878] - total_loss: 0.7278  obj_loss: 0.2480  noobj_loss: 0.1235  bbox_loss: 0.0397  cls_loss: 0.2195  \n",
      "<<<iteration:[640/878] - total_loss: 0.5791  obj_loss: 0.2465  noobj_loss: 0.1495  bbox_loss: 0.0305  cls_loss: 0.1051  \n",
      "<<<iteration:[660/878] - total_loss: 0.5887  obj_loss: 0.2459  noobj_loss: 0.1240  bbox_loss: 0.0317  cls_loss: 0.1224  \n",
      "<<<iteration:[680/878] - total_loss: 0.7094  obj_loss: 0.2506  noobj_loss: 0.1215  bbox_loss: 0.0457  cls_loss: 0.1698  \n",
      "<<<iteration:[700/878] - total_loss: 0.5872  obj_loss: 0.2668  noobj_loss: 0.1252  bbox_loss: 0.0338  cls_loss: 0.0889  \n",
      "<<<iteration:[720/878] - total_loss: 0.6728  obj_loss: 0.2363  noobj_loss: 0.1381  bbox_loss: 0.0459  cls_loss: 0.1380  \n",
      "<<<iteration:[740/878] - total_loss: 0.6023  obj_loss: 0.2515  noobj_loss: 0.1179  bbox_loss: 0.0292  cls_loss: 0.1458  \n",
      "<<<iteration:[760/878] - total_loss: 0.6401  obj_loss: 0.2464  noobj_loss: 0.1335  bbox_loss: 0.0281  cls_loss: 0.1864  \n",
      "<<<iteration:[780/878] - total_loss: 0.6211  obj_loss: 0.2146  noobj_loss: 0.1381  bbox_loss: 0.0319  cls_loss: 0.1780  \n",
      "<<<iteration:[800/878] - total_loss: 0.6022  obj_loss: 0.2411  noobj_loss: 0.1220  bbox_loss: 0.0361  cls_loss: 0.1195  \n",
      "<<<iteration:[820/878] - total_loss: 0.6131  obj_loss: 0.2332  noobj_loss: 0.1186  bbox_loss: 0.0287  cls_loss: 0.1770  \n",
      "<<<iteration:[840/878] - total_loss: 0.5536  obj_loss: 0.2326  noobj_loss: 0.1168  bbox_loss: 0.0298  cls_loss: 0.1136  \n",
      "<<<iteration:[860/878] - total_loss: 0.5529  obj_loss: 0.2498  noobj_loss: 0.1172  bbox_loss: 0.0258  cls_loss: 0.1157  \n",
      "\n",
      "epoch:83/100 - Train Loss: 0.5802, Val Loss: 1.1486\n",
      "\n",
      "<<<iteration:[20/878] - total_loss: 0.5475  obj_loss: 0.2191  noobj_loss: 0.1266  bbox_loss: 0.0272  cls_loss: 0.1293  \n",
      "<<<iteration:[40/878] - total_loss: 0.5597  obj_loss: 0.2162  noobj_loss: 0.1139  bbox_loss: 0.0250  cls_loss: 0.1615  \n",
      "<<<iteration:[60/878] - total_loss: 0.5279  obj_loss: 0.2433  noobj_loss: 0.1185  bbox_loss: 0.0233  cls_loss: 0.1088  \n",
      "<<<iteration:[80/878] - total_loss: 0.5660  obj_loss: 0.2412  noobj_loss: 0.1312  bbox_loss: 0.0323  cls_loss: 0.0976  \n",
      "<<<iteration:[100/878] - total_loss: 0.4629  obj_loss: 0.2253  noobj_loss: 0.1153  bbox_loss: 0.0243  cls_loss: 0.0585  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<<<iteration:[120/878] - total_loss: 0.5676  obj_loss: 0.2450  noobj_loss: 0.1140  bbox_loss: 0.0283  cls_loss: 0.1243  \n",
      "<<<iteration:[140/878] - total_loss: 0.5276  obj_loss: 0.1938  noobj_loss: 0.1029  bbox_loss: 0.0281  cls_loss: 0.1421  \n",
      "<<<iteration:[160/878] - total_loss: 0.5813  obj_loss: 0.2626  noobj_loss: 0.1084  bbox_loss: 0.0230  cls_loss: 0.1497  \n",
      "<<<iteration:[180/878] - total_loss: 0.5353  obj_loss: 0.2027  noobj_loss: 0.0984  bbox_loss: 0.0327  cls_loss: 0.1202  \n",
      "<<<iteration:[200/878] - total_loss: 0.6001  obj_loss: 0.2562  noobj_loss: 0.1147  bbox_loss: 0.0254  cls_loss: 0.1593  \n",
      "<<<iteration:[220/878] - total_loss: 0.6444  obj_loss: 0.2245  noobj_loss: 0.1268  bbox_loss: 0.0322  cls_loss: 0.1954  \n",
      "<<<iteration:[240/878] - total_loss: 0.6608  obj_loss: 0.2654  noobj_loss: 0.1264  bbox_loss: 0.0312  cls_loss: 0.1761  \n",
      "<<<iteration:[260/878] - total_loss: 0.4962  obj_loss: 0.2090  noobj_loss: 0.1202  bbox_loss: 0.0288  cls_loss: 0.0832  \n",
      "<<<iteration:[280/878] - total_loss: 0.5339  obj_loss: 0.2779  noobj_loss: 0.1105  bbox_loss: 0.0240  cls_loss: 0.0807  \n",
      "<<<iteration:[300/878] - total_loss: 0.5227  obj_loss: 0.1886  noobj_loss: 0.1061  bbox_loss: 0.0256  cls_loss: 0.1531  \n",
      "<<<iteration:[320/878] - total_loss: 0.6890  obj_loss: 0.2867  noobj_loss: 0.1311  bbox_loss: 0.0291  cls_loss: 0.1911  \n",
      "<<<iteration:[340/878] - total_loss: 0.5554  obj_loss: 0.2405  noobj_loss: 0.1332  bbox_loss: 0.0259  cls_loss: 0.1188  \n",
      "<<<iteration:[360/878] - total_loss: 0.6657  obj_loss: 0.2609  noobj_loss: 0.1184  bbox_loss: 0.0298  cls_loss: 0.1967  \n",
      "<<<iteration:[380/878] - total_loss: 0.5490  obj_loss: 0.1922  noobj_loss: 0.1120  bbox_loss: 0.0307  cls_loss: 0.1473  \n",
      "<<<iteration:[400/878] - total_loss: 0.5715  obj_loss: 0.2571  noobj_loss: 0.1346  bbox_loss: 0.0275  cls_loss: 0.1096  \n",
      "<<<iteration:[420/878] - total_loss: 0.7058  obj_loss: 0.2796  noobj_loss: 0.1317  bbox_loss: 0.0267  cls_loss: 0.2267  \n",
      "<<<iteration:[440/878] - total_loss: 0.6186  obj_loss: 0.2291  noobj_loss: 0.1237  bbox_loss: 0.0327  cls_loss: 0.1641  \n",
      "<<<iteration:[460/878] - total_loss: 0.4733  obj_loss: 0.2120  noobj_loss: 0.1235  bbox_loss: 0.0228  cls_loss: 0.0857  \n",
      "<<<iteration:[480/878] - total_loss: 0.5541  obj_loss: 0.2196  noobj_loss: 0.1057  bbox_loss: 0.0266  cls_loss: 0.1484  \n",
      "<<<iteration:[500/878] - total_loss: 0.6175  obj_loss: 0.2638  noobj_loss: 0.1237  bbox_loss: 0.0330  cls_loss: 0.1270  \n",
      "<<<iteration:[520/878] - total_loss: 0.5838  obj_loss: 0.2458  noobj_loss: 0.1386  bbox_loss: 0.0246  cls_loss: 0.1456  \n",
      "<<<iteration:[540/878] - total_loss: 0.5499  obj_loss: 0.2560  noobj_loss: 0.1210  bbox_loss: 0.0233  cls_loss: 0.1169  \n",
      "<<<iteration:[560/878] - total_loss: 0.5455  obj_loss: 0.2075  noobj_loss: 0.1227  bbox_loss: 0.0271  cls_loss: 0.1409  \n",
      "<<<iteration:[580/878] - total_loss: 0.5216  obj_loss: 0.2250  noobj_loss: 0.1259  bbox_loss: 0.0228  cls_loss: 0.1195  \n",
      "<<<iteration:[600/878] - total_loss: 0.6904  obj_loss: 0.2826  noobj_loss: 0.1413  bbox_loss: 0.0272  cls_loss: 0.2011  \n",
      "<<<iteration:[620/878] - total_loss: 0.6204  obj_loss: 0.2386  noobj_loss: 0.1146  bbox_loss: 0.0282  cls_loss: 0.1837  \n",
      "<<<iteration:[640/878] - total_loss: 0.5928  obj_loss: 0.2516  noobj_loss: 0.1283  bbox_loss: 0.0208  cls_loss: 0.1730  \n",
      "<<<iteration:[660/878] - total_loss: 0.5600  obj_loss: 0.1881  noobj_loss: 0.1104  bbox_loss: 0.0226  cls_loss: 0.2039  \n",
      "<<<iteration:[680/878] - total_loss: 0.5206  obj_loss: 0.2419  noobj_loss: 0.1251  bbox_loss: 0.0254  cls_loss: 0.0893  \n",
      "<<<iteration:[700/878] - total_loss: 0.5782  obj_loss: 0.2389  noobj_loss: 0.1228  bbox_loss: 0.0237  cls_loss: 0.1596  \n",
      "<<<iteration:[720/878] - total_loss: 0.4858  obj_loss: 0.2286  noobj_loss: 0.1090  bbox_loss: 0.0227  cls_loss: 0.0890  \n",
      "<<<iteration:[740/878] - total_loss: 0.5326  obj_loss: 0.2243  noobj_loss: 0.1254  bbox_loss: 0.0288  cls_loss: 0.1016  \n",
      "<<<iteration:[760/878] - total_loss: 0.5640  obj_loss: 0.2550  noobj_loss: 0.1346  bbox_loss: 0.0243  cls_loss: 0.1200  \n",
      "<<<iteration:[780/878] - total_loss: 0.5242  obj_loss: 0.2114  noobj_loss: 0.1184  bbox_loss: 0.0257  cls_loss: 0.1252  \n",
      "<<<iteration:[800/878] - total_loss: 0.5851  obj_loss: 0.2443  noobj_loss: 0.1106  bbox_loss: 0.0265  cls_loss: 0.1530  \n",
      "<<<iteration:[820/878] - total_loss: 0.5718  obj_loss: 0.2260  noobj_loss: 0.1278  bbox_loss: 0.0255  cls_loss: 0.1546  \n",
      "<<<iteration:[840/878] - total_loss: 0.4556  obj_loss: 0.1823  noobj_loss: 0.1125  bbox_loss: 0.0256  cls_loss: 0.0891  \n",
      "<<<iteration:[860/878] - total_loss: 0.6116  obj_loss: 0.2026  noobj_loss: 0.1140  bbox_loss: 0.0281  cls_loss: 0.2114  \n",
      "\n",
      "epoch:84/100 - Train Loss: 0.5678, Val Loss: 1.3344\n",
      "\n",
      "<<<iteration:[20/878] - total_loss: 0.5562  obj_loss: 0.2625  noobj_loss: 0.1269  bbox_loss: 0.0245  cls_loss: 0.1077  \n",
      "<<<iteration:[40/878] - total_loss: 0.6234  obj_loss: 0.2794  noobj_loss: 0.1382  bbox_loss: 0.0268  cls_loss: 0.1412  \n",
      "<<<iteration:[60/878] - total_loss: 0.5846  obj_loss: 0.2702  noobj_loss: 0.1311  bbox_loss: 0.0253  cls_loss: 0.1222  \n",
      "<<<iteration:[80/878] - total_loss: 0.6245  obj_loss: 0.2411  noobj_loss: 0.1347  bbox_loss: 0.0288  cls_loss: 0.1718  \n",
      "<<<iteration:[100/878] - total_loss: 0.6059  obj_loss: 0.2383  noobj_loss: 0.1270  bbox_loss: 0.0248  cls_loss: 0.1800  \n",
      "<<<iteration:[120/878] - total_loss: 0.5238  obj_loss: 0.2399  noobj_loss: 0.1071  bbox_loss: 0.0216  cls_loss: 0.1221  \n",
      "<<<iteration:[140/878] - total_loss: 0.5274  obj_loss: 0.2292  noobj_loss: 0.1281  bbox_loss: 0.0269  cls_loss: 0.0995  \n",
      "<<<iteration:[160/878] - total_loss: 0.5497  obj_loss: 0.2068  noobj_loss: 0.1276  bbox_loss: 0.0285  cls_loss: 0.1363  \n",
      "<<<iteration:[180/878] - total_loss: 0.5786  obj_loss: 0.2378  noobj_loss: 0.1245  bbox_loss: 0.0324  cls_loss: 0.1164  \n",
      "<<<iteration:[200/878] - total_loss: 0.6921  obj_loss: 0.2097  noobj_loss: 0.1198  bbox_loss: 0.0506  cls_loss: 0.1693  \n",
      "<<<iteration:[220/878] - total_loss: 0.4975  obj_loss: 0.2008  noobj_loss: 0.1016  bbox_loss: 0.0217  cls_loss: 0.1374  \n",
      "<<<iteration:[240/878] - total_loss: 0.5652  obj_loss: 0.2601  noobj_loss: 0.1188  bbox_loss: 0.0287  cls_loss: 0.1022  \n",
      "<<<iteration:[260/878] - total_loss: 0.5340  obj_loss: 0.1965  noobj_loss: 0.1107  bbox_loss: 0.0261  cls_loss: 0.1514  \n",
      "<<<iteration:[280/878] - total_loss: 0.5286  obj_loss: 0.2180  noobj_loss: 0.1134  bbox_loss: 0.0240  cls_loss: 0.1341  \n",
      "<<<iteration:[300/878] - total_loss: 0.7293  obj_loss: 0.2440  noobj_loss: 0.1318  bbox_loss: 0.0439  cls_loss: 0.1998  \n",
      "<<<iteration:[320/878] - total_loss: 0.5771  obj_loss: 0.2115  noobj_loss: 0.1228  bbox_loss: 0.0380  cls_loss: 0.1143  \n",
      "<<<iteration:[340/878] - total_loss: 0.5180  obj_loss: 0.2359  noobj_loss: 0.1229  bbox_loss: 0.0271  cls_loss: 0.0850  \n",
      "<<<iteration:[360/878] - total_loss: 0.6025  obj_loss: 0.2452  noobj_loss: 0.1100  bbox_loss: 0.0303  cls_loss: 0.1507  \n",
      "<<<iteration:[380/878] - total_loss: 0.6731  obj_loss: 0.2518  noobj_loss: 0.1363  bbox_loss: 0.0432  cls_loss: 0.1369  \n",
      "<<<iteration:[400/878] - total_loss: 0.6604  obj_loss: 0.2650  noobj_loss: 0.1384  bbox_loss: 0.0311  cls_loss: 0.1709  \n",
      "<<<iteration:[420/878] - total_loss: 0.5786  obj_loss: 0.2809  noobj_loss: 0.1227  bbox_loss: 0.0275  cls_loss: 0.0988  \n",
      "<<<iteration:[440/878] - total_loss: 0.6780  obj_loss: 0.2742  noobj_loss: 0.1391  bbox_loss: 0.0301  cls_loss: 0.1835  \n",
      "<<<iteration:[460/878] - total_loss: 0.5213  obj_loss: 0.2138  noobj_loss: 0.1192  bbox_loss: 0.0283  cls_loss: 0.1064  \n",
      "<<<iteration:[480/878] - total_loss: 0.5529  obj_loss: 0.1959  noobj_loss: 0.1145  bbox_loss: 0.0346  cls_loss: 0.1265  \n",
      "<<<iteration:[500/878] - total_loss: 0.6508  obj_loss: 0.2932  noobj_loss: 0.1344  bbox_loss: 0.0261  cls_loss: 0.1597  \n",
      "<<<iteration:[520/878] - total_loss: 0.6345  obj_loss: 0.2770  noobj_loss: 0.1559  bbox_loss: 0.0292  cls_loss: 0.1336  \n",
      "<<<iteration:[540/878] - total_loss: 0.4501  obj_loss: 0.1999  noobj_loss: 0.1097  bbox_loss: 0.0245  cls_loss: 0.0727  \n",
      "<<<iteration:[560/878] - total_loss: 0.4761  obj_loss: 0.2118  noobj_loss: 0.1029  bbox_loss: 0.0257  cls_loss: 0.0844  \n",
      "<<<iteration:[580/878] - total_loss: 0.7822  obj_loss: 0.2245  noobj_loss: 0.1221  bbox_loss: 0.0502  cls_loss: 0.2455  \n",
      "<<<iteration:[600/878] - total_loss: 0.5975  obj_loss: 0.1827  noobj_loss: 0.1132  bbox_loss: 0.0387  cls_loss: 0.1646  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<<<iteration:[620/878] - total_loss: 0.5984  obj_loss: 0.2459  noobj_loss: 0.1093  bbox_loss: 0.0293  cls_loss: 0.1517  \n",
      "<<<iteration:[640/878] - total_loss: 0.5884  obj_loss: 0.2338  noobj_loss: 0.1128  bbox_loss: 0.0325  cls_loss: 0.1356  \n",
      "<<<iteration:[660/878] - total_loss: 0.5710  obj_loss: 0.2205  noobj_loss: 0.1256  bbox_loss: 0.0268  cls_loss: 0.1535  \n",
      "<<<iteration:[680/878] - total_loss: 0.5944  obj_loss: 0.2432  noobj_loss: 0.1192  bbox_loss: 0.0302  cls_loss: 0.1405  \n",
      "<<<iteration:[700/878] - total_loss: 0.5297  obj_loss: 0.2494  noobj_loss: 0.1205  bbox_loss: 0.0257  cls_loss: 0.0918  \n",
      "<<<iteration:[720/878] - total_loss: 0.6364  obj_loss: 0.1920  noobj_loss: 0.1172  bbox_loss: 0.0361  cls_loss: 0.2054  \n",
      "<<<iteration:[740/878] - total_loss: 0.6024  obj_loss: 0.2589  noobj_loss: 0.1283  bbox_loss: 0.0298  cls_loss: 0.1305  \n",
      "<<<iteration:[760/878] - total_loss: 0.6179  obj_loss: 0.2523  noobj_loss: 0.1316  bbox_loss: 0.0320  cls_loss: 0.1397  \n",
      "<<<iteration:[780/878] - total_loss: 0.6301  obj_loss: 0.2187  noobj_loss: 0.1284  bbox_loss: 0.0374  cls_loss: 0.1599  \n",
      "<<<iteration:[800/878] - total_loss: 0.6144  obj_loss: 0.2336  noobj_loss: 0.1111  bbox_loss: 0.0293  cls_loss: 0.1787  \n",
      "<<<iteration:[820/878] - total_loss: 0.5524  obj_loss: 0.2230  noobj_loss: 0.1226  bbox_loss: 0.0240  cls_loss: 0.1482  \n",
      "<<<iteration:[840/878] - total_loss: 0.4937  obj_loss: 0.1708  noobj_loss: 0.1059  bbox_loss: 0.0245  cls_loss: 0.1473  \n",
      "<<<iteration:[860/878] - total_loss: 0.5630  obj_loss: 0.2386  noobj_loss: 0.1143  bbox_loss: 0.0272  cls_loss: 0.1312  \n",
      "\n",
      "epoch:85/100 - Train Loss: 0.5892, Val Loss: 1.1568\n",
      "\n",
      "<<<iteration:[20/878] - total_loss: 0.6568  obj_loss: 0.2878  noobj_loss: 0.1427  bbox_loss: 0.0291  cls_loss: 0.1521  \n",
      "<<<iteration:[40/878] - total_loss: 0.5871  obj_loss: 0.2545  noobj_loss: 0.1307  bbox_loss: 0.0258  cls_loss: 0.1380  \n",
      "<<<iteration:[60/878] - total_loss: 0.5468  obj_loss: 0.2043  noobj_loss: 0.1139  bbox_loss: 0.0332  cls_loss: 0.1193  \n",
      "<<<iteration:[80/878] - total_loss: 0.5522  obj_loss: 0.2537  noobj_loss: 0.1199  bbox_loss: 0.0290  cls_loss: 0.0938  \n",
      "<<<iteration:[100/878] - total_loss: 0.5960  obj_loss: 0.2640  noobj_loss: 0.1199  bbox_loss: 0.0259  cls_loss: 0.1427  \n",
      "<<<iteration:[120/878] - total_loss: 0.5355  obj_loss: 0.1955  noobj_loss: 0.1117  bbox_loss: 0.0234  cls_loss: 0.1673  \n",
      "<<<iteration:[140/878] - total_loss: 0.4980  obj_loss: 0.2322  noobj_loss: 0.1241  bbox_loss: 0.0213  cls_loss: 0.0974  \n",
      "<<<iteration:[160/878] - total_loss: 0.5830  obj_loss: 0.2896  noobj_loss: 0.1413  bbox_loss: 0.0289  cls_loss: 0.0784  \n",
      "<<<iteration:[180/878] - total_loss: 0.5392  obj_loss: 0.2133  noobj_loss: 0.1239  bbox_loss: 0.0287  cls_loss: 0.1204  \n",
      "<<<iteration:[200/878] - total_loss: 0.5407  obj_loss: 0.2071  noobj_loss: 0.1108  bbox_loss: 0.0252  cls_loss: 0.1522  \n",
      "<<<iteration:[220/878] - total_loss: 0.6236  obj_loss: 0.2306  noobj_loss: 0.1130  bbox_loss: 0.0274  cls_loss: 0.1996  \n",
      "<<<iteration:[240/878] - total_loss: 0.5757  obj_loss: 0.2713  noobj_loss: 0.1427  bbox_loss: 0.0244  cls_loss: 0.1110  \n",
      "<<<iteration:[260/878] - total_loss: 0.5496  obj_loss: 0.2106  noobj_loss: 0.1145  bbox_loss: 0.0290  cls_loss: 0.1366  \n",
      "<<<iteration:[280/878] - total_loss: 0.5324  obj_loss: 0.2388  noobj_loss: 0.1361  bbox_loss: 0.0256  cls_loss: 0.0974  \n",
      "<<<iteration:[300/878] - total_loss: 0.5455  obj_loss: 0.2152  noobj_loss: 0.1377  bbox_loss: 0.0267  cls_loss: 0.1279  \n",
      "<<<iteration:[320/878] - total_loss: 0.5335  obj_loss: 0.2378  noobj_loss: 0.1191  bbox_loss: 0.0273  cls_loss: 0.0995  \n",
      "<<<iteration:[340/878] - total_loss: 0.4815  obj_loss: 0.2012  noobj_loss: 0.1165  bbox_loss: 0.0206  cls_loss: 0.1191  \n",
      "<<<iteration:[360/878] - total_loss: 0.5767  obj_loss: 0.2893  noobj_loss: 0.1307  bbox_loss: 0.0234  cls_loss: 0.1053  \n",
      "<<<iteration:[380/878] - total_loss: 0.4938  obj_loss: 0.2329  noobj_loss: 0.1273  bbox_loss: 0.0222  cls_loss: 0.0864  \n",
      "<<<iteration:[400/878] - total_loss: 0.6601  obj_loss: 0.2309  noobj_loss: 0.1327  bbox_loss: 0.0340  cls_loss: 0.1927  \n",
      "<<<iteration:[420/878] - total_loss: 0.6447  obj_loss: 0.2291  noobj_loss: 0.1385  bbox_loss: 0.0315  cls_loss: 0.1888  \n",
      "<<<iteration:[440/878] - total_loss: 0.5365  obj_loss: 0.2172  noobj_loss: 0.1233  bbox_loss: 0.0240  cls_loss: 0.1375  \n",
      "<<<iteration:[460/878] - total_loss: 0.5948  obj_loss: 0.2354  noobj_loss: 0.1184  bbox_loss: 0.0237  cls_loss: 0.1817  \n",
      "<<<iteration:[480/878] - total_loss: 0.5896  obj_loss: 0.2244  noobj_loss: 0.1318  bbox_loss: 0.0295  cls_loss: 0.1516  \n",
      "<<<iteration:[500/878] - total_loss: 0.5865  obj_loss: 0.2634  noobj_loss: 0.1339  bbox_loss: 0.0290  cls_loss: 0.1113  \n",
      "<<<iteration:[520/878] - total_loss: 0.5664  obj_loss: 0.1917  noobj_loss: 0.1199  bbox_loss: 0.0268  cls_loss: 0.1810  \n",
      "<<<iteration:[540/878] - total_loss: 0.5248  obj_loss: 0.2310  noobj_loss: 0.1054  bbox_loss: 0.0250  cls_loss: 0.1161  \n",
      "<<<iteration:[560/878] - total_loss: 0.4490  obj_loss: 0.1724  noobj_loss: 0.0981  bbox_loss: 0.0223  cls_loss: 0.1160  \n",
      "<<<iteration:[580/878] - total_loss: 0.5347  obj_loss: 0.2433  noobj_loss: 0.1211  bbox_loss: 0.0285  cls_loss: 0.0882  \n",
      "<<<iteration:[600/878] - total_loss: 0.6096  obj_loss: 0.2535  noobj_loss: 0.1226  bbox_loss: 0.0351  cls_loss: 0.1192  \n",
      "<<<iteration:[620/878] - total_loss: 0.5516  obj_loss: 0.2283  noobj_loss: 0.1238  bbox_loss: 0.0218  cls_loss: 0.1522  \n",
      "<<<iteration:[640/878] - total_loss: 0.5324  obj_loss: 0.2304  noobj_loss: 0.1223  bbox_loss: 0.0240  cls_loss: 0.1205  \n",
      "<<<iteration:[660/878] - total_loss: 0.5844  obj_loss: 0.2591  noobj_loss: 0.1372  bbox_loss: 0.0252  cls_loss: 0.1307  \n",
      "<<<iteration:[680/878] - total_loss: 0.5542  obj_loss: 0.2619  noobj_loss: 0.1328  bbox_loss: 0.0271  cls_loss: 0.0905  \n",
      "<<<iteration:[700/878] - total_loss: 0.5488  obj_loss: 0.2224  noobj_loss: 0.1219  bbox_loss: 0.0243  cls_loss: 0.1439  \n",
      "<<<iteration:[720/878] - total_loss: 0.5508  obj_loss: 0.2413  noobj_loss: 0.1241  bbox_loss: 0.0263  cls_loss: 0.1159  \n",
      "<<<iteration:[740/878] - total_loss: 0.5571  obj_loss: 0.1857  noobj_loss: 0.1136  bbox_loss: 0.0262  cls_loss: 0.1836  \n",
      "<<<iteration:[760/878] - total_loss: 0.5322  obj_loss: 0.2415  noobj_loss: 0.1226  bbox_loss: 0.0252  cls_loss: 0.1032  \n",
      "<<<iteration:[780/878] - total_loss: 0.6305  obj_loss: 0.2333  noobj_loss: 0.1204  bbox_loss: 0.0328  cls_loss: 0.1732  \n",
      "<<<iteration:[800/878] - total_loss: 0.6217  obj_loss: 0.1964  noobj_loss: 0.1121  bbox_loss: 0.0456  cls_loss: 0.1414  \n",
      "<<<iteration:[820/878] - total_loss: 0.5741  obj_loss: 0.2609  noobj_loss: 0.1208  bbox_loss: 0.0225  cls_loss: 0.1403  \n",
      "<<<iteration:[840/878] - total_loss: 0.6305  obj_loss: 0.2449  noobj_loss: 0.1266  bbox_loss: 0.0275  cls_loss: 0.1847  \n",
      "<<<iteration:[860/878] - total_loss: 0.6487  obj_loss: 0.2233  noobj_loss: 0.1120  bbox_loss: 0.0449  cls_loss: 0.1448  \n",
      "\n",
      "epoch:86/100 - Train Loss: 0.5664, Val Loss: 1.5385\n",
      "\n",
      "<<<iteration:[20/878] - total_loss: 0.6580  obj_loss: 0.2491  noobj_loss: 0.1199  bbox_loss: 0.0363  cls_loss: 0.1677  \n",
      "<<<iteration:[40/878] - total_loss: 0.5506  obj_loss: 0.2464  noobj_loss: 0.1258  bbox_loss: 0.0311  cls_loss: 0.0858  \n",
      "<<<iteration:[60/878] - total_loss: 0.5812  obj_loss: 0.2464  noobj_loss: 0.1286  bbox_loss: 0.0261  cls_loss: 0.1399  \n",
      "<<<iteration:[80/878] - total_loss: 0.5311  obj_loss: 0.2369  noobj_loss: 0.1197  bbox_loss: 0.0214  cls_loss: 0.1276  \n",
      "<<<iteration:[100/878] - total_loss: 0.5559  obj_loss: 0.2517  noobj_loss: 0.1233  bbox_loss: 0.0212  cls_loss: 0.1364  \n",
      "<<<iteration:[120/878] - total_loss: 0.5160  obj_loss: 0.2154  noobj_loss: 0.1106  bbox_loss: 0.0246  cls_loss: 0.1224  \n",
      "<<<iteration:[140/878] - total_loss: 0.6231  obj_loss: 0.2497  noobj_loss: 0.1306  bbox_loss: 0.0290  cls_loss: 0.1631  \n",
      "<<<iteration:[160/878] - total_loss: 0.5621  obj_loss: 0.2484  noobj_loss: 0.1213  bbox_loss: 0.0246  cls_loss: 0.1299  \n",
      "<<<iteration:[180/878] - total_loss: 0.5178  obj_loss: 0.2509  noobj_loss: 0.1395  bbox_loss: 0.0225  cls_loss: 0.0849  \n",
      "<<<iteration:[200/878] - total_loss: 0.6096  obj_loss: 0.2828  noobj_loss: 0.1438  bbox_loss: 0.0301  cls_loss: 0.1044  \n",
      "<<<iteration:[220/878] - total_loss: 0.5587  obj_loss: 0.2407  noobj_loss: 0.1096  bbox_loss: 0.0302  cls_loss: 0.1121  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<<<iteration:[240/878] - total_loss: 0.5629  obj_loss: 0.2505  noobj_loss: 0.1331  bbox_loss: 0.0278  cls_loss: 0.1066  \n",
      "<<<iteration:[260/878] - total_loss: 0.5245  obj_loss: 0.2194  noobj_loss: 0.1308  bbox_loss: 0.0251  cls_loss: 0.1141  \n",
      "<<<iteration:[280/878] - total_loss: 0.5579  obj_loss: 0.2443  noobj_loss: 0.1401  bbox_loss: 0.0247  cls_loss: 0.1201  \n",
      "<<<iteration:[300/878] - total_loss: 0.5128  obj_loss: 0.2678  noobj_loss: 0.1393  bbox_loss: 0.0248  cls_loss: 0.0511  \n",
      "<<<iteration:[320/878] - total_loss: 0.6165  obj_loss: 0.3018  noobj_loss: 0.1428  bbox_loss: 0.0270  cls_loss: 0.1085  \n",
      "<<<iteration:[340/878] - total_loss: 0.6489  obj_loss: 0.2496  noobj_loss: 0.1344  bbox_loss: 0.0335  cls_loss: 0.1647  \n",
      "<<<iteration:[360/878] - total_loss: 0.6645  obj_loss: 0.2521  noobj_loss: 0.1341  bbox_loss: 0.0343  cls_loss: 0.1740  \n",
      "<<<iteration:[380/878] - total_loss: 0.5333  obj_loss: 0.2074  noobj_loss: 0.1253  bbox_loss: 0.0234  cls_loss: 0.1464  \n",
      "<<<iteration:[400/878] - total_loss: 0.5067  obj_loss: 0.1988  noobj_loss: 0.1064  bbox_loss: 0.0220  cls_loss: 0.1447  \n",
      "<<<iteration:[420/878] - total_loss: 0.5715  obj_loss: 0.2261  noobj_loss: 0.1367  bbox_loss: 0.0296  cls_loss: 0.1291  \n",
      "<<<iteration:[440/878] - total_loss: 0.5486  obj_loss: 0.2286  noobj_loss: 0.1219  bbox_loss: 0.0274  cls_loss: 0.1223  \n",
      "<<<iteration:[460/878] - total_loss: 0.5233  obj_loss: 0.1957  noobj_loss: 0.1101  bbox_loss: 0.0186  cls_loss: 0.1794  \n",
      "<<<iteration:[480/878] - total_loss: 0.6477  obj_loss: 0.2531  noobj_loss: 0.1225  bbox_loss: 0.0266  cls_loss: 0.2004  \n",
      "<<<iteration:[500/878] - total_loss: 0.5926  obj_loss: 0.2418  noobj_loss: 0.1297  bbox_loss: 0.0254  cls_loss: 0.1590  \n",
      "<<<iteration:[520/878] - total_loss: 0.5763  obj_loss: 0.2372  noobj_loss: 0.1257  bbox_loss: 0.0290  cls_loss: 0.1311  \n",
      "<<<iteration:[540/878] - total_loss: 0.6190  obj_loss: 0.2738  noobj_loss: 0.1297  bbox_loss: 0.0289  cls_loss: 0.1361  \n",
      "<<<iteration:[560/878] - total_loss: 0.5468  obj_loss: 0.2306  noobj_loss: 0.1168  bbox_loss: 0.0248  cls_loss: 0.1338  \n",
      "<<<iteration:[580/878] - total_loss: 0.5825  obj_loss: 0.2161  noobj_loss: 0.1168  bbox_loss: 0.0280  cls_loss: 0.1680  \n",
      "<<<iteration:[600/878] - total_loss: 0.5821  obj_loss: 0.2485  noobj_loss: 0.1187  bbox_loss: 0.0269  cls_loss: 0.1398  \n",
      "<<<iteration:[620/878] - total_loss: 0.6211  obj_loss: 0.2477  noobj_loss: 0.1374  bbox_loss: 0.0429  cls_loss: 0.0904  \n",
      "<<<iteration:[640/878] - total_loss: 0.5002  obj_loss: 0.2110  noobj_loss: 0.1212  bbox_loss: 0.0370  cls_loss: 0.0438  \n",
      "<<<iteration:[660/878] - total_loss: 0.5060  obj_loss: 0.2072  noobj_loss: 0.1351  bbox_loss: 0.0300  cls_loss: 0.0813  \n",
      "<<<iteration:[680/878] - total_loss: 0.5683  obj_loss: 0.2113  noobj_loss: 0.1262  bbox_loss: 0.0270  cls_loss: 0.1588  \n",
      "<<<iteration:[700/878] - total_loss: 0.6088  obj_loss: 0.2439  noobj_loss: 0.1314  bbox_loss: 0.0307  cls_loss: 0.1456  \n",
      "<<<iteration:[720/878] - total_loss: 0.4983  obj_loss: 0.2165  noobj_loss: 0.1254  bbox_loss: 0.0258  cls_loss: 0.0901  \n",
      "<<<iteration:[740/878] - total_loss: 0.5152  obj_loss: 0.2064  noobj_loss: 0.1005  bbox_loss: 0.0242  cls_loss: 0.1374  \n",
      "<<<iteration:[760/878] - total_loss: 0.6992  obj_loss: 0.2756  noobj_loss: 0.1407  bbox_loss: 0.0323  cls_loss: 0.1919  \n",
      "<<<iteration:[780/878] - total_loss: 0.4720  obj_loss: 0.2038  noobj_loss: 0.1078  bbox_loss: 0.0207  cls_loss: 0.1107  \n",
      "<<<iteration:[800/878] - total_loss: 0.5023  obj_loss: 0.2607  noobj_loss: 0.1130  bbox_loss: 0.0207  cls_loss: 0.0815  \n",
      "<<<iteration:[820/878] - total_loss: 0.5944  obj_loss: 0.2361  noobj_loss: 0.1351  bbox_loss: 0.0298  cls_loss: 0.1417  \n",
      "<<<iteration:[840/878] - total_loss: 0.5160  obj_loss: 0.1839  noobj_loss: 0.1267  bbox_loss: 0.0304  cls_loss: 0.1166  \n",
      "<<<iteration:[860/878] - total_loss: 0.5204  obj_loss: 0.2289  noobj_loss: 0.1239  bbox_loss: 0.0222  cls_loss: 0.1185  \n",
      "\n",
      "epoch:87/100 - Train Loss: 0.5667, Val Loss: 1.1526\n",
      "\n",
      "<<<iteration:[20/878] - total_loss: 0.7233  obj_loss: 0.2986  noobj_loss: 0.1571  bbox_loss: 0.0322  cls_loss: 0.1849  \n",
      "<<<iteration:[40/878] - total_loss: 0.5642  obj_loss: 0.2359  noobj_loss: 0.1236  bbox_loss: 0.0327  cls_loss: 0.1028  \n",
      "<<<iteration:[60/878] - total_loss: 0.5638  obj_loss: 0.2837  noobj_loss: 0.1176  bbox_loss: 0.0240  cls_loss: 0.1011  \n",
      "<<<iteration:[80/878] - total_loss: 0.5402  obj_loss: 0.2167  noobj_loss: 0.1057  bbox_loss: 0.0220  cls_loss: 0.1609  \n",
      "<<<iteration:[100/878] - total_loss: 0.5274  obj_loss: 0.2527  noobj_loss: 0.1429  bbox_loss: 0.0258  cls_loss: 0.0743  \n",
      "<<<iteration:[120/878] - total_loss: 0.6719  obj_loss: 0.2068  noobj_loss: 0.1523  bbox_loss: 0.0564  cls_loss: 0.1071  \n",
      "<<<iteration:[140/878] - total_loss: 0.5137  obj_loss: 0.2231  noobj_loss: 0.1368  bbox_loss: 0.0224  cls_loss: 0.1101  \n",
      "<<<iteration:[160/878] - total_loss: 0.5183  obj_loss: 0.2214  noobj_loss: 0.1235  bbox_loss: 0.0261  cls_loss: 0.1046  \n",
      "<<<iteration:[180/878] - total_loss: 0.5955  obj_loss: 0.2499  noobj_loss: 0.1300  bbox_loss: 0.0240  cls_loss: 0.1606  \n",
      "<<<iteration:[200/878] - total_loss: 0.5362  obj_loss: 0.2472  noobj_loss: 0.1302  bbox_loss: 0.0233  cls_loss: 0.1075  \n",
      "<<<iteration:[220/878] - total_loss: 0.5463  obj_loss: 0.2522  noobj_loss: 0.1159  bbox_loss: 0.0255  cls_loss: 0.1087  \n",
      "<<<iteration:[240/878] - total_loss: 0.5410  obj_loss: 0.2537  noobj_loss: 0.1250  bbox_loss: 0.0237  cls_loss: 0.1061  \n",
      "<<<iteration:[260/878] - total_loss: 0.4913  obj_loss: 0.2448  noobj_loss: 0.1227  bbox_loss: 0.0188  cls_loss: 0.0914  \n",
      "<<<iteration:[280/878] - total_loss: 0.5536  obj_loss: 0.2533  noobj_loss: 0.1280  bbox_loss: 0.0255  cls_loss: 0.1088  \n",
      "<<<iteration:[300/878] - total_loss: 0.5730  obj_loss: 0.1995  noobj_loss: 0.1207  bbox_loss: 0.0267  cls_loss: 0.1798  \n",
      "<<<iteration:[320/878] - total_loss: 0.5553  obj_loss: 0.2304  noobj_loss: 0.1342  bbox_loss: 0.0230  cls_loss: 0.1427  \n",
      "<<<iteration:[340/878] - total_loss: 0.4986  obj_loss: 0.2410  noobj_loss: 0.1199  bbox_loss: 0.0225  cls_loss: 0.0852  \n",
      "<<<iteration:[360/878] - total_loss: 0.5193  obj_loss: 0.2411  noobj_loss: 0.1238  bbox_loss: 0.0241  cls_loss: 0.0956  \n",
      "<<<iteration:[380/878] - total_loss: 0.6416  obj_loss: 0.2772  noobj_loss: 0.1259  bbox_loss: 0.0274  cls_loss: 0.1643  \n",
      "<<<iteration:[400/878] - total_loss: 0.5362  obj_loss: 0.2275  noobj_loss: 0.1345  bbox_loss: 0.0273  cls_loss: 0.1050  \n",
      "<<<iteration:[420/878] - total_loss: 0.6072  obj_loss: 0.2523  noobj_loss: 0.1389  bbox_loss: 0.0286  cls_loss: 0.1422  \n",
      "<<<iteration:[440/878] - total_loss: 0.4869  obj_loss: 0.2249  noobj_loss: 0.1112  bbox_loss: 0.0204  cls_loss: 0.1045  \n",
      "<<<iteration:[460/878] - total_loss: 0.6671  obj_loss: 0.2621  noobj_loss: 0.1245  bbox_loss: 0.0266  cls_loss: 0.2096  \n",
      "<<<iteration:[480/878] - total_loss: 0.5902  obj_loss: 0.2525  noobj_loss: 0.1401  bbox_loss: 0.0262  cls_loss: 0.1367  \n",
      "<<<iteration:[500/878] - total_loss: 0.5796  obj_loss: 0.2434  noobj_loss: 0.1230  bbox_loss: 0.0312  cls_loss: 0.1186  \n",
      "<<<iteration:[520/878] - total_loss: 0.5428  obj_loss: 0.2325  noobj_loss: 0.1258  bbox_loss: 0.0271  cls_loss: 0.1118  \n",
      "<<<iteration:[540/878] - total_loss: 0.6324  obj_loss: 0.2512  noobj_loss: 0.1213  bbox_loss: 0.0266  cls_loss: 0.1876  \n",
      "<<<iteration:[560/878] - total_loss: 0.5432  obj_loss: 0.2287  noobj_loss: 0.1329  bbox_loss: 0.0246  cls_loss: 0.1253  \n",
      "<<<iteration:[580/878] - total_loss: 0.5572  obj_loss: 0.2377  noobj_loss: 0.1250  bbox_loss: 0.0297  cls_loss: 0.1087  \n",
      "<<<iteration:[600/878] - total_loss: 0.5786  obj_loss: 0.2420  noobj_loss: 0.1236  bbox_loss: 0.0276  cls_loss: 0.1368  \n",
      "<<<iteration:[620/878] - total_loss: 0.5470  obj_loss: 0.2230  noobj_loss: 0.1256  bbox_loss: 0.0247  cls_loss: 0.1380  \n",
      "<<<iteration:[640/878] - total_loss: 0.6029  obj_loss: 0.2451  noobj_loss: 0.1219  bbox_loss: 0.0265  cls_loss: 0.1643  \n",
      "<<<iteration:[660/878] - total_loss: 0.4966  obj_loss: 0.1924  noobj_loss: 0.1164  bbox_loss: 0.0217  cls_loss: 0.1372  \n",
      "<<<iteration:[680/878] - total_loss: 0.5387  obj_loss: 0.2406  noobj_loss: 0.1284  bbox_loss: 0.0241  cls_loss: 0.1134  \n",
      "<<<iteration:[700/878] - total_loss: 0.5473  obj_loss: 0.2296  noobj_loss: 0.1295  bbox_loss: 0.0300  cls_loss: 0.1031  \n",
      "<<<iteration:[720/878] - total_loss: 0.6479  obj_loss: 0.2388  noobj_loss: 0.1307  bbox_loss: 0.0420  cls_loss: 0.1339  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<<<iteration:[740/878] - total_loss: 0.5929  obj_loss: 0.2116  noobj_loss: 0.1178  bbox_loss: 0.0263  cls_loss: 0.1907  \n",
      "<<<iteration:[760/878] - total_loss: 0.5287  obj_loss: 0.2290  noobj_loss: 0.1284  bbox_loss: 0.0259  cls_loss: 0.1062  \n",
      "<<<iteration:[780/878] - total_loss: 0.5183  obj_loss: 0.2356  noobj_loss: 0.1316  bbox_loss: 0.0253  cls_loss: 0.0903  \n",
      "<<<iteration:[800/878] - total_loss: 0.7002  obj_loss: 0.2750  noobj_loss: 0.1188  bbox_loss: 0.0358  cls_loss: 0.1866  \n",
      "<<<iteration:[820/878] - total_loss: 0.5796  obj_loss: 0.2173  noobj_loss: 0.1302  bbox_loss: 0.0313  cls_loss: 0.1405  \n",
      "<<<iteration:[840/878] - total_loss: 0.5997  obj_loss: 0.2603  noobj_loss: 0.1258  bbox_loss: 0.0318  cls_loss: 0.1173  \n",
      "<<<iteration:[860/878] - total_loss: 0.6463  obj_loss: 0.2015  noobj_loss: 0.1187  bbox_loss: 0.0446  cls_loss: 0.1623  \n",
      "\n",
      "epoch:88/100 - Train Loss: 0.5702, Val Loss: 1.1496\n",
      "\n",
      "<<<iteration:[20/878] - total_loss: 0.6869  obj_loss: 0.2379  noobj_loss: 0.1229  bbox_loss: 0.0342  cls_loss: 0.2163  \n",
      "<<<iteration:[40/878] - total_loss: 0.6734  obj_loss: 0.2780  noobj_loss: 0.1431  bbox_loss: 0.0265  cls_loss: 0.1912  \n",
      "<<<iteration:[60/878] - total_loss: 0.6666  obj_loss: 0.2449  noobj_loss: 0.1393  bbox_loss: 0.0373  cls_loss: 0.1657  \n",
      "<<<iteration:[80/878] - total_loss: 0.6071  obj_loss: 0.2062  noobj_loss: 0.1123  bbox_loss: 0.0413  cls_loss: 0.1382  \n",
      "<<<iteration:[100/878] - total_loss: 0.6262  obj_loss: 0.2415  noobj_loss: 0.1281  bbox_loss: 0.0288  cls_loss: 0.1768  \n",
      "<<<iteration:[120/878] - total_loss: 0.5472  obj_loss: 0.1804  noobj_loss: 0.1158  bbox_loss: 0.0300  cls_loss: 0.1586  \n",
      "<<<iteration:[140/878] - total_loss: 0.6331  obj_loss: 0.2871  noobj_loss: 0.1343  bbox_loss: 0.0263  cls_loss: 0.1476  \n",
      "<<<iteration:[160/878] - total_loss: 0.6118  obj_loss: 0.1842  noobj_loss: 0.1342  bbox_loss: 0.0571  cls_loss: 0.0749  \n",
      "<<<iteration:[180/878] - total_loss: 0.5007  obj_loss: 0.2370  noobj_loss: 0.1309  bbox_loss: 0.0240  cls_loss: 0.0784  \n",
      "<<<iteration:[200/878] - total_loss: 0.5867  obj_loss: 0.2290  noobj_loss: 0.1140  bbox_loss: 0.0288  cls_loss: 0.1568  \n",
      "<<<iteration:[220/878] - total_loss: 0.5788  obj_loss: 0.2234  noobj_loss: 0.1187  bbox_loss: 0.0308  cls_loss: 0.1421  \n",
      "<<<iteration:[240/878] - total_loss: 0.5643  obj_loss: 0.2263  noobj_loss: 0.1353  bbox_loss: 0.0249  cls_loss: 0.1459  \n",
      "<<<iteration:[260/878] - total_loss: 0.6052  obj_loss: 0.2720  noobj_loss: 0.1364  bbox_loss: 0.0271  cls_loss: 0.1293  \n",
      "<<<iteration:[280/878] - total_loss: 0.5469  obj_loss: 0.2211  noobj_loss: 0.1194  bbox_loss: 0.0245  cls_loss: 0.1436  \n",
      "<<<iteration:[300/878] - total_loss: 0.4572  obj_loss: 0.2073  noobj_loss: 0.1241  bbox_loss: 0.0218  cls_loss: 0.0788  \n",
      "<<<iteration:[320/878] - total_loss: 0.4948  obj_loss: 0.2369  noobj_loss: 0.1306  bbox_loss: 0.0244  cls_loss: 0.0707  \n",
      "<<<iteration:[340/878] - total_loss: 0.4433  obj_loss: 0.1975  noobj_loss: 0.1070  bbox_loss: 0.0215  cls_loss: 0.0850  \n",
      "<<<iteration:[360/878] - total_loss: 0.6032  obj_loss: 0.2178  noobj_loss: 0.1222  bbox_loss: 0.0266  cls_loss: 0.1913  \n",
      "<<<iteration:[380/878] - total_loss: 0.4810  obj_loss: 0.2139  noobj_loss: 0.1258  bbox_loss: 0.0285  cls_loss: 0.0616  \n",
      "<<<iteration:[400/878] - total_loss: 0.5326  obj_loss: 0.2196  noobj_loss: 0.1328  bbox_loss: 0.0313  cls_loss: 0.0901  \n",
      "<<<iteration:[420/878] - total_loss: 0.6239  obj_loss: 0.2769  noobj_loss: 0.1425  bbox_loss: 0.0264  cls_loss: 0.1437  \n",
      "<<<iteration:[440/878] - total_loss: 0.4816  obj_loss: 0.2079  noobj_loss: 0.1257  bbox_loss: 0.0239  cls_loss: 0.0912  \n",
      "<<<iteration:[460/878] - total_loss: 0.5902  obj_loss: 0.1950  noobj_loss: 0.1176  bbox_loss: 0.0308  cls_loss: 0.1822  \n",
      "<<<iteration:[480/878] - total_loss: 0.6214  obj_loss: 0.2920  noobj_loss: 0.1133  bbox_loss: 0.0233  cls_loss: 0.1561  \n",
      "<<<iteration:[500/878] - total_loss: 0.5274  obj_loss: 0.2344  noobj_loss: 0.1379  bbox_loss: 0.0252  cls_loss: 0.0982  \n",
      "<<<iteration:[520/878] - total_loss: 0.6391  obj_loss: 0.2816  noobj_loss: 0.1380  bbox_loss: 0.0288  cls_loss: 0.1444  \n",
      "<<<iteration:[540/878] - total_loss: 0.5857  obj_loss: 0.2327  noobj_loss: 0.1413  bbox_loss: 0.0280  cls_loss: 0.1424  \n",
      "<<<iteration:[560/878] - total_loss: 0.5058  obj_loss: 0.2451  noobj_loss: 0.1302  bbox_loss: 0.0205  cls_loss: 0.0931  \n",
      "<<<iteration:[580/878] - total_loss: 0.5797  obj_loss: 0.2307  noobj_loss: 0.1197  bbox_loss: 0.0275  cls_loss: 0.1518  \n",
      "<<<iteration:[600/878] - total_loss: 0.5809  obj_loss: 0.2719  noobj_loss: 0.1529  bbox_loss: 0.0254  cls_loss: 0.1053  \n",
      "<<<iteration:[620/878] - total_loss: 0.5968  obj_loss: 0.2586  noobj_loss: 0.1351  bbox_loss: 0.0254  cls_loss: 0.1439  \n",
      "<<<iteration:[640/878] - total_loss: 0.5237  obj_loss: 0.2589  noobj_loss: 0.1196  bbox_loss: 0.0214  cls_loss: 0.0980  \n",
      "<<<iteration:[660/878] - total_loss: 0.5841  obj_loss: 0.2573  noobj_loss: 0.1415  bbox_loss: 0.0241  cls_loss: 0.1355  \n",
      "<<<iteration:[680/878] - total_loss: 0.5535  obj_loss: 0.2072  noobj_loss: 0.1410  bbox_loss: 0.0281  cls_loss: 0.1353  \n",
      "<<<iteration:[700/878] - total_loss: 0.5387  obj_loss: 0.2359  noobj_loss: 0.1227  bbox_loss: 0.0237  cls_loss: 0.1230  \n",
      "<<<iteration:[720/878] - total_loss: 0.4835  obj_loss: 0.2223  noobj_loss: 0.1163  bbox_loss: 0.0226  cls_loss: 0.0902  \n",
      "<<<iteration:[740/878] - total_loss: 0.5300  obj_loss: 0.2102  noobj_loss: 0.1242  bbox_loss: 0.0230  cls_loss: 0.1429  \n",
      "<<<iteration:[760/878] - total_loss: 0.6074  obj_loss: 0.2150  noobj_loss: 0.1233  bbox_loss: 0.0232  cls_loss: 0.2144  \n",
      "<<<iteration:[780/878] - total_loss: 0.5240  obj_loss: 0.2538  noobj_loss: 0.1423  bbox_loss: 0.0246  cls_loss: 0.0763  \n",
      "<<<iteration:[800/878] - total_loss: 0.7896  obj_loss: 0.2263  noobj_loss: 0.1316  bbox_loss: 0.0705  cls_loss: 0.1448  \n",
      "<<<iteration:[820/878] - total_loss: 0.5037  obj_loss: 0.2287  noobj_loss: 0.1520  bbox_loss: 0.0233  cls_loss: 0.0822  \n",
      "<<<iteration:[840/878] - total_loss: 0.5600  obj_loss: 0.2523  noobj_loss: 0.1552  bbox_loss: 0.0214  cls_loss: 0.1233  \n",
      "<<<iteration:[860/878] - total_loss: 0.5216  obj_loss: 0.2491  noobj_loss: 0.1399  bbox_loss: 0.0225  cls_loss: 0.0899  \n",
      "\n",
      "epoch:89/100 - Train Loss: 0.5677, Val Loss: 1.1251\n",
      "\n",
      "<<<iteration:[20/878] - total_loss: 0.5623  obj_loss: 0.2482  noobj_loss: 0.1414  bbox_loss: 0.0274  cls_loss: 0.1067  \n",
      "<<<iteration:[40/878] - total_loss: 0.5737  obj_loss: 0.2678  noobj_loss: 0.1214  bbox_loss: 0.0245  cls_loss: 0.1229  \n",
      "<<<iteration:[60/878] - total_loss: 0.4727  obj_loss: 0.2103  noobj_loss: 0.1173  bbox_loss: 0.0243  cls_loss: 0.0823  \n",
      "<<<iteration:[80/878] - total_loss: 0.6133  obj_loss: 0.2885  noobj_loss: 0.1336  bbox_loss: 0.0353  cls_loss: 0.0816  \n",
      "<<<iteration:[100/878] - total_loss: 0.5664  obj_loss: 0.2592  noobj_loss: 0.1424  bbox_loss: 0.0238  cls_loss: 0.1171  \n",
      "<<<iteration:[120/878] - total_loss: 0.5714  obj_loss: 0.2588  noobj_loss: 0.1303  bbox_loss: 0.0235  cls_loss: 0.1298  \n",
      "<<<iteration:[140/878] - total_loss: 0.6696  obj_loss: 0.3181  noobj_loss: 0.1530  bbox_loss: 0.0265  cls_loss: 0.1426  \n",
      "<<<iteration:[160/878] - total_loss: 0.5899  obj_loss: 0.2481  noobj_loss: 0.1428  bbox_loss: 0.0320  cls_loss: 0.1103  \n",
      "<<<iteration:[180/878] - total_loss: 0.4939  obj_loss: 0.2365  noobj_loss: 0.1374  bbox_loss: 0.0224  cls_loss: 0.0767  \n",
      "<<<iteration:[200/878] - total_loss: 0.5263  obj_loss: 0.2359  noobj_loss: 0.1298  bbox_loss: 0.0201  cls_loss: 0.1251  \n",
      "<<<iteration:[220/878] - total_loss: 0.5447  obj_loss: 0.2388  noobj_loss: 0.1250  bbox_loss: 0.0230  cls_loss: 0.1282  \n",
      "<<<iteration:[240/878] - total_loss: 0.5754  obj_loss: 0.2337  noobj_loss: 0.1173  bbox_loss: 0.0227  cls_loss: 0.1695  \n",
      "<<<iteration:[260/878] - total_loss: 0.6998  obj_loss: 0.2467  noobj_loss: 0.1338  bbox_loss: 0.0343  cls_loss: 0.2149  \n",
      "<<<iteration:[280/878] - total_loss: 0.6350  obj_loss: 0.2762  noobj_loss: 0.1433  bbox_loss: 0.0282  cls_loss: 0.1461  \n",
      "<<<iteration:[300/878] - total_loss: 0.5360  obj_loss: 0.1877  noobj_loss: 0.1067  bbox_loss: 0.0251  cls_loss: 0.1693  \n",
      "<<<iteration:[320/878] - total_loss: 0.5306  obj_loss: 0.2253  noobj_loss: 0.1335  bbox_loss: 0.0230  cls_loss: 0.1235  \n",
      "<<<iteration:[340/878] - total_loss: 0.5595  obj_loss: 0.2647  noobj_loss: 0.1405  bbox_loss: 0.0248  cls_loss: 0.1007  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<<<iteration:[360/878] - total_loss: 0.5711  obj_loss: 0.2320  noobj_loss: 0.1192  bbox_loss: 0.0245  cls_loss: 0.1570  \n",
      "<<<iteration:[380/878] - total_loss: 0.5760  obj_loss: 0.2518  noobj_loss: 0.1501  bbox_loss: 0.0290  cls_loss: 0.1040  \n",
      "<<<iteration:[400/878] - total_loss: 0.5699  obj_loss: 0.2214  noobj_loss: 0.1232  bbox_loss: 0.0247  cls_loss: 0.1632  \n",
      "<<<iteration:[420/878] - total_loss: 0.5231  obj_loss: 0.2401  noobj_loss: 0.1288  bbox_loss: 0.0285  cls_loss: 0.0761  \n",
      "<<<iteration:[440/878] - total_loss: 0.5796  obj_loss: 0.2621  noobj_loss: 0.1368  bbox_loss: 0.0282  cls_loss: 0.1083  \n",
      "<<<iteration:[460/878] - total_loss: 0.6099  obj_loss: 0.2031  noobj_loss: 0.1522  bbox_loss: 0.0359  cls_loss: 0.1514  \n",
      "<<<iteration:[480/878] - total_loss: 0.5546  obj_loss: 0.2360  noobj_loss: 0.1229  bbox_loss: 0.0259  cls_loss: 0.1279  \n",
      "<<<iteration:[500/878] - total_loss: 0.5980  obj_loss: 0.2375  noobj_loss: 0.1249  bbox_loss: 0.0236  cls_loss: 0.1801  \n",
      "<<<iteration:[520/878] - total_loss: 0.5961  obj_loss: 0.2561  noobj_loss: 0.1336  bbox_loss: 0.0265  cls_loss: 0.1405  \n",
      "<<<iteration:[540/878] - total_loss: 0.5087  obj_loss: 0.2292  noobj_loss: 0.1456  bbox_loss: 0.0231  cls_loss: 0.0913  \n",
      "<<<iteration:[560/878] - total_loss: 0.5830  obj_loss: 0.2783  noobj_loss: 0.1311  bbox_loss: 0.0274  cls_loss: 0.1019  \n",
      "<<<iteration:[580/878] - total_loss: 0.4731  obj_loss: 0.1754  noobj_loss: 0.1104  bbox_loss: 0.0219  cls_loss: 0.1329  \n",
      "<<<iteration:[600/878] - total_loss: 0.4968  obj_loss: 0.2092  noobj_loss: 0.1198  bbox_loss: 0.0273  cls_loss: 0.0911  \n",
      "<<<iteration:[620/878] - total_loss: 0.5367  obj_loss: 0.2120  noobj_loss: 0.1236  bbox_loss: 0.0271  cls_loss: 0.1276  \n",
      "<<<iteration:[640/878] - total_loss: 0.4713  obj_loss: 0.2029  noobj_loss: 0.1317  bbox_loss: 0.0247  cls_loss: 0.0792  \n",
      "<<<iteration:[660/878] - total_loss: 0.5331  obj_loss: 0.1997  noobj_loss: 0.1111  bbox_loss: 0.0244  cls_loss: 0.1561  \n",
      "<<<iteration:[680/878] - total_loss: 0.5510  obj_loss: 0.2556  noobj_loss: 0.1279  bbox_loss: 0.0225  cls_loss: 0.1191  \n",
      "<<<iteration:[700/878] - total_loss: 0.5022  obj_loss: 0.2155  noobj_loss: 0.1227  bbox_loss: 0.0227  cls_loss: 0.1120  \n",
      "<<<iteration:[720/878] - total_loss: 0.7012  obj_loss: 0.2290  noobj_loss: 0.1193  bbox_loss: 0.0397  cls_loss: 0.2140  \n",
      "<<<iteration:[740/878] - total_loss: 0.6316  obj_loss: 0.2664  noobj_loss: 0.1370  bbox_loss: 0.0273  cls_loss: 0.1602  \n",
      "<<<iteration:[760/878] - total_loss: 0.6024  obj_loss: 0.2357  noobj_loss: 0.1374  bbox_loss: 0.0249  cls_loss: 0.1733  \n",
      "<<<iteration:[780/878] - total_loss: 0.6272  obj_loss: 0.2245  noobj_loss: 0.1358  bbox_loss: 0.0240  cls_loss: 0.2150  \n",
      "<<<iteration:[800/878] - total_loss: 0.5404  obj_loss: 0.2464  noobj_loss: 0.1235  bbox_loss: 0.0245  cls_loss: 0.1098  \n",
      "<<<iteration:[820/878] - total_loss: 0.5275  obj_loss: 0.2361  noobj_loss: 0.1217  bbox_loss: 0.0266  cls_loss: 0.0976  \n",
      "<<<iteration:[840/878] - total_loss: 0.4875  obj_loss: 0.2301  noobj_loss: 0.1259  bbox_loss: 0.0236  cls_loss: 0.0763  \n",
      "<<<iteration:[860/878] - total_loss: 0.5844  obj_loss: 0.2514  noobj_loss: 0.1350  bbox_loss: 0.0263  cls_loss: 0.1338  \n",
      "\n",
      "epoch:90/100 - Train Loss: 0.5628, Val Loss: 1.1250\n",
      "\n",
      "<<<iteration:[20/878] - total_loss: 0.6183  obj_loss: 0.2789  noobj_loss: 0.1414  bbox_loss: 0.0290  cls_loss: 0.1236  \n",
      "<<<iteration:[40/878] - total_loss: 0.5568  obj_loss: 0.2747  noobj_loss: 0.1205  bbox_loss: 0.0227  cls_loss: 0.1083  \n",
      "<<<iteration:[60/878] - total_loss: 0.5544  obj_loss: 0.1997  noobj_loss: 0.1224  bbox_loss: 0.0274  cls_loss: 0.1564  \n",
      "<<<iteration:[80/878] - total_loss: 0.4571  obj_loss: 0.2239  noobj_loss: 0.1100  bbox_loss: 0.0218  cls_loss: 0.0692  \n",
      "<<<iteration:[100/878] - total_loss: 0.5930  obj_loss: 0.3075  noobj_loss: 0.1541  bbox_loss: 0.0246  cls_loss: 0.0856  \n",
      "<<<iteration:[120/878] - total_loss: 0.6465  obj_loss: 0.2245  noobj_loss: 0.1138  bbox_loss: 0.0385  cls_loss: 0.1727  \n",
      "<<<iteration:[140/878] - total_loss: 0.7469  obj_loss: 0.2440  noobj_loss: 0.1285  bbox_loss: 0.0564  cls_loss: 0.1565  \n",
      "<<<iteration:[160/878] - total_loss: 0.7159  obj_loss: 0.2620  noobj_loss: 0.1262  bbox_loss: 0.0399  cls_loss: 0.1911  \n",
      "<<<iteration:[180/878] - total_loss: 0.5786  obj_loss: 0.2706  noobj_loss: 0.1531  bbox_loss: 0.0249  cls_loss: 0.1071  \n",
      "<<<iteration:[200/878] - total_loss: 0.5986  obj_loss: 0.2378  noobj_loss: 0.1245  bbox_loss: 0.0257  cls_loss: 0.1701  \n",
      "<<<iteration:[220/878] - total_loss: 0.4974  obj_loss: 0.2492  noobj_loss: 0.1240  bbox_loss: 0.0211  cls_loss: 0.0806  \n",
      "<<<iteration:[240/878] - total_loss: 0.5277  obj_loss: 0.2290  noobj_loss: 0.1223  bbox_loss: 0.0264  cls_loss: 0.1054  \n",
      "<<<iteration:[260/878] - total_loss: 0.5533  obj_loss: 0.2471  noobj_loss: 0.1289  bbox_loss: 0.0251  cls_loss: 0.1163  \n",
      "<<<iteration:[280/878] - total_loss: 0.6217  obj_loss: 0.2502  noobj_loss: 0.1427  bbox_loss: 0.0340  cls_loss: 0.1303  \n",
      "<<<iteration:[300/878] - total_loss: 0.6337  obj_loss: 0.2213  noobj_loss: 0.1341  bbox_loss: 0.0272  cls_loss: 0.2093  \n",
      "<<<iteration:[320/878] - total_loss: 0.5554  obj_loss: 0.2501  noobj_loss: 0.1261  bbox_loss: 0.0225  cls_loss: 0.1300  \n",
      "<<<iteration:[340/878] - total_loss: 0.5732  obj_loss: 0.2625  noobj_loss: 0.1395  bbox_loss: 0.0297  cls_loss: 0.0923  \n",
      "<<<iteration:[360/878] - total_loss: 0.6249  obj_loss: 0.2414  noobj_loss: 0.1263  bbox_loss: 0.0303  cls_loss: 0.1690  \n",
      "<<<iteration:[380/878] - total_loss: 0.6591  obj_loss: 0.2486  noobj_loss: 0.1159  bbox_loss: 0.0257  cls_loss: 0.2240  \n",
      "<<<iteration:[400/878] - total_loss: 0.5440  obj_loss: 0.2496  noobj_loss: 0.1328  bbox_loss: 0.0292  cls_loss: 0.0819  \n",
      "<<<iteration:[420/878] - total_loss: 0.5192  obj_loss: 0.2344  noobj_loss: 0.1142  bbox_loss: 0.0226  cls_loss: 0.1149  \n",
      "<<<iteration:[440/878] - total_loss: 0.5354  obj_loss: 0.2542  noobj_loss: 0.1229  bbox_loss: 0.0262  cls_loss: 0.0886  \n",
      "<<<iteration:[460/878] - total_loss: 0.5114  obj_loss: 0.2195  noobj_loss: 0.1263  bbox_loss: 0.0323  cls_loss: 0.0671  \n",
      "<<<iteration:[480/878] - total_loss: 0.5232  obj_loss: 0.2364  noobj_loss: 0.1332  bbox_loss: 0.0227  cls_loss: 0.1066  \n",
      "<<<iteration:[500/878] - total_loss: 0.6037  obj_loss: 0.2389  noobj_loss: 0.1297  bbox_loss: 0.0237  cls_loss: 0.1817  \n",
      "<<<iteration:[520/878] - total_loss: 0.5254  obj_loss: 0.2550  noobj_loss: 0.1239  bbox_loss: 0.0205  cls_loss: 0.1060  \n",
      "<<<iteration:[540/878] - total_loss: 0.5006  obj_loss: 0.2439  noobj_loss: 0.1340  bbox_loss: 0.0193  cls_loss: 0.0933  \n",
      "<<<iteration:[560/878] - total_loss: 0.5135  obj_loss: 0.2363  noobj_loss: 0.1299  bbox_loss: 0.0223  cls_loss: 0.1010  \n",
      "<<<iteration:[580/878] - total_loss: 0.5740  obj_loss: 0.2314  noobj_loss: 0.1253  bbox_loss: 0.0265  cls_loss: 0.1475  \n",
      "<<<iteration:[600/878] - total_loss: 0.5573  obj_loss: 0.2353  noobj_loss: 0.1387  bbox_loss: 0.0288  cls_loss: 0.1089  \n",
      "<<<iteration:[620/878] - total_loss: 0.5172  obj_loss: 0.2165  noobj_loss: 0.1262  bbox_loss: 0.0268  cls_loss: 0.1034  \n",
      "<<<iteration:[640/878] - total_loss: 0.5394  obj_loss: 0.2462  noobj_loss: 0.1492  bbox_loss: 0.0209  cls_loss: 0.1144  \n",
      "<<<iteration:[660/878] - total_loss: 0.5869  obj_loss: 0.2302  noobj_loss: 0.1469  bbox_loss: 0.0267  cls_loss: 0.1497  \n",
      "<<<iteration:[680/878] - total_loss: 0.5086  obj_loss: 0.2328  noobj_loss: 0.1337  bbox_loss: 0.0229  cls_loss: 0.0944  \n",
      "<<<iteration:[700/878] - total_loss: 0.4990  obj_loss: 0.2383  noobj_loss: 0.1213  bbox_loss: 0.0206  cls_loss: 0.0969  \n",
      "<<<iteration:[720/878] - total_loss: 0.5806  obj_loss: 0.2376  noobj_loss: 0.1467  bbox_loss: 0.0240  cls_loss: 0.1499  \n",
      "<<<iteration:[740/878] - total_loss: 0.5545  obj_loss: 0.2293  noobj_loss: 0.1321  bbox_loss: 0.0229  cls_loss: 0.1449  \n",
      "<<<iteration:[760/878] - total_loss: 0.5857  obj_loss: 0.2345  noobj_loss: 0.1399  bbox_loss: 0.0318  cls_loss: 0.1222  \n",
      "<<<iteration:[780/878] - total_loss: 0.4891  obj_loss: 0.2407  noobj_loss: 0.1292  bbox_loss: 0.0220  cls_loss: 0.0738  \n",
      "<<<iteration:[800/878] - total_loss: 0.5772  obj_loss: 0.2722  noobj_loss: 0.1489  bbox_loss: 0.0232  cls_loss: 0.1145  \n",
      "<<<iteration:[820/878] - total_loss: 0.5966  obj_loss: 0.2709  noobj_loss: 0.1393  bbox_loss: 0.0267  cls_loss: 0.1226  \n",
      "<<<iteration:[840/878] - total_loss: 0.6182  obj_loss: 0.2658  noobj_loss: 0.1302  bbox_loss: 0.0278  cls_loss: 0.1486  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<<<iteration:[860/878] - total_loss: 0.5611  obj_loss: 0.2584  noobj_loss: 0.1354  bbox_loss: 0.0253  cls_loss: 0.1084  \n",
      "\n",
      "epoch:91/100 - Train Loss: 0.5679, Val Loss: 1.1688\n",
      "\n",
      "<<<iteration:[20/878] - total_loss: 0.6307  obj_loss: 0.2640  noobj_loss: 0.1427  bbox_loss: 0.0278  cls_loss: 0.1561  \n",
      "<<<iteration:[40/878] - total_loss: 0.6992  obj_loss: 0.2660  noobj_loss: 0.1304  bbox_loss: 0.0424  cls_loss: 0.1561  \n",
      "<<<iteration:[60/878] - total_loss: 0.6747  obj_loss: 0.2839  noobj_loss: 0.1607  bbox_loss: 0.0233  cls_loss: 0.1941  \n",
      "<<<iteration:[80/878] - total_loss: 0.5498  obj_loss: 0.2385  noobj_loss: 0.1347  bbox_loss: 0.0235  cls_loss: 0.1262  \n",
      "<<<iteration:[100/878] - total_loss: 0.5311  obj_loss: 0.2588  noobj_loss: 0.1578  bbox_loss: 0.0203  cls_loss: 0.0917  \n",
      "<<<iteration:[120/878] - total_loss: 0.5870  obj_loss: 0.2905  noobj_loss: 0.1350  bbox_loss: 0.0213  cls_loss: 0.1225  \n",
      "<<<iteration:[140/878] - total_loss: 0.6083  obj_loss: 0.2222  noobj_loss: 0.1392  bbox_loss: 0.0248  cls_loss: 0.1925  \n",
      "<<<iteration:[160/878] - total_loss: 0.5222  obj_loss: 0.2403  noobj_loss: 0.1279  bbox_loss: 0.0286  cls_loss: 0.0748  \n",
      "<<<iteration:[180/878] - total_loss: 0.5680  obj_loss: 0.2218  noobj_loss: 0.1443  bbox_loss: 0.0274  cls_loss: 0.1369  \n",
      "<<<iteration:[200/878] - total_loss: 0.6564  obj_loss: 0.2715  noobj_loss: 0.1402  bbox_loss: 0.0258  cls_loss: 0.1859  \n",
      "<<<iteration:[220/878] - total_loss: 0.5139  obj_loss: 0.2212  noobj_loss: 0.1242  bbox_loss: 0.0250  cls_loss: 0.1056  \n",
      "<<<iteration:[240/878] - total_loss: 0.6125  obj_loss: 0.2590  noobj_loss: 0.1184  bbox_loss: 0.0238  cls_loss: 0.1755  \n",
      "<<<iteration:[260/878] - total_loss: 0.5041  obj_loss: 0.2675  noobj_loss: 0.1210  bbox_loss: 0.0201  cls_loss: 0.0754  \n",
      "<<<iteration:[280/878] - total_loss: 0.5169  obj_loss: 0.2523  noobj_loss: 0.1131  bbox_loss: 0.0224  cls_loss: 0.0959  \n",
      "<<<iteration:[300/878] - total_loss: 0.4984  obj_loss: 0.2317  noobj_loss: 0.1275  bbox_loss: 0.0229  cls_loss: 0.0884  \n",
      "<<<iteration:[320/878] - total_loss: 0.5129  obj_loss: 0.2425  noobj_loss: 0.1418  bbox_loss: 0.0231  cls_loss: 0.0840  \n",
      "<<<iteration:[340/878] - total_loss: 0.4732  obj_loss: 0.2357  noobj_loss: 0.1319  bbox_loss: 0.0220  cls_loss: 0.0617  \n",
      "<<<iteration:[360/878] - total_loss: 0.5456  obj_loss: 0.2533  noobj_loss: 0.1167  bbox_loss: 0.0190  cls_loss: 0.1388  \n",
      "<<<iteration:[380/878] - total_loss: 0.6899  obj_loss: 0.2230  noobj_loss: 0.1449  bbox_loss: 0.0563  cls_loss: 0.1132  \n",
      "<<<iteration:[400/878] - total_loss: 0.5340  obj_loss: 0.2165  noobj_loss: 0.1269  bbox_loss: 0.0228  cls_loss: 0.1402  \n",
      "<<<iteration:[420/878] - total_loss: 0.7070  obj_loss: 0.2077  noobj_loss: 0.1286  bbox_loss: 0.0629  cls_loss: 0.1206  \n",
      "<<<iteration:[440/878] - total_loss: 0.5071  obj_loss: 0.2142  noobj_loss: 0.1146  bbox_loss: 0.0275  cls_loss: 0.0983  \n",
      "<<<iteration:[460/878] - total_loss: 0.5471  obj_loss: 0.2610  noobj_loss: 0.1261  bbox_loss: 0.0272  cls_loss: 0.0872  \n",
      "<<<iteration:[480/878] - total_loss: 0.5889  obj_loss: 0.2910  noobj_loss: 0.1293  bbox_loss: 0.0293  cls_loss: 0.0868  \n",
      "<<<iteration:[500/878] - total_loss: 0.5203  obj_loss: 0.2520  noobj_loss: 0.1328  bbox_loss: 0.0212  cls_loss: 0.0960  \n",
      "<<<iteration:[520/878] - total_loss: 0.5040  obj_loss: 0.2554  noobj_loss: 0.1179  bbox_loss: 0.0221  cls_loss: 0.0793  \n",
      "<<<iteration:[540/878] - total_loss: 0.5900  obj_loss: 0.2438  noobj_loss: 0.1330  bbox_loss: 0.0257  cls_loss: 0.1509  \n",
      "<<<iteration:[560/878] - total_loss: 0.5541  obj_loss: 0.2667  noobj_loss: 0.1396  bbox_loss: 0.0213  cls_loss: 0.1109  \n",
      "<<<iteration:[580/878] - total_loss: 0.6938  obj_loss: 0.2292  noobj_loss: 0.1221  bbox_loss: 0.0525  cls_loss: 0.1409  \n",
      "<<<iteration:[600/878] - total_loss: 0.6086  obj_loss: 0.2553  noobj_loss: 0.1377  bbox_loss: 0.0231  cls_loss: 0.1691  \n",
      "<<<iteration:[620/878] - total_loss: 0.5894  obj_loss: 0.2224  noobj_loss: 0.1608  bbox_loss: 0.0315  cls_loss: 0.1290  \n",
      "<<<iteration:[640/878] - total_loss: 0.5483  obj_loss: 0.2193  noobj_loss: 0.1332  bbox_loss: 0.0333  cls_loss: 0.0957  \n",
      "<<<iteration:[660/878] - total_loss: 0.5435  obj_loss: 0.2605  noobj_loss: 0.1389  bbox_loss: 0.0237  cls_loss: 0.0948  \n",
      "<<<iteration:[680/878] - total_loss: 0.5287  obj_loss: 0.2106  noobj_loss: 0.1355  bbox_loss: 0.0283  cls_loss: 0.1085  \n",
      "<<<iteration:[700/878] - total_loss: 0.5789  obj_loss: 0.2477  noobj_loss: 0.1295  bbox_loss: 0.0289  cls_loss: 0.1218  \n",
      "<<<iteration:[720/878] - total_loss: 0.5284  obj_loss: 0.2377  noobj_loss: 0.1192  bbox_loss: 0.0234  cls_loss: 0.1142  \n",
      "<<<iteration:[740/878] - total_loss: 0.5935  obj_loss: 0.2410  noobj_loss: 0.1451  bbox_loss: 0.0274  cls_loss: 0.1430  \n",
      "<<<iteration:[760/878] - total_loss: 0.5502  obj_loss: 0.2218  noobj_loss: 0.1080  bbox_loss: 0.0294  cls_loss: 0.1276  \n",
      "<<<iteration:[780/878] - total_loss: 0.5574  obj_loss: 0.2442  noobj_loss: 0.1500  bbox_loss: 0.0236  cls_loss: 0.1201  \n",
      "<<<iteration:[800/878] - total_loss: 0.5443  obj_loss: 0.2521  noobj_loss: 0.1255  bbox_loss: 0.0230  cls_loss: 0.1143  \n",
      "<<<iteration:[820/878] - total_loss: 0.5694  obj_loss: 0.2407  noobj_loss: 0.1275  bbox_loss: 0.0243  cls_loss: 0.1433  \n",
      "<<<iteration:[840/878] - total_loss: 0.5992  obj_loss: 0.2386  noobj_loss: 0.1246  bbox_loss: 0.0219  cls_loss: 0.1887  \n",
      "<<<iteration:[860/878] - total_loss: 0.6328  obj_loss: 0.2388  noobj_loss: 0.1238  bbox_loss: 0.0264  cls_loss: 0.1999  \n",
      "\n",
      "epoch:92/100 - Train Loss: 0.5700, Val Loss: 1.1650\n",
      "\n",
      "<<<iteration:[20/878] - total_loss: 0.6454  obj_loss: 0.2751  noobj_loss: 0.1420  bbox_loss: 0.0311  cls_loss: 0.1439  \n",
      "<<<iteration:[40/878] - total_loss: 0.7469  obj_loss: 0.2718  noobj_loss: 0.1598  bbox_loss: 0.0498  cls_loss: 0.1461  \n",
      "<<<iteration:[60/878] - total_loss: 0.5484  obj_loss: 0.2110  noobj_loss: 0.1277  bbox_loss: 0.0244  cls_loss: 0.1517  \n",
      "<<<iteration:[80/878] - total_loss: 0.5286  obj_loss: 0.2398  noobj_loss: 0.1269  bbox_loss: 0.0237  cls_loss: 0.1070  \n",
      "<<<iteration:[100/878] - total_loss: 0.4812  obj_loss: 0.2054  noobj_loss: 0.1219  bbox_loss: 0.0252  cls_loss: 0.0887  \n",
      "<<<iteration:[120/878] - total_loss: 0.6213  obj_loss: 0.2616  noobj_loss: 0.1369  bbox_loss: 0.0277  cls_loss: 0.1528  \n",
      "<<<iteration:[140/878] - total_loss: 0.5533  obj_loss: 0.2241  noobj_loss: 0.1523  bbox_loss: 0.0262  cls_loss: 0.1219  \n",
      "<<<iteration:[160/878] - total_loss: 0.5596  obj_loss: 0.2484  noobj_loss: 0.1475  bbox_loss: 0.0261  cls_loss: 0.1070  \n",
      "<<<iteration:[180/878] - total_loss: 0.5092  obj_loss: 0.2341  noobj_loss: 0.1206  bbox_loss: 0.0247  cls_loss: 0.0912  \n",
      "<<<iteration:[200/878] - total_loss: 0.5265  obj_loss: 0.2353  noobj_loss: 0.1260  bbox_loss: 0.0232  cls_loss: 0.1120  \n",
      "<<<iteration:[220/878] - total_loss: 0.5679  obj_loss: 0.2890  noobj_loss: 0.1299  bbox_loss: 0.0216  cls_loss: 0.1060  \n",
      "<<<iteration:[240/878] - total_loss: 0.5170  obj_loss: 0.2187  noobj_loss: 0.1351  bbox_loss: 0.0224  cls_loss: 0.1189  \n",
      "<<<iteration:[260/878] - total_loss: 0.5375  obj_loss: 0.2274  noobj_loss: 0.1140  bbox_loss: 0.0221  cls_loss: 0.1425  \n",
      "<<<iteration:[280/878] - total_loss: 0.5826  obj_loss: 0.2582  noobj_loss: 0.1310  bbox_loss: 0.0254  cls_loss: 0.1318  \n",
      "<<<iteration:[300/878] - total_loss: 0.6001  obj_loss: 0.2600  noobj_loss: 0.1397  bbox_loss: 0.0234  cls_loss: 0.1534  \n",
      "<<<iteration:[320/878] - total_loss: 0.6899  obj_loss: 0.2828  noobj_loss: 0.1422  bbox_loss: 0.0307  cls_loss: 0.1828  \n",
      "<<<iteration:[340/878] - total_loss: 0.4965  obj_loss: 0.2458  noobj_loss: 0.1243  bbox_loss: 0.0228  cls_loss: 0.0745  \n",
      "<<<iteration:[360/878] - total_loss: 0.5293  obj_loss: 0.2387  noobj_loss: 0.1295  bbox_loss: 0.0252  cls_loss: 0.1001  \n",
      "<<<iteration:[380/878] - total_loss: 0.6076  obj_loss: 0.2696  noobj_loss: 0.1501  bbox_loss: 0.0220  cls_loss: 0.1531  \n",
      "<<<iteration:[400/878] - total_loss: 0.4879  obj_loss: 0.2509  noobj_loss: 0.1491  bbox_loss: 0.0192  cls_loss: 0.0663  \n",
      "<<<iteration:[420/878] - total_loss: 0.5645  obj_loss: 0.2285  noobj_loss: 0.1304  bbox_loss: 0.0277  cls_loss: 0.1321  \n",
      "<<<iteration:[440/878] - total_loss: 0.5359  obj_loss: 0.2735  noobj_loss: 0.1410  bbox_loss: 0.0236  cls_loss: 0.0741  \n",
      "<<<iteration:[460/878] - total_loss: 0.4540  obj_loss: 0.2207  noobj_loss: 0.1301  bbox_loss: 0.0188  cls_loss: 0.0742  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<<<iteration:[480/878] - total_loss: 0.5381  obj_loss: 0.2380  noobj_loss: 0.1543  bbox_loss: 0.0262  cls_loss: 0.0917  \n",
      "<<<iteration:[500/878] - total_loss: 0.5779  obj_loss: 0.2427  noobj_loss: 0.1402  bbox_loss: 0.0204  cls_loss: 0.1629  \n",
      "<<<iteration:[520/878] - total_loss: 0.7001  obj_loss: 0.2421  noobj_loss: 0.1374  bbox_loss: 0.0255  cls_loss: 0.2616  \n",
      "<<<iteration:[540/878] - total_loss: 0.5161  obj_loss: 0.2621  noobj_loss: 0.1387  bbox_loss: 0.0217  cls_loss: 0.0764  \n",
      "<<<iteration:[560/878] - total_loss: 0.7050  obj_loss: 0.2484  noobj_loss: 0.1272  bbox_loss: 0.0302  cls_loss: 0.2419  \n",
      "<<<iteration:[580/878] - total_loss: 0.6008  obj_loss: 0.2734  noobj_loss: 0.1492  bbox_loss: 0.0247  cls_loss: 0.1291  \n",
      "<<<iteration:[600/878] - total_loss: 0.5625  obj_loss: 0.2510  noobj_loss: 0.1298  bbox_loss: 0.0246  cls_loss: 0.1235  \n",
      "<<<iteration:[620/878] - total_loss: 0.5676  obj_loss: 0.2871  noobj_loss: 0.1392  bbox_loss: 0.0197  cls_loss: 0.1126  \n",
      "<<<iteration:[640/878] - total_loss: 0.5774  obj_loss: 0.2450  noobj_loss: 0.1277  bbox_loss: 0.0245  cls_loss: 0.1462  \n",
      "<<<iteration:[660/878] - total_loss: 0.5115  obj_loss: 0.2476  noobj_loss: 0.1401  bbox_loss: 0.0242  cls_loss: 0.0727  \n",
      "<<<iteration:[680/878] - total_loss: 0.4752  obj_loss: 0.2152  noobj_loss: 0.1305  bbox_loss: 0.0228  cls_loss: 0.0809  \n",
      "<<<iteration:[700/878] - total_loss: 0.5251  obj_loss: 0.2447  noobj_loss: 0.1182  bbox_loss: 0.0206  cls_loss: 0.1184  \n",
      "<<<iteration:[720/878] - total_loss: 0.6473  obj_loss: 0.2933  noobj_loss: 0.1503  bbox_loss: 0.0253  cls_loss: 0.1522  \n",
      "<<<iteration:[740/878] - total_loss: 0.5343  obj_loss: 0.2069  noobj_loss: 0.1398  bbox_loss: 0.0260  cls_loss: 0.1276  \n",
      "<<<iteration:[760/878] - total_loss: 0.5045  obj_loss: 0.2340  noobj_loss: 0.1274  bbox_loss: 0.0211  cls_loss: 0.1012  \n",
      "<<<iteration:[780/878] - total_loss: 0.5319  obj_loss: 0.2608  noobj_loss: 0.1313  bbox_loss: 0.0218  cls_loss: 0.0962  \n",
      "<<<iteration:[800/878] - total_loss: 0.5582  obj_loss: 0.1933  noobj_loss: 0.1335  bbox_loss: 0.0318  cls_loss: 0.1391  \n",
      "<<<iteration:[820/878] - total_loss: 0.5482  obj_loss: 0.2554  noobj_loss: 0.1233  bbox_loss: 0.0223  cls_loss: 0.1196  \n",
      "<<<iteration:[840/878] - total_loss: 0.4920  obj_loss: 0.1950  noobj_loss: 0.1215  bbox_loss: 0.0270  cls_loss: 0.1013  \n",
      "<<<iteration:[860/878] - total_loss: 0.5267  obj_loss: 0.2424  noobj_loss: 0.1210  bbox_loss: 0.0224  cls_loss: 0.1120  \n",
      "\n",
      "epoch:93/100 - Train Loss: 0.5605, Val Loss: 1.7312\n",
      "\n",
      "<<<iteration:[20/878] - total_loss: 1.0537  obj_loss: 0.2287  noobj_loss: 0.1365  bbox_loss: 0.1278  cls_loss: 0.1175  \n",
      "<<<iteration:[40/878] - total_loss: 0.5662  obj_loss: 0.2567  noobj_loss: 0.1288  bbox_loss: 0.0262  cls_loss: 0.1143  \n",
      "<<<iteration:[60/878] - total_loss: 0.5281  obj_loss: 0.2213  noobj_loss: 0.1263  bbox_loss: 0.0256  cls_loss: 0.1155  \n",
      "<<<iteration:[80/878] - total_loss: 0.5598  obj_loss: 0.2511  noobj_loss: 0.1115  bbox_loss: 0.0283  cls_loss: 0.1115  \n",
      "<<<iteration:[100/878] - total_loss: 0.5592  obj_loss: 0.2306  noobj_loss: 0.1309  bbox_loss: 0.0384  cls_loss: 0.0711  \n",
      "<<<iteration:[120/878] - total_loss: 0.5234  obj_loss: 0.2502  noobj_loss: 0.1257  bbox_loss: 0.0226  cls_loss: 0.0973  \n",
      "<<<iteration:[140/878] - total_loss: 0.5914  obj_loss: 0.3023  noobj_loss: 0.1482  bbox_loss: 0.0236  cls_loss: 0.0968  \n",
      "<<<iteration:[160/878] - total_loss: 0.5417  obj_loss: 0.2310  noobj_loss: 0.1353  bbox_loss: 0.0282  cls_loss: 0.1021  \n",
      "<<<iteration:[180/878] - total_loss: 0.5557  obj_loss: 0.2422  noobj_loss: 0.1359  bbox_loss: 0.0211  cls_loss: 0.1399  \n",
      "<<<iteration:[200/878] - total_loss: 0.4852  obj_loss: 0.2235  noobj_loss: 0.1244  bbox_loss: 0.0244  cls_loss: 0.0774  \n",
      "<<<iteration:[220/878] - total_loss: 0.5653  obj_loss: 0.2748  noobj_loss: 0.1333  bbox_loss: 0.0212  cls_loss: 0.1179  \n",
      "<<<iteration:[240/878] - total_loss: 0.4806  obj_loss: 0.2172  noobj_loss: 0.1282  bbox_loss: 0.0184  cls_loss: 0.1072  \n",
      "<<<iteration:[260/878] - total_loss: 0.6101  obj_loss: 0.2291  noobj_loss: 0.1585  bbox_loss: 0.0386  cls_loss: 0.1085  \n",
      "<<<iteration:[280/878] - total_loss: 0.8758  obj_loss: 0.1900  noobj_loss: 0.1189  bbox_loss: 0.1083  cls_loss: 0.0848  \n",
      "<<<iteration:[300/878] - total_loss: 0.6761  obj_loss: 0.2481  noobj_loss: 0.1321  bbox_loss: 0.0454  cls_loss: 0.1348  \n",
      "<<<iteration:[320/878] - total_loss: 0.5729  obj_loss: 0.2891  noobj_loss: 0.1247  bbox_loss: 0.0260  cls_loss: 0.0913  \n",
      "<<<iteration:[340/878] - total_loss: 1.2273  obj_loss: 0.2228  noobj_loss: 0.1477  bbox_loss: 0.1536  cls_loss: 0.1627  \n",
      "<<<iteration:[360/878] - total_loss: 0.8316  obj_loss: 0.2432  noobj_loss: 0.1330  bbox_loss: 0.0651  cls_loss: 0.1964  \n",
      "<<<iteration:[380/878] - total_loss: 0.5526  obj_loss: 0.2213  noobj_loss: 0.1202  bbox_loss: 0.0309  cls_loss: 0.1168  \n",
      "<<<iteration:[400/878] - total_loss: 0.7265  obj_loss: 0.2773  noobj_loss: 0.1364  bbox_loss: 0.0549  cls_loss: 0.1065  \n",
      "<<<iteration:[420/878] - total_loss: 0.7379  obj_loss: 0.2438  noobj_loss: 0.1266  bbox_loss: 0.0629  cls_loss: 0.1163  \n",
      "<<<iteration:[440/878] - total_loss: 0.6267  obj_loss: 0.2310  noobj_loss: 0.1305  bbox_loss: 0.0310  cls_loss: 0.1755  \n",
      "<<<iteration:[460/878] - total_loss: 0.5169  obj_loss: 0.1889  noobj_loss: 0.1133  bbox_loss: 0.0249  cls_loss: 0.1470  \n",
      "<<<iteration:[480/878] - total_loss: 0.7902  obj_loss: 0.2219  noobj_loss: 0.1159  bbox_loss: 0.0613  cls_loss: 0.2037  \n",
      "<<<iteration:[500/878] - total_loss: 0.7309  obj_loss: 0.2245  noobj_loss: 0.1268  bbox_loss: 0.0747  cls_loss: 0.0695  \n",
      "<<<iteration:[520/878] - total_loss: 0.6235  obj_loss: 0.2418  noobj_loss: 0.1297  bbox_loss: 0.0272  cls_loss: 0.1808  \n",
      "<<<iteration:[540/878] - total_loss: 0.5346  obj_loss: 0.2702  noobj_loss: 0.1410  bbox_loss: 0.0212  cls_loss: 0.0877  \n",
      "<<<iteration:[560/878] - total_loss: 0.5275  obj_loss: 0.1858  noobj_loss: 0.1312  bbox_loss: 0.0271  cls_loss: 0.1409  \n",
      "<<<iteration:[580/878] - total_loss: 0.7358  obj_loss: 0.1999  noobj_loss: 0.1184  bbox_loss: 0.0709  cls_loss: 0.1221  \n",
      "<<<iteration:[600/878] - total_loss: 0.5986  obj_loss: 0.2635  noobj_loss: 0.1284  bbox_loss: 0.0312  cls_loss: 0.1150  \n",
      "<<<iteration:[620/878] - total_loss: 0.9718  obj_loss: 0.2355  noobj_loss: 0.1401  bbox_loss: 0.1074  cls_loss: 0.1293  \n",
      "<<<iteration:[640/878] - total_loss: 0.6292  obj_loss: 0.2307  noobj_loss: 0.1183  bbox_loss: 0.0325  cls_loss: 0.1770  \n",
      "<<<iteration:[660/878] - total_loss: 0.6092  obj_loss: 0.2243  noobj_loss: 0.1408  bbox_loss: 0.0341  cls_loss: 0.1438  \n",
      "<<<iteration:[680/878] - total_loss: 0.6539  obj_loss: 0.2378  noobj_loss: 0.1376  bbox_loss: 0.0450  cls_loss: 0.1224  \n",
      "<<<iteration:[700/878] - total_loss: 0.5314  obj_loss: 0.1957  noobj_loss: 0.1175  bbox_loss: 0.0365  cls_loss: 0.0944  \n",
      "<<<iteration:[720/878] - total_loss: 0.5143  obj_loss: 0.2461  noobj_loss: 0.1347  bbox_loss: 0.0222  cls_loss: 0.0900  \n",
      "<<<iteration:[740/878] - total_loss: 0.6322  obj_loss: 0.1920  noobj_loss: 0.1382  bbox_loss: 0.0369  cls_loss: 0.1868  \n",
      "<<<iteration:[760/878] - total_loss: 0.6036  obj_loss: 0.2462  noobj_loss: 0.1245  bbox_loss: 0.0240  cls_loss: 0.1751  \n",
      "<<<iteration:[780/878] - total_loss: 0.5464  obj_loss: 0.2654  noobj_loss: 0.1404  bbox_loss: 0.0261  cls_loss: 0.0804  \n",
      "<<<iteration:[800/878] - total_loss: 0.6210  obj_loss: 0.2488  noobj_loss: 0.1269  bbox_loss: 0.0409  cls_loss: 0.1042  \n",
      "<<<iteration:[820/878] - total_loss: 0.5698  obj_loss: 0.2180  noobj_loss: 0.1509  bbox_loss: 0.0300  cls_loss: 0.1263  \n",
      "<<<iteration:[840/878] - total_loss: 0.4867  obj_loss: 0.2188  noobj_loss: 0.1225  bbox_loss: 0.0230  cls_loss: 0.0918  \n",
      "<<<iteration:[860/878] - total_loss: 0.6657  obj_loss: 0.2268  noobj_loss: 0.1231  bbox_loss: 0.0495  cls_loss: 0.1296  \n",
      "\n",
      "epoch:94/100 - Train Loss: 0.6399, Val Loss: 1.1648\n",
      "\n",
      "<<<iteration:[20/878] - total_loss: 0.6198  obj_loss: 0.2561  noobj_loss: 0.1376  bbox_loss: 0.0342  cls_loss: 0.1241  \n",
      "<<<iteration:[40/878] - total_loss: 0.5599  obj_loss: 0.2522  noobj_loss: 0.1287  bbox_loss: 0.0269  cls_loss: 0.1090  \n",
      "<<<iteration:[60/878] - total_loss: 0.4757  obj_loss: 0.2265  noobj_loss: 0.1213  bbox_loss: 0.0207  cls_loss: 0.0854  \n",
      "<<<iteration:[80/878] - total_loss: 0.6221  obj_loss: 0.2242  noobj_loss: 0.1213  bbox_loss: 0.0386  cls_loss: 0.1440  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<<<iteration:[100/878] - total_loss: 0.5609  obj_loss: 0.2218  noobj_loss: 0.1196  bbox_loss: 0.0246  cls_loss: 0.1563  \n",
      "<<<iteration:[120/878] - total_loss: 0.5086  obj_loss: 0.2306  noobj_loss: 0.1292  bbox_loss: 0.0272  cls_loss: 0.0774  \n",
      "<<<iteration:[140/878] - total_loss: 0.6526  obj_loss: 0.2530  noobj_loss: 0.1328  bbox_loss: 0.0248  cls_loss: 0.2093  \n",
      "<<<iteration:[160/878] - total_loss: 0.5826  obj_loss: 0.2424  noobj_loss: 0.1251  bbox_loss: 0.0293  cls_loss: 0.1313  \n",
      "<<<iteration:[180/878] - total_loss: 0.6084  obj_loss: 0.2038  noobj_loss: 0.1370  bbox_loss: 0.0336  cls_loss: 0.1681  \n",
      "<<<iteration:[200/878] - total_loss: 0.5426  obj_loss: 0.2237  noobj_loss: 0.1219  bbox_loss: 0.0236  cls_loss: 0.1400  \n",
      "<<<iteration:[220/878] - total_loss: 0.5615  obj_loss: 0.2398  noobj_loss: 0.1416  bbox_loss: 0.0253  cls_loss: 0.1242  \n",
      "<<<iteration:[240/878] - total_loss: 0.5134  obj_loss: 0.2097  noobj_loss: 0.1537  bbox_loss: 0.0283  cls_loss: 0.0856  \n",
      "<<<iteration:[260/878] - total_loss: 0.5257  obj_loss: 0.2415  noobj_loss: 0.1275  bbox_loss: 0.0226  cls_loss: 0.1074  \n",
      "<<<iteration:[280/878] - total_loss: 0.5699  obj_loss: 0.2615  noobj_loss: 0.1277  bbox_loss: 0.0264  cls_loss: 0.1126  \n",
      "<<<iteration:[300/878] - total_loss: 0.5104  obj_loss: 0.2302  noobj_loss: 0.1315  bbox_loss: 0.0233  cls_loss: 0.0982  \n",
      "<<<iteration:[320/878] - total_loss: 0.5987  obj_loss: 0.2149  noobj_loss: 0.1415  bbox_loss: 0.0314  cls_loss: 0.1562  \n",
      "<<<iteration:[340/878] - total_loss: 0.5843  obj_loss: 0.2534  noobj_loss: 0.1439  bbox_loss: 0.0259  cls_loss: 0.1296  \n",
      "<<<iteration:[360/878] - total_loss: 0.6288  obj_loss: 0.2365  noobj_loss: 0.1301  bbox_loss: 0.0391  cls_loss: 0.1318  \n",
      "<<<iteration:[380/878] - total_loss: 0.5566  obj_loss: 0.2382  noobj_loss: 0.1320  bbox_loss: 0.0284  cls_loss: 0.1104  \n",
      "<<<iteration:[400/878] - total_loss: 0.5308  obj_loss: 0.2329  noobj_loss: 0.1399  bbox_loss: 0.0254  cls_loss: 0.1009  \n",
      "<<<iteration:[420/878] - total_loss: 0.5860  obj_loss: 0.2565  noobj_loss: 0.1513  bbox_loss: 0.0260  cls_loss: 0.1237  \n",
      "<<<iteration:[440/878] - total_loss: 0.5748  obj_loss: 0.2594  noobj_loss: 0.1309  bbox_loss: 0.0238  cls_loss: 0.1311  \n",
      "<<<iteration:[460/878] - total_loss: 0.5112  obj_loss: 0.2049  noobj_loss: 0.1394  bbox_loss: 0.0246  cls_loss: 0.1136  \n",
      "<<<iteration:[480/878] - total_loss: 0.5679  obj_loss: 0.2575  noobj_loss: 0.1251  bbox_loss: 0.0224  cls_loss: 0.1361  \n",
      "<<<iteration:[500/878] - total_loss: 0.5997  obj_loss: 0.2690  noobj_loss: 0.1333  bbox_loss: 0.0226  cls_loss: 0.1511  \n",
      "<<<iteration:[520/878] - total_loss: 0.5133  obj_loss: 0.2477  noobj_loss: 0.1355  bbox_loss: 0.0226  cls_loss: 0.0847  \n",
      "<<<iteration:[540/878] - total_loss: 0.5266  obj_loss: 0.2209  noobj_loss: 0.1326  bbox_loss: 0.0273  cls_loss: 0.1031  \n",
      "<<<iteration:[560/878] - total_loss: 0.5899  obj_loss: 0.2500  noobj_loss: 0.1368  bbox_loss: 0.0226  cls_loss: 0.1584  \n",
      "<<<iteration:[580/878] - total_loss: 0.5411  obj_loss: 0.2136  noobj_loss: 0.1346  bbox_loss: 0.0232  cls_loss: 0.1440  \n",
      "<<<iteration:[600/878] - total_loss: 0.6184  obj_loss: 0.2670  noobj_loss: 0.1312  bbox_loss: 0.0275  cls_loss: 0.1483  \n",
      "<<<iteration:[620/878] - total_loss: 0.5500  obj_loss: 0.2368  noobj_loss: 0.1295  bbox_loss: 0.0219  cls_loss: 0.1389  \n",
      "<<<iteration:[640/878] - total_loss: 0.4752  obj_loss: 0.2184  noobj_loss: 0.1152  bbox_loss: 0.0263  cls_loss: 0.0679  \n",
      "<<<iteration:[660/878] - total_loss: 0.5587  obj_loss: 0.2421  noobj_loss: 0.1463  bbox_loss: 0.0276  cls_loss: 0.1057  \n",
      "<<<iteration:[680/878] - total_loss: 0.5331  obj_loss: 0.2436  noobj_loss: 0.1395  bbox_loss: 0.0240  cls_loss: 0.0996  \n",
      "<<<iteration:[700/878] - total_loss: 0.5153  obj_loss: 0.2483  noobj_loss: 0.1277  bbox_loss: 0.0232  cls_loss: 0.0872  \n",
      "<<<iteration:[720/878] - total_loss: 0.5287  obj_loss: 0.2050  noobj_loss: 0.1229  bbox_loss: 0.0289  cls_loss: 0.1176  \n",
      "<<<iteration:[740/878] - total_loss: 0.6344  obj_loss: 0.2613  noobj_loss: 0.1282  bbox_loss: 0.0295  cls_loss: 0.1614  \n",
      "<<<iteration:[760/878] - total_loss: 0.5714  obj_loss: 0.2843  noobj_loss: 0.1414  bbox_loss: 0.0220  cls_loss: 0.1063  \n",
      "<<<iteration:[780/878] - total_loss: 0.5607  obj_loss: 0.2658  noobj_loss: 0.1417  bbox_loss: 0.0259  cls_loss: 0.0947  \n",
      "<<<iteration:[800/878] - total_loss: 0.5047  obj_loss: 0.2366  noobj_loss: 0.1310  bbox_loss: 0.0236  cls_loss: 0.0844  \n",
      "<<<iteration:[820/878] - total_loss: 0.4987  obj_loss: 0.2387  noobj_loss: 0.1460  bbox_loss: 0.0211  cls_loss: 0.0813  \n",
      "<<<iteration:[840/878] - total_loss: 0.5663  obj_loss: 0.2681  noobj_loss: 0.1337  bbox_loss: 0.0244  cls_loss: 0.1096  \n",
      "<<<iteration:[860/878] - total_loss: 0.5616  obj_loss: 0.2745  noobj_loss: 0.1592  bbox_loss: 0.0234  cls_loss: 0.0907  \n",
      "\n",
      "epoch:95/100 - Train Loss: 0.5592, Val Loss: 1.1362\n",
      "\n",
      "<<<iteration:[20/878] - total_loss: 0.5927  obj_loss: 0.2626  noobj_loss: 0.1437  bbox_loss: 0.0240  cls_loss: 0.1385  \n",
      "<<<iteration:[40/878] - total_loss: 0.5404  obj_loss: 0.2469  noobj_loss: 0.1392  bbox_loss: 0.0227  cls_loss: 0.1104  \n",
      "<<<iteration:[60/878] - total_loss: 0.5569  obj_loss: 0.2279  noobj_loss: 0.1411  bbox_loss: 0.0210  cls_loss: 0.1535  \n",
      "<<<iteration:[80/878] - total_loss: 0.4944  obj_loss: 0.2204  noobj_loss: 0.1108  bbox_loss: 0.0214  cls_loss: 0.1115  \n",
      "<<<iteration:[100/878] - total_loss: 0.5083  obj_loss: 0.2133  noobj_loss: 0.1444  bbox_loss: 0.0255  cls_loss: 0.0955  \n",
      "<<<iteration:[120/878] - total_loss: 0.4879  obj_loss: 0.2051  noobj_loss: 0.1307  bbox_loss: 0.0252  cls_loss: 0.0914  \n",
      "<<<iteration:[140/878] - total_loss: 0.5316  obj_loss: 0.2573  noobj_loss: 0.1340  bbox_loss: 0.0251  cls_loss: 0.0819  \n",
      "<<<iteration:[160/878] - total_loss: 0.4908  obj_loss: 0.2551  noobj_loss: 0.1311  bbox_loss: 0.0206  cls_loss: 0.0672  \n",
      "<<<iteration:[180/878] - total_loss: 0.4640  obj_loss: 0.2069  noobj_loss: 0.1347  bbox_loss: 0.0187  cls_loss: 0.0960  \n",
      "<<<iteration:[200/878] - total_loss: 0.6192  obj_loss: 0.2718  noobj_loss: 0.1331  bbox_loss: 0.0256  cls_loss: 0.1527  \n",
      "<<<iteration:[220/878] - total_loss: 0.5295  obj_loss: 0.2436  noobj_loss: 0.1238  bbox_loss: 0.0221  cls_loss: 0.1136  \n",
      "<<<iteration:[240/878] - total_loss: 0.5708  obj_loss: 0.2644  noobj_loss: 0.1419  bbox_loss: 0.0291  cls_loss: 0.0898  \n",
      "<<<iteration:[260/878] - total_loss: 0.5589  obj_loss: 0.2169  noobj_loss: 0.1204  bbox_loss: 0.0225  cls_loss: 0.1692  \n",
      "<<<iteration:[280/878] - total_loss: 0.6152  obj_loss: 0.2421  noobj_loss: 0.1339  bbox_loss: 0.0300  cls_loss: 0.1559  \n",
      "<<<iteration:[300/878] - total_loss: 0.5355  obj_loss: 0.2655  noobj_loss: 0.1326  bbox_loss: 0.0220  cls_loss: 0.0940  \n",
      "<<<iteration:[320/878] - total_loss: 0.5583  obj_loss: 0.2872  noobj_loss: 0.1330  bbox_loss: 0.0263  cls_loss: 0.0734  \n",
      "<<<iteration:[340/878] - total_loss: 0.5217  obj_loss: 0.2020  noobj_loss: 0.1304  bbox_loss: 0.0224  cls_loss: 0.1426  \n",
      "<<<iteration:[360/878] - total_loss: 0.5787  obj_loss: 0.2655  noobj_loss: 0.1392  bbox_loss: 0.0283  cls_loss: 0.1022  \n",
      "<<<iteration:[380/878] - total_loss: 0.4793  obj_loss: 0.2074  noobj_loss: 0.1238  bbox_loss: 0.0229  cls_loss: 0.0954  \n",
      "<<<iteration:[400/878] - total_loss: 0.6208  obj_loss: 0.2727  noobj_loss: 0.1373  bbox_loss: 0.0210  cls_loss: 0.1743  \n",
      "<<<iteration:[420/878] - total_loss: 0.6208  obj_loss: 0.2883  noobj_loss: 0.1489  bbox_loss: 0.0237  cls_loss: 0.1397  \n",
      "<<<iteration:[440/878] - total_loss: 0.5712  obj_loss: 0.2241  noobj_loss: 0.1505  bbox_loss: 0.0246  cls_loss: 0.1487  \n",
      "<<<iteration:[460/878] - total_loss: 0.5555  obj_loss: 0.2682  noobj_loss: 0.1399  bbox_loss: 0.0225  cls_loss: 0.1050  \n",
      "<<<iteration:[480/878] - total_loss: 0.6012  obj_loss: 0.2699  noobj_loss: 0.1728  bbox_loss: 0.0240  cls_loss: 0.1248  \n",
      "<<<iteration:[500/878] - total_loss: 0.4907  obj_loss: 0.2321  noobj_loss: 0.1533  bbox_loss: 0.0244  cls_loss: 0.0599  \n",
      "<<<iteration:[520/878] - total_loss: 0.6316  obj_loss: 0.2707  noobj_loss: 0.1405  bbox_loss: 0.0377  cls_loss: 0.1018  \n",
      "<<<iteration:[540/878] - total_loss: 0.6430  obj_loss: 0.2855  noobj_loss: 0.1281  bbox_loss: 0.0285  cls_loss: 0.1510  \n",
      "<<<iteration:[560/878] - total_loss: 0.5472  obj_loss: 0.2434  noobj_loss: 0.1352  bbox_loss: 0.0200  cls_loss: 0.1364  \n",
      "<<<iteration:[580/878] - total_loss: 0.5398  obj_loss: 0.2620  noobj_loss: 0.1236  bbox_loss: 0.0207  cls_loss: 0.1127  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<<<iteration:[600/878] - total_loss: 0.5566  obj_loss: 0.2819  noobj_loss: 0.1504  bbox_loss: 0.0222  cls_loss: 0.0886  \n",
      "<<<iteration:[620/878] - total_loss: 0.5644  obj_loss: 0.2771  noobj_loss: 0.1355  bbox_loss: 0.0242  cls_loss: 0.0987  \n",
      "<<<iteration:[640/878] - total_loss: 0.4689  obj_loss: 0.2173  noobj_loss: 0.1524  bbox_loss: 0.0230  cls_loss: 0.0606  \n",
      "<<<iteration:[660/878] - total_loss: 0.5371  obj_loss: 0.2449  noobj_loss: 0.1282  bbox_loss: 0.0238  cls_loss: 0.1090  \n",
      "<<<iteration:[680/878] - total_loss: 0.5292  obj_loss: 0.2287  noobj_loss: 0.1261  bbox_loss: 0.0204  cls_loss: 0.1354  \n",
      "<<<iteration:[700/878] - total_loss: 0.6235  obj_loss: 0.2992  noobj_loss: 0.1564  bbox_loss: 0.0254  cls_loss: 0.1193  \n",
      "<<<iteration:[720/878] - total_loss: 0.5227  obj_loss: 0.2397  noobj_loss: 0.1350  bbox_loss: 0.0249  cls_loss: 0.0912  \n",
      "<<<iteration:[740/878] - total_loss: 0.5102  obj_loss: 0.2201  noobj_loss: 0.1488  bbox_loss: 0.0228  cls_loss: 0.1016  \n",
      "<<<iteration:[760/878] - total_loss: 0.5643  obj_loss: 0.2681  noobj_loss: 0.1469  bbox_loss: 0.0244  cls_loss: 0.1009  \n",
      "<<<iteration:[780/878] - total_loss: 0.4660  obj_loss: 0.2092  noobj_loss: 0.1215  bbox_loss: 0.0243  cls_loss: 0.0746  \n",
      "<<<iteration:[800/878] - total_loss: 0.6019  obj_loss: 0.2457  noobj_loss: 0.1410  bbox_loss: 0.0311  cls_loss: 0.1300  \n",
      "<<<iteration:[820/878] - total_loss: 0.5965  obj_loss: 0.2217  noobj_loss: 0.1357  bbox_loss: 0.0215  cls_loss: 0.1993  \n",
      "<<<iteration:[840/878] - total_loss: 0.5367  obj_loss: 0.2673  noobj_loss: 0.1417  bbox_loss: 0.0239  cls_loss: 0.0792  \n",
      "<<<iteration:[860/878] - total_loss: 0.4441  obj_loss: 0.1974  noobj_loss: 0.1307  bbox_loss: 0.0204  cls_loss: 0.0793  \n",
      "\n",
      "epoch:96/100 - Train Loss: 0.5488, Val Loss: 1.1331\n",
      "\n",
      "<<<iteration:[20/878] - total_loss: 0.5514  obj_loss: 0.2411  noobj_loss: 0.1327  bbox_loss: 0.0273  cls_loss: 0.1074  \n",
      "<<<iteration:[40/878] - total_loss: 0.5265  obj_loss: 0.2316  noobj_loss: 0.1442  bbox_loss: 0.0242  cls_loss: 0.1019  \n",
      "<<<iteration:[60/878] - total_loss: 0.6166  obj_loss: 0.3008  noobj_loss: 0.1445  bbox_loss: 0.0258  cls_loss: 0.1144  \n",
      "<<<iteration:[80/878] - total_loss: 0.4905  obj_loss: 0.2401  noobj_loss: 0.1288  bbox_loss: 0.0218  cls_loss: 0.0768  \n",
      "<<<iteration:[100/878] - total_loss: 0.4842  obj_loss: 0.2287  noobj_loss: 0.1225  bbox_loss: 0.0207  cls_loss: 0.0906  \n",
      "<<<iteration:[120/878] - total_loss: 0.5842  obj_loss: 0.2114  noobj_loss: 0.1291  bbox_loss: 0.0363  cls_loss: 0.1268  \n",
      "<<<iteration:[140/878] - total_loss: 0.5344  obj_loss: 0.2045  noobj_loss: 0.1371  bbox_loss: 0.0237  cls_loss: 0.1427  \n",
      "<<<iteration:[160/878] - total_loss: 0.5622  obj_loss: 0.2685  noobj_loss: 0.1384  bbox_loss: 0.0266  cls_loss: 0.0914  \n",
      "<<<iteration:[180/878] - total_loss: 0.5921  obj_loss: 0.2400  noobj_loss: 0.1488  bbox_loss: 0.0314  cls_loss: 0.1208  \n",
      "<<<iteration:[200/878] - total_loss: 0.5420  obj_loss: 0.2283  noobj_loss: 0.1329  bbox_loss: 0.0279  cls_loss: 0.1077  \n",
      "<<<iteration:[220/878] - total_loss: 0.5194  obj_loss: 0.2662  noobj_loss: 0.1289  bbox_loss: 0.0182  cls_loss: 0.0975  \n",
      "<<<iteration:[240/878] - total_loss: 0.5679  obj_loss: 0.2800  noobj_loss: 0.1440  bbox_loss: 0.0222  cls_loss: 0.1052  \n",
      "<<<iteration:[260/878] - total_loss: 0.5329  obj_loss: 0.2249  noobj_loss: 0.1287  bbox_loss: 0.0214  cls_loss: 0.1365  \n",
      "<<<iteration:[280/878] - total_loss: 0.4703  obj_loss: 0.2422  noobj_loss: 0.1292  bbox_loss: 0.0226  cls_loss: 0.0506  \n",
      "<<<iteration:[300/878] - total_loss: 0.6273  obj_loss: 0.2845  noobj_loss: 0.1405  bbox_loss: 0.0244  cls_loss: 0.1506  \n",
      "<<<iteration:[320/878] - total_loss: 0.8136  obj_loss: 0.2206  noobj_loss: 0.1413  bbox_loss: 0.0807  cls_loss: 0.1185  \n",
      "<<<iteration:[340/878] - total_loss: 0.5225  obj_loss: 0.2448  noobj_loss: 0.1333  bbox_loss: 0.0241  cls_loss: 0.0907  \n",
      "<<<iteration:[360/878] - total_loss: 0.5147  obj_loss: 0.2292  noobj_loss: 0.1437  bbox_loss: 0.0218  cls_loss: 0.1048  \n",
      "<<<iteration:[380/878] - total_loss: 0.5415  obj_loss: 0.1824  noobj_loss: 0.1363  bbox_loss: 0.0310  cls_loss: 0.1357  \n",
      "<<<iteration:[400/878] - total_loss: 0.5588  obj_loss: 0.2698  noobj_loss: 0.1243  bbox_loss: 0.0289  cls_loss: 0.0823  \n",
      "<<<iteration:[420/878] - total_loss: 0.5652  obj_loss: 0.2653  noobj_loss: 0.1401  bbox_loss: 0.0246  cls_loss: 0.1069  \n",
      "<<<iteration:[440/878] - total_loss: 0.5135  obj_loss: 0.2390  noobj_loss: 0.1431  bbox_loss: 0.0208  cls_loss: 0.0989  \n",
      "<<<iteration:[460/878] - total_loss: 0.5596  obj_loss: 0.2228  noobj_loss: 0.1542  bbox_loss: 0.0232  cls_loss: 0.1439  \n",
      "<<<iteration:[480/878] - total_loss: 0.5549  obj_loss: 0.2591  noobj_loss: 0.1504  bbox_loss: 0.0221  cls_loss: 0.1099  \n",
      "<<<iteration:[500/878] - total_loss: 0.5857  obj_loss: 0.2552  noobj_loss: 0.1339  bbox_loss: 0.0265  cls_loss: 0.1311  \n",
      "<<<iteration:[520/878] - total_loss: 0.5149  obj_loss: 0.2317  noobj_loss: 0.1492  bbox_loss: 0.0234  cls_loss: 0.0918  \n",
      "<<<iteration:[540/878] - total_loss: 0.5553  obj_loss: 0.2398  noobj_loss: 0.1382  bbox_loss: 0.0217  cls_loss: 0.1382  \n",
      "<<<iteration:[560/878] - total_loss: 0.6132  obj_loss: 0.2946  noobj_loss: 0.1565  bbox_loss: 0.0197  cls_loss: 0.1420  \n",
      "<<<iteration:[580/878] - total_loss: 0.5351  obj_loss: 0.2538  noobj_loss: 0.1534  bbox_loss: 0.0209  cls_loss: 0.1000  \n",
      "<<<iteration:[600/878] - total_loss: 0.6027  obj_loss: 0.3044  noobj_loss: 0.1518  bbox_loss: 0.0240  cls_loss: 0.1021  \n",
      "<<<iteration:[620/878] - total_loss: 0.4904  obj_loss: 0.2349  noobj_loss: 0.1297  bbox_loss: 0.0224  cls_loss: 0.0787  \n",
      "<<<iteration:[640/878] - total_loss: 0.4821  obj_loss: 0.2339  noobj_loss: 0.1349  bbox_loss: 0.0179  cls_loss: 0.0911  \n",
      "<<<iteration:[660/878] - total_loss: 0.5539  obj_loss: 0.2642  noobj_loss: 0.1359  bbox_loss: 0.0280  cls_loss: 0.0818  \n",
      "<<<iteration:[680/878] - total_loss: 0.5273  obj_loss: 0.2507  noobj_loss: 0.1617  bbox_loss: 0.0232  cls_loss: 0.0799  \n",
      "<<<iteration:[700/878] - total_loss: 0.5436  obj_loss: 0.2399  noobj_loss: 0.1435  bbox_loss: 0.0252  cls_loss: 0.1057  \n",
      "<<<iteration:[720/878] - total_loss: 0.5110  obj_loss: 0.2342  noobj_loss: 0.1403  bbox_loss: 0.0246  cls_loss: 0.0835  \n",
      "<<<iteration:[740/878] - total_loss: 0.5286  obj_loss: 0.2248  noobj_loss: 0.1419  bbox_loss: 0.0247  cls_loss: 0.1092  \n",
      "<<<iteration:[760/878] - total_loss: 0.5860  obj_loss: 0.2600  noobj_loss: 0.1196  bbox_loss: 0.0252  cls_loss: 0.1404  \n",
      "<<<iteration:[780/878] - total_loss: 0.6745  obj_loss: 0.2841  noobj_loss: 0.1348  bbox_loss: 0.0284  cls_loss: 0.1811  \n",
      "<<<iteration:[800/878] - total_loss: 0.4988  obj_loss: 0.2487  noobj_loss: 0.1522  bbox_loss: 0.0208  cls_loss: 0.0697  \n",
      "<<<iteration:[820/878] - total_loss: 0.6046  obj_loss: 0.2247  noobj_loss: 0.1314  bbox_loss: 0.0337  cls_loss: 0.1459  \n",
      "<<<iteration:[840/878] - total_loss: 0.6471  obj_loss: 0.2320  noobj_loss: 0.1274  bbox_loss: 0.0464  cls_loss: 0.1194  \n",
      "<<<iteration:[860/878] - total_loss: 0.5898  obj_loss: 0.2131  noobj_loss: 0.1412  bbox_loss: 0.0357  cls_loss: 0.1278  \n",
      "\n",
      "epoch:97/100 - Train Loss: 0.5549, Val Loss: 1.1421\n",
      "\n",
      "<<<iteration:[20/878] - total_loss: 0.6274  obj_loss: 0.2313  noobj_loss: 0.1244  bbox_loss: 0.0320  cls_loss: 0.1737  \n",
      "<<<iteration:[40/878] - total_loss: 0.5144  obj_loss: 0.2619  noobj_loss: 0.1265  bbox_loss: 0.0250  cls_loss: 0.0641  \n",
      "<<<iteration:[60/878] - total_loss: 0.5040  obj_loss: 0.2565  noobj_loss: 0.1460  bbox_loss: 0.0197  cls_loss: 0.0758  \n",
      "<<<iteration:[80/878] - total_loss: 0.5283  obj_loss: 0.2149  noobj_loss: 0.1248  bbox_loss: 0.0222  cls_loss: 0.1402  \n",
      "<<<iteration:[100/878] - total_loss: 0.5956  obj_loss: 0.2200  noobj_loss: 0.1395  bbox_loss: 0.0453  cls_loss: 0.0795  \n",
      "<<<iteration:[120/878] - total_loss: 0.5528  obj_loss: 0.2445  noobj_loss: 0.1272  bbox_loss: 0.0291  cls_loss: 0.0994  \n",
      "<<<iteration:[140/878] - total_loss: 0.5599  obj_loss: 0.2256  noobj_loss: 0.1344  bbox_loss: 0.0358  cls_loss: 0.0880  \n",
      "<<<iteration:[160/878] - total_loss: 0.6672  obj_loss: 0.2566  noobj_loss: 0.1226  bbox_loss: 0.0255  cls_loss: 0.2218  \n",
      "<<<iteration:[180/878] - total_loss: 0.5697  obj_loss: 0.2459  noobj_loss: 0.1468  bbox_loss: 0.0267  cls_loss: 0.1170  \n",
      "<<<iteration:[200/878] - total_loss: 0.6538  obj_loss: 0.2856  noobj_loss: 0.1549  bbox_loss: 0.0283  cls_loss: 0.1493  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<<<iteration:[220/878] - total_loss: 0.5197  obj_loss: 0.2339  noobj_loss: 0.1340  bbox_loss: 0.0199  cls_loss: 0.1192  \n",
      "<<<iteration:[240/878] - total_loss: 0.4970  obj_loss: 0.2419  noobj_loss: 0.1415  bbox_loss: 0.0215  cls_loss: 0.0767  \n",
      "<<<iteration:[260/878] - total_loss: 0.5582  obj_loss: 0.2392  noobj_loss: 0.1478  bbox_loss: 0.0252  cls_loss: 0.1191  \n",
      "<<<iteration:[280/878] - total_loss: 0.4709  obj_loss: 0.2348  noobj_loss: 0.1291  bbox_loss: 0.0208  cls_loss: 0.0676  \n",
      "<<<iteration:[300/878] - total_loss: 0.5142  obj_loss: 0.2589  noobj_loss: 0.1270  bbox_loss: 0.0217  cls_loss: 0.0832  \n",
      "<<<iteration:[320/878] - total_loss: 0.6501  obj_loss: 0.3021  noobj_loss: 0.1597  bbox_loss: 0.0255  cls_loss: 0.1407  \n",
      "<<<iteration:[340/878] - total_loss: 0.4375  obj_loss: 0.1960  noobj_loss: 0.1292  bbox_loss: 0.0194  cls_loss: 0.0798  \n",
      "<<<iteration:[360/878] - total_loss: 0.4901  obj_loss: 0.2586  noobj_loss: 0.1387  bbox_loss: 0.0218  cls_loss: 0.0533  \n",
      "<<<iteration:[380/878] - total_loss: 0.5472  obj_loss: 0.2423  noobj_loss: 0.1351  bbox_loss: 0.0217  cls_loss: 0.1289  \n",
      "<<<iteration:[400/878] - total_loss: 0.5274  obj_loss: 0.2400  noobj_loss: 0.1405  bbox_loss: 0.0288  cls_loss: 0.0730  \n",
      "<<<iteration:[420/878] - total_loss: 0.5210  obj_loss: 0.2458  noobj_loss: 0.1501  bbox_loss: 0.0222  cls_loss: 0.0894  \n",
      "<<<iteration:[440/878] - total_loss: 0.5485  obj_loss: 0.2453  noobj_loss: 0.1279  bbox_loss: 0.0234  cls_loss: 0.1223  \n",
      "<<<iteration:[460/878] - total_loss: 0.5062  obj_loss: 0.2371  noobj_loss: 0.1432  bbox_loss: 0.0234  cls_loss: 0.0803  \n",
      "<<<iteration:[480/878] - total_loss: 0.5928  obj_loss: 0.2467  noobj_loss: 0.1340  bbox_loss: 0.0251  cls_loss: 0.1534  \n",
      "<<<iteration:[500/878] - total_loss: 0.6141  obj_loss: 0.2698  noobj_loss: 0.1485  bbox_loss: 0.0244  cls_loss: 0.1479  \n",
      "<<<iteration:[520/878] - total_loss: 0.5597  obj_loss: 0.2410  noobj_loss: 0.1213  bbox_loss: 0.0197  cls_loss: 0.1596  \n",
      "<<<iteration:[540/878] - total_loss: 0.5801  obj_loss: 0.2701  noobj_loss: 0.1384  bbox_loss: 0.0223  cls_loss: 0.1293  \n",
      "<<<iteration:[560/878] - total_loss: 0.5228  obj_loss: 0.2603  noobj_loss: 0.1416  bbox_loss: 0.0202  cls_loss: 0.0908  \n",
      "<<<iteration:[580/878] - total_loss: 0.5738  obj_loss: 0.2380  noobj_loss: 0.1563  bbox_loss: 0.0324  cls_loss: 0.0957  \n",
      "<<<iteration:[600/878] - total_loss: 0.5431  obj_loss: 0.2352  noobj_loss: 0.1341  bbox_loss: 0.0248  cls_loss: 0.1169  \n",
      "<<<iteration:[620/878] - total_loss: 0.5662  obj_loss: 0.2141  noobj_loss: 0.1320  bbox_loss: 0.0322  cls_loss: 0.1249  \n",
      "<<<iteration:[640/878] - total_loss: 0.6900  obj_loss: 0.2412  noobj_loss: 0.1426  bbox_loss: 0.0317  cls_loss: 0.2188  \n",
      "<<<iteration:[660/878] - total_loss: 0.5637  obj_loss: 0.2577  noobj_loss: 0.1378  bbox_loss: 0.0241  cls_loss: 0.1166  \n",
      "<<<iteration:[680/878] - total_loss: 0.6448  obj_loss: 0.2380  noobj_loss: 0.1310  bbox_loss: 0.0460  cls_loss: 0.1113  \n",
      "<<<iteration:[700/878] - total_loss: 0.6176  obj_loss: 0.2434  noobj_loss: 0.1330  bbox_loss: 0.0232  cls_loss: 0.1918  \n",
      "<<<iteration:[720/878] - total_loss: 0.5710  obj_loss: 0.2210  noobj_loss: 0.1289  bbox_loss: 0.0210  cls_loss: 0.1803  \n",
      "<<<iteration:[740/878] - total_loss: 0.5571  obj_loss: 0.2275  noobj_loss: 0.1441  bbox_loss: 0.0270  cls_loss: 0.1228  \n",
      "<<<iteration:[760/878] - total_loss: 0.5769  obj_loss: 0.2443  noobj_loss: 0.1550  bbox_loss: 0.0296  cls_loss: 0.1071  \n",
      "<<<iteration:[780/878] - total_loss: 0.5478  obj_loss: 0.2560  noobj_loss: 0.1388  bbox_loss: 0.0235  cls_loss: 0.1050  \n",
      "<<<iteration:[800/878] - total_loss: 0.6321  obj_loss: 0.2556  noobj_loss: 0.1412  bbox_loss: 0.0444  cls_loss: 0.0840  \n",
      "<<<iteration:[820/878] - total_loss: 0.5212  obj_loss: 0.2280  noobj_loss: 0.1221  bbox_loss: 0.0269  cls_loss: 0.0976  \n",
      "<<<iteration:[840/878] - total_loss: 0.5377  obj_loss: 0.2375  noobj_loss: 0.1387  bbox_loss: 0.0239  cls_loss: 0.1113  \n",
      "<<<iteration:[860/878] - total_loss: 0.6255  obj_loss: 0.2422  noobj_loss: 0.1445  bbox_loss: 0.0485  cls_loss: 0.0686  \n",
      "\n",
      "epoch:98/100 - Train Loss: 0.5614, Val Loss: 1.1360\n",
      "\n",
      "<<<iteration:[20/878] - total_loss: 0.5801  obj_loss: 0.2777  noobj_loss: 0.1556  bbox_loss: 0.0188  cls_loss: 0.1304  \n",
      "<<<iteration:[40/878] - total_loss: 0.5262  obj_loss: 0.2190  noobj_loss: 0.1279  bbox_loss: 0.0238  cls_loss: 0.1241  \n",
      "<<<iteration:[60/878] - total_loss: 0.5182  obj_loss: 0.2341  noobj_loss: 0.1326  bbox_loss: 0.0224  cls_loss: 0.1057  \n",
      "<<<iteration:[80/878] - total_loss: 0.5766  obj_loss: 0.3120  noobj_loss: 0.1478  bbox_loss: 0.0235  cls_loss: 0.0731  \n",
      "<<<iteration:[100/878] - total_loss: 0.4965  obj_loss: 0.2297  noobj_loss: 0.1314  bbox_loss: 0.0225  cls_loss: 0.0888  \n",
      "<<<iteration:[120/878] - total_loss: 0.5231  obj_loss: 0.2000  noobj_loss: 0.1238  bbox_loss: 0.0220  cls_loss: 0.1512  \n",
      "<<<iteration:[140/878] - total_loss: 0.6271  obj_loss: 0.2226  noobj_loss: 0.1403  bbox_loss: 0.0300  cls_loss: 0.1845  \n",
      "<<<iteration:[160/878] - total_loss: 0.6101  obj_loss: 0.2567  noobj_loss: 0.1343  bbox_loss: 0.0272  cls_loss: 0.1501  \n",
      "<<<iteration:[180/878] - total_loss: 0.5229  obj_loss: 0.2536  noobj_loss: 0.1320  bbox_loss: 0.0226  cls_loss: 0.0904  \n",
      "<<<iteration:[200/878] - total_loss: 0.5480  obj_loss: 0.2480  noobj_loss: 0.1458  bbox_loss: 0.0228  cls_loss: 0.1132  \n",
      "<<<iteration:[220/878] - total_loss: 0.5035  obj_loss: 0.2301  noobj_loss: 0.1353  bbox_loss: 0.0213  cls_loss: 0.0994  \n",
      "<<<iteration:[240/878] - total_loss: 0.5245  obj_loss: 0.2459  noobj_loss: 0.1318  bbox_loss: 0.0235  cls_loss: 0.0951  \n",
      "<<<iteration:[260/878] - total_loss: 0.6277  obj_loss: 0.3151  noobj_loss: 0.1655  bbox_loss: 0.0243  cls_loss: 0.1082  \n",
      "<<<iteration:[280/878] - total_loss: 0.4779  obj_loss: 0.2055  noobj_loss: 0.1273  bbox_loss: 0.0225  cls_loss: 0.0963  \n",
      "<<<iteration:[300/878] - total_loss: 0.5711  obj_loss: 0.2470  noobj_loss: 0.1337  bbox_loss: 0.0224  cls_loss: 0.1454  \n",
      "<<<iteration:[320/878] - total_loss: 0.6109  obj_loss: 0.2664  noobj_loss: 0.1381  bbox_loss: 0.0238  cls_loss: 0.1565  \n",
      "<<<iteration:[340/878] - total_loss: 0.5058  obj_loss: 0.2242  noobj_loss: 0.1272  bbox_loss: 0.0245  cls_loss: 0.0956  \n",
      "<<<iteration:[360/878] - total_loss: 0.5812  obj_loss: 0.2575  noobj_loss: 0.1339  bbox_loss: 0.0231  cls_loss: 0.1411  \n",
      "<<<iteration:[380/878] - total_loss: 0.5173  obj_loss: 0.2174  noobj_loss: 0.1356  bbox_loss: 0.0308  cls_loss: 0.0779  \n",
      "<<<iteration:[400/878] - total_loss: 0.4648  obj_loss: 0.2371  noobj_loss: 0.1462  bbox_loss: 0.0215  cls_loss: 0.0472  \n",
      "<<<iteration:[420/878] - total_loss: 0.5631  obj_loss: 0.2950  noobj_loss: 0.1567  bbox_loss: 0.0215  cls_loss: 0.0821  \n",
      "<<<iteration:[440/878] - total_loss: 0.5317  obj_loss: 0.2133  noobj_loss: 0.1362  bbox_loss: 0.0237  cls_loss: 0.1317  \n",
      "<<<iteration:[460/878] - total_loss: 0.5083  obj_loss: 0.2122  noobj_loss: 0.1314  bbox_loss: 0.0243  cls_loss: 0.1087  \n",
      "<<<iteration:[480/878] - total_loss: 0.4881  obj_loss: 0.2018  noobj_loss: 0.1186  bbox_loss: 0.0263  cls_loss: 0.0954  \n",
      "<<<iteration:[500/878] - total_loss: 0.5381  obj_loss: 0.2575  noobj_loss: 0.1293  bbox_loss: 0.0233  cls_loss: 0.0997  \n",
      "<<<iteration:[520/878] - total_loss: 0.5128  obj_loss: 0.2531  noobj_loss: 0.1395  bbox_loss: 0.0255  cls_loss: 0.0623  \n",
      "<<<iteration:[540/878] - total_loss: 0.4757  obj_loss: 0.2374  noobj_loss: 0.1290  bbox_loss: 0.0201  cls_loss: 0.0734  \n",
      "<<<iteration:[560/878] - total_loss: 0.4895  obj_loss: 0.2343  noobj_loss: 0.1325  bbox_loss: 0.0212  cls_loss: 0.0827  \n",
      "<<<iteration:[580/878] - total_loss: 0.4937  obj_loss: 0.2423  noobj_loss: 0.1430  bbox_loss: 0.0157  cls_loss: 0.1014  \n",
      "<<<iteration:[600/878] - total_loss: 0.5342  obj_loss: 0.2429  noobj_loss: 0.1578  bbox_loss: 0.0216  cls_loss: 0.1043  \n",
      "<<<iteration:[620/878] - total_loss: 0.5603  obj_loss: 0.2707  noobj_loss: 0.1390  bbox_loss: 0.0217  cls_loss: 0.1116  \n",
      "<<<iteration:[640/878] - total_loss: 0.5357  obj_loss: 0.2526  noobj_loss: 0.1422  bbox_loss: 0.0191  cls_loss: 0.1164  \n",
      "<<<iteration:[660/878] - total_loss: 0.5353  obj_loss: 0.2649  noobj_loss: 0.1308  bbox_loss: 0.0229  cls_loss: 0.0906  \n",
      "<<<iteration:[680/878] - total_loss: 0.6149  obj_loss: 0.3001  noobj_loss: 0.1587  bbox_loss: 0.0257  cls_loss: 0.1072  \n",
      "<<<iteration:[700/878] - total_loss: 0.5513  obj_loss: 0.2640  noobj_loss: 0.1464  bbox_loss: 0.0179  cls_loss: 0.1243  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<<<iteration:[720/878] - total_loss: 0.4881  obj_loss: 0.1939  noobj_loss: 0.1379  bbox_loss: 0.0237  cls_loss: 0.1068  \n",
      "<<<iteration:[740/878] - total_loss: 0.5308  obj_loss: 0.2634  noobj_loss: 0.1324  bbox_loss: 0.0241  cls_loss: 0.0807  \n",
      "<<<iteration:[760/878] - total_loss: 0.4838  obj_loss: 0.2405  noobj_loss: 0.1284  bbox_loss: 0.0179  cls_loss: 0.0899  \n",
      "<<<iteration:[780/878] - total_loss: 0.4727  obj_loss: 0.2203  noobj_loss: 0.1289  bbox_loss: 0.0214  cls_loss: 0.0808  \n",
      "<<<iteration:[800/878] - total_loss: 0.5770  obj_loss: 0.2873  noobj_loss: 0.1435  bbox_loss: 0.0232  cls_loss: 0.1020  \n",
      "<<<iteration:[820/878] - total_loss: 0.6634  obj_loss: 0.2911  noobj_loss: 0.1611  bbox_loss: 0.0325  cls_loss: 0.1290  \n",
      "<<<iteration:[840/878] - total_loss: 0.6063  obj_loss: 0.2878  noobj_loss: 0.1761  bbox_loss: 0.0273  cls_loss: 0.0940  \n",
      "<<<iteration:[860/878] - total_loss: 0.6250  obj_loss: 0.2693  noobj_loss: 0.1356  bbox_loss: 0.0230  cls_loss: 0.1731  \n",
      "\n",
      "epoch:99/100 - Train Loss: 0.5419, Val Loss: 1.1458\n",
      "\n",
      "<<<iteration:[20/878] - total_loss: 0.5958  obj_loss: 0.2886  noobj_loss: 0.1428  bbox_loss: 0.0325  cls_loss: 0.0732  \n",
      "<<<iteration:[40/878] - total_loss: 0.5689  obj_loss: 0.2795  noobj_loss: 0.1648  bbox_loss: 0.0206  cls_loss: 0.1043  \n",
      "<<<iteration:[60/878] - total_loss: 0.5168  obj_loss: 0.2492  noobj_loss: 0.1245  bbox_loss: 0.0182  cls_loss: 0.1142  \n",
      "<<<iteration:[80/878] - total_loss: 0.4941  obj_loss: 0.2648  noobj_loss: 0.1365  bbox_loss: 0.0206  cls_loss: 0.0578  \n",
      "<<<iteration:[100/878] - total_loss: 0.5473  obj_loss: 0.2550  noobj_loss: 0.1372  bbox_loss: 0.0203  cls_loss: 0.1223  \n",
      "<<<iteration:[120/878] - total_loss: 0.5223  obj_loss: 0.2463  noobj_loss: 0.1492  bbox_loss: 0.0244  cls_loss: 0.0796  \n",
      "<<<iteration:[140/878] - total_loss: 0.5431  obj_loss: 0.2346  noobj_loss: 0.1547  bbox_loss: 0.0302  cls_loss: 0.0802  \n",
      "<<<iteration:[160/878] - total_loss: 0.5800  obj_loss: 0.2544  noobj_loss: 0.1511  bbox_loss: 0.0240  cls_loss: 0.1303  \n",
      "<<<iteration:[180/878] - total_loss: 0.4965  obj_loss: 0.2266  noobj_loss: 0.1406  bbox_loss: 0.0231  cls_loss: 0.0841  \n",
      "<<<iteration:[200/878] - total_loss: 0.5586  obj_loss: 0.2604  noobj_loss: 0.1597  bbox_loss: 0.0221  cls_loss: 0.1081  \n",
      "<<<iteration:[220/878] - total_loss: 0.5629  obj_loss: 0.2808  noobj_loss: 0.1672  bbox_loss: 0.0223  cls_loss: 0.0868  \n",
      "<<<iteration:[240/878] - total_loss: 0.5363  obj_loss: 0.2496  noobj_loss: 0.1527  bbox_loss: 0.0216  cls_loss: 0.1024  \n",
      "<<<iteration:[260/878] - total_loss: 0.4830  obj_loss: 0.2237  noobj_loss: 0.1275  bbox_loss: 0.0234  cls_loss: 0.0785  \n",
      "<<<iteration:[280/878] - total_loss: 0.5212  obj_loss: 0.2108  noobj_loss: 0.1266  bbox_loss: 0.0238  cls_loss: 0.1280  \n",
      "<<<iteration:[300/878] - total_loss: 0.5022  obj_loss: 0.2275  noobj_loss: 0.1269  bbox_loss: 0.0199  cls_loss: 0.1118  \n",
      "<<<iteration:[320/878] - total_loss: 0.5419  obj_loss: 0.2185  noobj_loss: 0.1338  bbox_loss: 0.0341  cls_loss: 0.0860  \n",
      "<<<iteration:[340/878] - total_loss: 0.5821  obj_loss: 0.2281  noobj_loss: 0.1529  bbox_loss: 0.0283  cls_loss: 0.1363  \n",
      "<<<iteration:[360/878] - total_loss: 0.5612  obj_loss: 0.2864  noobj_loss: 0.1503  bbox_loss: 0.0243  cls_loss: 0.0780  \n",
      "<<<iteration:[380/878] - total_loss: 0.6469  obj_loss: 0.2593  noobj_loss: 0.1587  bbox_loss: 0.0279  cls_loss: 0.1688  \n",
      "<<<iteration:[400/878] - total_loss: 0.5439  obj_loss: 0.2618  noobj_loss: 0.1389  bbox_loss: 0.0234  cls_loss: 0.0957  \n",
      "<<<iteration:[420/878] - total_loss: 0.6216  obj_loss: 0.2228  noobj_loss: 0.1348  bbox_loss: 0.0344  cls_loss: 0.1595  \n",
      "<<<iteration:[440/878] - total_loss: 0.5550  obj_loss: 0.2813  noobj_loss: 0.1572  bbox_loss: 0.0249  cls_loss: 0.0708  \n",
      "<<<iteration:[460/878] - total_loss: 0.5580  obj_loss: 0.2270  noobj_loss: 0.1495  bbox_loss: 0.0228  cls_loss: 0.1424  \n",
      "<<<iteration:[480/878] - total_loss: 0.5759  obj_loss: 0.2304  noobj_loss: 0.1431  bbox_loss: 0.0232  cls_loss: 0.1580  \n",
      "<<<iteration:[500/878] - total_loss: 0.5023  obj_loss: 0.2712  noobj_loss: 0.1308  bbox_loss: 0.0213  cls_loss: 0.0594  \n",
      "<<<iteration:[520/878] - total_loss: 0.5078  obj_loss: 0.2032  noobj_loss: 0.1286  bbox_loss: 0.0239  cls_loss: 0.1208  \n",
      "<<<iteration:[540/878] - total_loss: 0.4985  obj_loss: 0.2713  noobj_loss: 0.1459  bbox_loss: 0.0183  cls_loss: 0.0627  \n",
      "<<<iteration:[560/878] - total_loss: 0.5612  obj_loss: 0.2849  noobj_loss: 0.1632  bbox_loss: 0.0234  cls_loss: 0.0779  \n",
      "<<<iteration:[580/878] - total_loss: 0.5138  obj_loss: 0.2464  noobj_loss: 0.1457  bbox_loss: 0.0211  cls_loss: 0.0888  \n",
      "<<<iteration:[600/878] - total_loss: 0.5610  obj_loss: 0.2532  noobj_loss: 0.1416  bbox_loss: 0.0251  cls_loss: 0.1117  \n",
      "<<<iteration:[620/878] - total_loss: 0.5370  obj_loss: 0.2084  noobj_loss: 0.1242  bbox_loss: 0.0201  cls_loss: 0.1659  \n",
      "<<<iteration:[640/878] - total_loss: 0.4843  obj_loss: 0.2391  noobj_loss: 0.1346  bbox_loss: 0.0202  cls_loss: 0.0768  \n",
      "<<<iteration:[660/878] - total_loss: 0.4963  obj_loss: 0.2362  noobj_loss: 0.1257  bbox_loss: 0.0193  cls_loss: 0.1006  \n",
      "<<<iteration:[680/878] - total_loss: 0.5289  obj_loss: 0.2273  noobj_loss: 0.1249  bbox_loss: 0.0228  cls_loss: 0.1252  \n",
      "<<<iteration:[700/878] - total_loss: 0.5550  obj_loss: 0.2364  noobj_loss: 0.1352  bbox_loss: 0.0220  cls_loss: 0.1412  \n",
      "<<<iteration:[720/878] - total_loss: 0.5511  obj_loss: 0.2525  noobj_loss: 0.1229  bbox_loss: 0.0217  cls_loss: 0.1286  \n",
      "<<<iteration:[740/878] - total_loss: 0.5298  obj_loss: 0.2218  noobj_loss: 0.1501  bbox_loss: 0.0233  cls_loss: 0.1163  \n",
      "<<<iteration:[760/878] - total_loss: 0.6014  obj_loss: 0.2988  noobj_loss: 0.1490  bbox_loss: 0.0257  cls_loss: 0.0999  \n",
      "<<<iteration:[780/878] - total_loss: 0.5823  obj_loss: 0.2782  noobj_loss: 0.1531  bbox_loss: 0.0293  cls_loss: 0.0808  \n",
      "<<<iteration:[800/878] - total_loss: 0.5601  obj_loss: 0.2488  noobj_loss: 0.1263  bbox_loss: 0.0225  cls_loss: 0.1359  \n",
      "<<<iteration:[820/878] - total_loss: 0.5353  obj_loss: 0.2630  noobj_loss: 0.1468  bbox_loss: 0.0249  cls_loss: 0.0745  \n",
      "<<<iteration:[840/878] - total_loss: 0.6641  obj_loss: 0.2443  noobj_loss: 0.1548  bbox_loss: 0.0296  cls_loss: 0.1944  \n",
      "<<<iteration:[860/878] - total_loss: 0.6131  obj_loss: 0.2731  noobj_loss: 0.1421  bbox_loss: 0.0234  cls_loss: 0.1517  \n",
      "\n",
      "epoch:100/100 - Train Loss: 0.5460, Val Loss: 1.1182\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>Train Loss</td><td>█▃▄▄▃▄▃▃▃▃▃▃▃▃▃▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>Train bbox Loss</td><td>█▂▃▂▂▃▂▁▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>Train class Loss</td><td>██▇█▇█▇▇▇▇▇▇▇▇▆▄▃▂▂▂▂▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>Train obj Loss</td><td>▁▁▂▁▂▂▂▂▂▂▂▂▂▂▂▃▄▅▅▅▅▆▆▆▆▆▇▆▇▇▇▇▇▇█▇█▇██</td></tr><tr><td>Val Loss</td><td>▅▃▆▃▃▃▃▃▃▄█▅▃▃▃▁▁▁▁▁▁▁▁▁▁▁▂▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>Val bbox Loss</td><td>▅▂▅▂▂▁▁▁▁▃█▄▁▁▁▁▁▁▁▁▁▁▁▁▁▁▂▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>Val class Loss</td><td>████▇▇█▇▇▇▇▇▇█▇▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>Val obj Loss</td><td>▁▁▂▄▃▄▃▄▅▃▂▄▄▃▃▆▇▇▅▆▇▇▅▇▆▇▄▅▇▇█▇▇▅▆▇██▇▇</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>Train Loss</td><td>0.54603</td></tr><tr><td>Train bbox Loss</td><td>0.0238</td></tr><tr><td>Train class Loss</td><td>0.10737</td></tr><tr><td>Train obj Loss</td><td>0.24861</td></tr><tr><td>Val Loss</td><td>1.11823</td></tr><tr><td>Val bbox Loss</td><td>0.04744</td></tr><tr><td>Val class Loss</td><td>0.60864</td></tr><tr><td>Val obj Loss</td><td>0.18529</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">true-flower-3</strong> at: <a href='https://wandb.ai/urp/yolo_swin/runs/syu3qbnc' target=\"_blank\">https://wandb.ai/urp/yolo_swin/runs/syu3qbnc</a><br/>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20231006_160259-syu3qbnc/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "best_epoch = 0\n",
    "best_score = float('inf')\n",
    "train_losses = []\n",
    "val_losses = []\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    train_loss, val_loss = train_one_epoch(dataloaders, model, criterion, optimizer, device)\n",
    "    train_losses.append(train_loss)\n",
    "    val_losses.append(val_loss)\n",
    "#     train_loss[\"obj_loss\"] += obj_loss\n",
    "#     train_loss[\"noobj_loss\"] += noobj_loss\n",
    "#     train_loss[\"bbox_loss\"] += bbox_loss\n",
    "#     train_loss[\"cls_loss\"] += cls_loss\n",
    "    wandb.log({\"Train Loss\": train_loss['total_loss'],\n",
    "               \"Train obj Loss\":train_loss[\"obj_loss\"],\n",
    "               \"Train bbox Loss\":train_loss[\"bbox_loss\"],\n",
    "               \"Train class Loss\":train_loss[\"cls_loss\"],\n",
    "               \"Val Loss\": val_loss['total_loss'],\n",
    "               \"Val obj Loss\":val_loss[\"obj_loss\"],\n",
    "               \"Val bbox Loss\":val_loss[\"bbox_loss\"],\n",
    "               \"Val class Loss\":val_loss[\"cls_loss\"],})\n",
    "    print(f\"\\nepoch:{epoch+1}/{num_epochs} - Train Loss: {train_loss['total_loss']:.4f}, Val Loss: {val_loss['total_loss']:.4f}\\n\")\n",
    "    \n",
    "    if (epoch+1) % 10 == 0:\n",
    "        save_model(model.state_dict(), f'model_{epoch+1}.pth', save_dir=f\"./trained_model/{BACKBONE}_{PART}_LR{LR}_AUG{AUG_FACTOR}\")\n",
    "wandb.finish()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4de7fe95",
   "metadata": {},
   "source": [
    "# Test Dataset Inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "b71f9334",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import os \n",
    "import pandas as pd\n",
    "import cv2\n",
    "import torch\n",
    "import matplotlib.pyplot as plt\n",
    "from ipywidgets import interact\n",
    "import albumentations as A\n",
    "from albumentations.pytorch import ToTensorV2\n",
    "import torchvision\n",
    "from torch import nn\n",
    "import torchsummary\n",
    "from torch.utils.data import DataLoader\n",
    "from collections import defaultdict\n",
    "from torchvision.utils import make_grid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "63f8dfc5",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "64dd5b10",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_model(ckpt_path, num_classes, device):\n",
    "    checkpoint = torch.load(ckpt_path, map_location=device)\n",
    "    model = YOLO_SWIN(num_classes=num_classes)\n",
    "    model.load_state_dict(checkpoint)\n",
    "    model = model.to(device)\n",
    "    model.eval()\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "4d80869e",
   "metadata": {},
   "outputs": [],
   "source": [
    "IMAGE_SIZE=448\n",
    "transformer = A.Compose([\n",
    "            A.Resize(height=IMAGE_SIZE, width=IMAGE_SIZE),\n",
    "            A.Normalize(mean=(0.485, 0.456, 0.406),std=(0.229, 0.224, 0.225)),\n",
    "            ToTensorV2(),\n",
    "        ],\n",
    "        bbox_params=A.BboxParams(format='yolo', label_fields=['class_ids']),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "76bcd114",
   "metadata": {},
   "outputs": [],
   "source": [
    "ckpt_path=\"./trained_model/YOLO_SWIN_T_body_LR0.0001_AUG30/model_90.pth\"\n",
    "model = load_model(ckpt_path, NUM_CLASSES, device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "0d42c594",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "start making augmented images-- augmented factor:0\n",
      "total length of augmented images: 0\n"
     ]
    }
   ],
   "source": [
    "test_dataset=PET_dataset(\"body\" ,neck_dir=NECK_PATH,body_dir=BODY_PATH,phase='test', transformer=transformer, aug=None)\n",
    "test_dataloaders = DataLoader(test_dataset, batch_size=1, shuffle=False, collate_fn=collate_fn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "07fed11f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "20"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(test_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "3709c974",
   "metadata": {},
   "outputs": [],
   "source": [
    "@torch.no_grad()\n",
    "def model_predict(image, model, conf_thres=0.2, iou_threshold=0.1):\n",
    "    predictions = model(image)\n",
    "    prediction = predictions.detach().cpu().squeeze(dim=0)\n",
    "#     print(prediction.shape)\n",
    "    \n",
    "    grid_size = prediction.shape[-1]\n",
    "    y_grid, x_grid = torch.meshgrid(torch.arange(grid_size), torch.arange(grid_size))\n",
    "    stride_size = IMAGE_SIZE/grid_size\n",
    "\n",
    "    conf = prediction[[0,5], ...].reshape(1, -1)\n",
    "    xc = (prediction[[1,6], ...] * IMAGE_SIZE + x_grid*stride_size).reshape(1,-1)\n",
    "    yc = (prediction[[2,7], ...] * IMAGE_SIZE + y_grid*stride_size).reshape(1,-1)\n",
    "    w = (prediction[[3,8], ...] * IMAGE_SIZE).reshape(1,-1)\n",
    "    h = (prediction[[4,9], ...] * IMAGE_SIZE).reshape(1,-1)\n",
    "    cls = torch.max(prediction[10:, ...].reshape(NUM_CLASSES, -1), dim=0).indices.tile(1,2)\n",
    "    \n",
    "    x_min = xc - w/2\n",
    "    y_min = yc - h/2\n",
    "    x_max = xc + w/2\n",
    "    y_max = yc + h/2\n",
    "\n",
    "    prediction_res = torch.cat([x_min, y_min, x_max, y_max, conf, cls], dim=0)\n",
    "    prediction_res = prediction_res.transpose(0,1)\n",
    "\n",
    "    # x_min과 y_min이 음수가 되지않고, x_max와 y_max가 이미지 크기를 넘지 않게 제한\n",
    "    prediction_res[:, 2].clip(min=0, max=image.shape[1]) \n",
    "    prediction_res[:, 3].clip(min=0, max=image.shape[0])\n",
    "        \n",
    "    pred_res = prediction_res[prediction_res[:, 4] > conf_thres]\n",
    "    nms_index = torchvision.ops.nms(boxes=pred_res[:, 0:4], scores=pred_res[:, 4], iou_threshold=iou_threshold)\n",
    "    pred_res_ = pred_res[nms_index].numpy()\n",
    "    \n",
    "    n_obj = pred_res_.shape[0]\n",
    "    bboxes = np.zeros(shape=(n_obj, 4), dtype=np.float32)\n",
    "    bboxes[:, 0:2] = (pred_res_[:, 0:2] + pred_res_[:, 2:4]) / 2\n",
    "    bboxes[:, 2:4] = pred_res_[:, 2:4] - pred_res_[:, 0:2]\n",
    "    scores = pred_res_[:, 4]\n",
    "    class_ids = pred_res_[:, 5]\n",
    "    \n",
    "    # 이미지 값이 들어가면 모델을 통해서, 후처리까지 포함된 yolo 포멧의 box좌표, 그 좌표에 대한 confidence score\n",
    "    # 그리고 class id를 반환\n",
    "    return bboxes, scores, class_ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "10dddcd9",
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_images = []\n",
    "pred_labels =[]\n",
    "\n",
    "for index, batch in enumerate(test_dataloaders):\n",
    "    images = batch[0].to(device)\n",
    "    bboxes, scores, class_ids = model_predict(images, model, conf_thres=0.2, iou_threshold=0.1)\n",
    "    \n",
    "    if len(bboxes) > 0:\n",
    "        prediction_yolo = np.concatenate([bboxes, scores[:, np.newaxis], class_ids[:, np.newaxis]], axis=1)\n",
    "    else:\n",
    "        prediction_yolo = np.array([])\n",
    "    \n",
    "    # 텐서형의 이미지를 다시 unnormalize를 시키고, 다시 chw를 hwc로 바꾸고 넘파이로 바꾼다.\n",
    "    np_image = make_grid(images[0], normalize=True).cpu().permute(1,2,0).numpy()\n",
    "    pred_images.append(np_image)\n",
    "    pred_labels.append(prediction_yolo)\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "b07fa545",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "67d56b200fe84211b9fb6625330e5b49",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "interactive(children=(IntSlider(value=0, description='index', max=19), Output()), _dom_classes=('widget-intera…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from ipywidgets import interact\n",
    "\n",
    "@interact(index=(0,len(pred_images)-1))\n",
    "def show_result(index=0):\n",
    "    print(pred_labels[index])\n",
    "    if len(pred_labels[index]) > 0:\n",
    "        result = visualize(pred_images[index], pred_labels[index][:, 0:4], pred_labels[index][:, 5])\n",
    "    else:\n",
    "        result = pred_images[index]\n",
    "        \n",
    "    plt.figure(figsize=(6,6))\n",
    "    plt.imshow(result)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c005b3d0",
   "metadata": {},
   "source": [
    "# 탐지성능검증을 위한 지표 적용"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "edc7e158",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NOTE! Installing ujson may make loading annotations faster.\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "from pycocotools.coco import COCO\n",
    "from pycocotools.cocoeval import COCOeval"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "d742eb1c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading annotations into memory...\n",
      "Done (t=0.00s)\n",
      "Creating index...\n",
      "index created!\n"
     ]
    }
   ],
   "source": [
    "annFile = \"/home/host_data/PET_data/Body/test/test.json\"\n",
    "# val.json은 COCO api의 Ground truth input 값으로 들어갈 것이다.\n",
    "with open(annFile, mode='r') as f:\n",
    "    json_data = json.load(f)\n",
    "imageToid = json_data[\"imageToid\"]\n",
    "# 데이터셋을 구축할 때, 이미지, target, filename을 반환하게 했는데, 그 filename을 통해서 id를 추적하고\n",
    "# val.json에 있는 annotation값 즉 bbox좌표(ground truth)를 알아내서 IoU를 계산한다.\n",
    "cocoGt=COCO(annFile)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "789df476",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'images': [{'file_name': 'shape4_4.jpg',\n",
       "   'height': 448,\n",
       "   'width': 448,\n",
       "   'id': 0},\n",
       "  {'file_name': 'shape1_129.jpg', 'height': 448, 'width': 448, 'id': 1},\n",
       "  {'file_name': 'shape1_17.jpg', 'height': 448, 'width': 448, 'id': 2},\n",
       "  {'file_name': 'shape1_32.jpg', 'height': 448, 'width': 448, 'id': 3},\n",
       "  {'file_name': 'shape1_53.jpg', 'height': 448, 'width': 448, 'id': 4},\n",
       "  {'file_name': 'shape1_59.jpg', 'height': 448, 'width': 448, 'id': 5},\n",
       "  {'file_name': 'shape1_67.jpg', 'height': 448, 'width': 448, 'id': 6},\n",
       "  {'file_name': 'shape1_81.jpg', 'height': 448, 'width': 448, 'id': 7},\n",
       "  {'file_name': 'shape1_93.jpg', 'height': 448, 'width': 448, 'id': 8},\n",
       "  {'file_name': 'shape3_115.jpg', 'height': 448, 'width': 448, 'id': 9},\n",
       "  {'file_name': 'shape3_131.jpg', 'height': 448, 'width': 448, 'id': 10},\n",
       "  {'file_name': 'shape3_143.jpg', 'height': 448, 'width': 448, 'id': 11},\n",
       "  {'file_name': 'shape3_40.jpg', 'height': 448, 'width': 448, 'id': 12},\n",
       "  {'file_name': 'shape3_64.jpg', 'height': 448, 'width': 448, 'id': 13},\n",
       "  {'file_name': 'shape3_73.jpg', 'height': 448, 'width': 448, 'id': 14},\n",
       "  {'file_name': 'shape3_75.jpg', 'height': 448, 'width': 448, 'id': 15},\n",
       "  {'file_name': 'shape4_27.jpg', 'height': 448, 'width': 448, 'id': 16},\n",
       "  {'file_name': 'shape4_32.jpg', 'height': 448, 'width': 448, 'id': 17},\n",
       "  {'file_name': 'shape4_34.jpg', 'height': 448, 'width': 448, 'id': 18},\n",
       "  {'file_name': 'shape4_35.jpg', 'height': 448, 'width': 448, 'id': 19}],\n",
       " 'imageToid': {'shape4_4.jpg': 0,\n",
       "  'shape1_129.jpg': 1,\n",
       "  'shape1_17.jpg': 2,\n",
       "  'shape1_32.jpg': 3,\n",
       "  'shape1_53.jpg': 4,\n",
       "  'shape1_59.jpg': 5,\n",
       "  'shape1_67.jpg': 6,\n",
       "  'shape1_81.jpg': 7,\n",
       "  'shape1_93.jpg': 8,\n",
       "  'shape3_115.jpg': 9,\n",
       "  'shape3_131.jpg': 10,\n",
       "  'shape3_143.jpg': 11,\n",
       "  'shape3_40.jpg': 12,\n",
       "  'shape3_64.jpg': 13,\n",
       "  'shape3_73.jpg': 14,\n",
       "  'shape3_75.jpg': 15,\n",
       "  'shape4_27.jpg': 16,\n",
       "  'shape4_32.jpg': 17,\n",
       "  'shape4_34.jpg': 18,\n",
       "  'shape4_35.jpg': 19},\n",
       " 'categories': [{'id': 0, 'supercategory': '', 'name': 'BS'},\n",
       "  {'id': 1, 'supercategory': '', 'name': 'Scratch'}],\n",
       " 'annotations': [{'id': 0,\n",
       "   'image_id': 1,\n",
       "   'bbox': [399.8754005432129,\n",
       "    282.6992073059082,\n",
       "    13.137152314186096,\n",
       "    19.49651265144348],\n",
       "   'area': 256.1286562974692,\n",
       "   'iscrowd': 0,\n",
       "   'category_id': 1,\n",
       "   'segmentation': []},\n",
       "  {'id': 1,\n",
       "   'image_id': 1,\n",
       "   'bbox': [234.45586013793945,\n",
       "    235.42533493041992,\n",
       "    39.41100883483887,\n",
       "    15.09401535987854],\n",
       "   'area': 594.8703727013667,\n",
       "   'iscrowd': 0,\n",
       "   'category_id': 1,\n",
       "   'segmentation': []},\n",
       "  {'id': 2,\n",
       "   'image_id': 1,\n",
       "   'bbox': [80.96704006195068,\n",
       "    120.54290580749512,\n",
       "    11.796736121177673,\n",
       "    15.09401535987854],\n",
       "   'area': 178.0601162094898,\n",
       "   'iscrowd': 0,\n",
       "   'category_id': 1,\n",
       "   'segmentation': []},\n",
       "  {'id': 3,\n",
       "   'image_id': 1,\n",
       "   'bbox': [138.87731742858887,\n",
       "    102.19954872131348,\n",
       "    8.579200029373169,\n",
       "    12.788159847259521],\n",
       "   'area': 109.71218133723767,\n",
       "   'iscrowd': 0,\n",
       "   'category_id': 1,\n",
       "   'segmentation': []},\n",
       "  {'id': 4,\n",
       "   'image_id': 1,\n",
       "   'bbox': [116.62469863891602,\n",
       "    174.94444465637207,\n",
       "    10.724224090576172,\n",
       "    10.691519737243652],\n",
       "   'area': 114.658253531019,\n",
       "   'iscrowd': 0,\n",
       "   'category_id': 1,\n",
       "   'segmentation': []},\n",
       "  {'id': 5,\n",
       "   'image_id': 1,\n",
       "   'bbox': [125.87410926818848,\n",
       "    178.08896255493164,\n",
       "    4.021695852279663,\n",
       "    5.66048002243042],\n",
       "   'area': 22.764729028120314,\n",
       "   'iscrowd': 0,\n",
       "   'category_id': 0,\n",
       "   'segmentation': []},\n",
       "  {'id': 6,\n",
       "   'image_id': 1,\n",
       "   'bbox': [26.676159620285034,\n",
       "    138.67660522460938,\n",
       "    7.238783836364746,\n",
       "    5.2411521673202515],\n",
       "   'area': 37.93956759272589,\n",
       "   'iscrowd': 0,\n",
       "   'category_id': 0,\n",
       "   'segmentation': []},\n",
       "  {'id': 7,\n",
       "   'image_id': 1,\n",
       "   'bbox': [40.61747169494629,\n",
       "    259.6388397216797,\n",
       "    6.702527821063995,\n",
       "    5.2411521673202515],\n",
       "   'area': 35.12896821589384,\n",
       "   'iscrowd': 0,\n",
       "   'category_id': 0,\n",
       "   'segmentation': []},\n",
       "  {'id': 8,\n",
       "   'image_id': 1,\n",
       "   'bbox': [258.0488967895508,\n",
       "    170.33228302001953,\n",
       "    7.238783836364746,\n",
       "    4.82182389497757],\n",
       "   'area': 34.904140872760934,\n",
       "   'iscrowd': 0,\n",
       "   'category_id': 0,\n",
       "   'segmentation': []},\n",
       "  {'id': 9,\n",
       "   'image_id': 1,\n",
       "   'bbox': [150.53965377807617,\n",
       "    197.58547019958496,\n",
       "    6.166271805763245,\n",
       "    4.82182389497757],\n",
       "   'area': 29.7326767359557,\n",
       "   'iscrowd': 0,\n",
       "   'category_id': 0,\n",
       "   'segmentation': []},\n",
       "  {'id': 10,\n",
       "   'image_id': 1,\n",
       "   'bbox': [392.23474502563477,\n",
       "    220.54098892211914,\n",
       "    8.042943596839905,\n",
       "    23.060352563858032],\n",
       "   'area': 185.47311499435264,\n",
       "   'iscrowd': 0,\n",
       "   'category_id': 1,\n",
       "   'segmentation': []},\n",
       "  {'id': 11,\n",
       "   'image_id': 1,\n",
       "   'bbox': [276.81605529785156,\n",
       "    207.9624900817871,\n",
       "    15.817983865737915,\n",
       "    15.513344049453735],\n",
       "   'area': 245.38982587790048,\n",
       "   'iscrowd': 0,\n",
       "   'category_id': 1,\n",
       "   'segmentation': []},\n",
       "  {'id': 12,\n",
       "   'image_id': 1,\n",
       "   'bbox': [433.7903289794922,\n",
       "    68.97139167785645,\n",
       "    11.26047968864441,\n",
       "    9.64364778995514],\n",
       "   'area': 108.59210006323039,\n",
       "   'iscrowd': 0,\n",
       "   'category_id': 1,\n",
       "   'segmentation': []},\n",
       "  {'id': 0,\n",
       "   'image_id': 2,\n",
       "   'bbox': [284.4423713684082,\n",
       "    118.81721878051758,\n",
       "    10.353728294372559,\n",
       "    9.22655963897705],\n",
       "   'area': 95.52929159379255,\n",
       "   'iscrowd': 0,\n",
       "   'category_id': 0,\n",
       "   'segmentation': []},\n",
       "  {'id': 1,\n",
       "   'image_id': 2,\n",
       "   'bbox': [246.52588272094727,\n",
       "    51.36095857620239,\n",
       "    8.394623875617981,\n",
       "    7.586431980133057],\n",
       "   'area': 63.68524303117675,\n",
       "   'iscrowd': 0,\n",
       "   'category_id': 0,\n",
       "   'segmentation': []},\n",
       "  {'id': 2,\n",
       "   'image_id': 2,\n",
       "   'bbox': [139.63263511657715,\n",
       "    43.97971153259277,\n",
       "    36.377151012420654,\n",
       "    19.47814440727234],\n",
       "   'area': 708.5594005450827,\n",
       "   'iscrowd': 0,\n",
       "   'category_id': 1,\n",
       "   'segmentation': []},\n",
       "  {'id': 0,\n",
       "   'image_id': 3,\n",
       "   'bbox': [361.4898490905762,\n",
       "    257.31819915771484,\n",
       "    58.42278575897217,\n",
       "    46.3375358581543],\n",
       "   'area': 2707.167930039639,\n",
       "   'iscrowd': 0,\n",
       "   'category_id': 1,\n",
       "   'segmentation': []},\n",
       "  {'id': 1,\n",
       "   'image_id': 3,\n",
       "   'bbox': [107.15488243103027,\n",
       "    150.59789276123047,\n",
       "    29.492287158966064,\n",
       "    39.57184028625488],\n",
       "   'area': 1167.0640771309709,\n",
       "   'iscrowd': 0,\n",
       "   'category_id': 1,\n",
       "   'segmentation': []},\n",
       "  {'id': 2,\n",
       "   'image_id': 3,\n",
       "   'bbox': [293.93863677978516,\n",
       "    124.66093063354492,\n",
       "    7.583744168281555,\n",
       "    13.122368097305298],\n",
       "   'area': 99.51668253198298,\n",
       "   'iscrowd': 0,\n",
       "   'category_id': 1,\n",
       "   'segmentation': []},\n",
       "  {'id': 3,\n",
       "   'image_id': 3,\n",
       "   'bbox': [211.92236709594727,\n",
       "    345.1754837036133,\n",
       "    12.077632069587708,\n",
       "    9.22655963897705],\n",
       "   'area': 111.43499258767281,\n",
       "   'iscrowd': 0,\n",
       "   'category_id': 1,\n",
       "   'segmentation': []},\n",
       "  {'id': 0,\n",
       "   'image_id': 4,\n",
       "   'bbox': [399.8713684082031,\n",
       "    99.04115200042725,\n",
       "    9.15398371219635,\n",
       "    8.844863653182983],\n",
       "   'area': 80.96573781783454,\n",
       "   'iscrowd': 0,\n",
       "   'category_id': 0,\n",
       "   'segmentation': []},\n",
       "  {'id': 1,\n",
       "   'image_id': 4,\n",
       "   'bbox': [161.58508682250977,\n",
       "    92.87040328979492,\n",
       "    11.92799997329712,\n",
       "    8.433600068092346],\n",
       "   'area': 100.59598138700409,\n",
       "   'iscrowd': 0,\n",
       "   'category_id': 1,\n",
       "   'segmentation': []},\n",
       "  {'id': 2,\n",
       "   'image_id': 4,\n",
       "   'bbox': [265.33248138427734,\n",
       "    133.49504470825195,\n",
       "    23.57913613319397,\n",
       "    13.987008213996887],\n",
       "   'area': 329.8015707739348,\n",
       "   'iscrowd': 0,\n",
       "   'category_id': 1,\n",
       "   'segmentation': []},\n",
       "  {'id': 3,\n",
       "   'image_id': 4,\n",
       "   'bbox': [260.4779510498047,\n",
       "    171.95942306518555,\n",
       "    16.089024782180786,\n",
       "    11.107264399528503],\n",
       "   'area': 178.70505218624848,\n",
       "   'iscrowd': 0,\n",
       "   'category_id': 1,\n",
       "   'segmentation': []},\n",
       "  {'id': 4,\n",
       "   'image_id': 4,\n",
       "   'bbox': [182.66751861572266,\n",
       "    174.2222785949707,\n",
       "    42.4421763420105,\n",
       "    12.341504096984863],\n",
       "   'area': 523.8002932098766,\n",
       "   'iscrowd': 0,\n",
       "   'category_id': 1,\n",
       "   'segmentation': []},\n",
       "  {'id': 5,\n",
       "   'image_id': 4,\n",
       "   'bbox': [36.894145488739014,\n",
       "    210.42425537109375,\n",
       "    14.424704313278198,\n",
       "    14.398720741271973],\n",
       "   'area': 207.69728918231408,\n",
       "   'iscrowd': 0,\n",
       "   'category_id': 1,\n",
       "   'segmentation': []},\n",
       "  {'id': 6,\n",
       "   'image_id': 4,\n",
       "   'bbox': [20.527360677719116,\n",
       "    187.5923843383789,\n",
       "    18.30841636657715,\n",
       "    24.683008193969727],\n",
       "   'area': 451.9067911948332,\n",
       "   'iscrowd': 0,\n",
       "   'category_id': 1,\n",
       "   'segmentation': []},\n",
       "  {'id': 7,\n",
       "   'image_id': 4,\n",
       "   'bbox': [350.77144622802734,\n",
       "    291.9817695617676,\n",
       "    8.04473602771759,\n",
       "    8.021888375282288],\n",
       "   'area': 64.53397442296234,\n",
       "   'iscrowd': 0,\n",
       "   'category_id': 0,\n",
       "   'segmentation': []},\n",
       "  {'id': 8,\n",
       "   'image_id': 4,\n",
       "   'bbox': [285.5825309753418,\n",
       "    294.4497833251953,\n",
       "    9.15398371219635,\n",
       "    5.9651198387146],\n",
       "   'area': 54.604609844892764,\n",
       "   'iscrowd': 0,\n",
       "   'category_id': 0,\n",
       "   'segmentation': []},\n",
       "  {'id': 9,\n",
       "   'image_id': 4,\n",
       "   'bbox': [337.4564552307129,\n",
       "    249.60902404785156,\n",
       "    9.15398371219635,\n",
       "    5.553855836391449],\n",
       "   'area': 50.83990586621396,\n",
       "   'iscrowd': 0,\n",
       "   'category_id': 0,\n",
       "   'segmentation': []},\n",
       "  {'id': 0,\n",
       "   'image_id': 5,\n",
       "   'bbox': [263.36800384521484,\n",
       "    125.01618576049805,\n",
       "    17.00921607017517,\n",
       "    47.94854402542114],\n",
       "   'area': 815.567145578695,\n",
       "   'iscrowd': 0,\n",
       "   'category_id': 1,\n",
       "   'segmentation': []},\n",
       "  {'id': 1,\n",
       "   'image_id': 5,\n",
       "   'bbox': [72.01465892791748,\n",
       "    43.00979280471802,\n",
       "    9.053183674812317,\n",
       "    12.759040355682373],\n",
       "   'area': 115.5099358543352,\n",
       "   'iscrowd': 0,\n",
       "   'category_id': 0,\n",
       "   'segmentation': []},\n",
       "  {'id': 2,\n",
       "   'image_id': 5,\n",
       "   'bbox': [130.72371292114258,\n",
       "    75.00953388214111,\n",
       "    7.956032395362854,\n",
       "    5.5560959577560425],\n",
       "   'area': 44.20447943165168,\n",
       "   'iscrowd': 0,\n",
       "   'category_id': 0,\n",
       "   'segmentation': []},\n",
       "  {'id': 3,\n",
       "   'image_id': 5,\n",
       "   'bbox': [431.40250396728516,\n",
       "    251.47269821166992,\n",
       "    8.504384398460388,\n",
       "    15.228415966033936],\n",
       "   'area': 129.50830315480408,\n",
       "   'iscrowd': 0,\n",
       "   'category_id': 1,\n",
       "   'segmentation': []},\n",
       "  {'id': 0,\n",
       "   'image_id': 6,\n",
       "   'bbox': [84.33644962310791,\n",
       "    115.56204414367676,\n",
       "    8.97209620475769,\n",
       "    6.0766719579696655],\n",
       "   'area': 54.52048541165712,\n",
       "   'iscrowd': 0,\n",
       "   'category_id': 0,\n",
       "   'segmentation': []},\n",
       "  {'id': 1,\n",
       "   'image_id': 6,\n",
       "   'bbox': [211.58860778808594,\n",
       "    313.47411727905273,\n",
       "    6.878592014312744,\n",
       "    6.28633588552475],\n",
       "   'area': 43.24113982145818,\n",
       "   'iscrowd': 0,\n",
       "   'category_id': 0,\n",
       "   'segmentation': []},\n",
       "  {'id': 2,\n",
       "   'image_id': 6,\n",
       "   'bbox': [237.00948333740234,\n",
       "    191.31168174743652,\n",
       "    8.074751734733582,\n",
       "    6.28633588552475],\n",
       "   'area': 50.76060159675894,\n",
       "   'iscrowd': 0,\n",
       "   'category_id': 0,\n",
       "   'segmentation': []},\n",
       "  {'id': 3,\n",
       "   'image_id': 6,\n",
       "   'bbox': [239.8506965637207,\n",
       "    73.54905319213867,\n",
       "    11.364415645599365,\n",
       "    7.124543905258179],\n",
       "   'area': 80.96627822467565,\n",
       "   'iscrowd': 0,\n",
       "   'category_id': 1,\n",
       "   'segmentation': []},\n",
       "  {'id': 4,\n",
       "   'image_id': 6,\n",
       "   'bbox': [220.11226081848145,\n",
       "    77.94931411743164,\n",
       "    12.56057620048523,\n",
       "    8.800959944725037],\n",
       "   'area': 110.5451280231371,\n",
       "   'iscrowd': 0,\n",
       "   'category_id': 1,\n",
       "   'segmentation': []},\n",
       "  {'id': 0,\n",
       "   'image_id': 7,\n",
       "   'bbox': [260.0505714416504,\n",
       "    74.07366466522217,\n",
       "    10.261439800262451,\n",
       "    6.695807874202728],\n",
       "   'area': 68.70862941525459,\n",
       "   'iscrowd': 0,\n",
       "   'category_id': 0,\n",
       "   'segmentation': []},\n",
       "  {'id': 1,\n",
       "   'image_id': 7,\n",
       "   'bbox': [338.49805450439453,\n",
       "    142.81165313720703,\n",
       "    6.750912189483643,\n",
       "    5.649727940559387],\n",
       "   'area': 38.140817221188684,\n",
       "   'iscrowd': 0,\n",
       "   'category_id': 0,\n",
       "   'segmentation': []},\n",
       "  {'id': 2,\n",
       "   'image_id': 7,\n",
       "   'bbox': [173.50188827514648,\n",
       "    241.47198867797852,\n",
       "    15.392383337020874,\n",
       "    35.15366506576538],\n",
       "   'area': 541.0986883934999,\n",
       "   'iscrowd': 0,\n",
       "   'category_id': 1,\n",
       "   'segmentation': []},\n",
       "  {'id': 3,\n",
       "   'image_id': 7,\n",
       "   'bbox': [131.7805461883545,\n",
       "    198.57645416259766,\n",
       "    9.18131160736084,\n",
       "    7.5331196784973145],\n",
       "   'area': 69.16391914382575,\n",
       "   'iscrowd': 0,\n",
       "   'category_id': 0,\n",
       "   'segmentation': []},\n",
       "  {'id': 4,\n",
       "   'image_id': 7,\n",
       "   'bbox': [14.98739242553711,\n",
       "    206.63237953186035,\n",
       "    6.211072146892548,\n",
       "    14.01971173286438],\n",
       "   'area': 87.0774410514566,\n",
       "   'iscrowd': 0,\n",
       "   'category_id': 1,\n",
       "   'segmentation': []},\n",
       "  {'id': 5,\n",
       "   'image_id': 7,\n",
       "   'bbox': [329.4515724182129,\n",
       "    32.74745512008667,\n",
       "    12.961983919143677,\n",
       "    19.878655910491943],\n",
       "   'area': 257.666818245987,\n",
       "   'iscrowd': 0,\n",
       "   'category_id': 1,\n",
       "   'segmentation': []},\n",
       "  {'id': 6,\n",
       "   'image_id': 7,\n",
       "   'bbox': [212.25298881530762,\n",
       "    37.559871673583984,\n",
       "    23.76371145248413,\n",
       "    20.715519189834595],\n",
       "   'area': 492.27762061562714,\n",
       "   'iscrowd': 0,\n",
       "   'category_id': 1,\n",
       "   'segmentation': []},\n",
       "  {'id': 0,\n",
       "   'image_id': 8,\n",
       "   'bbox': [96.9884147644043,\n",
       "    99.31577777862549,\n",
       "    7.4712958335876465,\n",
       "    5.957055985927582],\n",
       "   'area': 44.50692756810909,\n",
       "   'iscrowd': 0,\n",
       "   'category_id': 0,\n",
       "   'segmentation': []},\n",
       "  {'id': 1,\n",
       "   'image_id': 8,\n",
       "   'bbox': [273.53178787231445,\n",
       "    194.83161544799805,\n",
       "    7.4712958335876465,\n",
       "    5.957055985927582],\n",
       "   'area': 44.50692756810909,\n",
       "   'iscrowd': 0,\n",
       "   'category_id': 0,\n",
       "   'segmentation': []},\n",
       "  {'id': 2,\n",
       "   'image_id': 8,\n",
       "   'bbox': [265.50719833374023,\n",
       "    194.6264305114746,\n",
       "    6.364287853240967,\n",
       "    6.367871880531311],\n",
       "   'area': 40.526969660260136,\n",
       "   'iscrowd': 0,\n",
       "   'category_id': 0,\n",
       "   'segmentation': []},\n",
       "  {'id': 3,\n",
       "   'image_id': 8,\n",
       "   'bbox': [194.1148166656494,\n",
       "    289.7314643859863,\n",
       "    6.918015897274017,\n",
       "    5.5462400913238525],\n",
       "   'area': 38.36897712187691,\n",
       "   'iscrowd': 0,\n",
       "   'category_id': 0,\n",
       "   'segmentation': []},\n",
       "  {'id': 4,\n",
       "   'image_id': 8,\n",
       "   'bbox': [254.4384536743164,\n",
       "    285.62330627441406,\n",
       "    5.811007916927338,\n",
       "    4.313791990280151],\n",
       "   'area': 25.067479407495696,\n",
       "   'iscrowd': 0,\n",
       "   'category_id': 0,\n",
       "   'segmentation': []},\n",
       "  {'id': 0,\n",
       "   'image_id': 9,\n",
       "   'bbox': [235.02484512329102,\n",
       "    183.77184295654297,\n",
       "    7.015679597854614,\n",
       "    5.93779194355011],\n",
       "   'area': 41.65764579467,\n",
       "   'iscrowd': 0,\n",
       "   'category_id': 0,\n",
       "   'segmentation': []},\n",
       "  {'id': 0,\n",
       "   'image_id': 10,\n",
       "   'bbox': [223.83334732055664,\n",
       "    28.83148765563965,\n",
       "    38.333120346069336,\n",
       "    17.446911334991455],\n",
       "   'area': 668.7945518714287,\n",
       "   'iscrowd': 0,\n",
       "   'category_id': 1,\n",
       "   'segmentation': []},\n",
       "  {'id': 1,\n",
       "   'image_id': 10,\n",
       "   'bbox': [251.33338928222656,\n",
       "    131.73843574523926,\n",
       "    12.000127792358398,\n",
       "    7.98425567150116],\n",
       "   'area': 95.81208838487623,\n",
       "   'iscrowd': 0,\n",
       "   'category_id': 0,\n",
       "   'segmentation': []},\n",
       "  {'id': 2,\n",
       "   'image_id': 10,\n",
       "   'bbox': [347.33350372314453,\n",
       "    133.95648384094238,\n",
       "    7.333312034606934,\n",
       "    9.462655663490295],\n",
       "   'area': 69.39260665641484,\n",
       "   'iscrowd': 0,\n",
       "   'category_id': 0,\n",
       "   'segmentation': []},\n",
       "  {'id': 3,\n",
       "   'image_id': 10,\n",
       "   'bbox': [63.16665267944336,\n",
       "    213.0589485168457,\n",
       "    8.999872207641602,\n",
       "    9.16697633266449],\n",
       "   'area': 82.50161552445547,\n",
       "   'iscrowd': 0,\n",
       "   'category_id': 0,\n",
       "   'segmentation': []},\n",
       "  {'id': 4,\n",
       "   'image_id': 10,\n",
       "   'bbox': [135.9998016357422,\n",
       "    257.4149703979492,\n",
       "    6.666687965393066,\n",
       "    7.3928961753845215],\n",
       "   'area': 49.28613196183642,\n",
       "   'iscrowd': 0,\n",
       "   'category_id': 0,\n",
       "   'segmentation': []},\n",
       "  {'id': 5,\n",
       "   'image_id': 10,\n",
       "   'bbox': [111.33337593078613,\n",
       "    280.3328514099121,\n",
       "    17.333120346069336,\n",
       "    10.645376324653625],\n",
       "   'area': 184.51758896441856,\n",
       "   'iscrowd': 0,\n",
       "   'category_id': 1,\n",
       "   'segmentation': []},\n",
       "  {'id': 6,\n",
       "   'image_id': 10,\n",
       "   'bbox': [166.0001277923584,\n",
       "    297.92761993408203,\n",
       "    6.000063896179199,\n",
       "    7.3928961753845215],\n",
       "   'area': 44.35784943012595,\n",
       "   'iscrowd': 0,\n",
       "   'category_id': 0,\n",
       "   'segmentation': []},\n",
       "  {'id': 7,\n",
       "   'image_id': 10,\n",
       "   'bbox': [33.83340787887573,\n",
       "    157.16960525512695,\n",
       "    8.333248138427734,\n",
       "    7.98425567150116],\n",
       "   'area': 66.53478371126812,\n",
       "   'iscrowd': 0,\n",
       "   'category_id': 0,\n",
       "   'segmentation': []},\n",
       "  {'id': 0,\n",
       "   'image_id': 11,\n",
       "   'bbox': [331.4796829223633,\n",
       "    365.0263786315918,\n",
       "    14.7324800491333,\n",
       "    12.90060818195343],\n",
       "   'area': 190.05795266231473,\n",
       "   'iscrowd': 0,\n",
       "   'category_id': 1,\n",
       "   'segmentation': []},\n",
       "  {'id': 1,\n",
       "   'image_id': 11,\n",
       "   'bbox': [176.28710556030273,\n",
       "    373.9684524536133,\n",
       "    11.049471855163574,\n",
       "    9.675455927848816],\n",
       "   'area': 106.90867796064106,\n",
       "   'iscrowd': 0,\n",
       "   'category_id': 0,\n",
       "   'segmentation': []},\n",
       "  {'id': 0,\n",
       "   'image_id': 12,\n",
       "   'bbox': [383.04850006103516,\n",
       "    47.98931264877319,\n",
       "    39.97011041641235,\n",
       "    28.614656925201416],\n",
       "   'area': 1143.730996828059,\n",
       "   'iscrowd': 0,\n",
       "   'category_id': 1,\n",
       "   'segmentation': []},\n",
       "  {'id': 1,\n",
       "   'image_id': 12,\n",
       "   'bbox': [117.24607467651367,\n",
       "    31.14854335784912,\n",
       "    11.991168141365051,\n",
       "    8.047871947288513],\n",
       "   'area': 96.50338570011154,\n",
       "   'iscrowd': 0,\n",
       "   'category_id': 0,\n",
       "   'segmentation': []},\n",
       "  {'id': 2,\n",
       "   'image_id': 12,\n",
       "   'bbox': [37.80537462234497,\n",
       "    101.0459508895874,\n",
       "    13.656383991241455,\n",
       "    11.326783776283264],\n",
       "   'area': 154.6829086346882,\n",
       "   'iscrowd': 0,\n",
       "   'category_id': 1,\n",
       "   'segmentation': []},\n",
       "  {'id': 3,\n",
       "   'image_id': 12,\n",
       "   'bbox': [49.62988758087158,\n",
       "    209.09638786315918,\n",
       "    15.988224744796753,\n",
       "    21.16307282447815],\n",
       "   'area': 338.35996460825726,\n",
       "   'iscrowd': 0,\n",
       "   'category_id': 1,\n",
       "   'segmentation': []},\n",
       "  {'id': 4,\n",
       "   'image_id': 12,\n",
       "   'bbox': [56.12498950958252,\n",
       "    323.1083564758301,\n",
       "    7.660800337791443,\n",
       "    10.730495929718018],\n",
       "   'area': 82.20418684305349,\n",
       "   'iscrowd': 0,\n",
       "   'category_id': 0,\n",
       "   'segmentation': []},\n",
       "  {'id': 5,\n",
       "   'image_id': 12,\n",
       "   'bbox': [64.28530979156494,\n",
       "    333.98804473876953,\n",
       "    5.995584070682526,\n",
       "    6.855743944644928],\n",
       "   'area': 41.10418918719131,\n",
       "   'iscrowd': 0,\n",
       "   'category_id': 0,\n",
       "   'segmentation': []},\n",
       "  {'id': 6,\n",
       "   'image_id': 12,\n",
       "   'bbox': [341.74560546875,\n",
       "    339.6511917114258,\n",
       "    21.98380756378174,\n",
       "    22.355199575424194],\n",
       "   'area': 491.4524055160607,\n",
       "   'iscrowd': 0,\n",
       "   'category_id': 1,\n",
       "   'segmentation': []},\n",
       "  {'id': 7,\n",
       "   'image_id': 12,\n",
       "   'bbox': [21.98380756378174,\n",
       "    34.725377559661865,\n",
       "    11.991168141365051,\n",
       "    18.182080030441284],\n",
       "   'area': 218.02437880477723,\n",
       "   'iscrowd': 0,\n",
       "   'category_id': 1,\n",
       "   'segmentation': []},\n",
       "  {'id': 0,\n",
       "   'image_id': 13,\n",
       "   'bbox': [403.49433517456055,\n",
       "    142.9164752960205,\n",
       "    14.398720741271973,\n",
       "    11.083519697189331],\n",
       "   'area': 159.58850495021647,\n",
       "   'iscrowd': 0,\n",
       "   'category_id': 1,\n",
       "   'segmentation': []},\n",
       "  {'id': 1,\n",
       "   'image_id': 13,\n",
       "   'bbox': [422.4747428894043,\n",
       "    149.77087783813477,\n",
       "    6.544831871986389,\n",
       "    9.041536211967468],\n",
       "   'area': 59.17533437180377,\n",
       "   'iscrowd': 0,\n",
       "   'category_id': 0,\n",
       "   'segmentation': []},\n",
       "  {'id': 2,\n",
       "   'image_id': 13,\n",
       "   'bbox': [48.59590530395508,\n",
       "    80.20813083648682,\n",
       "    11.45356822013855,\n",
       "    13.416703939437866],\n",
       "   'area': 153.66913385975323,\n",
       "   'iscrowd': 0,\n",
       "   'category_id': 1,\n",
       "   'segmentation': []},\n",
       "  {'id': 0,\n",
       "   'image_id': 14,\n",
       "   'bbox': [140.91391944885254,\n",
       "    103.85849857330322,\n",
       "    7.976192235946655,\n",
       "    6.454335808753967],\n",
       "   'area': 51.48102316597587,\n",
       "   'iscrowd': 0,\n",
       "   'category_id': 0,\n",
       "   'segmentation': []},\n",
       "  {'id': 1,\n",
       "   'image_id': 14,\n",
       "   'bbox': [295.12178802490234,\n",
       "    211.97120666503906,\n",
       "    7.311359763145447,\n",
       "    7.334656357765198],\n",
       "   'area': 53.6263113706634,\n",
       "   'iscrowd': 0,\n",
       "   'category_id': 0,\n",
       "   'segmentation': []},\n",
       "  {'id': 2,\n",
       "   'image_id': 14,\n",
       "   'bbox': [424.23718643188477,\n",
       "    192.46125411987305,\n",
       "    16.949631929397583,\n",
       "    12.322239637374878],\n",
       "   'area': 208.85742639933773,\n",
       "   'iscrowd': 0,\n",
       "   'category_id': 1,\n",
       "   'segmentation': []},\n",
       "  {'id': 0,\n",
       "   'image_id': 15,\n",
       "   'bbox': [164.61221885681152,\n",
       "    184.62662887573242,\n",
       "    7.360639929771423,\n",
       "    6.4883840680122375],\n",
       "   'area': 47.75865885070362,\n",
       "   'iscrowd': 0,\n",
       "   'category_id': 0,\n",
       "   'segmentation': []},\n",
       "  {'id': 1,\n",
       "   'image_id': 15,\n",
       "   'bbox': [118.77510833740234,\n",
       "    320.29491424560547,\n",
       "    7.360639929771423,\n",
       "    5.308800160884857],\n",
       "   'area': 39.076166443386036,\n",
       "   'iscrowd': 0,\n",
       "   'category_id': 0,\n",
       "   'segmentation': []},\n",
       "  {'id': 2,\n",
       "   'image_id': 15,\n",
       "   'bbox': [406.67961502075195,\n",
       "    313.3639144897461,\n",
       "    8.36460816860199,\n",
       "    6.783616125583649],\n",
       "   'area': 56.74229085671717,\n",
       "   'iscrowd': 0,\n",
       "   'category_id': 0,\n",
       "   'segmentation': []},\n",
       "  {'id': 3,\n",
       "   'image_id': 15,\n",
       "   'bbox': [31.450496196746826,\n",
       "    247.5943717956543,\n",
       "    12.044927716255188,\n",
       "    9.142784357070923],\n",
       "   'area': 110.12417670622793,\n",
       "   'iscrowd': 0,\n",
       "   'category_id': 1,\n",
       "   'segmentation': []},\n",
       "  {'id': 4,\n",
       "   'image_id': 15,\n",
       "   'bbox': [269.50245666503906,\n",
       "    177.99084281921387,\n",
       "    38.476481437683105,\n",
       "    14.451584100723267],\n",
       "   'area': 556.0461073965951,\n",
       "   'iscrowd': 0,\n",
       "   'category_id': 1,\n",
       "   'segmentation': []},\n",
       "  {'id': 5,\n",
       "   'image_id': 15,\n",
       "   'bbox': [388.278018951416,\n",
       "    100.57152080535889,\n",
       "    9.033471941947937,\n",
       "    6.4883840680122375],\n",
       "   'area': 58.61263542697056,\n",
       "   'iscrowd': 0,\n",
       "   'category_id': 0,\n",
       "   'segmentation': []},\n",
       "  {'id': 6,\n",
       "   'image_id': 15,\n",
       "   'bbox': [368.53778076171875,\n",
       "    49.10617733001709,\n",
       "    10.372095704078674,\n",
       "    7.963199615478516],\n",
       "   'area': 82.59506852242566,\n",
       "   'iscrowd': 0,\n",
       "   'category_id': 0,\n",
       "   'segmentation': []},\n",
       "  {'id': 7,\n",
       "   'image_id': 15,\n",
       "   'bbox': [280.2092170715332,\n",
       "    30.230591773986816,\n",
       "    7.695296287536621,\n",
       "    6.783616125583649],\n",
       "   'area': 52.20193598727741,\n",
       "   'iscrowd': 0,\n",
       "   'category_id': 0,\n",
       "   'segmentation': []},\n",
       "  {'id': 0,\n",
       "   'image_id': 16,\n",
       "   'bbox': [58.72294616699219,\n",
       "    116.19104385375977,\n",
       "    50.51424026489258,\n",
       "    36.88204908370972],\n",
       "   'area': 1863.0686888760738,\n",
       "   'iscrowd': 0,\n",
       "   'category_id': 1,\n",
       "   'segmentation': []},\n",
       "  {'id': 1,\n",
       "   'image_id': 16,\n",
       "   'bbox': [275.7771530151367,\n",
       "    123.9284439086914,\n",
       "    17.364479541778564,\n",
       "    12.121983885765076],\n",
       "   'area': 210.49194119013708,\n",
       "   'iscrowd': 0,\n",
       "   'category_id': 0,\n",
       "   'segmentation': []},\n",
       "  {'id': 2,\n",
       "   'image_id': 16,\n",
       "   'bbox': [363.23034286499023,\n",
       "    182.7333812713623,\n",
       "    9.155776143074036,\n",
       "    10.574591994285583],\n",
       "   'area': 96.81859710402163,\n",
       "   'iscrowd': 0,\n",
       "   'category_id': 0,\n",
       "   'segmentation': []},\n",
       "  {'id': 3,\n",
       "   'image_id': 16,\n",
       "   'bbox': [164.32998275756836,\n",
       "    127.41029930114746,\n",
       "    62.19584274291992,\n",
       "    24.760064363479614],\n",
       "   'area': 1539.9730694555537,\n",
       "   'iscrowd': 0,\n",
       "   'category_id': 1,\n",
       "   'segmentation': []},\n",
       "  {'id': 0,\n",
       "   'image_id': 17,\n",
       "   'bbox': [405.12281036376953,\n",
       "    129.6252098083496,\n",
       "    41.80915117263794,\n",
       "    59.750205993652344],\n",
       "   'area': 2498.1053949848683,\n",
       "   'iscrowd': 0,\n",
       "   'category_id': 1,\n",
       "   'segmentation': []},\n",
       "  {'id': 1,\n",
       "   'image_id': 17,\n",
       "   'bbox': [295.56396102905273,\n",
       "    120.62489700317383,\n",
       "    16.1745924949646,\n",
       "    14.2499840259552],\n",
       "   'area': 230.4876846795804,\n",
       "   'iscrowd': 0,\n",
       "   'category_id': 0,\n",
       "   'segmentation': []},\n",
       "  {'id': 2,\n",
       "   'image_id': 17,\n",
       "   'bbox': [150.7573757171631,\n",
       "    180.37510299682617,\n",
       "    25.635007619857788,\n",
       "    13.2500479221344],\n",
       "   'area': 339.6650794473962,\n",
       "   'iscrowd': 0,\n",
       "   'category_id': 0,\n",
       "   'segmentation': []},\n",
       "  {'id': 3,\n",
       "   'image_id': 17,\n",
       "   'bbox': [200.04364395141602,\n",
       "    328.87500381469727,\n",
       "    16.1745924949646,\n",
       "    14.7499520778656],\n",
       "   'area': 238.57446417973244,\n",
       "   'iscrowd': 0,\n",
       "   'category_id': 0,\n",
       "   'segmentation': []},\n",
       "  {'id': 4,\n",
       "   'image_id': 17,\n",
       "   'bbox': [358.7355537414551,\n",
       "    335.87500381469727,\n",
       "    65.00256252288818,\n",
       "    70.74995040893555],\n",
       "   'area': 4598.928074948071,\n",
       "   'iscrowd': 0,\n",
       "   'category_id': 1,\n",
       "   'segmentation': []},\n",
       "  {'id': 5,\n",
       "   'image_id': 17,\n",
       "   'bbox': [62.713725090026855,\n",
       "    191.74982261657715,\n",
       "    41.80915117263794,\n",
       "    91.9999361038208],\n",
       "   'area': 3846.439236437675,\n",
       "   'iscrowd': 0,\n",
       "   'category_id': 1,\n",
       "   'segmentation': []},\n",
       "  {'id': 0,\n",
       "   'image_id': 18,\n",
       "   'bbox': [300.5403633117676,\n",
       "    340.46028900146484,\n",
       "    23.14412784576416,\n",
       "    14.86732792854309],\n",
       "   'area': 344.09133830310134,\n",
       "   'iscrowd': 0,\n",
       "   'category_id': 0,\n",
       "   'segmentation': []},\n",
       "  {'id': 1,\n",
       "   'image_id': 18,\n",
       "   'bbox': [216.72626876831055,\n",
       "    209.2567653656006,\n",
       "    18.184319734573364,\n",
       "    11.150271892547607],\n",
       "   'area': 202.76010922151215,\n",
       "   'iscrowd': 0,\n",
       "   'category_id': 0,\n",
       "   'segmentation': []},\n",
       "  {'id': 2,\n",
       "   'image_id': 18,\n",
       "   'bbox': [364.68185806274414,\n",
       "    129.2211151123047,\n",
       "    12.563712120056152,\n",
       "    12.637184262275696],\n",
       "   'area': 158.76994507933603,\n",
       "   'iscrowd': 0,\n",
       "   'category_id': 0,\n",
       "   'segmentation': []},\n",
       "  {'id': 3,\n",
       "   'image_id': 18,\n",
       "   'bbox': [40.501888275146484, 308.0, 28.764737129211426, 47.07942533493042],\n",
       "   'area': 1354.2272939536101,\n",
       "   'iscrowd': 0,\n",
       "   'category_id': 1,\n",
       "   'segmentation': []},\n",
       "  {'id': 0,\n",
       "   'image_id': 19,\n",
       "   'bbox': [340.0687446594238, 126.1263313293457, 64.1755542755127, 56.0],\n",
       "   'area': 3593.831039428711,\n",
       "   'iscrowd': 0,\n",
       "   'category_id': 1,\n",
       "   'segmentation': []},\n",
       "  {'id': 1,\n",
       "   'image_id': 19,\n",
       "   'bbox': [407.4680976867676,\n",
       "    112.50444412231445,\n",
       "    54.042688846588135,\n",
       "    54.99110507965088],\n",
       "   'area': 2971.8671811496047,\n",
       "   'iscrowd': 0,\n",
       "   'category_id': 1,\n",
       "   'segmentation': []},\n",
       "  {'id': 2,\n",
       "   'image_id': 19,\n",
       "   'bbox': [88.2797441482544,\n",
       "    216.4323902130127,\n",
       "    18.73043203353882,\n",
       "    9.585407972335815],\n",
       "   'area': 179.53883253957713,\n",
       "   'iscrowd': 0,\n",
       "   'category_id': 0,\n",
       "   'segmentation': []},\n",
       "  {'id': 3,\n",
       "   'image_id': 19,\n",
       "   'bbox': [193.1404151916504,\n",
       "    146.18015480041504,\n",
       "    15.967167854309082,\n",
       "    15.89190411567688],\n",
       "   'area': 253.74870053959808,\n",
       "   'iscrowd': 0,\n",
       "   'category_id': 0,\n",
       "   'segmentation': []},\n",
       "  {'id': 4,\n",
       "   'image_id': 19,\n",
       "   'bbox': [153.68326377868652,\n",
       "    353.65746688842773,\n",
       "    19.344640016555786,\n",
       "    9.080959677696228],\n",
       "   'area': 175.667895969892,\n",
       "   'iscrowd': 0,\n",
       "   'category_id': 0,\n",
       "   'segmentation': []},\n",
       "  {'id': 5,\n",
       "   'image_id': 19,\n",
       "   'bbox': [54.349568367004395,\n",
       "    124.73887634277344,\n",
       "    52.20006322860718,\n",
       "    40.612545013427734],\n",
       "   'area': 2119.977417575583,\n",
       "   'iscrowd': 0,\n",
       "   'category_id': 1,\n",
       "   'segmentation': []},\n",
       "  {'id': 6,\n",
       "   'image_id': 19,\n",
       "   'bbox': [349.4337387084961,\n",
       "    347.0992126464844,\n",
       "    84.13440227508545,\n",
       "    32.28825569152832],\n",
       "   'area': 2716.553093111861,\n",
       "   'iscrowd': 0,\n",
       "   'category_id': 1,\n",
       "   'segmentation': []},\n",
       "  {'id': 7,\n",
       "   'image_id': 19,\n",
       "   'bbox': [73.0799970626831,\n",
       "    257.675724029541,\n",
       "    80.44959831237793,\n",
       "    95.09919929504395],\n",
       "   'area': 7650.69238311506,\n",
       "   'iscrowd': 0,\n",
       "   'category_id': 1,\n",
       "   'segmentation': []},\n",
       "  {'id': 0,\n",
       "   'image_id': 0,\n",
       "   'bbox': [289.3614158630371,\n",
       "    332.76005935668945,\n",
       "    13.038591980934143,\n",
       "    6.861119985580444],\n",
       "   'area': 89.45934402421616,\n",
       "   'iscrowd': 0,\n",
       "   'category_id': 0,\n",
       "   'segmentation': []},\n",
       "  {'id': 1,\n",
       "   'image_id': 0,\n",
       "   'bbox': [399.3552551269531,\n",
       "    271.77292251586914,\n",
       "    9.695615768432617,\n",
       "    9.402176141738892],\n",
       "   'area': 91.15988725742454,\n",
       "   'iscrowd': 0,\n",
       "   'category_id': 0,\n",
       "   'segmentation': []}]}"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "json_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "e29cd722",
   "metadata": {},
   "outputs": [
    {
     "ename": "Exception",
     "evalue": "datasetType not supported",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mException\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[72], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mcocoGt\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mshowAnns\u001b[49m\u001b[43m(\u001b[49m\u001b[43manns\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mbbox\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/usr/local/lib/python3.8/dist-packages/pycocotools/coco.py:299\u001b[0m, in \u001b[0;36mCOCO.showAnns\u001b[0;34m(self, anns)\u001b[0m\n\u001b[1;32m    297\u001b[0m     datasetType \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcaptions\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m    298\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 299\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdatasetType not supported\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m    300\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m datasetType \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124minstances\u001b[39m\u001b[38;5;124m'\u001b[39m:\n\u001b[1;32m    301\u001b[0m     ax \u001b[38;5;241m=\u001b[39m plt\u001b[38;5;241m.\u001b[39mgca()\n",
      "\u001b[0;31mException\u001b[0m: datasetType not supported"
     ]
    }
   ],
   "source": [
    "cocoGt.showAnns(anns='bbox')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "68ba0798",
   "metadata": {},
   "outputs": [],
   "source": [
    "# COCO에서는 x_min, y_min, w, h를 지원하기 때문에\n",
    "# x_cen, y_cen, w, h를 x_min, y_min, w, h로 바꿔줘야한다.\n",
    "def XcenYcenWH_to_XminYmin_WH(box):\n",
    "    Xmin = box[:, 0] - box[:, 2]/2\n",
    "    Ymin = box[:, 1] - box[:, 3]/2\n",
    "    W = box[:, 2]\n",
    "    H = box[:, 3]\n",
    "    return np.stack((Xmin, Ymin, W, H), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "9f422091",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0/20 Done.\n"
     ]
    }
   ],
   "source": [
    "COCO_anno = []\n",
    "\n",
    "for index, batch in enumerate(test_dataloaders):\n",
    "    images = batch[0].to(device)\n",
    "    filename = batch[2][0]\n",
    "\n",
    "    bboxes, scores, class_ids = model_predict(images, model, conf_thres=0.1, iou_threshold=0.1)\n",
    "    box_xywh = XcenYcenWH_to_XminYmin_WH(bboxes)\n",
    "    score = scores[:, np.newaxis]\n",
    "    cls_id = class_ids[:, np.newaxis]\n",
    "\n",
    "    img_id = np.array([imageToid[filename], ] * len(cls_id))[:, np.newaxis]\n",
    "    COCO_anno.append(np.concatenate((img_id, box_xywh, score, cls_id), axis=1))\n",
    "\n",
    "    if index % 50 == 0:\n",
    "        print(f\"{index}/{len(test_dataloaders)} Done.\")\n",
    "\n",
    "COCO_anno = np.concatenate(COCO_anno, axis=0)\n",
    "# COCO_anno.shape은 (2331,7)이 나오는데 prediction한 결과물이 2331개, 7개는 imageid, box좌표 4개, score, class id\n",
    "# 이다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "02f18118",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 1.00000000e+00,  5.45950546e+01,  8.31340027e+01,\n",
       "         6.72633667e+01,  2.59286194e+01,  4.68564093e-01,\n",
       "         1.00000000e+00],\n",
       "       [ 1.00000000e+00,  2.53172150e+02,  2.72938271e+01,\n",
       "         4.12192993e+01,  1.17416897e+01,  2.81199336e-01,\n",
       "         1.00000000e+00],\n",
       "       [ 1.00000000e+00,  2.62366028e+02,  3.81568756e+01,\n",
       "         3.86082764e+01,  1.59544830e+01,  1.96980491e-01,\n",
       "         1.00000000e+00],\n",
       "       [ 1.00000000e+00,  1.68209839e+01,  3.07458588e+02,\n",
       "         5.60678940e+01,  4.72313232e+01,  1.51311278e-01,\n",
       "         1.00000000e+00],\n",
       "       [ 1.00000000e+00,  1.29427597e+02,  1.20509850e+02,\n",
       "         3.36961060e+01, -1.33567810e+00,  1.22508153e-01,\n",
       "         1.00000000e+00],\n",
       "       [ 1.00000000e+00,  1.46362259e+02,  2.67868378e+02,\n",
       "         3.49928284e+01,  4.33332520e+01,  1.11201063e-01,\n",
       "         1.00000000e+00],\n",
       "       [ 1.00000000e+00,  3.59887848e+01,  2.61313171e+02,\n",
       "         7.83865356e+00,  7.92987061e+00,  1.08486384e-01,\n",
       "         0.00000000e+00],\n",
       "       [ 2.00000000e+00,  2.76704285e+02,  1.19436440e+02,\n",
       "         1.08864136e+01,  7.33793640e+00,  1.04002438e-01,\n",
       "         0.00000000e+00],\n",
       "       [ 3.00000000e+00,  3.39757629e+02,  2.43729187e+02,\n",
       "         2.89874878e+01,  2.15596619e+01,  2.06679642e-01,\n",
       "         1.00000000e+00],\n",
       "       [ 3.00000000e+00,  5.30737000e+01,  3.06593964e+02,\n",
       "         6.71400452e+01,  6.12566528e+01,  1.38508156e-01,\n",
       "         1.00000000e+00],\n",
       "       [ 4.00000000e+00,  2.63101318e+02,  1.45425339e+02,\n",
       "         3.73135376e+01,  2.77233582e+01,  1.59474507e-01,\n",
       "         1.00000000e+00],\n",
       "       [ 4.00000000e+00,  4.01199188e+01,  1.88946930e+02,\n",
       "         1.96670837e+01,  2.45867615e+01,  1.32946536e-01,\n",
       "         1.00000000e+00],\n",
       "       [ 4.00000000e+00,  3.92103333e+02,  1.02850388e+02,\n",
       "         1.05815430e+01,  9.80790710e+00,  1.17251314e-01,\n",
       "         0.00000000e+00],\n",
       "       [ 5.00000000e+00,  3.39369537e+02,  1.96122101e+02,\n",
       "         3.87935181e+01,  4.15890503e+01,  1.34373233e-01,\n",
       "         1.00000000e+00],\n",
       "       [ 5.00000000e+00,  3.57917542e+02,  1.59929474e+02,\n",
       "         2.58137207e+01,  3.56095581e+01,  1.15830168e-01,\n",
       "         1.00000000e+00],\n",
       "       [ 5.00000000e+00,  3.37819427e+02,  3.23551575e+02,\n",
       "         4.08377686e+01,  5.51270142e+01,  1.08378597e-01,\n",
       "         1.00000000e+00],\n",
       "       [ 1.00000000e+01,  2.05814941e+02,  3.25806046e+01,\n",
       "         4.15003052e+01,  4.25471497e+00,  1.59416422e-01,\n",
       "         1.00000000e+00],\n",
       "       [ 1.00000000e+01,  3.38774780e+02,  1.37422165e+02,\n",
       "         9.64758301e+00,  8.67605591e+00,  1.23065501e-01,\n",
       "         0.00000000e+00],\n",
       "       [ 1.00000000e+01,  7.04817734e+01,  2.77363617e+02,\n",
       "         2.92105560e+01,  2.36818237e+01,  1.15406081e-01,\n",
       "         1.00000000e+00],\n",
       "       [ 1.10000000e+01,  2.60551758e+01,  9.83486176e+01,\n",
       "         4.28872223e+01,  7.79568176e+01,  3.63612235e-01,\n",
       "         1.00000000e+00],\n",
       "       [ 1.10000000e+01,  2.62763153e+02,  2.15091614e+02,\n",
       "         1.01166382e+01,  8.36184692e+00,  1.96729779e-01,\n",
       "         0.00000000e+00],\n",
       "       [ 1.10000000e+01,  1.73847412e+02,  9.21521530e+01,\n",
       "         1.02268372e+01,  8.56129456e+00,  1.40329957e-01,\n",
       "         0.00000000e+00],\n",
       "       [ 1.10000000e+01,  3.29249023e+02,  4.58714752e+01,\n",
       "         1.05214844e+01,  9.93363953e+00,  1.17161259e-01,\n",
       "         0.00000000e+00],\n",
       "       [ 1.10000000e+01,  3.41497253e+02,  1.69075439e+02,\n",
       "         7.69299316e+00,  8.89263916e+00,  1.15738861e-01,\n",
       "         0.00000000e+00],\n",
       "       [ 1.10000000e+01,  6.79914703e+01,  2.05712769e+02,\n",
       "         8.61228943e+00,  8.42349243e+00,  1.02802172e-01,\n",
       "         0.00000000e+00],\n",
       "       [ 1.20000000e+01,  5.81324158e+01,  2.01292786e+02,\n",
       "         2.04159393e+01,  8.19128418e+00,  3.13415259e-01,\n",
       "         1.00000000e+00],\n",
       "       [ 1.20000000e+01,  3.77042145e+02,  5.54944153e+01,\n",
       "         3.57032471e+01,  1.37575607e+01,  2.20533013e-01,\n",
       "         1.00000000e+00],\n",
       "       [ 1.20000000e+01,  3.55381226e+02,  4.14003830e+01,\n",
       "         4.62058105e+01,  7.71730042e+00,  2.18239516e-01,\n",
       "         1.00000000e+00],\n",
       "       [ 1.20000000e+01,  3.73928375e+02,  2.01021118e+01,\n",
       "         3.33538818e+01,  2.41212387e+01,  2.13926837e-01,\n",
       "         1.00000000e+00],\n",
       "       [ 1.20000000e+01,  1.22758484e+02,  3.02923241e+01,\n",
       "         1.23826904e+01,  1.19346237e+01,  1.86385378e-01,\n",
       "         0.00000000e+00],\n",
       "       [ 1.40000000e+01,  2.87829163e+02,  2.08671967e+02,\n",
       "         1.11901245e+01,  9.50152588e+00,  2.74542749e-01,\n",
       "         0.00000000e+00],\n",
       "       [ 1.40000000e+01,  1.31800751e+02,  9.78252411e+01,\n",
       "         1.18191223e+01,  9.44015503e+00,  2.06479713e-01,\n",
       "         0.00000000e+00],\n",
       "       [ 1.50000000e+01,  2.26146240e+02,  1.59955551e+02,\n",
       "         6.54940948e+01,  3.08700867e+01,  2.90015996e-01,\n",
       "         1.00000000e+00],\n",
       "       [ 1.50000000e+01,  1.66739014e+02,  1.76303070e+02,\n",
       "         1.15086670e+01,  9.91195679e+00,  2.35127956e-01,\n",
       "         0.00000000e+00],\n",
       "       [ 1.50000000e+01,  3.89738556e+02,  1.01213936e+02,\n",
       "         1.02603760e+01,  6.99925232e+00,  1.55789107e-01,\n",
       "         0.00000000e+00],\n",
       "       [ 1.50000000e+01,  3.96670319e+02,  2.98372925e+02,\n",
       "         9.51666260e+00,  8.70501709e+00,  1.29295990e-01,\n",
       "         0.00000000e+00],\n",
       "       [ 1.50000000e+01,  2.32195663e+01,  2.26431747e+02,\n",
       "         1.60292511e+01,  1.74015808e+01,  1.02666527e-01,\n",
       "         1.00000000e+00],\n",
       "       [ 1.50000000e+01,  1.06065163e+02,  3.06053772e+02,\n",
       "         9.26734924e+00,  7.30694580e+00,  1.02127701e-01,\n",
       "         0.00000000e+00],\n",
       "       [ 1.60000000e+01,  1.56448555e+01,  8.23272247e+01,\n",
       "         4.60871506e+01,  3.84539642e+01,  3.58062088e-01,\n",
       "         1.00000000e+00],\n",
       "       [ 1.60000000e+01,  1.22153320e+02,  9.65531616e+01,\n",
       "         6.12883911e+01,  4.49446716e+01,  2.29844749e-01,\n",
       "         1.00000000e+00],\n",
       "       [ 1.60000000e+01,  2.67630402e+02,  1.13028648e+02,\n",
       "         1.37642212e+01,  1.22866669e+01,  2.13571921e-01,\n",
       "         0.00000000e+00],\n",
       "       [ 1.60000000e+01,  2.40874004e+01,  1.20768311e+02,\n",
       "         4.11751137e+01,  4.21452026e+01,  1.78820550e-01,\n",
       "         1.00000000e+00],\n",
       "       [ 1.60000000e+01,  3.58797241e+02,  1.79497711e+02,\n",
       "         1.27983398e+01,  1.02404480e+01,  1.31158233e-01,\n",
       "         0.00000000e+00],\n",
       "       [ 1.60000000e+01,  9.33009415e+01,  1.84319763e+02,\n",
       "         2.58386536e+01,  3.14971619e+01,  1.23886377e-01,\n",
       "         1.00000000e+00],\n",
       "       [ 1.70000000e+01,  3.82362976e+02,  1.03237793e+02,\n",
       "         5.40891113e+01,  5.75663528e+01,  3.33290339e-01,\n",
       "         1.00000000e+00],\n",
       "       [ 1.70000000e+01,  1.35361877e+02,  1.73950668e+02,\n",
       "         1.34229736e+01,  1.11173401e+01,  2.40575075e-01,\n",
       "         0.00000000e+00],\n",
       "       [ 1.70000000e+01,  2.86635834e+02,  1.12924446e+02,\n",
       "         1.51478271e+01,  1.09553680e+01,  1.50311530e-01,\n",
       "         0.00000000e+00],\n",
       "       [ 1.70000000e+01,  3.45530884e+02,  3.44119354e+02,\n",
       "         1.26783447e+01,  2.28374023e+01,  1.01524986e-01,\n",
       "         1.00000000e+00],\n",
       "       [ 1.80000000e+01,  2.04671173e+02,  2.08091614e+02,\n",
       "         1.40703125e+01,  1.15645752e+01,  2.27773741e-01,\n",
       "         0.00000000e+00],\n",
       "       [ 1.80000000e+01,  3.63520538e+02,  1.22477722e+02,\n",
       "         1.31996460e+01,  1.23312988e+01,  1.66744947e-01,\n",
       "         0.00000000e+00],\n",
       "       [ 1.90000000e+01,  3.30725433e+02,  1.11054504e+02,\n",
       "         6.07620239e+01,  4.27321396e+01,  3.66558373e-01,\n",
       "         1.00000000e+00],\n",
       "       [ 1.90000000e+01,  7.26707840e+01,  2.03900742e+02,\n",
       "         1.08666840e+01,  1.10506897e+01,  2.04201654e-01,\n",
       "         0.00000000e+00],\n",
       "       [ 1.90000000e+01,  3.92303741e+02,  8.70350342e+01,\n",
       "         2.02300415e+01,  2.66704712e+01,  1.90429166e-01,\n",
       "         1.00000000e+00],\n",
       "       [ 1.90000000e+01,  1.93034210e+02,  1.38405258e+02,\n",
       "         1.75264893e+01,  1.42734985e+01,  1.41034365e-01,\n",
       "         0.00000000e+00],\n",
       "       [ 1.90000000e+01,  3.38007446e+02,  2.78201172e+02,\n",
       "         3.16158447e+01,  2.41932983e+01,  1.27245009e-01,\n",
       "         1.00000000e+00],\n",
       "       [ 1.90000000e+01,  1.82962402e+02,  1.34284286e+02,\n",
       "         1.29763489e+01,  1.29699402e+01,  1.23633906e-01,\n",
       "         0.00000000e+00],\n",
       "       [ 1.90000000e+01,  4.25123558e+01,  2.59968262e+02,\n",
       "         1.81580200e+01,  4.80307007e+01,  1.05852492e-01,\n",
       "         1.00000000e+00]])"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "COCO_anno"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "b4e16066",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading and preparing results...\n",
      "Converting ndarray to lists...\n",
      "(57, 7)\n",
      "0/57\n",
      "DONE (t=0.00s)\n",
      "Creating index...\n",
      "index created!\n"
     ]
    }
   ],
   "source": [
    "cocoDt = cocoGt.loadRes(COCO_anno)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "08690e8f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running per image evaluation...\n",
      "Evaluate annotation type *bbox*\n",
      "DONE (t=0.01s).\n",
      "Accumulating evaluation results...\n",
      "DONE (t=0.00s).\n"
     ]
    },
    {
     "ename": "IndexError",
     "evalue": "index 2 is out of bounds for axis 2 with size 2",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[73], line 6\u001b[0m\n\u001b[1;32m      4\u001b[0m cocoEval\u001b[38;5;241m.\u001b[39mevaluate()\n\u001b[1;32m      5\u001b[0m cocoEval\u001b[38;5;241m.\u001b[39maccumulate()\n\u001b[0;32m----> 6\u001b[0m \u001b[43mcocoEval\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msummarize\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      7\u001b[0m eval_stats \u001b[38;5;241m=\u001b[39m cocoEval\u001b[38;5;241m.\u001b[39mstats\n",
      "File \u001b[0;32m/usr/local/lib/python3.8/dist-packages/pycocotools/cocoeval.py:518\u001b[0m, in \u001b[0;36mCOCOeval.summarize\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    516\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m iouType \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mkeypoints\u001b[39m\u001b[38;5;124m'\u001b[39m:\n\u001b[1;32m    517\u001b[0m     summarize \u001b[38;5;241m=\u001b[39m _summarizeKps\n\u001b[0;32m--> 518\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstats \u001b[38;5;241m=\u001b[39m \u001b[43msummarize\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/usr/local/lib/python3.8/dist-packages/pycocotools/cocoeval.py:485\u001b[0m, in \u001b[0;36mCOCOeval.summarize.<locals>._summarizeDets\u001b[0;34m()\u001b[0m\n\u001b[1;32m    483\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_summarizeDets\u001b[39m():\n\u001b[1;32m    484\u001b[0m     stats \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mzeros((\u001b[38;5;241m12\u001b[39m,))\n\u001b[0;32m--> 485\u001b[0m     stats[\u001b[38;5;241m0\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[43m_summarize\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m    486\u001b[0m     stats[\u001b[38;5;241m1\u001b[39m] \u001b[38;5;241m=\u001b[39m _summarize(\u001b[38;5;241m1\u001b[39m, iouThr\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m.5\u001b[39m, maxDets\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mparams\u001b[38;5;241m.\u001b[39mmaxDets[\u001b[38;5;241m2\u001b[39m])\n\u001b[1;32m    487\u001b[0m     stats[\u001b[38;5;241m2\u001b[39m] \u001b[38;5;241m=\u001b[39m _summarize(\u001b[38;5;241m1\u001b[39m, iouThr\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m.75\u001b[39m, maxDets\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mparams\u001b[38;5;241m.\u001b[39mmaxDets[\u001b[38;5;241m2\u001b[39m])\n",
      "File \u001b[0;32m/usr/local/lib/python3.8/dist-packages/pycocotools/cocoeval.py:469\u001b[0m, in \u001b[0;36mCOCOeval.summarize.<locals>._summarize\u001b[0;34m(ap, iouThr, areaRng, maxDets)\u001b[0m\n\u001b[1;32m    467\u001b[0m         t \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mwhere(iouThr \u001b[38;5;241m==\u001b[39m p\u001b[38;5;241m.\u001b[39miouThrs)[\u001b[38;5;241m0\u001b[39m]\n\u001b[1;32m    468\u001b[0m         s \u001b[38;5;241m=\u001b[39m s[:,:,:,t,:]\n\u001b[0;32m--> 469\u001b[0m     s \u001b[38;5;241m=\u001b[39m \u001b[43ms\u001b[49m\u001b[43m[\u001b[49m\u001b[43m:\u001b[49m\u001b[43m,\u001b[49m\u001b[43maind\u001b[49m\u001b[43m,\u001b[49m\u001b[43mmind\u001b[49m\u001b[43m,\u001b[49m\u001b[43m:\u001b[49m\u001b[43m,\u001b[49m\u001b[43m:\u001b[49m\u001b[43m]\u001b[49m\n\u001b[1;32m    470\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    471\u001b[0m     \u001b[38;5;66;03m# dimension of recall: [TxKxAxM]\u001b[39;00m\n\u001b[1;32m    472\u001b[0m     s \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39meval[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mrecall\u001b[39m\u001b[38;5;124m'\u001b[39m]\n",
      "\u001b[0;31mIndexError\u001b[0m: index 2 is out of bounds for axis 2 with size 2"
     ]
    }
   ],
   "source": [
    "annType = \"bbox\"\n",
    "cocoEval = COCOeval(cocoGt,cocoDt,annType)\n",
    "cocoEval.params.areaRng = [[0, 1e+8], [0, 20**2], [20**2, 100**2], [100**2, 1e+8]]\n",
    "cocoEval.evaluate()\n",
    "cocoEval.accumulate()\n",
    "cocoEval.summarize()\n",
    "eval_stats = cocoEval.stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a281361d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21be762e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "491320a0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca1fbf9f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44b82c44",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1fe00502",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56200c9a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bccb8f0c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
