{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "8153b79b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import os \n",
    "import pandas as pd\n",
    "import cv2\n",
    "import torch\n",
    "import matplotlib.pyplot as plt\n",
    "from ipywidgets import interact\n",
    "import albumentations as A\n",
    "from albumentations.pytorch import ToTensorV2\n",
    "import torchvision\n",
    "from torch import nn\n",
    "import torchsummary\n",
    "from torch.utils.data import DataLoader\n",
    "from collections import defaultdict\n",
    "from torchvision.utils import make_grid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "2938f369",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cuda', index=0)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "device"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6998f56",
   "metadata": {},
   "source": [
    "## Utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "1a602257",
   "metadata": {},
   "outputs": [],
   "source": [
    "CLASS_NAME_TO_ID = {'Unformed': 0, 'Burr': 1}\n",
    "CLASS_ID_TO_NAME = {0: 'Unformed', 1: 'Burr'}\n",
    "BOX_COLOR = {'Unformed':(200, 0, 0), 'Burr':(0, 0, 200)}\n",
    "TEXT_COLOR = (255, 255, 255)\n",
    "\n",
    "def save_model(model_state, model_name, save_dir=\"./trained_model\"):\n",
    "    os.makedirs(save_dir, exist_ok=True)\n",
    "    torch.save(model_state, os.path.join(save_dir, model_name))\n",
    "\n",
    "\n",
    "def visualize_bbox(image, bbox, class_name, color=BOX_COLOR, thickness=2):\n",
    "    x_center, y_center, w, h = bbox\n",
    "    x_min = int(x_center - w/2)\n",
    "    y_min = int(y_center - h/2)\n",
    "    x_max = int(x_center + w/2)\n",
    "    y_max = int(y_center + h/2)\n",
    "    \n",
    "    cv2.rectangle(image, (x_min, y_min), (x_max, y_max), color=color[class_name], thickness=thickness)\n",
    "    \n",
    "    ((text_width, text_height), _) = cv2.getTextSize(class_name, cv2.FONT_HERSHEY_SIMPLEX, 0.35, 1)    \n",
    "    cv2.rectangle(image, (x_min, y_min - int(1.3 * text_height)), (x_min + text_width, y_min), color[class_name], -1)\n",
    "    cv2.putText(\n",
    "        image,\n",
    "        text=class_name,\n",
    "        org=(x_min, y_min - int(0.3 * text_height)),\n",
    "        fontFace=cv2.FONT_HERSHEY_SIMPLEX,\n",
    "        fontScale=0.35, \n",
    "        color=TEXT_COLOR, \n",
    "        lineType=cv2.LINE_AA,\n",
    "    )\n",
    "    return image\n",
    "\n",
    "\n",
    "def visualize(image, bboxes, category_ids):\n",
    "    img = image.copy()\n",
    "    for bbox, category_id in zip(bboxes, category_ids):\n",
    "#         print('category_id: ',category_id)\n",
    "        class_name = CLASS_ID_TO_NAME[category_id.item()]\n",
    "        img = visualize_bbox(img, bbox, class_name)\n",
    "    return img"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b957496f",
   "metadata": {},
   "source": [
    "## Datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "395a1431",
   "metadata": {},
   "outputs": [],
   "source": [
    "class PET_dataset():\n",
    "    def __init__(self,part,neck_dir,body_dir,phase, transformer=None, aug=None, aug_factor=0):\n",
    "        self.neck_dir=neck_dir\n",
    "        self.body_dir=body_dir\n",
    "        self.part=part\n",
    "        self.phase=phase\n",
    "        self.transformer=transformer\n",
    "        self.aug=aug\n",
    "        self.aug_factor=aug_factor\n",
    "        if(self.part==\"body\"):\n",
    "            self.image_files = sorted([fn for fn in os.listdir(self.body_dir+\"/\"+self.phase+\"/image\") if fn.endswith(\"jpg\")])\n",
    "            self.label_files= sorted([lab for lab in os.listdir(self.body_dir+\"/\"+self.phase+\"/label\") if lab.endswith(\"txt\")])\n",
    "        elif(self.part==\"neck\"):\n",
    "            self.image_files = sorted([fn for fn in os.listdir(self.neck_dir+\"/\"+self.phase+\"/image\") if fn.endswith(\"jpg\")])\n",
    "            self.label_files= sorted([lab for lab in os.listdir(self.neck_dir+\"/\"+self.phase+\"/label\") if lab.endswith(\"txt\")])\n",
    "        \n",
    "        self.auged_img_list, self.auged_label_list=self.make_aug_list(self.image_files, self.label_files)\n",
    "        \n",
    "    def __getitem__(self,index):\n",
    "        if(self.aug==None):\n",
    "            filename, image = self.get_image(self.part, index)\n",
    "            bboxes, class_ids = self.get_label(self.part, index)\n",
    "\n",
    "            if(self.transformer):\n",
    "                transformed_data=self.transformer(image=image, bboxes=bboxes, class_ids=class_ids)\n",
    "                image = transformed_data['image']\n",
    "                bboxes = np.array(transformed_data['bboxes'])\n",
    "                class_ids = np.array(transformed_data['class_ids'])\n",
    "\n",
    "\n",
    "            target = {}\n",
    "    #         print(f'bboxes:{bboxes}\\nclass_ids:{class_ids}\\nlen_bboxes:{len(bboxes)}\\nlen_class_ids:{len(class_ids)}')\n",
    "    #         print(f'filename: {filename}')\n",
    "            target[\"boxes\"] = torch.Tensor(bboxes).float()\n",
    "            target[\"labels\"] = torch.Tensor(class_ids).long()\n",
    "\n",
    "            ###\n",
    "            bboxes=torch.Tensor(bboxes).float()\n",
    "            class_ids=torch.Tensor(class_ids).long()\n",
    "            target = np.concatenate((bboxes, class_ids[:, np.newaxis]), axis=1)\n",
    "            ###\n",
    "        else:\n",
    "            image=self.auged_img_list[index][1]\n",
    "            target=self.auged_label_list[index]\n",
    "            filename=self.auged_img_list[index][0]\n",
    "        return image, target, filename\n",
    "    \n",
    "    def __len__(self, ):\n",
    "        length=0\n",
    "        if(self.aug==None):\n",
    "            length=len(self.image_files)\n",
    "        else:\n",
    "            length=len(self.auged_img_list)\n",
    "        return length\n",
    "    \n",
    "    def make_aug_list(self,ori_image_list,ori_label_files):\n",
    "        aug_image_list=[]\n",
    "        aug_label_list=[]\n",
    "        \n",
    "        print(f\"start making augmented images-- augmented factor:{self.aug_factor}\")\n",
    "        for i in range(len(ori_image_list)):\n",
    "            filename, ori_image = self.get_image(self.part, i)\n",
    "            ori_bboxes, ori_class_ids = self.get_label(self.part, i)\n",
    "            for j in range(self.aug_factor):\n",
    "                auged_data=self.aug(image=ori_image, bboxes=ori_bboxes, class_ids=ori_class_ids)\n",
    "                image = auged_data['image']\n",
    "                bboxes = np.array(auged_data['bboxes'])\n",
    "                class_ids = np.array(auged_data['class_ids'])\n",
    "                \n",
    "                bboxes=torch.Tensor(bboxes).float()\n",
    "                class_ids=torch.Tensor(class_ids).long()\n",
    "                \n",
    "                aug_image_list.append((filename, image))\n",
    "                aug_label_list.append(np.concatenate((bboxes, class_ids[:, np.newaxis]), axis=1))\n",
    "        \n",
    "        print(f\"total length of augmented images: {len(aug_image_list)}\")\n",
    "        \n",
    "        return aug_image_list, aug_label_list\n",
    "        \n",
    "    \n",
    "    def get_image(self, part, index): # 이미지 불러오는 함수\n",
    "        filename = self.image_files[index]\n",
    "        if(part==\"body\"):\n",
    "#             print(f\"body called!-> {self.part}\")\n",
    "            image_path = self.body_dir+\"/\"+self.phase+\"/image/\"+filename\n",
    "        elif(part==\"neck\"):\n",
    "#             print(f\"neck called!-> {self.part}\")\n",
    "            image_path = self.neck_dir+\"/\"+self.phase+\"/image/\"+filename\n",
    "        image = cv2.imread(image_path)\n",
    "        image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "        return filename, image\n",
    "    \n",
    "    def get_label(self, part, index): # label (box좌표, class_id) 불러오는 함수\n",
    "        label_filename=self.label_files[index]\n",
    "        if(part==\"body\"):\n",
    "#             print(f\"body label called!-> {self.part}\")\n",
    "            label_path = self.body_dir+\"/\"+self.phase+\"/label/\"+label_filename\n",
    "        elif(part==\"neck\"):\n",
    "#             print(f\"neck label called!-> {self.part}\")\n",
    "            label_path = self.neck_dir+\"/\"+self.phase+\"/label/\"+label_filename\n",
    "        with open(label_path, 'r') as file:\n",
    "            labels = file.readlines()\n",
    "        \n",
    "        class_ids=[]\n",
    "        bboxes=[]\n",
    "        for label in labels:\n",
    "            label=label.replace(\"\\n\", \"\")\n",
    "            obj=label.split(' ')[0]\n",
    "            coor=label.split(' ')[1:]\n",
    "            obj=int(obj)\n",
    "            coor=list(map(float, coor))\n",
    "            class_ids.append(obj)\n",
    "            bboxes.append(coor)\n",
    "            \n",
    "        return bboxes, class_ids\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "214f686d",
   "metadata": {},
   "outputs": [],
   "source": [
    "IMAGE_SIZE = 448\n",
    "\n",
    "transformer = A.Compose([ \n",
    "        # bounding box의 변환, augmentation에서 albumentations는 Detection 학습을 할 때 굉장히 유용하다. \n",
    "        A.Resize(height=IMAGE_SIZE, width=IMAGE_SIZE),\n",
    "        A.Normalize(mean=(0.485, 0.456, 0.406),std=(0.229, 0.224, 0.225)),\n",
    "        ToTensorV2(),\n",
    "        # albumentations 라이브러리에서는 Normalization을 먼저 진행해 주고 tensor화를 진행해 주어야한다.\n",
    "    ],\n",
    "    # box 위치에 대한 transformation도 함께 진행된다. \n",
    "    bbox_params=A.BboxParams(format='yolo', label_fields=['class_ids']),\n",
    ")\n",
    "\n",
    "augmentator=A.Compose([\n",
    "#     A.Resize(height=IMAGE_SIZE, width=IMAGE_SIZE),\n",
    "    A.HorizontalFlip(p=0.7),\n",
    "#     A.Sharpen(p=0.7),\n",
    "    A.BBoxSafeRandomCrop(p=0.6),\n",
    "    A.VerticalFlip (p=0.5),\n",
    "    A.HueSaturationValue(p=0.5),\n",
    "    A.Resize(height=IMAGE_SIZE, width=IMAGE_SIZE),\n",
    "    A.Normalize(mean=(0.485, 0.456, 0.406),std=(0.229, 0.224, 0.225)),\n",
    "    ToTensorV2(),\n",
    "    ],\n",
    "    bbox_params=A.BboxParams(format='yolo', label_fields=['class_ids']),\n",
    ")\n",
    "\n",
    "def collate_fn(batch):\n",
    "    image_list = []\n",
    "    target_list = []\n",
    "    filename_list = []\n",
    "    \n",
    "    for a,b,c in batch:\n",
    "        image_list.append(a)\n",
    "        target_list.append(b)\n",
    "        filename_list.append(c)\n",
    "\n",
    "    return torch.stack(image_list, dim=0), target_list, filename_list\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59088e3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# NECK_PATH = '/home/host_data/PET_data/Neck'\n",
    "# BODY_PATH = '/home/host_data/PET_data/Body'\n",
    "\n",
    "NECK_PATH = '/home/host_data/PET_data_IP_AUG/aug_patched_Neck/'\n",
    "BODY_PATH = '/home/host_data/PET_data_image_patching/Body'\n",
    "# trainset_yes_aug=PET_dataset(part='neck',neck_dir=NECK_PATH,body_dir=BODY_PATH,phase='train', transformer=transformer, aug=augmentator, aug_factor=5)\n",
    "trainset_no_aug=PET_dataset(part='neck',neck_dir=NECK_PATH,body_dir=BODY_PATH,phase='valid', transformer=transformer, aug=None)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e67afb5",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(trainset_no_aug)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a738cdd5",
   "metadata": {},
   "outputs": [],
   "source": [
    "@interact(index=(0, len(trainset_no_aug)-1))\n",
    "\n",
    "def show_sample(index=0):\n",
    "    image, target, filename = trainset_no_aug[index]\n",
    "    image=image.permute(1,2,0).numpy()\n",
    "    img_H, img_W, _ = image.shape\n",
    "    print(filename)\n",
    "    print(image.shape)\n",
    "#     print(image)\n",
    "\n",
    "#     bboxes = target['boxes']\n",
    "#     class_ids = target[\"labels\"]\n",
    "    \n",
    "    ###\n",
    "    bboxes = target[:, 0:4]\n",
    "    class_ids = target[:, 4]\n",
    "    ###\n",
    "    bboxes[:, [0,2]] *= img_W\n",
    "    bboxes[:, [1,3]] *= img_H\n",
    "\n",
    "    canvas = visualize(image, bboxes, class_ids)\n",
    "    plt.figure(figsize=(6,6))\n",
    "    plt.imshow(canvas)\n",
    "    plt.axis('off')\n",
    "    plt.show()\n",
    "\n",
    "# show_sample()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "325e66d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "@interact(index=(0, len(trainset_yes_aug)-1))\n",
    "\n",
    "def show_sample(index=0):\n",
    "    image, target, filename = trainset_yes_aug[index]\n",
    "    image=image.permute(1,2,0).numpy()\n",
    "    img_H, img_W, _ = image.shape\n",
    "    print(filename)\n",
    "    print(image.shape)\n",
    "#     print(image)\n",
    "\n",
    "#     bboxes = target['boxes']\n",
    "#     class_ids = target[\"labels\"]\n",
    "    ###\n",
    "    bboxes = target[:, 0:4]\n",
    "    class_ids = target[:, 4]\n",
    "    ###\n",
    "    bboxes[:, [0,2]] *= img_W\n",
    "    bboxes[:, [1,3]] *= img_H\n",
    "    print(bboxes)\n",
    "\n",
    "    canvas = visualize(image, bboxes, class_ids)\n",
    "    plt.figure(figsize=(6,6))\n",
    "    plt.imshow(canvas)\n",
    "    plt.axis('off')\n",
    "    plt.show()\n",
    "\n",
    "# show_sample()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2eba35b",
   "metadata": {},
   "source": [
    "## Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "6ba29e8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import math\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "class BasicConv(nn.Module):\n",
    "    def __init__(self, in_planes, out_planes, kernel_size, stride=1, padding=0, dilation=1, groups=1, relu=True, bn=True, bias=False):\n",
    "        super(BasicConv, self).__init__()\n",
    "        self.out_channels = out_planes\n",
    "        self.conv = nn.Conv2d(in_planes, out_planes, kernel_size=kernel_size, stride=stride, padding=padding, dilation=dilation, groups=groups, bias=bias)\n",
    "        self.bn = nn.BatchNorm2d(out_planes,eps=1e-5, momentum=0.01, affine=True) if bn else None\n",
    "        self.relu = nn.ReLU() if relu else None\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.conv(x)\n",
    "        if self.bn is not None:\n",
    "            x = self.bn(x)\n",
    "        if self.relu is not None:\n",
    "            x = self.relu(x)\n",
    "        return x\n",
    "\n",
    "class Flatten(nn.Module):\n",
    "    def forward(self, x):\n",
    "        return x.view(x.size(0), -1)\n",
    "\n",
    "class ChannelGate(nn.Module):\n",
    "    def __init__(self, gate_channels, reduction_ratio=16, pool_types=['avg', 'max']):\n",
    "        super(ChannelGate, self).__init__()\n",
    "        self.gate_channels = gate_channels\n",
    "        self.mlp = nn.Sequential(\n",
    "            Flatten(),\n",
    "            nn.Linear(gate_channels, gate_channels // reduction_ratio),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(gate_channels // reduction_ratio, gate_channels)\n",
    "            )\n",
    "        self.pool_types = pool_types\n",
    "    def forward(self, x):\n",
    "        channel_att_sum = None\n",
    "        for pool_type in self.pool_types:\n",
    "            if pool_type=='avg':\n",
    "                avg_pool = F.avg_pool2d( x, (x.size(2), x.size(3)), stride=(x.size(2), x.size(3)))\n",
    "                channel_att_raw = self.mlp( avg_pool )\n",
    "            elif pool_type=='max':\n",
    "                max_pool = F.max_pool2d( x, (x.size(2), x.size(3)), stride=(x.size(2), x.size(3)))\n",
    "                channel_att_raw = self.mlp( max_pool )\n",
    "            elif pool_type=='lp':\n",
    "                lp_pool = F.lp_pool2d( x, 2, (x.size(2), x.size(3)), stride=(x.size(2), x.size(3)))\n",
    "                channel_att_raw = self.mlp( lp_pool )\n",
    "            elif pool_type=='lse':\n",
    "                # LSE pool only\n",
    "                lse_pool = logsumexp_2d(x)\n",
    "                channel_att_raw = self.mlp( lse_pool )\n",
    "\n",
    "            if channel_att_sum is None:\n",
    "                channel_att_sum = channel_att_raw\n",
    "            else:\n",
    "                channel_att_sum = channel_att_sum + channel_att_raw\n",
    "\n",
    "        scale = F.sigmoid( channel_att_sum ).unsqueeze(2).unsqueeze(3).expand_as(x)\n",
    "        return x * scale\n",
    "\n",
    "def logsumexp_2d(tensor):\n",
    "    tensor_flatten = tensor.view(tensor.size(0), tensor.size(1), -1)\n",
    "    s, _ = torch.max(tensor_flatten, dim=2, keepdim=True)\n",
    "    outputs = s + (tensor_flatten - s).exp().sum(dim=2, keepdim=True).log()\n",
    "    return outputs\n",
    "\n",
    "class ChannelPool(nn.Module):\n",
    "    def forward(self, x):\n",
    "        return torch.cat( (torch.max(x,1)[0].unsqueeze(1), torch.mean(x,1).unsqueeze(1)), dim=1 )\n",
    "\n",
    "class SpatialGate(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(SpatialGate, self).__init__()\n",
    "        kernel_size = 7\n",
    "        self.compress = ChannelPool()\n",
    "        self.spatial = BasicConv(2, 1, kernel_size, stride=1, padding=(kernel_size-1) // 2, relu=False)\n",
    "    def forward(self, x):\n",
    "        x_compress = self.compress(x)\n",
    "        x_out = self.spatial(x_compress)\n",
    "        scale = F.sigmoid(x_out) # broadcasting\n",
    "        return x * scale\n",
    "\n",
    "class CBAM(nn.Module):\n",
    "    def __init__(self, gate_channels, reduction_ratio=16, pool_types=['avg', 'max'], no_spatial=False):\n",
    "        super(CBAM, self).__init__()\n",
    "        self.ChannelGate = ChannelGate(gate_channels, reduction_ratio, pool_types)\n",
    "        self.no_spatial=no_spatial\n",
    "        if not no_spatial:\n",
    "            self.SpatialGate = SpatialGate()\n",
    "    def forward(self, x):\n",
    "        x_out = self.ChannelGate(x)\n",
    "        if not self.no_spatial:\n",
    "            x_out = self.SpatialGate(x_out)\n",
    "        return x_out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "258ceb86",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import math\n",
    "from torch.nn import init\n",
    "# from .cbam import *\n",
    "# from .bam import *\n",
    "\n",
    "def conv3x3(in_planes, out_planes, stride=1):\n",
    "    \"3x3 convolution with padding\"\n",
    "    return nn.Conv2d(in_planes, out_planes, kernel_size=3, stride=stride,\n",
    "                     padding=1, bias=False)\n",
    "\n",
    "class BasicBlock(nn.Module):\n",
    "    expansion = 1\n",
    "\n",
    "    def __init__(self, inplanes, planes, stride=1, downsample=None, use_cbam=False):\n",
    "        super(BasicBlock, self).__init__()\n",
    "        self.conv1 = conv3x3(inplanes, planes, stride)\n",
    "        self.bn1 = nn.BatchNorm2d(planes)\n",
    "        self.relu = nn.ReLU(inplace=True)\n",
    "        self.conv2 = conv3x3(planes, planes)\n",
    "        self.bn2 = nn.BatchNorm2d(planes)\n",
    "        self.downsample = downsample\n",
    "        self.stride = stride\n",
    "\n",
    "        if use_cbam:\n",
    "            self.cbam = CBAM( planes, 16 )\n",
    "        else:\n",
    "            self.cbam = None\n",
    "\n",
    "    def forward(self, x):\n",
    "        residual = x\n",
    "\n",
    "        out = self.conv1(x)\n",
    "        out = self.bn1(out)\n",
    "        out = self.relu(out)\n",
    "\n",
    "        out = self.conv2(out)\n",
    "        out = self.bn2(out)\n",
    "\n",
    "        if self.downsample is not None:\n",
    "            residual = self.downsample(x)\n",
    "\n",
    "        if not self.cbam is None:\n",
    "            out = self.cbam(out)\n",
    "\n",
    "        out += residual\n",
    "        out = self.relu(out)\n",
    "\n",
    "        return out\n",
    "\n",
    "class Bottleneck(nn.Module):\n",
    "    expansion = 4\n",
    "\n",
    "    def __init__(self, inplanes, planes, stride=1, downsample=None, use_cbam=False):\n",
    "        super(Bottleneck, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(inplanes, planes, kernel_size=1, bias=False)\n",
    "        self.bn1 = nn.BatchNorm2d(planes)\n",
    "        self.conv2 = nn.Conv2d(planes, planes, kernel_size=3, stride=stride,\n",
    "                               padding=1, bias=False)\n",
    "        self.bn2 = nn.BatchNorm2d(planes)\n",
    "        self.conv3 = nn.Conv2d(planes, planes * 4, kernel_size=1, bias=False)\n",
    "        self.bn3 = nn.BatchNorm2d(planes * 4)\n",
    "        self.relu = nn.ReLU(inplace=True)\n",
    "        self.downsample = downsample\n",
    "        self.stride = stride\n",
    "\n",
    "        if use_cbam:\n",
    "            self.cbam = CBAM( planes * 4, 16 )\n",
    "        else:\n",
    "            self.cbam = None\n",
    "\n",
    "    def forward(self, x):\n",
    "        residual = x\n",
    "\n",
    "        out = self.conv1(x)\n",
    "        out = self.bn1(out)\n",
    "        out = self.relu(out)\n",
    "\n",
    "        out = self.conv2(out)\n",
    "        out = self.bn2(out)\n",
    "        out = self.relu(out)\n",
    "\n",
    "        out = self.conv3(out)\n",
    "        out = self.bn3(out)\n",
    "\n",
    "        if self.downsample is not None:\n",
    "            residual = self.downsample(x)\n",
    "\n",
    "        if not self.cbam is None:\n",
    "            out = self.cbam(out)\n",
    "\n",
    "        out += residual\n",
    "        out = self.relu(out)\n",
    "\n",
    "        return out\n",
    "\n",
    "class ResNet(nn.Module):\n",
    "    def __init__(self, block, layers,  network_type, num_classes, att_type=None):\n",
    "        self.inplanes = 64\n",
    "        super(ResNet, self).__init__()\n",
    "        self.network_type = network_type\n",
    "        # different model config between ImageNet and CIFAR \n",
    "        if network_type == \"ImageNet\":\n",
    "            self.conv1 = nn.Conv2d(3, 64, kernel_size=7, stride=2, padding=3, bias=False)\n",
    "            self.maxpool = nn.MaxPool2d(kernel_size=3, stride=2, padding=1)\n",
    "            self.avgpool = nn.AvgPool2d(7)\n",
    "        else:\n",
    "            self.conv1 = nn.Conv2d(3, 64, kernel_size=3, stride=1, padding=1, bias=False)\n",
    "\n",
    "        self.bn1 = nn.BatchNorm2d(64)\n",
    "        self.relu = nn.ReLU(inplace=True)\n",
    "\n",
    "        if att_type=='BAM':\n",
    "            self.bam1 = BAM(64*block.expansion)\n",
    "            self.bam2 = BAM(128*block.expansion)\n",
    "            self.bam3 = BAM(256*block.expansion)\n",
    "        else:\n",
    "            self.bam1, self.bam2, self.bam3 = None, None, None\n",
    "\n",
    "        self.layer1 = self._make_layer(block, 64,  layers[0], att_type=att_type)\n",
    "        self.layer2 = self._make_layer(block, 128, layers[1], stride=2, att_type=att_type)\n",
    "        self.layer3 = self._make_layer(block, 256, layers[2], stride=2, att_type=att_type)\n",
    "        self.layer4 = self._make_layer(block, 512, layers[3], stride=2, att_type=att_type)\n",
    "\n",
    "        self.fc = nn.Linear(512 * block.expansion, num_classes)\n",
    "        \n",
    "        self.final_conv = nn.Conv2d(512, 12, kernel_size=1, stride=1, padding=0, bias=False)\n",
    "\n",
    "        init.kaiming_normal(self.fc.weight)\n",
    "        for key in self.state_dict():\n",
    "            if key.split('.')[-1]==\"weight\":\n",
    "                if \"conv\" in key:\n",
    "                    init.kaiming_normal(self.state_dict()[key], mode='fan_out')\n",
    "                if \"bn\" in key:\n",
    "                    if \"SpatialGate\" in key:\n",
    "                        self.state_dict()[key][...] = 0\n",
    "                    else:\n",
    "                        self.state_dict()[key][...] = 1\n",
    "            elif key.split(\".\")[-1]=='bias':\n",
    "                self.state_dict()[key][...] = 0\n",
    "\n",
    "    def _make_layer(self, block, planes, blocks, stride=1, att_type=None):\n",
    "        downsample = None\n",
    "        if stride != 1 or self.inplanes != planes * block.expansion:\n",
    "            downsample = nn.Sequential(\n",
    "                nn.Conv2d(self.inplanes, planes * block.expansion,\n",
    "                          kernel_size=1, stride=stride, bias=False),\n",
    "                nn.BatchNorm2d(planes * block.expansion),\n",
    "            )\n",
    "\n",
    "        layers = []\n",
    "        layers.append(block(self.inplanes, planes, stride, downsample, use_cbam=att_type=='CBAM'))\n",
    "        self.inplanes = planes * block.expansion\n",
    "        for i in range(1, blocks):\n",
    "            layers.append(block(self.inplanes, planes, use_cbam=att_type=='CBAM'))\n",
    "\n",
    "        return nn.Sequential(*layers)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.conv1(x)\n",
    "        x = self.bn1(x)\n",
    "        x = self.relu(x)\n",
    "        if self.network_type == \"ImageNet\":\n",
    "            x = self.maxpool(x)\n",
    "\n",
    "        x = self.layer1(x)\n",
    "        if not self.bam1 is None:\n",
    "            x = self.bam1(x)\n",
    "\n",
    "        x = self.layer2(x)\n",
    "        if not self.bam2 is None:\n",
    "            x = self.bam2(x)\n",
    "\n",
    "        x = self.layer3(x)\n",
    "        if not self.bam3 is None:\n",
    "            x = self.bam3(x)\n",
    "\n",
    "        x = self.layer4(x)\n",
    "\n",
    "#         if self.network_type == \"ImageNet\":\n",
    "#             x = self.avgpool(x)\n",
    "#         else:\n",
    "        x = F.avg_pool2d(x, 2)\n",
    "        x = self.final_conv(x)\n",
    "#         x = x.view(x.size(0), -1)\n",
    "#         x = self.fc(x)\n",
    "        return x\n",
    "\n",
    "def ResidualNet(network_type, depth, num_classes, att_type):\n",
    "\n",
    "    assert network_type in [\"ImageNet\", \"CIFAR10\", \"CIFAR100\"], \"network type should be ImageNet or CIFAR10 / CIFAR100\"\n",
    "    assert depth in [18, 34, 50, 101], 'network depth should be 18, 34, 50 or 101'\n",
    "\n",
    "    if depth == 18:\n",
    "        model = ResNet(BasicBlock, [2, 2, 2, 2], network_type, num_classes, att_type)\n",
    "\n",
    "    elif depth == 34:\n",
    "        model = ResNet(BasicBlock, [3, 4, 6, 3], network_type, num_classes, att_type)\n",
    "\n",
    "    elif depth == 50:\n",
    "        model = ResNet(Bottleneck, [3, 4, 6, 3], network_type, num_classes, att_type)\n",
    "\n",
    "    elif depth == 101:\n",
    "        model = ResNet(Bottleneck, [3, 4, 23, 3], network_type, num_classes, att_type)\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "raw",
   "id": "cd10f35d",
   "metadata": {},
   "source": [
    "class YOLO_RESNET_CBAM(nn.Module):\n",
    "    def __init__(self, num_classes):\n",
    "        super().__init__()\n",
    "\n",
    "        self.num_classes = num_classes\n",
    "        self.num_bboxes = 2\n",
    "        self.grid_size = 7\n",
    "\n",
    "#         resnet18 = torchvision.models.resnet18(pretrained = True)\n",
    "#         swin=torchvision.models.swin_v2_t(weights='IMAGENET1K_V1')\n",
    "        res_cbam=ResNet(Bottleneck, [3, 4, 6, 3], network_type=\"ImageNet\", num_classes=2, att_type=\"CBAM\")\n",
    "        layers = [m for m in res_cbam.children()] #Resnet에서 Yolo에서 가져올수 있을만한 layer만 선별적으로 가져오기 위해서\n",
    "\n",
    "        # 기존 Resnet18의 layer들중에서 맨 뒤에 두개만 제외하고 다 가져와서 Backbone으로 사용\n",
    "        self.backbone = nn.Sequential(*layers[:-2]) \n",
    "        self.head = nn.Sequential(\n",
    "                nn.Conv2d(in_channels=2048, out_channels=1024, kernel_size=2, padding=0,bias=False),\n",
    "                nn.BatchNorm2d(1024),\n",
    "                nn.ReLU(inplace=True),\n",
    "\n",
    "                nn.Conv2d(in_channels=1024, out_channels=(4+1)*self.num_bboxes+num_classes, kernel_size=1, padding=0, bias=False),\n",
    "                nn.AdaptiveAvgPool2d(output_size=(self.grid_size, self.grid_size))\n",
    "            )\n",
    "\n",
    "    def forward(self, x):\n",
    "        out = self.backbone(x)\n",
    "        # out = self.neck(out)\n",
    "        out = self.head(out) # input (batch, 3, 448, 448) -> output feature (batch, 12, 7, 7)\n",
    "        return out\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "dc3dd80f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_2873/1777674582.py:131: UserWarning: nn.init.kaiming_normal is now deprecated in favor of nn.init.kaiming_normal_.\n",
      "  init.kaiming_normal(self.fc.weight)\n",
      "/tmp/ipykernel_2873/1777674582.py:135: UserWarning: nn.init.kaiming_normal is now deprecated in favor of nn.init.kaiming_normal_.\n",
      "  init.kaiming_normal(self.state_dict()[key], mode='fan_out')\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "ResNet(\n",
       "  (conv1): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
       "  (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
       "  (avgpool): AvgPool2d(kernel_size=7, stride=7, padding=0)\n",
       "  (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (relu): ReLU(inplace=True)\n",
       "  (layer1): Sequential(\n",
       "    (0): BasicBlock(\n",
       "      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (cbam): CBAM(\n",
       "        (ChannelGate): ChannelGate(\n",
       "          (mlp): Sequential(\n",
       "            (0): Flatten()\n",
       "            (1): Linear(in_features=64, out_features=4, bias=True)\n",
       "            (2): ReLU()\n",
       "            (3): Linear(in_features=4, out_features=64, bias=True)\n",
       "          )\n",
       "        )\n",
       "        (SpatialGate): SpatialGate(\n",
       "          (compress): ChannelPool()\n",
       "          (spatial): BasicConv(\n",
       "            (conv): Conv2d(2, 1, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), bias=False)\n",
       "            (bn): BatchNorm2d(1, eps=1e-05, momentum=0.01, affine=True, track_running_stats=True)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (1): BasicBlock(\n",
       "      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (cbam): CBAM(\n",
       "        (ChannelGate): ChannelGate(\n",
       "          (mlp): Sequential(\n",
       "            (0): Flatten()\n",
       "            (1): Linear(in_features=64, out_features=4, bias=True)\n",
       "            (2): ReLU()\n",
       "            (3): Linear(in_features=4, out_features=64, bias=True)\n",
       "          )\n",
       "        )\n",
       "        (SpatialGate): SpatialGate(\n",
       "          (compress): ChannelPool()\n",
       "          (spatial): BasicConv(\n",
       "            (conv): Conv2d(2, 1, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), bias=False)\n",
       "            (bn): BatchNorm2d(1, eps=1e-05, momentum=0.01, affine=True, track_running_stats=True)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (2): BasicBlock(\n",
       "      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (cbam): CBAM(\n",
       "        (ChannelGate): ChannelGate(\n",
       "          (mlp): Sequential(\n",
       "            (0): Flatten()\n",
       "            (1): Linear(in_features=64, out_features=4, bias=True)\n",
       "            (2): ReLU()\n",
       "            (3): Linear(in_features=4, out_features=64, bias=True)\n",
       "          )\n",
       "        )\n",
       "        (SpatialGate): SpatialGate(\n",
       "          (compress): ChannelPool()\n",
       "          (spatial): BasicConv(\n",
       "            (conv): Conv2d(2, 1, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), bias=False)\n",
       "            (bn): BatchNorm2d(1, eps=1e-05, momentum=0.01, affine=True, track_running_stats=True)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (layer2): Sequential(\n",
       "    (0): BasicBlock(\n",
       "      (conv1): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "        (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (cbam): CBAM(\n",
       "        (ChannelGate): ChannelGate(\n",
       "          (mlp): Sequential(\n",
       "            (0): Flatten()\n",
       "            (1): Linear(in_features=128, out_features=8, bias=True)\n",
       "            (2): ReLU()\n",
       "            (3): Linear(in_features=8, out_features=128, bias=True)\n",
       "          )\n",
       "        )\n",
       "        (SpatialGate): SpatialGate(\n",
       "          (compress): ChannelPool()\n",
       "          (spatial): BasicConv(\n",
       "            (conv): Conv2d(2, 1, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), bias=False)\n",
       "            (bn): BatchNorm2d(1, eps=1e-05, momentum=0.01, affine=True, track_running_stats=True)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (1): BasicBlock(\n",
       "      (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (cbam): CBAM(\n",
       "        (ChannelGate): ChannelGate(\n",
       "          (mlp): Sequential(\n",
       "            (0): Flatten()\n",
       "            (1): Linear(in_features=128, out_features=8, bias=True)\n",
       "            (2): ReLU()\n",
       "            (3): Linear(in_features=8, out_features=128, bias=True)\n",
       "          )\n",
       "        )\n",
       "        (SpatialGate): SpatialGate(\n",
       "          (compress): ChannelPool()\n",
       "          (spatial): BasicConv(\n",
       "            (conv): Conv2d(2, 1, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), bias=False)\n",
       "            (bn): BatchNorm2d(1, eps=1e-05, momentum=0.01, affine=True, track_running_stats=True)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (2): BasicBlock(\n",
       "      (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (cbam): CBAM(\n",
       "        (ChannelGate): ChannelGate(\n",
       "          (mlp): Sequential(\n",
       "            (0): Flatten()\n",
       "            (1): Linear(in_features=128, out_features=8, bias=True)\n",
       "            (2): ReLU()\n",
       "            (3): Linear(in_features=8, out_features=128, bias=True)\n",
       "          )\n",
       "        )\n",
       "        (SpatialGate): SpatialGate(\n",
       "          (compress): ChannelPool()\n",
       "          (spatial): BasicConv(\n",
       "            (conv): Conv2d(2, 1, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), bias=False)\n",
       "            (bn): BatchNorm2d(1, eps=1e-05, momentum=0.01, affine=True, track_running_stats=True)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (3): BasicBlock(\n",
       "      (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (cbam): CBAM(\n",
       "        (ChannelGate): ChannelGate(\n",
       "          (mlp): Sequential(\n",
       "            (0): Flatten()\n",
       "            (1): Linear(in_features=128, out_features=8, bias=True)\n",
       "            (2): ReLU()\n",
       "            (3): Linear(in_features=8, out_features=128, bias=True)\n",
       "          )\n",
       "        )\n",
       "        (SpatialGate): SpatialGate(\n",
       "          (compress): ChannelPool()\n",
       "          (spatial): BasicConv(\n",
       "            (conv): Conv2d(2, 1, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), bias=False)\n",
       "            (bn): BatchNorm2d(1, eps=1e-05, momentum=0.01, affine=True, track_running_stats=True)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (layer3): Sequential(\n",
       "    (0): BasicBlock(\n",
       "      (conv1): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (cbam): CBAM(\n",
       "        (ChannelGate): ChannelGate(\n",
       "          (mlp): Sequential(\n",
       "            (0): Flatten()\n",
       "            (1): Linear(in_features=256, out_features=16, bias=True)\n",
       "            (2): ReLU()\n",
       "            (3): Linear(in_features=16, out_features=256, bias=True)\n",
       "          )\n",
       "        )\n",
       "        (SpatialGate): SpatialGate(\n",
       "          (compress): ChannelPool()\n",
       "          (spatial): BasicConv(\n",
       "            (conv): Conv2d(2, 1, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), bias=False)\n",
       "            (bn): BatchNorm2d(1, eps=1e-05, momentum=0.01, affine=True, track_running_stats=True)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (1): BasicBlock(\n",
       "      (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (cbam): CBAM(\n",
       "        (ChannelGate): ChannelGate(\n",
       "          (mlp): Sequential(\n",
       "            (0): Flatten()\n",
       "            (1): Linear(in_features=256, out_features=16, bias=True)\n",
       "            (2): ReLU()\n",
       "            (3): Linear(in_features=16, out_features=256, bias=True)\n",
       "          )\n",
       "        )\n",
       "        (SpatialGate): SpatialGate(\n",
       "          (compress): ChannelPool()\n",
       "          (spatial): BasicConv(\n",
       "            (conv): Conv2d(2, 1, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), bias=False)\n",
       "            (bn): BatchNorm2d(1, eps=1e-05, momentum=0.01, affine=True, track_running_stats=True)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (2): BasicBlock(\n",
       "      (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (cbam): CBAM(\n",
       "        (ChannelGate): ChannelGate(\n",
       "          (mlp): Sequential(\n",
       "            (0): Flatten()\n",
       "            (1): Linear(in_features=256, out_features=16, bias=True)\n",
       "            (2): ReLU()\n",
       "            (3): Linear(in_features=16, out_features=256, bias=True)\n",
       "          )\n",
       "        )\n",
       "        (SpatialGate): SpatialGate(\n",
       "          (compress): ChannelPool()\n",
       "          (spatial): BasicConv(\n",
       "            (conv): Conv2d(2, 1, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), bias=False)\n",
       "            (bn): BatchNorm2d(1, eps=1e-05, momentum=0.01, affine=True, track_running_stats=True)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (3): BasicBlock(\n",
       "      (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (cbam): CBAM(\n",
       "        (ChannelGate): ChannelGate(\n",
       "          (mlp): Sequential(\n",
       "            (0): Flatten()\n",
       "            (1): Linear(in_features=256, out_features=16, bias=True)\n",
       "            (2): ReLU()\n",
       "            (3): Linear(in_features=16, out_features=256, bias=True)\n",
       "          )\n",
       "        )\n",
       "        (SpatialGate): SpatialGate(\n",
       "          (compress): ChannelPool()\n",
       "          (spatial): BasicConv(\n",
       "            (conv): Conv2d(2, 1, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), bias=False)\n",
       "            (bn): BatchNorm2d(1, eps=1e-05, momentum=0.01, affine=True, track_running_stats=True)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (4): BasicBlock(\n",
       "      (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (cbam): CBAM(\n",
       "        (ChannelGate): ChannelGate(\n",
       "          (mlp): Sequential(\n",
       "            (0): Flatten()\n",
       "            (1): Linear(in_features=256, out_features=16, bias=True)\n",
       "            (2): ReLU()\n",
       "            (3): Linear(in_features=16, out_features=256, bias=True)\n",
       "          )\n",
       "        )\n",
       "        (SpatialGate): SpatialGate(\n",
       "          (compress): ChannelPool()\n",
       "          (spatial): BasicConv(\n",
       "            (conv): Conv2d(2, 1, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), bias=False)\n",
       "            (bn): BatchNorm2d(1, eps=1e-05, momentum=0.01, affine=True, track_running_stats=True)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (5): BasicBlock(\n",
       "      (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (cbam): CBAM(\n",
       "        (ChannelGate): ChannelGate(\n",
       "          (mlp): Sequential(\n",
       "            (0): Flatten()\n",
       "            (1): Linear(in_features=256, out_features=16, bias=True)\n",
       "            (2): ReLU()\n",
       "            (3): Linear(in_features=16, out_features=256, bias=True)\n",
       "          )\n",
       "        )\n",
       "        (SpatialGate): SpatialGate(\n",
       "          (compress): ChannelPool()\n",
       "          (spatial): BasicConv(\n",
       "            (conv): Conv2d(2, 1, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), bias=False)\n",
       "            (bn): BatchNorm2d(1, eps=1e-05, momentum=0.01, affine=True, track_running_stats=True)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (layer4): Sequential(\n",
       "    (0): BasicBlock(\n",
       "      (conv1): Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "        (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (cbam): CBAM(\n",
       "        (ChannelGate): ChannelGate(\n",
       "          (mlp): Sequential(\n",
       "            (0): Flatten()\n",
       "            (1): Linear(in_features=512, out_features=32, bias=True)\n",
       "            (2): ReLU()\n",
       "            (3): Linear(in_features=32, out_features=512, bias=True)\n",
       "          )\n",
       "        )\n",
       "        (SpatialGate): SpatialGate(\n",
       "          (compress): ChannelPool()\n",
       "          (spatial): BasicConv(\n",
       "            (conv): Conv2d(2, 1, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), bias=False)\n",
       "            (bn): BatchNorm2d(1, eps=1e-05, momentum=0.01, affine=True, track_running_stats=True)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (1): BasicBlock(\n",
       "      (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (cbam): CBAM(\n",
       "        (ChannelGate): ChannelGate(\n",
       "          (mlp): Sequential(\n",
       "            (0): Flatten()\n",
       "            (1): Linear(in_features=512, out_features=32, bias=True)\n",
       "            (2): ReLU()\n",
       "            (3): Linear(in_features=32, out_features=512, bias=True)\n",
       "          )\n",
       "        )\n",
       "        (SpatialGate): SpatialGate(\n",
       "          (compress): ChannelPool()\n",
       "          (spatial): BasicConv(\n",
       "            (conv): Conv2d(2, 1, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), bias=False)\n",
       "            (bn): BatchNorm2d(1, eps=1e-05, momentum=0.01, affine=True, track_running_stats=True)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (2): BasicBlock(\n",
       "      (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (cbam): CBAM(\n",
       "        (ChannelGate): ChannelGate(\n",
       "          (mlp): Sequential(\n",
       "            (0): Flatten()\n",
       "            (1): Linear(in_features=512, out_features=32, bias=True)\n",
       "            (2): ReLU()\n",
       "            (3): Linear(in_features=32, out_features=512, bias=True)\n",
       "          )\n",
       "        )\n",
       "        (SpatialGate): SpatialGate(\n",
       "          (compress): ChannelPool()\n",
       "          (spatial): BasicConv(\n",
       "            (conv): Conv2d(2, 1, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), bias=False)\n",
       "            (bn): BatchNorm2d(1, eps=1e-05, momentum=0.01, affine=True, track_running_stats=True)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (fc): Linear(in_features=512, out_features=2, bias=True)\n",
       "  (final_conv): Conv2d(512, 12, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       ")"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "NUM_CLASSES = 2\n",
    "# model = YOLO_SWIN(num_classes=NUM_CLASSES)\n",
    "model = ResNet(BasicBlock, [3, 4, 6, 3], network_type=\"ImageNet\", num_classes=NUM_CLASSES, att_type=\"CBAM\")\n",
    "model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "43ecd862",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------------------------------\n",
      "        Layer (type)               Output Shape         Param #\n",
      "================================================================\n",
      "            Conv2d-1         [-1, 64, 224, 224]           9,408\n",
      "       BatchNorm2d-2         [-1, 64, 224, 224]             128\n",
      "              ReLU-3         [-1, 64, 224, 224]               0\n",
      "         MaxPool2d-4         [-1, 64, 112, 112]               0\n",
      "            Conv2d-5         [-1, 64, 112, 112]          36,864\n",
      "       BatchNorm2d-6         [-1, 64, 112, 112]             128\n",
      "              ReLU-7         [-1, 64, 112, 112]               0\n",
      "            Conv2d-8         [-1, 64, 112, 112]          36,864\n",
      "       BatchNorm2d-9         [-1, 64, 112, 112]             128\n",
      "          Flatten-10                   [-1, 64]               0\n",
      "           Linear-11                    [-1, 4]             260\n",
      "             ReLU-12                    [-1, 4]               0\n",
      "           Linear-13                   [-1, 64]             320\n",
      "          Flatten-14                   [-1, 64]               0\n",
      "           Linear-15                    [-1, 4]             260\n",
      "             ReLU-16                    [-1, 4]               0\n",
      "           Linear-17                   [-1, 64]             320\n",
      "      ChannelGate-18         [-1, 64, 112, 112]               0\n",
      "      ChannelPool-19          [-1, 2, 112, 112]               0\n",
      "           Conv2d-20          [-1, 1, 112, 112]              98\n",
      "      BatchNorm2d-21          [-1, 1, 112, 112]               2\n",
      "        BasicConv-22          [-1, 1, 112, 112]               0\n",
      "      SpatialGate-23         [-1, 64, 112, 112]               0\n",
      "             CBAM-24         [-1, 64, 112, 112]               0\n",
      "             ReLU-25         [-1, 64, 112, 112]               0\n",
      "       BasicBlock-26         [-1, 64, 112, 112]               0\n",
      "           Conv2d-27         [-1, 64, 112, 112]          36,864\n",
      "      BatchNorm2d-28         [-1, 64, 112, 112]             128\n",
      "             ReLU-29         [-1, 64, 112, 112]               0\n",
      "           Conv2d-30         [-1, 64, 112, 112]          36,864\n",
      "      BatchNorm2d-31         [-1, 64, 112, 112]             128\n",
      "          Flatten-32                   [-1, 64]               0\n",
      "           Linear-33                    [-1, 4]             260\n",
      "             ReLU-34                    [-1, 4]               0\n",
      "           Linear-35                   [-1, 64]             320\n",
      "          Flatten-36                   [-1, 64]               0\n",
      "           Linear-37                    [-1, 4]             260\n",
      "             ReLU-38                    [-1, 4]               0\n",
      "           Linear-39                   [-1, 64]             320\n",
      "      ChannelGate-40         [-1, 64, 112, 112]               0\n",
      "      ChannelPool-41          [-1, 2, 112, 112]               0\n",
      "           Conv2d-42          [-1, 1, 112, 112]              98\n",
      "      BatchNorm2d-43          [-1, 1, 112, 112]               2\n",
      "        BasicConv-44          [-1, 1, 112, 112]               0\n",
      "      SpatialGate-45         [-1, 64, 112, 112]               0\n",
      "             CBAM-46         [-1, 64, 112, 112]               0\n",
      "             ReLU-47         [-1, 64, 112, 112]               0\n",
      "       BasicBlock-48         [-1, 64, 112, 112]               0\n",
      "           Conv2d-49         [-1, 64, 112, 112]          36,864\n",
      "      BatchNorm2d-50         [-1, 64, 112, 112]             128\n",
      "             ReLU-51         [-1, 64, 112, 112]               0\n",
      "           Conv2d-52         [-1, 64, 112, 112]          36,864\n",
      "      BatchNorm2d-53         [-1, 64, 112, 112]             128\n",
      "          Flatten-54                   [-1, 64]               0\n",
      "           Linear-55                    [-1, 4]             260\n",
      "             ReLU-56                    [-1, 4]               0\n",
      "           Linear-57                   [-1, 64]             320\n",
      "          Flatten-58                   [-1, 64]               0\n",
      "           Linear-59                    [-1, 4]             260\n",
      "             ReLU-60                    [-1, 4]               0\n",
      "           Linear-61                   [-1, 64]             320\n",
      "      ChannelGate-62         [-1, 64, 112, 112]               0\n",
      "      ChannelPool-63          [-1, 2, 112, 112]               0\n",
      "           Conv2d-64          [-1, 1, 112, 112]              98\n",
      "      BatchNorm2d-65          [-1, 1, 112, 112]               2\n",
      "        BasicConv-66          [-1, 1, 112, 112]               0\n",
      "      SpatialGate-67         [-1, 64, 112, 112]               0\n",
      "             CBAM-68         [-1, 64, 112, 112]               0\n",
      "             ReLU-69         [-1, 64, 112, 112]               0\n",
      "       BasicBlock-70         [-1, 64, 112, 112]               0\n",
      "           Conv2d-71          [-1, 128, 56, 56]          73,728\n",
      "      BatchNorm2d-72          [-1, 128, 56, 56]             256\n",
      "             ReLU-73          [-1, 128, 56, 56]               0\n",
      "           Conv2d-74          [-1, 128, 56, 56]         147,456\n",
      "      BatchNorm2d-75          [-1, 128, 56, 56]             256\n",
      "           Conv2d-76          [-1, 128, 56, 56]           8,192\n",
      "      BatchNorm2d-77          [-1, 128, 56, 56]             256\n",
      "          Flatten-78                  [-1, 128]               0\n",
      "           Linear-79                    [-1, 8]           1,032\n",
      "             ReLU-80                    [-1, 8]               0\n",
      "           Linear-81                  [-1, 128]           1,152\n",
      "          Flatten-82                  [-1, 128]               0\n",
      "           Linear-83                    [-1, 8]           1,032\n",
      "             ReLU-84                    [-1, 8]               0\n",
      "           Linear-85                  [-1, 128]           1,152\n",
      "      ChannelGate-86          [-1, 128, 56, 56]               0\n",
      "      ChannelPool-87            [-1, 2, 56, 56]               0\n",
      "           Conv2d-88            [-1, 1, 56, 56]              98\n",
      "      BatchNorm2d-89            [-1, 1, 56, 56]               2\n",
      "        BasicConv-90            [-1, 1, 56, 56]               0\n",
      "      SpatialGate-91          [-1, 128, 56, 56]               0\n",
      "             CBAM-92          [-1, 128, 56, 56]               0\n",
      "             ReLU-93          [-1, 128, 56, 56]               0\n",
      "       BasicBlock-94          [-1, 128, 56, 56]               0\n",
      "           Conv2d-95          [-1, 128, 56, 56]         147,456\n",
      "      BatchNorm2d-96          [-1, 128, 56, 56]             256\n",
      "             ReLU-97          [-1, 128, 56, 56]               0\n",
      "           Conv2d-98          [-1, 128, 56, 56]         147,456\n",
      "      BatchNorm2d-99          [-1, 128, 56, 56]             256\n",
      "         Flatten-100                  [-1, 128]               0\n",
      "          Linear-101                    [-1, 8]           1,032\n",
      "            ReLU-102                    [-1, 8]               0\n",
      "          Linear-103                  [-1, 128]           1,152\n",
      "         Flatten-104                  [-1, 128]               0\n",
      "          Linear-105                    [-1, 8]           1,032\n",
      "            ReLU-106                    [-1, 8]               0\n",
      "          Linear-107                  [-1, 128]           1,152\n",
      "     ChannelGate-108          [-1, 128, 56, 56]               0\n",
      "     ChannelPool-109            [-1, 2, 56, 56]               0\n",
      "          Conv2d-110            [-1, 1, 56, 56]              98\n",
      "     BatchNorm2d-111            [-1, 1, 56, 56]               2\n",
      "       BasicConv-112            [-1, 1, 56, 56]               0\n",
      "     SpatialGate-113          [-1, 128, 56, 56]               0\n",
      "            CBAM-114          [-1, 128, 56, 56]               0\n",
      "            ReLU-115          [-1, 128, 56, 56]               0\n",
      "      BasicBlock-116          [-1, 128, 56, 56]               0\n",
      "          Conv2d-117          [-1, 128, 56, 56]         147,456\n",
      "     BatchNorm2d-118          [-1, 128, 56, 56]             256\n",
      "            ReLU-119          [-1, 128, 56, 56]               0\n",
      "          Conv2d-120          [-1, 128, 56, 56]         147,456\n",
      "     BatchNorm2d-121          [-1, 128, 56, 56]             256\n",
      "         Flatten-122                  [-1, 128]               0\n",
      "          Linear-123                    [-1, 8]           1,032\n",
      "            ReLU-124                    [-1, 8]               0\n",
      "          Linear-125                  [-1, 128]           1,152\n",
      "         Flatten-126                  [-1, 128]               0\n",
      "          Linear-127                    [-1, 8]           1,032\n",
      "            ReLU-128                    [-1, 8]               0\n",
      "          Linear-129                  [-1, 128]           1,152\n",
      "     ChannelGate-130          [-1, 128, 56, 56]               0\n",
      "     ChannelPool-131            [-1, 2, 56, 56]               0\n",
      "          Conv2d-132            [-1, 1, 56, 56]              98\n",
      "     BatchNorm2d-133            [-1, 1, 56, 56]               2\n",
      "       BasicConv-134            [-1, 1, 56, 56]               0\n",
      "     SpatialGate-135          [-1, 128, 56, 56]               0\n",
      "            CBAM-136          [-1, 128, 56, 56]               0\n",
      "            ReLU-137          [-1, 128, 56, 56]               0\n",
      "      BasicBlock-138          [-1, 128, 56, 56]               0\n",
      "          Conv2d-139          [-1, 128, 56, 56]         147,456\n",
      "     BatchNorm2d-140          [-1, 128, 56, 56]             256\n",
      "            ReLU-141          [-1, 128, 56, 56]               0\n",
      "          Conv2d-142          [-1, 128, 56, 56]         147,456\n",
      "     BatchNorm2d-143          [-1, 128, 56, 56]             256\n",
      "         Flatten-144                  [-1, 128]               0\n",
      "          Linear-145                    [-1, 8]           1,032\n",
      "            ReLU-146                    [-1, 8]               0\n",
      "          Linear-147                  [-1, 128]           1,152\n",
      "         Flatten-148                  [-1, 128]               0\n",
      "          Linear-149                    [-1, 8]           1,032\n",
      "            ReLU-150                    [-1, 8]               0\n",
      "          Linear-151                  [-1, 128]           1,152\n",
      "     ChannelGate-152          [-1, 128, 56, 56]               0\n",
      "     ChannelPool-153            [-1, 2, 56, 56]               0\n",
      "          Conv2d-154            [-1, 1, 56, 56]              98\n",
      "     BatchNorm2d-155            [-1, 1, 56, 56]               2\n",
      "       BasicConv-156            [-1, 1, 56, 56]               0\n",
      "     SpatialGate-157          [-1, 128, 56, 56]               0\n",
      "            CBAM-158          [-1, 128, 56, 56]               0\n",
      "            ReLU-159          [-1, 128, 56, 56]               0\n",
      "      BasicBlock-160          [-1, 128, 56, 56]               0\n",
      "          Conv2d-161          [-1, 256, 28, 28]         294,912\n",
      "     BatchNorm2d-162          [-1, 256, 28, 28]             512\n",
      "            ReLU-163          [-1, 256, 28, 28]               0\n",
      "          Conv2d-164          [-1, 256, 28, 28]         589,824\n",
      "     BatchNorm2d-165          [-1, 256, 28, 28]             512\n",
      "          Conv2d-166          [-1, 256, 28, 28]          32,768\n",
      "     BatchNorm2d-167          [-1, 256, 28, 28]             512\n",
      "         Flatten-168                  [-1, 256]               0\n",
      "          Linear-169                   [-1, 16]           4,112\n",
      "            ReLU-170                   [-1, 16]               0\n",
      "          Linear-171                  [-1, 256]           4,352\n",
      "         Flatten-172                  [-1, 256]               0\n",
      "          Linear-173                   [-1, 16]           4,112\n",
      "            ReLU-174                   [-1, 16]               0\n",
      "          Linear-175                  [-1, 256]           4,352\n",
      "     ChannelGate-176          [-1, 256, 28, 28]               0\n",
      "     ChannelPool-177            [-1, 2, 28, 28]               0\n",
      "          Conv2d-178            [-1, 1, 28, 28]              98\n",
      "     BatchNorm2d-179            [-1, 1, 28, 28]               2\n",
      "       BasicConv-180            [-1, 1, 28, 28]               0\n",
      "     SpatialGate-181          [-1, 256, 28, 28]               0\n",
      "            CBAM-182          [-1, 256, 28, 28]               0\n",
      "            ReLU-183          [-1, 256, 28, 28]               0\n",
      "      BasicBlock-184          [-1, 256, 28, 28]               0\n",
      "          Conv2d-185          [-1, 256, 28, 28]         589,824\n",
      "     BatchNorm2d-186          [-1, 256, 28, 28]             512\n",
      "            ReLU-187          [-1, 256, 28, 28]               0\n",
      "          Conv2d-188          [-1, 256, 28, 28]         589,824\n",
      "     BatchNorm2d-189          [-1, 256, 28, 28]             512\n",
      "         Flatten-190                  [-1, 256]               0\n",
      "          Linear-191                   [-1, 16]           4,112\n",
      "            ReLU-192                   [-1, 16]               0\n",
      "          Linear-193                  [-1, 256]           4,352\n",
      "         Flatten-194                  [-1, 256]               0\n",
      "          Linear-195                   [-1, 16]           4,112\n",
      "            ReLU-196                   [-1, 16]               0\n",
      "          Linear-197                  [-1, 256]           4,352\n",
      "     ChannelGate-198          [-1, 256, 28, 28]               0\n",
      "     ChannelPool-199            [-1, 2, 28, 28]               0\n",
      "          Conv2d-200            [-1, 1, 28, 28]              98\n",
      "     BatchNorm2d-201            [-1, 1, 28, 28]               2\n",
      "       BasicConv-202            [-1, 1, 28, 28]               0\n",
      "     SpatialGate-203          [-1, 256, 28, 28]               0\n",
      "            CBAM-204          [-1, 256, 28, 28]               0\n",
      "            ReLU-205          [-1, 256, 28, 28]               0\n",
      "      BasicBlock-206          [-1, 256, 28, 28]               0\n",
      "          Conv2d-207          [-1, 256, 28, 28]         589,824\n",
      "     BatchNorm2d-208          [-1, 256, 28, 28]             512\n",
      "            ReLU-209          [-1, 256, 28, 28]               0\n",
      "          Conv2d-210          [-1, 256, 28, 28]         589,824\n",
      "     BatchNorm2d-211          [-1, 256, 28, 28]             512\n",
      "         Flatten-212                  [-1, 256]               0\n",
      "          Linear-213                   [-1, 16]           4,112\n",
      "            ReLU-214                   [-1, 16]               0\n",
      "          Linear-215                  [-1, 256]           4,352\n",
      "         Flatten-216                  [-1, 256]               0\n",
      "          Linear-217                   [-1, 16]           4,112\n",
      "            ReLU-218                   [-1, 16]               0\n",
      "          Linear-219                  [-1, 256]           4,352\n",
      "     ChannelGate-220          [-1, 256, 28, 28]               0\n",
      "     ChannelPool-221            [-1, 2, 28, 28]               0\n",
      "          Conv2d-222            [-1, 1, 28, 28]              98\n",
      "     BatchNorm2d-223            [-1, 1, 28, 28]               2\n",
      "       BasicConv-224            [-1, 1, 28, 28]               0\n",
      "     SpatialGate-225          [-1, 256, 28, 28]               0\n",
      "            CBAM-226          [-1, 256, 28, 28]               0\n",
      "            ReLU-227          [-1, 256, 28, 28]               0\n",
      "      BasicBlock-228          [-1, 256, 28, 28]               0\n",
      "          Conv2d-229          [-1, 256, 28, 28]         589,824\n",
      "     BatchNorm2d-230          [-1, 256, 28, 28]             512\n",
      "            ReLU-231          [-1, 256, 28, 28]               0\n",
      "          Conv2d-232          [-1, 256, 28, 28]         589,824\n",
      "     BatchNorm2d-233          [-1, 256, 28, 28]             512\n",
      "         Flatten-234                  [-1, 256]               0\n",
      "          Linear-235                   [-1, 16]           4,112\n",
      "            ReLU-236                   [-1, 16]               0\n",
      "          Linear-237                  [-1, 256]           4,352\n",
      "         Flatten-238                  [-1, 256]               0\n",
      "          Linear-239                   [-1, 16]           4,112\n",
      "            ReLU-240                   [-1, 16]               0\n",
      "          Linear-241                  [-1, 256]           4,352\n",
      "     ChannelGate-242          [-1, 256, 28, 28]               0\n",
      "     ChannelPool-243            [-1, 2, 28, 28]               0\n",
      "          Conv2d-244            [-1, 1, 28, 28]              98\n",
      "     BatchNorm2d-245            [-1, 1, 28, 28]               2\n",
      "       BasicConv-246            [-1, 1, 28, 28]               0\n",
      "     SpatialGate-247          [-1, 256, 28, 28]               0\n",
      "            CBAM-248          [-1, 256, 28, 28]               0\n",
      "            ReLU-249          [-1, 256, 28, 28]               0\n",
      "      BasicBlock-250          [-1, 256, 28, 28]               0\n",
      "          Conv2d-251          [-1, 256, 28, 28]         589,824\n",
      "     BatchNorm2d-252          [-1, 256, 28, 28]             512\n",
      "            ReLU-253          [-1, 256, 28, 28]               0\n",
      "          Conv2d-254          [-1, 256, 28, 28]         589,824\n",
      "     BatchNorm2d-255          [-1, 256, 28, 28]             512\n",
      "         Flatten-256                  [-1, 256]               0\n",
      "          Linear-257                   [-1, 16]           4,112\n",
      "            ReLU-258                   [-1, 16]               0\n",
      "          Linear-259                  [-1, 256]           4,352\n",
      "         Flatten-260                  [-1, 256]               0\n",
      "          Linear-261                   [-1, 16]           4,112\n",
      "            ReLU-262                   [-1, 16]               0\n",
      "          Linear-263                  [-1, 256]           4,352\n",
      "     ChannelGate-264          [-1, 256, 28, 28]               0\n",
      "     ChannelPool-265            [-1, 2, 28, 28]               0\n",
      "          Conv2d-266            [-1, 1, 28, 28]              98\n",
      "     BatchNorm2d-267            [-1, 1, 28, 28]               2\n",
      "       BasicConv-268            [-1, 1, 28, 28]               0\n",
      "     SpatialGate-269          [-1, 256, 28, 28]               0\n",
      "            CBAM-270          [-1, 256, 28, 28]               0\n",
      "            ReLU-271          [-1, 256, 28, 28]               0\n",
      "      BasicBlock-272          [-1, 256, 28, 28]               0\n",
      "          Conv2d-273          [-1, 256, 28, 28]         589,824\n",
      "     BatchNorm2d-274          [-1, 256, 28, 28]             512\n",
      "            ReLU-275          [-1, 256, 28, 28]               0\n",
      "          Conv2d-276          [-1, 256, 28, 28]         589,824\n",
      "     BatchNorm2d-277          [-1, 256, 28, 28]             512\n",
      "         Flatten-278                  [-1, 256]               0\n",
      "          Linear-279                   [-1, 16]           4,112\n",
      "            ReLU-280                   [-1, 16]               0\n",
      "          Linear-281                  [-1, 256]           4,352\n",
      "         Flatten-282                  [-1, 256]               0\n",
      "          Linear-283                   [-1, 16]           4,112\n",
      "            ReLU-284                   [-1, 16]               0\n",
      "          Linear-285                  [-1, 256]           4,352\n",
      "     ChannelGate-286          [-1, 256, 28, 28]               0\n",
      "     ChannelPool-287            [-1, 2, 28, 28]               0\n",
      "          Conv2d-288            [-1, 1, 28, 28]              98\n",
      "     BatchNorm2d-289            [-1, 1, 28, 28]               2\n",
      "       BasicConv-290            [-1, 1, 28, 28]               0\n",
      "     SpatialGate-291          [-1, 256, 28, 28]               0\n",
      "            CBAM-292          [-1, 256, 28, 28]               0\n",
      "            ReLU-293          [-1, 256, 28, 28]               0\n",
      "      BasicBlock-294          [-1, 256, 28, 28]               0\n",
      "          Conv2d-295          [-1, 512, 14, 14]       1,179,648\n",
      "     BatchNorm2d-296          [-1, 512, 14, 14]           1,024\n",
      "            ReLU-297          [-1, 512, 14, 14]               0\n",
      "          Conv2d-298          [-1, 512, 14, 14]       2,359,296\n",
      "     BatchNorm2d-299          [-1, 512, 14, 14]           1,024\n",
      "          Conv2d-300          [-1, 512, 14, 14]         131,072\n",
      "     BatchNorm2d-301          [-1, 512, 14, 14]           1,024\n",
      "         Flatten-302                  [-1, 512]               0\n",
      "          Linear-303                   [-1, 32]          16,416\n",
      "            ReLU-304                   [-1, 32]               0\n",
      "          Linear-305                  [-1, 512]          16,896\n",
      "         Flatten-306                  [-1, 512]               0\n",
      "          Linear-307                   [-1, 32]          16,416\n",
      "            ReLU-308                   [-1, 32]               0\n",
      "          Linear-309                  [-1, 512]          16,896\n",
      "     ChannelGate-310          [-1, 512, 14, 14]               0\n",
      "     ChannelPool-311            [-1, 2, 14, 14]               0\n",
      "          Conv2d-312            [-1, 1, 14, 14]              98\n",
      "     BatchNorm2d-313            [-1, 1, 14, 14]               2\n",
      "       BasicConv-314            [-1, 1, 14, 14]               0\n",
      "     SpatialGate-315          [-1, 512, 14, 14]               0\n",
      "            CBAM-316          [-1, 512, 14, 14]               0\n",
      "            ReLU-317          [-1, 512, 14, 14]               0\n",
      "      BasicBlock-318          [-1, 512, 14, 14]               0\n",
      "          Conv2d-319          [-1, 512, 14, 14]       2,359,296\n",
      "     BatchNorm2d-320          [-1, 512, 14, 14]           1,024\n",
      "            ReLU-321          [-1, 512, 14, 14]               0\n",
      "          Conv2d-322          [-1, 512, 14, 14]       2,359,296\n",
      "     BatchNorm2d-323          [-1, 512, 14, 14]           1,024\n",
      "         Flatten-324                  [-1, 512]               0\n",
      "          Linear-325                   [-1, 32]          16,416\n",
      "            ReLU-326                   [-1, 32]               0\n",
      "          Linear-327                  [-1, 512]          16,896\n",
      "         Flatten-328                  [-1, 512]               0\n",
      "          Linear-329                   [-1, 32]          16,416\n",
      "            ReLU-330                   [-1, 32]               0\n",
      "          Linear-331                  [-1, 512]          16,896\n",
      "     ChannelGate-332          [-1, 512, 14, 14]               0\n",
      "     ChannelPool-333            [-1, 2, 14, 14]               0\n",
      "          Conv2d-334            [-1, 1, 14, 14]              98\n",
      "     BatchNorm2d-335            [-1, 1, 14, 14]               2\n",
      "       BasicConv-336            [-1, 1, 14, 14]               0\n",
      "     SpatialGate-337          [-1, 512, 14, 14]               0\n",
      "            CBAM-338          [-1, 512, 14, 14]               0\n",
      "            ReLU-339          [-1, 512, 14, 14]               0\n",
      "      BasicBlock-340          [-1, 512, 14, 14]               0\n",
      "          Conv2d-341          [-1, 512, 14, 14]       2,359,296\n",
      "     BatchNorm2d-342          [-1, 512, 14, 14]           1,024\n",
      "            ReLU-343          [-1, 512, 14, 14]               0\n",
      "          Conv2d-344          [-1, 512, 14, 14]       2,359,296\n",
      "     BatchNorm2d-345          [-1, 512, 14, 14]           1,024\n",
      "         Flatten-346                  [-1, 512]               0\n",
      "          Linear-347                   [-1, 32]          16,416\n",
      "            ReLU-348                   [-1, 32]               0\n",
      "          Linear-349                  [-1, 512]          16,896\n",
      "         Flatten-350                  [-1, 512]               0\n",
      "          Linear-351                   [-1, 32]          16,416\n",
      "            ReLU-352                   [-1, 32]               0\n",
      "          Linear-353                  [-1, 512]          16,896\n",
      "     ChannelGate-354          [-1, 512, 14, 14]               0\n",
      "     ChannelPool-355            [-1, 2, 14, 14]               0\n",
      "          Conv2d-356            [-1, 1, 14, 14]              98\n",
      "     BatchNorm2d-357            [-1, 1, 14, 14]               2\n",
      "       BasicConv-358            [-1, 1, 14, 14]               0\n",
      "     SpatialGate-359          [-1, 512, 14, 14]               0\n",
      "            CBAM-360          [-1, 512, 14, 14]               0\n",
      "            ReLU-361          [-1, 512, 14, 14]               0\n",
      "      BasicBlock-362          [-1, 512, 14, 14]               0\n",
      "          Conv2d-363             [-1, 12, 7, 7]           6,144\n",
      "================================================================\n",
      "Total params: 21,614,808\n",
      "Trainable params: 21,614,808\n",
      "Non-trainable params: 0\n",
      "----------------------------------------------------------------\n",
      "Input size (MB): 2.30\n",
      "Forward/backward pass size (MB): 513.68\n",
      "Params size (MB): 82.45\n",
      "Estimated Total Size (MB): 598.43\n",
      "----------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "torchsummary.summary(model, (3,448,448))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "13cf0424",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 12, 7, 7])\n"
     ]
    }
   ],
   "source": [
    "x = torch.randn(1, 3, 448, 448).to(device)\n",
    "with torch.no_grad():\n",
    "    y = model(x)\n",
    "print(y.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09df4b3a",
   "metadata": {},
   "source": [
    "## Loss func"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "9ad323bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "class YOLO_LOSS():\n",
    "    def __init__(self, num_classes, device, lambda_coord=5., lambda_noobj=0.5):\n",
    "        self.num_classes = num_classes\n",
    "        self.device = device\n",
    "        self.grid_size = 7\n",
    "        self.lambda_coord = lambda_coord\n",
    "        self.lambda_noobj = lambda_noobj\n",
    "        self.mse_loss = nn.MSELoss(reduction=\"sum\")\n",
    "\n",
    "    def __call__(self, predictions, targets):\n",
    "        self.batch_size, _, _, _ = predictions.shape\n",
    "        groundtruths = self.build_batch_target_grid(targets)\n",
    "        groundtruths = groundtruths.to(self.device)\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            iou1 = self.get_IoU(predictions[:, 1:5, ...], groundtruths[:, 1:5, ...])\n",
    "            iou2 = self.get_IoU(predictions[:, 6:10, ...], groundtruths[:, 1:5, ...])\n",
    "\n",
    "        ious = torch.stack([iou1, iou2], dim=1)\n",
    "        max_iou, best_box = ious.max(dim=1, keepdim=True)\n",
    "        max_iou = torch.cat([max_iou, max_iou], dim=1)\n",
    "        best_box = torch.cat([best_box.eq(0), best_box.eq(1)], dim=1)\n",
    "\n",
    "        predictions_ = predictions[:, :5*2, ...].reshape(self.batch_size, 2, 5, self.grid_size, self.grid_size)\n",
    "        obj_pred = predictions_[:, :, 0, ...]\n",
    "        xy_pred = predictions_[:, :, 1:3, ...]\n",
    "        wh_pred = predictions_[:, :, 3:5, ...]\n",
    "        cls_pred = predictions[:, 5*2:, ...]\n",
    "\n",
    "        groundtruths_ = groundtruths[:, :5, ...].reshape(self.batch_size, 1, 5, self.grid_size, self.grid_size)\n",
    "        obj_target = groundtruths_[:, :, 0, ...]\n",
    "        xy_target = groundtruths_[:, :, 1:3, ...]\n",
    "        wh_target= groundtruths_[:, :, 3:5, ...]\n",
    "        cls_target = groundtruths[:, 5:, ...]\n",
    "        \n",
    "        positive = obj_target * best_box\n",
    "\n",
    "        obj_loss = self.mse_loss(positive * obj_pred, positive * ious)\n",
    "        noobj_loss = self.mse_loss((1 - positive) * obj_pred, ious*0)\n",
    "        xy_loss = self.mse_loss(positive.unsqueeze(dim=2) * xy_pred, positive.unsqueeze(dim=2) * xy_target)\n",
    "        wh_loss = self.mse_loss(positive.unsqueeze(dim=2) * (wh_pred.sign() * (wh_pred.abs() + 1e-8).sqrt()),\n",
    "                           positive.unsqueeze(dim=2) * (wh_target + 1e-8).sqrt())\n",
    "        cls_loss = self.mse_loss(obj_target * cls_pred, cls_target)\n",
    "        \n",
    "        obj_loss /= self.batch_size\n",
    "        noobj_loss /= self.batch_size\n",
    "        bbox_loss = (xy_loss+wh_loss) / self.batch_size\n",
    "        cls_loss /= self.batch_size\n",
    "        \n",
    "        total_loss = obj_loss + self.lambda_noobj*noobj_loss + self.lambda_coord*bbox_loss + cls_loss\n",
    "        return total_loss, (obj_loss.item(), noobj_loss.item(), bbox_loss.item(), cls_loss.item())\n",
    "    \n",
    "    def build_target_grid(self, target):\n",
    "        target_grid = torch.zeros((1+4+self.num_classes, self.grid_size, self.grid_size), device=self.device)\n",
    "\n",
    "        for gt in target:\n",
    "            xc, yc, w, h, cls_id = gt\n",
    "            xn = (xc % (1/self.grid_size))\n",
    "            yn = (yc % (1/self.grid_size))\n",
    "            cls_id = int(cls_id)\n",
    "\n",
    "            i_grid = int(xc * self.grid_size)\n",
    "            j_grid = int(yc * self.grid_size)\n",
    "            target_grid[0, j_grid, i_grid] = 1\n",
    "            target_grid[1:5, j_grid, i_grid] = torch.Tensor([xn,yn,w,h])\n",
    "#             print(5+cls_id, j_grid, i_grid)\n",
    "            target_grid[5+cls_id, j_grid, i_grid] = 1\n",
    "\n",
    "        return target_grid\n",
    "    \n",
    "    def build_batch_target_grid(self, targets):\n",
    "        target_grid_batch = torch.stack([self.build_target_grid(target) for target in targets], dim=0)\n",
    "        return target_grid_batch\n",
    "    \n",
    "    def get_IoU(self, cbox1, cbox2):\n",
    "        box1 = self.xywh_to_xyxy(cbox1)\n",
    "        box2 = self.xywh_to_xyxy(cbox2)\n",
    "\n",
    "        x1 = torch.max(box1[:, 0, ...], box2[:, 0, ...])\n",
    "        y1 = torch.max(box1[:, 1, ...], box2[:, 1, ...])\n",
    "        x2 = torch.min(box1[:, 2, ...], box2[:, 2, ...])\n",
    "        y2 = torch.min(box1[:, 3, ...], box2[:, 3, ...])\n",
    "\n",
    "        intersection = (x2-x1).clamp(min=0) * (y2-y1).clamp(min=0)\n",
    "        union = abs(cbox1[:, 2, ...]*cbox1[:, 3, ...]) + \\\n",
    "                abs(cbox2[:, 2, ...]*cbox2[:, 3, ...]) - intersection\n",
    "\n",
    "        intersection[intersection.gt(0)] = intersection[intersection.gt(0)] / union[intersection.gt(0)]\n",
    "        return intersection\n",
    "    \n",
    "    def generate_xy_normed_grid(self):\n",
    "        y_offset, x_offset = torch.meshgrid(torch.arange(self.grid_size), torch.arange(self.grid_size))\n",
    "        xy_grid = torch.stack([x_offset, y_offset], dim=0)\n",
    "        xy_normed_grid = xy_grid / self.grid_size\n",
    "        return xy_normed_grid.to(self.device)\n",
    "\n",
    "    def xywh_to_xyxy(self, bboxes):\n",
    "        xy_normed_grid = self.generate_xy_normed_grid()\n",
    "        xcyc = bboxes[:,0:2,...] + xy_normed_grid.tile(self.batch_size, 1,1,1)\n",
    "        wh = bboxes[:,2:4,...]\n",
    "        x1y1 = xcyc - (wh/2)\n",
    "        x2y2 = xcyc + (wh/2)\n",
    "        return torch.cat([x1y1, x2y2], dim=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62bbfb76",
   "metadata": {},
   "source": [
    "## Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "4eb59e4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_one_epoch(dataloaders, model, criterion, optimizer, device):\n",
    "    train_loss = defaultdict(float)\n",
    "    val_loss = defaultdict(float)\n",
    "    \n",
    "    for phase in [\"train\", \"val\"]:\n",
    "        if phase == \"train\":\n",
    "            model.train()\n",
    "        else:\n",
    "            model.eval()\n",
    "        \n",
    "        running_loss = defaultdict(float)\n",
    "        for index, batch in enumerate(dataloaders[phase]):\n",
    "            images = batch[0].to(device)\n",
    "            targets = batch[1]\n",
    "            filenames = batch[2]\n",
    "            \n",
    "            with torch.set_grad_enabled(phase == \"train\"): # phase가 train 일때만 gradient 추적기능을 킨다.\n",
    "                predictions = model(images) #prediction shape=> B,12,7,7\n",
    "#             print(f\"predictions:{predictions}, \\ntargets: {targets}\\n\")\n",
    "            loss, (obj_loss, noobj_loss, bbox_loss, cls_loss) = criterion(predictions, targets)\n",
    "#             print(f\"loss:{loss}, obj_loss:{obj_loss}, noobj_loss:{noobj_loss}\\nbbox_loss:{bbox_loss}, cls_loss:{cls_loss}\\n--------------\\n\")\n",
    "            if phase == \"train\":\n",
    "                optimizer.zero_grad()\n",
    "                loss.backward()\n",
    "                optimizer.step()\n",
    "                \n",
    "                # 현재 epoch단계에서 loss가 얼마인지 running loss 가출력\n",
    "                running_loss[\"total_loss\"] += loss.item()\n",
    "                running_loss[\"obj_loss\"] += obj_loss\n",
    "                running_loss[\"noobj_loss\"] += noobj_loss\n",
    "                running_loss[\"bbox_loss\"] += bbox_loss\n",
    "                running_loss[\"cls_loss\"] += cls_loss\n",
    "                \n",
    "                train_loss[\"total_loss\"] += loss.item()\n",
    "                train_loss[\"obj_loss\"] += obj_loss\n",
    "                train_loss[\"noobj_loss\"] += noobj_loss\n",
    "                train_loss[\"bbox_loss\"] += bbox_loss\n",
    "                train_loss[\"cls_loss\"] += cls_loss\n",
    "                \n",
    "                if (index > 0) and (index % VERBOSE_FREQ) == 0:\n",
    "                    text = f\"<<<iteration:[{index}/{len(dataloaders[phase])}] - \"\n",
    "                    for k, v in running_loss.items():\n",
    "                        text += f\"{k}: {v/VERBOSE_FREQ:.4f}  \"\n",
    "                        running_loss[k] = 0.\n",
    "                    print(text)\n",
    "            else:\n",
    "                val_loss[\"total_loss\"] += loss.item()\n",
    "                val_loss[\"obj_loss\"] += obj_loss\n",
    "                val_loss[\"noobj_loss\"] += noobj_loss\n",
    "                val_loss[\"bbox_loss\"] += bbox_loss\n",
    "                val_loss[\"cls_loss\"] += cls_loss\n",
    "\n",
    "    for k in train_loss.keys():\n",
    "        train_loss[k] /= len(dataloaders[\"train\"])\n",
    "        val_loss[k] /= len(dataloaders[\"val\"])\n",
    "    return train_loss, val_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "97049805",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_dataloader(part, NECK_PATH, BODY_PATH, batch_size=2, aug_factor=0):\n",
    "    IMAGE_SIZE = 448\n",
    "    transformer = A.Compose([\n",
    "            A.Resize(height=IMAGE_SIZE, width=IMAGE_SIZE),\n",
    "            A.Normalize(mean=(0.485, 0.456, 0.406),std=(0.229, 0.224, 0.225)),\n",
    "            ToTensorV2(),\n",
    "        ],\n",
    "        bbox_params=A.BboxParams(format='yolo', label_fields=['class_ids']),\n",
    "    )\n",
    "    augmentator=A.Compose([\n",
    "    #     A.Resize(height=IMAGE_SIZE, width=IMAGE_SIZE),\n",
    "        A.HorizontalFlip(p=0.7),\n",
    "    #     A.Sharpen(p=0.7),\n",
    "        A.BBoxSafeRandomCrop(p=0.6),\n",
    "        A.VerticalFlip (p=0.6),\n",
    "        A.HueSaturationValue(p=0.6),\n",
    "        A.Resize(height=IMAGE_SIZE, width=IMAGE_SIZE),\n",
    "        A.Normalize(mean=(0.485, 0.456, 0.406),std=(0.229, 0.224, 0.225)),\n",
    "        ToTensorV2(),\n",
    "        ],\n",
    "        bbox_params=A.BboxParams(format='yolo', label_fields=['class_ids']),\n",
    "    )\n",
    "    \n",
    "    dataloaders = {}\n",
    "#     train_dataset = Detection_dataset(data_dir=data_dir, phase=\"train\", transformer=transformer)\n",
    "#     train_dataset=PET_dataset(part ,neck_dir=NECK_PATH,body_dir=BODY_PATH,phase='train', transformer=transformer, aug=augmentator, aug_factor=aug_factor)\n",
    "    train_dataset=PET_dataset(part ,neck_dir=NECK_PATH,body_dir=BODY_PATH,phase='train', transformer=transformer, aug=None)\n",
    "    dataloaders[\"train\"] = DataLoader(train_dataset, batch_size=batch_size, shuffle=True, collate_fn=collate_fn)\n",
    "\n",
    "#     val_dataset = Detection_dataset(data_dir=data_dir, phase=\"val\", transformer=transformer)\n",
    "    val_dataset=PET_dataset(part ,neck_dir=NECK_PATH,body_dir=BODY_PATH,phase='valid', transformer=transformer, aug=None)\n",
    "    dataloaders[\"val\"] = DataLoader(val_dataset, batch_size=batch_size, shuffle=False, collate_fn=collate_fn)\n",
    "    print(f\"trainset:{len(train_dataset)} validset:{len(val_dataset)}\")\n",
    "    return dataloaders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "c260f44c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "start making augmented images-- augmented factor:0\n",
      "total length of augmented images: 0\n",
      "start making augmented images-- augmented factor:0\n",
      "total length of augmented images: 0\n",
      "trainset:10500 validset:1800\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_2873/1777674582.py:131: UserWarning: nn.init.kaiming_normal is now deprecated in favor of nn.init.kaiming_normal_.\n",
      "  init.kaiming_normal(self.fc.weight)\n",
      "/tmp/ipykernel_2873/1777674582.py:135: UserWarning: nn.init.kaiming_normal is now deprecated in favor of nn.init.kaiming_normal_.\n",
      "  init.kaiming_normal(self.state_dict()[key], mode='fan_out')\n"
     ]
    }
   ],
   "source": [
    "# data_dir = \"/content/drive/MyDrive/fastCamMedicalProj/DATASET/DATASET/Detection/\"\n",
    "# NECK_PATH = '/home/host_data/PET_data/Neck'\n",
    "# BODY_PATH = '/home/host_data/PET_data/Body'\n",
    "NECK_PATH = '/home/host_data/PET_data_image_patching/patched_Neck'\n",
    "BODY_PATH = '/home/host_data/PET_data_image_patching/Body'\n",
    "is_cuda = True\n",
    "\n",
    "NUM_CLASSES = 2\n",
    "IMAGE_SIZE = 448\n",
    "BATCH_SIZE = 16\n",
    "VERBOSE_FREQ = 20\n",
    "LR=0.0001\n",
    "AUG_FACTOR=0\n",
    "PATCH_FACTOR=50\n",
    "BACKBONE=\"YOLO_RESNET_CBAM\"\n",
    "PART=\"neck\"\n",
    "num_epochs = 100\n",
    "# DEVICE = torch.device('cuda' if torch.cuda.is_available and is_cuda else 'cpu')\n",
    "\n",
    "dataloaders = build_dataloader(part=PART,NECK_PATH=NECK_PATH,BODY_PATH=BODY_PATH,batch_size=BATCH_SIZE, aug_factor=AUG_FACTOR)\n",
    "model = YOLO_SWIN(num_classes=NUM_CLASSES)\n",
    "model = model.to(device)\n",
    "criterion = YOLO_LOSS(num_classes=NUM_CLASSES, device=device)\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=LR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "817b20fb",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mgomduribo\u001b[0m (\u001b[33murp\u001b[0m). Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.15.12 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.15.11"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/workspace/Plastic_Bottle_defect_detection/experiments/wandb/run-20231029_052112-2ha0l5n1</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/urp/yolo_cbam_neck_IMAGE_PATCH/runs/2ha0l5n1' target=\"_blank\">volcanic-bee-1</a></strong> to <a href='https://wandb.ai/urp/yolo_cbam_neck_IMAGE_PATCH' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/urp/yolo_cbam_neck_IMAGE_PATCH' target=\"_blank\">https://wandb.ai/urp/yolo_cbam_neck_IMAGE_PATCH</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/urp/yolo_cbam_neck_IMAGE_PATCH/runs/2ha0l5n1' target=\"_blank\">https://wandb.ai/urp/yolo_cbam_neck_IMAGE_PATCH/runs/2ha0l5n1</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<button onClick=\"this.nextSibling.style.display='block';this.style.display='none';\">Display W&B run</button><iframe src='https://wandb.ai/urp/yolo_cbam_neck_IMAGE_PATCH/runs/2ha0l5n1?jupyter=true' style='border:none;width:100%;height:420px;display:none;'></iframe>"
      ],
      "text/plain": [
       "<wandb.sdk.wandb_run.Run at 0x7f207061fd60>"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import wandb\n",
    "import random\n",
    "\n",
    "# start a new wandb run to track this script\n",
    "wandb.init(\n",
    "    # set the wandb project where this run will be logged\n",
    "    project=\"yolo_cbam_neck_IMAGE_PATCH\",\n",
    "    \n",
    "    # track hyperparameters and run metadata\n",
    "    config={\n",
    "    \"learning_rate\": LR,\n",
    "    \"batch_size\": BATCH_SIZE,\n",
    "    \"architecture\": BACKBONE,\n",
    "    \"dataset\": PART,\n",
    "    \"epochs\": num_epochs,\n",
    "    \"patch factor\":PATCH_FACTOR,\n",
    "    \"aug factor\":AUG_FACTOR,\n",
    "    }\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "0b358951",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.8/dist-packages/torch/nn/functional.py:1967: UserWarning: nn.functional.sigmoid is deprecated. Use torch.sigmoid instead.\n",
      "  warnings.warn(\"nn.functional.sigmoid is deprecated. Use torch.sigmoid instead.\")\n",
      "/usr/local/lib/python3.8/dist-packages/torch/functional.py:504: UserWarning: torch.meshgrid: in an upcoming release, it will be required to pass the indexing argument. (Triggered internally at /opt/pytorch/pytorch/aten/src/ATen/native/TensorShape.cpp:3423.)\n",
      "  return _VF.meshgrid(tensors, **kwargs)  # type: ignore[attr-defined]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<<<iteration:[20/657] - total_loss: 10.1845  obj_loss: 0.1299  noobj_loss: 11.5701  bbox_loss: 0.5955  cls_loss: 1.2919  \n",
      "<<<iteration:[40/657] - total_loss: 7.8270  obj_loss: 0.1283  noobj_loss: 8.8927  bbox_loss: 0.5244  cls_loss: 0.6303  \n",
      "<<<iteration:[60/657] - total_loss: 7.3574  obj_loss: 0.1167  noobj_loss: 8.6518  bbox_loss: 0.4767  cls_loss: 0.5314  \n",
      "<<<iteration:[80/657] - total_loss: 6.3902  obj_loss: 0.0921  noobj_loss: 6.6878  bbox_loss: 0.4878  cls_loss: 0.5149  \n",
      "<<<iteration:[100/657] - total_loss: 5.8531  obj_loss: 0.0809  noobj_loss: 6.1053  bbox_loss: 0.4443  cls_loss: 0.4981  \n",
      "<<<iteration:[120/657] - total_loss: 5.0827  obj_loss: 0.0692  noobj_loss: 5.0795  bbox_loss: 0.4108  cls_loss: 0.4195  \n",
      "<<<iteration:[140/657] - total_loss: 5.1290  obj_loss: 0.0676  noobj_loss: 5.3390  bbox_loss: 0.3984  cls_loss: 0.3997  \n",
      "<<<iteration:[160/657] - total_loss: 5.5292  obj_loss: 0.0680  noobj_loss: 5.6231  bbox_loss: 0.4428  cls_loss: 0.4358  \n",
      "<<<iteration:[180/657] - total_loss: 4.4929  obj_loss: 0.0535  noobj_loss: 3.9740  bbox_loss: 0.4112  cls_loss: 0.3964  \n",
      "<<<iteration:[200/657] - total_loss: 4.7099  obj_loss: 0.0645  noobj_loss: 4.7327  bbox_loss: 0.3765  cls_loss: 0.3963  \n",
      "<<<iteration:[220/657] - total_loss: 4.5702  obj_loss: 0.0521  noobj_loss: 3.8758  bbox_loss: 0.4338  cls_loss: 0.4110  \n",
      "<<<iteration:[240/657] - total_loss: 4.0245  obj_loss: 0.0493  noobj_loss: 3.1150  bbox_loss: 0.4204  cls_loss: 0.3160  \n",
      "<<<iteration:[260/657] - total_loss: 3.7079  obj_loss: 0.0564  noobj_loss: 3.2746  bbox_loss: 0.3342  cls_loss: 0.3432  \n",
      "<<<iteration:[280/657] - total_loss: 3.8944  obj_loss: 0.0499  noobj_loss: 3.4797  bbox_loss: 0.3489  cls_loss: 0.3604  \n",
      "<<<iteration:[300/657] - total_loss: 3.0805  obj_loss: 0.0395  noobj_loss: 2.2780  bbox_loss: 0.3153  cls_loss: 0.3255  \n",
      "<<<iteration:[320/657] - total_loss: 2.8697  obj_loss: 0.0398  noobj_loss: 2.2587  bbox_loss: 0.2792  cls_loss: 0.3044  \n",
      "<<<iteration:[340/657] - total_loss: 3.0979  obj_loss: 0.0453  noobj_loss: 2.6013  bbox_loss: 0.2869  cls_loss: 0.3174  \n",
      "<<<iteration:[360/657] - total_loss: 2.8787  obj_loss: 0.0334  noobj_loss: 2.0355  bbox_loss: 0.2929  cls_loss: 0.3633  \n",
      "<<<iteration:[380/657] - total_loss: 2.8990  obj_loss: 0.0414  noobj_loss: 2.2088  bbox_loss: 0.2829  cls_loss: 0.3386  \n",
      "<<<iteration:[400/657] - total_loss: 2.7339  obj_loss: 0.0375  noobj_loss: 1.8847  bbox_loss: 0.2846  cls_loss: 0.3313  \n",
      "<<<iteration:[420/657] - total_loss: 2.4861  obj_loss: 0.0363  noobj_loss: 1.7170  bbox_loss: 0.2598  cls_loss: 0.2923  \n",
      "<<<iteration:[440/657] - total_loss: 2.5161  obj_loss: 0.0371  noobj_loss: 1.8055  bbox_loss: 0.2488  cls_loss: 0.3323  \n",
      "<<<iteration:[460/657] - total_loss: 2.4079  obj_loss: 0.0351  noobj_loss: 1.5719  bbox_loss: 0.2546  cls_loss: 0.3140  \n",
      "<<<iteration:[480/657] - total_loss: 2.5108  obj_loss: 0.0316  noobj_loss: 1.6650  bbox_loss: 0.2614  cls_loss: 0.3397  \n",
      "<<<iteration:[500/657] - total_loss: 2.3352  obj_loss: 0.0358  noobj_loss: 1.4438  bbox_loss: 0.2521  cls_loss: 0.3168  \n",
      "<<<iteration:[520/657] - total_loss: 2.2175  obj_loss: 0.0342  noobj_loss: 1.3477  bbox_loss: 0.2370  cls_loss: 0.3243  \n",
      "<<<iteration:[540/657] - total_loss: 2.1299  obj_loss: 0.0388  noobj_loss: 1.3411  bbox_loss: 0.2240  cls_loss: 0.3004  \n",
      "<<<iteration:[560/657] - total_loss: 2.1202  obj_loss: 0.0292  noobj_loss: 1.1689  bbox_loss: 0.2414  cls_loss: 0.2995  \n",
      "<<<iteration:[580/657] - total_loss: 2.0141  obj_loss: 0.0337  noobj_loss: 1.1713  bbox_loss: 0.2167  cls_loss: 0.3113  \n",
      "<<<iteration:[600/657] - total_loss: 1.9222  obj_loss: 0.0271  noobj_loss: 1.0622  bbox_loss: 0.2071  cls_loss: 0.3287  \n",
      "<<<iteration:[620/657] - total_loss: 1.9112  obj_loss: 0.0343  noobj_loss: 1.0230  bbox_loss: 0.2151  cls_loss: 0.2901  \n",
      "<<<iteration:[640/657] - total_loss: 1.8548  obj_loss: 0.0340  noobj_loss: 1.0735  bbox_loss: 0.2004  cls_loss: 0.2819  \n",
      "\n",
      "epoch:1/100 - Train Loss: 3.7796, Val Loss: 2.2452\n",
      "\n",
      "<<<iteration:[20/657] - total_loss: 1.6535  obj_loss: 0.0342  noobj_loss: 0.9222  bbox_loss: 0.1738  cls_loss: 0.2893  \n",
      "<<<iteration:[40/657] - total_loss: 1.8944  obj_loss: 0.0310  noobj_loss: 0.8270  bbox_loss: 0.2298  cls_loss: 0.3008  \n",
      "<<<iteration:[60/657] - total_loss: 1.6946  obj_loss: 0.0328  noobj_loss: 0.7790  bbox_loss: 0.1914  cls_loss: 0.3151  \n",
      "<<<iteration:[80/657] - total_loss: 1.6154  obj_loss: 0.0389  noobj_loss: 0.7915  bbox_loss: 0.1875  cls_loss: 0.2430  \n",
      "<<<iteration:[100/657] - total_loss: 1.4703  obj_loss: 0.0352  noobj_loss: 0.7433  bbox_loss: 0.1551  cls_loss: 0.2881  \n",
      "<<<iteration:[120/657] - total_loss: 1.5040  obj_loss: 0.0367  noobj_loss: 0.6818  bbox_loss: 0.1683  cls_loss: 0.2848  \n",
      "<<<iteration:[140/657] - total_loss: 1.5877  obj_loss: 0.0360  noobj_loss: 0.7452  bbox_loss: 0.1827  cls_loss: 0.2654  \n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[30], line 7\u001b[0m\n\u001b[1;32m      4\u001b[0m val_losses \u001b[38;5;241m=\u001b[39m []\n\u001b[1;32m      6\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m epoch \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(num_epochs):\n\u001b[0;32m----> 7\u001b[0m     train_loss, val_loss \u001b[38;5;241m=\u001b[39m \u001b[43mtrain_one_epoch\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdataloaders\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcriterion\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moptimizer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      8\u001b[0m     train_losses\u001b[38;5;241m.\u001b[39mappend(train_loss)\n\u001b[1;32m      9\u001b[0m     val_losses\u001b[38;5;241m.\u001b[39mappend(val_loss)\n",
      "Cell \u001b[0;32mIn[26], line 13\u001b[0m, in \u001b[0;36mtrain_one_epoch\u001b[0;34m(dataloaders, model, criterion, optimizer, device)\u001b[0m\n\u001b[1;32m     11\u001b[0m running_loss \u001b[38;5;241m=\u001b[39m defaultdict(\u001b[38;5;28mfloat\u001b[39m)\n\u001b[1;32m     12\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m index, batch \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(dataloaders[phase]):\n\u001b[0;32m---> 13\u001b[0m     images \u001b[38;5;241m=\u001b[39m \u001b[43mbatch\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m]\u001b[49m\u001b[38;5;241m.\u001b[39mto(device)\n\u001b[1;32m     14\u001b[0m     targets \u001b[38;5;241m=\u001b[39m batch[\u001b[38;5;241m1\u001b[39m]\n\u001b[1;32m     15\u001b[0m     filenames \u001b[38;5;241m=\u001b[39m batch[\u001b[38;5;241m2\u001b[39m]\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "best_epoch = 0\n",
    "best_score = float('inf')\n",
    "train_losses = []\n",
    "val_losses = []\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    train_loss, val_loss = train_one_epoch(dataloaders, model, criterion, optimizer, device)\n",
    "    train_losses.append(train_loss)\n",
    "    val_losses.append(val_loss)\n",
    "#     train_loss[\"obj_loss\"] += obj_loss\n",
    "#     train_loss[\"noobj_loss\"] += noobj_loss\n",
    "#     train_loss[\"bbox_loss\"] += bbox_loss\n",
    "#     train_loss[\"cls_loss\"] += cls_loss\n",
    "    wandb.log({\"Train Loss\": train_loss['total_loss'],\n",
    "               \"Train obj Loss\":train_loss[\"obj_loss\"],\n",
    "               \"Train bbox Loss\":train_loss[\"bbox_loss\"],\n",
    "               \"Train class Loss\":train_loss[\"cls_loss\"],\n",
    "               \"Val Loss\": val_loss['total_loss'],\n",
    "               \"Val obj Loss\":val_loss[\"obj_loss\"],\n",
    "               \"Val bbox Loss\":val_loss[\"bbox_loss\"],\n",
    "               \"Val class Loss\":val_loss[\"cls_loss\"],})\n",
    "    print(f\"\\nepoch:{epoch+1}/{num_epochs} - Train Loss: {train_loss['total_loss']:.4f}, Val Loss: {val_loss['total_loss']:.4f}\\n\")\n",
    "    \n",
    "    if (epoch+1) % 10 == 0:\n",
    "        save_model(model.state_dict(), f'model_{epoch+1}.pth', save_dir=f\"./trained_model/{BACKBONE}_{PART}_LR{LR}_IP{PATCH_FACTOR}\")\n",
    "wandb.finish()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4637805f",
   "metadata": {},
   "source": [
    "## Test Dataset Inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb53d0b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import os \n",
    "import pandas as pd\n",
    "import cv2\n",
    "import torch\n",
    "import matplotlib.pyplot as plt\n",
    "from ipywidgets import interact\n",
    "import albumentations as A\n",
    "from albumentations.pytorch import ToTensorV2\n",
    "import torchvision\n",
    "from torch import nn\n",
    "import torchsummary\n",
    "from torch.utils.data import DataLoader\n",
    "from collections import defaultdict\n",
    "from torchvision.utils import make_grid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d867479",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0594e046",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_model(ckpt_path, num_classes, device):\n",
    "    checkpoint = torch.load(ckpt_path, map_location=device)\n",
    "    model = YOLO_SWIN(num_classes=num_classes)\n",
    "    model.load_state_dict(checkpoint)\n",
    "    model = model.to(device)\n",
    "    model.eval()\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af5b0a1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "IMAGE_SIZE=448\n",
    "transformer = A.Compose([\n",
    "            A.Resize(height=IMAGE_SIZE, width=IMAGE_SIZE),\n",
    "            A.Normalize(mean=(0.485, 0.456, 0.406),std=(0.229, 0.224, 0.225)),\n",
    "            ToTensorV2(),\n",
    "        ],\n",
    "        bbox_params=A.BboxParams(format='yolo', label_fields=['class_ids']),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1e6b930",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ckpt_path=\"./trained_model/YOLO_SWIN_T_body_LR0.0001_AUG30/model_90.pth\"\n",
    "ckpt_path=\"/workspace/Plastic_Bottle_defect_detection/trained_model/YOLO_SWIN_T_neck_LR0.0001_Image_Patch50/model_100.pth\"\n",
    "model = load_model(ckpt_path, NUM_CLASSES, device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8cb2aaaf",
   "metadata": {},
   "outputs": [],
   "source": [
    "NECK_PATH = '/home/host_data/PET_data/Neck'\n",
    "BODY_PATH = '/home/host_data/PET_data/Body'\n",
    "test_dataset=PET_dataset(\"neck\" ,neck_dir=NECK_PATH,body_dir=BODY_PATH,phase='test', transformer=transformer, aug=None)\n",
    "test_dataloaders = DataLoader(test_dataset, batch_size=1, shuffle=False, collate_fn=collate_fn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a2e8599",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(test_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "adf189c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "@torch.no_grad()\n",
    "def model_predict(image, model, conf_thres=0.2, iou_threshold=0.1):\n",
    "    predictions = model(image)\n",
    "    prediction = predictions.detach().cpu().squeeze(dim=0)\n",
    "    f_map=prediction\n",
    "\n",
    "#     print(prediction.shape)\n",
    "    \n",
    "    grid_size = prediction.shape[-1]\n",
    "    y_grid, x_grid = torch.meshgrid(torch.arange(grid_size), torch.arange(grid_size))\n",
    "    stride_size = IMAGE_SIZE/grid_size\n",
    "\n",
    "    conf = prediction[[0,5], ...].reshape(1, -1)\n",
    "    xc = (prediction[[1,6], ...] * IMAGE_SIZE + x_grid*stride_size).reshape(1,-1)\n",
    "    yc = (prediction[[2,7], ...] * IMAGE_SIZE + y_grid*stride_size).reshape(1,-1)\n",
    "    w = (prediction[[3,8], ...] * IMAGE_SIZE).reshape(1,-1)\n",
    "    h = (prediction[[4,9], ...] * IMAGE_SIZE).reshape(1,-1)\n",
    "    cls = torch.max(prediction[10:, ...].reshape(NUM_CLASSES, -1), dim=0).indices.tile(1,2)\n",
    "    \n",
    "    x_min = xc - w/2\n",
    "    y_min = yc - h/2\n",
    "    x_max = xc + w/2\n",
    "    y_max = yc + h/2\n",
    "\n",
    "    prediction_res = torch.cat([x_min, y_min, x_max, y_max, conf, cls], dim=0)\n",
    "    prediction_res = prediction_res.transpose(0,1)\n",
    "\n",
    "    # x_min과 y_min이 음수가 되지않고, x_max와 y_max가 이미지 크기를 넘지 않게 제한\n",
    "    prediction_res[:, 2].clip(min=0, max=image.shape[1]) \n",
    "    prediction_res[:, 3].clip(min=0, max=image.shape[0])\n",
    "        \n",
    "    pred_res = prediction_res[prediction_res[:, 4] > conf_thres]\n",
    "    nms_index = torchvision.ops.nms(boxes=pred_res[:, 0:4], scores=pred_res[:, 4], iou_threshold=iou_threshold)\n",
    "    pred_res_ = pred_res[nms_index].numpy()\n",
    "    \n",
    "    n_obj = pred_res_.shape[0]\n",
    "    bboxes = np.zeros(shape=(n_obj, 4), dtype=np.float32)\n",
    "    bboxes[:, 0:2] = (pred_res_[:, 0:2] + pred_res_[:, 2:4]) / 2\n",
    "    bboxes[:, 2:4] = pred_res_[:, 2:4] - pred_res_[:, 0:2]\n",
    "    scores = pred_res_[:, 4]\n",
    "    class_ids = pred_res_[:, 5]\n",
    "    \n",
    "    # 이미지 값이 들어가면 모델을 통해서, 후처리까지 포함된 yolo 포멧의 box좌표, 그 좌표에 대한 confidence score\n",
    "    # 그리고 class id를 반환\n",
    "    return bboxes, scores, class_ids,f_map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4b23b08",
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_images = []\n",
    "pred_labels =[]\n",
    "feature_maps=[]\n",
    "\n",
    "for index, batch in enumerate(test_dataloaders):\n",
    "    images = batch[0].to(device)\n",
    "    bboxes, scores, class_ids, fmap = model_predict(images, model, conf_thres=0.1, iou_threshold=0.1)\n",
    "    \n",
    "    if len(bboxes) > 0:\n",
    "        prediction_yolo = np.concatenate([bboxes, scores[:, np.newaxis], class_ids[:, np.newaxis]], axis=1)\n",
    "    else:\n",
    "        prediction_yolo = np.array([])\n",
    "    \n",
    "    # 텐서형의 이미지를 다시 unnormalize를 시키고, 다시 chw를 hwc로 바꾸고 넘파이로 바꾼다.\n",
    "    np_image = make_grid(images[0], normalize=True).cpu().permute(1,2,0).numpy()\n",
    "    pred_images.append(np_image)\n",
    "    pred_labels.append(prediction_yolo)\n",
    "    feature_maps.append(fmap)\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c8d0fca",
   "metadata": {},
   "outputs": [],
   "source": [
    "from ipywidgets import interact\n",
    "\n",
    "@interact(index=(0,len(pred_images)-1))\n",
    "def show_result(index=0):\n",
    "    print(pred_labels[index])\n",
    "    if len(pred_labels[index]) > 0:\n",
    "        result = visualize(pred_images[index], pred_labels[index][:, 0:4], pred_labels[index][:, 5])\n",
    "    else:\n",
    "        result = pred_images[index]\n",
    "        \n",
    "    plt.figure(figsize=(6,6))\n",
    "    plt.imshow(result)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e21a11e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#feature map에서 0,5번쨰에 해당하는 objectness 투사\n",
    "from ipywidgets import interact\n",
    "\n",
    "@interact(index=(0,len(pred_images)-1))\n",
    "def show_result(index=0):\n",
    "    print(pred_labels[index])\n",
    "    if len(pred_labels[index]) > 0:\n",
    "        result = visualize(pred_images[index], pred_labels[index][:, 0:4], pred_labels[index][:, 5])\n",
    "    else:\n",
    "        result = pred_images[index]\n",
    "    \n",
    "    f_map=feature_maps[index]\n",
    "    zero_canvas=np.zeros((448,448))\n",
    "\n",
    "    cv_re1=cv2.resize(f_map[0,:,:].numpy(),(448,448))\n",
    "    cv_re2=cv2.resize(f_map[5,:,:].numpy(),(448,448))\n",
    "    zero_canvas=zero_canvas+cv_re1+cv_re2\n",
    "\n",
    "    \n",
    "    fig = plt.figure()\n",
    "    rows = 1\n",
    "    cols = 2\n",
    "    ax1 = fig.add_subplot(rows, cols, 1)\n",
    "    ax1.imshow(result)\n",
    "    ax1.set_title('Detection')\n",
    "    ax1.axis(\"off\")\n",
    "    \n",
    "    ax2 = fig.add_subplot(rows, cols, 2)\n",
    "    ax2.imshow(zero_canvas)\n",
    "    ax2.set_title('feature map-objectness')\n",
    "    ax2.axis(\"off\")\n",
    "\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c749262",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f10c99f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de590e88",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
